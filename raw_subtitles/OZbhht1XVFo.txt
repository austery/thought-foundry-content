- When we think about technology, we think about 
social media, we think about search engines,  
we think about apps on our phones, but 
undergirding all of this are chips. The  
reason that technology that we think of exists is 
because every year chips get better and better.  
And so I think we've actually misunderstood what 
technology means. We think of the easy part,  
which is writing the software. But the 
hard part is actually manufacturing the  
chips that give us the advances in 
computing that enable us to have a  
computer on our phone or to attach devices to 
the internet. All that has been made possible  
by better and better semiconductors. I'm 
Chris Miller, a professor at The Fletcher  
School and author of, "Chip War: The Fight 
for the World's Most Critical Technology."
- [Announcer] Chapter One, 
"How to Build a Microchip."
- Well, I first got interested in chips when 
I realized you really couldn't understand how  
the world works without them. Whether it's walking 
around your house and realizing there are chips in  
almost every device you rely on. Or trying to 
understand big shifts in international trade,  
there's no good that is traded more than 
semiconductors. Or looking at the political  
dynamics around the world, with the US-China 
competition focusing on technology. Chips are  
at the center of all of these major trends. But 
a chip is a piece of silicon, often the size of  
your fingernail. And in it is carved thousands, or 
millions, in some cases billions of tiny devices  
called transistors, which flip circuits on 
or off, on and off. And when they're on,  
they produce a one. When they're off, they produce 
a zero. And all of the ones and zeros undergirding  
computing, undergirding data storage, all of 
your Instagram likes, all of your text messages,  
these are all just long strings of ones and zeros, 
which are created on the chip by these circuits  
flipping on and off. There are a couple different 
categories of chips. Some chips process data,  
other chips remember data, and a third category 
turns real world signals, like audio or pictures  
into ones and zeros so that they can then be 
processed or remembered. And so when we look  
at the world, we see pictures. But when a phone, 
for example, uses its camera to look at the world,  
it takes in lots of rays of light, and then 
has to learn how to convert those into ones  
and zeros that can be stored. And so there's 
very specific sensors for pictures, for sound,  
for radio waves that use semiconductors to 
convert these real world signals into strings  
in ones of zeros that can then be re-represented 
as pictures later on, for example, when you pull  
a photo up on your phone. All of this is done by 
different types of semiconductors. So, generally,  
chips have a foundation of silicon, but there are 
dozens of other materials that are layered on top  
to make the transistors at such tiny scale. So 
a typical advanced chip could have several dozen  
materials. The foundation is silicon, but 
there are many other chemicals involved in  
the process. Yeah, it's true that sand is from 
silicon and so are chips, but the similarities  
basically end there. The silicon that's used in 
manufacturing chips is among the most purified  
elements that we have. And the reason is that when 
you're manufacturing chips with tiny transistors,  
you need to place almost every atom perfectly 
to make those chips work. Which means that if  
your silicon, or any of the other materials that 
you're using, has even a single atomic impurity,  
it can cause defects in the way your chip 
functions. And so the production of the silicon  
wafers that are used in the chip manufacturing 
process requires extraordinary levels of purity.  
There's really just four companies in the world 
today that are capable of producing silicon  
wafers at the right level of purity at the scale 
that's required for contemporary manufacturing.  
The good news is that there's silicon everywhere. 
It's one of the most widely-distributed elements  
in the Earth's crust. The hard part is really 
the refining and the purification of silicon to  
make sure there aren't any impurities that could 
disrupt the manufacturing process. So on top of  
your silicon, you could have boron, gallium, 
gallium arsenide, lots of different chemicals  
that are used, and every chip maker has its own 
proprietary process. So we don't really know,  
inside of a typical chip, what materials 
are used, because chip makers usually keep  
it pretty secretive. That's their special sauce 
that lets them manufacture chips with the right  
level of capability. Now we're not gonna 
run out of silicon, nor will we run out of  
the other materials that are generally used in 
chipmaking. There are some concerns that certain  
materials are predominantly refined and processed 
in a single country. So for some of the materials  
like gallium and germanium, China produces around 
90% of those materials. So there's geopolitical  
issues that could interrupt supply, but it's not 
gonna be that we're running out of the capability  
to produce them. I visited a bunch of chipmaking 
facilities over the course of the research. The  
interesting thing though is that, when you 
go inside one of these massive facilities,  
called fabs, what you find is that there are 
huge machines and not much else. Because the  
manufacturing process has to be extraordinarily 
automated because humans are way too imprecise for  
manufacturing at nanometer scale. And so inside of 
a chipmaking facility, there are very few humans,  
and lots of big machines that, from the outside, 
are impressive in their size, but you can't see  
what's actually happening because it's happening 
at microscopic level. So there are a handful of  
companies that play a big role in the making 
of the machines that make chips, a couple in  
the United States, one in the Netherlands, and one 
other large one in Japan. Five companies play the  
dominant role in the manufacture of the machines 
that make chips. And in some ways, it's actually  
harder to make the machines that make chips than 
it is to make the chips themselves. Because these  
tools are among the most precise tools that have 
ever been deployed. Just to give you one example,  
ASML, a company based in the Netherlands, produces 
machines that are used in the manufacture of  
almost every high-end chip today. And these 
machines are capable of manipulating materials  
at basically the atomic level to produce chips 
with billions and billions of transistors like  
those that are inside of your phone or that are 
used for training AI systems. So there's a pretty  
small number of companies that make chips. 
And when you look at specific types of chips,  
you find that there's even more concentration. 
The biggest chip maker in the world is the  
Taiwan Semiconductor Manufacturing Company. 
When it comes to advanced processor chips,  
like the chips in your phone, or the chips in 
your computer, TSMC makes around 90% of them. So  
they've got an extraordinary market share, and are 
probably the most important semiconductor company,  
and arguably the most important company, in 
the world, because the chips that they produce,  
we rely on for basically everything. There's 
been a lot of consolidation in the chip industry  
over the past couple of decades, and it's been 
driven by economics and by technology. Today,  
a single cutting edge chipmaking facility can cost 
$20 billion, one of the most expensive factories  
in all of human history. And so there's just a 
couple of companies that can afford to put up  
that sum of money on a regular basis to build more 
and more cutting edge facilities. And to make that  
work financially, you've gotta produce a ton of 
chips. And so there are huge benefits that accrue  
to the largest firms. The more chips you produce, 
the more your cost structure makes sense, and the  
better your technology gets, because you learn 
from every chip you manufacture, you gather data  
from it, and you tweak your manufacturing process 
to make sure you've got fewer and fewer impurities  
at every step. And so TSMC is both the world's 
largest chip maker, but it's also the world's  
most advanced, precisely because it gathers more 
data than anyone else. Because chipmaking requires  
ultra-purified materials and hugely complex 
equipment, there's not a single company that  
can do it on its own. Everyone requires a set of 
partnerships with supply chain providers to give  
them the materials, and the intellectual property, 
and the software and the tools that they need to  
produce advanced chips. And so if you take for 
example, the primary processor inside of your  
smartphone, it was probably made in Taiwan, but it 
was made in Taiwan using chipmaking tools from the  
Netherlands, and from the United States, and from 
Japan. It was produced using chemicals from Japan,  
and then often assembled and packaged in Malaysia 
before ending up inside of your smartphone. And  
that's typical. A typical chip requires components 
and materials sourced from dozens of different  
companies because the process is simply too 
hard for any one company to do on its own.
- [Announcer] What is nanometer scale,  
and how does it relate to the 
innovation process of silicon chips?
- So a nanometer is a billionth of a meter, 
and chips today are measured in nanometers.  
If you look at the chip inside of your phone, 
for example, and try to measure the size of  
the transistors, of which there will be billions 
on your smartphone chip, each one of these will  
be measured in a handful of nanometers. And so 
that makes them only slightly larger than atoms,  
smaller than any sort of living thing, far smaller 
than a bacteria, smaller than a mitochondria,  
half the size, for the most cutting edge 
transistors, of a coronavirus. There's  
basically nothing we manufacture at such tiny 
scale as we do with semiconductors. Every year,  
we make more transistors than we've made all other 
goods combined in all of human history. And in  
fact, nothing else really comes close. A typical 
smartphone chip could have 10 billion transistors  
just in the main processor chip. A big data center 
run by Google or Amazon Web Services would have  
more transistors than you could plausibly count. 
We know that we make more transistors than there  
are cells in the human body, for example. We 
don't even know how many we make in aggregate,  
because there are just so many. Moore's Law 
predicts that the number of transistors per chip,  
and as a result, the computing power per 
chip will double every couple of years.  
And that's been empirically true since the 1960s, 
which means that the capabilities of chips have  
gotten vastly better, and continue to get much, 
much better at a faster rate than anything else.  
So I like to think, for example, of airplanes to 
illustrate the difference. If airplanes doubled  
in speed every two years from the 1960s up to 
the present, we'd be flying faster, literally,  
than the speed of light. But chips have done 
that. Chips have increased in that capability  
because the scale of the transistors has shrunk 
to the level that today we're manufacturing them  
smaller than even viruses. And that has 
enabled the explosion of computing power,  
both in terms of the computing capabilities 
in high-powered data centers or in your phone,  
but also the application of computing to all 
sorts of devices. 'Cause today, there's computing  
everywhere. It's in your dishwasher, it's in 
your refrigerator, it's in your coffee maker,  
it's in your car. And it's possible to put 
computing everywhere because today it's so cheap,  
we can produce it almost for free. And that 
has enabled the application of chips to all  
sorts of different devices. To understand the 
change and the rate of innovation, in the 1950s,  
you could hold a single transistor in your hand. 
Today, you can hold 10 billion transistors in  
your hand in a chip that's the size of your 
fingernail. And that's not an expensive chip,  
that's a chip that often will just cost $50 
or so. So the rate of shrinking transistors,  
as well as the rate of decline in their cost, 
has been unparalleled in any other segment of  
the economy. So before transistors, computers 
used vacuum tubes, which are sort of light  
bulb like-devices that would turn on and off, on 
and off to produce the ones and zeros. And they  
were cutting edge for their time, but they had 
huge inefficiencies. They wasted a lot of heat,  
for example, they worked pretty slowly. And they 
also, because they created light, attracted moths,  
and so computers had to be regularly debugged in 
the early days of computing, which meant removing  
moths from the lights that they were attracted to. 
You can see why it was hard to scale that up into  
a 10 billion unit system. You know, I think the 
transistor is the key reason why we've been able  
to scale down. There's really nothing else, 
if you look all across the economy, that has  
shrunk in size and shrunk in cost at that level. 
And it's done so not just for a couple years,  
it's done so now for over half a century. 
And that's why when you compare progress in  
the computing industry to progress anywhere else, 
there's really no comparison. Well, Moore's Law is  
not a law of nature, it's not a law of physics. We 
wish it were, because then we could rely on it to  
keep delivering advances far into the future. But 
it's really a law of economics. It says that, if  
you're able to find a way to shrink, shrink your 
transistors smaller, then you will be able to find  
a larger market as well. And that has incentivized 
huge investments in shrinking, in improving  
manufacturing processes, and making chemicals more 
purified to enable it, which has sustained this  
rate of advance. And if ever it turns out that 
the economics are on Moore's Law break down, the  
technology will immediately break down as well. 
Thankfully, the good news is that, right now,  
we're seeing a new wave of excitement about ways 
you can deploy computing, which has led to a surge  
of new investment into AI, but also a surge of new 
investment into semiconductors, because it's now  
clear that if we can shrink even further, we'll 
enable a whole new era of advances in artificial  
intelligence that rely on even more computing than 
we've been able to muster thus far. You can define  
Moore's Law in a bunch of different ways. Is 
it based on the 2D size of the transistor,  
or the 3D size of the transistor? Is it based on 
the processing speed that comes out of it? And  
I think there's a lot of people in the industry 
that are trying to sell a certain chip with given  
characteristics that have an incentive to say 
Moore's Law, based on the other characteristics,  
has come to a halt. If you look at the rate of 
increase of machine learning semiconductors,  
for example, chips that are optimized for AI 
capabilities, they've been doubling in their  
capabilities every two years for the past decade 
or so. In other words, exactly what Gordon Moore  
predicted when he set out Moore's Law in 1965. 
And so my view is that when you zoom out and  
look at the rate of technological progress, 
there's really no slowdown that's happening.  
When I started my research on semiconductors, I 
thought that because chips were everywhere, chips  
were easy to make, and because nuclear bombs were 
only controlled by a handful of governments, they  
were hard to make. But what I realized is it's 
actually the exact opposite. If you take nuclear  
weapons, that technology has barely improved since 
the 1960s. It's so easy to make nuclear bombs,  
even the North Koreans can do it. But chips are 
everywhere because they're cheap and they're tiny,  
and making things very inexpensive and very small 
is extraordinarily difficult, which is why there's  
just a couple companies in the world that can 
do it at the cutting edge. And the reason is  
that it's brutally expensive, and it requires 
manufacturing processes that get better, and  
better, and better every single year. And so if 
you're trying to catch up to the cutting edge in  
the chip industry, you're not trying to catch up 
to a static cutting edge, you're trying to catch  
up to a cutting edge that is racing forward at the 
rate of Moore's Law, doubling every two years. And  
so it's a race between companies, but it's the 
fastest race humans have ever undertaken, which  
is why it's extraordinarily difficult to reach the 
cutting edge. A couple years ago, it became harder  
to shrink transistors in two-dimensional 
format. For a long time, chips were made,  
they were just described as planar chips, chips in 
a plane, in which all the transistors were on the  
same level. Now we've started making transistors 
that have three dimensions, because we're learning  
to stack them on top of each other to package 
more of them together in a way that produces  
more computing power. And so one of the key 
trends over the next couple of years is going to  
be more 3D construction of groups of transistors, 
which will enable more of them to be crammed into  
a small amount of space. So the machines that 
make chips are extraordinarily precise in their  
manufacturing. For example, there are tools 
that can lay down thin films of material that  
are just a couple of atoms thick with basically 
perfect uniformity. And to pattern the transistors  
on a piece of silicon, you use a tool called a 
lithography tool. And today there's one company,  
ASML, of the Netherlands, which makes most of 
the world's lithography tools. And for the most  
advanced chips, these tools can cost $350 million 
a piece for a single tool. And they cost so much  
because they require some of the most precise 
components ever used, like a mirror that's the  
flattest mirror humans have ever made, a laser 
that's the most powerful laser ever deployed  
in a commercial device, and a ball of tin that 
falls through a vacuum that is struck twice by  
that laser, explodes into a plasma measuring 40 
times the temperature of the surface of the Sun,  
and this plasma emits light at just the right 
wavelength, 13.5 nanometers, to be bounced  
off the mirrors in exactly the right geometry 
and land on your chip to carve the transistors  
into the silicon. It's the most complex and 
expensive machine that humans have ever made,  
and it's required to make all of the most advanced 
chips. Today, there are just three companies  
capable of producing cutting edge processor 
chips, the types of chips that go in phones,  
or computers, or are used for AI. And it used 
to be a larger number of companies that could  
produce at the cutting edge, but it's shrunk 
into three, and might in the future shrink  
only to two for two reasons. First, the expense 
is extraordinary. $20 billion per facility is  
a level of spending that many governments can't 
afford, to say nothing of companies. But second,  
the scale required to manufacture efficiently 
is vast. And that means that the benefits  
accrue to the largest firm. And in this case, 
that's TSMC, the Taiwanese firm that's at the  
center of the chip industry. That's why they 
manufacture on 90% of the most advanced chips,  
because they're cheaper, and they're better than 
their competitors when it comes to manufacturing.
- [Announcer] Chapter 2, 
"The First Chip Builders."
- In the middle of the 20th century, all 
telephones were managed by AT&T. They were  
a monopoly, and the government regulated them, 
and one of the rules was that their research  
lab had to share its inventions with the rest 
of the world. And they had some of the most  
brilliant physicists and chemists working in 
the world at that time, which they hired to  
improve the phone system. But in the process, 
they created some of the key inventions that  
drove technological progress in computing for 
decades to come. The transistor was one of the  
inventions that emerged out of Bell Labs, but 
actually many of the processes that are used to  
both design and manufacturer semiconductors today 
were first pioneered by researchers working at  
Bell Labs. But because Bell Labs wasn't a computer 
company, they were able to take those technologies  
and either spin out their own startup or sell it 
to somebody else. And that's how many of the key  
technological advances undergirding semiconductors 
first emerged. So William Shockley, John Bardeen,  
and Walter Brattain invented the first transistor 
while they were working at Bell Labs. They were  
initially planning to use these transistors 
as part of the telephone network. But in the  
late 1950s, the first engineers realized 
that you could take multiple transistors,  
and make them on a single piece of semiconductor 
material. And so that was the first chip, a piece  
of material with multiple transistors carved into 
it. And that was important, because if you had  
individual transistors, they were connected 
via wires in a way, that was okay if you had  
a handful of transistors. But if you had 1,000 
connected together, you had a jungle of wires  
you had to manage. But the chip managed to have 
the electrical connection in a piece of material.  
And so the jungle of connections was replaced by 
a single block of material, which was much more  
reliable, and also much more easy to shrink in 
its size. And so it was the invention of the chip  
that made it possible to deploy lots and lots of 
transistors together in a way that was economical,  
but also possible to engineer and avoided all 
of the wiring. The first chips were invented by  
engineers working at Texas Instruments and 
a company called Fairchild Semiconductor in  
Silicon Valley. They were invented simultaneously. 
Jack Kilby invented one in 1958 working in a Texas  
Instruments lab. And for a long time they were 
really at the cutting edge of chip manufacturing.  
At first, they were building chips primarily for 
the U.S. government, for the space program, for  
example, and for weapon systems. But they realized 
early on you could take the exact same chips that  
the government wanted to guide spacecraft, 
and use them for commercial applications,  
like computers or pocket calculators. And that set 
the industry off into its first phase of growth  
in the 1960s and '70s and '80s. For the past 15 
years, they've taken a different tack. They don't  
today produce chips that are used in computing, 
they're not, for example, in AI systems in a large  
way. Instead, they produce a lot of chips that 
are in industrial applications, or in automobile  
uses. And so Texas Instruments chips are all 
around you, but you don't see them because  
they're buried deep in your devices, making 
sure your windshield wipers work, for example,  
on your car, or that your windows move up and 
down when you press the button. Those are the  
types of use cases that Texas Instruments produces 
chips for. One of the first startups in Silicon  
Valley was created by one of the researchers who 
invented the first transistor, William Shockley,  
who was by all accounts, a brilliant physicist, 
but a horrible manager and a horrible person. And  
so he hired a very talented set of engineers in 
Silicon Valley. He moved to Palo Alto, California,  
where his mother lived, for the purpose. 
And although he hired lots of great people,  
they detested working for him. And so eight of 
them in the late 1950s went out on their own,  
and created Fairchild Semiconductor, which became 
one of the key startups that would give rise to  
Silicon Valley, and played a major role in Silicon 
Valley even being named Silicon Valley, because  
for a long time it was the absolute epicenter of 
chip design and manufacturing thanks to people  
at Fairchild Semiconductor. Robert Noyce, one 
of the two inventors of the integrated circuit,  
Gordon Moore, who later would go co-found Intel, 
and many others first started their career working  
at Fairchild. Intel was founded in 1969, and 
it initially planned to focus on making memory  
chips. But they realized early on that there was 
a potentially larger market for a type of chip  
that wouldn't just remember data, but would also 
process it, especially if that processing could  
be programmed in different ways for different use 
cases. And it quickly focused on making chips for  
personal computers, which at the time was a very 
small market, but they correctly bet that soon,  
everyone, would have a personal computer. 
And Intel, even today, is the world's largest  
producer of chips that go inside of PCs. Gordon 
Moore is one of the two co-founders of Intel.  
He's most famous today probably for coining the 
term Moore's Law, but he also played an absolutely  
critical role running Intel's R&D operations from 
the earliest days for many years. And when it came  
to the microprocessor, he was an early advocate 
of focusing on microprocessors at the expense  
of the more memory-focused chips that Intel had 
previously made. And so in some ways, he was the  
key figure in Intel in making the company focus 
on microprocessors. A tiny computer on a chip,  
as they originally called it. And it gave rise to 
the idea that you could deploy chips in lots of  
different use cases without having to redesign the 
chip itself, because the chips themselves could  
have a program running on top of them. Today, we 
take it for granted that you can have a chip in  
your phone, and a chip in your dishwasher, 
and a chip in your car. But at the time,  
that would've required many different chips for 
each of those purposes. Whereas, today, thanks to  
the microprocessor, we have programmable chips. 
And that was the main source of revenue for the  
chip industry, the main focus of technology, until 
about 20 years ago when the first smartphones  
began being produced. And today, smartphone chips 
are generally designed by one set of companies,  
but they're manufactured largely in Taiwan. 
So the largest designers of smartphone chips  
are Apple, which designs its own chips in 
California. Qualcomm, and other companies,  
almost all of them manufacture all of the 
chips that they design in Taiwan. And so today,  
the chip industry is split into two different 
parts. There's the chip designers, which, today,  
is essentially like a type of programming almost, 
programming where each of the transistors goes on  
the chip, and the actual manufacturing takes place 
generally in Taiwan or elsewhere in East Asia,  
where different companies specialize 
in manufacturing at precision scale.
- [Announcer] Chapter three, "Global Impact." How 
has the semiconductor industry spread globally?
- The chip industry was a global industry from 
really the earliest days. Fairchild Semiconductor  
was founded in Silicon Valley before it was even 
called Silicon Valley, but they opened their first  
facility in Hong Kong just a couple years later. 
So there was already a globalized nature to the  
chip industry from day one. But one of the things 
that's changed a lot over the past couple of  
decades is that, today, each region focuses on a 
different part of the semiconductor supply chain.  
The first chips that were invented in the late 
'50s and early '60s were used for space programs  
and missile systems. So they were at the center of 
the Cold War competition. And the U.S. was ahead,  
but the Soviet Union realized that they 
also needed chips to guide their missiles  
more accurately or to help their spacecraft 
launch effectively. And so they were focused  
on building their own chip industry, but also 
on copying whatever they could from the West.  
And so since the earliest days of the Cold War, 
there were Soviet exchange students in physics,  
for example, studying at Stanford University, but 
also transmitting the knowledge that they gained  
back to the Soviet Defense industrial complex. And 
so there was a lot of copying, a lot of efforts to  
replicate what the U.S. was doing. But the Soviets 
made a couple of key errors. One was that they  
focused too much on copying, and not enough on 
innovating. And so they got very good at copying,  
but not so good at innovating, and that left them 
behind. And the second error they made was that  
they only focused on the military aspects. And 
the military was where the first chips were used,  
but today, most chips go to the private sector. 
99% of chips that are made go into phones, or PCs,  
or data centers, not for defense equipment. And so 
if you only focus on the government and military  
uses, you've got a tiny market relative to the 
vast consumer market that was out there. U.S.  
firms were profit-seeking, they focused on the 
consumer market as early as they could. In the  
Soviet Union, they never made that shift, and so 
their chip industry was always tiny in comparison  
to the U.S., which meant they could invest less, 
they could hire fewer workers, and ultimately  
their technology fell behind even though they were 
pretty good at copying. So in the U.S. right now,  
most of the key chip firms only design chips. 
Most of the manufacturing of chips happens in  
East Asia, in Taiwan, for example, or in Korea. 
Many of the chemicals that go into chipmaking come  
from Japan. And the machines that are used to make 
chips come from either Silicon Valley, where some  
of them are still made, or the Netherlands 
or Japan. So the industry has globalized,  
but it's also specialized in the process. And 
so there's not a single region today that can  
make cutting edge chips on its own. Everyone 
relies on this internationalized supply chain  
that brings together the U.S., Taiwan, Europe, 
Japan, and Korea. Japan was a major player in  
electronics assembly early in the 1950s and 1960s, 
so devices would be assembled in Japan because  
labor costs at the time were lower. But Japanese 
firms were fixated on moving up the value chain,  
producing more complex, more expensive types of 
goods. And Japanese firms realized very early on  
that consumer electronics could be a major growth 
area for them, where they could sell not just  
domestically, but all around the world. And so 
companies like Sony, which were among the leaders  
in the 1970s and 1980s, bet on the consumer market 
to produce the types of goods that would take  
advantage of the advanced chip technology that 
they were pursuing at the time. And so although  
we don't remember it much today, devices like the 
Sony Walkman in the 1980s was at the center of the  
tech industry, and it put Japan really on the map. 
And at that point, Japan was, by a lot of metrics,  
just as capable as the United States when it came 
to building advanced chips and then deploying them  
in very profitable uses like the Sony Walkman. One 
of the places where the Japanese excelled was in  
video games, which most people might not think of 
as driving technological advances, but actually,  
the computing that's required to show graphics 
that look real life is extraordinarily complex.  
And so the Japanese companies like Sony, Nintendo 
is another one, were fixated on how to make better  
graphics, and it required more and more computing 
power to make better and better graphics. And  
today, they're no longer major players in that 
sphere, but NVIDIA, which is the central player  
in AI, actually started as a video game company, 
it made graphics cards for computers. And for most  
of their early history, they were selling chips 
primarily to gamers, because the graphics were  
better and rendered more rapidly. But it turns 
out that the same essential math that's used for  
showing graphics on a screen is pretty similar to 
the math that's used in training AI systems. And  
so NVIDIA was able to take chips that were made 
for video games, and made for computer games,  
and pivot them to be used in AI systems, which 
is why a video game company that was founded in  
the 1990s has now become not just any AI company, 
but the most important AI company in the world. In  
the 1980s, the South Koreans saw Japan becoming a 
major player in the chip industry and saw Japanese  
firms rise to the top, both in terms of technology 
and in terms of the amount of money they were  
making, selling both chips and devices that 
used them, and South Korea wanted to replicate  
Japan's strategy. So companies like Samsung and 
SK Hynix were founded to establish chip industries  
in Korea. And they replicated the Japanese model, 
they get very good at manufacturing, they competed  
very effectively on cost. They also represented 
an alternative to Japanese production. 'Cause U.S.  
firms in the 1980s were very worried that Japan 
was gonna take over the chip industry. So they  
were excited to have another option besides 
Japan, and shifted business towards Koreans,  
both because the Korean producers were cost 
competitive, but also because it provided a bit  
more diversification in the industry that would 
limit the ability of Japanese firms to dominate.  
One of the biggest European chip makers in the 
1960s, '70s, and '80s was the Dutch company  
Phillips, which today still exists, but doesn't 
produce any semiconductors. They got out of the  
semiconductor business several decades ago. But 
one of the legacy units that they'd created was  
a unit that made the tools that make chips. And 
in particular, they focused on the lithography  
tools that are capable of patterning transistors 
on a chip. ASML was spun out of Phillips several  
decades ago, and at the time, most people thought 
it would likely fail, the Netherlands wasn't a big  
part of the chip industry, Silicon Valley was a 
long way away. But ASML took a series of pretty  
wild technological bets on technologies most 
people thought would fail. And the best example  
of this is the current cutting edge of lithography 
called extreme ultraviolet lithography, the tools  
that cost $350 million a piece to produce, 
everyone else thought that was a technology  
that would never work. It took three decades 
to commercialize, tens of billions of dollars  
of research and development money went into 
it, but ASML made that bet, and it was a bet  
that looked like a very bad bet for many years 
until about a decade ago when they first were  
able to build the initial EUV lithography 
machines. So chip makers have always used  
lithography to manufacture semiconductors, but 
as transistors have gotten smaller and smaller,  
we've needed better and better lithography systems 
to print smaller transistors onto silicon chips.  
And several decades ago, it was clear that the 
cutting edge in lithography at the time was gonna  
be too broad in terms of the wavelength 
of light used to print tiny transistors.  
The cutting edge used light with a wavelength 
of 193 nanometers, which sounds really small,  
and it is really small. But if your transistors 
are measured in 10 nanometers, or 5 nanometers,  
193 nanometers is still too broad of a brush 
with which to paint your transistors on the  
silicon chip. And so ASML bet on a new type of 
lithography system using light with a wavelength  
of 13.5 nanometers, much more narrow. Which sounds 
logical, but it was extraordinarily difficult to  
produce. Research started in the early 1990s, 
and it took 25 years before these machines were  
commercialized, because it required building a 
supply chain that involved these extraordinarily  
complex components, the flattest mirrors humans 
have ever made, the most powerful laser ever  
in a commercial device, all of these had to be 
invented in the process of making these machines  
work. So Taiwan was a major player in electronics 
assembly, and putting together transistor radios,  
for example, in the 1950s and '60s, or assembling 
televisions. And they did quite well on that,  
but there's not much money to be made in the 
assembly, the money is made in the manufacturing  
of the complex components involved. And 
so the Taiwanese government realized,  
as early as the 1970s, that they needed to move up 
the value chain and learn to do the more complex  
parts of electronics manufacturing. In 1987, there 
was a American engineer named Morris Chang who was  
passed over for the CEO job of Texas Instruments 
where he'd worked for several decades. And so he  
left TI, and was looking for something else to do, 
and he'd gotten to know the Taiwanese government  
for several years, because Texas Instruments, his 
former employer, operated a number of plants in  
Taiwan. And so the Taiwanese approached him and 
said, "Would you like to build a chip factory in  
Taiwan?" And he said yes. And he had an idea, 
which was to do manufacturing differently  
than anyone else. At the time, most chips were 
manufactured and designed by the same companies,  
but Morris Chang realized that manufacturing is 
getting more and more complex every single year,  
that if you specialized on manufacturing, you 
could manufacture better than your competitors.  
And so he established TSMC in Taiwan in 
1987 with the aim never of designing chips,  
only of manufacturing. His vision was sort of like 
to do for chips what Gutenberg had done for books.  
Gutenberg didn't write any books, he only printed 
them. Morris Chang didn't wanna design any chips,  
he only wanted to manufacture them. That's 
exactly what TSMC has done. And it's enabled  
TSMC to win among its customers, some of the 
largest companies in the world, Apple, NVIDIA,  
Qualcomm, AMD, they all rely on TSMC to produce 
its chips, which means that TSMC is the largest  
chipmaker in the world by far. And as a result, 
it's got more scale, it can drive down its costs,  
and it can hone its technology more than anyone 
else. And so TSMC, thanks to this unique business  
model, is both the largest and the most advanced 
chipmaker in the world. Today, China's the world's  
largest importer of chips. They spend as much 
money each year importing chips as they spend  
importing oil. There's nothing that China's 
more reliant on the outside world to purchase.  
And China imports all these chips, both for its 
own use, but also because most of the world's  
phones and computers and servers are assembled 
in China. So there's a flow of chips into China,  
they're assembled in the devices, and the many 
of those devices are re-exported to the U.S.,  
or to Europe, or to Japan, or to international 
markets. And so today, China's primary interface  
with the chip industry is by buying chips, 
assembling them, and then shipping them abroad.  
But the Chinese government realizes this is not 
the best place in the industry to be. They wanna  
do the higher value add parts of the industry, 
just like Taiwan did, just like Japan did to move  
up the value chain. And so for the past decade, 
China's been trying to build its own chip industry  
to manufacture more chips domestically. And right 
now it's having a lot of success when it comes to  
more low-end chips, the types of commodity chips 
that are in many different types of devices,  
where China is vastly expanding its manufacturing 
capacity and making real strides towards becoming  
a lot more self-sufficient. But at the cutting 
edge, the types of chips that are inside phones or  
in AI systems, China's still meaningfully behind 
industry leaders like TSMC. Right now, the most  
advanced Chinese firm, SMIC, is about five years 
behind TSMC, which might not sound like a lot,  
but that's two and a half Moore's Laws behind 
TSMC, which means that, for the most cutting  
edge applications, you really take a performance 
hit if you want to use a Chinese manufacturer  
versus a Taiwanese one. Until 2020, TSMC'S 
two largest customers were first, Apple, the  
biggest U.S. smartphone maker, and second Huawei, 
China's largest phone company. TSMC manufactured  
ships for both of their phones. But the United 
States is worried that Huawei is controlled by  
the Chinese government, it's worried about the 
surveillance capabilities that this might enable,  
and so the U.S. has been trying to limit Huawei's 
access to advanced technologies. And since 2020,  
it's prohibited Huawei from manufacturing 
advanced chips at TSMC. And so Huawei's had  
to turn to domestic suppliers to manufacture many 
of the chips that it needs. And this has been a  
challenge, it's possible to find Chinese domestic 
suppliers, but they're not as good as TSMC,  
the costs are higher, the performance is lower. 
And it's been a real headwind for Huawei over  
the past couple of years as they've tried to 
build their own supply chain to make up for  
the fact that they've lost access to the cutting 
edge in Taiwan. So until recently, India was a  
very small player in the chip industry. There's 
a couple of chip companies in India, but they're  
not at the cutting edge, and they're not that 
large. Much of the semiconductor manufacturing,  
as well as the rest of the supply chain, the 
assembly of phones, for example, of computers  
takes place in Southern India. Tamil Nadu, for 
example, is one of the key hubs for manufacturing.  
And then Bangalore is a major center for 
chip design inside of India. But right now,  
India is the country that's changing the most 
rapidly, I think, when it comes to investment in  
semiconductors. There's a series of new projects 
underway in India to put it more on the map of  
electronics manufacturing. And I think if you 
look at India today, you see what China looked  
like 30 years ago, or what Taiwan looked like 50 
years ago, a country that's on the early stages of  
a major change in the types of manufacturing that 
happened there. And so I wouldn't be surprised at  
all if in 10 or 20 years we looked at India as a 
really central player in the production of all the  
computing and electronics that we rely on, because 
they're taking the exact same steps that China,  
and Taiwan, and Japan before them took when they 
were becoming major manufacturers. The irony of  
the chip industry is that it's simultaneously 
globalized, and yet extraordinarily localized  
for certain types of production. And that's 
inevitable I think, because the engineering  
involved is so complicated, the dollar values 
required to spend are so vast that we need  
specialization. And specialization implies that 
we've got to rely on other people to help in  
the process. And so I think it's inevitable that 
U.S. firms will rely on manufacturing in Taiwan,  
and chemicals from Japan, and the rest of the 
supply chain for a very long time because no one  
has the capabilities they need to produce 
the chips that they require on their own.
- [Announcer] What happened during 
the COVID-19 chip shortages?
- During the pandemic, the supply and demand 
dynamics on the chip industry were out of  
whack. Because a lot of people ordered new 
computers, for example, to work from home,  
and so PC production shot up in ways that weren't 
expected, or people bought fewer cars in the early  
days of the pandemic, and so car production 
declined. And companies couldn't predict what  
type of chip they would need. The effect of that 
was to create shortages of certain types of chips,  
when demand roared back in the later stages of the 
pandemic. Car companies in particular found they  
couldn't get the types of chips that they rely 
on to produce cars. And that was something they  
hadn't focused on for a long time, they thought 
of their supply chain as being about engines,  
and wheels, and axles, and other parts of the 
car that you think of when you think of car  
parts. But today, contemporary cars require a lot 
of chips, hundreds or even thousands of chips for  
the most sophisticated cars. And the thing 
about cars, if you're missing just one chip,  
your car often doesn't work. And during the 
pandemic, car companies found themselves often in  
that situation. Just a single chip, often even the 
cheapest chips, were causing them to have to leave  
cars in the factory parking lot as they waited 
for the right chip to arrive. And that illustrated  
a couple of things. First is that complex 
manufactured devices, like cars, need a lot  
of chips. Second, they don't just need the same 
type of chip, they need a thousand different types  
of chips produced by different manufacturers. 
And if even one of those is late, the car has  
to wait until it arrives. And the third thing 
it illustrated is that it's not just the tech  
sector that needs chips, it's actually everything. 
It's cars, it's tractors, it's medical devices,  
all of these faced shortages during the pandemic 
because they couldn't get the types of chips that  
they needed. And the really interesting thing 
about the pandemic that most people don't realize  
is that we didn't actually produce fewer chips. 
We actually produced more chips each year of  
the pandemic. The problem was that supply couldn't 
keep up with demand. And we had demand in segments  
in the industry that we weren't expecting. That 
created hundreds of billions of dollars of losses  
for manufacturers like automakers, because they 
couldn't finish the goods that were sitting in  
their factory parking lots, and therefore couldn't 
sell them. And that matters, because the shortages  
we saw in 2021 and 2022 are tiny in comparison to 
the shortages we would see if something happened  
to a large scale chipmaker, like those in Taiwan. 
Anything that disrupted chip production in Taiwan  
would be catastrophic for the world economy, for 
the United States, for Europe, for Japan, for  
everyone, because everyone relies on chips made 
in Taiwan. Earthquakes are one thing that could  
cause problems. And the reality is that Taiwan's 
had a lot of earthquakes, so they're pretty well  
prepared. And chip facilities, because they have 
to be extraordinarily safe from vibration, they're  
actually among the most earthquake-safe buildings 
that exist today. So it's not a guarantee,  
but it means that they've done a lot in terms 
of ensuring themselves from earthquakes. Water  
is one of the materials that's actually most 
widely used in chip manufacturing for a number  
of the manufacturing steps. And it needs to be 
ultra-purified water too. And so chip plants  
have to draw huge volumes of water from the local 
water supply, and then try to recycle that at the  
end to make sure there aren't any chemicals that 
are being discharged back into the environment.  
And it's a major challenge for chipmakers, because 
the volumes that they use are huge. And many of  
the places where chips are manufactured 
don't have surplus water. So in Taiwan,  
droughts have been an issue many times in recent 
years, and it's a major limitation on TSMC'S  
ability to expand its manufacturing footprint 
in Taiwan. The other is energy. Electricity  
is very important for chipmaking, and as we use 
more advanced chip making tools in factories,  
they require even more power to operate. And so 
electricity is a second limiting factor as well.  
And especially as countries try to use more green 
energy, that creates more challenges, because you  
need both more energy, but also you need energy 
that's perfectly reliable. And so the Sun or wind  
power can't always be relied on. Which means that 
if you're in Taiwan trying to map out your future  
power supply, you've got a limited number of 
options to look at. I think the bigger risk is  
not seismic, but rather geopolitical. It's that 
China carries through on the threats it regularly  
makes to use force against Taiwan to take control 
of the island. And for a long time, I think people  
wrote off that risk as unlikely, because for a 
long time, China was weak, and the United States  
was pledging to protect Taiwan. But today, China's 
getting stronger every single year, its military  
capabilities are growing on a regular basis. And 
this has raised questions about whether we need  
to worry that China might at some point move on 
Taiwan. And the problem is that even a small move,  
a small conflict would be disastrous for the chip 
industry, because it's not just about the security  
of the facilities themselves, it's also about 
the supply chain. Taiwan needs to import energy,  
needs to import chemicals, materials, tools, spare 
parts, many of which come from abroad, from Japan,  
from the United States, from Europe, energy coming 
in from the Middle East. And if any of this is  
disrupted, chip production could break down. 
And if chip production in Taiwan breaks down,  
that matters for everyone, because 
everyone uses Taiwanese made chips.
- [Announcer] How would you describe 
the ubiquity of chips in modern life?
- Well, I like to think of cars as a case study 
in how we rely on chips for almost everything.  
If you sit in a new car, it'll have, on average, 
1,000 chips inside of it. It's a chip that makes  
the window move up or down when you press the 
button. It's a chip that manages the windshield  
wipers going back and forth. If you have any 
sort of autonomous braking features in your car,  
there's a chip that manages the sensor, 
a chip that sends that information to the  
brakes to step on the brakes if there's a 
object in front of your vehicle. If you've  
got a internal combustion engine, there's a chip 
that manages fuel injection into your engine to  
make sure it's operating the right way. There's 
of course, a chip that's attached to your GPS,  
multiple chips in the display that tells you where 
to go when you're looking for directions. I've  
only mentioned a dozen or so chips, and there are 
several hundred more that make your car work the  
way you expect. And cars are not really unique. 
Today, everything that we rely on, almost anything  
with an on-off switch has at least one, and often 
dozens or hundreds of chips inside. The other way  
to think about the ubiquity of chips is just to 
walk around your apartment or your house, and look  
at the devices. The dishwasher, the microwave, 
your coffee maker, your washing machine,  
any sort of consumer electronic you have, they all 
require chips. And it's often not just one chip,  
it's often a fair number of chips. And the more 
complex the chip, the harder it is to make,  
and therefore, generally, the more companies 
can charge for selling it. So the chip in  
your smartphone, for example, that runs the 
operating system, is extraordinarily complex,  
billions of transistors, it has to operate 
at extraordinary speed, draw on as little  
power as possible because your battery life is 
constrained. And so having perfectly optimized  
smartphone processors is really important. Which 
is why Apple designs its own smartphone processors  
in-house. It doesn't trust anyone else to do 
it. And so those chips are really expensive,  
compared to many other types of chips that 
you'd find in a dishwasher or a washing machine,  
which can cost less than a dollar, because they're 
not required to do anything particularly complex.  
And the reality is that, as devices get more 
advanced, as we have more and more things  
connecting to wifi and Bluetooth, more sensors, 
more AI capabilities installed in devices,  
we're gonna be using more and more chips as 
far as we can see into the future. Both China  
and the U.S. see chips as really central to the 
technology competition between them right now.  
China's worried that because it relies on 
importing chips from Taiwan and from Korea,  
which are both U.S. allies, it's gonna be cut 
off in the future from getting the chips that it  
needs. And right now, that's already happening to 
some degree, the U.S. is limiting the ability of  
AI firms like NVIDIA to sell their most cutting 
edge chips to China, because the U.S. wants to  
keep the most advanced AI capabilities for itself. 
And so China's concerns are understandable. The  
U.S. is worried that if it sells advanced AI chips 
to China, they're gonna be used not for optimizing  
food delivery apps, but used for military and 
intelligence use cases. And the U.S. is not wrong  
to believe that, because just as companies are 
trying to figure out how they're going to use AI,  
it's already the case that militaries and 
intelligence agencies are deploying AI to optimize  
their systems too. And so both countries recognize 
that chips will be at the center of the AI race,  
and as a result, they're trying to improve 
their position, become more self-sufficient,  
and prevent their technology from benefiting 
their competitor. As of 2022, the U.S. has made it  
illegal to transfer the most advanced AI chips 
made by companies like NVIDIA to China. So today,  
if you're a Chinese firm, you can access a less 
advanced NVIDIA chip that's been specifically  
downgraded to meet the U.S. restrictions and 
is now legal to sell to China. But if you want  
the cutting edge, you've gotta go abroad. And the 
aim of these regulations is to give U.S. firms an  
advantage. To make sure that U.S. companies are 
leaders in AI, and that the U.S. gets to write  
the rules of how AI will play out. And so Chinese 
companies in the AI industry face a disadvantage  
as a result, they've got worse chips, which means 
that the cost of training AI systems is higher,  
it takes more time, it's more inefficient. 
And that's the U.S. goal, to kind of throw  
sand in the gears of China's AI ecosystem, and 
hope that the U.S. can race ahead as a result.
- [Announcer]  
What is the CHIPS Act, and what did it do to boost 
manufacturing capabilities in the United States?
- There were two concerns that prompted the 
Congress to pass the CHIPS Act. The first was  
reliance on Taiwan for our most advanced chips. 
And the second was a fear that the technological  
edge that the U.S. has vis-a-vis China was 
narrowing as China invested more and more. And so  
in 2022, Congress put forward around $50 billion 
to invest in the U.S. chip industry. Part of that  
money goes to directly incentivizing companies to 
build new manufacturing facilities in the United  
States, which in the past, they hadn't been doing 
much, they'd been relying on suppliers in Taiwan  
and Korea instead. And part of the money would go 
on R&D, building better chips, better chip making  
equipment, better chemicals used in the chip 
manufacturing process to help U.S. companies  
stay ahead of their competitors. Because the U.S. 
government believes, and I think they're justified  
in believing this, that keeping a technological 
advantage in chips is key for retaining your  
advantage in a whole set of industries that are 
downstream of semiconductors. And as we deploy  
AI in all sorts of different segments of the 
economy, you can already see that playing out.
- [Announcer] Chapter four, "The AI Revolution."
- The biggest change in the past couple of years 
has been the explosion of investment in AI. The  
release of ChatGPT in late 2022 encouraged all 
the big tech firms to spend tens of billions of  
dollars building vast AI infrastructure, which 
means data centers full of the most capable  
semiconductors. And I think right now we're seeing 
just the early phases of a new wave of investment  
in an AI industry that is just emerging. And if 
we know one thing, it's that this industry will  
require a ton of semiconductors. Because one of 
the key trends in the history of AI is that more  
advanced systems require being trained on larger 
volumes of data. If you wanna train a system on  
more data, you need more computing power, which 
means better chips to train it. And so today,  
companies like OpenAI or Anthropic are spending 
millions and millions, and soon billions of  
dollars training their AI systems. And most 
of that budget goes to buying chips, buying  
ultra-advanced semiconductors from companies 
like NVIDIA. So to train a cutting edge AI  
system requires tens of thousands of NVIDIA's most 
cutting edge chips. It requires using these chips  
for days, or sometimes months on end. So you're 
investing hundreds of millions of dollars, if  
not billions of dollars in data center capacity, 
and using the data center solely for the purpose  
of AI training. And you need the most advanced 
chips inside, because the most advanced chips  
are twice as good, on average, than the prior 
generation due to Moore's Law. And so there's  
a strong incentive to buy the best chips that 
NVIDIA has every single year, because it actually  
drives down your training costs, even though the 
chips themselves are extraordinarily expensive.  
One of the key challenges of AI is gonna be to 
drive down the cost of deploying AI systems.  
So we know how to train big systems right now, 
that's what open AI and Anthropic and others are  
doing. But to make AI really widespread across 
the economy, we need the cost of using it to  
be so cheap we don't even think about it. It's 
sort of like Google Search today. No one thinks,  
"What's the price of my Google search?" Because 
it's approximately zero. Google spends a bit of  
money on the data centers, but it's so low, 
you don't have to think about it. Today,  
AI is actually pretty expensive. A single query 
to ChatGPT is an appreciable amount of money,  
such that sometimes OpenAI has to slow the 
rate at which it rolls out new capabilities,  
because it'd be too expensive to actually deploy. 
There are a lot of companies that are exploring,  
how do you do deployment more efficiently? And 
there are a number of startups that are pioneering  
new models of chip design that are intended 
to increase the speed and drive down the cost  
of deploying AI models. Which I think is gonna 
be really important in making AI cheap enough,  
and therefore prolific enough to make a major 
impact on the economy. NVIDIA's chips, which are  
at the center of the AI ecosystem right now, are 
pretty general purpose in their capabilities. They  
can train many different types of models, and are 
useful both for training and also for deployment.  
But if you design a chip for a specific type 
of model, or a specific type of deployment,  
you can make it perfectly optimized for that 
use case. And so a lot of startups right now  
are looking at individual workloads, or individual 
deployment opportunities, and saying, "We're gonna  
design a chip that's perfectly tweaked for that 
use case." And if so, it'll run a lot faster,  
and run more efficiently than a sort of general 
purpose chip like an NVIDIA GPU will. Now, this  
is startups tackling this industry, but it's also 
big tech companies, Facebook, Microsoft, Google,  
they're all designing their own in-house chips 
as well. Because they know the specific workloads  
that are inside their data centers, and they've 
realized, if they design chips specifically  
around those workloads, they can operate more 
efficiently in many cases than a general purpose  
AI chip like NVIDIA's can do. On a silicon chip, 
the transistors flipping on and off are turning on  
and off electrical circuits. And so it's electrons 
flowing through copper wires that are carved into  
your silicon chip that make all of the ones and 
zeros that chips rely on. And so electricity  
is at the center of how chips work. And one 
of the things that we've seen over the past  
several decades is that chips get much, much more 
efficient in terms of how much power they use, but  
they also get much, much more capable in terms of 
computing. And one of the challenges that we face  
is that we're getting better at producing more 
capable chips at a faster rate than we're getting  
better at producing energy efficiency gains. Which 
means that we're using more power, in aggregate,  
every single year. When you look at artificial 
intelligence, which involves some of the most  
power-hungry chips that exist, one of the limiting 
factors to building vast AI infrastructures is  
gonna be the availability of power. Because for 
big data centers, they require a huge increase  
in electricity relative to smaller data centers 
that aren't focusing on AI. And there are very  
smart people in Silicon Valley who think that the 
biggest limitation to AI might actually not be  
the quality of the chips, or the algorithms that 
are behind AI, it might be the ability to deliver  
power to data centers. Because in many cases, 
this requires bringing new power supplies online,  
building new power plants that are capable of 
delivering electricity to power the chips inside  
of these new data centers. Well, when I look at 
the surge of investment in AI chips right now,  
I see no reason to doubt that Moore's Law won't 
continue for a very long time. That means more  
advanced chips, which means more computing power 
that we can apply to all sorts of uses, AI and all  
sorts of devices. And that means we'll be using 
even more semiconductors, because the trend has  
been that, as chips get better, they get cheaper, 
and we put them in more and types of uses. And so  
today, if your car has 1,000 chips, I wouldn't be 
surprised if it has 10x that number in a decade.  
And that basic trend is true of everything we 
rely on. And that's only made possible because  
chips get better, and they provide more computing 
for a lower price on an annual basis. The biggest  
geopolitical risk by far is that something 
goes wrong between China and Taiwan and the  
Taiwan Straits. Because it's not just Taiwan whose 
fate hangs in the balance today, it's our entire  
economy. And if you think of the biggest companies 
in the United States, Apple, NVIDIA, Microsoft,  
Amazon, Google, Facebook, they all rely on chips 
that, today, are only made in Taiwan. So it's not  
just a question of geopolitics in East Asia, it's 
a question of our tech sector, and it's a question  
of all the devices we rely on, because, today, for 
many of those devices, they rely on chips that,  
in some cases, can only be made by one company 
in a single factory in Taiwan. And so that  
illustrates the ways in which chips made in 
Taiwan are critical for the way we live our lives.