1
00:00:00,100 --> 00:00:01,033
会员朋友们大家好

2
00:00:01,033 --> 00:00:01,833
大家有没有想过

3
00:00:01,833 --> 00:00:03,866
就是亚马逊Facebook这样的公司

4
00:00:03,866 --> 00:00:05,766
它们有钱有业务

5
00:00:05,766 --> 00:00:07,100
然后有大量的数据

6
00:00:07,100 --> 00:00:09,133
又有卡 看上去是有人才的

7
00:00:09,200 --> 00:00:11,900
而且他们从上到下都是非常重视AI的

8
00:00:11,900 --> 00:00:12,233
那为什么

9
00:00:12,233 --> 00:00:14,266
他们反而在研究大模型这件事情上

10
00:00:14,266 --> 00:00:16,600
掉队而且看上去一直追赶不上来

11
00:00:16,600 --> 00:00:18,033
反而像DeepSeek这样的公司

12
00:00:18,033 --> 00:00:19,100
资源是他们的

13
00:00:19,100 --> 00:00:20,400
可能1/10,000都不到

14
00:00:20,400 --> 00:00:22,000
却能把这件事情给做出来

15
00:00:22,000 --> 00:00:23,700
我在频道里面其实做过几次分享啊

16
00:00:23,700 --> 00:00:26,033
就是我觉得在大厂的这种管理机制

17
00:00:26,033 --> 00:00:27,100
包括领导层不懂

18
00:00:27,266 --> 00:00:29,900
比如说我在2023年初的那个文章里边讲

19
00:00:29,900 --> 00:00:32,666
领导层的认知其实是一个稀缺资源

20
00:00:32,666 --> 00:00:34,266
都已经讲了一些道理

21
00:00:34,266 --> 00:00:36,166
但是我觉得那些东西都不是很具体

22
00:00:36,333 --> 00:00:37,033
我后来发现啊

23
00:00:37,033 --> 00:00:38,633
就是让我有一些具体认知的

24
00:00:38,633 --> 00:00:40,833
反而是一些谣言rumor

25
00:00:40,866 --> 00:00:42,833
这些谣言对我来说其实不是谣言

26
00:00:42,833 --> 00:00:43,766
它们是anecdotes

27
00:00:43,766 --> 00:00:46,100
但是因为我没有办法真的去亲身验证

28
00:00:46,100 --> 00:00:47,666
所以说在我嘴里说出来

29
00:00:47,666 --> 00:00:49,066
它其实就变成了一个rumor

30
00:00:49,066 --> 00:00:50,033
就变成了一个谣言

31
00:00:50,033 --> 00:00:51,633
可是我还是决定跟大家分享一下

32
00:00:51,633 --> 00:00:53,433
因为我觉得它对我形成判断

33
00:00:53,433 --> 00:00:55,633
其实是一些非常重要的依据

34
00:00:55,633 --> 00:00:56,866
那我今天跟大家分享出来

35
00:00:56,866 --> 00:00:58,400
我也希望大家在听的时候

36
00:00:58,400 --> 00:00:59,966
就注意到这个背景信息啊

37
00:00:59,966 --> 00:01:01,066
就是这些东西

38
00:01:01,066 --> 00:01:03,200
是我没有办法去亲身验证的

39
00:01:03,200 --> 00:01:04,666
所以说它有可能就是谣言

40
00:01:04,666 --> 00:01:06,266
但总之我觉得还挺重要

41
00:01:06,266 --> 00:01:08,600
就今天在这里边跟大家这样闭上门

42
00:01:08,600 --> 00:01:09,433
来分享一下

43
00:01:09,433 --> 00:01:10,400
第一个谣言

44
00:01:10,400 --> 00:01:11,466
或者说这个anecdote

45
00:01:11,466 --> 00:01:15,000
是关于亚马逊大模型的发展的过程

46
00:01:15,000 --> 00:01:17,266
这个其实是我多方验证的一个消息啊

47
00:01:17,266 --> 00:01:19,266
起码是有三个比较核心的人物

48
00:01:19,266 --> 00:01:20,433
我跟他们私下聊过

49
00:01:20,433 --> 00:01:21,900
然后交叉验证的信息

50
00:01:21,900 --> 00:01:22,866
我可以讲述一下

51
00:01:22,866 --> 00:01:25,533
我在这里听到的一个前因后果是什么

52
00:01:25,533 --> 00:01:27,833
就是当ChatGPT刚出来的时候

53
00:01:27,833 --> 00:01:30,033
其实是Andy Jassy亲自带队

54
00:01:30,033 --> 00:01:32,100
去做一个亚马逊内部的大模型

55
00:01:32,100 --> 00:01:32,966
代号是Q

56
00:01:32,966 --> 00:01:34,900
同时AWS那边也有一些小的动作

57
00:01:34,900 --> 00:01:36,100
包括bedrock团队

58
00:01:36,100 --> 00:01:38,166
去跟Anthropic进行深度合作

59
00:01:38,166 --> 00:01:40,766
后来betawork又去跟OpenAI去进行合作

60
00:01:40,766 --> 00:01:42,800
就是AWS作为一个Infra

61
00:01:42,800 --> 00:01:44,800
去serve外面的这些模型

62
00:01:44,800 --> 00:01:46,066
但是亚马逊自己呢

63
00:01:46,066 --> 00:01:48,766
他是想开发一个属于自己的模型的

64
00:01:48,766 --> 00:01:49,966
当时其实主要的厂商

65
00:01:49,966 --> 00:01:51,300
都是抱着这样的一个想法

66
00:01:51,300 --> 00:01:53,666
包括Databricks收购了一个模型公司

67
00:01:53,666 --> 00:01:55,633
对吧然后后来创始人现在又出来了

68
00:01:55,633 --> 00:01:57,366
就是哪怕Databricks这样的公司

69
00:01:57,366 --> 00:01:59,400
他也是想做一个自己的模型

70
00:01:59,466 --> 00:02:01,966
我在2023年的那个文章里边就有讲

71
00:02:01,966 --> 00:02:03,300
我觉得不是很看好

72
00:02:03,300 --> 00:02:04,800
很多公司去做这件事情

73
00:02:04,800 --> 00:02:05,100
当时

74
00:02:05,100 --> 00:02:07,500
我其实还跟腾讯的总办领导有过交流

75
00:02:07,500 --> 00:02:08,866
就是我把这个文章

76
00:02:08,866 --> 00:02:10,200
发给了一个总办领导

77
00:02:10,200 --> 00:02:11,700
然后他问我那应该怎么办

78
00:02:11,700 --> 00:02:14,433
我说现在腾讯最好的方式

79
00:02:14,433 --> 00:02:17,066
就是跟微软进行一个官方的合作

80
00:02:17,066 --> 00:02:19,900
通过腾讯的渠道把ChatGPT给用起来

81
00:02:19,933 --> 00:02:21,766
这是我看腾讯最好的一步

82
00:02:21,766 --> 00:02:22,266
当然了

83
00:02:22,266 --> 00:02:23,866
你也应该开发自己的大模型

84
00:02:23,866 --> 00:02:25,233
但是不要对这件事情

85
00:02:25,233 --> 00:02:26,900
抱有一个急功近利的心态

86
00:02:26,900 --> 00:02:28,300
我觉得后半句

87
00:02:28,300 --> 00:02:29,166
反正最后是发生了

88
00:02:29,166 --> 00:02:30,666
就是腾讯在开发大模型上

89
00:02:30,666 --> 00:02:32,166
是没有一个急功近利的心态

90
00:02:32,166 --> 00:02:33,233
但是他也没有去

91
00:02:33,233 --> 00:02:34,866
依托自己的这个渠道优势吧

92
00:02:34,866 --> 00:02:37,166
去能把一个外面的模型给引进起来

93
00:02:37,166 --> 00:02:39,366
当然我知道这里边的困难是非常大的

94
00:02:39,366 --> 00:02:40,866
就是你真的想去做这件事

95
00:02:40,866 --> 00:02:41,833
也未必能做成

96
00:02:41,833 --> 00:02:44,166
总之我当时的判断就是

97
00:02:44,166 --> 00:02:47,633
这些领导们肯定会觉得自己有人

98
00:02:47,633 --> 00:02:48,500
有钱有卡

99
00:02:48,500 --> 00:02:50,433
是可以做一个大模型的

100
00:02:50,433 --> 00:02:51,866
但是不那么容易

101
00:02:51,866 --> 00:02:53,033
因为这件事情

102
00:02:53,033 --> 00:02:56,100
他其实是需要一个非常强的领导力

103
00:02:56,100 --> 00:02:58,466
非常强的对这件事情的原理理解

104
00:02:58,466 --> 00:03:00,333
我不看好这些过去的领导

105
00:03:00,333 --> 00:03:01,800
对这件事有原理理解

106
00:03:01,800 --> 00:03:04,333
尤其是这些领导如果之前做过AI的话

107
00:03:04,333 --> 00:03:06,100
他们很有可能会带着错误的理解

108
00:03:06,100 --> 00:03:09,066
然后带着错误的KPI去盯这件事儿

109
00:03:09,066 --> 00:03:10,300
反而把这件事搞砸

110
00:03:10,300 --> 00:03:12,100
所以说我当时有朋友啊

111
00:03:12,100 --> 00:03:14,366
就是在那个Amazon Q上

112
00:03:14,366 --> 00:03:16,866
会去说他跟Andy Jassy是这个

113
00:03:16,866 --> 00:03:17,833
每周都会开会

114
00:03:17,833 --> 00:03:19,600
基本上资源都给的很好

115
00:03:19,600 --> 00:03:21,100
所有事情都给很多绿灯

116
00:03:21,100 --> 00:03:22,333
但是具体的人就不说了

117
00:03:22,333 --> 00:03:24,000
总之亚马逊内部的人可以知道

118
00:03:24,000 --> 00:03:27,600
就是带亚马逊Q的这个人是一个SVP

119
00:03:27,600 --> 00:03:30,233
他并不是一个真的懂generative AI的人

120
00:03:30,233 --> 00:03:33,433
或者说我对他之前所做的一些业务

121
00:03:33,433 --> 00:03:34,900
也不是那么认可

122
00:03:34,900 --> 00:03:36,500
比如说亚马逊之前

123
00:03:36,500 --> 00:03:38,633
可能人工智能真的拿出手的东西是什么

124
00:03:38,633 --> 00:03:39,266
Alexa

125
00:03:39,266 --> 00:03:40,733
但是大家知道Alexa那个玩意儿

126
00:03:40,733 --> 00:03:42,333
就是它上面有什么人工智能呢

127
00:03:42,333 --> 00:03:43,900
就是很多if-else的condition

128
00:03:43,900 --> 00:03:45,700
然后有很多非常简单模型的应用

129
00:03:45,933 --> 00:03:47,833
我在可能四五年前的视频里边

130
00:03:47,833 --> 00:03:49,033
就有批判过

131
00:03:49,033 --> 00:03:51,700
Alexa的路线只能走向人工智障

132
00:03:51,700 --> 00:03:53,166
是不能走向人工智能的

133
00:03:53,166 --> 00:03:55,733
现在也看就是那条路本来就是一条死路

134
00:03:55,733 --> 00:03:57,600
然后你又让在这条路上的人

135
00:03:57,600 --> 00:03:59,000
因为他做了这件事

136
00:03:59,000 --> 00:04:00,466
然后去招兵买马

137
00:04:00,466 --> 00:04:03,300
build empire（打造版图）然后去领导这个大模型

138
00:04:03,300 --> 00:04:05,333
那到最后其实就是折腾了很久

139
00:04:05,333 --> 00:04:06,066
大概经过了

140
00:04:06,066 --> 00:04:07,700
可能前前后后一年的时间吧

141
00:04:07,700 --> 00:04:10,066
Q这个项目就算是宣告失败

142
00:04:10,066 --> 00:04:12,000
然后就是被高层定性为

143
00:04:12,000 --> 00:04:13,066
这个项目是失败了

144
00:04:13,066 --> 00:04:14,833
然后整个经历了一些重组

145
00:04:14,833 --> 00:04:15,733
但问题是啊

146
00:04:15,733 --> 00:04:17,633
就是在这样的一个企业里边

147
00:04:17,633 --> 00:04:19,000
你虽然这个项目失败了

148
00:04:19,000 --> 00:04:20,733
人其实是没有得到大换血的

149
00:04:20,733 --> 00:04:23,233
就是真正在亚马逊里边

150
00:04:23,233 --> 00:04:25,333
有大模型能力的人

151
00:04:25,333 --> 00:04:27,100
其实是凤毛麟角的

152
00:04:27,100 --> 00:04:29,600
而且这些人是不具备话语权的

153
00:04:29,600 --> 00:04:32,133
这就是我在之前的一个视频里也有讲啊

154
00:04:32,133 --> 00:04:34,233
我当时还讲了《三体》里章北海 的例子

155
00:04:34,233 --> 00:04:35,333
不知道大家有没有记得

156
00:04:35,333 --> 00:04:36,500
就当时《三体》的故事

157
00:04:36,500 --> 00:04:39,266
是要发展公质引擎还是非公质引擎

158
00:04:39,433 --> 00:04:41,200
当时是公质引擎占了上风

159
00:04:41,200 --> 00:04:42,133
但是章北海 知道

160
00:04:42,133 --> 00:04:43,600
我们如果想要进行一个

161
00:04:43,600 --> 00:04:44,633
恒星级别的航行

162
00:04:44,633 --> 00:04:46,233
就必须要非公质引擎

163
00:04:46,233 --> 00:04:47,400
那做法是怎么办呢

164
00:04:47,400 --> 00:04:47,900
做法是

165
00:04:47,900 --> 00:04:50,366
他就把公质引擎的专家们全都暗杀了

166
00:04:50,366 --> 00:04:51,333
我后来就想了

167
00:04:51,333 --> 00:04:52,533
为什么做这么极端

168
00:04:52,600 --> 00:04:55,333
因为这就是做这件事情的唯一方式

169
00:04:55,333 --> 00:04:57,233
你必须要把那些老专家全都干掉

170
00:04:57,233 --> 00:04:58,166
因为这些老专家

171
00:04:58,166 --> 00:04:59,433
他们的expertise（专门技能）

172
00:04:59,433 --> 00:05:00,433
他们的价值

173
00:05:00,433 --> 00:05:01,300
他们的话语权

174
00:05:01,300 --> 00:05:02,233
他们的资源

175
00:05:02,233 --> 00:05:02,933
他们的身份

176
00:05:02,933 --> 00:05:05,400
全都在于他们之前的那些功劳簿

177
00:05:05,400 --> 00:05:07,200
他们是没有办法放下自己

178
00:05:07,200 --> 00:05:08,433
之前的所有身份

179
00:05:08,433 --> 00:05:10,566
去从头去拥抱一个新技术的

180
00:05:10,566 --> 00:05:12,833
因为你在拥抱新技术的同时

181
00:05:12,833 --> 00:05:15,566
就相当于你把自己身份价值给清零了

182
00:05:15,566 --> 00:05:17,433
各方面就是他们从自己的利益角度

183
00:05:17,433 --> 00:05:19,500
情感角度等等理智角度来说

184
00:05:19,500 --> 00:05:21,333
都是非常难做这件事情的

185
00:05:21,333 --> 00:05:22,833
那你真正要去做好这件事儿呢

186
00:05:22,833 --> 00:05:25,233
你真的要去找市场上真正的大模型

187
00:05:25,233 --> 00:05:26,433
这里的一流人才

188
00:05:26,433 --> 00:05:28,533
也就是说这些人能在OpenAI

189
00:05:28,533 --> 00:05:29,533
能在Anthropic

190
00:05:29,533 --> 00:05:32,633
这种顶级的AI lab里边拿到offer的人

191
00:05:32,633 --> 00:05:34,000
你要凑齐这样一批人

192
00:05:34,000 --> 00:05:35,833
你才有可能把这件事给做好

193
00:05:35,833 --> 00:05:37,033
然后我另外一个朋友啊

194
00:05:37,033 --> 00:05:39,566
就是他其实算是被挖过来的

195
00:05:39,566 --> 00:05:39,900
之前

196
00:05:39,900 --> 00:05:42,566
有一个非常好的大模型训练经历的人

197
00:05:42,566 --> 00:05:44,500
就是他是属于这种类型的人

198
00:05:44,500 --> 00:05:45,633
被挖到亚马逊

199
00:05:45,666 --> 00:05:46,733
结果他在亚马逊呢

200
00:05:46,733 --> 00:05:49,033
虽然做的东西是非常核心的

201
00:05:49,033 --> 00:05:51,400
可是有一个事情就让他下定了去意

202
00:05:51,400 --> 00:05:52,233
是什么事情呢

203
00:05:52,233 --> 00:05:54,566
就是当时做完亚马逊的OP1

204
00:05:54,566 --> 00:05:56,300
就是planning之后

205
00:05:56,300 --> 00:05:58,000
SVP跟大家吃饭聊天

206
00:05:58,000 --> 00:05:59,033
然后去打鸡血

207
00:05:59,033 --> 00:05:59,900
说我们明年啊

208
00:05:59,900 --> 00:06:00,833
大家好好干

209
00:06:00,833 --> 00:06:01,433
还是那些话

210
00:06:01,433 --> 00:06:02,833
就是我们其实是有资源的

211
00:06:02,833 --> 00:06:03,800
然后我们也是有业务的

212
00:06:03,800 --> 00:06:04,700
我们也是有数据的

213
00:06:04,700 --> 00:06:05,833
然后我们再去招一堆

214
00:06:05,833 --> 00:06:07,600
这个非常出色的new grad

215
00:06:07,600 --> 00:06:08,833
来做这件事儿就行了

216
00:06:08,833 --> 00:06:10,400
然后他当时一听就'what the fuck'

217
00:06:10,400 --> 00:06:11,833
就是你完全不懂

218
00:06:11,833 --> 00:06:14,400
然后你在这里边你去找了一堆老专家不行

219
00:06:14,400 --> 00:06:15,500
然后你现在又去找new grad

220
00:06:15,500 --> 00:06:16,233
你就是不愿意

221
00:06:16,233 --> 00:06:17,733
去做那个难而正确的事情

222
00:06:17,733 --> 00:06:18,533
难而正确的事情

223
00:06:18,533 --> 00:06:21,000
就是真的去提升自己的技术判断力

224
00:06:21,000 --> 00:06:23,400
去进到你那个不comfortable的地方

225
00:06:23,433 --> 00:06:26,133
去真的在这里边判断谁是专家谁不行

226
00:06:26,133 --> 00:06:28,500
然后去真的打造这么一个人才团队

227
00:06:28,500 --> 00:06:30,900
可是这些SVP或者说这些领导们

228
00:06:30,900 --> 00:06:32,633
他们comfortable的事情是什么呢

229
00:06:32,633 --> 00:06:33,400
要么就是相信

230
00:06:33,400 --> 00:06:35,133
他们已经有track record的人

231
00:06:35,133 --> 00:06:36,400
这个试过了一次不行

232
00:06:36,400 --> 00:06:36,933
接下来呢

233
00:06:36,933 --> 00:06:38,300
他们就可能去找new grad

234
00:06:38,400 --> 00:06:40,133
这些领导是没有判断能力的

235
00:06:40,200 --> 00:06:41,566
那在这里边他就只能说

236
00:06:41,566 --> 00:06:44,333
我看上去给到了对应的资源

237
00:06:44,333 --> 00:06:46,500
所以说我也要对应的KPI

238
00:06:46,500 --> 00:06:47,633
如果你们做不到的话

239
00:06:47,633 --> 00:06:48,366
那说明人不对

240
00:06:48,366 --> 00:06:49,400
那就再换一批

241
00:06:49,433 --> 00:06:51,166
这样的做法就是没有办法做好的

242
00:06:51,166 --> 00:06:51,966
那个人走的时候

243
00:06:51,966 --> 00:06:53,133
他老板也去留他

244
00:06:53,133 --> 00:06:54,433
然后他就跟老板说

245
00:06:54,433 --> 00:06:55,333
你想要留我

246
00:06:55,333 --> 00:06:56,033
那怎么留呢

247
00:06:56,033 --> 00:06:58,000
就是把我顶上的这些人

248
00:06:58,000 --> 00:06:59,200
比我级别高的这些人

249
00:06:59,200 --> 00:07:00,433
全都扔到市场上

250
00:07:00,433 --> 00:07:03,000
能拿到顶级AI offer的人留下

251
00:07:03,000 --> 00:07:04,366
拿不到的全都开掉

252
00:07:04,366 --> 00:07:04,800
这样的话

253
00:07:04,800 --> 00:07:06,333
我们才有可能把这件事情做好

254
00:07:06,333 --> 00:07:06,766
不然的话

255
00:07:06,766 --> 00:07:07,766
我说一个什么东西

256
00:07:07,766 --> 00:07:09,333
就上面一堆人在那说

257
00:07:09,333 --> 00:07:09,833
他要做这个

258
00:07:09,833 --> 00:07:10,400
他要做那个

259
00:07:10,400 --> 00:07:11,566
教他们他们又不愿意学

260
00:07:11,566 --> 00:07:12,400
然后你做一个事情

261
00:07:12,400 --> 00:07:13,600
他们还有各种各样的挑战

262
00:07:13,600 --> 00:07:14,700
各种各样的alignment

263
00:07:14,700 --> 00:07:16,700
在那种语境下就是不懂的比懂得多

264
00:07:16,700 --> 00:07:18,766
那你又没有办法证明你说的是对的

265
00:07:18,766 --> 00:07:20,633
自然而然就很难把这件事做好

266
00:07:20,633 --> 00:07:21,800
所以说老板一听

267
00:07:21,800 --> 00:07:23,233
虽然你说的是有道理的

268
00:07:23,233 --> 00:07:25,333
但是我好像没有办法满足你这个需求

269
00:07:25,333 --> 00:07:26,833
所以说这位同学就走了

270
00:07:26,833 --> 00:07:28,433
然后还有一位在亚马逊的同学

271
00:07:28,433 --> 00:07:30,800
他其实是当时李沐组的一个科学家

272
00:07:30,800 --> 00:07:32,300
他已经接受了我的访谈邀请

273
00:07:32,300 --> 00:07:33,700
暂时先不透露名字

274
00:07:33,700 --> 00:07:35,200
但是如果到时候访谈的话

275
00:07:35,200 --> 00:07:36,333
大家就知道他是谁了

276
00:07:36,333 --> 00:07:38,133
这位同学跟我分享了两个Insights

277
00:07:38,133 --> 00:07:39,366
我觉得是很有道理的

278
00:07:39,366 --> 00:07:41,733
第一个Insights是真正的做大模型的

279
00:07:41,733 --> 00:07:42,233
这个团队

280
00:07:42,233 --> 00:07:43,433
他要干的事情是什么

281
00:07:43,433 --> 00:07:45,000
它要cook出来一个recipe

282
00:07:45,000 --> 00:07:46,800
就好像绝命毒师的那个老白

283
00:07:46,800 --> 00:07:49,200
他去cook一个99%程度的冰毒

284
00:07:49,200 --> 00:07:50,433
就是这个recipe

285
00:07:50,500 --> 00:07:52,800
一定是要有很强的know‑how的人

286
00:07:52,800 --> 00:07:54,833
然后有很强的探索实验

287
00:07:54,833 --> 00:07:56,700
然后去把这个东西给做出来

288
00:07:56,733 --> 00:07:58,166
那你要做出来这个recipe

289
00:07:58,166 --> 00:08:00,766
其实不光是需要顶级的AI研究者

290
00:08:00,766 --> 00:08:02,966
你还需要比如说做Infra的人

291
00:08:02,966 --> 00:08:04,466
你还要需要做data的人

292
00:08:04,466 --> 00:08:05,533
你还需要做很多

293
00:08:05,533 --> 00:08:07,400
比如说处理啊并行运算的人

294
00:08:07,400 --> 00:08:07,833
所以说

295
00:08:07,833 --> 00:08:10,100
你需要有一个相对比较全面的团队

296
00:08:10,100 --> 00:08:11,300
然后他们互相之间呢

297
00:08:11,300 --> 00:08:12,566
合作的一定要非常紧密

298
00:08:12,566 --> 00:08:15,333
就是你data的人不能pre-training和post-training 的人

299
00:08:15,333 --> 00:08:16,133
然后分开做

300
00:08:16,133 --> 00:08:17,100
其实这是做不好的

301
00:08:17,100 --> 00:08:19,633
每个人心中都要有一个big picture

302
00:08:19,633 --> 00:08:21,800
然后他们互相之间了解彼此的工作

303
00:08:21,800 --> 00:08:22,966
又有自己的专精

304
00:08:22,966 --> 00:08:24,733
才能把这件事情比较好的做好

305
00:08:24,733 --> 00:08:26,633
听说在DeepSeek团队里边

306
00:08:26,666 --> 00:08:27,833
基本上都是这个样子的

307
00:08:27,833 --> 00:08:29,600
就是大家其实都很优秀

308
00:08:29,600 --> 00:08:31,200
infra的人是懂模型的

309
00:08:31,200 --> 00:08:32,700
然后pre-training, post-training

310
00:08:32,700 --> 00:08:34,433
都知道自己要干的事情是什么

311
00:08:34,433 --> 00:08:35,733
所以说在这样一个团队里边

312
00:08:35,733 --> 00:08:37,733
就可以很高效的把这件事情做出来

313
00:08:37,733 --> 00:08:39,933
第一就是你需要比较全面的团队

314
00:08:39,933 --> 00:08:41,633
去把这个recipe给做出来

315
00:08:41,633 --> 00:08:42,800
第二个insight是

316
00:08:42,800 --> 00:08:44,900
这样的团队的KPI到底是什么

317
00:08:44,900 --> 00:08:45,133
或者说

318
00:08:45,133 --> 00:08:48,033
这个团队所要optimize for的东西是什么

319
00:08:48,033 --> 00:08:49,000
在他看来应该

320
00:08:49,000 --> 00:08:51,233
是optimize for information gain（以信息增益为优化目标）

321
00:08:51,233 --> 00:08:53,133
就是说你每做一个事情

322
00:08:53,133 --> 00:08:54,233
你每做一个实验

323
00:08:54,233 --> 00:08:56,500
你应该想方设法的最大化

324
00:08:56,500 --> 00:08:59,333
你这个实验所能得到的新信息

325
00:08:59,333 --> 00:08:59,900
什么意思呢

326
00:08:59,900 --> 00:09:01,000
就是你一个实验

327
00:09:01,000 --> 00:09:03,566
如果说它有50%的可能性失败

328
00:09:03,566 --> 00:09:05,100
50%的可能性成功

329
00:09:05,100 --> 00:09:05,600
这个时候

330
00:09:05,600 --> 00:09:07,933
你基本上是最大化了你的information gain

331
00:09:07,933 --> 00:09:08,700
你可以在这里边

332
00:09:08,700 --> 00:09:10,733
test到那个最关键的variation

333
00:09:10,733 --> 00:09:11,800
或者hypothesis

334
00:09:11,866 --> 00:09:13,533
如果说你在一个很大的压力

335
00:09:13,533 --> 00:09:14,733
比如说leadership跟你说

336
00:09:14,733 --> 00:09:16,000
我给了你们这么多钱

337
00:09:16,000 --> 00:09:17,633
你三个月就必须给我做出来

338
00:09:17,633 --> 00:09:18,166
那这个时候

339
00:09:18,166 --> 00:09:21,333
你只能去找那种90%到99%成功率的

340
00:09:21,333 --> 00:09:22,100
这种东西

341
00:09:22,100 --> 00:09:23,200
那其实你到最后

342
00:09:23,200 --> 00:09:25,100
得不到一个非常好的recipe

343
00:09:25,133 --> 00:09:26,933
这是第二点很重要的insights

344
00:09:27,000 --> 00:09:27,800
所以说这件事情

345
00:09:27,800 --> 00:09:30,300
归根结底就是我觉得leadership不懂

346
00:09:30,300 --> 00:09:32,566
然后这里边的老势力太多

347
00:09:32,566 --> 00:09:34,800
那些公质引擎的专家都没有被干掉

348
00:09:34,833 --> 00:09:37,233
然后他们没有用一个正确的KPI

349
00:09:37,233 --> 00:09:38,900
leadership没有去干正确的事情

350
00:09:38,900 --> 00:09:40,633
所以导致这件事就是做不好

351
00:09:40,633 --> 00:09:42,033
那我们再看Meta是什么样子的

352
00:09:42,033 --> 00:09:43,766
我觉得小扎在这件事情上

353
00:09:43,766 --> 00:09:46,133
其实还是相对有一定的魄力

354
00:09:46,133 --> 00:09:47,500
可是我觉得

355
00:09:47,500 --> 00:09:48,233
他仍然是

356
00:09:48,233 --> 00:09:50,233
自己没有去搞懂这件事的时候

357
00:09:50,233 --> 00:09:52,166
他希望通过砸钱去做

358
00:09:52,200 --> 00:09:52,966
可是砸钱啊

359
00:09:52,966 --> 00:09:54,433
它带来了一个负面效果

360
00:09:54,433 --> 00:09:55,966
这个rumor确实是一个rumor

361
00:09:55,966 --> 00:09:56,166
就是

362
00:09:56,166 --> 00:09:58,766
我没有从内部的人得到任何verification

363
00:09:58,766 --> 00:10:01,000
我也没有去找内部的人去做verification

364
00:10:01,000 --> 00:10:03,433
但是从一个边缘的人听来的这个八卦

365
00:10:03,433 --> 00:10:06,100
就是在Superintelligence团队里边

366
00:10:06,100 --> 00:10:07,700
其实是有来自于OpenAI的人

367
00:10:07,700 --> 00:10:09,066
和来自于DeepMind的人

368
00:10:09,066 --> 00:10:10,200
他们其实互相看不上

369
00:10:10,200 --> 00:10:11,200
然后甚至互相

370
00:10:11,200 --> 00:10:12,700
有点拆台的这种行为

371
00:10:12,700 --> 00:10:14,933
注意啊这是一个完全的rumor啊

372
00:10:14,933 --> 00:10:16,100
确实没有办法verify

373
00:10:16,200 --> 00:10:19,133
可是我确实又从另外一个信源听到了

374
00:10:19,133 --> 00:10:20,700
就是superintelligence团队

375
00:10:20,700 --> 00:10:22,233
首先对外合作比较少

376
00:10:22,233 --> 00:10:24,700
其次对外合作的时候其实也有点尴尬

377
00:10:24,700 --> 00:10:25,633
你比如说就是

378
00:10:25,633 --> 00:10:27,633
他们是一堆很强的AI researcher

379
00:10:27,633 --> 00:10:28,100
那这个时候

380
00:10:28,100 --> 00:10:30,100
他们需要利用Meta已有的

381
00:10:30,100 --> 00:10:31,233
比较好的Infra

382
00:10:31,300 --> 00:10:32,733
想去跟Infra团队合作

383
00:10:32,733 --> 00:10:34,166
但问题是当你合作的时候

384
00:10:34,166 --> 00:10:36,700
一开会你拿的工资是别人的100倍

385
00:10:36,700 --> 00:10:38,900
你拿的total compensation是别人的100倍

386
00:10:38,900 --> 00:10:40,333
那别人跟你合作的时候

387
00:10:40,333 --> 00:10:41,700
这个心情是个什么心情

388
00:10:41,700 --> 00:10:42,366
在这种情况下

389
00:10:42,366 --> 00:10:43,733
我觉得是比较难facilitate（促成）

390
00:10:43,733 --> 00:10:44,900
比较好的合作的

391
00:10:44,966 --> 00:10:46,500
然后另外一个很重要的点就是

392
00:10:46,500 --> 00:10:49,600
我从外界得到的信息来看

393
00:10:49,600 --> 00:10:51,166
小扎成立这个团队

394
00:10:51,166 --> 00:10:53,600
是要搞所谓的Superintelligence

395
00:10:53,666 --> 00:10:56,266
那我不觉得这个是一个特别make sense的goal

396
00:10:56,266 --> 00:10:57,166
什么意思呢

397
00:10:57,166 --> 00:10:57,566
就是

398
00:10:57,566 --> 00:11:01,233
如果他想做的是一个特别牛逼的模型

399
00:11:01,233 --> 00:11:03,366
这个模型因为他so牛逼

400
00:11:03,366 --> 00:11:05,166
导致他和现在的这个模型

401
00:11:05,166 --> 00:11:06,600
有一个本质的差距

402
00:11:06,600 --> 00:11:07,533
我觉得这个不可能

403
00:11:07,533 --> 00:11:09,000
我觉得现在这个模型

404
00:11:09,000 --> 00:11:11,866
其实它的智力会incrementally地上升

405
00:11:11,866 --> 00:11:14,500
但是它的范式仍然是现有的这个范式

406
00:11:14,500 --> 00:11:16,333
那所以说在这个范式之下

407
00:11:16,333 --> 00:11:17,566
你应该要做好的

408
00:11:17,566 --> 00:11:19,000
其实是把现在的

409
00:11:19,000 --> 00:11:21,666
围绕这个范式的整个ecosystem搭好

410
00:11:21,666 --> 00:11:23,166
就像Andrej Karpathy说的

411
00:11:23,166 --> 00:11:25,500
你要去做10年那些困难的事情

412
00:11:25,500 --> 00:11:27,933
要把它比如说能读懂网页

413
00:11:27,933 --> 00:11:29,333
然后能操作网页

414
00:11:29,333 --> 00:11:31,400
然后可能再能读懂网页背后的东西

415
00:11:31,400 --> 00:11:33,100
把更多的context给搭起来

416
00:11:33,133 --> 00:11:34,933
我们在我们新的这个

417
00:11:34,933 --> 00:11:36,933
教大家做Agentic APP的课程里边

418
00:11:36,933 --> 00:11:38,233
我们教大家的三个方向

419
00:11:38,233 --> 00:11:40,433
分别是Frictionless Interaction

420
00:11:40,433 --> 00:11:43,900
Contextual Intelligence和Proactive Intelligence

421
00:11:44,066 --> 00:11:44,800
具体是什么意思

422
00:11:44,800 --> 00:11:45,600
我在这里贴个图

423
00:11:45,600 --> 00:11:47,000
就不细展开了

424
00:11:47,000 --> 00:11:47,200
但是

425
00:11:47,200 --> 00:11:50,000
这些东西都是需要很多的工作去做的

426
00:11:50,000 --> 00:11:51,166
你不把这些东西做好

427
00:11:51,166 --> 00:11:53,166
然后去指望一个特别聪明的模型

428
00:11:53,166 --> 00:11:54,000
解决所有问题

429
00:11:54,000 --> 00:11:56,600
在我看来这是一个演绎法的错误

430
00:11:56,600 --> 00:11:58,800
而不是一个基于第一性原理思考

431
00:11:58,800 --> 00:11:59,966
所能得出来的结果

432
00:11:59,966 --> 00:12:01,200
其实历史上有很多例子啊

433
00:12:01,200 --> 00:12:02,633
就比如说我在课程里边讲

434
00:12:02,633 --> 00:12:03,900
汽车在发明的时候

435
00:12:03,900 --> 00:12:05,766
你如果去看一八七几年

436
00:12:05,766 --> 00:12:07,700
1876年的时候的第一辆车

437
00:12:07,700 --> 00:12:08,733
其实和我们现在这个车

438
00:12:08,733 --> 00:12:10,000
长得几乎是一样的

439
00:12:10,000 --> 00:12:11,700
汽车引擎的这个技术

440
00:12:11,700 --> 00:12:13,800
在一八七几年就已经成熟了

441
00:12:13,800 --> 00:12:16,700
但是汽车在大规模普及是二战以后

442
00:12:16,700 --> 00:12:18,366
一九四几年之后的事情

443
00:12:18,366 --> 00:12:20,700
这个六七十年的时候在发生什么

444
00:12:20,700 --> 00:12:23,200
不是说你的引擎一步一步的迭代

445
00:12:23,233 --> 00:12:25,400
当然现代引擎和那个时候的引擎

446
00:12:25,400 --> 00:12:27,933
确实现代的引擎要好很多

447
00:12:27,933 --> 00:12:28,366
可是

448
00:12:28,366 --> 00:12:30,833
其实大家如果看这个技术范式的话

449
00:12:30,833 --> 00:12:32,166
是同一个技术范式

450
00:12:32,166 --> 00:12:34,766
真正影响汽车的大规模普及使用

451
00:12:34,766 --> 00:12:36,700
和让汽车变得真的有用

452
00:12:36,700 --> 00:12:38,166
是整个它的ecosystem

453
00:12:38,166 --> 00:12:39,600
是要把路给铺好

454
00:12:39,600 --> 00:12:42,400
是要把汽车的流水线制造给打通

455
00:12:42,400 --> 00:12:44,900
是要有大规模的infrastructure的建设

456
00:12:44,900 --> 00:12:46,300
然后是要有加油站

457
00:12:46,300 --> 00:12:48,633
汽车服务 修车行 驾校的配套

458
00:12:48,633 --> 00:12:50,766
这些东西都是一步一步做起来的

459
00:12:50,766 --> 00:12:53,900
才让这个汽车变得真正的有用起来

460
00:12:53,933 --> 00:12:54,700
可是小扎想的

461
00:12:54,700 --> 00:12:55,433
可能就是说

462
00:12:55,433 --> 00:12:57,100
现在我不管路是什么样子的

463
00:12:57,100 --> 00:12:58,533
我不管这个流水线是什么样子的

464
00:12:58,533 --> 00:13:00,733
我不管这个模型跟真实世界的交互

465
00:13:00,733 --> 00:13:02,966
它能控制多少我们的现有的算力

466
00:13:02,966 --> 00:13:05,000
或者说融入多少我们现有的软件算力

467
00:13:05,000 --> 00:13:07,566
我就是发明一个特别牛逼的模型

468
00:13:07,566 --> 00:13:09,166
然后它就可以解决所有问题

469
00:13:09,233 --> 00:13:09,733
在我看来

470
00:13:09,733 --> 00:13:10,800
这是一条错误路线

471
00:13:10,800 --> 00:13:12,000
当然了小扎可能是对的

472
00:13:12,000 --> 00:13:12,833
我有可能是错的

473
00:13:12,833 --> 00:13:14,433
我完全不介意被小扎打脸

474
00:13:14,433 --> 00:13:16,366
我自己作为一个AI降临派对吧

475
00:13:16,366 --> 00:13:18,700
我希望小扎的这个路线是正确的

476
00:13:18,700 --> 00:13:19,733
我希望我被打脸

477
00:13:19,733 --> 00:13:21,166
然后出来一个Superintelligence

478
00:13:21,166 --> 00:13:23,100
把我们所有的这些头疼的问题给解决

479
00:13:23,100 --> 00:13:24,933
但是我不认为这是一个feasible的事情

480
00:13:24,933 --> 00:13:25,400
我认为

481
00:13:25,400 --> 00:13:27,733
他是犯了一个不基于第一性原理的

482
00:13:27,733 --> 00:13:29,266
演绎法的典型错误

483
00:13:29,266 --> 00:13:30,133
如果大家感兴趣

484
00:13:30,133 --> 00:13:30,533
再听

485
00:13:30,533 --> 00:13:32,733
我觉得演绎法的这个典型错误是什么

486
00:13:32,733 --> 00:13:34,600
我到时候可以再单独出一期视频去讲

487
00:13:34,600 --> 00:13:35,700
这是第二个rumor

488
00:13:35,733 --> 00:13:36,766
第三个就不是rumor了

489
00:13:36,766 --> 00:13:38,433
是一个真实的案例

490
00:13:38,433 --> 00:13:40,166
就是我跟亚马逊

491
00:13:40,166 --> 00:13:42,033
我一开始工作的这些同事们

492
00:13:42,033 --> 00:13:43,833
都是一些scientists们一起吃饭

493
00:13:43,833 --> 00:13:45,100
然后他们有在亚马逊的

494
00:13:45,100 --> 00:13:46,300
然后有去了Meta的

495
00:13:46,300 --> 00:13:48,200
然后有在Airbnb的

496
00:13:48,233 --> 00:13:49,100
很搞笑的就是

497
00:13:49,100 --> 00:13:49,900
这三组人

498
00:13:49,900 --> 00:13:51,733
现在全都在用通义千问的模型

499
00:13:51,733 --> 00:13:52,900
就是在Meta的人

500
00:13:52,900 --> 00:13:54,366
我就不透露具体的org吧

501
00:13:54,366 --> 00:13:56,333
他们是在用通义千问的模型

502
00:13:56,333 --> 00:13:57,133
好像使用的原因

503
00:13:57,133 --> 00:13:58,900
除了比LLaMA的效果好之外

504
00:13:58,900 --> 00:13:59,633
就是通义千问

505
00:13:59,633 --> 00:14:01,966
它其实是在很多电商的数据上train的

506
00:14:01,966 --> 00:14:04,266
可能更符合Meta的那种场景吧

507
00:14:04,266 --> 00:14:05,533
Airbnb就不说了

508
00:14:05,533 --> 00:14:07,733
他们的CEO就公开的去说

509
00:14:07,733 --> 00:14:09,433
他们是使用通义千问的模型

510
00:14:09,433 --> 00:14:10,833
觉得比OpenAI效果要好

511
00:14:10,833 --> 00:14:11,600
或者起码不差

512
00:14:11,600 --> 00:14:12,600
然后便宜很多

513
00:14:12,633 --> 00:14:13,300
让我没想到的是

514
00:14:13,300 --> 00:14:15,133
亚马逊也是在用通义千问的模型

515
00:14:15,133 --> 00:14:16,333
后来一想也是有道理的

516
00:14:16,333 --> 00:14:18,700
就是亚马逊内部的模型Q没有做好

517
00:14:18,700 --> 00:14:20,433
那你接下来要么就使用Anthropic

518
00:14:20,433 --> 00:14:21,633
或者说是OpenAI

519
00:14:21,633 --> 00:14:23,733
但是对于亚马逊内部的那种基建来说

520
00:14:23,733 --> 00:14:26,333
他们是可能更prefer使用一个open-weight的model

521
00:14:26,333 --> 00:14:28,800
这样大家可以在上面做更多的花活

522
00:14:28,800 --> 00:14:29,700
比如说浓缩呀

523
00:14:29,700 --> 00:14:30,533
比如说fine-tune啊

524
00:14:30,533 --> 00:14:32,733
比如说做chain of thought啊这些东西

525
00:14:32,733 --> 00:14:34,700
所以说他们去使用一个通义千问

526
00:14:34,700 --> 00:14:35,366
更快更好

527
00:14:35,366 --> 00:14:36,533
然后可以做更多的花活

528
00:14:36,533 --> 00:14:37,700
更多的customization

529
00:14:37,700 --> 00:14:39,100
我觉得也是非常make sense的

530
00:14:39,100 --> 00:14:41,633
总之这些东西我听着就觉得yeah～就是

531
00:14:41,633 --> 00:14:44,366
你如果用正确的方式去做事儿的话

532
00:14:44,366 --> 00:14:45,700
你就会得到正确的结果

533
00:14:45,700 --> 00:14:47,500
你如果用一个错误的方式去做事儿

534
00:14:47,500 --> 00:14:49,766
不管你是去要求KPI也好

535
00:14:49,766 --> 00:14:52,166
还是你要去砸钱砸卡也好

536
00:14:52,166 --> 00:14:54,033
在一个简单的事情上

537
00:14:54,033 --> 00:14:56,366
这样大力出奇迹是可以做到的

538
00:14:56,400 --> 00:14:58,166
但是在一个困难的事情上这样做

539
00:14:58,166 --> 00:14:59,366
就只能适得其反

540
00:14:59,366 --> 00:15:00,233
好以上

541
00:15:00,233 --> 00:15:02,100
就是我对亚马逊和Meta

542
00:15:02,100 --> 00:15:03,100
为什么做不出模型

543
00:15:03,100 --> 00:15:04,566
的看法的分享

544
00:15:04,566 --> 00:15:05,733
again 就是大家注意

545
00:15:05,733 --> 00:15:07,900
这里边有什么是我确信的信息

546
00:15:07,900 --> 00:15:10,300
有什么是我自己没有办法证实的信息

547
00:15:10,300 --> 00:15:11,600
大家形成自己的判断

548
00:15:11,600 --> 00:15:12,933
我提出来的这些观点

549
00:15:12,933 --> 00:15:14,566
是为了激活大家的思考

550
00:15:14,566 --> 00:15:16,366
和让大家形成自己的观点

551
00:15:16,366 --> 00:15:18,633
大家自己在里边进行甄别判断

552
00:15:18,633 --> 00:15:20,333
如果你知道我哪里的信息说的不对

553
00:15:20,333 --> 00:15:22,733
或者说你觉得我哪里的逻辑有问题

554
00:15:22,733 --> 00:15:24,333
或者说是我看到的事情

555
00:15:24,333 --> 00:15:26,366
不是这个事情比较重要的那个侧面

556
00:15:26,366 --> 00:15:28,433
欢迎在视频下面留言跟我讨论

557
00:15:28,433 --> 00:15:29,533
那我们这视频就到这儿

558
00:15:29,533 --> 00:15:30,300
下次见拜拜
