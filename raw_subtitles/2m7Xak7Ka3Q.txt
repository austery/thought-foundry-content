Why does I need a lot of memory at all?
So you just explain,
you know, it's important for inference.
It's important for training, whatever.
But like, why?
Let's say
you want to train a model, right?
And then you need,
you just need the pure tons of data.
What you need to do is right. Tons of data
there to train your model.
And then for the inferencing part,
like you need one data
after another to kind of compute one
after another, sort of a chunk of sort.
Right.
So to to do that process, how can you keep
the previous data you process
to keep in there and the process
to another data that coming out after it?
Right.
So that's why you need a lot of memory,
you know back to try to beat starts
coming up.
People just like hey
I wasn't whether I like a very
simple questions
people right now is sort nastier.
People are doing like
hey can you write of, plenty more.
How tensor can happen
on people arrival example.
They will give like 20 page report
and they will wait like five minutes.
Right.
And so if you think about a process
like they do all the calculation,
all the researchers,
and also give you the output tokens that,
that's not,
and so you get from your prompt less
significant way longer than the prompts
that you are given.
Right.
And that's also the longer response
that you are getting
when you go back to the GPT three.
And remember, usage,
we know back to GPT three
was the workload,
you know, the monthly daily users.
But right now it was
I think the use of GPT was 800 million.
Right.
And we are not included.
The users for the Gemini
for called for AI.
Right.
So if you multiply loss, in fact,
I think the memory
the management inefficient
and it's very, clear to me.
Hello and
welcome to another episode of the Odd Lots
podcast.
I'm Joe Weisenthal and I'm Tracy Alloway.
Tracy, you know what I'm worried about?
I don't know if I'm worried about it,
but it kind of feels like the direction
things are going,
which is that like all energy,
industrial commodities,
anything that we use for any purpose
is just going to like feed
the AI beast and us humans.
We're
just going to get left out in the cold.
Okay? Nothing for you.
We got to like we got to feed it
all to the AI and and maybe in ten
or 20 or 50 years, the
AI is so powerful that this is AI. Why?
Why do humans get any of this?
We just,
we should keep it all to ourselves.
A legitimate concern, I would say.
I mean, to some extent, we are already
seeing this crowding out effect.
Right?
So energy prices in certain areas
have been going up
and most recently memory chip prices.
So this has been all over earnings.
Recently.
You had companies like Apple saying that
because of a crunch in memory chip supply,
they might have to either
raise their prices
or like cut down on the amount of phones
they use.
Nintendo. Yeah.
Like if you pull up
a chart of Nintendo shares right now,
they are just getting hammered
and supposedly it is all because
of this memory chip shortage.
By the way, do you remember,
do you remember like buying your first PC?
Yeah.
In like you bought one before I did,
I think.
But mine was in the mid 90s. Yeah, yeah.
I think it's about when I go to remember
how much memory those things had.
Oh like nothing. Yeah.
Like I looked it up or something like less
than ten megabytes for a bunch of them.
You know how much PCs have nowadays?
Actually, I have no idea.
I think it's let's see, 16GB.
Yeah. Is that crazy?
It is.
It is really crazy.
I remember, like,
do you remember zip drives. Yeah.
Oh my gosh.
And or like
and then there were all these special,
you know obviously various memory
peripherals that you could buy.
And they came in sort of dedicated
cartridges and stuff like that.
I think they were called zip drive.
Yeah. I think right there. ZIP drive,
I don't remember.
Yeah, yeah.
It was yeah.
That's why additional memory storage etc..
It used to be
this big part of the consumer process.
I'm actually glad.
You know, my son really wants a Nintendo,
but if they can't produce them anymore
because they can't get the memory, then
I'll say, sorry, no video games.
That's so mean.
You're going to have to sit him down
and be like, I'm so sorry, son.
You know, there's
this thing called the supply shortage.
Yeah, I'm going to use this
as a learning opportunity to explain
how global supply chains actually work.
Totally.
You know what the other
the one interesting thing is,
if you look at spot dram prices,
which we have on the terminal,
you know, there are a lot this is,
I think, maybe the interesting dynamic.
There's a lot of eye
related things on the terminal
that have been surging for several years,
most notably some of the big chip
companies, Nvidia, etc.
if you look at a chart of spot
Dram prices, the big surge
wasn't until late last year,
and then since then it's gone nuts.
So for a long time even there's this
AI story and I mean the AI industry
like propagated people were really paying
attention to that, that area.
And then suddenly it's just gone like,
you know, haywire.
Haywire. Yeah.
And so obviously huge
supply demand imbalances.
We need to understand what's going on
because I think the,
the stakes are, you know, it's
getting so much as you mentioned,
a lot of companies are losing out
pretty big.
Others are making a lot of money.
Yeah, we sort of need to get a handle
on, what's going on with the memory?
Let's do it.
I'm really excited to say
we really do have the perfect guest.
We are going to be speaking with Ray Wang.
He's an analyst at Semi Analysis
and he's recently
published a brand new report,
on exactly this topic.
Talk about a memory supercycle
and so forth.
So truly the perfect guest.
As I mentioned,
he's, comes to us from Korea.
Ray, thank you so much for coming
on. Alonzo.
Hey, nice to be both.
And thanks for having me.
So many questions.
Really appreciate you.
Joining
us, let's just start with the basics.
Like,
what is it about AI or what is going on?
What is the core idea
such that demand for memory
and various forms is absolutely
seemed to be booming right now
in a way that call it the, supply
side of the equation, very off guard.
Yeah.
I think, you know, to really
to get kind of, some imbalanced supply
demand dynamics, really,
we wanted to get like,
you know,
what happened a few years ago, right?
Because, you know, your capacity is like
your investment few years ago.
And what's happening,
you know, in 2022 and 2024, it's
it's sort of, a down cycle. Right?
Because you remember, during a Covid,
all the companies are try to log in to buy
tons of Dram.
Right.
And you know, there's a lot of,
purchases there. Right.
And this sort of like up cycle, right.
Plays like a very, very short life
cycle because like when now Covid
gradually getting better. Right.
You actually don't need that much Dram.
And back then the company will be like,
hey, you actually don't have a sustainable
demand, right?
So they don't want to over invest
to expand their capacity.
And when you go into the downside,
your CapEx typically
being very constrained, very like,
you know, company from their perspective,
they try to be conservative.
So that leads to 2024 and 25 that you're
in incremental wafer capacity, the goal.
So Dram it's actually quite limited.
But what's happening on
the demand is actually you know
demand was accelerating so fast right.
You know, just you know, one way to
look at this is to get immediate earnings.
Right.
And if you, when you, when you on one
side, you demand accelerating so fast.
On the other hand the supply side, your,
supply just couldn't catch up.
And there's more nuances behind that,
behind the supply.
Right.
Because before they are just supplying
all the commodity.
Ran like DDR, lp DDR, right.
All the memory that goes to a PC goes
through laptops,
goes through
your mobile, goes to Nintendo Switches.
Right. But you know what's happening.
You know, in this I it's like there's
a new thing called SBN.
And think about it's like a specialized
memory for directly for this reader.
And that memory is extremely dram
wafer intensive.
To give you a sense. Right.
You know, on the same way, for a basis,
you can produce three more bits,
if you do commodity Dram,
but you can only produce one bit of HBM.
Right.
And that ratio will actually going higher
when you go to HBM for HBM for
in the next few years. Right.
So in that way, on the same wafer basis,
you can you can only produce that much.
HBM and right now
what's happening is like,
hey, this is super, super, profitable.
And why not?
We dedicate more wafer for HBM.
But so here's the problem, right?
You only have that much wafer
and you need to try to do everything.
So that's handing out a lot of the supply
going into the commodity Dram.
Right. So we have
we have sort of both things happening.
And essentially comes down to like
I think really in using start
really kind of people aware,
it's like probably Q2 2025
that people realize, hey, like, you know,
we actually could have enough,
like enough dram, both enough,
commodity
Dram and also HBM, for the demand.
So you mentioned the,
the C word, just that.
Oh, wait, not that C word. Commodities.
You mentioned commodities.
And when I'm reading these articles
about a memory chip shortage,
people use commodity
type language, right?
So you hear supercycle a lot.
You hear commoditized chips
versus, you know, other types of chips.
Are they customized?
I don't think so.
But anyway,
how much does this particular industry
actually resemble
a commodities like industry.
And then maybe explain a little bit more
why historically
it has been really, really cyclical.
Yeah.
So I think a couple of reasons. Right.
You know, fundamentally the,
the sort of the cost per bits for the year
end was actually coming that coming down
every single year significantly.
Right. Even, you know, most recent year
this isn't coming down.
But like the
the standard layer coming down
for every single year
is actually slowing down.
Like, you know, over the past
like ten, 20 years. Right.
So the cost was key going down right.
So the cost is hard to be kind of like
you know, the most competitive part.
Right.
Another thing is the earth.
So the,
the understanding,
the sort of the committee
that that set up the standard
for the event. Right.
So well you are doing
in a similar products. Right.
You just having, you know, oh this is kind
of a little better for efficiency.
So the the performance
was a little better right here and there.
So like it's harmful, you know, a memory
supplier to significantly differentiate
their products
compared to their competitor.
Right.
So essentially what's the
what's the things that will in the end
will be the market prices. Right.
And then when you're selling
the similar products and you are targeting
similar audience. Right.
That sort of like on a commodity,
you know, sort of semiconductor
commodity products to me.
And I think those are the two men
characteristics I'm seeing for Dram.
And I think that's a little,
little different.
For each VM, explain this.
So there's commodity Dram
and then there's HB.
What it HBM is a type of Dram.
Is that what you're saying.
Yes. Yes.
So, so in the sense of like sort of yeah.
Like walk us through
like what the commodity version
and why there is this thing called HBM
high Bandwidth memory.
What that's all about.
Yeah. Yeah.
So essentially the emergence of HBM
is really go down to a kind of model layer
because, you know,
this is when you like, try to scale
and try scaling your air model.
Right.
Your thoughts is if
you're promising, increasing
significantly every single year, right.
Because your computers increase,
lot faster, but your memory bandwidth
was actually still off
is increasing by some very limited,
especially if you are using the memory
from, kind of traditional commodity DDR.
And then the bandwidth
is actually limited.
So from a memory supply,
they are thinking, hey, like,
how can we expand the bandwidth
to supporting low memory.
They're going
to, to skill scale the AI, right?
So let's call ourselves SVM.
So the 22 SVM.
That's so there's that, multiply 8
or 12 or even, you know, future
16 there and dies together.
Right. So that making you
have like
essentially having higher, bandwidth,
have enough capacity to support
AI development, over the past few years
and in the next few years.
And that's very different. Right?
You're stacking all these dice together
compared to, hey, I'm just
we just have like one Dram products
as a chip.
Right.
And also that also comes out to a point
that SVM manufacturing
also in the packaging of both front end
and back end
is a lot more complex
compared to commodity Dram.
And that's why I say commodity right
is more like commoditized.
So I think HP is less
so because it's a lot more complex.
Right.
And for supplier
you can actually differentiate either
from the front end or back end technology.
And when you know it's better right.
And gives you a better margin,
better ability to compare,
compete with your competitor. Right.
You know, stuff like thermal, things
like that is the thing
that will really stand out. Right?
And that's very different
from a commodity Dram
getting more and more layers on it
kind of reminds me of the razor wars
where like, you know,
Gillette would unveil a three blade thing,
and then the next day
someone has like 12 or whatever.
So if I'm a company like Nintendo,
how am I actually purchasing chips?
Because I think this is going
to be important
when we talk about
what's going on right now.
But do I have like a forward contract,
with a major supplier,
or do I have, I don't know, a warehouse
full of chips that I bought previously?
How do they actually manage that?
So there's
a couple of ways they do it right.
And then we'll never do it in in terms of
like kind of
they will do it different way
like in different environments
and also different vendors. Right.
So it's hard to say like, hey, this is
exactly, exactly the way they do it.
But technically
I think you can think about like, hey,
this is a map of the chips and kind of
purchasing the next four months
and this is a month
we're going to commit, right?
And we're going to sign a contract Pi same
whether this term will be four months
or if for the LTA you can go like as long
as like two a year or even two years.
Right.
So that's the way you think about it.
But people, you'll be like, hey, we signed
this contract for four months, right?
And sorry, for three months for a quarter.
So by the end of that quarter,
you negotiated a new contract
pricing for the next quarter.
So that's typically the way it work.
But, you know, the problem for right now
is for consumers wanting this, like
the pricing probably is sort of
I will say secondary
because if you couldn't secure value,
you couldn't even make any money.
Right.
So number one is securing value
whether that, you know,
make sure that fits,
to the demand outlook.
You are saying to us
whether we can negotiate the best pricing
you can, but
given the overall pricing environment.
So a slow volatile was so asking
so much, it's hard to like
not taking some kind of margin impact
because essentially, you know,
you try to get a chips right
and you cannot just, you know,
get too much away from your vendors.
I want to get more into the demand
destruction element, because I think
this is very important to think about
where the equilibrium is going.
But could you some just to clarify,
what is it about AI specifically?
Is it in the training?
Is it in the inference where specifically
in the process of building out
AI services,
does this voracious demand for Dram
come from
so also you say let's see what go to be.
All of this I think is really where
like right now and you know and training
you need tons of HBM that just
everyone knows right.
You also need a lot of the CPU, Dram and
less Lpddr3 and a DDR to go to the server.
You also need HBM, right?
So that's the training part.
You know, inferencing.
You also need HBM, right.
And you also need the CPU at the end
of course, of loss, workload.
Right.
You know, the main one will be the VM
and even the inferencing.
Right.
Right now
they are supporting to fill in the core.
And, you know,
I think 80% now, I think right now,
like the most important thing
will be to call. Right.
And the call is super, super like memory
bound and memory intensive.
And the memory importance of there was
just will only increase
to my understanding, especially given the
long run this window continue to expand.
And the inference usage and adoptions
continue to going up.
Right.
So I think those are the typical way
I will think about those.
Right.
And the last thing is,
I think a lot of people
talk about these days
about genetic AI, right?
I don't think I you want to power loss.
You need a lot of CPU,
you know, a lot of CPU server, right.
So what's also
what's included in the CPU server?
There's a lot of theory in there.
Right.
And a lot of I don't think will also
mean you need a lot of inference as well.
Right.
And that go back to my previous home.
You need a lot of HP and Indira. Right.
So I will say like kind of different.
And I got HP and it's kind of everywhere.
And we had to talk about storage
my storage.
And so everywhere,
you know in doing this process.
Why does I need a lot of memory at all.
So you just explain,
you know, it's important for inference.
It's important for training whatever.
But like why.
Yeah, I think I think this needs to like
goes down to the, to the model layer.
Right.
Because essentially
when you are trying to train, let's say
you want to train a model, right?
And then you need just pure tons of data.
You need to draw straight
tons of data there to train your model.
And then for the inferencing part,
like you need one data
after another to kind of compute one
after another, sort of a chain of sort.
Right.
So to to do that process, how can you keep
the previous data you process
to keep it in there and the process
to another data that coming out after it?
Right.
So that's why you need a lot of memory.
Then go back to my previous
polling. Right.
The colon context window
basically means like when you're
when the things that you are
process is longer and longer, right.
Like how can you how can you have
enough memory to process those.
Right. And you know, I'm going
to go example, if you use
you guys definitely remember it, right.
You know back to try GPT coming out.
People just like hey I wasn't
whether I like a very
simple questions people right now
it's more nastier.
People are doing like, hey, can you write
a, plenty page for
how tensor can happen on people, right.
Example.
They will give like a 20 page report
and they will wait like five minutes.
Right.
And so if you think about a process
like they do all the calculation,
all the researchers,
and also give you the output tokens that
the, the sample,
answer you get from your prompt, less
significant way longer than the prompts
that you are given.
Right.
And that's also the longer response
that you are getting
when you go back to the GPT three.
And remember, usage,
we know back to GPT three
was the would,
you know, the monthly daily users.
But right now it was
I think the use of GPT was 800 million.
Right. And we are not included.
The users
for the Gemini, for cloud, for AI.
Right.
So if you multiply loss effects,
I think the memory the most inefficient.
And it's very, clear to me.
Yeah, it's really interesting.
I know some
people were talking about this,
but it really strikes me
in my own usage of AI,
just basically how much more use it
as capabilities have grown.
Like it was
sort of cute in late 2022 is like,
oh, get it to write a poem about this.
And I was like, okay.
And then I would go,
you know, several weeks, sometimes
without having anything to query.
And then, you know, these days,
like I'm using it all the time,
like trying to do things with code
or scrape data, etc..
So just overall token consumption
has grown
massively with increased capabilities.
All right.
Let's talk
about the demand destruction element.
Any commodity is going to be
the price is going to be a function
of supply and demand.
And eventually prices get higher enough
such that certain forms of demand
just are no longer economical.
And it's like, you know what?
We're just not going to make
as many video games or cameras or whatever
else uses, memory.
Are we starting to see any of that yet
such that certain,
uses and consumption of.
So Joe doesn't have to buy a switch for
his son?
Yeah. That's right.
Yeah, I actually bought a switch recently.
So on the price have I haven't see
price spikes under my reseller,
I don't know.
We'll see how the average arbitrage there
works.
But yeah, I think I think we're already
seeing a lot of impacts, actually.
But you kind of, you kind of vary
in different kinds on the line,
right in piece.
You are surely seeing that
still not knowable.
Answer.
So so they are all having a price hike
for kind of different Apollo lines, right.
And, you know, on the kind of demand side,
are you also seeing that,
I think, for the Chinese smartphone
market, right.
A lot of the analysts
of the research firm.
Right,
a lot of the company was saying, like,
they are cutting off their smartphone.
It for example, I think
MediaTek recently definitely earnings.
Right.
They are saying they are cutting off
the numbers on mobile too.
I think it was talk for 10 to 15% of 2026
outlook.
That's very significant right.
Not to offer same this year will be
this year supposed to be 100 million.
But you will essentially goes to
a 90 million.
Right. That's very significant.
So I think we are already seeing the app
in kind of very different place.
That's right.
Apple will be a good example here
because they are saying, hey, like,
hey, we have all the price hike, right?
But we actually managed pretty well.
They are saying the real sort
of meaningful marketing impact
will actually show up
in the second half of 2026, in stealth,
like the first quarter of second quarter.
I think are some of the things
I'm seeing.
So it's definitely already
showing up in the market. Right.
I think what you can expect
this year will be two things.
One is sort of demand disruption in PCs,
right by the consumer warnings
or latte spec,
whether it's a memory display
that's very straightforward,
but also the camera, right.
Camera is also very important,
I'm sure, in some of the display
on a camera
as well. And, you know, also on the,
whole what we call it delay luxury
because you don't want to launch
a new products that have higher price
than initially thought, which will impact
your new launch performance,
which usually then you are new
to have better ASP at a margin compared
to a previous generation products. Right?
I think those are the things
that we going to see,
in the coming months,
in the coming quarters.
I think we'll all impact
and people will start feeling it.
Joe, do you think we're going
to get people like stripping old tenders
for memory chips?
Like, remember how during the commodity
supercycle in, like, the early 20 tens,
I guess there were all those stories about
people, like stealing electricity wires.
Yeah.
It happened again in 2021.
Yeah I think yeah, we might
I might get some of that.
Well, actually, on that note, is there,
is there like a short term fix
for this problem
either in terms of design,
maybe you can make the products
more efficient in some ways
so that it needs less memory or,
recycling old memory chips, I don't know.
Yeah.
I think, you know, upon the demand
side is a lot difficult, right.
On an OEM perspective. Right.
There's only that much you can do, right?
You can just spec. Right.
But I don't think to address
the fundamental issues. Right.
You are just this micro upon us.
And so you can ship.
But that is a double edged sword right?
When you don't start going upon us,
that as you look back compared to
some of your peers, who doesn't just spec
right and make you less competitive,
that impact your final sort of,
quarterly or annual shipment,
I think what need to be addressed, where
what can be done.
Let's all be on the supply side. Right.
So supply side, we are mainly talk
about couple of vendors, right.
The micron Samsung and for legacy ones.
Right. You have Wimbledon.
Yeah. And China like CME and JC right.
Last people.
So I think the most right way right now
this year
because this year that really challenges
there's a clean room constraint.
So clean room is basically
you have limited space
that you can put all this equipment.
And so manufacturing chips in fab. Right.
So you have clean room shortage
in all three major memory makers.
Right.
So your incremental wafer capacity
coming online
for 2026 will actually be quite limited.
So in that sense, how can you produce more
bit more Dram bits
while having only limited
incremental wafer capacity.
And the only thing you can do, it's,
not migration.
So for example, so in theorem processors
now you have the most advances.
Right now it's one C right.
Going down I have 1B1A and one x bar.
But right.
You know I think why
now they are trying to do is migrate
as much as they can to one B and one C,
which are the same way for basis.
They are produce, a lot more chip,
lot more bits of compared to a legacy.
Not right.
So doing that way on the same way
from pieces you can produce more bits.
So that should produce more,
supply even though your wafer capacity
is constrained.
But a challenge is two things.
One, how fast you can read about this.
Not migration, right?
Not migration is typically difficult.
Well, I will say difficult is
it only takes time, right.
For to go to the most advanced
now. Right.
You need EUV machine. Right.
You need all different
kind of manufacturing processes. Right.
And not every fab
can already prepare to doing that. Right.
So you what takes time to remember
all those production for the new events
that also you are
having the challenge to like hey okay
I want to do now migration right.
But how are we going
to balance the capacity with HBM. Again?
That's another issue.
You want to kind of think about it, right?
Because some of the SVM process
not it's actually using of windings.
They are using one
B. So let's actually do events processing.
All right.
So even you are
including one B by your listener.
You want to do more HBM.
So like the increase here
is actually quite limited.
So I think those are in a way
can potentially fix the issue.
But you know,
you know, from our house view, right.
Even we factor all those in.
I think this year we're still going
to have see question if we can shortage.
Yeah.
One of the themes that comes up
when we talk about any commodities
supercycle is that, sure, higher prices
will eventually elicit
more production, more supply.
But in the meantime, you know,
there's a sweet spot for the existing
producers, especially when you have just
a small number of producers
that can produce at scale.
They can
they enjoy massive profits. Right.
And there sort of going to be reluctant
to build out new fabs
because that's money going out the door.
It also means lower prices.
So there's always the sort of Goldilocks
period for them
before the supply comes on line,
where they're just raking in profit.
What do we see
is the, industry's impulse to invest.
And I'm curious, like,
you know, whether it's Chinese producers,
are they in a position to undercut,
potentially undercut the profits
of the Korean makers
or the Korean makers
seeing themselves as having a long window
where they can enjoy large profits
before they have to invest?
Like, what is the thinking on the supply
side about those big capital outlays?
Yeah,
that's a very good strategic question.
I think, you know,
every manager will probably give you
a somewhat different answer
or in kind of on the high level,
probably same, but I think in general.
Right.
Like, you know, you know,
look at like historical cycle, it's like,
you know, if we are seeing quite
a sustainable demand in the next few years
and then clearly the capacity couldn't
catch on the demand,
they are going to expand the capacity
in some time.
Right.
Is probably not going to be like,
hey, we now see in 2026
the capacity economy online
like meaningfully is probably 2028.
So they will I think, you know
will still announce. Right.
And we are seeing that from micron right.
Omicron is announcing a new name Fab
in Singapore right.
They are expanding now.
And they have two fab that currently
is under construction in the US right.
Also doing tons of migration
and recently acquire
the new fab from SMC
which is a Taiwanese shoemaker.
Right.
And they all just move on and
you are already seeing some sign of that.
And another sign
you are seeing it's the CapEx, right?
Both the Hynix, Samsung and Micron,
their direct CapEx
has actually increased
quite significant this year.
And you see similar trend in 2007
given I think, you know,
they're going to probably,
you know, try to expand more capacity
and invest more in both spend as well.
Also equipment that goes to events,
events, events, equipment.
Right.
That go by certain point
I was talking about the non migration.
If you want net migration
you need to use more advanced equipment
to produce more advanced chips.
Yeah.
It really does
remind me of the oil industry, right?
Where like there's a bust in the airline
commodity price
and everyone starts
talking about being disciplined.
Yeah. Yeah CapEx spend.
And so it takes a while to, ramp up.
I wanted to ask about,
I guess, the balance between HBM
and other types of Dram.
How are people or how are the actual chip
makers thinking about that?
And is there
is there a chance that because HBM,
my understanding is that it
it has higher profit margins?
Is there a chance that everyone
just pours into HBM
and kind of leaves the,
the more basic stuff in the dust?
Yeah.
So actually,
you know, it's very interesting.
I think what always seems for here
when you wrote about this,
for our institutional clients
that, you know, know the market.
Well, typically
we think SVR has higher margin, right?
Which is which is definitely true.
But what's happening, you know,
we see all of this like, spot price
control price going out so much. Right?
The margin of the commodity line right
now, it's actually higher than NBM.
So here. So that created a real dilemma.
That's crazy that you talk about it
because when your margin
is actually going higher,
why would you make more SVM.
Like why. Right.
But I think if you really think
about like a long term perspective
on the memory,
supply it right before the whole airplane,
your demand is really driving
from a market, right?
PC, mobile, automotive, industrial,
blah blah blah.
Right?
SBM right now is surge
as a new growth driver for the company,
which we believe will last
for the next few years.
Right. And for the memory supply,
they're thinking the same.
And if you're not, continue to push
your capacity to push the technology.
When you're lagging behind, it's
hard to coming back and then go back.
Go back to my previous point
that this is a area that it's
relatively easier to differentiate
your products to get more market
share, more meaningfully. Right.
So I think remember, makers are very,
very value SVM.
Even though right now
the margin of commodity right is high.
It right.
They will I think they will still invest
quite a lot IBM
and they will do their best
to sort of balance the commodity market.
But I think, you know, I think this year
at least the number I'm seeing, it's
still quite a significant shortage. Yeah.
How do the Chinese, producers
compared to the, Korean producers.
Is there a is there a gap?
Oh, yeah,
I think there is definitely the gap.
I think, like, you know,
if you look at the memory in general,
I think is probably three years
is fair to say.
It's again, it's probably four years.
I will say,
you know, that this is Mary Lang,
you know, timeliness is like,
can I solve today?
You know, who knows
what's going to happen in the future?
But I think, you know, there's
definitely a gap.
You know,
when I think about the competition
pressure from Chinese memory makers,
we always want to, like, kind of separate
the Chinese market
and also the China market.
Let's also in the memory
supply was looking at it. Right.
So Chinese market is probably about 25%
of the global demand.
So really
the competition is happening in China
because for the leading Chinese
memory supplier like CSA, for example,
I believe like 90%
or 95% of the revenue is coming from,
China, Hong Kong, Hong Kong, Hong Kong.
Right.
So meaning, you know, most of the data
is really company in Chinese market.
Company
with Micron and Heineken and Samsung.
I want to say on the
right, not on the events on the high end.
Right.
I think it will still dominated
by industry
maybe makers,
but CSA are getting two momentum right?
Right now, probably getting
some of the low end of Myanmar products.
And I also benefited by Chinese comments
policy in terms of the self-sufficiency
drive to, you know,
whether it's for a commodity, right.
And also, right now
they are pushing for developments
that support Chinese AI hardware.
So if there's a shortage and it seems like
the shortage is going to be with us
for some time, how are the chip makers
actually allocating what supply they have?
Does it go to, you know, the company
that I think is going to be really big
and important in the future, like,
I don't know, an OpenAI or something,
or does it go to an existing customer
that's been buying
in volume from me for years?
Yeah, I think there's
no doubt me that, you know,
some of the highest, highest here.
A customer will get a volume for sure.
Of course there are some more complex
like pricing negotiation behind,
but I will
I will say like the volume will be
it still will be the most important thing.
I think that's probably
what they're going to do.
Right.
And, you know, before
I think about like a buy customer,
I will think about kind of by sector,
I will say the server drain
and spend $0.02 together will be the top,
top priority.
Because, you know,
if for the whole market, in theory,
we are seeing actually SBN and server,
the unit together
is probably like more it's
more than half of the direct market.
Right.
And that's important.
And it's going so fast. Right.
And it's unlike the mobile.
Right. Mobile is kind of flat.
The mobile demand is really driven
by the increased,
direct contents in a mobile,
which is quite limited. Right.
If you buy an iPhone over the past year,
you know, like I actually can't imitate
how they're doing content increase.
So I think I think they are
those are the top two priorities,
for the memory company
to focus on in the next two years.
And we'll see what happened.
You know, after like,
you know, the second half of 2027 or 2028
if there is, some structural change,
but I think serve a different entry
and will be the top priorities.
You know, the other day I was very lazy,
which is not just just that one day,
just one day.
And, I use clawed code.
You know, I have a bunch of screenshots
on the desktop of my computer,
and I, I sort of make my desktop
look like, imagine I can't see folders.
So I like drag and drop them
and put them in the recycling bin.
And I was very lazy.
And I put in to cloud code.
I should clean up my desktop,
clean up my desktop.
And I was like, there's so insane.
I'm using, you know, anthropic computers,
wherever they are
on the other side of the country
to clean up my own computer desktop.
Why do I even have to do a good job?
Yeah, of course you're doing great.
And I was like,
why do I even have my own computer?
At this point,
I started wondering, you know, I'm like,
why do I even have a computer
could to related
to this sort of Dram question
could we just get into a situation
in which people
don't really have their own compute on it,
on their own devices, because more of it,
like anthropic brain is sort of,
or OpenAI's brain is sort of controlling
the things we use.
Why not just have a very low spec,
low spec computer or low spec phone
or whatever, or, you know, low memory,
whatever, because I'm already
using their computers, etc..
And are we just going to see
whether memory or elsewhere
this sort of migration or all of the
interesting stuff and all of the memory
and all of the compute happens elsewhere,
and my phone just becomes a sort of,
you know, or my computer just becomes,
a screen with an internet access.
Yeah.
I mean,
I don't I don't
know about the idea of, like, you know,
not having the personal devices, like,
I wasn't a device, but it's just sort of
seems like it over time.
Does it make sense for me
to have all of this
actual compute inside my house
when I'm just like, I might as well
let them know I was feeling to?
Yeah, I say it depends on like,
what's your emperor's purpose? Why?
You know, for example, on laptops,
for example,
if you're doing like video editing, very,
very heavy. Right.
Why are we still allowed to I think
probably still need quite a last year.
They. Right.
If you are just,
you know, doing like you know
document work like how cold events are,
how are you going to use it.
If I'm using like super intensively
I think you still need like a good year
end especially you all like pulling
all different API from different places.
Right.
So I will say you just
it really depends on the purpose.
I don't think like, you know,
at least at least I haven't seen, like,
you know, the API kind of structure or,
sort of the render structure
in the devices, from projecting AI.
So going back to the beginning
of this conversation
and the cyclicality of the industry,
people have been throwing around the term
supercycle again, very commodities
ask, is this just a super cycle?
You know, maybe bigger than a previous
turns that we've seen throughout history?
Or do you think something structural
has shifted
here,
perhaps, given the rise of AI and the fact
that Joe is, you know,
using claw to clean up his desktop?
This is a actually very dangerous
question to read.
And you are basically asking, right,
whether this time is different.
Right? Right.
You know, I think, well, you know,
I think there are a couple things that
actually run ins with the history right
now migration, say capacity rhino things.
But I will say, like, you know, there's
kind of a kind of differencing I'm seeing.
Right?
Because we really see, sort of supercycle
that there's a new demand driver
coming online.
It's not only constrained demand,
this thing is also constrained supply
right before because we, you know,
for example, in 2020 10 to 2012 there's
so supercycle driven by mobile right.
So mobile is basically hey
we have a new product coming online and,
you know quite a lot less
that's our capacity couldn't catch up.
But right now, I mean it's like,
hey, okay, we need to do SVM, but you I,
it's actually constrained
to a commodity, right? Capacity.
So I think this is the key difference
that we are seeing with this.
Right.
Permanently that demand serrations
is also last quite long.
Right.
And if you're really starting counting,
sort of I will say the aspiration
in terms of demand probably, let's say
second half of 2023, where really
I start kind of emerging in people's
attention,
let's say like to now it's
almost probably like the same three years.
Right. So you have two weeks, two years.
And we are looking at this cycle
to last until let's say, you know, safely
to say like second half of 27.
Right. So we are looking at like
what kind of four year cycle.
That's quite rare in the history.
The usually like in a cycle
if you look at historically
for the memory is probably like,
15 months.
I, you know, probably longest like
18 months, from the start to its peak.
But right now
we are going to throw to an area
that is like, hey,
that email was going up.
Not a price directly,
but the demand at least was growing
quite significantly over the past
few years. Right.
And the pricing impact is happening right
now, starting from, probably Q2 2025.
Yeah.
Well, what did when you say, okay,
the cycle could end
by 2027 or the second half of 2027.
What are the ingredients for it to slow
down?
Is it the more production capacity?
Is it a slowdown in total demand.
Like what
what do you see
potentially happening in 2027
that bring supply
and demand more into balance?
Yeah.
So I will say that you and I will say
like it's a more tricky area
to sort of estimate because,
you know, based on a number,
you know, I'm modeling,
we are seeing here, it's actually
we are seeing the
the demand is actually going to
actually the demand
is actually going higher and the shortage
is actually going to worse.
And the part of that is because a media
and server,
they are different
content is going to see acts compared to.
Well, right.
And then if we get a demand video service
the drop into 100.
Yeah I'm sorry looping else sorry
nothing else are doing 300.
Right.
And if that's the case and the demand
will continue to be that strong.
All right.
You're actually in a shortage
to even be worse compared to 26.
And your theory
should go a little worse, right.
Because the memory makers
going to try to make more spin wafer.
Right.
And that kind of cutting out
more on commodity Dram.
Oh, I think the reason I say
it's more tricky because two things,
I mentioned about the migration,
it's actually happened this year.
It also going to happen in 29
seven. Right.
So tons of migration going to coming
online have been completed.
So that will allow for additional bids
for the memory supplier.
Additionally, the wafer should have lot
more coming online by the end of 26.
And for, you know, throughout 2027. Right.
So I think those are two variables
that you want to factor in, for why
I'm seeing at least I think like 20 to 27
you're and going to still be shortage.
Yeah.
We need a strategic memory reserve.
Yeah. Put a floor on prices and the cycle.
Actually on that note
do you see a lot of stockpiling
in the market or panic buying right now
where people are seeing these forecasts
and they're freaking out and just buying
whatever they can.
How are you get a bullwhip effect.
That's right.
Yeah. It's hard to say no.
Right.
Like,
one of the good I think in the signal
you're seeing in timing Samsung and Micron
they're doing inventory
was dropping every single quarter
since I think Q3 2025.
Right.
That's just a 1 or 2 signal
that you are not just,
you know, buying the,
some of the products on the shelf.
Right?
And then upon us and coming online
that quarter,
you're also buying, now products
that are in their inventory, right?
Yeah.
You're trying to get as much as you can
and, you know, you know, given
all the demand and how it's developed
so fast, like by month, monthly basis,
it's hard to say, like, hey, there's no,
sort of preemptive
purchasing behavior happening.
Right?
Especially when the hyperscalers
and the media labs,
they're competing with each other,
intensively,
securing capacity on the hardware
is sort of the baseline, right?
You you you want to get the best equipment
that you can compete, right?
Yeah.
So obviously,
if I'm buying a Nintendo Switch
or if I'm buying a PC
or maybe some sort of consumer device,
then the increased memory cost
is a meaningful driver of that.
And maybe, you know, the company
we have to raise prices,
maybe I won't buy it or whatever.
And you might get this.
What about like for the big, hyperscalers
when we see these huge capital expenditure
numbers from the likes of a Microsoft
or an Amazon, do these prices changes
move the dial at these levels
in terms of do they affect anything
when we're talking about these buyers?
Yeah, I
don't think you know, number one for sure.
I think the the the CapEx is not really
all the CapEx increase is not because
of the different price increase,
but the price increase,
thus going to have some kinds of impacts
to their purchases of memory.
Right.
Assuming the hyperscalers
are the direct buyer of the memory, which,
you know, is not necessarily the case
in kind of different locations, right?
So if they are assuming
they are the direct buyers of your memory,
for sure, I if you know,
if your initial call was due to hundred
million
to buy a certain amount in memory right
now, probably you need to do some discount
there for sure.
Especially this thing
is that's probably going to the discount
to be more and more in the coming quarter.
Right?
So why would the thinking now try and are
hopefully they are trying to do.
But I just still very difficult.
It's I try to have a long term agreement.
Right.
To have a secure commit
to commit large value
for a year basis
and to hopefully to have better pricing.
But it's really hard to,
you know, to achieve that
because why no memory supply?
I want to do that. Right.
We've we can you know,
negotiate the pricing, in a coding basis
so we can actually get more money.
Right.
You know, especially given, Chrome,
pricing and supply demand environment
we want.
Thank you so much for coming on online.
It's really the perfect guest.
Let's, stay in touch and maybe we'll,
revisit it in 2027
to see if things have eased.
Yeah, hopefully.
All right.
Thank you.
Thank you so much. Care. Take care.
That was great, Tracy. That was fun.
I do feel like there's a lot
of moving pieces there, but just for me,
I in general, the crowding out
is such a big part of the story.
When you saw those big capital
expenditure plans
for 2027,
like these are real macro drivers.
They're going to show up in the CPI,
etc. like that.
And because it's like,
you know, maybe we'll get
a lot of productivity gains in the future.
But right now
that pace of spending is so furious.
It is like a fiscal boom. Yeah.
I mean still stimulus.
This is what happens
when some of the world's biggest companies
and most cash rich companies decide that
this is an existential threat, right?
There's no upper limit on how much they're
willing to spend in order to survive.
And so you could just throw money at IBM
chips, I guess.
And then you get the chip
makers going, well, actually, like
we want to produce a bunch of HBM, like,
forget about Dram, all that stuff.
I do think like,
yeah, you know, when it comes to
some of the data center and energy stuff,
you know, it's a little ambiguous how much
it's affecting energy prices right now.
But already
the politics of that is very fraught.
And then you're going to start
upsetting the gamer community
because they can't get act.
You know,
Nvidia has talked about, a big mistake
and then they're going to upset my son
because he can't get
a Nintendo Switch, etc..
People are just going to start
feeling it more and more,
the sort of visceral reality
that various resources that they thought
they could get abundantly.
It's like, nope, we've switched this line
over to the data centers,
over to AI, and it's going to become more
this crowding out
effect is going to become more
and more real to people directly.
Which is so ironic
because when you think about AI,
you know, it's this thing
that exists in the ether, right?
But at the same time, it has this huge
physical impact on the world.
And it's it's kind of funny and I
guess, like, not what a lot of people
would have expected.
No, I suppose I suppose not.
The dram people,
if you anyone who has a terminal or just
should just look up Dram prices
because this is
I thought you were going to say
anyone who has a terminal
should start stripping out
everyone who has a terminal
should just unscrew the bag
and pull out the dram.
No, but if you had, you
people should just look at the chart
because it's really here
is this thing that's very sleepy.
I mean, this was true commoditized tech.
You know, this was the low end,
in terms of what people were excited
about in chips and so forth.
And as we mentioned in the beginning,
you know, costs
generally were on this downward trend
and so forth, because growth was modest
and technology continues to improve.
And then it literally just looks
like an L really in like the last
four months just gone completely nuts.
And so yeah, kind of a fascinating spot
to watch.
And it's just interesting to the point
that you were making
how much it really is
like a commodity supercycle.
Yeah.
Commodity cycle I well I guess in 2027
maybe we'll find out.
We'll see if it balances out.
Shall we leave it
there? Let's leave it there.
This has been another episode
of the Odd Lots podcast.
I'm Tracy Alloway. You can follow me @tracyalloway
And Iâ€™m Joe Weisenthal
You can follow me @thestalwart
Follow our guest Ray Wang.
He's @rwang07.
Follow our producers Carmen Rodriguez
@carmenarmen,
Dashiel Bennett @dashbot
and Cale Brooks @calebrooks
And if you want more Odd Lots content,
then you can find that
including out daily newsletter over @bloomberg.com/oddlots
And you can chat about all of these
topics 24-7
in our discord, discord.gg/oddlots
And if you enjoyed this conversation
then please
like the video,
leave a comment or better yet, subscribe!
Thanks for watching.