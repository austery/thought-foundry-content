So, as mentioned,
I'm probably most well-known
as one of the transformers authors.
Transformers are, of course,
the T in ChatGPT,
and are the architectures that run
most of the state-of-the-art
artificial intelligence.
If I think back to that time
when we were working
on the transformers,
I remember it as a very organic,
bottom-up kind of project,
where the idea came
from talking over lunch
or scribbling randomly
on the whiteboards in the office.
And importantly, when we felt
like we did actually have a good idea,
we had the freedom
to actually spend the time
and go and work on it.
And even more importantly,
we didn't have any pressure
that was coming down from management.
No pressure to work
on any particular project,
publish a number of papers,
to push a certain number up.
So that's the image I want you
to have in your mind, right?
That is the kind of environment
that allowed the transformer
to come into existence.
An organic, open-ended
and with a lot of freedom
to pursue the ideas
that we thought
were interesting and important.
And my deep concern
is that right now in the AI industry,
we do not have this kind of environment.
And I want to talk about why not
and what can we do about it.
So the main paradox that I see
in artificial intelligence research,
or the industry in general right now,
is that despite the fact
that there's never been so much interest
and resources and money and talent,
this has somehow caused a narrowing
of the research that we're doing.
And to me, I think
the reason is fairly obvious.
It's because the immense amount
of pressure that comes with that, right?
Pressure from investors
that are going to ask
for a return on their investment
and pressure that comes from individuals,
because this is such
an overcrowded industry right now,
where it is very difficult to stand out.
And the researchers are really
feeling this pressure, right?
If you're doing, let's say,
standard AI research right now,
you kind of have to assume
that there's maybe
three or four other groups
doing something very similar
or maybe exactly the same.
So you have to spend the time
checking to see if you've been scooped,
to see if someone else
has put your idea out there.
And even in academia,
where you would hope
you would have more freedom,
there's pressure to publish, right,
and to have your papers published.
So if you have an interesting idea
that could create
something very interesting,
or you have kind of a mediocre idea
that it'll probably get a paper
and probably get accepted,
the temptation is to go
for the low-hanging fruit.
So unfortunately,
this pressure damages the science,
because people are rushing out papers,
and it's reducing the amount
of creativity that we have.
So I want to take an analogy
from AI itself.
So when we're designing
AI search algorithms,
we have to trade off something called
the exploration-exploitation trade off.
When you're searching for a solution,
you can either spend your time
exploring or exploiting.
If you spend all your time exploring,
then you will probably only find
a large number of medical solutions.
If you spend your time just exploiting,
then you might lose out
on finding other alternative solutions
that you might be able
to exploit better and improve better.
And we are almost certainly
in that situation right now
in the AI industry.
So all I really want to ask you today
is to consider just changing
that balance a little bit, right?
Just turning up the dial
and exploring more.
So I actually remember what it was like
just before the transformers,
and I want to paint that picture
for you as well.
Back then, my main memory was
there were a lot of papers coming out,
and they were always permutating
the current architecture,
which was recurrent
neural networks at the time,
just endlessly trying different things,
different gates, different layers,
mostly for incremental gains.
And then after the transformer came out,
all of that work that was spent
on improving the recurrent neural network
kind of felt a bit pointless.
Maybe that's a bit too harsh,
but think of it like this.
How much time do you think
those researchers would have spent
trying to improve
the recurrent neural network
if they knew something like transformers
was around the corner, right?
It turned out we needed
a longer conceptual leap.
We needed to throw away
recurrence completely.
And again, I am worried
that we're in that situation right now
where we're just concentrating
on one architecture
and just permuting it
and trying different things
where there might be a breakthrough
just around the corner.
And if there is, then
we should be acting like it.
The next breakthrough,
almost by definition,
has to come from this sort of open-ended,
much more speculative research, right?
And the only way to really hedge your bets
against missing out on the next big thing
is to invest in this kind of research.
So if I came up here and did nothing
but just moan about the current situation,
I don't think it would be a great talk.
So I want to give you
a couple of suggestions.
First of all,
in my company, we champion
having nature-inspired.
So there are still things,
plenty of things
that the human brain can do,
that current state-of-the-art AI can't do.
So maybe if we take
some inspiration from nature,
we can get some of those properties.
But that's kind of my bias.
You should follow
what's interesting to you?
There's actually a quote I heard
two weeks ago and I thought,
that's perfect,
I'm having that for my talk.
And I think I'm stealing it
from a guy called Brian Chung.
And it goes like this.
“You should only do research
that wouldn’t happen
if you weren’t working on it.”
And I think that captures it perfectly.
And if we all did that,
we wouldn’t be stepping
on each other’s toes,
and we'd be exploring
much more efficiently.
So I want to give you a concrete example.
There's a piece of research
that we put out recently
called the Continuous Thought Machine.
And all we did is we just took
a little bit of inspiration from nature.
So in the human brain,
synchronization is very important.
And we try to add
this kind of synchronization
into artificial neural networks.
I remember the employee
coming to me with the idea
and I said,
OK, work on it for a week,
and we’ll see what happens.
That employee later confided in me
that in his previous employment,
or even in his academic
position before that,
that he probably would have gotten
skepticism and told not to waste his time.
But after that week,
he started to find much more
interesting properties of this model.
And the project became a success.
We actually announced that we got
a spotlight at NeurIPS this year.
And I think there's a couple
of reasons for that.
I think there's a hunger for this kind
of new and differentiated research,
and more interestingly,
at no point, when we were
working on this project,
did we have to worry about being scooped.
So we could take our time, right,
to do the science properly
and run the benchmarks
that we wanted to run.
And I think that's the kind
of research we should be doing.
So hopefully, from that you can tell
that I'm not just up here
trying to make a talk that sounds good.
I actually believe this, right?
I am putting my money where my mouth is,
and I am creating this kind
of environment,
the kind of environment
that allow transformers
to come into existence at my company.
I'm not sure if I should tell you this,
because it's a bit of an advantage
that the company has right now,
but it's a really,
really good way of getting talent.
Think about it.
Talented, intelligent people,
ambitious people,
will naturally seek out
this kind of environment
with high autonomy.
And some of our best hires recently
have been explicitly
because of this reason.
And by the way,
it works better than just money.
Think about it.
These superstars that are
apparently being snapped up
for literally a million dollars
a year in some cases,
do you think that when
they start their new position,
they feel empowered
to try their mad ideas,
their more speculative ideas?
Or do they feel immense pressure
to prove their worth
and will once again go
for the low-hanging fruit?
So there's another reason, I think,
that maybe we're not exploring
quite as efficiently as we should be.
And that's because
transformers are too good.
I know, modesty.
(Laughter)
But seriously, I mean,
what can I mean by that?
What I mean is, I think
the punchline is going to be
that when we look back
at this point in AI history,
the fact that the current technology
is so powerful and flexible
that it stopped us
from looking for better.
It makes sense, right?
If the current technology was worse,
more people would be looking for better.
So there's two points
I would like to clarify.
First of all,
I'm not saying that there isn't already
plenty of very interesting
research happening.
I'm just saying that given the amount
of talent and resources
that we have currently,
we can afford to do a lot more, right?
I and several other,
many other researchers
believe we're not done
and we should be looking for better.
But I'm also not saying that we should
throw away the current technology.
No, there's still plenty
of very important research to be done
on the current technology
and will bring a lot of value
in the coming years.
I personally made the decision
at the beginning of this year
that I'm going to drastically reduce
the amount of time
that I spend on transformers.
I'm explicitly now exploring
and looking for the next thing.
Now it might sound
a little controversial, maybe,
to hear one of the transformers
authors stand on stage
and tell you that he's
absolutely sick of them,
but it's kind of fair enough, right?
I've been working on them
longer than anyone,
with the possible exception
of seven other people.
So ...
Are we bold enough?
Researchers,
are you bold enough
to spend more time on the ideas
that you think are important
and interesting?
Managers.
Are you bold enough
to give the researchers some more freedom
to pursue these ideas?
Business leaders.
Are you bold enough to create businesses
that create these kind of environments
that will allow the managers
to feel like they can afford
to give the freedom to their researchers?
And investors.
Are you bold enough
to invest in these kind of businesses,
where, in my opinion,
these are the kind of businesses
is where the next breakthrough
is going to come from.
And I will leave you with this.
A lot of the pressure, like I said,
comes from competition, right?
Competition between companies,
between products,
between researchers,
fighting over the same idea.
But genuinely, from my perspective,
this is not a competition.
We all have the same goal.
We all want to see
this technology perfected
so that we can all benefit from it.
So if we can all, collectively,
turn up the explore dial
and then openly share what we find,
we can get to our goal
much faster.
Thank you.
(Applause)