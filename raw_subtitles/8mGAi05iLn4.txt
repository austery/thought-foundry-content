我坐在这个电脑前面
我面对AI
我不知道问什么
就不知道问什么
那就是因为你没有目标
那我如何才能有目标呢
这是过去的教育专家
就是说我把这个知识教会给你了
你会用它
就行了
大脑有一个叫做工作记忆的容量
当你所做的事情
超过你工作记忆容量的时候
你就会瞬间的崩盘
其实我们可以通过对人类认知的局限
去反推AI会不会有类似的这些局限性
我感觉不会啊
我加算力就好了
我记得你们研究的这个
是多 Agent 协作
和单 Agent 工作
这是单个 Agent 使用各种技术
使用各种技能的时候
而你们觉得
好像单 Agent 这种更有效率一些
直观上来讲的话
它可以提高效率
沟通就会有信息的损失
在我测试的一些比较简单的任务里面
我确实发现了
这个单智能体
如果你给它赋一些技能的话
它可以
效果会比多智能体一起协作要更快
能做好这件任务
甚至更好
我们之前所有的教育都是在教技能
那当然也会启发思考
但是从来没有教你怎么去找意义
和定自己的目标
其实不管是不是AI
我们都希望做一个
不可能被轻易取代的人
那么你自己得形成自己的目标
等牛马工作越来越少
然后呢
能够给你下目标的老板
都不找你了
这农历新年前面（录制）的最后一期
送给大家
祝大家春节快乐
也祝大家马年快乐
欢迎回到 INDIGO TALK
这一期我们来线下录制节目
我们现在的环境在温哥华
一个非常好的视野
然后呢
今天我邀请到了一位来自于 UBC 的教授
他是在人工智能实验室的李霄霄教授
要不教授来简单介绍一下自己
好啊 大家好
首先非常感谢 Indigo 的邀请
有机会在这里跟大家分享一些
我们对 AI 前沿的看法
简单做一下自我介绍吧
好啊 我是
博士是在耶鲁大学
做的是
神经科学
神经影像和人工智能之间的交叉研究
然后 2020 年毕业之后
加入了普林斯顿大学
做了一年的博士后
研究的方向主要是机器学习系统
分布式运算
还有 AI 的这些安全隐私
2021 年我加入 UBC
英属哥伦比亚大学
然后我在这边 Lead 的是
Trusted and Efficient AI （TEA） lab
去年我就评上副教授
我现在
既在 UBC 然后也在
加拿大一个非常有名的 AI 实验室
叫做 Vector Institute
是 Geoffrey Hinton 他当时创办的
在那边做研究员
然后在我学术休假期间的话
我也在谷歌做访问的研究员
那是一个标准的 AI Researcher
但是现在在加拿大这边
对吧
应该算起来做 AI 的研究已经 12 年了
12 年了
从耶鲁然后到 Princeton
我听到 Princeton 的介绍
应该有那个分布式的 Decentralize
这些 AI 对不对
然后还有 AI 的 Security
安全这一块
然后呢 现在在 UBC
因为我们
我们离 UBC 很近
我现在这个位置
我们离 UBC 估计开车就十来分钟
嗯 对
这就到了
很近所以就是因为离 UBC 近
所以是风景很好
OK 对
UBC 确实很好的校园
欢迎大家来参观
我认为是在北美
是非常现代和漂亮的一个大学
漂亮 然后
我们今天就想聊的话题
因为正好是
我们叫霄霄教授
好吧 叫霄霄
就是
我们待会称呼的时候就更加自然一点
你叫我 Indigo
我叫你霄霄
没问题
然后呢
从你的
可以从你的研究这边的方向开始
因为我知道你在之前
应该前两周
还三周左右
给我看了一下
你们正在 Work On 的一个论文
这个关于 Agent
就是说关于这个 Agent
就是 Multi Agent
或者是单 Agent 在工作效率的问题
但不过
我们不要把话题一下带的这么深
行 没问题
我们可以先从最开始的基础的开始
好吧 然后
你先跟我们聊一下
你之前在普林斯顿
包括来 UBC 这边的一个研究的
主要的工作内容是什么呢
我们可以先先
先大概了解一下更详细的 Background
因为我开始做 AI 研究的时候
当时是 Pre-GPT 的时代
那个时候
还是基于一些卷积神经网络的一些任务
然后我们关注更多的是这些 AI 模型
它的一个效率和安全的问题啊
我们可以看到
即使在 Pre-GPT 的时代的时候
在一些图像分类任务也好
还有一些
语言翻译任务也好
那个当时的 AI 模型
其实已经有了比较高的准确性
但是呢
我们在考虑到
AI 部署到实际应用中的时候
它就会存在效率和安全性的问题
所以那些是我
主要是在普林斯顿博士后期间
还有最开始来到 UBC 当时的研究
但很快大家就发现
在 2022 年的时候
2023 年的时候就到了这个
GPT 大模型的时代
虽然在之前
我们也关心到了那个 Transformer
就是那之后
其实我们的研究会有一个转向
可能我们之后可以聊到
那么我很好奇
就是那个你现在在的这个实验室
就是 Trusted and Efficient AI lab
叫 TEA lab
你们主要是研究的这个内容是什么
我们还是不管这个底层的 AI
它的技术怎么改变
我们相信提高这个 AI 的可靠性
还有它的这个效率
它是一个永恒的一个课题
所以我们还是说
在基于现在的
一个
已经发展到的 AI 底层框架和技术上面
我们想进一步的提升它的安全可靠性
可信性 可解释性
还有它的一个效率问题
那这个 lab 和 Hinton 教授成立的那个
嗯它是属于两种机构
因为 Hinton 教授
成立的那个叫做 Vector Institute
向量研究所
它更加相当于一个研究所
OK
研究中心
那边他会 Host 很多高校里边的教授
去那边做
Faculty Member
当我们有很多那个资源
可以从那边获得
然后那就
它相当于是一个研究俱乐部了
它更像一个生态
让大家一起做 AI 的这些
Professor 也好
学生也好
可以认识合作的一个平台
那我再问一下
问一下关于
加拿大这边
因为其实这一轮 AI
我们就是大家总是把加拿大给低估
这其实这一轮 AI 爆发就来自于加拿大
对吧 这一轮
这一轮的爆发就包括从 Hinton 开始是吧
这一次的
包括我们从 McGill 大学那边的
是吧 然后现在我觉得比较火的
叫做 Continual Learning
是吧 就持续学习
Alberta 大学的 是吧
那个可能是强化学习
对 强化学习
RL 吧现在最流行的 RL
然后呢 那边有另外一个大神
就是那个写那个什么苦涩教训
The Bitter Lesson
对的
Richard S. Sutton 对
他也是和 Gemini
就是 Google Labs 这边
在相当于强力合作
他们在一块做研究
一块出论文
一块出各种东西
那么就是和阿尔伯塔
多伦多大学
麦吉尔
然后好像 UBC 的没什么
哈哈哈
UBC
我
我因为我们看这些
您刚说的那些大佬嘛
都是就功成名就
都很多年前了
都是已经获得图灵奖的了
可能我们 UBC 这边的话就比较年轻
OK OK
我觉得随着时间的这个验证吧
希望我们这边也会涌现出一些大佬
对对对是的
哈哈哈 加油加油
哈哈哈 加油
然后
因为这样
因为我刚才说这一轮
其实从研究上面
加拿大
对整个这一次新一代的 AI 革命
或者叫就是
我们叫做神经网络
包括现在的这些
包括这些
神经网络的深度学习算法
其实都是有很大的贡献
包括现在的强化学习
就加拿大
在不停的给美国的这个商业公司
输送人才
然后加拿大负责做研究
然后去美国创业赚钱
我们也很欢迎大家来加拿大这边
来学 AI 的
研究这些工作
然后那我把问题带回来
就是你刚才讲到了这个
你们研究室做的是可信的 AI
和高效能的 AI
那么现在其实有一个最火的话题
我觉得2025 年
叫做代码资源
是吧 就是 AI 都能够写代码
所有的实验室
2025 年也出现了这个 Agent
比如说像 Manus 这样的
智能体
但是 2026 年一开年
这个知道吧
我们现在那个 OpenClaw
之前叫那个 Clawdbot
这样的一个开源产品
一下子
让整个 Agent 好像就换了一个身份
又出现了一样
我觉得这个力量很大
那我们可以说一下
就是从你们的眼光里面看
从你研究方面来看
Agent 到底是什么
我觉得这是一个非常好的话题
其实啊这也是我们实验室现在
在研究的一个课题吧
对我们来说是很欣喜的看到
大家在讨论这个话题
然后
并且应用 Agent 在他们的实际生活中
但是呢
就是说刚刚您说的
好像 25 年 Agent 变成一个特别火的话题
从学术的程度来讲的话
Agent 不是一个新的概念
它比较早的定义在
或者说比较 Official 的定义在
在
可能是 90 年代有一本那个教科书
AI 的教科书叫做
《Artificial Intelligence A Modern Approach》
然后是
Peter
Norvig
他现在也是在
相当于是 Google 的 AI 的一个 Director
然后另外一个是
另外一个 Co-Author 是
Stuart Russell 他们写了一本书里边
他们在里面定义了
Agent 是一个可以感知环境
并且根据环境能够自主决策
以最大化目标的这么一个系统
就是 95 年那个时候的
听上去跟 Richard Sutton 讲的一样的
他后来写的那个什么
那个阿尔伯塔计划里面
Alberta Plan
对吧 那个里面讲到了感知环境
自我进化
OK
我觉得这是一个
就是说在
大模型以前
大家也会
公认的一个定义
OK 其实上面公认的一个定义
但是
不过目前我们看到的市场上面
对于 Agent 的一个定义会更加广泛一些
无论是说只是一些对话的链路也好
或者是工作流也好
大家也把它贴上了这个 Agent 的标签
我们的话
其实不会特别在乎就是 Agent
它具体的定义是什么
但是呢对于定义的理解的话
会影响到我们对它的一个期待
或者是我们技术路线的选择
嗯 了解
那你现在来看一下
就是说
Agent
我给大家普及一下
因为我周围问过很多朋友
大家我都
他们都在用 AI
他们到底用 AI
就是你干嘛
就是跟 AI 聊聊天
问问题
那实际上现在最强大的模型
你跟他聊天 问问题
其实你用任何模型都没有什么差别了
就是哪怕开源的模型
什么模型
但是你想深入的让他去帮你
代表你去干一些事情的时候
执行很多事情的时候
这个差别其实挺大的
那么在这个里面
我觉得是规划能力
他得有自主规划能力
这是一个
那你怎么看
你怎么看这个
这两个区别给大家分享一下
我觉得这个本质区别还挺大的
就是说我们看 ChatGPT
它提供了一些 Chatbot
之类的
它主要是一个问答的一个功能
可能有一个范式
会介于这种 Chatbot 和 Agent 之间
叫做 Workflow
OK
Anthropic 之前给了 Workflow 和 Agent
有一个非常清晰的定义的区分
他认为 Workflow 呢
是一个大模型
和工具在一个既定的路线下面
进行交互的这么一个系统
然后 Agent 是一个大模型
它有自主的去做一个 Planning 和进化
并且使用工具
Even 去创造工具的这么一个系统
所以我觉得你刚讲了一点
非常核心的一个
区别就是说它能不能够根据用户
所设定的一个目标
进行一个自主的规划
我觉得这个
并不是
所有的大模型
现在都能够非常完美的做到这一点
那你觉得最好的是哪些
你在用的时候
哎呀
我这个不好去评判吧
但是
就大家个人体感
个人体感
就是大家
大家公认的
美国这边的御三家
包括国内的那个御三家之类的
这些都不错
而且就是
你可以看到最新的这些模型
他们的这个 Reasoning 的能力上去了之后
他们这个 Agent 的规划能力也在提升
反正我就直接说
我也不在乎什么
我就觉得我用的最多
我就 Planning 里最好的是 Anthropic Claude 对
可能他写代码的深度不一定是最好
但是现在 Coding Assist 很好了 OpenAI
Code assist 很好
但是他真的他的 Planning 的这个适应性
就你用他的时候你的感知
因为这个 Planning 很重要
就是说 AI 能够很好的理解你在说什么
而且他完全能够还原
就是抓住你的想法
然后做一个很合适的 Plan 出来
而且很有效的完成这个 Plan
而且他还会自我反省
当这个东西碰到问题的时候
他自己退回来
我要去改我的计划
我再修改我的计划
我自我审查
然后我自己
就是他有一点点元认知能力了
就他知道我在干什么
他知道他自己在干什么感觉
你说这个我也有观察到
我觉得可能就是 Anthropic
他可能最开始就是想去做一个 Agent 的
基础建设
所以从这个角度上来说的话
可能对用户的这个体感来说的话
这点是比较好的
是的 然后其他的模型呢
有 Planning 能力
但是就是 Gemini
我觉得它挺快的
速度就速度
Gemini 就速度快
它速度巨快
然后它也有一点 Planning 能力
但是我感觉
可能做事情深入下去的时候
还是那个 Anthropic 好
但这样你就有不同嘛
你有的东西需要有代理任务的时候
就可以交给 Claude 去做
如果说我只是回答快速回答的时候
或者大家深度思考一下
其实 Gemini 也可以
包括 ChatGPT 也是可以的
包括 ChatGPT
现在最新更新的 Codex 是吧
它 5.2 还是 5.3 吧
对 5.3写代码能力大家都说挺好的
就是对因为它在这个方面强化了嘛
然后国产的像 MiniMax 还有
除了 MiniMax 
还有个什么
包括千问也好
然后 Kimi
然后 Kimi
对 Kimi
他们之间都有啊
御三家
两边的其实都有这些能力
而且但是具体这个
我觉得可有效性来说
我觉得还是 Claude 在
在我的用的认知里面
它是比较好的
所以我
我们会把 AI 的任务分成一种
聊天对话式任务
还有一种让他去做事情的任务
我觉得可能不同的
这种 AI 的 Frontier lab 也好
他们的技术路线
可能是有一定的差异性的
用人类的学习和认知去理解 AI
我们现在的 AI 是处于
什么样的一个时刻
这个其实没有
我觉得没有办法去很好的
去定义 AI在哪个时刻
因为我会从我的角度上觉得
我们对 AI 的认知
过于的局限 太少了
我们是很多时候是说
只是说用人类的认知去类比 AI 的认知
让我们知道
是不是它也跟人类的认知一样
有一定的局限
然后
可以用人类解决自己认知局限的方法
去提升 AI 的能力
我可以举个比较简单的一个例子
比如说
局限性
就是
之前就是
也是一本很古早的书
讲的是
应该是人类社会学的书
讲的就是人类的认知
就是有限的
他应该是那个理论叫做
认知有限理论
类似的
对于所有自然界的复杂系统来说
人大脑所具备的能力
是远远小于解决这些复杂问题
它所需要的理性能力的
具体例子就是说
我们比如说下国际象棋对吧
我们可以完全有一些
非常理性的那种解
就是说你在下每一步的时候
你能算出这一步他最后的赢率是多少
使得你每一次都能选择最优的解
这是我们叫做一个理性的能力
但是人类的能力
就是说大概你只能往前看 3-5 步
然后你去想哎
这是不是可能让我赢的一个方法
所以人类
他就是会没有办法
去完全的去解决一些复杂任务
我们把这个叫做
人类认知的一些局限之一
从其他一些局限
就我个人的感知
就是说
就我之前给你发那篇文章
我们讲的
一件事情就是说啊
当人他有很多的技能的时候
他就会认知崩溃
然后这也是我们最近在看的一件事情
就是如果你给一个 Agent
他有特别多的技能的话
他可能也会有类似的这种认知的
崩溃的这些东西
我不知道有没有
讲的太学术了
你可以再把话题拉回去
没关系
没关系我就喜欢听这个
更加这个
没关系你继续
认知崩溃
我想听你再详细解释一下
就是为什么
为什么掌握太多技能之后会认知崩溃
OK
我觉得这可能从自己
就是我们自己的体验去说吧
就是说你同时能够做多少项的任务
我觉得
可能每个人大概就是同时能做
三项任务
可能已经差不多了
对吧
或者说你同时能具备多少项技能
一个人不可能既是一个滑雪冠军
然后又是一个奥赛冠军
然后又会 Whatever 会画画
你可以从
周围人类的这种例子上面发现了
一个人并没有办法有大量的技能
这个在认知心理学里边
其实也是有这样的例子的
从最早期的时候
不好意思
又牵扯到一些学术上的东西
最早期就是有个叫 Hick's Law 的时候
他们是在做了一个实验
是说啊 他给了很多的灯
然后把它编码成一个矩阵
然后让人去做实验
如果是那些灯亮了之后
他就需要按那个按钮
代表这个灯是亮的
然后他发现
当你这个灯越来越多的时候
人去准确的按哪个灯亮的时候
这件事情就不那么准确了
或者是他所需要的思考的时间的话
他就会
大脑的思考就
就会增强
然后另外的时间就发现哎
当你给一些
那当你就是
大脑有一个叫做
工作记忆的容量
当你所做的事情
超过你工作记忆容量的时候
你就会瞬间的崩塌
你的崩溃
崩溃
所有的崩溃
这些东西都已经反映到
其实我们人类的认知
它是有这种局限的
其实我们可以通过对人类认知的局限
去反推
AI 会不会有类似的这些局限性
我感觉不会啊
我加算力好了
我不同的实体
实例就是 1000 个
或者上百
成百上千个
同时他们自己做自己的事情的时候
我觉得
我觉得你讲的一点非常好的一点就是
我们在讲类比的时候
可能是我们拿一个 AI 和
 Sorry
一个 AI Agent 和一个人去做类比
我们说可能一个 AI Agent
他可能有这样的这种
这种认知的局限
但你刚讲的就是说组织
其实人类架构也是这样的
你每个人的能力是有限的情况下面
所以人类就会有这种组织
分层抽象的这种能力
你完全可以用同样的
解决人类认知局限的方法
去解决 AI 它的认知局限
所以就会有了这样一种多智能体
的这么一个架构 对吧
我是这样理解的
我们回到前面来
就是你前面问到的那个
我们这个问题是
人类用人类的学习认知去理解 AI 嘛
然后呢
就是人类会有认知局限
因为我们脑容量有限
我们作为大脑带宽有限
而且我们的关键是我们注意力有限
Attention 是有限的
一次只能注意几个事情
但是 Transformer 是多头注意力嘛
它同时注意所有的事情
然后它就变形展开了
但是它其实也能
也能发现它有注意力局限
当你的 Context 很长很长
上下文特别大的时候
它就会 Lost
它就会丢失在上下文里面了
但是它还是这个能力比人类好多了
对不对
对对对
但就是它也有它的局限
它上下文的
这也是它的一个局限之一
这是
这个就相当于
你内存永远是有物理限制的
上下文就是它的物理限制
我们得用各种方法
那么就因为这些限制
所以单个
但是我现在我感觉单个 AI 的 Efficiency
这个效率
就是它计算效率和它使用技能的
比如说你现在用 Claude
我告诉你
我这有五个 Skill 可以用
它能够在它的一个 Planning 里面
去把这些 Skill 
排得很好
就是你给他再多 Skill 他都学得会
都不像人
我说
我说是一个人和一个 AI Agent 
那这个怎么看呢
我觉得 Yes or No
因为你刚讲到一点
就是说当你给 AI 五个 Skill 的时候
你会发现他可能他能力比他没有 Skill
或者只有一两个 Skill 的时候要强
其实我们最近的研究也发现
你不是说能够无限的增强
这个 AI 的能力
当你给到
越来越多的这么一个 Skill
我们的研究发现
当你给到 Skill
大概是在 20 到 30 个的时候
他能达到一个最好的一个 Performance
再给多的时候
他可能他的这个 Performance 也会 Saturate
也会饱和
当然就是它的原因是什么
我们只能做一些有可能的猜想
但是其实我觉得 AI
它现在包括 Agent
它的运算的底层
里边有一些很复杂的现象
我们也没有办法解释
对
因为现在确实是不可解释性的
现在都是在做可解释性研究
对吧
那么我再问回来
就是你们在做安全的时候
你们会尝试去做这些事情吗
可解释性的研究
嗯会吧
就是说我们也会发现
其实当你有
多智能体一起协作的时候
我们会发现
当你其中有一个智能体
他这个叛变了
他可能会让你整个组织的决策
都会走向错误的极端
然后我们去发现哎
为什么在哪一轮的沟通当中
这个叛变的智能体
它带来了这个决策性的影响和改变
但是
我们的所谓的解释性
很多时候是从这个 Agent
他自己的输出去反推的
我们并没有说从真正的
我们说底层的神经网络的架构
比如说 Transformer
他们的注意力也好
或者像大模型
他的一些算法也好
去理解哎
为什么
AI 会涌现出这样的能力
和这样的安全性的问题
嗯了解
了解 OK
这听上去还是
未知的东西比较多
哈哈哈 对
我感觉是非常有趣
因为就是有这么多未知的东西
所以大家才可以有很多可以尝试的
所以我只从个人的使用感觉
和对于这个我们 AI
我们叫硅基智能的特点来看
因为它的能力的提升
你可以用来 Scaling
Scaling 是吧
扩大
或者是我一把硬件的能力加强
内存变大
GPU 变快让它这个变得更好
哎但是物理
因为这个物理限制是有的
就跟人脑脑子
就我们大脑之后有物理限制嘛
但是我们大脑其实更有效一点
其实在某些程度上
在某些程度上
它是非常有效的
它非常有效率的
就是学习过程很有效率
比 AI 快多了
实际上我们的这个
我们叫做潜移默化的
我们叫做
就是说泛化式学习能力要比 AI 好
你看两个例子就懂了
AI 要大量训练才行
这个我觉得 AI 也有可能赶上了
赶上 OK
OK OK
我们回头后后面再聊
对然后我可能要要要更正一点
就是说我
我们
虽然在有时候拿 AI 跟人类去类比吧
但是我并不觉得
AI 一定要非得跟人类去类比
因为本来硅基生物和碳基生物
它们的底层原理就不一样
我们用的还是底层的这种
这种神经的这种
网络电信号
现在的 AI
比如说你我们刚刚说的这件
大模型也好
Agent 也好
它核心
还是就是现在 Transformer 的架构
下面的一些
这些
生成网络
所以
我觉得没有必要一定要给他们去做
一个
Exactly One to One Mapping 吧
很多时候
我们的研究只是说想通过人的理解
人的认知
去发现
AI 是不是也有类似的认知的局限
然后
用去解决人类认知局限的一些方案
去解决 AI 类似认知局限
的这么一些问题
那我记得以前那个
你刚刚说的那个词比较好
就是硅基智能
我觉得硅基智能的逻辑
虽然说我们都用了神经网络
用了这种类似的结构
但是因为硬件架构完全不同
或者实现方法完全不同
会产生另外一种完全不同的智能形式
就是它
可能单体的能量效率没有这个人类在
虽然我们叫生物智能
这么高能量效率
但是呢
人不能这样子
插上管子插电的哈哈哈
但是个硅基可以
硅基你可以不停的给它更多电能源
给它更多的算力
可以快速复制
所以说它可能通过暴力的方式
产生完全不同形式的智能出来
而且关键是它是可以复制的
我同意
我觉得你讲的这点特别好
就是说我们只想到
我们人类进化到现在
我们是进化或自然选择
所得到的一个结果
但其实 AI 有一点很可怕的是
它可以自己进化
现在有很多可以让 AI 自己
我们叫做 Self
叫 Self-Evolving 的算法
但还有一点
它可以被设计
我们人类给它
可以附加外界的一些能力
让它设计成一个非常 Powerful 的方法
但人类目前是没有办法被设计的
所以被设计
所以我觉得从这种角度上面
其实 AI 它的进展
可能会比我们人类智能的发展
会在某种程度上不一样的路线
不一样的路线
就是我们必须得承认另外一个
在我们所认知的宇宙里
我们反正智慧
智慧生物也没找到
就这智慧生物都在这个地球上面
那么在我们所了解的这个星球上面
新的智慧物种已经诞生了
已经诞生了
而且它进化非常快
而且是超过我们的速度的
所以说
我觉得这个
我们往我们往硅基的这个融合这个
哈哈哈这个必须得
必须得接受这个现实
这个听上去有点可怕
这虽然听上去有点可怕
但是确实也得
警示一下
那么正好
这个我们再聊一下
关于你研究的这个话题
你给我看过那个论文前
其实前面我们都在聊 AI Agent 对吧
然后呢
其实我刚才已经提到了
就是我说
单个 Agent 的和单个 AI 实体的运作
可能会有一些 Context 的限制
各种东西
我们说人也有这种限制
但是 AI 其实它的那个计算量提升
它的那个技能掌握程度会更好一些
但是呢 多 Agent 的时候
它就能够像人类的组织一样去协作了
我记得你们研究的这个
是多 Agent 的协作
和单 Agent 的工作
这是单个 Agent 的使用各种技术
使用各种技能的时候
而你的结论
好像单 Agent 这种更有效率一些
还是
你可以说一下你的这个研究方向
和这个结论
就是我们最近
应该说是
我最近可能
做了一个比较有趣的研究
就是去看
如果你给一个 Agent 赋予技能的话
它能不能去取代
多 Agent 的这么一些任务
直观上来讲的话
它可以提高效率
因为多 Agent 的话
它会有很多 Communication 的 Cost
非常容易
这可以跟人类来类比
你如果要跟其他人去协同
合作一个东西的话
沟通就会有信息的损失
然后如果这件事情
你可以自己在自己能力范围内
能干完的话
可能你是会一个高效的方法
能把它给做好的
然后
在我测试的一些比较简单的任务里面
我确实发现了
这个单智能体
如果你给它赋一些技能的话
它可以
效果会比多智能体一起协作要更快
能做好这些任务
甚至更好
那有没有更具体的一些数据
或者是呈现一些案例在这里面
我
我测试的
可能就是一些比较简单的一些数学题
或者有一些那种写代码的
这么一些任务
还没有机会再测试到一些更加复杂的
比如说在这种计算机使用上面的
一些更加复杂的任务上面去那
那 Claude 不是刚刚 Opus 发布了 4.6 吗
它里面出了一个 Agent Team
哈哈哈
那么正好它里面
它里面会有
它上次不是官方发了一个演示
说它启动了一个 Agent Team
它是为了做测试
压力测试
里面有 16 个 Agents
有的负责代码
有的负责写这个代码
有的负责写那个代码
有的负责代码审核
有的负责做 Planning
有的负责做这个测试
对还有各种各样的角色
然后他们让
这一个 Agent Team
一块完成了一个编译器
就是 C 的编译器完成了
然后这个编译器
可以重新编译 Linux 内核
我有看到这个
他们那个还是一个多智能体
或者是有一些 Sub-Agent
我们叫子智能体
的这么一个设计方法
在他那个情景下面
这是合理的
因为本来他的任务比较复杂
Agent 嘛
因为现在还是基于大模型
这样的一个基座的话
最后面他还是会由他的上下文的
这个容量受限
所以刚你讲到那个复杂任务的话
在我看来的话
它确实是一个
比较适合用多智能体的这么一个范式
去设计的一个任务
因为他有不同角色
我们叫 Persona
不同的角色去做这些
就是像一个小团队一样
因为我一个写代码的人
很难去在我这代码里面
再去发现我的错误
因为他换一个角度来思考这个问题
就是有人负责做
有人负责审核
就做的人和审核人一定要分开
你刚才讲的这个也是一个
就是说
当我们一定需要两个独立的
这么一个智能体
去协作的时候
也需要需要多智能体这么一个框架
而不是单智能体
因为当当智能体它的
整个记忆空间是没有办法隔离的
就相当于一个人
他既做裁判又做比赛选手
这样就不合理了
那你们研究里面
你们多智能体协作的这个
用的这个背景的场景是什么
就是为什么它没有单个 Agent 的
带技能会更好
我好奇啊
我再问一下
我们学术上面还是严谨一点
就说我们在
做了这个背景
是说我们去关注的是
某一类的多智能体的任务
它是特定的那种可以串行去计算的
就比如说
当你一个智能体做完一个任务之后
它的输出会接到下一个智能体
然后并且他们的记忆是可以被共享的
这就跟刚刚你讲的那个
可能是不一样的
因为你刚讲的那个就相当于
其实你有可能不同的智能体搭配
需要多任务
多任务并行去计算
并且你还需要他们在某种程度上面
进行隔离
所以我们的那个研究
是没有考虑到这种情况的
我们更加考虑到是这样
串行的这么一些任务流
那举个例子
串行任务流
就是大家就相当于是我这边有 123
就是我们两个是智能体
那边还有几个智能体
然后我们共享同一个任务清单
这个 Plan
然后呢
我们把这些任务拆成小块
然后我们按顺序执行
这种情况下
这种情况下
突然就是搬砖
我们一块搬是更快
还是一个人搬更快
你这么理解非常对的
就比如说我们两个非要做个菜
我说我是
一个切菜能手
你是一个煮菜的能手
然后我就负责切菜
你就负责煮
然后这样子的方法会比我
这我们就发现
其实如果一个人
他完全可以切菜和做饭的话
他可能会比我们这样子
串联的两个智能体
要更加得高效和做得更好一点
就是你在很多情况下
在真实世界里面
就是有的时候
一个人做事情会比几个人做事情更快
因为他一个人在他的 Context 也是连续的啊
他会很快速的
把他自己的这些任务给优化掉
然后组织成一个调用
使用他自己的不同的技能
如果说我把这个技能
分配到不同的智能体上去
因为他们需要沟通
还浪费了时间
我觉得这是一个主要的一个
就沟通他所浪费的这个成本
就比如说我们说 Token 的成本
或者是信息的损失
这是主要的两个缺陷
还有一个就是
当你构造多智能体的时候
你不可控性就会更多了
因为你在考虑到
这么一个串联的环节里面
只要有一个智能体
它的错误是会产生的
它的错误会累积到
所有它下游的智能体上面去
我了解
那确实
那确实
我自己
我按照我的使用体验
我在用 Claude 的时候
特别是 Claude Code 的时候
我下达任务的时候
比如说我想去做一些编码转码
把东西分片
然后呢 他自己就决定
这个时候他要使用 Sub Agent 的
他把这五片让 5 个 Agent 同时做
就相当他有个调度员
我觉得这个事情能够把它分包出去
我就分包给五个人就快了
如果说很多情况下呢
他还是一步一步做的
但是由他的这个组的 Agent 来决定
什么时候要启动 Sub Agent
什么时候要拿回来自己做
他都有这个智能了
你现在用那个 Claude Code 的 Cowork 的话
你会发现你给他一个任务的时候
他会自己写一个 Skill 对
或者写好几个 Skill
然后这些都是他自己去执行的
当然就像你说的
在需要把它分包给 Sub Agent 的时候
他也会把它并行的给那个分配下去
这是感觉挺聪明的
就像一个特别好的一个人类调度指挥
在指挥大家工作一样
那这个里面我正好啊
其实这个东西
实际上涉及到了一个
我们现在社会工作效率管理的问题
因为我们本身在这个世界上面有
我们是多人类协作的嘛
就是说就是这个
就会也会涉及到一个组织效率的问题
有时候组织人很多的时候
其实效率更低
我非常同意
但是呢
人太少的时候不够用
就是这
这个边界和
什么样的任务适合一个人串行来做
什么样的任务适合快速分包出去来做
我在用 Claude 的时候
我看到 AI 好像调度得非常好
哈哈哈 对
因为
它里面就会涉及到一个任务路由
这么一个概念
它会根据你任务的复杂性
它去决定这件事情到底是自己单干
还是说它要把它分到给一些 Sub Agent
或者是多个 Agent 共同协作
那么这个时候就得得出一个结论来了
我们为什么
我总觉得人类组织是一个特别冗余的
特别低效的组织
但是我们人
为什么这个就是人类这个社群
我们一块工作
因为有这么多公司出现的嘛
就我们通过这种低效的合作
然后因为确实产生了
比单个个体要牛X得多的事情出来
比如说你干工程
建大型的这种 是吧
建高铁 是吧
然后你建水坝
你建火箭
造火箭 这些东西
其实这种大型的
这种 Build 这种事情的时候
就是必须得多人协作
那这个里面就是因为有的人
每个人的专业能力不一样嘛
有的人负责生产
有的人负责检查
那么事实上在大多数的组织里面
其实效率是低下的
都通过这种路由和沟通
让这个摩擦掉了
那么我觉得
我觉得组织会这样变化
如果说我们 AI Agent
AI 的这个模型能力
在今年和明年再进一步提高
它有非常好的这种 Agent 和 Sub Agent
或者是像你们现在设计的这种
一个 Agent 加上 Skill
它自己会平衡
比如说我现在用这 3 个工
我现在我要干的这个事情
我加 3 个 Skill
我自己干就好了
我不需要其他 Agent 参与进来
他就自己决定了
当他发现这个任务可以分片分包出去
你们干的更快
他就决定分包出去了
所以这个 AI
这个 AI Agent 的调度能力
比一个熟练的人类做的还好
我觉得是他是有这样的能力的
有这种能力
有这种能力
他们有这种
那么我接下来就是那个 Elon Musk
他不是讲了个新故事
人家问他
xAI 做了 Grok
到时候怎么和他
Tesla 的机器人怎么结合
他回答我觉得非常好
这确实是考虑过了这个
而且未来就是这样子的
就是说所有的机器人
它的智能
它通过 FSD 都是在边缘完成的
在边缘是个相当于能力有限的智能
但是他做这些事情很好
但是呢
Grok 的能力它足够强大吧
它能够在云端
来进行复杂的调度和计算
然后它就可以非常好的去调度这个
那个 Optimus 的那个
那个叫做 Swarm 是吧
他的机器人的 Swarm
然后在工厂里面快速干活
就是他居然有个大脑来指挥他
马上你去干这个
然后怎么分配他
其实这个效率
就把现在
为什么现在说一个工厂的生产效率
你们这个工厂的 Workflow 的组织
和这个指挥人
这个指挥家很重要的
不然就乱七八糟里面就效率极低
那么我觉得 AI 以后扮演的角色
会比人更好
嗯我我觉得确实
就说特别是对于这种任务的
这种复杂程度的估计
以及这么一个高效的分配机制来说的话
我觉得很多时候
人在进行估算的时候
有比较多主观
或者是非量化的这么一个估算
但其实 AI 它本来就是一个非常量化的
一个机器
它确实能在某些方面上面
可能比人做的出色
所以说我觉得这个社会
如果说我们刚才前面讲的
硅基和碳基怎么融合
我觉得单体的这个生物机制
融合还是很难
因为技术还不够对
但是呢 AI Agent 作为这个出色的调度员
和这个出色的这个我们的智力补充者
融入到我们的这个公司
或者社会的组织结构里面去
会更快一点
我觉得你讲得非常的这个乐观啊
就是我可能
我可能
你可以反驳我
我可能泼一个冷水的
你可以反驳我
包括我们现在看一些这种
Agent 的设计也好
它还是过度得
模仿人类的一些组织架构
或分层的一些
这么一个范式吧
但是我觉得
可能 AI 未必需要像人类这样去进行
这个角色的分类或者组织
包括很多时候我们在讲人
我们也没有现在强制的
让 AI 的这个思考过程
我们叫 Chain of Thought
强制的跟人类的思考过程去 Align
就他的思考方案路径可能完全不一样
他的思考路径可能完全不一样
所以就是我
虽然觉得
他让 Agent 现在去模仿人类组织架构
是一个方式
但是我也期待
他可能会有一种更加自身的
一种自己去学习他们组织架构的方式
然后人类的组织架构
可以从他们的组织架构里边去
反过来去学习 OK
我理解你的意思
就是说因为人
本身这个人能力
就是因为人有各种问题嘛
人你要休息是吧
有情绪 然后呢
还有什么自尊心
有EGO 是吧
有各种问题
都有在一个组织里面
所以说它造成很多摩擦和障碍
然后呢 如果说所以说
人类社会公司里面会设计什么
高层 中层 是吧
执行层 不同的分层
但是对 AI 来说不需要了
有可能确实不需要了
他只要一个调度员
或者说都不需要调度员
或者说他是形成一种默契之间的调度
就跟打个比方说
我觉得一个蚁群
就是 Swarm Learning 的那种
Swarm Learning 就像鸟群
它没有 Leader
它没有 Leader
但是这一群鸟在一块飞的时候
动向它们去了干嘛
它能够形成非常有效的组织
就它单个个体很傻的
蚂蚁单个个体很傻
但是它 它也没有指挥
但是在蚂蚁里面
会有一点点简单的分工
有人负责是吧
这个搬食物有人负责送
送女王
喂食有人负责 Guard
就是这种简单的这个职能上的分工
然后他们一块行动
它能够表现出非常智能的东西
情况释放出来
所以所以我个人会对这种多智能体
它的协作的这个未来的方向
我可能会比较脑洞大开
我觉得它不局限于人类的这种形式
而且我觉得从出发点上来说
我们现在给 Agent 的
设计的这种协作方式
很多时候还是在默认
可能
Agent 跟人类有类似的认知局限
这我前面讲的
想 Clarify 一个问题
我说我们虽然尝试做这样类比
但是我未必觉得这个是真实存在的
也有可能 AI 它足够强大
所以人类的一些组织架构的设计
对它来说就是冗余的
就像你刚刚讲的那点
这我很认同
你刚才反驳也很好
我觉得确实是
因为为什么呢
我在想呢
因为我最近我不是在做一本书
写一本书吗
我书里有一章
就是关于 Agent 的组织和未来的组织
其实刚刚给我很大的启发
我可能之前的惯性还是说
AI 怎么进入人世界的组织
然后去改造这个组织
你就还不如
就我们完全做一个 AI 原生的机构
或者说叫做我们叫做 Vendor
一个服务提供商
它里边的组织怎么样
他们自己来就好了
自己来决定
自己来演化
嗯 OK OK
回头我写这一章的时候
我们可以再详细了解一下
我们可以再做一个
这一块的我们访谈
我就把它写到书里面去
对对对 挺好挺好
这给我很多启发在这里
因为你现在看这种多智能体的话
它还是效率问题的一个问题
我不知道
前段时间你说你玩这个
OpenClaw
你没有注意到
你在叫它多智能体的时候
它对那个 Token 的那个消耗量
大啊
很大 对吧
包括可能要用那个什么
Claude Code 或者 Claude Cowork
它的消耗量都很大的
我觉得这个可能也是一个没有解决
然后
我们想在我们研究中解决的一个问题
就怎么让这种多智能体
它的这个
效率会提得更高
但是他应该是任务下下去了
他就干活嘛
在里面
这个
你们有什么办法呢
我好奇
这个尝试引到我们
的这种科研上面
对吧
我觉得有两个东西我们现在做
我觉得比较有趣
我就跟大家分享一下
一件事情
就是比较直接的
就是说如果作为用户
我比较介意
我现在让多智能体执行的这个任务
它消耗很多 Token 的话
我们可能想要问的问题就是说
如果我给定你这么多的 Budget
我比如说我给你十美元
你能不能把我的任务做成
我可能不需要一个 100%满意的答案
你给
你那答案可能需要我两千美金
我现在只给你 10 美金
你能不能做到 90%
这样限制他是吧
这样去限制他
我们现在有个工作就是做这种
带有这种限制性
Budget 限制性的一个 Agent 的一个优化
那你是告诉他你的 Token 消耗有限
然后自己在有限的情况下
他自己去想了
还是你们会有一些
他自己去想
就比如说他有件事情
他比如说他有多个任务
他每个任务都想做到极致的满意之后
再进行下一个任务的时候
我会告诉他
你这个任务已经可能达到了
你这个八九十分的
你得放弃一下
你对完美的这个主义的这个追求
或者
不要再去摄取更多的一个可能的答案
你得转过来再把下面的事情给做完了
那这个挺好的
还有一种情况会出现
就是说因为模型
Model 的这个智能不一样
有的 Model 聪明
有的 Model 傻一点
就是
或者有的是开源的
在本地因为就端侧运行的会
因为你刚说安全嘛
有了很多东西
我也是希望在端侧的
比如说苹果做的也很好
Apple 我们说很多东西都起了个早
就是它的这个
它的那个 m 芯片
里面有各种计算单元嘛
它把这个本地的语音处理
照片识别
那些什么扫描都用本地的
这个 NPU 做了
那个 Neural 的
那个就是本地计算
它完全没有通过云端
本地
闲暇时间就把这个事情都算完了
哎
要存本地很安全
不需要传到网上去
把我的照片都给别人看到
然后再给你做一个识别
那么当这样的一个 Agent 的网络
或者说这样的一个 Agent 的 Swarm
有的 Agent 很聪明
有的 Agent 就是
就是他只能干这一件事情的
那这个东西是不是也会存在
这种组织可塑性
就是让
也算是你们研究话题里面的一部分
或者说是你调用一些比较傻的模型
然后让他去干这些事情
然后你有没有这种一些优化
我觉得你说这个完全是有可能的
因为如果你的一些
你说所谓的比较傻的模型
或者是说我们看的
就现在比较小的模型
小模型
你让他去做些专业化的事情的话
他完全是可能在他能力范围内
去能够做的到的
所以当你在调度的时候
我觉得这可能是未来
这种端侧的这种 IoT 方向上
面多智能体协作的一个方向吧
你只需要有个超级无敌的大脑
你知道把
哪些对应的任务分给到端侧
只能把那件任务
做得比较好的一个模型去做
那就可以
我觉得可能是一个
一个比较 Straightforward 的一个路径
但我刚听你讲的另外一点
让我想到的是
因为我们也做那种安全性的东西嘛
你可能现在发现包括那个 OpenClaw
对吧 其实
大家虽然说
在一个 Mac mini 上面可以部署
但是其实你还是用的是云端的 API
我觉得聪明一点吧
对 哈哈哈
而且不用耗本地的算力
因为很耗电的 对吧
这其实就牵扯到另外一个问题
就部署的问题
就是我们也会发现
其实你多
你如果是这种多智能体多 Agent 的话
它的部署它会比单智能体的部署
它需要更大的这么一个资源 Memory
你就相当于你同时需要多个智能体
就要多个大模型需要
所以有一个方向
我们也现在看的话
就是说假设
如果说我们人类都是从一些多人合作
多智能体合作的方法去设计一些任务
我先我们先把这些任务做好了
但是在我们的部署阶段
我能不能把这么一个
多智能体协作的任务
把它能够编译到单智能体能做的上面
这是两个方向
就是说一方面你在设计的时候
你可以按照多智能体去设计
去做到尽善尽美
但是你在实际部署在资源有限的情况下面
我们可以考虑到把它再压缩
再编译到单智能体
单智能体
这么一个更小的
啊 OK
那就更省资源一点吧
但是任务完成会打折吗
会打折吧
那什么任务能够接受打折呢
比如说一些简单
或者说容错率比较高的任务
写邮件啊
或者是分析一些文档
那我们正好聊一个话题
就是说关于 AI
就是因为你们既然在做安全啊
就是你们怎么看 AI 的失败
怎么做的
怎么能够看待容错
因为确实是
因为现在我觉得有个范式变化
我们之前的程序都是 100%正确的
因为那你是一个数字
就是 a 进去 
 1+1=2
这样出来的
永远都得到的是一个确定性的答案
所以有了上一代时代软件
但是它就有局限嘛
你得了确定性答案
它就没法像人类一样
去做泛化的这种智能型的推理
很多模糊性的任务就做不好
那么现在呢
我们进入到 AI
可以做模糊性任务了
可以编排任务了
那么那就有另外一个问题
就是我们到底是成功率要多少
然后失败什么样的能接受
什么样的任务
能接受 100%失败
我们才能够
再看看你们研究的东西
你可以跟我们分享一下
这个我觉得
我可能就避免讲特别多学术的东西
但是从这个比较宏观的讲的话
确实在我们在不同任务上面
我们对的容错率的感知是不一样
我举个例子
就是如果是在医疗上面
或者是在法律上面
我们对 AI 的容错率是更低一点的
我们希望他可能是尽可能接近 100%
但做一些
可能他的犯错代价不太大的
任务的上面的话
我们可能更加的包容
那什么样子
就像说写邮件
我可能写几个 Template
也不会特别的要紧
或者我生成一个视频
然后只是做娱乐的这么一个目的的话
也无所谓
我从我技术层面角度上面
可能不讲特别多
因为我们的观众可能就是有特别
Diverse 的 Background
我从因为我自己也是做教育的
然后我会觉得目前一点的话
就是说人类一定要有
对 AI 给你的结果的一个审判的能力
之前也有一些那种研究表明
就是说那个当你 AI 的能力越强的时候
他发现人类犯错的这个概率
反而越大了
是他越来越相信 AI 的结果
而不认真去审查他的结果
我觉得这种 Critical Thinking 吧
是人类一个非常重要的能力
也是现在学生
他们需要去培训的
一个很重要的一个能力
那挺难
因为你想想看那个专家
因为如果说我是某一个领域的专家
比如说
你是一个非常有经验的一个医生
就做大脑手术或者说肺部手术的
你可能很快的识别出来
一个 AI 出的结果里面的这个一些问题
因为你是专家
你已经足够专业
而且你还有很多直觉在里面
这直觉是非常奇妙的一种东西
但是很多人他做不到啊
他没有
他没有 Sense
他不在这个行业里面
就是普通人
这个太对了
我觉得其实你看
绝大多数人都是普通人
所以说
我们在讲到这个
AI 对教育的影响也好
他还是
我觉得还是
目前来说
让大家意识到 AI 有可能失败
这是一件非常重要的事情
这个是
这个教育很重要
就是说因为确实之前
我在写这本书里面就讲了
很多人就完全相信 AI
他完全相信 AI
说什么他都觉得是对的
然后他这个就没有自我了
自己什么都不会了
然后但是这个里面会有一个问题
我觉得会有问题
就是说
要让人
普通人识别出一个专业 AI 里面的错误
我觉得这个是不现实的
你不可能让在任何一个人
都去接受专家训练
那么那是不是意味着
未来要做这种专业级别的 AI 的
这种出这种非常高可靠结果的时候
旁边必须得有
非常专业的人类和他一块来
来做这个事情来出结论
就是
如果说我需要极高可靠
比如像医疗
我知道你们也在
你在研究医疗的
是不是得必须得这样
还是说完全可以放心
或者说
针对医生的这个专业人群的这个训练
会有一些变化
我觉得是
不一定
一定要有一个非常专业的人类去
Verify 每一个 AI 的结果
就我们在对 AI
的这个输出的时候
可能有些方式
可以让大家更加得警惕到 AI
他可能犯了错误
我举个例子
比如说现在的你跟 Chatbot 去聊天的话
他给你输出的这些句子的话就是
白底黑字
我们现在有一个面向这种
医疗行业的这么一个 AI 产品
应该叫 AI 研究
然后我们的输出的话
会高亮一些 AI 有可能会答错的一些点
然后需要这个我们的用户就是医生
他们去 Verify 这个答案可能是对的
然后另外呢
我们可以把对应的
这么一些医学的术语
给它链接到一些
文献也好
还有一些以往的这种
这种 Clinical Guideline 也好
让他们去查
只有当他们 Confirm 了之后
不一定他们自己有这个能力
但我们会让他强制
让他关注到这样高亮的词语
并且链接到外部的这么一些文献
让他们核实后
之后他们才能进一步
进到下一步的这么一个分析里面
相当于
你会把那种会出错的地方能找出来
我觉得是一个设计
AI 输出设计的一个问题
输出设计
那就是说什么是有哪个地方
比如说因为 AI 本身是概率嘛
你告诉你这个答案呢
就是它的概率是多少
然后给它一个结果出来
或者说可信度
你的可信度
这个 AI 的 Confidence Score 有多少
如果是
它的可信度非常低
我们在 0 到 1 之间
它可信度只有一个 0.2 左右
它也给你输出了对应那个词
它可能会被高亮出来
需要人类进一步的进行一个审查
那确实是个好办法
在医疗里面
或者其实很多在科研内容里面
或者说专业领域里面都需要
但对于我觉得
对于普通人来说
好像确实
AI 搜索结果
比他们自己能想到的好多了
哈哈哈
所以我觉得还是
我觉得还是需要一个 Critical Thinking 的
这么一个训练吧
我觉得现在确实
如果大家过分的依赖 AI 的答案的话
会让大脑产生一定的惰性
这是很这是很严重的一个问题
我记得这前两周
前一周
也是 Anthropic 做的研究还不错
他们也出了个报告
就是说
你经常在使用 Claude Code 之后
你的哪些编程能力会退化
其实所有人都退化了
会退化
这个会退化
我经常就讲这个东西
可能就有点偷懒
就好像你想锻炼你的肌肉
你去练举重
但是后来你说
现在有个高科技
它可以是外骨骼
然后我接上它之后举重很轻松
那么但是你执行这整套之后
其实你并没有锻炼到你的肌肉
就最终
我觉得以后会成为一种
一种什么样 一种训练吧
我觉得在这个里面
会有一种训练
就是你刚才说外骨骼
这个比方很好
就是说如果我经常在套外骨骼
那我的肌肉一定会萎缩的
那所以说我们接下来就两个
就两个选择
我除了
用外骨骼之外
我得戒断
我就是
现在我说我自己
用 FSD 我都不会开车了
所以每周 7 天
我有一天我自己开
哈哈哈怎么回事
对啊 这是一个办法
对对对 这是一个办法
那就是我天天戴外骨骼搬东西
那有一天我自己搬
我要锻炼一下
或者说我要去健身房
当你在做工作的时候
你可以用外骨骼增强你自己
但是你还得保持你自己身体的健康
你保持肌肉的活力
你还是得去健身房
就为什么
以前古代的时候为什么大家都挺壮的
那劳力活都得自己搬嘛
你现在又有车又有东西
什么东西都有
都自动化了
那所有现代人都退化了
而现在
大量的工作都做在这个 Office 里面
我觉得很快做 Office 人员变少了
因为你没有 Office 可以做了是吧
哈哈哈
讲到这我又想到有人会觉得
之后可能不需要大学
不需要教育
因为 AI 已经能做这么多事情
你也可以能从这个
这个 GPT 里边学很多的这个东西嘛
但是我觉得
可能以后教育的这个理念
或者大学的本质
它并不是说在给你一些知识
而是说帮助人类
去锻炼他的一些思维
这些东西
并不是
你可以直接能够从现在的这种 AI 里面
所获得的
所以说这个这很矛盾
我们新的这个教育
然后正好顺着这个东西说
我们其实聊一个比较
我觉得
因为我觉得一直是我在思考的问题
包括我在写书的时候
我也考虑过这个问题
我们叫做
这个叫做可能是一种认知坍塌
或者叫做一种你认知就是萎缩了
慢慢就会
因为你
当用大量的外界东西帮你的时候
你如何维护自己还有一些基本的认知
就你想想看
我现在用 AI 会非常方便
我所有的知识我都不用记了
但是还有一个问题就是说
我坐在这个电脑前面
我面对 AI
我不知道问什么
就是不知道问什么
那就是因为你没有目标
那我如何才能有目标呢
有很多人生下来不是
但所有
所有人/动物生下来我们都有
我们活着嘛
活着就是我们目标
但是对人 这是这不一样
他有一些意义更高的目标
有人想事业有成
有人想赚钱
或者有人想干其他
追求艺术创作
就是在这个目标
在你很小的时候
你得让自己有这样的目标感
不然为什么我觉得很多人没有能动性
就是因为他没有很好
很强的目标感驱动
而且我们之前大量的教育
并没有教你要有这么强的目标感
就是过去的教育最大的问题
就是说我把这个知识教会给你了
你会用它
就行了
那
那个这个
这个相当于是从上上个
200 多年前开始的教育
因为那个时候大量的人
世界上很多工作
或者说打仗这样的事情
我需要有技能的人来做这个事情
那么这个开学校了
我训练你怎么听口令
我训练你怎么走正步
我训练你怎么去用这个器械去战斗
怎么去训练怎么合作
然后后面随着这个知识更多的时候
我需要战争更复杂
然后经济更复杂
我需要学更多的东西
一切都是因为我要用这个技能
我才去学
那么很清楚
我受教育目标我就学技能
那是
目标是我学技能
学 Skill
那现在 Skill 我拿就好了
就像这个礼物一样
是
我还需要学吗
我不用学了
我觉得可能也是现在 AI 发展的可能
两种方向
我们可以看到 AI 一方面啊
有很多的 AI 是提升人类的效率
它其实做的是人类能做的事情
对但是能够以更快
或者一种更好的方法把它给做好
嗯但是我觉得
AI 可能也潜在的有另外一种能力
就是扩展人类的边界
这件事情可能是要人和 AI 一起探索的
或者是由人的能动性主观去探索的
我举个比较那个简单的例子吧
就是说我们在思考这一轮啊
AI 的所谓的工业革命
对人类的改变的话
相比于可能之前蒸汽时代一些改变
对吧
我们那个时候有很多很伟大的发明
包括飞机
飞机它其实不是提升人类效率
而是拓展人类边界的一件事情
但是我们现在看
其实 AI 它还没有朝着那个方向去发展
所以我觉得人类他
我们人类的一些创造力
和寻找一些东西的意义
能够跟 AI 一起协同的
去做这些伟大的事情
了解 那我就是说
你说两个方面
我都很认同
就第一个是帮我们提升效率
帮我提效
这是显而易见的
现在大家都要做这些事情
但提升效率的同时
会让我们陷入到一个
就是说你的认知会坍塌
因为你经常不这样做这个事情
你基本的这个认知结构就没有了
那这个事情呢
所以说这个回到了一个很核心的问题
我应该学习
应该学什么
我应该平时
就像以后
真的像现在
我老了 体力劳动不用做了
大家要保持肌肉
我只能去健身房
那以后 是吧
很多东西不用学了
我要保持这个
我脑子里面有对世界有基本的
那我大脑
这个世界有基本的理解和认知
那我只能去哪
去学校去健身房
去锻炼
就是可能是我就会有很多这种俱乐部
叫做什么认知提升班
或者认知形成
就是他可能就是让你做一些基本的
让你大脑形成这样的一个意识
或者形成这样一个结构
不至于忘掉这样的
对世界的这样理解
学校就是教你这样的一套
这种通识教育
你确实不用学怎么去做计算的
但是你的通识
大脑对这个世界理解的完整性
道德是什么
然后逻辑是什么
这种教育其实更重要了
因为
因为之前可能我们都在学技能嘛
之前
就是我们现在认为学校里面那些
很无用的
很无用的专业
可能会变得更有用了
哈哈哈
这个确实
还是那个报告里面
我最近看也有趣一点
说这个 AI 可能最先取代的比较多了
比如说像法律之类的这么一些
我们所谓的白领工作
其实
取代比较少的就是比如说零售
销售
建筑
这些行业
这体力活吧
但是我说了
还有一种认知活就是
就是相当于是
我能很好的就通识型的认知
认知后我感觉我你很 Smart
很有智慧
然后你可以把各种行业知识给
像哲学
或者学一些理论的物理
和数学这种计算的思维方式
很重要
我同意
我觉得这种跨领域的这么一些
资源整合和创造力类似的东西的话
目前还是人类的一项优势
也是需要我们去保持的一种
思维方式
因为这个就是说我想的逻辑
就是在 AI 能够辅助我们
完成很多技能型工作的时候
我们需要有这个能力
以至于我们在没有 AI 的时候
我们快速恢复我们的知识系统
哈哈哈
我我觉得还有一点就是说
包括现在有一些简单任务的话
我也不会通过 AI 去做
我觉得很多东西是我浅层意识里面
它虽然也是一个我们叫做 System Two
它是经过一个思考去对完成了任务
但是可能有些东西
映射在我们人类大脑里面的东西
会让我一个更快的反应
而我不需要去等待
比如说现在的大模型
它去反应好几秒才给我一个答案
那就是直觉训练
一些直觉
对你直觉的训练
这是第一个
我觉得可能教育会这样变化
教的东西不一样了
就是我们之前
我说最前面
我们之前所有教育
都是技能教育
可能有的大学里面
有的大学
在北美大学风格不一样
那有的学校就挺适合教这种东西的
培养这个人的这个创造力
但是有的学校很工科
就是需要训练工程师
有的就是训练科学家的
像普林斯顿
哈哈哈
训练科学家的
然后第二个
就是我觉得更有意义更大的事情
就是拓展边界
这个时候你刚才
给的非常好的一个
我们认为现在这一轮 AI 革命
带来了更有更有意义的事情
如果说不拓展边界
那我们的经济就永远是这个饼
就这么大
你效率再高
你也只是我效率高的
把效率低的吃掉了
我饼变不大
哈哈哈
是的
那如果边界变大了之后
那我们就要做更大的饼了
更大的饼
那我经济还会增长
如果饼不大
经济增长不了
就把饼闹大
那这个边界就是刚刚讲的
科学艺术
科学边界
艺术边界和这些研究的边界
总体上来说
就是一种创造力的一些边界
它可能需要很多的
这种领域的融会贯通
那确实是的
那这个
就跟之前说
其实有个例子挺好的
挺形象的
我们为什么一个变革发生的时候
总是让
让这个我们在这空间上移动的
这个效率变高
比如说
蒸汽机之后
那叫蒸汽
蒸汽车
就快嘛 是吧
然后呢 后面还有铁路的
然后电力时代就有了
那个铁轨嘛
就是高铁嘛
然后呢
后来还有引擎
有了之后就有飞机嘛
我们永远都是因为这个
移动速度变快了
之后
让这个世界突然一下这个结构变
就是物理的结构
移动物理世界的结构发生了变化之后
就会有
让这个空间 就是饼就变大了
你就新的职业和新的这个
他就是因为让那个
让我们人类在这个空间里面移动的
这个效率变得极高了
那么我们这一次除了 AI
是让我们头脑的
就是以前乔布斯说那个
电脑就是个人大脑
自行车
其实现在 AI 才是
叫智力的
这个叫做加速器
那么有了 AI
能够让我们智力边界变高
其实还有一点就是说
我如果说在物理层面上来看呢
就是两方面
一方面是机器人
可以让我们的这个效率变得更高
因为它可以帮我们干很多事情
然后另外一摊呢
我们人移动是这样移的
往上移的
就是你可以往外
你可以把地球想象成
之前的你只是在表面
然后马上你可以在外空间上面
在近地轨道上面
可以干很多事情
就升维了
哈哈哈
就是直接升了一维
对对对 所以说
我觉得未来把饼做大的几个地方
就是 AI 能够把 AI 饼做大
然后这个空间运转能力
我们能够把饼做大
然后呢 AI 还能够驱动这个机器人
把生产的效率提高了
饼做大
所以说我觉得在这个下面来看
这个教育和边界的意义就全变了
我觉得这个
它也是会随着这个 AI 的发展
它会去改变的
这么一些行业
那么最后吧
我们来总结一下就是
好 你来
你做教育
你是教育工作者
哈哈哈 总结一下
你从
从你的这个怎么来看这个大学的教育
在现在这样的一下面的一些
或者说给年轻人选大学
或者选未来求职一些建议
好吧这是很现实的一个问题
我觉得吧
就是大学的教育
目前来说还是非常有意义的
他还是在啊
锻炼两种思维能力
我们之前也谈到过
一个是 Critical Thinking
就是
你对问题和答案的一个审视能力
另外一个是逻辑思考的能力
所以说我觉得就目前来说
我还是觉得教育它是一个有意义
有价值的这么一个行业
但是就对于我们的学生来说的话
我们会发现之前或者这几年吧
或者更早一些
会有越来越多的
学生选择 AI 的专业
我觉得
这可能要保持一定的审慎的态度
就像 Anthropic 最近出的那个报告
来说的话
我们会发现
有一些的行业可能会更早的被 AI 取代
有些会晚一些 程序员
哈哈哈
所以就是可能在选
选择这个专业方向上面
大家可能会
不要统一往一些可能高密度
又同样有高风险
被取代的一些行业去挤兑
但是
我们也要抱有乐观的这么一个心态
很有可能有一些新的专业
会在 AI 热潮之后去诞生
然后可能
什么专业 For Example
哈哈哈
就像你说的
就是怎么
就是
让人和 AI 更好的去协作
对吧
这可能说不定是商学院管理学里边
里边需要一个新的一个课题
当然也可能做 AI plus
Whatever 他们都可能形成一个新的学科
然后就是说
讲到这个
可能就是说
人和 AI 之间目前看到一个趋势
就是需要他们的协同能力
所以我觉得还是要保持
要跟学会跟 AI 去协作
这也是我们在大学教育里边一个
非常重要的一个课题
这个还挺难的
但是我刚才我要总结一下
好吧 就是我觉得
我们之前所有的教育都是在教技能
那当然也会启发思考
但是从来没有教你怎么去找意义
和定自己的目标
这个我觉得是非常的
因为很多人其实打工人嘛
反正你上班
就是为了老板给你下目标的
你回家是吧
活着就是目标
哈哈哈
这实际上如果说这个这样的
这牛马工作越来越少
然后呢
能够给你下目标的老板
都不找你了 对吧
那么你自己得形成自己的目标
而且我觉得当这个就是繁重的那些
就我们叫做
比较耗散的那些工作
就是我们叫牛马工作
就是重复性的工作
需要硬技能的工作就重复性的工作
越来越少的时候
你人很多时间就被释放出来了
那么当然
这一个释放出来的比较现实的问题
很多人可能适应不了这个
世界变化
就跟从农业社会往工业时代变
从工业时代往信息时代变
很多人就淘汰掉了
他就当一辈子农民吗
他就不学任何技能
很多人就会被淘汰掉
这是这是自然法则
所以说大家很多人
都不想自己或者是自己的下一代
当变成被淘汰掉的人
那么我觉得这个里面
你从小就开始
寻找目标和意义感
最重要的就是
我同意
家庭要给他这样的一个环境
你就折腾就好了
你哪怕你自己去学
因为其实很多我觉得欧洲这种
这种比较过得富裕
富裕生活过得很久的地方
其实这些都是这样子
你看他们好多人其实我就喜欢艺术
特别 Artist 的嘛
比如说我就喜欢创作这些东西
他所有的东西
他通过他的创作
而且现在这些创作很容易形成网络
我喜欢在这个里面
去做一些 Creative 的事情
我能够形成一个 Network
大家一块 Enjoy 这个事情
大家都得到了满足
而且 AI 最后还能帮你强化创作
做的好
其实我觉得任何人
接下来这是关于做 Creative 的事情
把 Creative 边界
把创意的边界打开之后我们会进入
到一个全新的文艺文化
新的文艺复兴的时代
进入新的文艺复兴时代
所以这个时候我们很多普通体力工作
劳动力都会减少
大家都在这个人去做新的创作
形成新的这种子网络
我觉得会是
而且这个人也会产生新的经济嘛
我并不清楚他是什么样的经济
我觉得未来可能 10 年左右
会极大的可能性往这个方向发展
Indigo 你讲得特别好
就是说我觉得意义这个东西很重要
而且你的眼光也放得特别的长远
我就再讲一点比较近期的吧
就短期来看
不得不承认一点
就是说人类得在满足温饱之后
才能寻找他们的意义
哈哈哈
所以可能就有人会问一个问题
就是说做怎么样的工作不被 AI 取代
其实这个问题不仅是 AI 有了之后
会思考这个问题
包括可能大模型
之前我就有学生加入我们组里面
他们会问
就是说我们学生培养的目标是什么
其实不管是不是 AI
我们都希望做一个
不可能被轻易取代的人
或者说我们的工作对于 AI 来说
是一个在超出它的分布的一个工作
超出它的分布
我举个例子
为什么你刚刚讲到
这个 AI 可能会很快的取代程序员
是因为我们有大量的代码
在这个 GitHub 上面
或者是公司的内部
你可以去训练这个 AI 模型
它就掌握了这一项编程的一项技能
但是如果你的工作
它是一个比较 Unique 的工作
然后 AI 它并没有办法
在你所做的这个工作上面
获得大量的数据
进行学习的话
那你被 AI 取代的可能性就会更低一点
是的然后大概率你可能会变成一个
给 AI 搞数据的人
哈哈哈 只要自己不参与进去
只要不给他喂大量的数据
这也是自己形成一个护城河的
一个方法
这为什么
之前 OpenAI 会招了很多医生去给他们标注
或者用 Biology 去标注
他们那些医学的数据
然后另外一点我想补充的就是说
我们今天可能聊了过于得乐观
好觉得 AI 能够做很多事情
能够取代了人类的一些工作
但是
因为我是做计算机的嘛
在软件工程里边
有个非常著名的九十九十法则
就是说
我们可能 90%的代码
花了 90%的时间去完成
但剩下的 10%的代码
也需要花 90%的时间去完成
我觉得目前我们看到 AI 的发展
普遍的话可能会过于的乐观
但有可能我们只在中途
剩下 10%的难度会超乎我们的想象
就是 99.9% 后面那个 0.1%
还会花掉 90%的时间
我觉得是这样的
你可以从自动驾驶的这个发展规律
可以
也可以验证到这么一个法则
挺好的我觉得这个这样才能平衡
不然我们真的没事做了
哈哈哈 对吧就 是
人永远做最后最尖端的这个事情
那我这个未来不好确定
我听上去
我们每次聊一次节目之后
未来又好又不好
都是这种结论
对吧
这种模糊的状态就是个客观的状态
对对对 那好吧
那我们正好我们是在春节前
我准备在春节前（致歉🙇）把这一期放了
那我们就当春节前（致歉🙇）的这个
这农历新年前面（录制）的最后一期
送给大家
然后作为
祝大家春节快乐
也祝大家马年快乐
好 拜拜