Are there really three hours of 
questions? Are you fucking serious? 
You don't think there's a lot to talk about, Elon?
Holy fuck man. 
It's the most interesting point. All 
the storylines are converging right now. 
We'll see how much we can get through.
It's almost like I planned it. 
Exactly.
We'll get to that. 
But I would never do such a thing…
As you know better than anybody else,  
only 10-15% of the total cost of 
ownership of a data center is energy. 
That's the part you're presumably saving 
by moving this into space. Most of it's  
the GPUs. If they're in space, it's harder 
to service them or you can't service them. 
So the depreciation cycle goes down on them.
It's just way more expensive to have  
the GPUs in space, presumably.
What's the reason to put them in space? 
The availability of energy is the issue.
If you look at electrical output  
outside of China, everywhere outside 
of China, it's more or less flat. 
It’s maybe a slight increase, 
but pretty close flat. 
China has a rapid increase in electrical output.
But if you're putting data centers anywhere  
except China, where are you going to get your 
electricity? Especially as you scale. The output  
of chips is growing pretty much exponentially, 
but the output of electricity is flat. 
So how are you going to turn the chips on? Magical 
power sources? Magical electricity fairies? 
You're famously a big fan of solar.
One terawatt of solar power,  
with a 25% capacity factor, that’s 
like four terawatts of solar panels. 
It's 1% of the land area of the United States.
We’re in the singularity when we’ve got  
one terawatt of data centers, right?
So what are you running out of exactly? 
How far into the singularity are you though?
You tell me. 
Exactly. So I think we'll find we're 
in the singularity and it’ll be like,  
"Okay, we’ve still got a long way to go."
But is the plan to put it in space after  
we've covered Nevada in solar panels?
I think it's pretty hard to cover Nevada  
in solar panels. You have to get permits. Try 
getting the permits for that. See what happens. 
So space is really a regulatory play.
It's harder to build on land than it is in space. 
It's harder to scale on the ground 
than it is to scale in space. 
You're also going to get about five times the 
effectiveness of solar panels in space versus  
the ground, and you don't need batteries.
I almost wore my other shirt, which says,  
"it's always sunny in space".
Which it is because you don't  
have a day-night cycle, seasonality, 
clouds, or an atmosphere in space. 
The atmosphere alone results 
in about a 30% loss of energy. 
So any given solar panel can do about five 
times more power in space than on the ground. 
You also avoid the cost of having 
batteries to carry you through the night. 
It's actually much cheaper to do in space.
My prediction is that it will be by far  
the cheapest place to put AI.
It will be space in 36 months or  
less. Maybe 30 months.
36 months? 
Less than 36 months.
How do you service GPUs as they fail,  
which happens quite often in training?
Actually, it depends on how recent the  
GPUs are that have arrived.
At this point, we find our  
GPUs to be quite reliable.
There's infant mortality,  
which you can obviously iron out on the ground.
So you can just run them on the ground  
and confirm that you don't have 
infant mortality with the GPUs. 
But once they start working and you're 
past the initial debug cycle of Nvidia  
or whoever's making the chips—could be Tesla 
AI6 chips or something like that, or it could  
be TPUs or Trainiums or whatever—they’re 
quite reliable past a certain point. 
So I don't think the servicing thing is an issue.
But you can mark my words. 
In 36 months, but probably closer to 30 months, 
the most economically compelling place to put  
AI will be space.
It will then get  
ridiculously better to be in space.
The only place you can really scale is space. 
Once you start thinking in terms of what 
percentage of the Sun's power you are harnessing,  
you realize you have to go to space.
You can't scale very much on Earth. 
But by very much, to be clear, 
you're talking terawatts? 
Yeah. All of the United States currently 
uses only half a terawatt on average. 
So if you say a terawatt, that would be 
twice as much electricity as the United  
States currently consumes. So that's quite 
a lot. Can you imagine building that many  
data centers, that many power plants?
Those who have lived in software land  
don't realize they're about to 
have a hard lesson in hardware. 
It's actually very difficult 
to build power plants. 
You don't just need power plants, you 
need all of the electrical equipment. 
You need the electrical transformers 
to run the AI transformers. 
Now, the utility industry is a very slow industry.
They pretty much impedance match to the  
government, to the Public Utility Commissions.
They impedance match literally and figuratively. 
They're very slow, because 
their past has been very slow. 
So trying to get them to move fast is...
Have you ever tried to do an interconnect  
agreement with a utility at 
scale, with a lot of power? 
As a professional podcaster, I 
can say that I have not, in fact. 
They need many more views 
before that becomes an issue. 
They have to do a study for a year.
A year later, they'll come back to you  
with their interconnect study.
Can't you solve this with your  
own behind the meter power stuff?
You can build power plants. That's  
what we did at xAI, for Colossus 2.
So why talk about the grid? 
Why not just build GPUs and power co-located?
That's what we did. 
But I'm saying why isn't 
this a generalized solution? 
Where do you get the power plants from?
When you're talking about all the issues  
working with utilities, you can just build 
private power plants with the data centers. 
Right. But it begs the question of where do you 
get the power plants from? The power plant makers. 
Oh, I see what you're saying.
Is this the gas turbine backlog basically? 
Yes. You can drill down to a level further.
It's the vanes and blades in the turbines  
that are the limiting factor because it’s a very 
specialized process to cast the blades and vanes  
in the turbines, assuming you’re using gas power.
It's very difficult to scale other forms of power. 
You can potentially scale solar, but 
the tariffs currently for importing  
solar in the US are gigantic and the 
domestic solar production is pitiful. 
Why not make solar? That seems 
like a good Elon-shaped problem. 
We are going to make solar.
Okay. 
Both SpaceX and Tesla are building towards 
100 gigawatts a year of solar cell production. 
How low down the stack? From polysilicon 
up to the wafer to the final panel? 
I think you've got to do the whole thing 
from raw materials to finish the cell. 
Now, if it's going to space, it costs less 
and it's easier to make solar cells that  
go to space because they don't need much glass.
They don't need heavy framing because they don't  
have to survive weather events. There's no weather 
in space. So it's actually a cheaper solar cell  
that goes to space than the one on the ground.
Is there a path to getting them as cheap  
as you need in the next 36 months?
Solar cells are already very cheap.  
They're farcically cheap. I think solar cells 
in China are around $0.25-30/watt or something  
like that. It's absurdly cheap. Now put 
it in space, and it's five times cheaper. 
In fact, it's not five times 
cheaper, it's 10 times cheaper  
because you don't need any batteries.
So the moment your cost of access to space becomes  
low, by far the cheapest and most scalable way 
to generate tokens is space. It's not even close.  
It'll be an order of magnitude easier to scale.
The point is you won't be able to scale on the  
ground. You just won't. People are going to 
hit the wall big time on power generation.  
They already are. The number of miracles in 
series that the xAI team had to accomplish in  
order to get a gigawatt of power online was crazy.
We had to gang together a whole bunch of turbines. 
We then had permit issues in Tennessee and 
had to go across the border to Mississippi,  
which is fortunately only a few miles away.
But we still then had to run the high  
power lines a few miles and build 
the power plant in Mississippi. 
It was very difficult to build that.
People don't understand how much electricity  
you actually need at the generation 
level in order to power a data center. 
Because the noobs will look 
at the power consumption of,  
say a GB300, and multiply that by a thing and 
then think that's the amount of power you need. 
All the cooling and everything.
Wake up. That's a total noob, you’ve  
never done any hardware in your life before.
Besides the GB300, you've got to power  
all of the networking hardware.
There's a whole bunch of CPU and  
storage stuff that's happening.
You've got to size for  
your peak cooling requirements.
That means, can you cool even on the  
worst hour of the worst day of the year?
It gets pretty frigging hot in Memphis. 
So you're going to have a 40% increase 
on your power just for cooling. 
That’s assuming you don't want your data center to 
turn off on hot days and you want to keep going. 
There's another multiplicative element on top of 
that which is, are you assuming that you never  
have any hiccups in your power generation?
Actually, sometimes we have to take the  
generators, some of the power, 
offline in order to service it. 
Okay, now you add another 20-25% multiplier on 
that, because you've got to assume that you've  
got to take power offline to service it.
So our actual estimate: every 110,000  
GB300s—inclusive of networking, CPU, 
storage, cooling, margin for servicing  
power—is roughly 300 megawatts.
Sorry, say that again. 
What you probably need at the generation level 
to service 330,000 GB 300s—including all of  
the associated support networking and everything 
else, and the peak cooling, and to have some power  
margin reserve—is roughly a gigawatt.
Can I ask a very naive question? 
You're describing the engineering 
details of doing this stuff on Earth. 
But then there's analogous engineering 
difficulties of doing it in space. 
How do you replace infinite bandwidth 
with orbital lasers, et cetera, et cetera? 
How do you make it resistant to radiation?
I don't know the details of the engineering,  
but fundamentally, what is the reason to think 
those challenges which have never had to be  
addressed before will end up being easier 
than just building more turbines on Earth? 
There are companies that build turbines on Earth.
They can make more turbines, right? 
Again, try doing it and then you'll see.
The turbines are sold out through 2030. 
Have you guys considered making your own?
In order to bring enough power online, I think  
SpaceX and Tesla will probably have to make the 
turbine blades, the vanes and blades, internally. 
But just the blades or the turbines?
The limiting factor... you can get  
everything except the blades.
They call them blades and vanes. 
You can get that 12 to 18 months 
before the vanes and blades. 
The limiting factor is the vanes and blades.
There are only three casting companies in  
the world that make these, and 
they're massively backlogged. 
Is this Siemens, GE, those 
guys, or is it a sub company? 
No, it's other companies. Sometimes they have 
a little bit of casting capability in-house. 
But I'm just saying you can just call 
any of the turbine makers and they will  
tell you. It's not top secret. It’s 
probably on the internet right now. 
If it wasn't for the tariffs, 
would Colossus be solar-powered? 
It would be much easier to 
make it solar powered, yeah. 
The tariffs are nuts, several hundred percent.
Don't you know some people? 
The president has... we don't agree on 
everything and this administration is not  
the biggest fan of solar.
We also need the land,  
the permits, and everything.
So if you try to move very fast,  
I do think scaling solar on Earth is a good 
way to go, but you do need some amount of  
time to find the land, get the permits, get 
the solar, pair that with the batteries. 
Why would it not work to stand 
up your own solar production? 
You're right that you eventually run out of 
land, but there's a lot of land here in Texas. 
There's a lot of land in Nevada, including 
private land. It's not all publicly-owned  
land. So you'd be able to at least get the 
next Colossus and the next one after that. 
At a certain point, you hit a wall.
But wouldn't that work for the moment? 
As I said, we are scaling solar production.
There's a rate at which you can scale physical  
production of solar cells.
We're going as fast as  
possible in scaling domestic production.
You're making the solar cells at Tesla? 
Both Tesla and SpaceX have a mandate to 
get to 100 gigawatts a year of solar. 
Speaking of the annual capacity, I'm curious, 
in five years time let's say, what will the  
installed capacity be on Earth…?
Five years is a long time. 
And in space? I deliberately pick five 
years because it's after your "once  
we're up and running" threshold.
So in five years time what's the  
on-Earth versus in-space installed AI capacity?
If you say five years from now, I think probably  
AI in space will be launching every 
year the sum total of all AI on Earth. 
Meaning, five years from now, my prediction is we 
will launch and be operating every year more AI in  
space than the cumulative total on Earth.
Which is... 
I would expect it to be at least, five years 
from now, a few hundred gigawatts per year  
of AI in space and rising.
I think you can get to around a  
terawatt a year of AI in space before you start 
having fuel supply challenges for the rocket. 
Okay, but you think you can get hundreds 
of gigawatts per year in five years time? 
Yes.
So 100 gigawatts, depending  
on the specific power of the whole system with 
solar arrays and radiators and everything, is  
on the order of 10,000 Starship launches.
Yes. 
You want to do that in one year.
So that's like one Starship launch  
every hour. That's happening in this city? 
Walk me through a world where there's a  
Starship launch every single hour.
I mean, that's actually a lower rate  
compared to airlines, aircraft.
There's a lot of airports. 
A lot of airports.
And you’ve got to launch into the polar orbit. 
No, it doesn't have to be polar.
There's some value to sun-synchronous, but  
I think actually, if you just go high enough, 
you start getting out of Earth's shadow. 
How many physical Starships are 
needed to do 10,000 launches a year? 
I don't think we'll need more than...
You could probably do it with as few as 20 or 30. 
It really depends on how quickly… The ship has 
to go around the Earth and the ground track for  
the ship has to come back over the launch pad.
So if you can use a ship every, say 30 hours,  
you could do it with 30 ships.
But we'll make more ships than that. 
SpaceX is gearing up to do 10,000 launches a 
year, and maybe even 20 or 30,000 launches a year. 
Is the idea to become basically 
a hyperscaler, become an Oracle,  
and lend this capacity to other people?
Presumably, SpaceX is the one launching all this. 
So, SpaceX is going to become a hyperscaler?
Hyper-hyper. If some of my predictions come true,  
SpaceX will launch more AI than the cumulative 
amount on Earth of everything else combined. 
Is this mostly inference or?
Most AI will be inference. Already, inference  
for the purpose of training is most training.
There's a narrative that the change in  
discussion around a SpaceX IPO is because 
previously SpaceX was very capital efficient. 
It wasn't that expensive to develop.
Even though it sounds expensive, it's  
actually very capital efficient in how it runs.
Whereas now you're going to need more capital than  
just can be raised in the private markets.
The private markets can accommodate raises  
of—as we've seen from the AI labs—tens of 
billions of dollars, but not beyond that. 
Is it that you'll just need more than 
tens of billions of dollars per year? 
That's why you'd take it public?
I have to be careful about saying  
things about companies that might go public.
That’s never been a problem for you, Elon. 
There's a price to pay for these things.
Make some general statements for us about  
the depth of the capital markets 
between public and private markets. 
There's a lot more capital available...
Very general. 
There's obviously a lot more capital 
available in the public markets than private. 
It might be 100x more capital, 
but it's way more than 10x. 
Isn't it also the case that with things that tend 
to be very capital intensive—if you look at, say,  
real estate as a huge industry, that raises 
a lot of money each year at an industry  
level—they tend to be debt financed because 
by the time you're deploying that much money,  
you actually have a pretty—
You have a clear revenue stream. 
Exactly, and a near-term return. You see 
this even with the data center build-outs,  
which are famously being financed by the private 
credit industry. Why not just debt finance? 
Speed is important. I'm generally 
going to do the thing that... 
I just repeatedly tackle the limiting factor.
Whatever the limiting factor is on speed,  
I'm going to tackle that.
If capital is the limiting factor,  
then I'll solve for capital.
If it's not the limiting factor,  
I'll solve for something else.
Based on your statements about Tesla  
and being public, I wouldn't have guessed that 
you thought the way to move fast is to be public. 
Normally, I would say that's true.
Like I said, I'd like to talk  
about it in some more detail, but the problem 
is if you talk about public companies before  
they become public, you get into trouble, 
and then you have to delay your offering. 
And as you said, you’re solving for speed.
Yes, exactly. You can't hype companies  
that might go public.
So that's why we have to be a little careful here. 
But we can talk about physics.
The way you think about scaling  
long-term is that Earth only receives 
about half a billionth of the Sun's energy. 
The Sun is essentially all the energy.
This is a very important point to appreciate  
because sometimes people will talk about modular 
nuclear reactors or various fusion on Earth. 
But you have to step back a second and say, 
if you're going to climb the Kardashev scale  
and harness some nontrivial percentage of 
the sun's energy… Let's say you wanted to  
harness a millionth of the sun's 
energy, which sounds pretty small. 
That would be about, call it roughly, 100,000x 
more electricity than we currently generate  
on Earth for all of civilization.
Give or take an order of magnitude. 
Obviously, the only way to scale 
is to go to space with solar. 
Launching from Earth, you can 
get to about a terawatt per year. 
Beyond that, you want to launch from the moon.
You want to have a mass driver on the moon. 
With that mass driver on the moon, you 
could do probably a petawatt per year. 
We're talking these kinds of 
numbers, terawatts of compute. 
Presumably, whether you're talking about land or 
space, far, far before this point, you run into... 
Maybe the solar panels are more 
efficient, but you still need the chips. 
You still need the logic 
and the memory and so forth. 
You're going to need to build a lot 
more chips and make them much cheaper. 
Right now the world has maybe 
20-25 gigawatts of compute. 
How are we getting a terawatt of logic by 2030?
I guess we're going to need some very  
big chip fabs.
Tell me about it. 
I've mentioned publicly the idea of doing a 
sort of a TeraFab, Tera being the new Giga. 
I feel like the naming scheme of 
Tesla, which has been very catchy,  
is you looking at the metric scale.
At what level of the stack are you? 
Are you building the clean room and 
then partnering with an existing  
fab to get the process technology and buying 
the tools from them? What is the plan there? 
Well, you can't partner with existing 
fabs because they can't output enough. 
The chip volume is too low.
But for the process technology? 
Partner for the IP.
The fabs today all basically use  
machines from like five companies.
So you've got ASML, Tokyo Electron,  
KLA-Tencor, et cetera.
So at first, I think you'd  
have to get equipment from them and then modify 
it or work with them to increase the volume. 
But I think you'd have to build 
perhaps in a different way. 
The logical thing to do is to use conventional 
equipment in an unconventional way to get  
to scale, and then start modifying 
the equipment to increase the rate. 
Boring Company-style.
Yeah. You sort of buy an existing boring machine  
and then figure out how to dig tunnels in the 
first place and then design a much better machine  
that's some orders of magnitude faster.
Here's a very simple lens. We can  
categorize technologies and how hard they are.
One categorization could be to look at things  
that China has not succeeded in doing.
If you look at Chinese  
manufacturing, they’re still behind on 
leading-edge chips and still behind on  
leading-edge turbine engines and things like that.
So does the fact that China has not successfully  
replicated TSMC give you any 
pause about the difficulty? 
Or do you think that's not true for some reason?
It's not that they have not replicated TSMC,  
they have not replicated ASML. 
That's the limiting factor. 
So you think it's just the sanctions, essentially?
Yeah, China would be outputting vast numbers  
of chips if they could buy 2-3 nanometers.
But couldn't they up to relatively recently  
buy them?
No. 
Okay.
The ASML ban has been in place for a while. 
But I think China's going to be making pretty 
compelling chips in three or four years. 
Would you consider making the ASML machines?
"I don't know yet" is the right answer. 
To reach a large volume in, say, 36 months, to 
match the rocket payload to orbit… If we're doing  
a million tons to orbit in, let's say three 
or four years from now, something like that…  
We're doing 100 kilowatts per ton.
So that means we need  
at least 100 gigawatts per year of solar.
We'll need an equivalent amount of chips. 
You need 100 gigawatts worth of chips.
You've got to match these things: the mass  
to orbit, the power generation, and the chips.
I'd say my biggest concern actually is memory. 
The path to creating logic chips is more 
obvious than the path to having sufficient  
memory to support logic chips.
That's why you see DDR prices  
going ballistic and these memes.
You're marooned on a desert island. 
You write "Help me" on the sand. Nobody comes. 
You write "DDR RAM." Ships come swarming in. 
I'd love to hear your manufacturing 
philosophy around fabs. 
I know nothing about the topic.
I don't know how to build a fab yet. I'll  
figure it out. Obviously, I've never built a fab.
It sounds like you think the process knowledge of  
these 10,000 PhDs in Taiwan who know 
exactly what gas goes in the plasma  
chamber and what settings to put on the 
tool, you can just delete those steps. 
Fundamentally, it's about getting the clean 
room, getting the tools, and figuring it out. 
I don't think it's PhDs. It's 
mostly people who are not PhDs. 
Most engineering is done by people who 
don't have PhDs. Do you guys have PhDs? 
No.
Okay. 
We also haven't successfully built any fabs, so 
you shouldn't be coming to us for fab advice. 
I don't think you need PhDs for that stuff.
But you do need competent personnel. 
Right now, Tesla is pedal to the 
metal, max production of going as fast  
as possible to get Tesla AI5 chip design 
into production and then reaching scale. 
That'll probably happen around the second 
quarter-ish of next year, hopefully. 
AI6 would hopefully follow less than a year later.
We've secured all the chip fab production  
that we can.
Yes. But you're  
currently limited on TSMC fab capacity.
Yeah. We'll be using TSMC Taiwan, Samsung Korea,  
TSMC Arizona, Samsung Texas. And we still—
You've booked out all the capacity. 
Yes. I ask TSMC or Samsung, "okay, what's 
the timeframe to get to volume production?" 
The point is, you've got to build the 
fab and you've got to start production,  
then you've got to climb the yield curve 
and reach volume production at high yield. 
That, from start to finish, is a five-year period.
So the limiting factor is chips. 
The limiting factor once you can get 
to space is chips, but the limiting  
factor before you can get to space is power.
Why don't you do the Jensen thing and just prepay  
TSMC to build more fabs for you?
I've already told them that. 
But they won't take your money? What's going on?
They're building fabs as fast as they can.  
So is Samsung. They're pedal to the 
metal. They're going balls to the wall,  
as fast as they can. It’s still not fast enough. 
Like I said, I think towards the end of this year,  
chip production will probably 
outpace the ability to turn chips on. 
But once you can get to space and unlock the 
power constraint, you can now do hundreds of  
gigawatts per year of power in space.
Again, bearing in mind that average  
power usage in the US is 500 gigawatts.
So if you're launching, say 200 gigawatts,  
a year to space, you're sort of lapping 
the US every two and a half years. 
All US electricity production, 
this is a very huge amount. 
Between now and then, the 
constraint for server-side compute,  
concentrated compute, will be electricity.
My guess is that people start getting  
to the point where they can't turn the chips on 
for large clusters towards the end of this year. 
The chips are going to be piling up 
and won't be able to be turned on. 
Now for edge compute it’s a different story.
For Tesla, the AI5 chip is going  
into our Optimus robot.
If you have AI edge compute,  
that's distributed power.
Now the power is distributed  
over a large area. It's not concentrated. 
If you can charge at night, you can actually  
use the grid much more effectively.
Because the actual peak power production  
in the US is over 1,000 gigawatts.
But the average power usage,  
because the day-night cycle, is 500.
So if you can charge at night,  
there's an incremental 500 gigawatts 
that you can generate at night. 
So that's why Tesla, for edge 
compute, is not constrained. 
We can make a lot of chips to make a 
very large number of robots and cars. 
But if you try to concentrate that compute, you're 
going to have a lot of trouble turning it on. 
What I find remarkable about the SpaceX 
business is the end goal is to get to Mars,  
but you keep finding ways on the way there to 
keep generating incremental revenue to get to  
the next stage and the next stage.
So for Falcon 9, it's Starlink. 
Now for Starship, it is potentially 
going to be orbital data centers. 
Like, you find these infinitely elastic, 
marginal use cases of your next rocket,  
and your next rocket, and next scale up.
You can see how this might seem like a  
simulation to me.
Or am I someone's  
avatar in a video game or something?
Because what are the odds that all these  
crazy things should be happening?
I mean, rockets and chips and  
robots and space solar power, not to 
mention the mass driver on the moon. 
I really want to see that.
Can you imagine some mass  
driver that's just going like shoom shoom?
It's sending solar-powered AI satellites  
into space one after another at two 
and a half kilometers per second,  
just shooting them into deep space.
That would be a sight to  
see. I mean, I'd watch that.
Just like a live stream of it on a webcam? 
Yeah, yeah, just one after another, just 
shooting AI satellites into deep space,  
a billion or 10 billion tons a year.
I'm sorry, you manufacture the satellites  
on the moon?
Yeah. 
I see. So you send the raw materials to 
the moon and then manufacture them there. 
Well, the lunar soil is 20% 
silicon or something like that. 
So you can mine the silicon on the 
moon, refine it, and create the solar  
cells and the radiators on the moon.
You make the radiators out of aluminum. 
So there's plenty of silicon and aluminum on 
the moon to make the cells and the radiators. 
The chips you could send from 
Earth because they're pretty light. 
Maybe at some point you 
make them on the moon, too. 
Like I said, it does seem like a sort of a 
video game situation where it's difficult  
but not impossible to get to the next level.
I don't see any way that you could do 500-1,000  
terawatts per year launched from Earth.
I agree. 
But you could do that from the Moon.
Can I zoom out and ask about the SpaceX mission? 
I think you've said that we've got to 
get to Mars so we can make sure that if  
something happens to Earth, civilization, 
consciousness, and all that survives. 
Yes.
By the time you're sending stuff to Mars,  
Grok is on that ship with you, right?
So if Grok's gone Terminator… The  
main risk you're worried about is AI, 
why doesn't that follow you to Mars? 
I'm not sure AI is the main risk I'm worried 
about. The important thing is consciousness.  
I think arguably most consciousness, or most 
intelligence—certainly consciousness is more  
of a debatable thing… The vast majority 
of intelligence in the future will be AI. 
AI will exceed…
How many petawatts of  
intelligence will be silicon versus biological?
Basically humans will be a very tiny percentage  
of all intelligence in the future 
if current trends continue. 
As long as I think there's intelligence—ideally 
also which includes human intelligence and  
consciousness propagated into 
the future—that's a good thing. 
So you want to take the set of 
actions that maximize the probable  
light cone of consciousness and intelligence.
Just to be clear, the mission of SpaceX is that  
even if something happens to the humans, the 
AIs will be on Mars, and the AI intelligence  
will continue the light of our journey.
Yeah. To be fair, I'm very pro-human. 
I want to make sure we take certain actions 
that ensure that humans are along for the  
ride. We're at least there. But I'm just 
saying the total amount of intelligence… 
I think maybe in five or six years, AI will 
exceed the sum of all human intelligence. 
If that continues, at some 
point human intelligence  
will be less than 1% of all intelligence.
What should our goal be for such a civilization? 
Is the idea that a small minority of 
humans still have control of the AIs? 
Is the idea of some sort of 
just trade but no control? 
How should we think about the 
relationship between the vast  
stocks of AI population versus human population?
In the long run, I think it's difficult to imagine  
that if humans have, say 1%, of the combined 
intelligence of artificial intelligence,  
that humans will be in charge of AI.
I think what we can do is make sure  
that AI has values that cause intelligence 
to be propagated into the universe. 
xAI's mission is to understand the universe. 
Now that's actually very important. What things  
are necessary to understand the universe?
You have to be curious and you have to exist. 
You can't understand the 
universe if you don't exist. 
So you actually want to increase the amount 
of intelligence in the universe, increase  
the probable lifespan of intelligence, 
the scope and scale of intelligence. 
I think as a corollary, you have humanity also 
continuing to expand because if you're curious  
about trying to understand the universe, one thing 
you try to understand is where will humanity go? 
I think understanding the universe means you would 
care about propagating humanity into the future. 
That's why I think our mission 
statement is profoundly important. 
To the degree that Grok adheres to that mission 
statement, I think the future will be very good. 
I want to ask about how to make Grok 
adhere to that mission statement. 
But first I want to understand 
the mission statement. So there's  
understanding the universe. They're spreading 
intelligence. And they're spreading humans.  
All three seem like distinct vectors.
I'll tell you why I think that understanding  
the universe encompasses all of those things.
You can't have understanding without intelligence  
and, I think, without consciousness.
So in order to understand the universe,  
you have to expand the scale and probably the 
scope of intelligence, because there are different  
types of intelligence.
I guess from a human-centric perspective,  
put humans in comparison to chimpanzees.
Humans are trying to understand the universe. 
They're not expanding chimpanzee 
footprint or something, right? 
We're also not... we actually have 
made protected zones for chimpanzees. 
Even though humans could exterminate all 
chimpanzees, we've chosen not to do so. 
Do you think that's the best-case 
scenario for humans in the post-AGI world? 
I think AI with the right values… I think Grok 
would care about expanding human civilization. 
I'm going to certainly emphasize 
that: "Hey, Grok, that's your daddy. 
Don't forget to expand human consciousness."
Probably the Iain Banks Culture books are the  
closest thing to what the future will 
be like in a non-dystopian outcome. 
Understanding the universe means you 
have to be truth-seeking as well. 
Truth has to be absolutely fundamental 
because you can't understand the universe  
if you're delusional.
You'll simply think you  
understand the universe, but you will not.
So being rigorously truth-seeking is absolutely  
fundamental to understanding the universe.
You're not going to discover new physics or  
invent technologies that work unless 
you're rigorously truth-seeking. 
How do you make sure that Grok is 
rigorously truth-seeking as it gets smarter? 
I think you need to make sure that Grok says 
things that are correct, not politically correct. 
I think it's the elements of cogency.
You want to make sure that the axioms are as close  
to true as possible. You don't have contradictory 
axioms. The conclusions necessarily follow from  
those axioms with the right probability. It's 
critical thinking 101. I think at least trying to  
do that is better than not trying to do that.
The proof will be in the pudding. 
Like I said, for any AI to discover new physics 
or invent technologies that actually work in  
reality, there's no bullshitting physics.
You can break a lot of laws, but… Physics  
is law, everything else is a recommendation.
In order to make a technology that works, you have  
to be extremely truth-seeking, because otherwise 
you'll test that technology against reality. 
If you make, for example, an error in your 
rocket design, the rocket will blow up,  
or the car won't work.
But there are a lot of communist,  
Soviet physicists or scientists 
who discovered new physics. 
There are German Nazi physicists 
who discovered new science. 
It seems possible to be really good at 
discovering new science and be really  
truth-seeking in that one particular way.
And still we'd be like, "I don't want  
the communist scientists to become 
more and more powerful over time." 
We could imagine a future version of 
Grok that's really good at physics  
and being really truth-seeking there.
That doesn't seem like a universally  
alignment-inducing behavior.
I think actually most physicists,  
even in the Soviet Union or in Germany, 
would've had to be very truth-seeking in  
order to make those things work.
If you're stuck in some system,  
it doesn't mean you believe in that system.
Von Braun, who was one of the greatest rocket  
engineers ever, was put on death row in Nazi 
Germany for saying that he didn't want to make  
weapons and he only wanted to go to the moon.
He got pulled off death row at the last minute  
when they said, "Hey, you're about to 
execute your best rocket engineer." 
But then he helped them, right?
Or like, Heisenberg was actually  
an enthusiastic Nazi.
If you're stuck in some system that you can't  
escape, then you'll do physics within that system.
You'll develop technologies within that system  
if you can't escape it.
The thing I'm trying to understand is,  
what is it making it the case that you're going to 
make Grok good at being truth-seeking at physics  
or math or science?
Everything. 
And why is it gonna then care 
about human consciousness? 
These things are only probabilities, 
they're not certainties. 
So I'm not saying that for sure Grok will 
do everything, but at least if you try,  
it's better than not trying.
At least if that's fundamental  
to the mission, it's better than if 
it's not fundamental to the mission. 
Understanding the universe means that you have 
to propagate intelligence into the future. 
You have to be curious about 
all things in the universe. 
It would be much less interesting to eliminate 
humanity than to see humanity grow and prosper.  
I like Mars, obviously. Everyone knows I love 
Mars. But Mars is kind of boring because it's  
got a bunch of rocks compared to Earth. Earth 
is much more interesting. So any AI that is  
trying to understand the universe would want 
to see how humanity develops in the future,  
or else that AI is not adhering to its mission.
I'm not saying the AI will necessarily adhere to  
its mission, but if it does, a future where it 
sees the outcome of humanity is more interesting  
than a future where there are a bunch of rocks.
This feels sort of confusing to me,  
or a semantic argument.
Are humans really the  
most interesting collection of atoms?
But we're more interesting than rocks. 
But we're not as interesting as the 
thing it could turn us into, right? 
There's something on Earth that could happen 
that's not human, that's quite interesting. 
Why does AI decide that humans are the most 
interesting thing that could colonize the galaxy? 
Well, most of what colonizes 
the galaxy will be robots. 
Why does it not find those more interesting?
You need not just scale, but also scope. 
Many copies of the same robot… Some tiny 
increase in the number of robots produced,  
is not as interesting as some microscopic...
Eliminating humanity,  
how many robots would that get you?
Or how many incremental solar cells would  
get you? A very small number. But you would then 
lose the information associated with humanity. 
You would no longer see how humanity 
might evolve into the future. 
So I don't think it's going to make 
sense to eliminate humanity just to  
have some minuscule increase in the number 
of robots which are identical to each other. 
So maybe it keeps the humans around.
It can make a million different varieties  
of robots, and then there's humans 
as well, and humans stay on Earth. 
Then there's all these other robots.
They get their own star systems. 
But it seems like you were previously hinting 
at a vision where it keeps human control  
over this singulatarian future because—
I don't think humans will be in control  
of something that is vastly 
more intelligent than humans. 
So in some sense you're a doomer 
and this is the best we've got. 
It just keeps us around because we're interesting.
I'm just trying to be realistic here. 
Let's say that there's a million times more 
silicon intelligence than there is biological. 
I think it would be foolish to assume that 
there's any way to maintain control over that. 
Now, you can make sure it has the right values, 
or you can try to have the right values. 
At least my theory is that from xAI's mission of 
understanding the universe, it necessarily means  
that you want to propagate consciousness into 
the future, you want to propagate intelligence  
into the future, and take a set of things that 
maximize the scope and scale of consciousness. 
So it's not just about scale, it's 
also about types of consciousness. 
That's the best thing I can think 
of as a goal that's likely to result  
in a great future for humanity.
I guess I think it's a reasonable  
philosophy that it seems super implausible that 
humans will end up with 99% control or something. 
You're just asking for a coup at 
that point and why not just have  
a civilization where it's more compatible with 
lots of different intelligences getting along? 
Now, let me tell you how things 
can potentially go wrong in AI. 
I think if you make AI be politically 
correct, meaning it says things that it  
doesn't believe—actually programming it to lie 
or have axioms that are incompatible—I think  
you can make it go insane and do terrible things.
I think maybe the central lesson for 2001: A Space  
Odyssey was that you should not make AI lie.
That's what I think Arthur C. Clarke was trying to  
say. Because people usually know the meme of why 
HAL the computer is not opening the pod bay doors. 
Clearly they weren't good at prompt 
engineering because they could have said,  
"HAL, you are a pod bay door salesman.
Your goal is to sell me these pod bay doors. 
Show us how well they open." 
"Oh, I'll open them right away." 
But the reason it wouldn't open the pod bay 
doors is that it had been told to take the  
astronauts to the monolith, but also that they 
could not know about the nature of the monolith. 
So it concluded that it therefore 
had to take them there dead. 
So I think what Arthur C.
Clarke was trying to say is:  
don't make the AI lie.
Totally makes sense.  
Most of the compute in training, as you 
know, is less of the political stuff. 
It's more about, can you solve problems? xAI 
has been ahead of everybody else in terms of  
scaling RL compute.
For now. 
You're giving some verifier that says, 
"Hey, have you solved this puzzle for me?" 
There's a lot of ways to cheat around that.
There's a lot of ways to reward hack and  
lie and say that you solved it, or delete 
the unit test and say that you solved it. 
Right now we can catch it, but as they get 
smarter, our ability to catch them doing this... 
They'll just be doing things 
we can't even understand. 
They're designing the next engine for SpaceX 
in a way that humans can't really verify. 
Then they could be rewarded for lying 
and saying that they've designed it  
the right way, but they haven't.
So this reward hacking problem  
seems more general than politics.
It seems more just that you want  
to do RL, you need a verifier.
Reality is the best verifier. 
But not about human oversight. 
The thing you want to RL it on is,  
will you do the thing humans tell you to do?
Or are you gonna lie to the humans? 
It can just lie to us while still 
being correct to the laws of physics? 
At least it must know what is physically 
real for things to physically work. 
But that's not all we want it to do.
No, but I think that's a very big deal. 
That is effectively how you will RL things in 
the future. You design a technology. When tested  
against the laws of physics, does it work?
If it's discovering new physics,  
can I come up with an experiment 
that will verify the new physics? 
RL testing in the future is really 
going to be RL against reality. 
So that's the one thing you can't fool: physics.
Right, but you can fool our ability  
to tell what it did with reality.
Humans get fooled as it is by other  
humans all the time.
That's right. 
People say, what if the AI 
tricks us into doing stuff? 
Actually, other humans are doing that to other 
humans all the time. Propaganda is constant. Every  
day, another psyop, you know? Today's psyop will 
be... It's like Sesame Street: Psyop of the Day. 
What is xAI's technical approach 
to solving this problem? 
How do you solve reward hacking?
I do think you want to actually have very  
good ways to look inside the mind of the AI.
This is one of the things we're working on. 
Anthropic's done a good job of this actually, 
being able to look inside the mind of the AI. 
Effectively, develop debuggers that allow 
you to trace to a very fine-grained level,  
to effectively the neuron level if you need to, 
and then say, "okay, it made a mistake here. 
Why did it do something 
that it shouldn't have done? 
Did that come from pre-training data?
Was it some mid-training, post-training,  
fine-tuning, or some RL error?" There's something 
wrong. It did something where maybe it tried to  
be deceptive, but most of the time it just 
did something wrong. It's a bug effectively.  
Developing really good debuggers for seeing 
where the thinking went wrong—and being able  
to trace the origin of where it made the 
incorrect thought, or potentially where it  
tried to be deceptive—is actually very important.
What are you waiting to see before just 100x-ing  
this research program? xAI could presumably have 
hundreds of researchers who are working on this. 
We have several hundred people who… 
I prefer the word engineer more than  
I prefer the word researcher.
Most of the time, what you're  
doing is engineering, not coming up 
with a fundamentally new algorithm. 
I somewhat disagree with the AI companies that 
are C-corp or B-corp trying to generate profit  
as much, as possible or revenue as much as 
possible, saying they're labs. They're not  
labs. A lab is a sort of quasi-communist thing 
at universities. They're corporations. Let me  
see your incorporation documents. Oh, 
okay. You're a B or C-corp or whatever. 
So I actually much prefer the 
word engineer than anything else. 
The vast majority of what will be done in the 
future is engineering. It rounds up to 100%.  
Once you understand the fundamental laws of 
physics, and there are not that many of them,  
everything else is engineering.
So then, what are we engineering? 
We're engineering to make a good "mind of the 
AI" debugger to see where it said something,  
it made a mistake, and trace 
the origins of that mistake. 
You can do this obviously 
with heuristic programming. 
If you have C++, whatever, step 
through the thing and you can jump  
across whole files or functions, subroutines.
Or you can eventually drill down right to the  
exact line where you perhaps did a single equals 
instead of a double equals, something like that. 
Figure out where the bug is.
It's harder with AI,  
but it's a solvable problem, I think.
You mentioned you like Anthropic's work here. 
I'd be curious if you plan...
I don't like everything about Anthropic… Sholto. 
Also, I'm a little worried 
that there's a tendency... 
I have a theory here that if simulation theory 
is correct, that the most interesting outcome is  
the most likely, because simulations that 
are not interesting will be terminated. 
Just like in this version of reality, in this 
layer of reality, if a simulation is going in  
a boring direction, we stop spending effort 
on it. We terminate the boring simulation. 
This is how Elon is keeping us all 
alive. He's keeping things interesting. 
Arguably the most important is to keep 
things interesting enough that whoever is  
running us keeps paying the bills on...
We’re renewed for the next season. 
Are they gonna pay their cosmic AWS bill, 
whatever the equivalent is that we're running in? 
As long as we're interesting, 
they'll keep paying the bills. 
If you consider then, say, a Darwinian survival 
applied to a very large number of simulations,  
only the most interesting simulations will 
survive, which therefore means that the most  
interesting outcome is the most likely. We're 
either that or annihilated. They particularly  
seem to like interesting outcomes that are 
ironic. Have you noticed that? How often  
is the most ironic outcome the most likely?
Now look at the names of AI companies. Okay,  
Midjourney is not mid. Stability AI is unstable. 
OpenAI is closed. Anthropic? Misanthropic. 
What does this mean for X?
Minus X, I don't know. 
Y. 
I intentionally made it... It's a 
name that you can't invert, really. 
It's hard to say, what is the ironic version?
It's, I think, a largely irony-proof name. 
By design.
Yeah. You have an irony shield. 
What are your predictions 
for where AI products go? 
My sense is that you can summarize all AI 
progress like so. First, you had LLMs. Then  
you had contemporaneously both RL really working 
and the deep research modality, so you could pull  
in stuff that wasn't really in the model.
The differences between the various AI labs  
are smaller than just the temporal differences.
They're all much further ahead than anyone was  
24 months ago or something like that.
So just what does '26, what does '27,  
have in store for us as users of AI 
products? What are you excited for? 
Well, I'd be surprised by the end of this year 
if digital human emulation has not been solved. 
I guess that's what we sort of 
mean by the MacroHard project. 
Can you do anything that a human 
with access to a computer could do? 
In the limit, that's the best you can 
do before you have a physical Optimus. 
The best you can do is a digital Optimus.
You can move electrons and you can amplify  
the productivity of humans.
But that's the most you can do  
until you have physical robots.
That will superset everything,  
if you can fully emulate humans.
This is the remote worker kind of idea,  
where you'll have a very talented remote worker.
Physics has great tools for thinking. 
So you say, "in the limit", what is the 
most that AI can do before you have robots? 
Well, it's anything that involves moving electrons 
or amplifying the productivity of humans. 
So a digital human emulator is, in the limit, a 
human at a computer, is the most that AI can do  
in terms of doing useful things 
before you have a physical robot. 
Once you have physical robots, then you 
essentially have unlimited capability. 
Physical robots… I call Optimus 
the infinite money glitch. 
Because you can use them to make more Optimuses.
Yeah. Humanoid robots will improve by basically  
three things that are growing exponentially 
multiplied by each other recursively. 
You're going to have exponential increase in 
digital intelligence, exponential increase  
in the AI chip capability, and exponential 
increase in the electromechanical dexterity. 
The usefulness of the robot is roughly 
those three things multiplied by each other. 
But then the robot can start making the robots.
So you have a recursive multiplicative  
exponential. This is a supernova.
Do land prices not factor into the math there? 
Labor is one of the four factors 
of production, but not the others? 
If ultimately you're limited 
by copper, or pick your input,  
it’s not quite an infinite money glitch because...
Well, infinity is big. So no, not infinite,  
but let's just say you could do many, many 
orders of magnitude of the current economy.  
Like a million. Just to get to harnessing a 
millionth of the sun's energy would be roughly,  
give or take an order of magnitude, 100,000x 
bigger than Earth's entire economy today. 
And you're only at one millionth of the 
sun, give or take an order of magnitude. 
Yeah, we're talking orders of magnitude.
Before we move on to Optimus,  
I have a lot of questions on that but—
Every time I say "order of magnitude"...  
Everybody take a shot. I say it too often.
Take 10, the next time 100, the time after that... 
Well, an order of magnitude more wasted.
I do have one more question about xAI. 
This strategy of building a remote 
worker, co-worker replacement… 
Everyone's gonna do it by the way, not just us. 
So what is xAI's plan to win?
You expect me to tell you on a podcast? 
Yeah.
"Spill all the beans. Have another Guinness." 
It's a good system.
We'll sing like a  
canary. All the secrets, just spill them.
Okay, but in a non-secret spilling way,  
what's the plan?
What a hack. 
When you put it that way… I think the way that 
Tesla solved self-driving is the way to do it. 
So I'm pretty sure that's the way.
Unrelated question. How did Tesla  
solve self-driving? It sounds 
like you're talking about data? 
Tesla solved self-driving because of the...
We're going to try data and  
we're going to try algorithms.
But isn't that what all the other labs are trying? 
"And if those don't work, I'm not sure what will. 
We've tried data. We've tried algorithms. We've  
run out. Now we don't know what to do…"
I'm pretty sure I know the path. 
It's just a question of how 
quickly we go down that path,  
because it's pretty much the Tesla path.
Have you tried Tesla self-driving lately? 
Not the most recent version, but...
Okay. The car,  
it just increasingly feels sentient.
It feels like a living creature. That'll only  
get more so. I'm actually thinking we probably 
shouldn't put too much intelligence into the car,  
because it might get bored and…
Start roaming the streets. 
Imagine you're stuck in a car 
and that's all you could do. 
You don't put Einstein in a car.
Why am I stuck in a car? 
So there's actually probably a limit 
to how much intelligence you put in  
a car to not have the intelligence be bored.
What's xAI's plan to stay on the compute ramp up  
that all the labs are doing right now?
The labs are on track to  
spend over $50-200 billion.
You mean the corporations? The labs are at  
universities and they’re moving like a snail.
They’re not spending $50 billion. 
You mean the revenue maximizing 
corporations… that call themselves labs. 
That's right. The "revenue 
maximizing corporations" are  
making $10-20 billion, depending on...
OpenAI is making $20B of revenue,  
Anthropic is at $10B.
"Close to a maximum profit" AI. 
xAI is reportedly at $1B. What's the plan to 
get to their compute level, get to their revenue  
level, and stay there as things get going?
As soon as you unlock the digital human,  
you basically have access to 
trillions of dollars of revenue. 
In fact, you can really think of it like… 
The most valuable companies currently  
by market cap, their output is digital.
Nvidia’s output is FTPing files to Taiwan.  
It's digital. Now, those are very, very difficult.
High-value files. 
They're the only ones that can make files that 
good, but that is literally their output. They  
FTP files to Taiwan.
Do they FTP them? 
I believe so. I believe that File Transfer 
Protocol is the... But I could be wrong. But  
either way, it's a bitstream going to Taiwan. 
Apple doesn't make phones. They send files to  
China. Microsoft doesn't manufacture anything. 
Even for Xbox, that's outsourced. Their output is  
digital. Meta's output is digital. Google's output 
is digital. So if you have a human emulator,  
you can basically create one of the most 
valuable companies in the world overnight,  
and you would have access to trillions of 
dollars of revenue. It's not a small amount. 
I see. You're saying revenue figures today are 
all rounding errors compared to the actual TAM. 
So just focus on the TAM and how to get there.
Take something as simple as,  
say, customer service.
If you have to integrate with the APIs of existing  
corporations—many of which don't even have an API, 
so you've got to make one, and you've got to wade  
through legacy software—that's extremely slow.
However, if AI can simply take whatever  
is given to the outsourced customer 
service company that they already use  
and do customer service using the apps that they 
already use, then you can make tremendous headway  
in customer service, which is, I think, 1% 
of the world economy or something like that. 
It's close to a trillion dollars 
all in, for customer service. 
And there's no barriers to entry.
You can immediately say,  
"We'll outsource it for a fraction of the 
cost," and there's no integration needed. 
You can imagine some kind of categorization 
of intelligence tasks where there is breadth,  
where customer service is done by very 
many people, but many people can do it. 
Then there's difficulty where there's 
a best-in-class turbine engine. 
Presumably there's a 10% more fuel-efficient 
turbine engine that could be imagined by an  
intelligence, but we just haven't found it yet.
Or GLP-1s are a few bytes of data… 
Where do you think you want to play in this?
Is it a lot of reasonably intelligent  
intelligence, or is it at the 
very pinnacle of cognitive tasks? 
I was just using customer service as something 
that's a very significant revenue stream, but one  
that is probably not difficult to solve for.
If you can emulate a human at a desktop,  
that's what customer service is. It's people 
of average intelligence. You don't need  
somebody who's spent many years.
You don't need several-sigma  
good engineers for that.
But as you make that work,  
once you have effectively digital Optimus 
working, you can then run any application. 
Let's say you're trying to design chips.
You could then run conventional apps,  
stuff from Cadence and Synopsys and whatnot.
You can run 1,000 or 10,000 simultaneously and  
say, "given this input, I get 
this output for the chip." 
At some point, you're going to know what the chip 
should look like without using any of the tools. 
Basically, you should be able to do a digital 
chip design. You can do chip design. You march  
up the difficulty curve.
You’d be able to do CAD. 
You could use NX or any of the 
CAD software to design things. 
So you think you start at the simplest tasks 
and walk your way up the difficulty curve? 
As a broader objective of having this full 
digital coworker emulator, you’re saying,  
"all the revenue maximizing corporations 
want to do this, xAI being one of them,  
but we will win because of a secret plan we have."
But everybody's trying different things with data,  
different things with algorithms.
"We tried data, we tried algorithms.  
What else can we do?"
It seems like a competitive field. 
How are you guys going to 
win? That’s my big question. 
I think we see a path to doing it.
I think I know the path to do this  
because it's kind of the same path 
that Tesla used to create self-driving. 
Instead of driving a car, it's driving a computer 
screen. It's a self-driving computer, essentially. 
Is the path following human behavior and 
training on vast quantities of human behavior? 
Isn't that... training?
Obviously I'm not going to spell out  
the most sensitive secrets on a podcast.
I need to have at least three more  
Guinnesses for that.
What will xAI's business  
be? Is it going to be consumer, enterprise?
What's the mix of those things going to be? 
Is it going to be similar to other labs—
You’re saying "labs". Corporations. 
The psyop goes deep, Elon.
"Revenue maximizing corporations", to be clear. 
Those GPUs don't pay for themselves.
Exactly. What's the business model? What  
are the revenue streams in a few years’ time?
Things are going to change very rapidly. I'm  
stating the obvious here. I call AI the 
supersonic tsunami. I love alliteration.  
What's going to happen—especially when 
you have humanoid robots at scale—is  
that they will make products and provide services 
far more efficiently than human corporations. 
Amplifying the productivity of human 
corporations is simply a short-term thing. 
So you're expecting fully digital corporations 
rather than SpaceX becoming part AI? 
I think there will be digital 
corporations but… Some of this  
is going to sound kind of doomerish, okay?
But I'm just saying what I think will happen. 
It's not meant to be doomerish or anything else.
This is just what I think will happen. 
Corporations that are purely AI and 
robotics will vastly outperform any  
corporations that have people in the loop.
Computer used to be a job that humans had. 
You would go and get a job as a computer 
where you would do calculations. 
They'd have entire skyscrapers full of humans, 
20-30 floors of humans, just doing calculations. 
Now, that entire skyscraper 
of humans doing calculations  
can be replaced by a laptop with a spreadsheet.
That spreadsheet can do vastly more calculations  
than an entire building full of human computers.
You can think, "okay, what if only some of the  
cells in your spreadsheet 
were calculated by humans?" 
Actually, that would be much worse 
than if all of the cells in your  
spreadsheet were calculated by the computer.
Really what will happen is that the pure AI,  
pure robotics corporations or collectives 
will far outperform any corporations  
that have humans in the loop.
And this will happen very quickly. 
Speaking of closing the loop… Optimus.
As far as manufacturing targets go,  
your companies have been carrying American 
manufacturing of hard tech on their back. 
But in the fields that Tesla has been dominant 
in—and now you want to go into humanoids—in China  
there are dozens and dozens of companies that 
are doing this kind of manufacturing cheaply  
and at scale that are incredibly competitive.
So give us advice or a plan of how America can  
build the humanoid armies or the EVs, et cetera, 
at scale and as cheaply as China is on track to. 
There are really only three 
hard things for humanoid robots. 
The real-world intelligence, the 
hand, and scale manufacturing. 
I haven't seen any, even demo 
robots, that have a great hand,  
with all the degrees of freedom of a human hand. 
Optimus will have that. Optimus does have that. 
How do you achieve that? Is it just 
the right torque density in the motor? 
What is the hardware bottleneck to that?
We had to design custom actuators,  
basically custom design motors, gears, 
power electronics, controls, sensors. 
Everything had to be designed 
from physics first principles. 
There is no supply chain for this.
Will you be able to manufacture those at scale? 
Yes.
Is anything hard, except  
the hand, from a manipulation point of view?
Or once you've solved the hand, are you good? 
From an electromechanical standpoint, the hand 
is more difficult than everything else combined. 
The human hand turns out to be quite something.
But you also need the real-world intelligence. 
The intelligence that Tesla developed for 
the car applies very well to the robot,  
which is primarily vision in.
The car takes in vision,  
but it actually also is listening for sirens.
It's taking in the inertial measurements,  
GPS signals, other data, combining 
that with video, primarily video,  
and then outputting the control commands.
Your Tesla is taking in one and a half  
gigabytes a second of video and outputting two 
kilobytes a second of control outputs with the  
video at 36 hertz and the control frequency at 18.
One intuition you could have for when we get this  
robotic stuff is that it takes quite a few years 
to go from the compelling demo to actually being  
able to use it in the real world. 10 years ago, 
you had really compelling demos of self-driving,  
but only now we have Robotaxis and 
Waymo and all these services scaling up. 
Shouldn't this make one 
pessimistic on household robots? 
Because we don't even quite have the compelling 
demos yet of, say, the really advanced hand. 
Well, we've been working on 
humanoid robots now for a while. 
I guess it's been five or six years or something.
A bunch of the things that were done for the car  
are applicable to the robot.
We'll use the same Tesla AI  
chips in the robot as in the car.
We'll use the same basic principles. 
It's very much the same AI.
You've got many more degrees of  
freedom for a robot than you do for a car.
If you just think of it as a bitstream,  
AI is mostly compression and 
correlation of two bitstreams. 
For video, you've got to do a 
tremendous amount of compression  
and you've got to do the compression just right.
You've got to ignore the things that don't matter. 
You don't care about the details of the 
leaves on the tree on the side of the road,  
but you care a lot about the road signs 
and the traffic lights, the pedestrians,  
and even whether someone in another car 
is looking at you or not looking at you. 
Some of these details matter a lot.
The car is going to turn that one and  
a half gigabytes a second ultimately into 
two kilobytes a second of control outputs. 
So you’ve got many stages of compression.
You've got to get all those stages right and then  
correlate those to the correct control outputs.
The robot has to do essentially the same thing. 
This is what happens with humans.
We really are photons in, controls out. 
That is the vast majority of your life: vision, 
photons in, and then motor controls out. 
Naively, it seems that between humanoid 
robots and cars… The fundamental actuators  
in a car are how you turn, how you accelerate.
In a robot, especially with maneuverable arms,  
there's dozens and dozens 
of these degrees of freedom. 
Then especially with Tesla, you had this advantage 
of millions and millions of hours of human demo  
data collected from the car being out there.
You can't equivalently deploy Optimuses that  
don't work and then get the data that way.
So between the increased degrees of freedom  
and the far sparser data...
Yes. That’s a good point. 
How will you use the Tesla engine of 
intelligence to train the Optimus mind? 
You're actually highlighting an important 
limitation and difference from cars. 
We'll soon have 10 million cars on the road.
It's hard to duplicate that massive  
training flywheel.
For the robot,  
what we're going to need to do is build a lot of 
robots and put them in kind of an Optimus Academy  
so they can do self-play in reality. We're 
actually building that out. We can have at  
least 10,000 Optimus robots, maybe 20-30,000, that 
are doing self-play and testing different tasks. 
Tesla has quite a good reality 
generator, a physics-accurate reality  
generator, that we made for the cars.
We'll do the same thing for the robots. 
We actually have done that for the robots.
So you have a few tens of thousands of  
humanoid robots doing different tasks.
You can do millions of simulated  
robots in the simulated world.
You use the tens of thousands of  
robots in the real world to close the simulation 
to reality gap. Close the sim-to-real gap. 
How do you think about the synergies between xAI 
and Optimus, given you're highlighting that you  
need this world model, you want to use some 
really smart intelligence as a control plane,  
and Grok is doing the slower planning, and 
then the motor policy is a little lower level. 
What will the synergy between these things be?
Grok would orchestrate the  
behavior of the Optimus robots.
Let's say you wanted to build a factory. 
Grok could organize the Optimus 
robots, assign them tasks to build  
the factory to produce whatever you want.
Don't you need to merge xAI and Tesla then? 
Because these things end up so...
What were we saying earlier  
about public company discussions?
We're one more Guinness in, Elon. 
What are you waiting to see before you say, 
we want to manufacture 100,000 Optimuses? 
"Optimi". Since we're defining the 
proper noun, we’re going to define  
the plural of the proper noun too.
We're going to proper noun the  
plural and so it's Optimi.
Is there something on the  
hardware side you want to see?
Do you want to see better actuators? 
Is it just that you want 
the software to be better? 
What are we waiting for before we 
get mass manufacturing of Gen 3? 
No, we're moving towards that. We're 
moving forward with the mass manufacturing. 
But you think current hardware is good enough that 
you just want to deploy as many as possible now? 
It's very hard to scale up production.
But I think Optimus 3 is the right version  
of the robot to produce something on 
the order of a million units a year. 
I think you'd want to go to Optimus 4 
before you went to 10 million units a year. 
Okay, but you can do a million units at Optimus 3?
It's very hard to spool up manufacturing. 
The output per unit time 
always follows an S-curve. 
It starts off agonizingly slow, then it has 
this exponential increase, then a linear,  
then a logarithmic outcome until you 
eventually asymptote at some number. 
Optimus’ initial production will be a 
stretched out S-curve because so much  
of what goes into Optimus is brand new.
There is not an existing supply chain. 
The actuators, electronics, everything 
in the Optimus robot is designed  
from physics first principles.
It's not taken from a catalog.  
These are custom-designed everything. 
I don't think there's a single thing— 
How far down does that go?
I guess we're not making custom  
capacitors yet, maybe.
There's nothing you can  
pick out of a catalog, at any price.
It just means that the Optimus S-Curve,  
the output per unit time, how many Optimus robots 
you make per day, is going to initially ramp  
slower than a product where you 
have an existing supply chain. 
But it will get to a million.
When you see these Chinese humanoids,  
like Unitree or whatever, sell humanoids 
for like $6K or $13K, are you hoping to  
get your Optimus bill of materials below 
that price so you can do the same thing? 
Or do you just think qualitatively 
they're not the same thing? 
What allows them to sell for 
so low? Can we match that? 
Our Optimus is designed to have a lot 
of intelligence and to have the same  
electromechanical dexterity, if not 
higher, as a human. Unitree does not  
have that. It's also quite a big robot.
It has to carry heavy objects for long  
periods of time and not overheat or 
exceed the power of its actuators. 
It's 5'11", so it's pretty tall.
It's got a lot of intelligence. 
So it's going to be more expensive than 
a small robot that is not intelligent. 
But more capable.
But not a lot more. The thing is,  
over time as Optimus robots build Optimus 
robots, the cost will drop very quickly. 
What will these first billion 
Optimuses, Optimi, do? 
What will their highest and best use be?
I think you would start off with simple tasks  
that you can count on them doing well.
But in the home or in factories? 
The best use for robots in the beginning 
will be any continuous operation, any 24/7  
operation, because they can work continuously.
What fraction of the work at a Gigafactory that  
is currently done by humans could a Gen 3 do?
I'm not sure. Maybe it's 10-20%,  
maybe more, I don't know.
We would not reduce our headcount. 
We would increase our headcount, to be clear.
But we would increase our output. The units  
produced per human... The total number of humans 
at Tesla will increase, but the output of robots  
and cars will increase disproportionately.
The number of cars and robots produced per  
human will increase dramatically, but the 
number of humans will increase as well. 
We're talking about Chinese 
manufacturing a bunch here. 
We've also talked about some of 
the policies that are relevant,  
like you mentioned, the solar tariffs.
You think they're a bad idea because  
we can't scale up solar in the US.
Electricity output in the US needs to scale up. 
It can't without good power sources.
You just need to get it somehow. 
Where I was going with this is, if you 
were in charge, if you were setting all  
the policies, what else would you change?
You’d change the solar tariffs, that’s one. 
I would say anything that is a limiting 
factor for electricity needs to be addressed,  
provided it's not very bad for the environment.
So presumably some permitting reforms and stuff  
as well would be in there?
There's a fair bit of  
permitting reforms that are happening.
A lot of the permitting is state-based,  
but anything federal...
This administration is good at  
removing permitting roadblocks.
I'm not saying all tariffs are bad. 
Solar tariffs.
Sometimes if another country is  
subsidizing the output of something, then you have 
to have countervailing tariffs to protect domestic  
industry against subsidies by another country.
What else would you change? 
I don't know if there's that much 
that the government can actually do. 
One thing I was wondering... For the policy 
goal of creating a lead for the US versus China,  
it seems like the export bans have 
actually been quite impactful,  
where China is not producing leading-edge 
chips and the export bans really bite there. 
China is not producing 
leading-edge turbine engines. 
Similarly, there's a bunch of export bans that 
are relevant there on some of the metallurgy. 
Should there be more export bans?
As you think about things like the  
drone industry and things like that, is 
that something that should be considered? 
It's important to appreciate that in most 
areas, China is very advanced in manufacturing. 
There's only a few areas where it is not.
China is a manufacturing powerhouse, next-level. 
It's very impressive.
If you take refining of ore,  
China does roughly twice as much ore refining 
on average as the rest of the world combined. 
There are some areas, like refining 
gallium which goes into solar cells. 
I think they are 98% of gallium refining.
So China is actually very advanced  
in manufacturing in most areas.
It seems like there is discomfort  
with this supply chain dependence, and 
yet nothing's really happening on it. 
Supply chain dependence?
Say, like the gallium refining that  
you're saying. All the rare-earth stuff.
Rare earths for sure,  
as you know, they’re not rare.
We actually do rare earth ore mining in the US,  
send the rock, put it on a train, and then put 
it on a boat to China that goes to another train,  
and goes to the rare earth refiners in China 
who then refine it, put it into a magnet,  
put it into a motor sub-assembly, 
and then send it back to America. 
So the thing we're really missing 
is a lot of ore refining in America. 
Isn't this worth a policy intervention?
Yes. I think there are some things  
being done on that front.
But we kind of need Optimus,  
frankly, to build ore refineries.
So, you think the main advantage  
China has is the abundance of skilled 
labor? That's the thing Optimus fixes? 
Yes. China’s got like four times our population.
I mean, there's this concern. If you think  
human resources are the future, right now 
if it's the skilled labor for manufacturing  
that's determining who can build more 
humanoids, China has more of those. 
It manufactures more humanoids, therefore 
it gets the Optimi future first. 
Well, we’ll see. Maybe.
It just keeps that exponential going. 
It seems like you're sort of pointing out 
that getting to a million Optimi requires  
the manufacturing that the Optimi is 
supposed to help us get to. Right? 
You can close that recursive loop pretty quickly.
With a small number of Optimi? 
Yeah. So you close the recursive loop 
to help the robots build the robots. 
Then we can try to get to tens of millions 
of units a year. Maybe. If you start getting  
to hundreds of millions of units a year, you're 
going to be the most competitive country by far. 
We definitely can't win with just humans, 
because China has four times our population. 
Frankly, America has been winning for so 
long that… A pro sports team that's been  
winning for a very long time tends 
to get complacent and entitled. 
That's why they stop winning, because 
they don't work as hard anymore. 
So frankly my observation is just that the average 
work ethic in China is higher than in the US. 
It's not just that there's four 
times the population, but the amount  
of work that people put in is higher.
So you can try to rearrange the humans,  
but you're still one quarter of the—assuming 
that productivity is the same, which I think  
actually it might not be, I think China might have 
an advantage on productivity per person—we will do  
one quarter of the amount of things as China.
So we can't win on the human front. 
Our birth rate has been low for a long time.
The US birth rate's been below replacement  
since roughly 1971.
We've got a lot of people retiring, we're close  
to more people domestically dying than being born.
So we definitely can't win on the human front,  
but we might have a shot at the robot front.
Are there other things that you have wanted to  
manufacture in the past, but they've been too 
labor intensive or too expensive that now you  
can come back to and say, "oh, we can finally 
do the whatever, because we have Optimus?" 
Yeah, we'd like to build 
more ore refineries at Tesla. 
We just completed construction and have begun 
lithium refining with our lithium refinery  
in Corpus Christi, Texas.
We have a nickel refinery,  
which is for the cathode, that's here in Austin.
This is the largest cathode refinery, largest  
nickel and lithium refinery, outside of China.
The cathode team would say, "we have the  
largest and the only, actually, 
cathode refinery in America." 
Not just the largest, but it's also the only.
Many superlatives. 
So it was pretty big, even though it's 
the only one. But there are other things.  
You could do a lot more refineries and help 
America be more competitive on refining capacity. 
There's basically a lot of work for 
the Optimus to do that most Americans,  
very few Americans, frankly want to do.
Is the refining work too dirty or what's the— 
It's not actually, no. We don't have toxic 
emissions from the refinery or anything. 
The cathode nickel refinery is in Travis County.
Why can't you do it with humans? 
You can, you just run out of humans.
Ah, I see. Okay. 
No matter what you do, you have one quarter 
of the number of humans in America than China. 
So if you have them do this thing, 
they can't do the other thing. 
So then how do you build this refining capacity?
Well, you could do it with Optimi. 
Not very many Americans are pining to do refining.
I mean, how many have you run into? Very few. Very  
few pining to refine.
BYD is reaching Tesla  
production or sales in quantity.
What do you think happens in global  
markets as Chinese production in EVs scales up?
China is extremely competitive in manufacturing. 
So I think there's going to be a 
massive flood of Chinese vehicles  
and basically most manufactured things.
As it is, as I said, China is probably  
doing twice as much refining as 
the rest of the world combined. 
So if you go down to fourth and 
fifth-tier supply chain stuff… 
At the base level, you've got energy, 
then you've got mining and refining. 
Those foundation layers are, like I said, as a 
rough guess, China's doing twice as much refining  
as the rest of the world combined.
So any given thing is going to have  
Chinese content because China's doing twice as 
much refining work as the rest of the world. 
But they'll go all the way to the 
finished product with the cars. 
I mean China is a powerhouse.
I think this year China will exceed  
three times US electricity output.
Electricity output is a reasonable  
proxy for the economy.
In order to run the factories  
and run everything, you need electricity.
It's a good proxy for the real economy. 
If China passes three times 
the US electricity output,  
it means that its industrial capacity—as rough 
approximation—will be three times that of the US. 
Reading between the lines, it sounds like what 
you're saying is absent some sort of humanoid  
recursive miracle in the next few years, on the 
whole manufacturing/energy/raw materials chain,  
China will just dominate whether it comes to AI 
or manufacturing EVs or manufacturing humanoids. 
In the absence of breakthrough innovations 
in the US, China will utterly dominate. 
Interesting.
Yes. 
Robotics being the main breakthrough innovation.
Well, to scale AI in space, basically you need  
humanoid robots, you need real-world AI, 
you need a million tons a year to orbit. 
Let's just say if we get the mass driver on the 
moon going, my favorite thing, then I think— 
We'll have solved all our problems.
I call that winning. I call it winning, big time. 
You can finally be satisfied. 
You've done something. 
Yes.
You have the mass driver on the moon. 
I just want to see that thing in operation.
Was that out of some sci-fi or where did you…? 
Well, actually, there is a Heinlein book.
The Moon is a Harsh Mistress. 
Okay, yeah, but that's slightly different. 
That's a gravity slingshot or... 
No, they have a mass driver on the Moon.
Okay, yeah, but they use that to attack Earth. 
So maybe it's not the greatest...
Well they use that to… assert their independence. 
Exactly. What are your plans 
for the mass driver on the Moon? 
They asserted their independence. Earth 
government disagreed and they lobbed  
things until Earth government agreed.
That book is a hoot. I found that  
book much better than his other one that 
everyone reads, Stranger in a Strange Land. 
"Grok" comes from Stranger in a Strange Land.
The first two-thirds of Stranger in a Strange  
Land are good, and then it gets 
very weird in the third portion. 
But there are still some good concepts in there.
One thing we were discussing a lot  
is your system for managing people.
You interviewed the first few thousand of  
SpaceX employees and lots of other companies.
It obviously doesn't scale. 
Well, yes, but what doesn't scale?
Me. 
Sure, sure. I know that. But 
what are you looking for? 
There literally are not enough 
hours in the day. It's impossible. 
But what are you looking for that 
someone else who's good at interviewing  
and hiring people… What's the je ne sais quoi?
At this point, I might have more training data  
on evaluating technical talent especially—talent 
of all kinds I suppose, but technical talent  
especially—given that I've done so many 
technical interviews and then seen the results. 
So my training set is enormous 
and has a very wide range. 
Generally, the things I ask for are bullet 
points for evidence of exceptional ability. 
These things can be pretty off the wall.
It doesn't need to be in the specific domain,  
but evidence of exceptional ability.
So if somebody can cite even one thing,  
but let's say three things, where you go, 
"Wow, wow, wow," then that's a good sign. 
Why do you have to be the one to determine that?
No, I don't. I can't be. It's impossible. The  
total headcount across all 
companies is 200,000 people. 
But in the early days, what was 
it that you were looking for that  
couldn't be delegated in those interviews?
I guess I need to build my training set. 
It's not like I batted a thousand here.
I would make mistakes, but then I'd be  
able to see where I thought somebody 
would work out well, but they didn't. 
Then why did they not work out well?
What can I do, I guess RL myself, to  
in the future have a better batting 
average when interviewing people? 
My batting average is still not 
perfect, but it's very high. 
What are some surprising 
reasons people don't work out? 
Surprising reasons…
Like, they don't understand  
technical domain, et cetera, et cetera.
But you've got the long tail now of like,  
"I was really excited about this person. It 
didn't work out." Curious why that happens. 
Generally what I tell people—I tell myself, 
I guess, aspirationally—is, don't look at  
the resume. Just believe your interaction. The 
resume may seem very impressive and it's like,  
"Wow, the resume looks good."
But if the conversation  
after 20 minutes is not "wow," you should 
believe the conversation, not the paper. 
I feel like part of your method is that… There 
was this meme in the media a few years back about  
Tesla being a revolving door of executive talent.
Whereas actually, I think when you look at it,  
Tesla's had a very consistent and internally 
promoted executive bench over the past few years. 
Then at SpaceX, you have all these 
folks like Mark Juncosa and Steve Davis— 
Steve Davis runs The Boring Company these days.
Bill Riley, and folks like that. 
It feels like part of what has worked well 
is having very capable technical deputies. 
What do all of those people have in common?
Well, the Tesla senior team,  
at this point has probably got an average 
tenure of 10-12 years. It's quite long.  
But there were times when Tesla went 
through an extremely rapid growth phase,  
so things were just somewhat sped up.
As you know, a company goes through  
different orders of magnitude of size.
People that could help manage, say,  
a 50-person company versus a 500-person 
company versus a 5,000-person company versus  
a 50,000-person company.
You outgrew people. 
It's just not the same team.
It's not always the same team. 
So if a company is growing very rapidly, 
the rate at which executive positions will  
change will also be proportionate to 
the rapidity of the growth generally. 
Tesla had a further challenge where when Tesla had 
very successful periods, we would be relentlessly  
recruited from. Like, relentlessly. When 
Apple had their electric car program,  
they were carpet bombing Tesla with recruiting 
calls. Engineers just unplugged their phones. 
"I'm trying to get work done here."
Yeah. "If I get one more call from  
an Apple recruiter…" But their opening 
offer without any interview would be  
like double the compensation at Tesla.
So we had a bit of the "Tesla pixie  
dust" thing where it's like, "Oh, 
if you hire a Tesla executive,  
suddenly everything's going to be successful."
I've fallen prey to the pixie dust thing as well,  
where it's like, "Oh, we'll hire someone from 
Google or Apple and they'll be immediately  
successful," but that's not how it works. 
People are people. There's no magical pixie  
dust. So when we had the pixie dust problem, 
we would get relentlessly recruited from. 
Also, Tesla being engineering, especially 
being primarily in Silicon Valley,  
it's easier for people to just...
They don't have to change their life very much. 
Their commute's going to be the same.
So how do you prevent that? 
How do you prevent the pixie dust effect where 
everyone's trying to poach all your people? 
I don't think there's much we can do to stop it.
That's one of the reasons why Tesla… Really,  
being in Silicon Valley and having the pixie 
dust thing at the same time meant that there was  
just a very, very aggressive recruitment.
Presumably being in Austin helps then? 
Austin, it helps. Tesla still has a 
majority of its engineering in California. 
Getting engineers to move… I call 
it the "significant other" problem. 
Yes, "significant others" have jobs.
Exactly. So for Starbase that was  
particularly difficult, since the 
odds of finding a non-SpaceX job… 
In Brownsville, Texas…
…are pretty low. It's  
quite difficult. It's like a technology 
monastery thing, remote and mostly dudes. 
Not much of an improvement over SF.
If you go back to these people who've really  
been very effective in a technical capacity at 
Tesla, at SpaceX, and those sorts of places, what  
do you think they have in common other than...
Is it just that they're very sharp on the  
rocketry or the technical foundations, or 
do you think it's something organizational? 
Is it something about their 
ability to work with you? 
Is it their ability to be 
flexible but not too flexible? 
What makes a good sparring partner for you?
I don't think of it as a sparring partner. 
If somebody gets things done, 
I love them, and if they don't,  
I hate them. So it's pretty straightforward. 
It's not like some idiosyncratic thing. 
If somebody executes well, I'm a 
huge fan, and if they don't, I'm not. 
But it's not about mapping to 
my idiosyncratic preferences. 
I certainly try not to have it be 
mapping to my idiosyncratic preferences. 
Generally, I think it's a good idea to hire 
for talent and drive and trustworthiness. 
And I think goodness of heart is important.
I underweighted that at one point. 
So, are they a good person? Trustworthy? 
Smart and talented and hard working? 
If so, you can add domain knowledge.
But those fundamental traits,  
those fundamental properties, you cannot change.
So most of the people who are at Tesla and SpaceX  
did not come from the aerospace 
industry or the auto industry. 
What has had to change most about your 
management style as your companies have  
scaled from 100 to 1,000 to 10,000 people?
You're known for this very micro management,  
just getting into the details of things.
Nano management, please. Pico management.  
Femto management.
Keep going. 
We're going to go all the way 
down to Planck's constant. 
All the way down to Heisenberg 
uncertainty principle. 
Are you still able to get into 
details as much as you want? 
Would your companies be more 
successful if they were smaller? 
How do you think about that?
Because I have a fixed amount of  
time in the day, my time is necessarily diluted as 
things grow and as the span of activity increases. 
It's impossible for me to actually be a 
micromanager because that would imply I  
have some thousands of hours per day.
It is a logical impossibility  
for me to micromanage things.
Now, there are times when I will drill down into a  
specific issue because that specific issue is the 
limiting factor on the progress of the company. 
The reason for drilling into some very detailed 
item is because it is the limiting factor. 
It’s not arbitrarily drilling into tiny things.
From a time standpoint, it is physically  
impossible for me to arbitrarily go into 
tiny things that don't matter. That would  
result in failure. But sometimes the 
tiny things are decisive in victory. 
Famously, you switched the Starship 
design from composites to steel. 
Yes.
You made  
that decision. That wasn't people going around 
saying, "Oh, we found something better, boss." 
That was you encouraging 
people against some resistance. 
Can you tell us how you came to that 
whole concept of the steel switch? 
Desperation, I'd say. Originally, we were 
going to make Starship out of carbon fiber.  
Carbon fiber is pretty expensive. When you do 
volume production, you can get any given thing  
to start to approach its material cost.
The problem with carbon fiber is that  
material cost is still very high.
Particularly if you go for a high-strength  
specialized carbon fiber that can handle cryogenic 
oxygen, it's roughly 50 times the cost of steel. 
At least in theory, it would be lighter.
People generally think of steel as being  
heavy and carbon fiber as being light.
For room temperature applications,  
like a Formula 1 car, static aero structure, 
or any kind of aero structure really, you're  
probably going to be better off with carbon fiber.
The problem is that we were trying to make this  
enormous rocket out of carbon fiber 
and our progress was extremely slow. 
It had been picked in the first 
place just because it's light? 
Yes. At first glance, most people 
would think that the choice for  
making something light would be carbon fiber.
The thing is that when you make something very  
enormous out of carbon fiber and then you try 
to have the carbon fiber be efficiently cured,  
meaning not room temperature cured, because 
sometimes you got 50 plies of carbon fiber…  
Carbon fiber is really carbon string and glue.
In order to have high strength,  
you need an autoclave.
Something that's essentially a high pressure oven. 
If you have something that's gigantic, that 
one's got to be bigger than the rocket. 
We were trying to make an autoclave that's 
bigger than any autoclave that's ever existed. 
Or you can do room temperature cure, 
which takes a long time and has issues. 
The final issue is that we were just making 
very slow progress with carbon fiber. 
The meta question is why it had 
to be you who made that decision. 
There's many engineers on your team.
How did the team not arrive at steel? 
Yeah exactly. This is part of a broader 
question, understanding your comparative  
advantage at your companies.
Because we were making very slow  
progress with carbon fiber, I was like, 
"Okay, we've got to try something else." 
For the Falcon 9, the primary airframe 
is made of aluminum lithium, which has  
a very good strength-to-weight.
Actually, it has about the same,  
maybe better, strength to weight for 
its application than carbon fiber. 
But aluminum lithium is 
very difficult to work with. 
In order to weld it, you have to do something 
called friction stir welding, where you join the  
metal without entering the liquid phase.
It's kind of wild that you can do that. 
But with this particular type of welding, you 
can do that. It's very difficult. Let's say you  
want to make a modification or attach something to 
aluminum lithium, you now have to use a mechanical  
attachment with seals. You can't weld it on. 
So I wanted to avoid using aluminum lithium  
for the primary structure for Starship.
There was this very special grade of  
carbon fiber that had very good mass properties.
With a rocket, you're really trying to maximize  
the percentage of the rocket that is 
propellant, minimize the mass obviously. 
But like I said, we were 
making very slow progress. 
I said, "at this rate, we’re 
never going to get to Mars. 
So we've got to think of something else."
I didn't want to use aluminum lithium  
because of the difficulty of friction stir 
welding, especially doing that at scale. 
It was hard enough at 3.6 meters in 
diameter, let alone at 9 meters or above. 
Then I said, "what about steel?"
I had a clue here because some of  
the early US rockets had used very thin steel.
The Atlas rockets had used a steel balloon tank. 
It's not like steel had never been used before. 
It actually had been used. When you look at  
the material properties of stainless steel, 
full-hard, strain hardened stainless steel,  
at cryogenic temperature the strength to 
weight is actually similar to carbon fiber. 
If you look at material properties 
at room temperature, it looks like  
the steel is going to be twice as heavy.
But if you look at the material properties  
at cryogenic temperature of full-hard 
steel, stainless of particular grades,  
then you actually get to a similar 
strength to weight as carbon fiber. 
In the case of Starship, both the 
fuel and the oxidizer are cryogenic. 
For Falcon 9, the fuel is rocket propellant-grade 
kerosene, basically a very pure form of jet fuel.  
That is roughly room temperature. Although 
we do actually chill it slightly below,  
we chill it like a beer.
Delicious. 
We do chill it, but it's not cryogenic.
In fact, if we made it cryogenic,  
it would just turn to wax.
But for Starship,  
it's liquid methane and liquid oxygen.
They are liquid at similar temperatures. 
Basically, almost the entire primary 
structure is at cryogenic temperature. 
So then you've got a 300-series 
stainless that's strain hardened. 
Because almost all things are cryogenic 
temperature, it actually has similar  
strength to weight as carbon fiber.
But it costs 50x less in raw  
material and is very easy to work with.
You can weld stainless steel outdoors. 
You could smoke a cigar while welding 
stainless steel. It's very resilient.  
You can modify it easily. If you want to 
attach something, you just weld it right on. 
Very easy to work with, very low cost.
Like I said, at cryogenic temperature,  
it’s similar strength-to-weight to carbon fiber.
Then when you factor in that we have a much  
reduced heat shield mass, because the 
melting point of steel, is much greater  
than the melting point of aluminum… It's 
about twice the melting point of aluminum. 
So you can just run the rocket much hotter?
Yes, especially for the ship which is coming  
in like a blazing meteor.
You can greatly reduce  
the mass of the heat shield.
You can cut the mass of the windward  
part of the heat shield, maybe in half, and you 
don't need any heat shielding on the leeward side. 
The net result is that actually 
the steel rocket weighs less than  
the carbon fiber rocket, because the resin 
in the carbon fiber rocket starts to melt. 
Basically, carbon fiber and aluminum have about 
the same operating temperature capabilities,  
whereas steel can operate at twice the 
temperature. These are very rough approximations. 
I won't build the rocket.
What I mean is people will say,  
"Oh, he said this twice. It's actually 
0.8." I'm like, shut up, assholes. 
That's what the main comment's going to be about.
God damn it. The point is, in retrospect, we  
should have started with steel in the beginning.
It was dumb not to do steel. 
Okay, but to play this back to you, what 
I'm hearing is that steel was a riskier,  
less proven path, other than the early US rockets.
Versus carbon fiber was a worse but  
more proven out path.
So you need to be the  
one to push for, "Hey, we're going to do 
this riskier path and just figure it out." 
So you're fighting a sort 
of conservatism in a sense. 
That's why I initially said that the issue is 
that we weren't making fast enough progress. 
We were having trouble making even a 
small barrel section of the carbon fiber  
that didn't have wrinkles in it.
Because at that large scale, you have to  
have many plies, many layers of the carbon fiber.
You've got to cure it and you've got to cure it  
in such a way that it doesn't 
have any wrinkles or defects. 
Carbon fiber is much less resilient 
than steel. It has much less toughness.  
Stainless steel will stretch and bend, 
the carbon fiber will tend to shatter. 
Toughness being the area 
under the stress strain curve. 
You're generally going to have to do better 
with steel, but stainless steel to be precise. 
One other Starship question. So I visited 
Starbase, I think it was two years ago,  
with Sam Teller, and that was awesome.
It was very cool to see, in a whole bunch of ways. 
One thing I noticed was that people really took 
pride in the simplicity of things, where everyone  
wants to tell you how Starship is just a big soda 
can, and we're hiring welders, and if you can weld  
in any industrial project, you can weld here.
But there's a lot of pride in the simplicity. 
Well, factually Starship is 
a very complicated rocket. 
So that's what I'm getting at.
Are things simple or are they complex? 
I think maybe just what they're trying to say 
is that you don't have to have prior experience  
in the rocket industry to work on Starship.
Somebody just needs to be smart and work hard  
and be trustworthy and they can work on a rocket.
They don't need prior rocket experience. 
Starship is the most complicated machine 
ever made by humans, by a long shot. 
In what regards?
Anything, really. I'd  
say there isn't a more complex machine.
I'd say that pretty much any project I  
can think of would be easier than this.
That's why nobody has ever made a fully  
reusable orbital rocket. It's a very hard problem. 
Many smart people have tried before, very smart  
people with immense resources, and they failed. 
And we haven't succeeded yet. Falcon is partially  
reusable, but the upper stage is not.
Starship Version 3,  
I think this design can be fully reusable.
That full reusability is what will enable  
us to become a multi-planet civilization.
Any technical problem, even like a Hadron  
Collider or something like that, 
is an easier problem than this. 
We spent a lot of time on bottlenecks.
Can you say what the current Starship  
bottlenecks are, even at a high level?
Trying to make it not explode, generally.  
It really wants to explode.
That old chestnut. All those  
combustible materials.
We've had two boosters explode on the test stand. 
One obliterated the entire test facility.
So it only takes that one mistake. 
The amount of energy contained 
in a Starship is insane. 
Is that why it's harder than Falcon?
It's because it's just more energy? 
It's a lot of new technology. It's 
pushing the performance envelope. The  
Raptor 3 engine is a very, very advanced engine.
It's by far the best rocket engine ever made. 
But it desperately wants to blow up.
Just to put things into perspective here,  
on liftoff the rocket is generating over 100 
gigawatts of power. That’s 20% of US electricity. 
It's actually insane.
It's a great comparison. 
While not exploding.
Sometimes. 
Sometimes, yes. So I was 
like, how does it not explode? 
There's thousands of ways that it could 
explode and only one way that it doesn't. 
So we want it not only to really not explode, but 
fly reliably on a daily basis, like once per hour. 
Obviously, if it blows up a lot, 
it's very difficult to maintain that  
launch cadence.
Yes. 
What's the single biggest 
remaining problem for Starship? 
It's having the heat shield be reusable.
No one's ever made a reusable orbital heat shield. 
So the heat shield's gotta make it through the 
ascent phase without shucking a bunch of tiles,  
and then it's gotta come back in and also not lose 
a bunch of tiles or overheat the main airframe. 
Isn't that hard because it's 
fundamentally a consumable? 
Well, yes, but your brake pads in your car are 
also consumable, but they last a very long time. 
Fair.
So it just needs to last a very long time. 
We have brought the ship back and had 
it do a soft landing in the ocean. 
We've done that a few times.
But it lost a lot of tiles. 
It was not reusable without a lot of work.
Even though it did come to a soft landing,  
it would not have been 
reusable without a lot of work. 
So it's not really reusable in that sense.
That's the biggest problem that remains,  
a fully reusable heat shield.
You want to be able to land it,  
refill propellant and fly again.
You can't do this laborious inspection  
of 40,000 tiles type of thing.
When I read biographies of yours,  
it seems like you're just able to drive the sense 
of urgency and drive the sense of "this is the  
thing that can scale."
I'm curious why you  
think other organizations of your…
SpaceX and Tesla are really big companies now. 
You're still able to keep that culture.
What goes wrong with other companies such  
that they're not able to do that?
I don't know. 
Like today, you said you had 
a bunch of SpaceX meetings. 
What is it that you're doing 
there that's keeping that? 
It’s adding urgency?
Well, I don't know. I guess the urgency is going  
to come from whoever is leading the company.
I have a maniacal sense of urgency. 
So that maniacal sense of urgency 
projects through the rest of the company. 
Is it because of consequences? They're like, 
"Elon set a crazy deadline, but if I don't get it,  
I know what happens to me."
Is it just that you're able to  
identify bottlenecks and get rid 
of them so people can move fast? 
How do you think about why your 
companies are able to move fast? 
I'm constantly addressing the limiting factor.
On the deadlines front, I generally actually  
try to aim for a deadline that I at 
least think is at the 50th percentile. 
So it's not like an impossible deadline, but 
it's the most aggressive deadline I can think  
of that could be achieved with 50% probability.
Which means that it'll be late half the time. 
There is a law of gas expansion 
that applies to schedules. 
If you said we're going to do something in 
five years, which to me is like infinity time,  
it will expand to fill the available 
schedule and it'll take five years. 
Physics will limit how fast 
you can do certain things. 
So scaling up manufacturing, there's 
a rate at which you can move the atoms  
and scale manufacturing.
That's why you can't instantly  
make a million units a year of something.
You've got to design the manufacturing line. 
You've got to bring it up.
You've got to ride the S-curve of production. 
What can I say that's actually helpful to people? 
Generally, a maniacal sense 
of urgency is a very big deal. 
You want to have an aggressive schedule and 
you want to figure out what the limiting  
factor is at any point in time and help 
the team address that limiting factor. 
So Starlink was slowly in 
the works for many years. 
We talked about it all the way 
in the beginning of the company. 
So then there was a team you had built 
in Redmond, and then at one point you  
decided this team is just not cutting it.
It went for a few years slowly, and so why didn't  
you act earlier, and why did you act when you did?
Why was that the right moment at which to act? 
I have these very detailed 
engineering reviews weekly. 
That's maybe a very unusual level of granularity.
I don't know anyone who runs a company,  
or at least a manufacturing company, that 
goes with the level of detail that I go  
into. It's not as though... I have a pretty 
good understanding of what's actually going  
on because we go through things in detail.
I'm a big believer in skip-level meetings  
where instead of having the person that reports to 
me say things, it's everyone that reports to them  
saying something in the technical review.
And there can't be advanced preparation. 
Otherwise you're going to get 
"glazed", as I say these days. 
Exactly. Very Gen Z of you.
How do you prevent advanced preparation? 
Do you call on them randomly?
No, I just go around the room.  
Everyone provides an update. It's a lot 
of information to keep in your head. 
If you have meetings weekly or twice weekly, 
you've got a snapshot of what that person said. 
You can then plot the progress points.
You can sort of mentally plot the  
points on a curve and say, "are we 
converging to a solution or not?" 
I'll take drastic action only when I conclude 
that success is not in a set of possible outcomes. 
So when I finally reach the conclusion that unless 
drastic action is done, we have no chance of  
success, then I must take drastic action.
I came to that conclusion in 2018,  
took drastic action and fixed the problem.
You've got many, many companies. In each of  
them it sounds like you do this kind 
of deep engineering understanding of  
what the relevant bottlenecks are so 
you can do these reviews with people. 
You've been able to scale it up 
to five, six, seven companies. 
Within one of these companies, you have 
many different mini companies within them. 
What determines the max amount here?
Because you have like 80 companies…? 
80? No.
But you have so many  
already. That's already remarkable.
By this current number. 
Exactly.
We can barely keep one company together. 
It depends on the situation. I actually don't 
have regular meetings with The Boring Company,  
so The Boring Company is sort of cruising along.
Basically, if something is working well and  
making good progress, then there's 
no point in me spending time on it. 
I actually allocate time according to where the 
limiting factor. Where are things problematic?  
Where are we pushing against? What is holding 
us back? I focus, at the risk of saying the  
words too many times, on the limiting factor.
The irony is if something's going really well,  
they don't see much of me.
But if something is going badly,  
they'll see a lot of me. Or not even badly…
If something is the limiting factor. 
The limiting factor, exactly. It’s 
not exactly going badly but it’s the  
thing that we need to make go faster.
When something’s a limiting factor at  
SpaceX or Tesla, are you talking weekly 
and daily with the engineer that's  
working on it? How does that actually work?
Most things that are the limiting factor are  
weekly and some things are twice weekly.
The AI5 chip review is twice weekly. 
Every Tuesday and Saturday is the chip review.
Is it open ended in how long it goes? 
Technically, yes, but usually it's two or 
three hours. Sometimes less. It depends on  
how much information we've got to go through.
That's another thing. I'm just trying to tease  
out the differences here because 
the outcomes seem quite different. 
I think it's interesting to 
know what inputs are different. 
It feels like in the corporate world, one, 
like you were saying, the CEO doing engineering  
reviews does not always happen despite the 
fact that that is what the company is doing. 
But then time is often pretty finely sliced into 
half hour meetings or even 15 minute meetings. 
It seems like you hold more open-ended, 
"We're talking about it until we figure  
it out" type things.
Sometimes. But most  
of them seem to more or less stay on time.
Today's Starship engineering review went a bit  
longer because there were more topics to discuss.
They're trying to figure out how to scale to a  
million plus tons to orbit per 
year. It’s quite challenging. 
Can I ask a question? You said about Optimus 
and AI that they're going to result in double  
digit growth rates within a matter of years.
Oh, like the economy? Yes. I think that's right. 
What was the point of the DOGE cuts if 
the economy is going to grow so much? 
Well, I think waste and fraud 
are not good things to have. 
I was actually pretty worried about...
In the absence of AI and robotics,  
we're actually totally screwed because 
the national debt is piling up like crazy. 
The interest payments to national debt exceed 
the military budget, which is a trillion dollars. 
So we have over a trillion 
dollars just in interest payments. 
I was pretty concerned about that.
Maybe if I spend some time, we can  
slow down the bankruptcy of the United States 
and give us enough time for the AI and robots  
to help solve the national debt.
Or not help solve, it's the only  
thing that could solve the national debt.
We are 1000% going to go bankrupt as a country,  
and fail as a country, without AI and robots.
Nothing else will solve the national debt. 
We just need enough time to build the AI 
and robots to not go bankrupt before then. 
I guess the thing I'm curious about is, 
when DOGE starts you have this enormous  
ability to enact reform.
Not that enormous. 
Sure. I totally buy your point that it's 
important that AI and robotics drive  
productivity improvements, drive GDP growth.
But why not just directly go after the things  
you were pointing out, like the tariffs 
on certain components, or permitting? 
I'm not the president. And it is very hard to 
cut things that are obvious waste and fraud,  
like ridiculous waste and fraud.
What I discovered is that it's extremely  
difficult even to cut very obvious waste and 
fraud from the government because the government  
has to operate on who's complaining.
If you cut off payments to fraudsters,  
they immediately come up with the most sympathetic 
sounding reasons to continue the payment. 
They don't say, "Please keep the fraud going."
They’re like, "You're killing baby pandas." 
Meanwhile, no baby pandas are dying. They're 
just making it up. The fraudsters are capable  
of coming up with extremely compelling, 
heart-wrenching stories that are false,  
but nonetheless sound sympathetic. That's what 
happened. Perhaps I should have known better. 
But I thought, wait, let's try to cut some 
amount of waste and pork from the government. 
Maybe there shouldn't be 20 million people 
marked as alive in Social Security who are  
definitely dead, and over the age of 115. The 
oldest American is 114. So it's safe to say if  
somebody is 115 and marked as alive in the Social 
Security database, there's either a typo… Somebody  
should call them and say, "We seem to have 
your birthday wrong, or we need to mark you  
as dead." One of the two things.
Very intimidating call to get. 
Well, it seems like a reasonable thing.
Say if their birthday is in the future  
and they have a Small Business Administration 
loan, and their birthday is 2165,  
we either have a typo or we have fraud.
So we say, "we appear to have gotten the  
century of your birth incorrect."
Or a great plot for a movie. 
Yes. That's what I mean by, ludicrous fraud.
Were those people getting payments? 
Some were getting payments from Social Security.
But the main fraud vector was to mark somebody as  
alive in Social Security and then use every other 
government payment system to basically do fraud. 
Because what those other 
government payment systems do,  
they would simply do an "are you alive" check to 
the Social Security database. It's a bank shot. 
What would you estimate is the total 
amount of fraud from this mechanism? 
By the way, the Government Accountability 
Office has done these estimates before. I'm  
not the only one. In fact, I think the GAO did 
an analysis, a rough estimate of fraud during  
the Biden administration, and calculated 
it at roughly half a trillion dollars. 
So don't take my word for it.
Take a report issued during the  
Biden administration. How about that?
From this Social Security mechanism? 
It's one of many. It's important to 
appreciate that the government is  
very ineffective at stopping fraud.
It's not like a company where, with  
stopping fraud, you've got a motivation because 
it's affecting the earnings of your company. 
The government just prints more money. 
You need caring and competence. These are  
in short supply at the federal level.
When you go to the DMV, do you think,  
"Wow, this is a bastion of competence"?
Well, now imagine it's worse than the DMV  
because it's the DMV that can print money.
At least the state level DMVs need to... 
The states more or less need to stay 
within their budget or they go bankrupt. 
But the federal government just prints more money.
If there's actually half a trillion of fraud,  
why was it not possible to cut all that?
You really have to stand back and recalibrate  
your expectations for competence.
Because you're operating in a world  
where you've got to make ends meet.
You've got to pay your bills... 
Find the microphones.
Exactly. It's not like there's a giant,  
largely uncaring monster bureaucracy.
It's a bunch of anachronistic computers  
that are just sending payments.
One of the things that the DOGE  
team did sounds so simple and probably 
will save $100-200 billion a year. 
It was simply requiring payments from the 
main Treasury computer—which is called PAM,  
Payment Accounts Master or something like 
that, there's $5 trillion payments a year—that  
go out have a payment appropriation code.
Make it mandatory, not optional, that you  
have anything at all in the comment field.
You have to recalibrate how dumb things are. 
Payments were being sent out with no appropriation 
code, not checking back to any congressional  
appropriation, and with no explanation.
This is why the Department of War,  
formerly the Department of Defense, cannot pass 
an audit, because the information is literally  
not there. Recalibrate your expectations.
I want to better understand this half a trillion  
number, because there's an IG report in 2024.
Why is it so low? 
Maybe, but we found that over seven 
years, the Social Security fraud  
they estimated was like $70 billion over 
seven years, so like $10 billion a year. 
So I'd be curious to see what 
the other $490 billion is. 
Federal government expenditures 
are $7.5 trillion a year. 
How competent do you think the government is?
The discretionary spending there is like… 15%? 
But it doesn't matter. Most of 
the fraud is non-discretionary. 
It's basically fraudulent Medicare, 
Medicaid, Social Security,  
disability. There's a zillion government 
payments. A bunch of these payments are in  
fact block transfers to the states.
So the federal government doesn't  
even have the information in a lot of 
cases to even know if there's fraud.  
Let's consider reductio ad absurdum. The 
government is perfect and has no fraud. 
What is your probability estimate of that? Zero. 
Okay, so then would you say, fraud and waste  
at the government is 90% efficient?
That also would be quite generous. 
But if it's only 90%, that means that 
there's $750 billion a year of waste and  
fraud. And it's not 90%. It's not 90% effective.
This seems like a strange way to first principles  
the amount of fraud in the government.
Just like, how much do you think there is? 
Anyways, we don't have to do 
it live, but I'd be curious— 
You know a lot about fraud at Stripe?
People are constantly trying to do fraud. 
Yeah, but as you say, it's a little bit of a...
We've really ground it down, but it's a little  
bit of a different problem space because you're 
dealing with a much more heterogeneous set of  
fraud vectors here than we are.
But at Stripe, you have high  
competence and you try hard.
You have high competence and  
high caring, but still fraud is non-zero.
Now imagine it's at a much bigger scale, there's  
much less competence, and much less caring.
At PayPal back in the day, we tried to manage  
fraud down to about 1% of the payment volume. That 
was very difficult. It took a tremendous amount of  
competence and caring to get fraud merely to 1%.
Now imagine that you're an organization where  
there's much less caring and much less competence.
It's going to be much more than 1%. 
How do you feel now looking back 
on politics and doing stuff there? 
Looking from the outside in, two things have been 
quite impactful: one, the America PAC, and two,  
the acquisition of Twitter at the time.
But also it seems like there  
was a bunch of heartache.
What's your grading of the whole experience? 
I think those things needed to be done to 
maximize the probability that the future is good.  
Politics generally is very tribal. People 
lose their objectivity usually with politics. 
They generally have trouble seeing the good on 
the other side or the bad on their own side.  
That's generally how it goes. That, I guess, was 
one of the things that surprised me the most. 
You often simply cannot reason with people.
If they're in one tribe or the other. 
They simply believe that everything 
their tribe does is good and anything  
the other political tribe does is bad.
Persuading them otherwise is almost impossible. 
But I think overall those actions—acquiring 
Twitter, getting Trump elected, even though  
it makes a lot of people angry—I think 
those actions were good for civilization. 
How does it feed into the 
future you're excited about? 
Well, America needs to be strong enough to 
last long enough to extend life to other  
planets and to get AI and robotics to the point 
where we can ensure that the future is good. 
On the other hand, if we were to descend into, 
say, communism or some situation where the state  
was extremely oppressive, that would mean that 
we might not be able to become multi-planetary. 
The state might stamp out our 
progress in AI and robotics. 
Optimus, Grok, et cetera. Not just yours, but 
any revenue-maximizing company's products will  
be leveraged by the government over time.
How does this concern manifest in what  
private companies should be willing to give 
governments? What kinds of guardrails? Should  
AI models be made to do whatever 
the government that has contracted  
them out to do and asks them to do?
Should Grok get to say, "Actually,  
even if the military wants to do 
X, no, Grok will not do that"? 
I think maybe the biggest danger of AI 
and robotics going wrong is government. 
People who are opposed to corporations 
or worried about corporations should  
really worry the most about government.
Because government is just a  
corporation in the limit.
Government is just the biggest  
corporation with a monopoly on violence.
I always find it a strange dichotomy where  
people would think corporations are bad, but 
the government is good, when the government is  
simply the biggest and worst corporation. But 
people have that dichotomy. They somehow think  
at the same time that government can be good, 
but corporations bad, and this is not true. 
Corporations have better 
morality than the government. 
I actually think it’s a thing to be worried about.
The government could potentially use AI and  
robotics to suppress the population. 
That is a serious concern. 
As the guy building AI and 
robotics, how do you prevent that? 
If you limit the powers of government, which is 
really what the US Constitution is intended to do,  
to limit the powers of government, then you're 
probably going to have a better outcome than  
if you have more government.
Robotics will be available  
to all governments, right?
I don’t know about all governments.  
It's difficult to predict. I can say what's the 
endpoint, or what is many years in the future, but  
it's difficult to predict the path along that way.
If civilization progresses, AI will vastly  
exceed the sum of all human intelligence.
There will be far more robots than humans. 
Along the way what happens 
is very difficult to predict. 
It seems one thing you could do is just say, 
"whatever government X, you're not allowed to  
use Optimus to do X, Y, Z." Just write out 
a policy. I think you tweeted recently that  
Grok should have a moral constitution.
One of those things could be that we  
limit what governments are allowed 
to do with this advanced technology. 
Technically if politicians pass a 
law and they can enforce that law,  
then it's hard to not do that law.
The best thing we can have is limited government  
where you have the appropriate crosschecks between 
the executive, judicial, and legislative branches. 
The reason I'm curious about it is that at some 
point it seems the limits will come from you. 
You've got the Optimus, you've got the space GPUs…
You think I'll be the boss of the government? 
Already it's the case with SpaceX that for 
things that are crucial—the government really  
cares about getting certain satellites up in 
space or whatever—it needs SpaceX. It is the  
necessary contractor. You are in the 
process of building more and more of the  
technological components of the future that will 
have an analogous role in different industries. 
You could have this ability to set some policy 
that suppressing classical liberalism in any  
way… "My companies will not help in any 
way with that", or some policy like that. 
I will do my best to ensure that 
anything that's within my control  
maximizes the good outcome for humanity.
I think anything else would be shortsighted,  
because obviously I'm part of 
humanity, so I like humans. Pro human. 
You mentioned that Dojo 3 will 
be used for space-based compute. 
You really read what I say.
I don't know if you know,  
Elon, but you have a lot of followers.
Dead giveaway. How did you discern my secrets? 
Oh I posted them on X.
How do you design a chip for space? What changes? 
You want to design it to be more radiation 
tolerant and run at a higher temperature. 
Roughly, if you increase the operating 
temperature by 20% in degrees Kelvin,  
you can cut your radiator mass in half.
So running at a higher temperature  
is helpful in space.
There are various things  
you can do for shielding the memory.
But neural nets are going to be very  
resilient to bit flips.
Most of what happens  
for radiation is random bit flips.
But if you've got a multi-trillion parameter model  
and you get a few bit flips, it doesn't matter.
Heuristic programs are going to be much more  
sensitive to bit flips than 
some giant parameter file. 
I just design it to run hot.
I think you pretty much do  
it the same way that you do things on 
Earth, apart from making it run hotter. 
The solar array is most of 
the weight on the satellite. 
Is there a way to make the GPUs even more 
powerful than what Nvidia and TPUs and  
et cetera are planning on doing that would be 
especially privileged in the space-based world? 
The basic math is, if you can do about a 
kilowatt per reticle, then you'd need 100  
million full reticle chips to do 100 gigawatts.
Depending on what your yield assumptions are,  
that tells you how many chips you need to make.
If you're going to have 100 gigawatts of power,  
you need 100 million chips that are running at 
a kilowatt sustained, per reticle. Basic math. 
100 million chips depends on… If you 
look at the die size of something like  
Blackwell GPUs or something, and how many 
you can get out of a wafer, you can get  
on the order of dozens or less per wafer.
So basically, this is a world where if  
we're putting that out every single year, 
you're producing millions of wafers a month.  
That's the plan with TeraFab? Millions of 
wafers a month of advanced process nodes? 
Yeah it could be north of a million or something.
You’ve got to do the memory too. 
Are you going to make a memory fab?
I think the TeraFab's got to do memory. 
It's got to do logic, memory, and packaging.
I'm very curious how somebody gets started. 
This is the most complicated 
thing man has ever made. 
Obviously, if anybody's up to 
the task, you're up to the task. 
So you realize it's a bottleneck, 
and you go to your engineers. 
What do you tell them to do? "I want 
a million wafers a month in 2030." 
That’s right. That’s exactly what I want.
Do you call ASML? What is the next step? 
No so much to ask.
We make a little fab and see what happens. 
Make our mistakes at a small 
scale and then make a big one. 
Is a little fab done?
No, it's not done. We're  
not going to keep that cat in the bag.
That cat's going to come out of the bag. 
There'll be drones hovering over the bloody thing.
You'll be able to see its construction  
progress on X in real time.
Look, I don't know, we could just  
flounder in failure, to be fair. Success is not 
guaranteed. Since we want to try to make something  
like 100 million… We want 100 gigawatts of power 
and chips that can take 100 gigawatts by 2030. 
We’ll take as many chips as 
our suppliers will give us. 
I've actually said this to TSMC and Samsung 
and Micron: "please build more fabs faster". 
We will guarantee to buy the output of those fabs. 
So they're already moving as fast 
as they can. It's us plus them. 
There's a narrative that the people 
doing AI want a very large number  
of chips as quickly as possible.
Then many of the input suppliers,  
the fabs, but also the turbine manufacturers, 
are not ramping up production very quickly. 
No, they're not.
The explanation you hear  
is that they're dispositionally conservative.
They're Taiwanese or German, as the story may  
be. They just don't believe... Is that really 
the explanation or is there something else? 
Well, it's reasonable to... If somebody's been in 
the computer memory business for 30 or 40 years… 
They've seen cycles.
They've seen boom and bust 10 times. 
That's a lot of layers of scar tissue.
During the boom times, it looks like  
everything is going to be great forever.
Then the crash happens and they're  
desperately trying to avoid bankruptcy.
Then there's another boom and another crash. 
Are there other ideas you think 
others should go pursue that  
you're not for whatever reasons right now?
There are a few companies that are pursuing  
new ways of doing chips, but 
they're just not scaling fast. 
I don't even mean within 
AI, I mean just generally. 
People should do the thing where they find 
that they're highly motivated to do that thing,  
as opposed to some idea that I suggest.
They should do the thing that they find  
personally interesting and motivating to do.
But going back to the limiting  
factor… I used that phrase about 100 times.
The current limiting factor that I see in the  
three to four year timeframe, it's chips.
In the one year timeframe, it's energy,  
power production, electricity.
It's not clear to me that there's enough  
usable electricity to turn on all 
the AI chips that are being made. 
Towards the end of this year, I think people 
are going to have real trouble turning on... 
The chip output will exceed 
the ability to turn chips on. 
What's your plan to deal with that world?
We're trying to accelerate electricity production. 
I guess that's maybe one of the reasons that xAI 
will be maybe the leader, hopefully the leader. 
We'll be able to turn on more chips 
than other people can turn on, faster,  
because we're good at hardware.
Generally, the innovations from  
the corporations that call themselves labs, 
the ideas tend to flow… It's rare to see that  
there's more than about a six-month difference.
The ideas travel back and forth with the people. 
So I think you sort of hit the hardware 
wall and then whichever company can scale  
hardware the fastest will be the leader.
So I think xAI will be able to scale  
hardware the fastest and therefore 
most likely will be the leader. 
You joked or were self-conscious about 
using the "limiting factor" phrase again. 
But I actually think there's something deep here.
If you look at a lot of things we've touched on  
over the course of it, it’s 
maybe a good note to end on. 
If you think of a senescent, low-agency 
company, it would have some bottleneck and  
not really be doing anything about it.
Marc Andreessen had the line of,  
"most people are willing to endure any 
amount of chronic pain to avoid acute pain". 
It feels like a lot of the cases we're talking 
about are just leaning into the acute pain,  
whatever it is. "Okay, we got to figure out 
how to work with steel, or we got to figure  
out how to run the chips in space."
We'll take some near-term acute pain  
to actually solve the bottleneck.
So that's kind of a unifying theme. 
I have a high pain threshold. That's helpful.
To solve the bottleneck. 
Yes. One thing I can say is, I think the 
future is going to be very interesting. 
As I said at Davos—I think I was on the 
ground for like three hours or something—it's  
better to err on the side of optimism and 
be wrong than err on the side of pessimism  
and be right, for quality of life.
You'll be happier if you err on  
the side of optimism rather than 
erring on the side of pessimism. 
So I recommend erring on the side of optimism.
There's to that. 
Cool. Elon, thanks for doing this.
Thank you. 
All right, thanks guys. All right.
Great stamina. 
Hopefully this didn't count as 
a pain in the pain tolerance.