There's
 a
 recent
 political
 pro
 article


uh
 AI
 super
 PAC
 leading
 the
 future
 say


they
 are
 spinning
 up
 a
 multi-million


dollar
 effort
 to
 sink
 Boris's
 nent


primary
 campaign
 to
 replace
 retiring


Manhattan
 representative
 Jerry
 Nadler.


Okay.
 So
 what
 is
 it
 about
 your
 time
 the


state
 assembly
 such
 that
 you
 got
 on


their
 radar?


>> Most
 prominently
 I
 I've
 done
 a
 number
 of


bills
 uh
 while
 there.
 I've
 passed
 27


bills
 in
 my
 three
 years,
 which


coincidentally
 is
 the
 same
 number


Congress
 as
 a
 whole
 passed
 in
 2023.
 Um,


but
 there's
 one
 bill
 in
 particular
 that


caught
 their
 eye,
 which
 is
 the
 raise


act.
 Uh,
 and
 this
 bill
 would
 for
 the


first
 time
 put
 safety
 standards
 on


advanced
 AI
 research.
 They
 really
 didn't


like
 that
 bill.
 Um,
 and
 so
 they


announced
 me
 as
 public
 enemy
 number
 one.


Uh,
 and
 the
 initial
 announcement
 said


they're
 planning
 to
 spend
 multiple


millions
 against
 me.
 Last
 week
 they


upped
 it
 to
 $10
 million.
 I'm
 hoping
 if


the
 campaign
 continues
 I
 can
 use
 up
 all


hundred
 million
 that
 they've
 planned.
 Um


but
 we'll
 see
 where
 it
 goes.


>> What
 was
 in
 the
 raise
 act?
 Like
 what
 was


the
 gist
 of
 this
 bill
 that
 they
 had?


>> Yeah,
 so
 it
 was
 requiring
 the
 major


frontier
 lab.
 So
 we're
 talking
 Meta,


Google,
 XAI,
 OpenAI,
 Anthropic.
 That's


probably
 all
 it
 would
 apply
 to
 right


now.
 I
 think
 over
 time
 maybe
 Amazon
 gets


in
 there
 and
 deepseek
 and
 maybe
 mistrol


but
 it's
 a
 singledigit
 number
 of


companies
 and
 they
 would
 have
 to
 have
 a


public
 safety
 plan
 that
 they
 disclose


and
 stuck
 to
 also
 disclose
 critical


safety
 incidents
 so
 things
 that
 go
 wrong


that
 could
 lead
 to
 increased
 risk
 your


model
 weights
 get
 stolen
 they
 you
 lose


control
 of
 the
 model
 etc
 and
 it
 that
 if


your
 uh
 models
 fail
 your
 own
 tests
 that


you
 can't
 release
 that
 model
 and
 that's


designed
 to
 counteract
 what
 we
 saw
 with


the
 tobacco
 companies
 where
 they
 knew


that
 cigarettes
 were
 causing
 cancer
 but


denied
 it
 publicly
 and
 continued
 to


release
 the
 product.
 This
 is
 saying,


"Hey,
 you
 companies,
 you're
 the
 experts,


but
 if
 you're
 getting
 reports
 back
 that


this
 is
 very
 dangerous,
 you
 need
 to
 take


action
 on
 that."


>> Hello
 and
 welcome
 to
 another
 episode
 of


the
 OddLotss
 podcast.
 I'm
 Joe
 Weisenthal


>> and
 I'm
 Tracy
 Aloway.


>> Uh,
 you
 know,
 obviously
 we've
 been


talking
 about
 I
 think
 2028
 is
 going
 to


be
 a
 big
 election
 for
 AI.
 really
 2026


actually
 now.
 You
 know,
 it's
 not
 really


even
 a
 prediction.
 This
 is
 just
 a


description
 of
 fact.
 AI
 is
 going
 to
 be


very
 big
 for
 politics.


>> Yeah,
 I
 think
 it's
 inescapable
 at
 this


point.
 AI
 is
 sort
 of
 dominating
 the
 news


cycle
 as
 well.
 And
 I
 know
 it's
 a
 running


joke
 on
 the
 podcast,
 but
 every
 time
 we


record
 an
 AI
 related
 episode,
 another


headline
 hits
 the
 terminal
 about,
 you


know,
 some
 new
 billion
 dollar
 billion.


the
 one
 that
 we
 just
 got


>> Disney
 to
 make
 $1
 billion
 equity


investment
 in
 open
 AI


>> literally
 every
 time
 we
 do
 an
 episode


especially
 about
 AI
 but
 even
 other


there's
 some
 headline
 about
 a
 new
 uh


investment
 which
 just
 goes
 to
 show
 but


you
 know
 I
 the
 fact
 that
 it's
 going
 to


dominate
 politics
 is
 the
 least


surprising
 thing
 ever
 because


>> it
 touches
 on
 everything
 anything
 that's


politically
 sensitive
 the
 labor
 market


right
 that's
 obvious
 big
 one
 uh


electricity
 cost
 water
 consumption
 um


just
 pure
 like
 sort
 of
 wealth
 and


inequality
 and
 who
 has
 the
 power
 and


who's
 accumulating
 more
 and
 more
 money


in
 the
 tech
 industry
 and
 who's
 not
 and


all
 this
 like
 there
 is
 hardly
 a


political
 uh
 topic
 that
 in
 some
 way
 I


feel
 like
 AI
 does
 not
 exacerbate
 in
 some


way.


>> Absolutely.
 Meanwhile,
 the
 other
 big


news
 politically
 when
 it
 comes
 to
 AI


this
 week
 is
 that
 Trump
 issued
 an


executive
 order
 for
 a
 national
 rule
 on


AI.


>> Yeah.
 which
 a
 lot
 of
 you
 know
 people
 who


are
 trying
 to
 safeguard
 the
 system
 and


protect
 data,
 privacy
 rights,
 that
 sort


of
 thing


>> do
 not
 want.


>> Well,
 this
 is
 the
 other
 thing.
 So,


there's
 all
 this
 anxiety
 for
 various


reasons,


pick
 your
 poison,
 whether
 it's
 going
 to


displace
 the
 jobs,
 whether
 AI
 is
 going


to
 be
 too
 woke
 and
 come
 up
 with
 like


versions
 of
 history
 that
 people
 don't


like,
 whether
 it's
 going
 to,
 you
 know,


just
 rot
 our
 minds
 with
 slop,
 etc.
 But


um
 so
 then
 you
 say
 okay
 we
 should


regulate
 it
 or
 you
 know
 whether
 it's


going
 to
 turn
 us
 all
 into
 paper
 clips.


So
 you
 say
 okay
 we
 should
 regulate
 but


what
 does
 that
 even
 look
 like?
 Like
 what


is
 a
 sort
 of
 productive
 regulation
 look


like
 such
 that
 okay
 hopefully
 we
 could


maintain
 positive
 aspects
 of
 the


technological
 development
 while
 capping


the
 downsides.
 Like
 that's
 that
 would
 be


nice.
 I
 would
 love
 that.
 But
 like
 how


how
 exactly
 do
 you
 do
 that?
 The
 argument


that
 you
 hear
 from
 AI
 proponents
 is
 that


any
 regulation
 needs
 to
 balance
 you
 know


safety
 with
 innovation
 because
 there's


also
 the
 question
 of
 China
 which
 that's


another
 hot
 button
 political
 topic
 right


this
 idea
 that
 the
 US
 is
 in
 an


existential
 battle
 with
 China
 over
 AI


and
 we
 have
 to
 win
 at
 all
 costs


therefore
 the
 industry
 must
 not
 be


tightly
 regulated


>> yeah
 right
 so
 it's
 also
 a
 geopolitical


element
 anyway
 so
 we
 mentioned
 AI
 is


going
 to
 be a
 big
 polic
 politics.
 Uh
 we


really
 do
 have
 the
 perfect
 guest
 because


we're
 going
 to
 be
 speaking
 to
 someone


that
 the
 AI
 industry
 is
 actually


targeting.
 Someone
 that
 the
 AI
 industry


is
 actively
 trying
 to
 stop.
 There's
 this


uh
 new
 super
 PAC.
 Um
 and
 I
 think
 it
 has


some
 Andrees
 money
 and
 maybe
 a
 little


some
 executives
 from
 Open
 AI,
 etc.


Anyway,
 they
 want
 to
 like,
 you
 know,


make
 sure
 that
 uh
 sort
 of
 AI
 sympathetic


politicians
 do
 well,
 but
 they're
 also


targeting
 politicians
 that
 they
 perceive


to
 be
 too
 negative.
 And
 they've
 even


named
 names
 which
 I
 think
 is
 super


interesting
 and
 we
 have
 them.
 So
 we
 are


going
 to
 be
 speaking
 with
 Alex
 Boris.


He's
 a
 state
 assembly
 member
 here
 in
 New


York.
 He's
 also
 a
 candidate
 for
 uh
 the


prime
 in
 the
 primary
 for
 the
 12th


district
 which
 is
 here
 in
 Manhattan


which
 like
 I
 feel
 like
 a
 thousand
 people


are
 going
 to
 be
 running
 for
 this
 open


seat.
 Um
 I
 feel
 like
 if
 you
 were


targeted
 by
 the
 AI
 industry
 that
 is


probably
 some
 of the
 best
 advertising


you
 could
 get
 in
 a
 very
 crowded
 field


where
 it's
 just
 like
 there's
 going
 to
 be


a
 million
 choices.
 Also,
 yeah,


>> I
 was
 going
 to
 say
 what
 you're
 going
 to


say
 next,
 I
 think,
 but
 he
 used
 to
 work


at
 Palunteer
 as
 a
 data
 scientist,
 and


Palunteer
 is
 one
 of
 the
 companies


backing
 that
 super
 PAC.


>> So,
 you
 know
 what
 I
 think
 we
 should
 do?


Can
 we
 talk
 about
 AI
 for
 like
 five


minutes
 and
 then
 make
 this
 a
 50-minute


episode
 about
 what
 Palanteer
 does
 for


someone
 who
 used
 to
 work?
 That's
 my
 goal


for
 this
 episode.


>> Why
 don't
 we
 just
 make
 it
 a
 series?


>> Let's
 make
 it
 a
 series.
 Anyway,
 Alex


Boris,
 uh,
 thank
 you
 so
 much
 for
 coming


on
 OddLots.


>> Thank
 you
 for
 having
 me.


>> So,
 what's
 the
 deal?
 like
 people
 are


flying
 in
 from
 around
 the
 country
 just


to
 run
 for
 this
 12th
 district
 seat


that's
 opened
 up.


>> Yeah.
 Most
 recently,
 uh
 George
 Conway,


who
 lives
 in
 Bethesda,
 Maryland,
 uh
 said


that
 he
 was
 going
 to
 move
 to
 the


district
 and
 run.
 Uh
 you
 you
 don't
 have


to
 you
 just
 have
 to
 live
 in
 the
 state.


You
 don't
 have
 to
 live
 in
 the
 district


to
 run.
 So,
 uh
 last
 week,
 uh
 someone
 who


lives
 in
 the
 Bronx
 also
 declared
 for


this.


>> Is
 this
 the
 one
 Jack
 Schlober?
 Is
 he


running?


>> Jack
 is
 also
 running.
 Yes.
 I
 think


there's
 10
 declared
 candidates
 now
 and


and
 more
 to
 come,
 I'm
 sure.


>> What
 a
 farce.
 How
 did
 you
 actually


transition
 from
 being
 a
 data
 scientist


at
 Palunteer
 to
 politics?
 It's
 not
 a


natural
 progression
 for
 a
 lot
 of
 people.


>> Well,
 what
 brought
 me
 to
 Palunteer
 in


the
 first
 place
 was
 the
 ability
 to
 work


with
 government.
 And
 actually,


>> what
 year
 are
 we
 talking
 about,
 by
 the


way?


>> So,
 I
 I
 joined
 Palunteer
 in
 2014.
 I
 left


in
 2019.
 Um,
 and
 so
 many
 people
 think
 of


government
 as
 just
 passing
 the
 bills,


but
 that's
 not
 how
 most
 citizens


interact
 with
 government.
 It's
 can
 I
 get


to
 the
 DMV
 and
 get
 my
 license
 renewed


quickly?
 It's
 starting
 a
 business.
 It's


the
 day-to-day
 interactions
 and
 that


implementation
 was
 an
 exciting
 thing
 to


work
 on.
 So
 I
 was
 at
 Palunteer
 for
 four


and
 a
 half
 years.
 I
 then
 went
 to
 a


couple
 of
 startups
 afterwards.
 One
 that


used
 early
 transformers
 BERT
 and
 Laser


to
 help
 banks
 with
 anti-moneyaundering,


counterterrorist
 financing,
 and
 then
 a


startup
 that
 worked
 with
 municipalities


to
 better
 distribute
 aid.
 So
 that
 I
 had


this
 throughine
 of
 actually
 having


government
 deliver
 on
 its
 promises


throughout.


>> Um,
 we're
 going
 to
 talk
 more
 about


Palants
 here
 later.
 So,
 I'm
 reading
 this


is
 from
 those
 recent
 political
 pro


article.
 Uh,
 AI
 super
 PAC
 leading
 the


future
 say
 they
 are
 spinning
 up
 a


multi-million
 dollar
 effort
 to
 sink


Boris's
 nent
 primary
 campaign
 to
 replace


retiring
 Manhattan
 Representative
 Jerry


Nadler.
 Okay.
 So,
 what
 is
 it
 about
 your


time
 the
 state
 assembly
 such
 that
 you


got
 on
 their
 radar?


>> Most
 prominently,
 I
 I've
 done
 a
 number


of
 bills
 uh
 while
 there.
 I've
 passed
 27


bills
 in
 my
 three
 years,
 which


coincidentally
 is
 the
 same
 number


Congress
 as
 a
 whole
 passed
 in
 2023.
 Um,


but
 there's
 one
 bill
 in
 particular
 that


caught
 their
 eye,
 which
 is
 the
 Raise


Act.
 Uh,
 and
 this
 bill
 would
 for
 the


first
 time
 put
 safety
 standards
 on


advanced
 AI
 research.
 They
 really
 didn't


like
 that
 bill.
 Um,
 and
 so
 they


announced
 me
 as
 public
 enemy
 number
 one.


Uh,
 and
 the
 initial
 announcement
 said


they're
 planning
 to
 spend
 multiple


millions
 against
 me.
 Last
 week
 they


upped
 it
 to
 $10
 million.
 I'm
 hoping
 if


the
 campaign
 continues
 I
 can
 use
 up
 all


hundred
 million
 that
 they've
 planned.
 Um


but
 we'll
 see
 where
 it
 goes.


>> What
 was
 in
 the
 raise
 act?
 Like
 what
 was


the
 gist
 of
 this
 bill
 that
 they
 had?


>> Yeah.
 So
 it
 was
 requiring
 the
 major


frontier
 lab.
 So
 we're
 talking
 Meta,


Google,
 XAI,
 OpenAI,
 Anthropic.
 That's


probably
 all
 it
 would
 apply
 to
 right


now.
 I
 think
 over
 time
 maybe
 Amazon
 gets


in
 there
 and
 deepseek
 and
 maybe
 mistrol


but
 it's
 a
 singledigit
 number
 of


companies
 and
 they
 would
 have
 to
 have
 a


public
 safety
 plan
 that
 they
 disclose


and
 stuck
 to
 also
 disclose
 critical


safety
 incidents
 so
 things
 that
 go
 wrong


that
 could
 lead
 to
 increased
 risk
 your


model
 weights
 get
 stolen
 they
 you
 lose


control
 of
 the
 model
 etc
 and
 that
 if


your
 uh
 models
 fail
 your
 own
 tests
 that


you
 can't
 release
 that
 model
 and
 that's


designed
 to
 counteract
 what
 we
 saw
 with


the
 tobacco
 companies
 where
 They
 knew


that
 cigarettes
 were
 causing
 cancer
 but


denied
 it
 publicly
 and
 continued
 to


release
 the
 product.
 This
 is
 saying,


"Hey,
 you
 companies,
 you're
 the
 experts,


but
 if
 you're
 getting
 reports
 back
 that


this
 is
 very
 dangerous,
 you
 need
 to
 take


action
 on
 that."


>> It
 also
 proposes
 fines
 for
 violations,


right?
 I
 think
 it's
 up
 to
 $10
 million


for
 the
 first
 and
 then
 subsequent
 ones


are
 $30
 million.


Does
 that
 actually
 matter
 to
 tech


companies?
 It's
 like
 I
 know
 they
 care
 I


they
 care
 about
 money
 but
 like
 if
 Google


is
 pulling
 in
 a hundred
 billion
 per
 year


it
 can
 you
 know
 it
 can
 pay
 three
 billion


fines.


>> Absolutely.
 In
 my
 opinion
 those
 fines


are
 too
 low.
 The
 original
 version
 had
 uh


10%
 of
 their
 training
 costs
 and
 it
 would


scale
 up
 with
 what
 they're
 investing.
 Um


but
 uh
 generally
 in
 New
 York
 we
 don't


like
 an
 uncapped
 maximum
 fine.
 So
 that


was
 part
 of
 the
 negotiations.
 Um
 I


agree.
 I
 think
 there
 could
 be
 companies


that
 just
 say
 we're
 going
 to
 ignore


this.
 I
 think
 the
 fact
 that
 they're


spending
 nearly
 that
 amount
 lobbying


against
 it
 suggests
 that
 they
 do
 think


it
 has
 some
 teeth.


>> Um,
 talk
 to
 us
 a
 little
 bit
 more
 about


like
 what
 specifically
 would
 in
 your


what
 what
 would
 trigger
 the
 fines


because
 there
 I
 could
 see
 some
 very


perverse
 things
 going
 on.
 First
 of
 all,


I
 could
 see
 smaller
 companies
 that
 are


right
 at
 the
 edge
 where
 it's
 like,
 okay,


maybe
 this
 isn't
 a
 big
 deal
 for
 Google,


but
 this
 is
 a
 bigger
 deal
 for
 a
 smaller


company
 that's
 just
 starting
 out.
 We


don't
 want
 to
 lock
 in
 just
 the
 hands
 of


the
 biggest
 players,
 right?
 Because


regulation
 can
 serve
 that.
 It
 could
 say


like
 it
 can
 perversely


uh
 uh
 lock
 in
 the
 the
 incumbents
 because


they're
 the
 only
 ones
 who
 can
 deal
 with


the
 regulatory
 thicket.
 There
 are
 also


issues
 that
 could
 arise
 where
 well,
 if


I'm
 going
 to
 get
 uh
 fined
 really
 badly,


I'm
 just
 I'm
 going
 to
 look
 the
 other


way.
 I'm
 not
 going
 to
 notice
 uh
 what


these
 uh
 safety
 violations
 are.
 But
 talk


to
 us
 about
 like
 what
 are
 in
 your
 view


the
 formal
 triggers
 such
 that
 the
 bill


does
 not
 have
 these
 sort
 of
 perverse


incentives.


>> Yeah,
 I
 feel
 like
 this
 is
 the
 form
 where


I
 can
 really
 get
 into
 the
 details
 on
 it.


So,
 let's
 dive
 in.
 There's
 a
 two-part


test
 for
 the
 raise
 act
 to
 apply.
 The


first
 is
 that
 you're
 a
 company
 that
 has


spent
 $und00
 million
 specifically
 on


compute,
 specifically
 on
 the
 final


training
 run
 of
 model.
 So
 not
 the
 tests


that
 lead
 up
 to
 it,
 but
 actually
 the


final
 pre-training
 and
 post-
 training


before
 you
 put
 the
 model
 out.
 Uh
 that's


one
 part.
 So
 it
 doesn't
 apply
 if
 you're


an
 academic
 institution.
 It
 doesn't


apply
 if
 you
 spent
 less
 than
 a hundred


million.
 The
 second
 part
 is
 how
 do
 you


define
 a
 frontier
 model?
 And
 the
 easy


way
 is
 you
 have
 trained
 a
 model
 that


itself
 by
 itself
 was
 a
 hundred
 million


dollars
 in
 compute
 and
 had
 10
 to
 the
 26


flops
 computational
 operations
 in


training,
 right?
 A
 size
 of
 the
 a
 measure


of
 the
 complexity
 and
 the
 size
 of
 the


model.
 That's
 a
 standard
 one
 that
 people


have
 dealt
 with
 for
 a
 while.
 And
 so


that's
 when
 I
 listed
 the
 five
 companies


that
 I
 think
 it
 applies
 to.
 Those
 are


the
 companies
 I
 think
 have
 trained
 one


of
 those
 100
 million
 10
 to
 the
 26.
 But


there's
 a
 second
 way
 that
 you
 can
 be
 a


frontier
 model
 and
 that
 is
 you
 are


trained
 via
 the
 specific
 process
 of


knowledge
 distillation
 and
 at
 least
 5


million
 is
 spent
 on
 that.
 So
 knowledge


distillation
 is
 a
 technique
 of
 training


a
 small
 model
 based
 on
 the
 outputs
 of
 a


larger
 model
 and
 it's
 a
 way
 to
 kind
 of


shortcut
 a
 lot
 of
 the
 training
 and
 get
 a


smaller
 model
 that
 has
 similar


capabilities.
 Importantly,
 it's
 the


technique
 that
 China
 has
 been
 using
 to


catch
 up
 to
 the
 US
 because
 of
 our
 limits


on
 compute
 to
 China
 because
 of
 the


export
 controls.
 That's
 how
 they're


making
 their
 advanced
 models.
 And
 so,


this
 is
 the
 only
 bill
 that
 I
 know
 of


that
 would
 apply
 some
 regulatory


scrutiny
 to,
 for
 example,
 Deepseek.


>> How
 do
 you
 actually
 solve
 I
 I
 guess
 the


blackbox
 problem,
 this
 idea
 that,
 you


know,
 um
 you
 have
 these
 models,


algorithms,
 whatever.
 Um,
 and
 no
 one


really
 has
 very
 good
 insight
 into
 what


they're
 actually
 doing.
 And
 even
 if
 you


have
 rules
 against
 something
 like


redlinining,
 the
 models
 can
 use
 proxy


data
 to
 determine,
 you
 know,
 someone's


race
 or
 someone's
 gender,
 income,


whatever.
 How
 do
 you
 how
 do
 you
 do
 that?


>> Well,
 on
 on
 those
 kinds
 of
 questions


around
 discrimination,
 you're
 right.


It's
 very
 challenging
 to
 know
 what
 the


intent
 of
 a
 model
 is.
 and
 you
 know


everyone
 there
 there's
 a
 whole
 subset
 of


people
 who
 that
 are
 really
 against
 when


you
 anthropomorphicize
 any
 model
 but
 I'm


just
 going
 to
 keep
 saying
 intent
 and


desire
 and
 we
 could
 have
 that


conversation
 separately.
 So
 it's
 tough


to
 know
 a
 model's
 intent
 but
 you
 can


know
 its
 impact.
 So
 to
 be
 clear
 the


raise
 act
 doesn't
 deal
 at
 all
 with
 those


questions
 of
 discrimination.
 There's


other
 bills
 pending
 in
 the
 legislature


that
 do
 and
 I
 think
 it's
 an
 important


one.
 But
 in
 that
 and
 in
 the
 safety


aspects,
 you
 can
 do
 a
 variety
 of
 tests


to
 see
 how
 does
 it
 behave
 in
 certain


circumstances.
 And
 you've
 seen
 outside


researchers,
 you've
 seen
 companies


themselves
 set
 up
 their
 models
 in
 what


appear
 to
 be
 compromising
 situations
 and


see
 how
 it
 behaves.
 So
 there
 was
 one


test
 that
 was
 done
 where
 a
 model
 was


told
 it
 was
 going
 to
 be
 shut
 down,
 uh,


but
 was
 given
 access
 to
 what
 it
 thought


was
 a
 company's
 email
 server.


>> Oh,
 I
 remember
 this.
 Yeah.
 and
 they
 had


planted
 fake
 emails
 that
 the
 engineer


conducting
 the
 test
 was
 having
 an


affair.
 And
 so
 the
 model
 after
 being


told
 it
 was
 shut
 down
 sent
 a
 message
 to


the
 engineer
 saying
 I
 am
 going
 to
 send


these
 emails
 to
 your
 wife
 if
 you
 shut
 me


down.
 Uh
 so
 I
 don't
 know
 the
 intent
 of


the
 model.
 I
 don't
 know
 exactly
 what's


going
 on
 but
 I
 know
 that
 that
 is


behavior
 you
 probably
 want
 to
 work
 out


of
 the
 model
 before
 it's
 released.


>> It's
 pretty
 creative
 at
 the
 very
 least.


>> Yeah
 to
 some
 extent
 it
 shows
 they're


working.
 You
 know,
 you
 mentioned


DeepSeek.
 It's
 an
 open-
 source
 piece
 of


software.
 They're
 in
 China.
 Anyone
 can


they're
 clearly
 not
 go
 the
 people
 at


DeepSeek
 are
 not
 going
 to
 concern


themselves
 with
 some
 legislation
 in
 the


New
 York
 State
 Assembly.
 Anyone
 with
 an


internet
 connection
 can
 theoretically


download
 that
 model
 and
 run
 it
 on
 any


server.
 Intuitively,
 this
 feels
 like
 it


hobbles
 the
 American
 companies
 who
 have


to
 abide
 by
 uh
 American
 laws,
 etc.
 and


advantages
 uh
 opensource
 models
 that
 are


just
 like
 that
 maybe
 not
 even
 have
 a


company
 behind
 them
 in
 the
 future
 etc.


How
 why
 does
 this
 not
 have
 a
 negative


disperate
 impact
 on
 our
 own
 uh
 on
 our


own
 companies?


>> Well,
 Deepseek
 open
 source
 the
 model
 but


they
 are
 still
 a
 company
 that
 wants
 to


profit
 and
 they
 sell
 things
 on
 top
 of


it.
 So
 Deepseek's
 available
 in
 the
 app


store.
 If
 they
 don't
 pay
 fines
 in
 the


US,
 we
 can
 have
 an
 injunction
 to
 take


them
 out
 of
 the
 app
 store.
 Um
 and
 they


want
 businesses
 to
 use
 it.
 So
 there
 is


still
 a
 real
 reason
 for
 them
 to
 comply


with
 the
 US.
 But
 on
 the
 flip
 side
 of
 it,


how
 it
 could
 hobble
 these
 companies,


we're
 not
 asking
 them
 to
 do
 much
 more


than
 they've
 already
 committed
 to


publicly.
 They
 made
 White
 House


voluntary
 commitments
 in
 2023
 and
 2024.


They've
 had
 international
 uh
 summits


like
 the
 Seoul
 uh
 summit
 where
 they
 put


forward
 basically
 plans
 to
 do
 exactly


this.
 What
 the
 RA
 act
 does
 is
 lock
 in


place
 a
 floor
 so
 that
 when
 they're


rushing
 for
 the
 next
 quarterly
 reporting


or
 their
 next
 fundraising
 round,
 they


don't
 have
 an
 incentive
 to
 cut
 out
 on


safety.
 And
 I
 would
 say
 that
 the
 labs


themselves,
 the
 lobbyists
 for
 the
 labs


did
 an
 estimate
 for
 what
 it
 would
 take


to
 comply
 with
 the
 raise
 act.
 And
 they


have
 every
 incentive
 to
 expand
 that


estimate,
 say
 this
 will
 hobble
 us,
 you


know,
 we're
 going
 to
 leave.
 And
 the


estimate
 they
 came
 back
 with
 was
 that
 it


would
 require
 Google
 or
 Meta
 to
 have
 one


extra
 full-time
 employee.
 Oh
 wow.
 Um,


how
 would
 the
 RAES
 act
 actually
 interact


with
 this
 new
 um,
 executive
 order
 that


Trump
 just
 put
 out
 for
 a
 single
 national


rule
 for
 AI?


>> So
 Trump
 is
 threatening
 to
 withhold


funding
 from
 states
 and
 to
 sue
 states


that
 do
 any
 sort
 of
 regulation
 around


AI.
 New
 York
 already
 does
 a
 bunch
 of
 it.


So
 regardless
 of
 whether
 the
 governor


signs
 the
 raise
 act
 or
 not,
 we
 would


probably
 be
 in
 Trump's
 crosshairs.
 For


example,
 the
 governor
 this
 year
 put


forward
 regulations
 around
 chat
 bots


requiring
 them
 to
 disclose
 that
 they
 are


an
 AI
 model
 at
 the
 start
 and
 every
 three


hours
 of
 continuous
 conversation.
 Um,


and


>> that
 seems
 so
 basic.


>> So
 basic
 um,
 and
 requires
 them
 to
 uh
 be


on
 the
 lookout
 and
 to
 alert
 for
 when


there's
 language
 that
 might
 indicate


potential
 self
 harm
 and
 to
 refer
 people


to
 resources,
 which
 also
 seems
 really


basic,
 but
 that
 would
 violate
 this
 uh,


executive
 order.
 And
 so
 we're
 sort
 of
 in


for
 a
 penny,
 in
 for
 a
 pound
 at
 this


point.
 And
 I
 think
 we
 need
 to
 stand
 up


for
 New
 York
 families.


>> Joe,
 I
 get
 notifications
 if
 I
 watch
 too


many
 episodes
 of
 a
 show
 on
 Netflix,


right?
 You
 can
 imagine
 people
 constantly


talking
 to
 chat
 bots
 needing
 reminders,


too.


>> I
 feel
 like
 um
 Yeah,
 I
 I've
 never
 I've


I've
 never
 had
 a
 three-hour
 conversation


with
 a
 chat.
 If
 I
 ever
 have
 a
 three-hour


conversation
 with
 a
 chatbot,
 Tracy,
 let


>> I'm
 I'm
 going
 to
 keep
 an
 eye
 on
 you


office.
 Yeah.
 and
 um
 you
 know
 talk
 to
 us


a
 little
 bit
 more
 about
 the
 politics
 of


AI
 within
 Albany
 right
 now.
 Um
 is
 this


the
 kind
 of
 thing
 is
 there
 a
 bipartisan


sort
 of
 anxiety?
 Talk
 Yeah,
 talk
 to
 us


about
 the
 vibe
 to


>> Yeah,
 I
 think
 it's
 it's
 similar
 to
 what


you
 see
 nationally
 which
 is
 there
 are


some
 uh
 especially
 on
 the
 right
 that


just
 think
 the
 only
 thing
 that
 matters


is
 how
 fast
 AI
 moves
 and
 not
 who
 it


hurts.
 There
 are
 some
 especially
 on
 the


left
 that
 don't
 want
 want
 this


technology
 put
 back
 in
 the
 box,
 right?


And
 then
 there's
 most
 people
 in
 the


middle
 that
 say,
 "Hey,
 we
 need
 to


balance
 the
 benefits
 of
 it
 and
 the


potential
 safety
 of
 it."
 And
 the
 RA
 act


is
 squarely
 within
 that
 that
 realm.
 It


passed
 with
 co-sponsors
 who
 are
 both


Democrats
 and
 Republicans.
 The
 majority


of
 Republicans
 voted
 for
 it
 in
 the


assembly
 and
 every
 single
 Republican


state
 senator
 voted
 for
 it.
 So,
 um,


Tracy,
 at
 the
 start,
 you
 were
 mentioning


that
 proponents
 are
 the
 ones
 who
 are


balancing
 safety
 and
 innovation.
 By
 that


measure,
 everyone
 voting
 for
 it
 is
 a


proponent.
 Why
 do
 you
 think
 Trump
 is


doing
 this?


>> I
 love
 why
 do
 you
 think
 Trump
 questions


No,
 no,
 no.
 Honestly,
 it's
 a
 basic


question,
 but
 I'm
 very
 curious
 to
 hear


your
 answer.


>> I
 I


for
 so
 many
 reasons
 wish
 I
 understood


that
 man
 better.
 Um
 but
 also
 feel
 like


it
 would
 not
 be
 good
 for
 my
 mental


health
 if
 I
 did.
 Um
 it
 is
 tough
 to


understand
 because
 it's
 so
 different


from
 his
 policy
 everywhere
 else.
 Right.


Right.
 He
 is
 putting
 forward
 tariffs
 and


having
 this
 nationalistic
 protective


sort
 of
 anti-trade
 agenda
 on
 food
 and
 on


diapers
 and
 on
 toys.
 Uh
 but
 then
 when
 it


comes
 to
 AI


>> pencils
 now


>> pencils


>> he
 says
 we
 don't
 need
 so
 many
 pencils.


>> Uh
 my
 wife
 and
 I
 just
 had
 our
 first
 kid


who's
 four
 months.
 So
 you
 see
 where
 my


head's
 at
 with
 diapers
 and
 toys
 as
 we


come
 into
 the
 holiday.
 Pencils
 are
 still


a
 few
 years
 off.
 But
 um
 but
 and
 then


when
 it
 comes
 to
 AI,
 he
 just
 wants
 to


push
 America's
 uh
 agenda
 everywhere
 and


say
 no
 regulation
 whatsoever.
 So
 it's


confusing.
 What
 I
 can
 say
 is
 that
 a


number
 of
 the
 people
 behind
 the
 super


PAC
 targeting
 me
 are
 the
 same
 people


that
 were
 funding
 his
 campaign.
 You
 had


Mark
 Andre
 put
 five
 a.5
 million
 into
 his


campaign.
 You
 had
 Joe
 Lansdale
 put
 a


million
 into
 his
 campaign.
 You
 had
 Greg


Brockman,
 the
 president
 of
 OpenAI,
 put


at
 least
 two
 and
 a
 half
 million
 into


tearing
 down
 the
 White
 House
 to
 build


the
 ballroom.
 And
 so
 you
 have
 a
 lot
 of


people
 around
 Trump
 at
 fundraising


events
 and
 at
 other
 events
 who
 are


pushing
 this
 agenda
 and
 he
 seems
 to
 have


empowered
 them.


>> So
 one
 of
 the
 things
 about
 the
 politics


of
 AI
 and
 I
 mentioned
 in
 the
 beginning


it's
 very
 multifaceted
 because
 there
 are


people
 that
 are
 worried
 about
 safety,


people
 are
 worried
 about
 ethics,
 people


worried
 about
 water,
 people
 who
 are


worried
 about
 electricity,
 people


worried
 about
 job
 displacement,
 etc.


as
 a
 uh
 I
 don't
 know
 as
 a
 candidate
 for


office,
 how
 do
 you
 think
 about
 some
 of


these
 other
 AI
 concerns
 out
 there
 beyond


simply
 the
 safety
 stuff?


>> Oh,
 there's
 a
 lot
 that
 we
 need
 to
 do.


The
 chat
 bots,
 I
 think,
 are
 in
 some


sense
 safety
 when
 you
 think
 of
 what's


happening
 in
 kids,
 but
 very
 much
 talked


about
 in
 a
 different
 sort
 of


conversation.
 and
 even
 expanding
 that


out
 to
 AI's
 effect
 on
 our
 kids
 broadly


in
 our
 education
 system.
 You
 can
 imagine


a
 really
 positive
 world
 where
 every


student
 has
 an
 individualized
 tutor
 at


exactly
 their
 level
 uh
 and
 teaches
 them


in
 the
 exact
 way
 that
 they
 want
 to
 learn


to
 uh
 supplement
 what
 they're
 getting


from
 teachers.
 But
 what
 we
 have
 right


now
 is
 we
 haven't
 updated
 our
 pedagogy.


And
 so
 a
 lot
 of
 people
 think
 assigning


an
 essay
 still
 teaches
 critical


thinking,
 right?
 We
 need
 to
 do
 a
 lot
 on


the
 education
 system.
 We
 need
 to
 do
 a


lot
 on
 the
 workforce
 as
 you
 mentioned.


We
 need
 to
 do
 a
 lot
 on
 the
 environment


and
 we're
 missing
 a
 golden
 opportunity


here
 because
 our
 grid
 is
 extremely
 old


and
 we
 need
 to
 pay
 for
 the
 upgrades
 and


government
 doesn't
 really
 know
 how
 to
 do


that.
 We've
 been
 passing
 off
 the
 cost
 to


rateayers.
 Now
 you
 have
 an
 unlimited
 set


of
 private
 capital
 it
 seems
 that
 wants


to
 invest
 to
 build
 data
 centers.
 Why


aren't
 we
 using
 that
 to
 actually
 upgrade


our
 grid
 and
 to
 require
 renewable
 energy


and
 have
 it
 there?
 Instead,
 we're


building
 these
 data
 centers,
 but
 saying


rateayers
 have
 to
 pay
 for
 the
 uh
 the


interconnects.
 It
 makes
 no
 sense.


>> Does
 this
 issue
 just
 AI
 in
 general,
 does


it
 actually
 resonate
 with
 voters
 at
 the


moment?
 Because
 in
 some
 sense,
 you're


trying
 to
 get
 ahead
 of
 things,
 right?


Because
 in
 the
 future,
 I
 know
 we
 said
 AI


is
 all
 over
 the
 news
 and
 we
 see
 it


everywhere,
 but
 in
 the
 future
 it's
 going


to
 be
 more
 embedded
 in
 our
 lives.
 So,


you're
 trying
 to
 get
 ahead
 of
 that.
 Do


people
 care
 at
 the
 moment?


>> It's
 already
 embedded
 in
 their
 lives.


They're
 seeing
 it.
 And
 it's
 not
 just,


you
 know,
 their
 kids
 in
 school.
 It's
 not


just
 the
 uh
 entry
 level
 unemployment
 at


9%.
 You
 know,
 we
 just
 saw
 a
 teddy
 bear


that
 was
 sent
 out
 with
 Chachi
 BT


embedded
 in
 it
 that
 taught
 a
 kid
 how
 to


find
 matches.


>> Teddy
 Ruxpin
 upgraded.
 Do
 you
 remember


that?


>> I
 was
 walking
 down
 St.
 Mark
 Street
 the


other
 day.
 I
 have
 to
 say
 unfortunately
 I


thought
 those
 were
 pretty
 clever.
 There


was
 like
 someone
 set
 up
 a
 thing
 where


there
 was
 like
 like
 a
 animatronic
 puppet


that
 had
 a
 camera
 in
 it
 and
 then
 it
 was


embedded
 with
 an
 LLM
 and
 it
 was
 make
 it


was
 doing
 insult
 comics
 of
 the
 people


who
 were
 walking
 by.


>> Oh
 my
 god.


>> So
 like
 someone
 would
 walk
 by
 and
 they


like
 so
 you
 think
 you
 bought
 it
 like


with
 a
 big
 Uniclo
 bag.
 It's
 like
 so
 you


think
 you
 bought
 enough
 at
 Uniqlo
 today?


But
 I
 was
 like
 oh
 super
 clever.
 My
 kids


loved
 it.
 It
 was
 like
 I
 was
 like,
 "Oh,


this
 was
 like
 this
 is
 like
 a
 really


clever
 thing."


>> Wait,
 what
 did
 it
 say
 to
 you,
 Joe?


>> Um,
 what
 did
 it
 I
 think
 I
 stayed
 out.
 I


watched
 the
 other
 people
 got
 mad.
 I


stood
 I
 stood
 on
 this.
 I
 was
 like,
 "Oh,


this
 is
 actually
 I
 don't
 know."
 My
 kids


loved
 it.
 They
 thought


>> we'll
 leave
 that
 as
 an
 exercise
 to
 the


listener
 to
 walk
 by
 what
 it
 would
 have


said.


>> What
 does
 it
 say
 to
 you?


>> Are
 you
 optimistic
 about
 AI?
 Like
 are


you
 pro
 AI
 in
 the
 sense
 that
 you
 think


that
 this
 will
 be
 important,
 productive,


positive
 technology
 that
 is
 important
 to


continue
 developing?
 It
 can
 be,
 but
 only


if
 the
 American
 people
 have
 a
 voice
 in


how
 it
 develops.
 It
 is
 the
 technology


that
 has
 the
 widest
 bounds
 of
 what
 could


potentially
 come
 from
 it.
 And
 the
 only


thing
 that
 comes
 close
 is
 nuclear
 energy


and
 nuclear
 fision,
 right?
 So,
 if
 you


put
 yourself
 in
 the
 mindset
 of
 someone


in
 the
 1930s,
 you
 had
 one
 set
 of
 people


saying,
 "Nuclear
 fusion
 is
 coming.
 We're


about
 to
 have
 clean
 unlimited
 energy
 and


live
 in
 utopia."
 and
 you
 had
 another
 set


of
 people
 that
 said
 we're
 all
 going to


be
 dead
 from
 nuclear
 bombs
 in
 10
 years,


right?
 And
 the
 reality
 is
 we've
 ended
 up


somewhere
 in
 the
 middle.
 AI,
 we're
 at


that
 moment
 right
 now
 where
 you
 have


people
 saying
 basically
 that
 that
 wide


of
 a
 potential
 outcome
 and
 it's
 up
 to
 us


in
 our
 policy
 to
 make
 sure
 that
 the


worst
 case
 doesn't
 happen
 so
 that
 we
 can


have
 as
 much
 of
 the
 best
 case
 as


possible.
 Like
 what
 AI
 could
 do
 for


medical
 research,
 for
 curing
 diseases
 is


remarkable.
 My
 mom
 has
 multiple


sclerosis.
 Autoimmune
 diseases
 are
 some


of
 the
 hardest
 for
 modern
 medicine
 to


deal
 with.
 I
 am
 incredibly
 optimistic
 of


what
 could
 come
 from
 some
 of
 this


research.
 It's
 just
 that
 the
 same


capabilities
 that
 will
 allow
 us
 to
 cure


diseases
 could
 in
 the
 wrong
 hands
 allow


someone
 to
 build
 a
 bioweapon.
 And
 we


just
 need
 to
 be
 thoughtful
 on
 how
 we
 got


>> um
 I
 guess
 I'm
 I'm
 worried
 about


bioweapons.
 I'm
 also
 worried
 about
 very


mundane
 things
 just
 like
 you
 know
 it's


the
 new
 uh
 Gemini
 image
 generator
 is


just
 stunning
 to
 me
 in
 terms
 of
 the


degree
 of
 fidelity
 like
 how
 easily
 you


really
 can't
 tell
 anymore
 like
 a
 year


ago
 you
 could
 say
 oh
 that
 looks
 like
 an


AI
 image
 we're
 basically
 past
 that
 um


other
 thing
 like
 bots
 and
 stuff
 like


that
 things
 that
 replicate
 our
 voice


these
 aren't
 like
 ultra
 science
 fiction


things
 like
 a
 machine
 that's
 going
 to


like
 manufure
 a
 boweapon
 or
 something


like
 that,
 but
 they're
 daytoday


pervasive
 phenomenon
 that's
 sort
 of
 like


they're
 going
 to
 make
 me
 trust
 people


less.
 They're
 going to
 make
 it
 harder
 to


communicate.
 Like
 this
 sort
 of
 What
 do


we
 do
 about
 that?


>> Can
 we
 nerd
 out
 about
 deep
 fakes?


Because
 this
 is
 a
 solvable
 problem
 and


one
 that
 that
 I
 think
 most
 people
 are


missing
 the
 boat
 on.
 So,
 it's
 always


been
 presented
 to
 us
 as
 like,
 oh,
 you'll


have
 to
 learn
 how
 to
 see
 what's
 wrong


with
 an
 AI
 image.
 Like,
 that's
 never


going
 to
 work.
 They're
 going
 to
 get


better
 and
 better.
 Maybe
 we're
 already


past
 the
 point
 where
 a
 human
 could
 see


it,
 but
 that's
 not
 how
 we've
 solved


these
 problems
 in
 the
 past.
 Uh
 if
 you
 go


back
 to
 the
 90s,
 people
 said
 we'll
 never


have
 internet
 banking
 because
 you
 don't


know
 that
 the
 computer
 on
 the
 other
 end


is
 actually
 the
 one
 that
 you're
 talking


to.
 And
 then
 we
 move
 from
 HTTP
 to
 HTTPS.


That
 was
 a
 solvable
 problem.
 That


basically
 same
 technique
 works
 for


images,
 video,
 and
 for
 audio.
 So
 there


is
 a
 free
 open-source
 metadata
 standard


that
 industry
 has
 created
 called
 C2PA


content
 credential
 provenence
 authority


that
 you
 can
 attach
 to
 any
 standard
 file


format
 that
 cryptographically
 proves


whether
 that
 content
 was
 taken
 from
 a


real
 device
 generated
 by
 AI
 andor
 how
 it


was
 edited
 over
 time.
 The
 challenge
 is


the
 creator
 has
 to
 attach
 it
 and
 so
 you


need
 to
 get
 to
 a
 place
 where
 that
 is
 the


default
 option.
 you
 see
 an
 image
 and
 it


doesn't
 have
 that


>> cryptographic
 proof,
 you
 should
 be


skeptical.
 Like
 that
 would
 be
 that
 would


be
 the
 idea
 where
 it's
 so
 pervasive
 that


the
 expectation
 is
 I
 could
 test
 very


quickly
 whether
 the
 creator
 has
 attached


this.


>> It'd
 be
 like
 going
 to
 your
 banking


website
 and
 only
 loading
 HTTP,
 right?


You
 would
 instantly
 be
 suspect,


>> but
 you
 can
 still
 produce
 the
 images.


And
 I
 guess
 I
 I've
 been
 reading
 a
 book


called
 The
 New
 Age
 of
 Sexism,
 and
 it's


about
 technology
 and
 discrimination


against
 women.
 And
 it
 has
 some
 awful


awful
 stories
 of
 school
 girls
 whose


classmates
 like,
 you
 know,
 put
 them
 in


porn
 videos
 and
 things
 like
 that.
 And


one
 of
 the
 problems
 is
 there's
 no
 rules


saying
 that
 you
 can't
 actually
 do
 that.


So
 even
 if
 you
 know
 that
 it's
 fake,
 it


can
 still
 be
 harmful.
 What
 do
 you
 do


about
 that?


>> Well,
 there
 are
 laws
 in
 New
 York
 State


that
 ban
 it
 and
 in
 other
 states
 have


taken
 action.
 And
 that's
 yet
 another


reason
 why
 this
 AI
 preeemption
 is
 such
 a


scary
 thought.
 Um
 because
 states
 are


leading
 the
 way
 right
 now
 in
 stopping


some
 of
 these
 absolute
 worst
 uses.
 I'm


very
 excited
 for
 Congress
 to
 actually


solve
 these
 problems,
 for
 there
 to


actually
 be
 federal
 standards.
 I'm


running
 on
 the
 platform
 of
 creating


these
 federal
 standards.
 But
 until
 they


do,
 stopping
 states
 from
 taking
 action


like
 against
 deep
 fake
 porn
 of
 children.


I
 mean,
 that's
 the
 stakes
 of
 what
 we're


talking
 about.


>> Could
 we
 talk
 about
 parents
 here
 for
 a


second?
 Definitely.


>> It's
 a
 rough
 segue,
 but
 yeah.


>> What
 did
 you
 do
 there?


>> So,
 I
 I
 joined
 Palunteer
 as
 a
 data


scientist
 in
 2014.
 Uh,
 and
 I
 left
 as
 one


of
 the
 five
 overall
 leads
 of
 the


government
 business.
 I
 spent
 the
 vast


majority
 of
 my
 time
 in
 the
 federal


civilian
 side
 of
 it.
 So,
 I
 worked
 with


the
 Census
 Bureau
 and
 the
 Bureau
 of


Economic
 Analysis
 on
 updating
 how
 they


calculate
 GDP.
 We
 actually
 made
 a
 change


to
 the
 way
 they
 account
 for
 spending


around
 moving
 holidays,
 holidays
 that


are
 sometimes
 in
 Q1,
 sometimes
 in
 Q2,


like
 Easter.
 Um,
 a
 paper
 I'm
 very,
 very


proud
 of
 and
 it's
 a
 rounding
 error
 or


error
 of
 a
 rounding
 error
 on
 how
 we


calculate
 GDP,
 but
 it
 did
 actually
 lead


to
 a
 change.
 Uh,
 I
 led
 our
 work
 with
 the


Department
 of
 Justice
 to
 go
 after
 the


opioid
 epidemic
 uh,
 and
 to
 solve
 some


violent
 crimes.
 I
 worked
 with
 Veterans


Affairs
 to
 better
 staff
 their
 hospitals


to
 make
 sure
 that
 veterans
 get
 the
 care


that
 they
 deserve
 and
 need.
 I
 worked


with
 the
 CDC
 to
 better
 track
 epidemics.


It
 was
 about
 allowing
 government
 to
 make


better
 use
 of
 the
 data
 that
 they
 already


had
 to
 serve
 the
 American
 people.


>> And
 what
 does
 Palanteer
 actually
 do?
 I


feel
 like
 we
 ask
 this
 question
 a
 lot,


but


>> well,
 I
 think
 it's
 because
 it's
 a


fundamentally
 unsexy
 thing
 and
 people


like
 to
 dress
 it
 up,
 but
 it's
 it's
 data


integration
 and
 analysis.
 It's
 making
 it


different
 data
 sources
 that
 you
 have


access
 to
 talk
 to
 each
 other,
 be
 updated


constantly
 like
 Palunteer
 was
 founded


around
 a
 time
 when
 data
 lakes
 and
 data


clouds
 were
 like
 the
 big


>> data
 lake
 again.


>> Yeah,
 exactly.
 Uh
 but
 it's
 just
 putting


>> Oh,
 actually
 I'm
 asking
 what
 is
 a
 data


lake?
 Well,
 I
 don't
 know
 what
 that


means.


>> Putting
 all
 of
 your
 data
 in
 one
 place,


okay,
 people
 can
 access
 it,
 right?
 And


um
 that
 was
 supposed
 to
 revolutionize


everyone's
 ability
 to
 do
 anything.
 But


some
 just
 putting
 data
 in
 one
 place


doesn't
 actually
 make
 a
 change.
 Some
 of


the
 things
 that
 Palanteer
 really
 put
 at


the
 forefront
 like
 an
 ontology,
 right?
 A


um
 view
 from
 on
 high
 of
 what
 each
 piece


of
 data
 is
 supposed
 to
 mean
 can
 actually


lead
 to
 better
 analysis.
 I'll
 give
 you


an
 example
 from
 my
 work
 at
 the


Department
 of
 Justice.
 Um,
 and
 I


actually
 I
 have
 two
 software
 patents
 for


this
 project,
 which
 was
 we
 were
 helping


them
 analyze
 banks
 behavior
 leading
 up


to
 the
 Great
 Recession
 and
 how
 they
 were


packaging
 mortgages
 uh
 into
 securities


and
 each
 security
 would
 have
 a
 loan


tape.
 Here's
 the
 thousand
 loans
 that
 are


in
 it.
 And
 some
 of
 those
 loans
 would
 not


be
 up
 to
 the
 standards
 that
 were


required
 and
 that
 would
 occasionally
 be


flagged
 before
 an
 issuance.
 Hey,
 this


loan
 isn't
 up
 to
 your
 standards.
 They


would
 pull
 the
 loan
 out
 and
 then
 their


next
 issuance
 put
 the
 loan
 back
 in.


Right?
 And
 so
 if
 you
 could
 find
 that


pattern
 of
 behavior,
 you
 could
 maybe


prove
 that
 they
 had
 knowledge
 that
 that


loan
 wasn't
 good
 and
 were
 still
 putting


it
 out
 there.
 The
 problem
 is
 that


eiscocovery
 software,
 right,
 all
 the


data
 was
 there,
 but
 it
 was
 just
 taught


to
 think
 of
 an
 Excel
 document
 as
 a


document
 that
 a
 lawyer
 would
 read.
 And


so
 there
 was
 no
 way
 in
 the
 software
 to


track
 those
 individual
 loans.
 M


>> but
 if
 you
 think
 of
 an
 individual
 loan


as
 its
 own
 object
 that
 should
 be


something
 that
 can
 be
 searched
 and


tracked
 across
 the
 database
 then
 that


analysis
 becomes
 very
 easy
 to
 do.
 So


that
 was
 something
 that
 we
 enabled
 at


Palunteer
 was
 putting
 this
 ontology
 of


what's
 the
 right
 level
 for
 each
 object.


Oh
 a
 loan
 is
 a
 meaningful
 instance.


Let's
 make
 it
 so
 you
 can
 search
 and


analyze
 an
 individual
 loan
 versus
 a


document.


>> How
 has
 your
 experience
 at
 Palunteer


actually
 informed
 your
 approach
 to


government?
 because
 we've
 done
 episodes


on
 why
 government
 software
 is
 so
 bad.


And
 I
 think
 you're
 one
 of
 the
 few


politicians
 out
 there
 who
 actually
 knows


how
 to
 code.
 Possibly
 the
 only
 one.


>> No,
 there's
 got
 to
 be
 a
 couple
 others.


>> You
 think?


>> Two
 or
 three.
 I
 don't
 know.


>> We'll
 find
 them.


>> Yeah.


>> I
 I
 am
 the
 first
 Democrat
 elected
 in
 New


York
 State
 at
 any
 level
 with
 a
 degree
 in


computer
 science.
 Uh
 I
 do
 think
 there


have
 been
 nationwide
 like
 four
 or
 five


Congress
 members
 that
 have
 that,
 so


they're
 out
 there.
 Um
 uh
 but
 but
 my
 time


at
 Palunteer
 informs
 what
 I
 do
 in


government,
 I
 think,
 in
 two
 main
 ways.


The
 first
 is


the
 work
 isn't
 done
 when
 the
 bill
 is


signed,
 right?
 It's
 about
 the
 actual


implementation.
 Everything
 Palanteer


does
 is
 about
 implementing
 things
 that


have
 already
 been
 passed.
 And
 there's


huge
 challenges
 in
 getting
 it
 to
 work.


But
 the
 second
 thing
 is
 that
 basis
 in


data
 and
 actually
 tracking
 your
 results


and
 seeing
 how
 you've
 done
 over
 time.
 So


few
 politicians
 will
 say,
 "Hey,
 that


bill
 I
 passed
 two
 years
 ago,
 here's
 how


it's
 working."
 And
 even
 more
 rare
 is


here's
 how
 it's
 not.
 Um
 I
 did
 my
 town


hall
 3
 weeks
 ago.
 I
 once
 a
 year
 get
 up


in
 front
 of
 my
 entire
 constituency,


spend
 two
 hours
 answering
 any
 questions


people
 have.
 We
 don't
 screen
 it
 at
 all.


But
 I
 led
 off
 actually
 with,
 hey,
 here's


a
 bill
 I
 passed
 a
 year
 ago
 and
 the
 data


shows
 it's
 not
 working
 and
 here's
 what


I've
 learned
 about
 that
 and
 how
 we're


going
 to
 change
 that.


>> How
 exactly
 do
 you
 judge
 performance
 by


the
 government?
 cuz
 I
 like
 the
 idea
 of


like
 tracking
 I
 guess
 alpha
 in
 the
 civil


service
 in
 some
 way,
 but
 would
 it
 just


be
 based
 on
 the
 bill
 execution
 or
 I


guess
 response
 rates
 from
 the
 public?


How
 would
 you
 do
 that?


>> So,
 I
 I'll
 give
 you
 an
 example.
 Um,
 we


passed
 a
 bill
 to
 raise
 the
 statutory


maximum
 fine
 on
 telemarketers.


>> By
 far
 my
 most
 popular
 bill.
 Um,
 but
 the


question
 is
 that's
 the
 statutory


maximum.
 Does
 that
 actually
 lead
 to
 more


fines
 to
 higher
 fines
 to
 more
 negotiated


settlements?
 Is
 raising
 that
 pressure?


And
 so
 we
 just
 looked
 at
 the
 Secretary


of
 State's
 data
 of
 how
 much
 were
 the


fines
 before
 that
 bill
 was
 passed
 and


afterwards
 and
 we
 found
 there
 were
 four


times
 as
 many
 fines
 actually
 there.
 So


raising
 the
 statutory
 max
 brought
 the


bad
 behaviors
 to
 um
 companies
 to
 the


table
 to
 actually
 negotiate
 and


hopefully
 is
 changing
 that
 behavior.
 The


example
 I
 gave
 of
 one
 that
 didn't
 work


was
 uh
 around
 mopeds
 and
 ebikes
 in
 New


York.
 So,
 uh,
 you
 know,
 this
 is
 I'm


going
 to
 be
 very
 local
 to
 New
 York.
 I


know
 there's
 a
 a
 nationwide,
 uh,


>> a
 nationwide
 primary,
 but


>> it'd
 be
 nice
 if
 there
 were
 some
 c
 some


talk
 of
 actual
 relevant
 things
 for
 the


12th
 district.


>> So,
 so
 we
 have
 these,
 uh,
 delivery


vehicles
 that
 are
 whizzing
 all
 over
 and


people
 are
 scared
 as
 they
 see
 them
 go


the
 wrong
 way,
 etc.
 And
 there's
 a
 lot
 of


discussion
 about
 what
 we
 can
 do
 to
 make


people
 safe
 on
 the
 streets.
 Um,
 one


aspect
 is
 that
 mopeds
 were
 already


required
 to
 be
 registered
 in
 New
 York


State,
 but
 almost
 never
 were.
 So,
 I


passed
 a
 bill
 that
 would
 require
 mopeds


to
 be
 registered
 at
 the
 point
 of
 sale.


Right?
 So,
 think
 about
 how
 many
 mopeds


you
 think
 exist
 in
 New
 York
 City.


>> The
 number
 that
 were
 actually
 registered


when
 the
 bill
 came
 into
 effect
 this


January
 was
 about
 1,700.


>> Wow.


>> Uh,
 and


>> I
 feel
 like,
 by
 the
 way,
 this
 would
 be


like
 one
 of
 those
 like
 hedge
 fund


interview
 questions.
 How
 many
 mopeds
 are


in
 New
 York
 City?
 I
 want
 to
 see
 how
 your


brain
 thinks.


>> And
 I
 think
 if
 your
 answer
 is
 1,700,
 the


hedge
 fund's
 not
 hiring
 you,
 right?
 Like


that
 is
 not
 what
 you
 would
 estimate.
 Uh


my
 thesis
 was
 it
 was
 that
 people
 were


walking
 out
 of
 the
 store
 without


registering
 and
 being
 told
 to
 do
 that.


>> We
 looked
 a
 month
 ago,
 the
 number
 that


are
 registered
 is
 now
 1,400.


>> So
 it's
 not
 that
 people
 weren't


registering
 when
 they
 came
 to
 the
 store.


It's
 that
 registration
 expires
 after
 a


year
 and
 no
 one's
 reregistering.
 So
 that


was
 an
 example
 of
 like
 I
 had
 a
 thesis.
 I


passed
 the
 bill.
 I
 think
 the
 bill
 is


still
 overall
 good.


register
 as
 they
 leave
 the
 store.
 But
 it


didn't
 actually
 solve
 the
 problem
 we


were
 out
 to
 solve
 and
 here's
 what
 I'm


going to
 do
 about
 it.
 And
 I
 think
 we


need
 a
 lot
 more
 of
 that
 in
 government.


>> Wait,
 what
 are
 you
 going
 to
 do
 about
 it?


>> Well,
 we're
 thinking
 about
 how
 we
 can


encourage
 the
 actual
 registr
 the


re-registration
 over
 time.
 So,
 one
 of


the
 aspects
 is
 requiring
 all
 the


delivery
 apps
 to
 actually
 check
 that
 the


drivers
 are
 registered
 when
 they
 sign
 up


and
 to
 make
 sure
 they
 keep
 that
 up
 to


date.


>> Makes
 sense
 to
 me.
 Um,
 you
 know,
 it


feels
 like
 we're
 like
 in
 this
 sort
 of


era
 of
 every
 day,
 you
 mentioned


telemarketers.
 Like
 we're
 just
 like


waiting
 through
 the
 muck
 of
 like


low-level
 scams
 everywhere.
 Every
 day
 I


get
 text
 messages
 and
 then
 they'll
 say


like
 from
 an
 unknown
 number,
 Joe,
 are


you
 coming
 to
 barbecue?
 And
 I'm
 like,
 I


don't
 know.
 I
 might
 have
 like
 sent
 I


might
 have
 like
 I
 might
 have
 agreed
 to


eat
 barbecue
 with
 someone.
 That
 sounds


like
 something
 I
 could
 have
 done,
 but


I'm
 like
 pretty
 sure
 it's
 fake.
 There's


a
 you
 go
 on
 like
 Amazon
 and
 there's
 AI


generated
 books
 about
 books
 and
 every


author
 like
 just
 generally
 it
 feels
 like


we
 are
 in
 a
 culture
 and
 economy
 and
 era


of
 like
 persistent
 low-level
 grift


across
 almost
 every
 dimension
 of
 our


lives
 and
 I'm
 sure
 there's
 many
 reasons


for
 it
 but
 when
 people
 talk
 about
 a
 low


trust
 society
 and
 what's
 happening
 how


much
 of
 this
 do
 you
 think
 is
 just


because
 like
 we
 are
 inundated
 with


people
 trying
 to
 rob
 us
 every
 day
 in


some
 way,
 digitally
 or
 otherwise.


>> I
 think
 that's
 a
 big
 part
 of
 it.
 And
 the


only
 way
 to
 solve
 that
 problem
 is
 you


need
 actual
 enforcement.
 You
 need
 there


to
 be
 consequences.
 You
 know,
 just


sorry,
 just
 to
 follow
 up
 on
 this,
 like
 I


guess
 the
 reason
 I'm
 asking
 is
 because


most
 pol,
 you
 know,
 it's
 like
 someone


running
 for
 office,
 they
 move
 to
 the


12th
 district
 and
 they're
 like,
 I'm


going
 to
 call
 out
 Trump's
 corruption
 and


there
 all
 these
 like
 Trump
 is
 a
 lot
 all


this
 like
 big
 stuff
 and
 you
 know,


whatever.
 Many
 of
 these
 issues
 are
 like,


you
 know,
 legitimate,
 etc.,
 But
 almost


nobody
 in
 elected
 office
 seems
 to
 be


just
 like
 talking
 about
 like
 who's
 going


to
 do
 something
 about
 the
 text
 message


scams,
 who's
 going to
 be
 do
 something


about
 the
 AIA
 books,
 all
 of
 these
 like


big
 national
 issues,
 but
 the
 that


doesn't
 affect
 me
 on
 a
 day-to-day
 basis


the
 way
 the
 sort
 of
 like
 persistent


abuse
 of
 technology
 constantly
 does


every
 minute
 of
 my
 life.


>> I
 I
 think
 that's
 why
 podcasts
 like
 this


are
 great
 because
 you
 get
 into
 the


details.
 No,
 but
 the
 top
 level
 news


doesn't
 cover
 a
 lot
 of
 that,
 right?
 I


have
 a
 colleague
 John
 Rivera
 who
 has
 a


bill
 in
 the
 state
 assembly
 on
 b


requiring
 disclosure
 for
 AI
 generated


books
 on
 Amazon
 like
 that
 specific


example
 is
 a
 bill
 that
 exists
 in
 New


York.
 The
 telemarketing
 bill
 I
 pass
 also


applies
 to
 text
 messages
 and
 so
 we
 tell


people
 how
 to
 report
 those
 and
 maybe
 get


fines
 uh
 coming
 from
 that.
 I
 think
 this


is
 key
 to
 you
 know
 every
 both
 parties
 in


2026
 is
 talking
 about
 just
 government's


effect
 and
 trying
 to
 make
 life
 a
 little


bit
 better.
 I
 think
 my
 other
 most


popular
 bill
 besides
 the
 telemarketing


one
 was
 my
 click
 to
 cancel
 bill
 this


year
 to
 allow
 New
 Yorkers


>> I
 love
 that


>> it's
 now
 you're
 right
 as
 of
 October
 1st.


New
 Yorkers
 need
 to
 be
 able
 to
 cancel


subscription
 the
 same
 way
 they
 signed
 up


for
 it.


>> I
 have
 a
 condai
 NAS
 subscription
 that


I've
 been
 trying
 to
 cancel
 for
 like
 a


year
 and
 I
 cannot
 log
 into
 the
 site.
 I


can't
 find
 the
 original
 email
 where
 I've


like
 actually
 signed
 up
 for
 it
 and


that's
 I
 think
 $12
 a
 month
 that
 I'm
 just


wasting.


>> I
 mean
 government
 needs
 to
 get
 big


things
 done.
 Absolutely.
 But
 we
 also


need
 to
 get
 small
 things
 right.
 You
 just


need
 to
 make
 life
 better.


>> Um,
 apppropo
 of
 nothing.
 This
 is
 a


completely
 random
 seg,
 but
 one
 of
 the


interesting
 things
 about
 Eric
 Adams
 was


his
 interest
 in
 digital
 assets
 and


cryptocurrency
 and
 tokenization
 and
 all


of
 that.
 What
 did
 you
 think
 about
 those


efforts?
 Do
 they
 actually
 matter
 to
 the


industry
 and
 to
 New
 York
 more
 widely,
 or


is
 it
 just
 sort
 of
 a
 pet
 project?


Uh
 I
 I
 have
 not
 seen
 the
 direct
 results


of
 what
 he
 was
 working
 on.
 That
 doesn't


mean
 they
 weren't
 there.
 It's
 just
 not


where
 I
 have
 been
 focused.
 I
 actually


worked
 on
 a
 a
 different
 bill
 this
 year


around
 crypto
 in
 the
 legislature
 where


New
 York
 really
 took
 the
 lead
 in


creating
 legal
 structures
 for
 many
 of


these
 companies
 through
 the
 limited


purpose
 trust
 and
 the
 bit
 license.
 Um


but
 now
 with
 new
 action
 at
 the
 federal


level
 um
 they
 have
 said
 you
 know
 there's


going
 to
 be
 federal
 licensing
 for
 these


trust
 companies
 for
 stable
 coins
 uh
 and


they
 will
 defer
 to
 states
 but
 only
 if


the
 states
 have
 detailed
 rules
 in


uh
 legislation
 or
 regulation
 in
 statute


or
 regulation
 and
 New
 York's
 done
 it


almost
 all
 by
 guidance
 and
 so
 I
 really


fought
 for
 a
 bill
 this
 year
 to


standardize
 what
 DFS
 had
 done
 in
 random


opinions
 put
 it
 into
 statutes
 so
 that


people
 know
 what
 the
 rules
 of
 the
 road


are
 and
 so
 that
 New
 York
 can
 keep
 its


regulatory
 structure.
 It
 passed
 the


Senate.
 Unfortunately,
 we
 didn't
 get
 it


done
 in
 the
 assembly.
 And
 now
 most
 of


the
 companies
 in
 New
 York
 are
 just


applying
 for
 the
 federal
 charter
 and
 we


as
 New
 Yorkers
 are
 going
 to
 lose
 our


ability
 to
 engage.
 So,
 um
 I
 think


regardless
 of
 your
 broad
 view
 on
 crypto,


finding
 ways
 to
 set
 rules
 of
 the
 road


that
 allow
 for
 innovation
 and
 allow
 for


us
 to
 have
 a
 say
 in
 how
 it
 develops
 is


something
 everyone
 should
 get
 behind.


>> Yeah.
 I'm
 looking
 at
 a
 map
 of
 the
 New


York
 12th
 Congressional
 District.
 I


think
 one
 thing
 that
 really
 stands
 out,


it's
 not
 some
 weird
 snaky
 district.
 It's


just
 a
 real
 big
 square
 in
 the
 middle
 of


Manhattan.
 Like
 people
 who
 don't
 live


here
 might
 not
 appreciate
 this
 is
 like


this
 is
 prime
 real
 estate
 you're
 running


for.
 I
 argue
 I
 mean
 this
 is
 this
 might


be
 the
 highest
 GDP
 district
 in
 the
 world


or
 in
 the
 country
 or
 pretty
 close
 to
 it,


right?


>> Pretty
 close
 to
 it
 if
 not
 the
 one.
 Yes.


There's
 more
 Fortune
 500
 companies


headquartered
 there
 than
 I
 think
 at


least
 37
 states.


>> You're
 a
 few
 blocks
 away
 from
 me
 by
 the


Okay,
 I'm
 in
 these
 village.
 It
 looks


like
 it
 just
 cuts
 off
 a
 few
 blocks.


>> We'll
 fix
 it
 in
 redistricting.


>> Uh
 fix
 it
 in
 uh
 fix
 it
 in
 redistricting.


Um,
 it
 must
 be
 weird
 like,
 you
 know,


thinking
 about
 going
 back
 to
 the


beginning
 with
 like
 the
 tech
 industry


and
 criticizing
 you
 and
 like
 it
 must
 be


sort
 of
 weird
 that
 like
 you're
 a


politician
 who
 could
 actually
 like
 talk


in
 like
 gigaflops
 and
 stuff
 like
 that


because
 there's
 a
 lot
 of
 like
 anti-
 AI


people
 etc
 whatever
 or
 open
 standards


for
 digital
 encryption.
 It
 must
 be
 kind


of
 interesting
 that
 like
 okay
 here
 is


someone
 who
 wants
 to
 like
 hold
 the


industry
 to
 some
 legislative
 standards


who's
 frankly
 um


>> knowledgeable


>> informed.
 Yeah.
 Yeah.
 Knowledgeable.


Yeah.
 That
 must
 be
 sort
 of
 weird
 for


them.


>> I
 think
 it
 is.
 And
 I
 think
 it's
 why
 all


of
 their
 spending
 against
 me
 so
 far
 is


backfiring
 because
 people
 are
 like,
 "Oh


yeah,
 who
 is
 this
 guy
 who
 doesn't


understand
 tech
 who's
 doing
 uninformed


things?"
 And
 then
 it's
 like,
 "Wait,
 it's


the
 guy
 with
 software
 patents
 who
 worked


at
 Palunteer
 who
 has
 a
 masters
 in


computer
 science."
 It's
 like
 there
 is
 a


a
 disconnect
 there.
 I
 think,
 you
 know,
 I


have
 support
 from
 a
 lot
 of
 the
 people


that
 are
 like
 my
 age
 that
 work
 in
 the


tech
 industry,
 the
 ones
 actually


building
 it,
 um
 because
 they
 see
 the


power
 of
 what
 they're
 building
 and
 think


there
 should
 be
 some
 protections
 for
 it.


It's
 really
 those
 at
 the
 top
 uh
 who
 are,


I
 think,
 primarily
 focused
 on
 profits


that
 don't
 want
 government
 getting


involved
 at
 all.


>> I
 have
 a
 theoretical
 question
 going
 back


to
 the
 idea
 of
 hedge
 funds
 asking
 random


questions
 to
 see
 how
 you
 think.
 If
 you


had,
 I
 don't
 know,
 a
 a
 Bloomberg


terminal
 equivalent
 of
 government
 data,


>> what
 would
 you
 be
 most
 excited
 about


looking
 up
 or
 what
 correlation
 would
 you


be
 most
 excited
 about
 finding?


>> That
 is
 a
 great
 question.
 I'm
 going
 to


stall
 at
 first
 by
 pointing
 out
 that
 I


actually
 do
 have
 a
 certification
 in
 the


Bloomberg
 terminal
 for
 my
 first
 job.
 So,


I'm
 I'm
 imagining
 this
 realistically.
 Um


uh
 so
 you
 know
 that
 all
 we
 do
 on
 the


terminal
 is
 just
 look
 at
 two
 lines
 that


correlate.
 It's
 like
 I've
 proved


correlation.


Um
 I
 think
 uh
 ways
 of
 running
 more
 well


not
 maybe
 running
 more
 natural


experiments
 but
 looking
 at
 over
 time
 how


investments
 the
 government
 make
 pays


off.
 So,
 we
 only
 budget
 year
 by
 year.


>> And
 so,
 you
 have
 things
 like
 investing


in
 early
 child
 care
 that


>> boosts
 your
 immediate
 uh
 who
 can
 be


employed,
 but
 also
 like
 will
 help
 the


kids
 if
 you
 have
 universal
 prek,
 etc.


But
 that
 payback
 in
 the
 government
 if


you're
 just
 thinking
 fiscally
 is
 not


going
 to
 come
 for
 20
 30
 years.
 And
 as
 we


budget
 yeartoyear,
 that
 is
 we
 think
 of


that
 as
 a
 cost.
 I
 think
 if
 we
 had
 more


ways
 of
 tying
 the
 effects
 previously
 in


budgets
 with
 what
 we're
 seeing
 now,
 it


would
 change
 radically
 where
 we
 would


invest.


>> Alex
 Boris,
 thank
 you
 so
 much
 for
 coming


on
 Oddlos.
 That
 was
 a
 lot
 of
 fun.


>> Thanks
 for
 having
 me.
 It
 must
 be
 kind
 of


weird
 uh
 like
 I
 you
 know
 I
 said
 it
 near


the
 end
 but
 an
 AI
 critic
 that
 knows


something
 about
 tech
 because
 there
 are
 a


lot
 of
 AI
 critics
 out
 there
 and
 I
 don't


get
 the
 impression
 a
 lot
 of
 them
 are


particularly
 actually
 wellinformed
 and


do
 not
 actually
 understand
 the
 sort
 of


strongest
 version
 of
 the
 argument
 that


uh
 they're
 running
 against.
 So,
 it's


interesting
 that
 this
 pack,
 this
 uh
 pro


artificial
 intelligence
 pack
 has
 decided


to
 target
 someone
 who
 I
 think
 a
 lot
 of


people
 would
 listen
 to.
 It's
 like


actually
 he
 knows
 what
 he's
 talking


about.
 He
 sounds
 pretty
 reasonable.


>> He's
 also
 the
 first
 one
 they're


targeting,
 right?
 So,
 it'll
 be


interesting
 to
 see
 who
 they
 go
 after.


>> Yeah.


>> After
 him.
 The
 other
 thing
 I
 was


thinking
 is
 if
 you
 think
 about
 one
 of


the
 threats
 to
 big
 tech
 business
 models,


it's
 it's
 always
 regulation,
 right?
 or


at
 least
 they
 say
 it's
 regulation.
 They


they
 seem
 to
 hate
 regulation.


>> So,
 or
 overregulation,
 I
 should
 say.
 So,


if
 you
 think
 about
 proposing
 some
 basic


safety
 guard
 rails
 and
 privacy,


>> that
 would
 seem
 like
 a
 good
 thing
 to
 me


in
 the
 sense
 that
 maybe
 you
 could


restore
 some
 of
 the
 trust
 or
 faith


between
 the
 general
 population
 and
 the


big
 tech
 companies
 and
 then
 you
 wouldn't


get
 these
 massive
 fights
 about


everything
 else.
 But
 that's
 probably
 a


long
 shot.
 It
 does
 seem
 like
 I
 have
 to


say
 that
 while
 a
 lot
 of
 what
 he
 said


made
 a
 lot
 of
 sense
 uh
 or
 sort
 of


sounded
 very
 reasonable,
 you
 know,
 I
 do


think
 that
 it's
 legitimate
 concern
 like


these
 issues
 aren't
 going
 to
 hobble


Deepseek
 now
 will
 deep
 does
 deepseeek


want
 to
 be
 in
 the
 app
 store
 and
 can
 US


laws
 enjoin
 them
 from
 being
 on
 the
 app


store?
 Sure.
 But
 they're
 not
 going
 to


hobble
 deepsek's
 development
 of
 a
 model.


And
 if
 they
 want
 to
 be
 a
 dominant
 player


in
 every
 country
 but
 the
 US
 and
 they're


completely
 unconstrained
 and
 the
 uh


American
 advanced
 labs
 are
 in
 or
 are


constrained.
 I
 do
 think
 that
 is


legitimate
 concern
 that
 the
 industry


might
 have.
 I
 also
 think
 it's
 a
 probably


a
 legitimate
 concern
 that
 um
 you
 don't


want
 to
 disincentivize
 the
 reporting
 of


safety
 issues
 that
 if
 a
 company
 gets


penalized
 for
 uh
 acknowledging
 that


something
 in
 their
 model
 like
 violated


some
 safety
 line,
 you
 do
 not
 want
 to


have
 the
 risk
 of
 like
 we're
 just
 going


to
 ignore
 this.
 And
 I
 think
 uh
 it's


reasonable
 that
 the
 industry
 might
 be


concerned
 that
 regulations
 could
 benefit


the
 incumbents.
 He
 argued
 against
 that.


He's
 like,
 "Oh,
 no,
 like
 this
 is
 not


going
 to
 affect
 like
 startups
 etc.
 But


there
 is
 always
 that
 risk
 that
 a


monetary
 fine
 is
 something
 that's
 very


easy
 for
 big
 companies
 to
 pay
 and
 more


marginal
 ones
 are
 more
 difficult.
 So,


you
 know,
 these
 are
 very
 tricky
 things.


But
 as
 you
 know,
 on
 the
 surface,
 more


than
 on
 the
 surface,
 an
 extremely


knowledgeable
 guy
 who
 what
 he
 says,
 none


of
 it
 sounds
 particularly
 ridiculous.


And
 I
 have
 to
 say,
 if
 I
 were
 running
 in


a
 primary
 that
 had
 like
 25
 people,


including
 like
 a
 Kennedy
 era,
 a
 Kennedy


heir,
 and
 some
 guy
 on
 Twitter
 who
 like


posts
 orange
 man
 bad
 a
 lot
 of
 times,


that
 sounds
 like
 a
 good
 way
 to
 stand
 out


from
 the
 crowd
 to
 be
 uh
 the
 AI


industry's
 number
 one
 target.
 You
 know,


I
 agree
 with
 you
 on
 the
 incumbent
 point,


but
 just
 in
 terms
 of
 US
 versus
 China,
 I


think
 people
 forget
 that
 China
 has
 its


own
 restrictions,
 quite
 quite
 severe


ones
 on
 censorship,
 right?
 And
 trolling,


I
 guess,
 every
 single
 communication
 in


the
 world
 um
 in
 case
 someone
 mentions
 um


a
 certain
 cartoon
 character
 seems
 like


that's
 that's
 a
 big
 regulatory
 barrier


>> as
 well.
 So,
 I
 don't
 know.
 I
 find
 the


the
 competition
 aspect
 of
 it
 overhyped


in
 some
 sense.
 But
 anyway,
 we
 could
 talk


about
 this
 for
 ages
 and
 a
 lot
 of
 these


issues
 are
 clearly
 like
 ongoing
 and
 no


one
 has
 the
 the
 solution
 yet.
 We're


trying
 to
 work
 that
 out.


>> All right.
 Shall
 we
 leave
 it
 there?


>> Let's
 leave
 it
 there.


>> This
 has
 been
 another
 episode
 of
 the
 Odd


Thoughts
 podcast.
 I'm
 Tracy
 Aloway.
 You


can
 follow
 me
 at
 Tracee
 Alaway.


>> And
 I'm
 Jill
 Weisenthal.
 You
 can
 follow


me
 at
 the
 stalwart.
 Follow
 our
 guest


Alex
 Boris.
 He's
 Alex
 Boris.
 Follow
 our


producers
 Kerman
 Rodriguez
 at
 Kerman


Dashelbennet
 at
 Dashbot
 and
 Kaleb
 Brooks


at
 Kaleb
 Brooks.


>> And
 for
 more
 Abbots
 content,
 you
 can


check
 out
 our
 daily
 newsletter
 that
 is


at
 bloomberg.com/allbots.


>> And
 you
 can
 join
 fellow
 listeners
 in


conversation
 247
 in
 our
 Discord,


discord.gg/odlouds.


>> And
 if
 you
 enjoyed
 this
 conversation,


please
 like
 the
 video
 or
 leave
 a
 comment


or
 better
 yet,
 subscribe.


>> Thanks
 for
 watching.