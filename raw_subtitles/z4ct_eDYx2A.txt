[music]


Bloomberg
 Audio
 Studios
 podcasts,
 radio,


news.


[music]


>> Hello
 and
 welcome
 to
 another
 episode
 of


the
 OddLots
 podcast.
 I'm
 Joe
 Weisenthal.


>> And
 I'm
 Tracy
 Aloway.
 Tracy,
 covering


the
 AI
 boom
 is
 actually
 reminding
 me
 a


little
 bit
 of
 the
 tariff
 boom
 in
 April


simply
 because
 every
 day
 there
 are
 new


headlines.
 Like
 there
 just
 today,
 we're


recording
 this
 November
 12th,
 Anthropic


commits
 $50
 billion
 to
 build
 AI
 data


centers
 in
 the
 US.
 So
 the
 advanced
 model


companies
 are
 vertically
 integrating


more
 to
 build
 their
 own
 data
 centers.


Every
 day
 some
 new
 development.


>> Yeah,
 it's
 becoming
 pretty
 hard
 to
 keep


up.
 So
 I
 think
 we're
 probably
 just
 going


to
 talk
 in
 terms
 of
 billions
 and


trillions.
 We're
 just
 going
 to
 say
 lots


and
 lots
 of
 money
 is
 going
 into
 the


space.
 But
 the
 way
 I've
 been
 thinking


about
 it
 is
 okay,
 at
 this
 point
 everyone


agrees
 that
 the
 AI
 buildout
 is
 super


expensive
 and
 all
 these
 companies
 are


spending
 massive
 amounts
 of
 capex
 to
 do


this.
 And
 I'm
 starting
 to
 think
 that
 AI


capex
 is
 kind
 of
 like
 the
 Schroinger's


cat
 of
 markets
 in
 the
 sense
 that
 it


could
 either
 be
 a
 massive
 strength
 for


these
 companies
 because
 the
 capex
 is
 so


expensive
 and
 it
 takes
 so
 much
 money
 to


build
 out
 and
 so
 anyone
 who
 manages
 to


do
 it
 kind
 of
 builds
 a
 moat
 around
 their


business


>> or
 it
 could
 be
 a
 massive
 weakness,


right?
 if
 you're
 spending
 all
 this
 money


and
 then
 that
 doesn't
 end
 up
 generating


the
 revenues
 that
 you
 actually
 need
 to


justify
 it.
 And
 going
 back
 to
 the


Schroinger's
 analogy,
 it
 seems
 like
 we


just
 don't
 know
 what's
 going
 to
 come
 out


of
 the
 box,
 right?
 Like
 it's


simultaneously
 a
 strength
 and
 a
 weakness


and
 until
 we
 build
 out
 AGI
 or
 whatever,


like
 we're
 just
 not
 going
 to
 know.


>> Totally
 right.
 There's
 so
 much
 at
 stake


here
 and
 obviously
 we
 know
 the
 numbers


are
 absolutely
 enormous.
 They're


staggering
 and
 we
 could
 talk
 about
 them


too.
 The
 financing
 structures
 are
 also


very
 interesting.
 You
 know,
 it's
 one


thing
 if
 you
 just
 have
 Meta
 or
 Alphabet


and
 they
 make
 a
 ton
 of
 money
 already
 and


they're
 spending
 money
 on
 data
 centers,


whatever.
 That's
 one
 thing.
 It's
 another


thing
 when
 you
 start
 seeing
 these
 SPVS


where
 the
 hyperscaler
 puts
 in
 this


amount
 of
 money
 and
 then
 the
 private


credit
 puts
 in
 this
 equity
 and
 then
 they


borrow
 a
 bunch
 and
 then
 there's
 all


these
 questions
 about
 the
 payback.
 And


we
 think
 of
 tech
 as
 from
 years
 and
 years


as
 basically
 being
 this
 equity
 story.


And
 when
 it
 becomes
 a
 credit
 story.


Yeah.
 And
 when
 you
 know
 people
 are


talking
 about
 quoting
 Oracle
 CDS.
 I


always
 forget
 these
 companies
 even
 have


CDS
 because
 I'm
 so
 unus
 to
 thinking
 of


big
 tech
 companies
 as
 credits.
 So
 when
 I


see
 people
 starting
 to
 tweet
 Oracle
 CDS


charts
 or
 coreweave
 CDS
 charts,
 it's


like
 okay,
 we
 are
 in
 a
 different
 level


of
 capital
 intensity,


>> right?
 And
 some
 of
 those
 swaps
 have
 been


going
 up
 lately.
 I'm
 going
 to
 say
 one


more
 thing.
 Thinking
 back
 to
 the
 2008


financial
 crisis,
 I
 remember
 the


economist
 at
 Raymond
 James,
 I
 think
 it


was
 Jeff
 Sout
 who
 went
 on
 to
 um
 become
 a


very
 big
 name.
 Yeah,
 we
 should
 we
 should


have
 him
 on
 the
 podcast.
 But
 he
 made
 the


point
 that
 historically
 when
 you
 had


real
 estate
 crashes,
 property
 crashes,


it
 was
 usually
 because
 of
 a
 problem
 in


the
 economy.
 But
 then
 what
 happened
 in


the
 run-up
 to
 2007208
 is
 the
 housing


market
 crash
 became
 the
 approximate


cause
 of
 the
 troubles
 in
 the
 economy.


And
 if
 you
 think
 about
 how
 much
 money
 is


being
 spent
 on
 AI
 right
 now,
 again,


billions,
 trillions,
 possibly
 of


dollars,
 it's
 very
 easy
 to
 see
 how
 AI


could
 morph
 into
 a
 problem
 for
 the
 wider


economy.


>> For
 the
 real
 economy,
 totally.
 Just
 on


this
 note
 and
 then
 we'll
 get
 into
 our


conversation.
 The
 center
 for
 public


enterprises
 out
 with
 a
 great
 report


today
 called
 bubble
 or
 nothing
 by
 Edv


Arun
 pointing
 out
 one
 of
 the
 things
 that


makes
 data
 centers
 interesting
 is
 how


they
 sit
 at
 this
 intersection
 of


essentially
 industrial
 spending
 and
 real


estate.
 It's
 an
 interesting
 asset
 class


for
 its
 own
 right.
 So
 much
 to
 talk


about.
 We
 could
 never
 do
 it
 justice
 in


one
 episode,
 but
 that
 means
 we
 got
 to
 do


more.
 Anyway,
 I'm
 very
 excited
 for


today's
 episode.
 We
 really
 do
 have
 the


perfect
 guest.
 Someone
 who's
 been


writing
 about
 this
 for
 a
 long
 time.


Someone
 who's
 just
 been
 writing
 about


the
 internet
 and
 all
 things
 for
 longer


than
 any
 of
 us.
 Someone
 who's
 been


blogging
 and
 investing
 for
 far
 longer


than
 um
 either
 of
 us
 or
 anything
 like


that.
 Way
 more
 knowledgeable
 about
 how


these
 businesses
 work
 than
 most.
 Very


focused
 on
 the
 data
 center
 buildout.


We're
 going
 to
 be
 speaking
 with
 Paul


Kadroski.
 He
 is
 a
 fellow
 at
 the
 MIT


Institute
 for
 the
 Digital
 Economy.
 also


a
 partner
 at
 SK
 Ventures
 and
 longtime


internet
 blogger,
 writer,
 newsletter,


yapper,
 etc.
 Someone
 we've
 never
 never


had
 on
 the
 podcast
 before.
 So
 Paul,


thank
 you
 so
 much
 for
 uh
 joining
 us.


>> Hey
 guys,
 thanks.
 Good
 to
 be
 here
 other


than
 the
 blogging
 part,
 but


>> no,
 it's
 all
 it's
 all
 it
 was
 you're


you're
 a
 true
 pioneer
 in
 that
 and
 it's


impressive
 that
 you
 still
 write
 with
 the


output
 that
 you
 do.
 At
 some
 point
 in
 the


last
 year,
 I
 feel
 like
 you
 really
 got


laser
 focused
 or
 maybe
 in
 the
 last
 two


years
 really
 got
 laser
 focused
 on
 the


data
 center
 story
 is
 this
 is
 where
 the


action
 is.


>> Yeah,
 I
 did.
 And
 in
 part
 just
 because
 I


caught
 myself
 by
 surprise
 with
 it.
 It


was
 weird.
 I
 was
 looking
 at
 first
 half


GDP
 data
 actually
 first
 quarter
 GDP
 data


earlier
 in
 the
 year
 and
 you
 know
 this


has
 become
 now
 a
 common
 place
 that


people
 know
 this
 but
 I
 hadn't
 realized


what
 a
 large
 fraction
 of
 GDP
 growth
 in


the
 first
 quarter
 data
 centers
 were.
 it


was
 on
 the
 order
 of
 50%,
 much
 larger
 if


you
 included
 all
 sort
 of
 externalities


all
 the
 other
 things
 that
 data
 center


spending
 in
 turn
 kind
 of
 accelerates
 and


then
 obviously
 the
 same
 thing
 was
 true


in
 the
 second
 quarter
 and
 it
 was
 I
 got


back
 to
 thinking
 about
 my
 dog
 and
 I
 was


my
 analogy
 is
 that


>> as
 one
 does


>> as
 one
 does
 I
 got
 thinking
 like
 my
 dog


barks
 when
 the
 mailman
 comes
 to
 the


house
 and
 keeps
 barking
 and
 then
 the


mailman
 goes
 away
 and
 I'm
 convinced
 he


thinks
 he
 makes
 the
 mailman
 go
 away


[laughter]
 right
 he
 has
 this
 really


screwed
 up
 causality
 and
 it's
 like
 dude


If
 you
 don't
 bark,
 it
 goes
 away
 anyway.


This
 is
 part
 of
 the
 job.
 They
 just
 go


away.
 And
 I
 think
 about
 macro
 policy
 in


the
 same
 way
 that
 if
 you
 don't


understand
 the
 drivers
 of
 GDP
 growth,


you're
 likely
 to
 think
 that
 whatever
 it


is
 you
 would
 most
 like
 to
 be
 causing
 GDP


growth
 is
 doing
 that.
 So
 in
 the
 case
 of


the
 US
 in
 the
 first
 half
 of
 the
 year,


you
 know,
 it
 was
 this
 puzzle
 was
 well


maybe
 it's
 tariffs.
 Maybe
 tariffs
 are


actually
 contributing
 to
 it.
 Maybe


consumers
 are
 much
 more
 resilient
 than


we
 expected.
 And
 as
 it
 turns
 out,
 a
 huge


factor,
 probably
 the
 largest
 factor
 was


this
 sort
 of
 unintentional
 private


sector
 stimulus
 program,
 otherwise
 known


as
 data
 centers.


>> And
 for
 me,
 that
 all
 started
 so
 that


started
 this
 puzzle
 of
 understanding


this
 sort
 of
 discommensurate
 size,
 the


consequences
 of
 that
 size
 and
 the
 the


acceleration's
 consequences
 in
 terms
 of


where
 where
 the
 money's
 coming
 from
 and


all
 sorts
 of
 other
 things.
 But
 just
 to


reframe
 in
 terms
 of
 something
 you
 guys


were
 already
 talking
 about
 and
 this
 I


think
 is
 super
 important
 in


understanding
 why
 this
 particular


episode
 is
 likely
 to
 turn
 out
 to
 be


historically
 really
 important.


>> Wait,
 when
 you
 say
 episode
 you're


referring
 to
 this
 podcast
 episode,


you're
 not
 referring
 to
 the
 broader


episode
 of
 AI
 data
 center.


>> No,
 entirely
 just
 the
 podcast.


[laughter]


>> Who
 cares
 about
 data
 centers
 when
 it's


the
 10
 year
 anniversary
 of
 OddLoga?
 So


the
 reason
 why
 it's
 it's
 sort
 of
 it's


going
 to
 be
 historically
 important
 is


because
 for
 the
 first
 time
 we
 combine


all
 the
 major
 ingredients
 of
 every


historical
 bubbles
 in
 a
 single
 bubble.


We
 have
 a
 meta
 bubble,
 no
 pun
 intended,


for
 meta.
 We
 have
 real
 estate.
 You
 guys


just
 talked
 about
 this,
 right?
 Some
 of


the
 largest
 bubbles
 in
 US
 history
 had


some
 relationship
 to
 real
 estate.
 We


have
 a
 great
 technology
 story.
 Almost


all
 the
 large
 modern
 bubbles
 have


something
 to
 do
 with
 technology.
 We
 have


loose
 credit.
 Most
 of
 the
 major
 bubbles


in
 some
 sense
 have
 a
 loose
 credit


aspect.
 And
 one
 of
 the
 other


exacerbating
 pieces
 that's
 some
 of
 the


largest
 bubbles
 thinking
 about
 even
 the


financial
 crisis
 is
 some
 kind
 of


notional
 government
 backs
 stop.
 You


know,
 think
 about
 the
 role
 in
 terms
 of


broadening
 home
 ownership
 in
 the
 context


of
 the
 real
 estate
 bubble
 and
 the
 role


that
 Fanny
 and
 Freddy
 played
 and


loosening
 credit
 standards
 and
 all
 of


those
 things.
 This
 is
 the
 first
 bubble


that
 has
 all
 of
 that.
 It's
 like
 we
 said,


you
 know
 what
 would
 be
 great?
 Let's


create
 a
 bubble
 that
 takes
 everything


that
 ever
 worked
 and
 put
 it
 all
 in
 one.


And
 this
 is
 what
 we've
 done.
 So
 it's
 got


a
 speculative
 real
 estate
 component.


It's
 probably
 one
 of
 the
 strongest


technology
 stories
 we
 ever
 had.
 Back
 to


rural
 electrification
 in
 terms
 of
 a


technology
 story.
 We
 have
 loose
 credit.


You
 guys
 talked
 about
 what's
 happening


with
 respect
 to


>> not
 just
 the
 role
 of
 private
 credit,
 but


how
 private
 credit
 has
 largely


supplanted
 commercial
 banks
 with
 respect


to
 being
 lenders
 here.
 So
 we
 have
 all
 of


these
 pieces
 that
 have
 all
 come
 together


at
 once.
 And
 I
 think
 in
 terms
 of
 framing


what's
 going
 on
 right
 now,
 it's
 really


important
 to
 understand
 that
 it
 brings


together
 all
 of
 these
 components
 in
 ways


we've
 never
 seen
 before,
 which
 is
 one
 of


the
 reasons
 why
 the
 notion
 that
 we
 can


land
 this
 thing
 on
 the
 runway
 gently
 is


nonsense.


>> I
 love
 that
 framing.
 The
 meta
 bubble
 is


perfect.
 Also,
 I
 had
 an
 epiphany


earlier.
 I
 already
 told
 Joe,
 so
 you
 can


attest
 to
 this,
 but
 I
 realized
 private


credit
 kind
 of
 supplanted
 shadow
 banking


as
 the
 term,
 right?
 Like
 after
 2008
 we


called
 it
 shadow
 banking
 and
 then
 at


some
 point
 it
 flipped
 to
 I
 guess
 the


couplier
 private
 credit.


>> Shadow
 banking
 always
 sounded
 sinister


in
 a
 way
 the
 private
 credit


>> someone
 figured
 that
 out
 and
 they're


like
 well
 now
 it's
 private
 credit.


>> I
 like
 to
 think
 of
 it
 as
 a
 kind
 of


financial
 witness
 protection
 program


[laughter]
 but
 it
 was
 like
 oh
 you're


those
 guys
 I
 understand
 now
 who
 you
 are.


Yeah,
 it's
 kind
 of
 like
 that
 and
 it's


now
 like
 1
 point
 whatever
 it
 is
 $1.7


trillion
 dollars
 is
 the
 size
 of
 which
 is


larger
 than
 you
 know
 many
 components
 of


the
 orthodox
 lending
 market
 combined
 in


terms
 of
 the
 the
 private
 credit
 industry


itself.
 So
 that's
 a
 huge
 new
 piece
 of


this
 that
 sometimes
 escapes
 notice
 how


big
 it
 is
 and
 why
 it
 emerged.
 So
 all
 of


those
 pieces.


>> Yeah,
 it's
 stunning
 the
 growth
 that


we've
 seen.
 Let
 me
 ask
 a
 very
 basic


question
 before
 we
 go
 further.
 But
 one


thing
 I've
 been
 wondering
 is
 Joe


mentioned
 that
 anthropic
 headline
 that


we
 heard
 before.
 We've
 seen
 Meta
 raising


financing
 for
 data
 center
 builds,
 all


that
 stuff.
 Why
 do
 these
 massively


profitable
 and
 cashri
 companies
 have
 to


raise
 financing
 at
 all?


>> Well,
 they
 don't,
 but
 there's
 these


irritating
 shareholders
 out
 there
 who


[laughter]
 get
 all
 pissy
 whenever
 you


start
 diluting
 earnings
 per
 share
 too


much
 and
 diverting
 it
 towards
 a
 single


source.
 Now,
 that's
 not
 the
 case
 with


private
 companies,
 obviously,
 but
 by
 the


same
 token,
 Open
 AAI
 doesn't
 have
 the


luxury
 of
 having
 cash
 flows
 via
 which


they
 can
 do
 any
 of
 the
 things
 we're


describing.
 So
 anthropic
 uh
 open
 AAI
 and


everyone
 else
 they
 have
 no
 option
 other


than
 to
 do
 exactly
 what
 we're


describing.
 It's
 a
 different
 story
 with


respect
 to
 how
 what
 percentage
 of


Google's
 free
 cash
 flow
 or
 Amazon
 free


cash
 flow
 that
 they
 want
 to
 continue
 to


divert
 towards
 data
 centers.
 So
 in
 terms


of
 the
 privates
 this
 is
 the
 only
 option


that
 they
 have.
 The
 public's
 obviously


increasing
 the
 hyperscalers
 increasingly


it
 was
 we
 got
 up
 to
 the
 point
 where


around
 $500
 billion
 around
 50%
 of
 their


free
 cash
 flow
 was
 going
 directly


towards
 spending
 on
 data
 centers.
 And


that's
 obviously
 a
 point
 at
 which
 you


know
 we
 have
 other
 things
 we
 have
 to
 do


with
 free
 cash
 flow
 and
 including
 having


some
 of
 it
 be
 earnings
 per
 share.
 And
 so


increasingly
 it's
 become
 the
 option.
 You


see
 what
 Met
 is
 doing
 recently
 with


respect
 to
 its
 SPVS.
 We
 bring
 in
 other


participants
 create
 new
 financing


vehicles
 and
 then
 we
 play
 this


entertaining
 game
 of
 it's
 not
 really
 our


debt.
 It's
 in
 an
 SPV.
 I
 don't
 have
 to


roll
 it
 back
 onto
 my
 own
 balance
 sheet


and
 then
 bring
 in
 new
 lenders,
 new


private
 credit
 firms
 and
 others.
 And
 so


that's
 the
 reason
 obviously
 it's
 partly


because
 of
 the
 scale.
 It's
 partly


because
 the
 privates
 who
 have
 no
 other


option
 and
 it's
 partly
 we've
 kind
 of


tapped
 out
 the
 public
 companies
 in
 terms


of
 the
 fraction
 of
 free
 cash
 flow
 that


they
 feel
 as
 if
 they
 can
 spend
 with


impunity
 in
 on
 these
 projects.
 explain


to
 us
 for
 those
 who
 don't
 know,
 you


know,
 again,
 SPV
 one
 of
 these
 terms
 that


we
 really
 haven't
 heard
 in
 a
 while
 and


there's
 nothing
 inherently
 bad
 about
 an


SPV
 except
 that
 you
 only
 hear
 about
 them


typically
 after
 there's
 something,
 you


know,
 some
 sort
 of
 crazy,
 right?
 Which


is
 weird
 obviously,
 but
 yes,


>> tell
 how
 would
 you
 in
 the
 broad
 strokes,


how
 would
 you
 characterize
 what
 these


financing
 vehicles
 are?
 So
 mechanically,


it's
 just
 a
 way
 of
 making
 sure
 that
 I


don't
 have
 to
 roll
 debt
 onto
 my
 balance


sheet.
 But
 legally,
 it's
 a
 structure


into
 which
 I
 and
 my
 partners
 contribute


capital
 that
 in
 exchange
 for
 which
 they


retain
 legal
 title
 to
 the
 project
 that


we've
 created,
 which
 allows
 us
 to
 all


contribute
 capital
 to
 this,
 but
 not
 have


to
 put
 it
 back
 on
 my
 balance
 sheet
 and


therefore
 not
 to
 have
 that
 debt
 rated,


which
 is
 really
 the
 key.
 Now,
 if
 you


look
 at
 the
 actual
 intrinsic,
 say
 for


example,
 the
 recent
 meta
 project
 that


they
 did
 in
 conjunction
 with
 Blue
 Owl,


it's
 wild
 in
 Byzantine.
 It
 looks
 like


something
 you
 might
 have
 seen
 in
 what


was
 that
 in
 Harry
 Potter,
 the
 forest


with
 all
 the
 spiderw
 webs.
 It
 looks
 a


little
 like
 that,
 right?
 Where


everything's
 connected
 to
 everything
 and


all
 I
 know
 is
 there's
 something
 in
 here


is
 going
 to
 get
 me.
 So
 there's


incredible
 complexity,
 but
 at
 the
 core


it's
 a
 mechanism
 via
 which
 I
 can
 raise


more
 capital
 and
 keep
 it
 off
 my
 balance


sheet
 by
 creating
 a
 legal
 entity
 that


controls
 the
 actual
 data
 center
 and
 I


don't
 therefore
 have
 to
 put
 it
 back
 roll


it
 all
 back
 onto
 my
 balance
 sheet
 and


have
 it
 rated.
 Now
 there's
 weird


intricacies
 obviously.
 So
 for
 example,


what
 happens
 if
 at
 some
 period
 in
 the


future
 this
 thing
 isn't
 performing
 the


way
 we
 expect?
 Who
 owns
 it
 at
 that


point?
 Is
 there
 a
 payment
 exchange?
 Does


it
 become
 Metas?
 Does
 it
 become
 Blue


Owls?
 Does
 it
 become
 someone
 else?
 And


these
 things
 will
 turn
 out
 to
 matter.


Right
 now,
 no
 one
 cares.
 If
 you
 go


through
 some
 of
 the
 documents
 on
 these


things,
 it's
 not
 entirely
 clear
 what
 the


recourse
 payment
 will
 be
 when
 it
 ever
 if


and
 when
 it
 ever
 has
 to
 revert
 back
 to


another
 owner.
 And
 it's
 not
 going
 to
 be


held
 on
 to
 by
 the
 SPV.
 And
 I
 think
 this


will
 turn
 out
 to
 be
 really
 important


four
 or
 five
 years
 down
 the
 road.
 But


right
 now,
 nobody
 cares.


[music]


[music]


So
 number
 one,
 the
 lifespan
 of
 data


centers
 is
 actually
 not
 that
 long.
 I


can't
 remember
 the
 like
 exact
 estimate


but
 maybe
 like
 three
 or
 four
 years


something
 like
 that
 and
 then
 also
 you


have
 this
 risk
 that
 tenants
 are
 sort
 of


rolling
 through
 and
 no
 one
 knows
 what


that
 actually
 means
 for
 the
 structure
 of


the
 debt
 and
 you
 kind
 of
 get
 this
 asset


liability
 mismatch.


>> Yeah.
 So
 I'll
 start
 with
 the
 first
 one


first.
 So,
 this
 gets
 into
 something


Michael
 Bur
 was
 tweeting
 about
 the
 other


day,
 which
 was
 sort
 of
 entertaining
 that


back
 about
 four
 years
 ago,
 tech


companies
 changed
 the
 depreciation


schedule
 for
 the
 assets
 inside
 of
 data


centers.
 They
 extended
 them
 somewhat.


Now,
 that
 wasn't
 an
 error.
 The
 reality


is
 that
 data
 centers
 used
 for
 the


purposes
 like
 at
 AWS
 where
 you've
 got
 a


big
 S3
 bucket
 and
 I'm
 storing
 data


inside
 of
 it.
 Those
 things
 generally


speaking,
 the
 assets
 are
 longived.
 I'm


not
 running
 them
 flat
 out.
 It's
 not


these
 are
 not
 street
 car
 racers
 that
 I'm


running
 around
 inside
 of
 a
 data
 center.


These
 are
 are
 relatively
 inexpensive


chips
 that
 I'm
 using
 for
 really
 mundane


purposes
 like
 storing
 large
 amounts,


terabytes,
 exabytes
 of
 data
 inside
 of
 S3


buckets.
 So,
 it's
 not
 unreasonable
 to


say
 their
 lifespans
 fairly
 long.
 They're


not
 being
 taxed
 that
 heavily.
 So,


pushing
 out
 the
 the
 depreciation


schedule
 makes
 a
 lot
 of
 sense.
 But
 that


was
 coincident
 with
 the
 emergence
 of


GPUdriven
 data
 centers
 using
 products


like
 chips
 from
 Nvidia


>> and
 those
 have
 much
 shorter
 lifespans.


So
 depending
 on
 the
 usage.
 So
 there's


two
 different
 reasons
 why
 the
 lifespan


and
 therefore
 the
 depreciation
 schedule


of
 a
 GPU
 inside
 of
 a
 data
 center
 is
 very


different.
 So
 the
 reason
 most
 people


think
 about
 is
 oh
 well
 technology


changes
 really
 quickly
 and
 I
 want
 to


have
 the
 latest
 and
 greatest
 and


therefore
 I'm
 going
 to
 have
 to
 upgrade


all
 the
 time.
 That's
 important
 but
 it's


probably
 about
 equal
 if
 not
 maybe


slightly
 less
 important
 than
 the
 nature


of
 how
 the
 chip
 is
 used
 inside
 the
 data


center.
 So
 when
 you
 run
 using
 like
 the


latest
 say
 an
 Nvidia
 chip
 for
 training
 a


model,
 those
 things
 are
 being
 run
 flat


out
 24
 hours
 a
 day,
 seven
 days
 a
 week,


which
 is
 why
 they're
 liquid
 cooled.


They're
 inside
 of
 these
 giant
 centers


where
 one
 of
 your
 primary
 problems
 is


keeping
 them
 all
 cool.
 It's
 like
 saying,


"I
 bought
 a
 used
 car
 and
 I
 don't
 care


what
 it
 was
 used
 for."
 Well,
 if
 it
 turns


out
 it
 was
 used
 by
 someone
 who
 was
 doing


like
 Lulu
 man's
 24
 hours
 of
 endurance


with
 it,
 that's
 very
 different
 even
 if


the
 mileage
 is
 the
 same
 as
 someone
 who


only
 drove
 it
 to
 church
 on
 Sundays,


right?
 These
 are
 very
 different


consequences
 with
 respect
 to
 what's


called
 the
 thermal
 degradation
 of
 the


chip.
 The
 chip's
 been
 run
 hot
 and
 flat


out.
 So
 it
 probably
 it's
 it
 useful


lifespan
 might
 be
 on
 the
 order
 of
 two


years,
 maybe
 even
 18
 months.
 So
 there's


a
 huge
 difference
 in
 terms
 of
 how
 the


chip
 was
 used
 leaving
 aside
 whether
 or


not
 there's
 a
 new
 generation
 of
 what's


come
 along.
 So
 it
 takes
 us
 back
 to
 these


depreciation
 schedules.
 So
 these


depreciation
 schedules
 change
 just
 as


the
 nature
 of
 how
 the
 lifespan
 of
 the


chips
 change
 dramatically
 because
 I
 can


use
 something
 for
 you
 know
 storing


things
 in
 S3
 buckets
 for
 a
 long
 time
 six


to
 eight
 years
 isn't
 unreasonable
 but
 if


I'm
 doing
 the
 the
 the
 lemons
 endurance


equivalent
 with
 a
 GPU
 it
 might
 be
 18


months
 that's
 a
 huge
 difference
 in
 terms


of
 the
 likely
 lifespan
 of
 a
 product
 that


I'm
 depreciating
 over
 a
 very
 different


period
 and
 so
 that's
 a
 huge
 part
 of
 the


problem
 here
 with
 respect
 to
 you
 know


understanding


the
 intrinsics
 in
 terms
 of
 how
 data


centers
 can
 and
 can't
 make
 money,
 how


they
 how
 you
 have
 to
 think
 about
 the


likely
 capex
 requirements
 because
 of


this
 much
 shorter
 lifespan
 of
 the


underlying
 technology.


>> And
 then
 talk
 about
 the
 tenency
 rollover


risk
 I
 guess
 we
 might
 call
 it.


>> Yeah,
 it's
 really
 interesting.
 So
 one


way
 to
 to
 think
 about
 data
 centers
 is
 as


giant
 apartment
 buildings,
 right?


They're
 essentially
 gigantic
 commercial


pieces
 of
 commercial
 real
 estate
 with
 a


bunch
 of
 tenants.
 Sometimes
 there's
 a


lot
 of
 tenants,
 sometimes
 there's
 only


one.
 Sometimes
 Google
 bought
 the
 whole


apartment
 building
 and
 just
 moved
 in
 or


this
 a
 giant
 office
 building
 they
 just


moved
 in.
 It's
 all
 theirs,
 right?
 So


think
 about
 it
 in
 those
 sorts
 of
 terms.


And
 the
 reason
 why
 as
 a
 sponsor
 of
 a


data
 center
 I
 might
 take
 a
 different


view
 on
 how
 many
 tenants
 I
 want
 is
 again


you
 think
 about
 it
 in
 terms
 of
 what
 can


I
 get
 Google
 to
 pay
 what
 can
 I
 get


someone
 who's
 a
 much
 flightier
 tenant
 to


pay.
 Well,
 I
 can
 get
 the
 flightier


tenants,
 more
 of
 them
 and
 diversified
 as


all
 leasing
 inside
 the
 data
 center


paying
 higher
 lease
 rates
 for
 GPUs
 over


the
 period
 of
 tenency
 than
 I
 can
 get
 a


Google
 to
 pay.
 Why?
 Because
 Google's
 got


great
 credit.
 They
 don't
 have
 to
 pay


very
 much
 and
 they
 know
 they
 don't.
 So,


if
 you
 look
 at
 the
 commercial
 real


estate
 data,
 the
 cap
 rate,
 the
 blended


cap
 rate
 for
 these
 for
 the
 largest
 data


centers
 that
 are
 tended
 by
 hyperscalers


is
 horrible.
 It's
 like
 4.8
 5.3%.
 It's


like
 a
 why
 don't
 you
 just
 buy
 a


treasury?
 What
 the
 hell
 are
 you
 doing?


So
 what
 happens
 then
 is
 people
 start


blending
 in
 more
 different
 kinds
 of


tenants
 to
 Tracy's
 point
 as
 an
 effort
 to


try
 and
 improve
 the
 yield
 the
 cap
 rate


on
 the
 underlying
 instrument
 which
 is


the
 data
 center.
 So
 what
 you
 could
 all


of
 this
 should
 start
 to
 sound
 familiar


because
 it's
 this
 idea
 of
 if
 I
 blend


together
 all
 of
 these
 different


tendencies
 I
 can
 increase
 the
 yield
 of


the
 securitized
 instrument
 but
 that
 also


changes
 the
 risk
 profile
 of
 what
 comes


out
 the
 other
 end
 which
 is
 takes
 us
 to


things
 like
 the
 increasing
 um
 usage
 of


these
 things
 in
 asset
 back
 securities


which
 are
 these
 tanch
 securities
 that


have
 all
 the
 different
 pieces.
 We
 have


different
 layers
 associated
 with
 it
 and


that's
 a
 reflection
 of
 well
 there's


different
 tenants
 inside
 these
 data


centers
 and
 people
 want
 different


exposures
 to
 risks
 so
 I
 may
 only
 want
 to


buy
 the
 senior
 trunch
 you
 may
 want
 to


buy
 the
 mezzanine
 and
 Tracy
 may
 want
 to


buy
 the
 equity
 tranch


>> can
 I
 just
 say
 I
 know
 we
 already
 said


this
 but
 Paul
 is
 truly
 truly
 the
 perfect


guest


>> I
 remember
 reading
 his
 coverage
 of


subprime
 and
 securization
 in
 like
 2008


and
 so
 having
 someone
 who's
 able
 to


synthesize


That
 experience
 with
 what's
 going
 on
 now


is
 just
 fantastic.


>> I
 kind
 of
 can't
 believe
 we're
 doing
 this


again.
 I
 mean,
 look,
 I
 mean,
 again,


there's
 nothing
 inherently
 wrong
 with


SPVS.
 There's
 nothing
 inherently
 wrong


with
 tunching,
 right?
 Like
 a
 lot
 of


these
 things
 are
 very
 intuitive,
 etc.


But


>> it
 is
 still
 a
 little
 weird
 how
 central


this
 is
 and
 how
 it's
 the
 same
 old


there's
 nothing
 new.
 I
 mean,
 some
 on


some
 financial
 level,
 it
 feels
 very


familiar.


>> No,
 there's
 there's
 nothing
 new
 under


the
 sun.
 And
 uh
 but
 I
 think
 that
 point's


really
 important.
 It's
 not
 that
 tanches


are
 evil.
 It's
 not
 that
 securitization


is
 evil
 or
 that
 asset
 back
 security
 or


project
 finance
 is
 evil.
 No.
 No.
 All
 of


these
 things
 are
 terrific
 pieces
 of
 uh


you
 know
 of
 the
 arsenal
 whenever
 you're


actually
 raising
 money
 for
 projects.
 The


issue
 start
 to
 arise
 at
 the
 scale
 which


is
 what
 you
 guys
 have
 already
 alluded


to.
 But
 the
 secondary
 piece
 which
 again


will
 sound
 painfully
 familiar
 to
 the


financial
 crisis
 is
 there's
 a
 flywheel


that
 gets
 created
 at
 the
 back
 end
 of


this.
 So
 once
 you
 start
 securitizing
 the


yield
 producing
 assets
 in
 the
 form
 of


these
 TR
 securities,
 the
 people
 who
 are


purchasing
 those
 things
 don't
 give
 a


rat's
 ass
 what's
 going
 on
 inside
 this


AI.
 I
 I
 joke
 all
 the
 time
 that
 a
 lot
 of


these
 people
 can't
 spell
 AI.
 They
 don't


care
 what's
 going
 on
 inside
 the
 data


center,
 right?
 It
 could
 be,
 you
 know,


the
 world
 hideand
 go
 seek
 championships


going
 on
 in
 there.
 I
 don't
 care
 as
 long


as
 it
 generates
 yield
 and
 I
 can


securitize
 it.
 Well,
 that's
 very
 much


analogous
 to
 what's
 happened
 in
 prior


periods
 like
 this
 where
 again
 you
 get


this
 secondary
 flywheel
 effect
 of
 let's


just
 create
 more
 of
 these
 things
 because


our
 customers
 want
 more
 and
 it's
 they're


really
 easy
 to
 securitize
 and
 look
 it's


backed
 up
 by
 Meta
 and
 Google
 or
 whoever


else.


>> Well,
 so
 this
 actually
 brings
 an


important
 point.
 I
 mentioned
 this
 great


report
 out
 from
 the
 center
 for
 public


enterprise.
 One
 of
 the
 things
 that
 they


pointed
 out
 is
 in
 this
 market


environment
 where
 everyone
 is
 just
 be


you
 know
 there's
 this
 sort
 of
 AI
 pixie


dust
 that
 if
 you
 but
 also
 just
 the


reality
 if
 your
 revenues
 are
 surging
 the


market
 probably
 loves
 you


>> like
 talk
 to
 us
 about
 the
 unit
 economics


here
 like
 is
 the
 incentive
 for
 all
 the


players
 essentially
 to
 just
 grow
 the
 top


line
 as
 much
 as
 possible
 even
 if
 these


aren't
 whether
 we're
 talking
 about


inference
 on
 a
 per
 token
 basis


even
 if
 these
 aren't
 particularly


profitable,
 how
 are
 you
 thinking
 about


the
 unit
 economics
 of
 some
 of
 these


businesses
 and
 how
 that
 could
 eventually


perhaps
 sort
 of
 um
 you
 know
 come
 home
 to


roost
 so
 to
 speak.


>> Yeah.
 So


the
 term
 of
 art
 obviously
 is
 these


things
 have
 negative
 unit
 economics


which
 is
 a
 fancy
 way
 of
 saying
 that
 we


lose
 money
 on
 every
 sale
 and
 try
 to
 make


it
 up
 on
 volume,
 right?
 I
 mean
 that's


the


>> that's
 the
 problem
 here.
 So
 but
 that's


okay.
 I
 mean
 we've
 had
 lots
 of
 things.


Amazon
 in
 its
 early
 days
 had
 negative


unit
 economics.
 We
 can
 you
 can
 get
 past


that.
 And
 as
 an
 aside,
 I'll
 say
 right


here,
 all
 of
 the
 things
 I'm
 saying
 isn't


to
 say
 that,
 you
 know,
 AI
 is
 some
 kind


of,
 you
 know,
 furry
 Tamagotchi
 thing


that's
 just
 a
 fad.
 AI
 is
 an
 incredibly


important
 technology.
 What
 we're
 talking


about
 is
 how
 it's
 funded
 and
 the


consequences
 of
 doing
 that
 in
 terms
 of


what's
 going
 to
 happen
 with
 respect
 to


the
 businesses
 and
 the
 return
 on
 those


businesses,
 right?
 So
 the
 unit
 economics


are
 dire
 for
 a
 bunch
 of
 reasons
 mostly


having
 to
 do
 with
 the
 more
 tokens
 you


have
 to
 produce
 the
 costs
 rise
 more
 or


less
 linearly
 with
 the
 demand
 on
 the


system
 as
 opposed
 to
 an
 orthodox


software
 business
 where
 the
 more
 people


who
 use
 my
 service
 the
 more
 people


across
 which
 I
 can
 spread
 my
 relatively


fixed
 costs.


>> Yeah,


>> that's
 not
 the
 way
 that
 for
 the
 most


part
 current
 generation
 large
 language


models
 work.
 costs
 rise
 linearly
 or


sublinearly
 with
 the
 number
 of
 users


which
 makes
 for
 really
 crappy
 unit


economics
 and
 that's
 a
 big
 part
 of
 the


problem.
 So,
 so
 from
 there
 you
 get
 to


the
 question
 of
 okay,
 so
 what
 does
 it


have
 to
 look
 like
 in
 terms
 of
 making
 it


look
 profitable?
 There's
 lots
 of
 ways
 to


back
 into
 this.
 You
 can
 do
 bottoms
 up


models
 that
 would
 suggest
 that
 like
 if


every
 iPhone
 user
 on
 Earth
 paid
 50
 bucks


that
 would
 work.
 We
 could
 have
 around
 a


$400
 billion
 $500
 billion
 annual
 stream


of
 revenue
 flowing
 and
 well
 that's
 not


going
 to
 happen
 but
 it's
 worth
 pointing


out
 like
 that
 would
 do
 it
 but
 it
 gives


you
 a
 sense
 of
 the
 kind
 of
 scale


>> of
 what
 at
 a
 consumer
 level
 for
 example


it
 might
 have
 to
 look
 like.
 People
 come


at
 it
 from
 the
 other
 end.
 One
 of
 my


favorite
 ways
 that
 people
 come
 at
 it
 is


to
 say,
 "Well,
 we
 could
 create
 a
 viable


model
 here."
 If
 you
 think,
 this
 was
 in


the
 JPM
 call
 last
 week.
 I
 don't
 know if


you
 guys
 saw
 the
 summary
 of
 it,
 but
 it


was
 huge
 fun
 for
 the
 whole
 family


listening
 in.
 [laughter]
 Um,
 so
 one
 of


the
 ways
 they
 backed
 into
 it
 was
 a
 top-


down
 model
 where
 they
 said,
 "Well,
 the


global
 TAM
 for
 human
 labor
 [laughter]


trillion
 dollars."


>> I
 love
 the
 global
 TAM.
 I
 said
 that
 was


right
 up
 there
 with
 saying
 like,
 if
 I


reduce
 humans
 to
 their
 chemical


components,
 here's
 what
 I
 can
 get
 for


you.
 Well,
 this
 was
 this
 was
 Steve


Eisman's
 line
 which
 was
 like
 beware
 of


anyone
 that
 mentions
 Tam.


>> Right.
 Right.
 Right.
 No.
 Exactly.
 And
 so


then
 and
 then
 they
 play
 the
 next
 step
 is


of
 course
 to
 say
 well
 imagine
 we
 can
 get


10%
 of
 that.
 Right.
 Which
 is
 which
 is


obviously
 one
 of the
 oldest
 cliches.


It's
 like
 saying
 you
 know
 I'm
 going
 to


get
 5%
 of
 the
 Chinese
 market.
 No
 one


ever
 gets
 5%
 of
 the
 Chinese
 market.
 It


doesn't
 happen.
 So
 the
 same
 thing
 won't


happen
 with
 global
 labor.
 But
 if
 you


were
 to
 do
 you
 do
 the
 math
 on
 that
 that


co
 those
 kinds
 of
 numbers
 get
 you
 to
 on


a
 weighted
 average
 cost
 of
 capital
 basis


to
 a
 reasonable
 return
 on
 current
 and


planned
 expenditures
 with
 respect
 to
 AI


data
 centers
 if
 you
 assume
 we're
 heading


to
 about
 a
 three
 or
 four
 trillion
 dollar


number
 which
 is
 kind
 of
 the
 I
 think
 it's


around
 the
 number
 that
 most
 people
 put


out
 there
 which
 I
 think
 is
 a
 completely


wrong
 number
 but
 nevertheless
 that's
 the


kind
 of
 number
 and
 what
 you'd
 have
 to
 do


to
 get
 there.
 You
 can
 get
 there
 from
 a


bottoms
 up
 model
 by
 making
 some
 really


unreasonable
 assumptions
 about
 the
 total


numbers
 of
 subscribers
 and
 what
 they


pay.
 You
 can
 get
 there
 from
 a
 top-
 down


model.
 You
 can
 also
 get
 there
 by


thinking
 about
 it
 purely
 in
 terms
 of


industrial
 users.
 Like
 think
 about


purely
 API
 users.
 Let's
 pretend
 retail


users
 of
 AI
 don't
 exist
 and
 say
 you
 know


anthropics
 projecting
 70
 billion
 dollars


in
 revenue
 in
 2028.
 something
 like
 35%


of
 their
 current
 revenues.
 Most
 of
 their


revenues
 today
 are
 from
 their
 API.
 35%


of
 that
 is
 from
 software
 developers.


That's
 split
 between
 two
 large
 users,


co-pilot
 and
 cursor.
 And
 so,
 you
 know,


we
 can
 model
 that
 out.
 Everybody
 has
 to


become
 a
 software
 developer.
 And
 we
 can


make
 the
 math
 work.
 The
 problem
 is
 it's


got
 huge
 fragility,
 right,
 in
 customer


concentration
 risk.
 So
 a
 cursor


disappears
 as
 a
 user
 of
 Enthropics
 API


and
 you
 just
 blew
 out
 15%
 of
 your
 of


your
 revenues
 because
 they're
 gone
 and


they've
 done
 something
 else.
 And
 as
 it


turns
 out,
 cursor
 two
 weeks
 ago


announced
 that
 they
 were
 creating
 their


own
 internal
 model
 that
 you
 could
 use


for
 software
 development.
 You
 wouldn't


have
 to
 call
 the
 entropic
 API.
 So
 you


can
 think
 about
 all
 these
 different
 ways


to
 get
 there,
 but
 they
 all
 have
 a
 lot
 of


built-in
 fragility
 with
 respect
 to


either
 we
 all
 become
 software
 developers


and
 we
 all
 subscribe
 to
 cursor.


Just
 going
 back
 to
 the
 used
 car
 analogy


that
 you
 mentioned
 before
 when
 we're


thinking
 about
 all
 this
 financing
 of
 the


AI
 capex
 spend
 is
 it
 useful
 to
 think
 of


GPUs
 essentially
 as
 the
 collateral


[sighs and gasps]


>> there
 the
 problem
 yes


>> or
 what
 would
 you
 call
 the
 collateral
 in


this
 case


>> so
 what
 ends
 up
 happening
 the
 collateral


in
 this
 case
 is
 the
 GPU
 there's
 no


question
 it
 is
 the
 GPU
 the
 issue
 is
 the


this
 disconnect
 this
 temporal
 mismatch


that
 you
 alluded
 to
 earlier
 with
 respect


to
 the
 duration
 of
 the
 underlying
 debt


and
 the
 assets
 that
 are
 producing
 the


income
 that
 allows
 me
 to
 pay
 for
 the


debt.
 Right?
 So,
 we've
 got
 this
 probably


unprecedented
 temporal
 mismatch
 with


30-year
 loans
 and
 two-year
 depreciation


on
 the
 underlying
 collateral,
 which
 is


essentially
 the
 GPUs
 that
 are
 the


incomeroucing
 assets.
 Um,
 and
 so
 that


creates
 this
 constant
 refinancing
 risk


because
 I'm
 going
 to
 continually
 have
 to


turn
 over
 the
 base.
 And
 we've
 seen
 this


many,
 many
 times.
 Right
 now,
 it's
 easy


to
 turn
 it
 over,
 but
 in
 two
 years
 it
 may


not
 be
 possible.
 There's
 a
 wave
 of


refinancings
 coming
 in
 2028
 in
 many
 of


the
 more
 speculative
 data
 centers.
 Will


they
 be
 able
 to
 turn
 over
 their
 debt
 and


refinance
 all
 the
 GPUs?
 Today
 they


could,
 but
 today
 isn't
 2028.
 So
 that's


the
 inherent
 problem
 is
 this
 structural


temporal
 mismatch
 between
 the


incomeroucing
 assets
 and
 the
 duration
 of


the
 loans.
 And
 it
 gets
 worse
 if
 you


think
 about
 it
 in
 more
 holistic
 terms.


Think
 about
 it
 in
 terms
 of
 one
 of
 the


other
 gating
 factors
 here
 that's
 driving


all
 of
 this
 is
 the
 scarcity
 of
 energy


supply.
 It's
 really
 difficult.


>> You
 can
 hook
 them
 up
 to
 the
 Well,
 it's


actually
 kind
 of
 turned
 into
 a
 bit
 of
 a


joke.
 I
 can
 hook
 you
 up
 to
 the
 grid,
 but


I
 can't
 give
 you
 power.
 I
 don't
 know if


you
 saw
 the
 recent
 episode
 with
 the


Oregon
 Public
 Utilities
 Commission.


Amazon
 had
 three
 data
 centers
 that
 they


connected
 to
 the
 grid
 and
 it
 was
 kind
 of


like
 the
 Oregon
 PUC
 said,
 "Oh,
 you
 want


power,
 too?
 Oh,
 [laughter]
 wow.
 We
 can't


help
 you
 with
 we
 can't
 help
 you
 with


that."
 So,
 now
 there's
 a
 complaint
 in
 at


the
 Oregon
 PUC
 from
 ADS,
 Amazon,
 the


digital
 services
 group
 that
 runs
 AWS


complaining
 that
 we
 now
 have
 data


centers,
 but
 we
 have
 no
 power,
 right?
 It


sounds
 a
 little
 bit
 like
 like
 a
 winter


storm
 hazard
 or
 something
 but
 it's
 a


structural
 problem
 with
 respect
 to
 the


inability.
 We
 can
 connect
 people
 but
 we


can't
 provide
 them
 with
 power.
 So
 the


next
 stage
 is
 and
 this
 takes
 best
 back


to
 the
 collateral
 problem
 and
 the


temporal
 mismatch
 is
 that
 people
 are


doing
 behind
 the
 meter
 power.
 They're


building
 natural
 gas
 or
 if
 you're
 fairmy


you're
 saying
 wild
 things
 about
 nuclear


power
 and
 you're
 saying
 okay
 I'm
 coming


with
 my
 own
 power.
 You
 don't
 need
 to


connect
 me
 to
 the
 grid
 because
 I'm
 going


to
 power
 this
 myself.
 That
 creates,
 you


know,
 two
 or
 three
 different
 issues,
 but


among
 the
 more
 important
 is
 think
 about


how
 longived
 an
 asset,
 a
 natural
 gas


plant
 is.
 This
 is
 not
 something
 that's


got
 a
 fiveyear
 lifespan
 and
 we
 just


cheerily
 wave
 goodbye.
 This
 is
 going
 to


be
 running
 probably
 25
 to
 30
 years.
 And


the
 only
 thing
 you
 your
 ability
 to


forecast,
 we
 know
 the
 cost
 of
 the


natural
 gas
 plant,
 but
 in
 terms
 of
 the


cost
 of
 the
 center
 and
 its
 income


ability
 to
 generate
 enough
 income
 to
 pay


off
 the
 loan
 associated
 with
 the
 natural


gas
 plant,
 God
 help
 you
 if
 you
 think
 you


can
 sort
 that
 out
 because
 what
 you've


really
 got
 is
 a
 huge
 likelihood
 of
 a


stranded
 asset
 out
 there.
 Natural
 gas


plants
 that
 are
 no
 longer
 useful
 for


powering
 these
 things
 that
 they
 [music]


were
 built
 for.


>> [music]


[music]


>> The
 good
 news
 is
 that
 Daniel
 Jurgen
 said


this
 on
 the
 show.
 You
 know
 the
 back


orders
 for
 natural
 gas
 turbines
 like
 you


probably
 if
 you
 ordered
 one
 today
 you


would
 probably
 get
 it
 in
 2030.
 So
 the


good
 news
 I
 suppose
 10
 years
 is
 that
 at


least
 you
 [laughter]
 don't
 have
 to
 have


the
 turbine
 sitting
 there
 for
 years
 like


I
 don't
 know
 it's
 may
 I
 don't
 know if


that's
 good
 news
 at
 all
 but
 there
 are


you
 may
 never
 get
 it
 anyway


>> you
 may
 never
 get
 the
 gas
 plant
 built


anyway
 someone
 will
 be
 stuck
 with
 the


bill


>> but
 it
 kind
 of
 raises
 this
 goes
 back
 to


Tracy's
 question
 earlier
 this
 raises
 a


really
 interesting
 thing
 so
 like
 like


honestly
 what
 the
 f
 are
 all
 these
 people


doing
 who
 are
 announcing


>> these
 giant
 funding
 trans
 I
 think
 of
 it


like
 people
 all
 showing
 up
 at
 the
 okay


coral
 at
 once
 and
 it's
 like
 dude
 over


there
 has
 one
 gun
 and
 I
 got
 two.


>> Yeah,


>> that
 guy's
 got
 Oh,
 two.


>> That's
 not
 a
 knife.
 This
 is
 a
 knife.


>> Oh,
 yeah.
 But
 but
 it's
 this
 deterrence.


It's
 this
 deterrence
 program
 that's


going
 on.
 Don't
 even
 imagine
 spending
 50


because
 I'm
 spending
 a
 hundred.


>> There's
 no
 point
 in
 you
 doing
 any
 of


this.


>> It's
 this
 game
 theoretic.


>> Well,
 this
 also
 worries
 me
 because
 you


hear
 so
 many
 people
 framing
 this
 as
 like


an
 existential
 competition,
 right?
 And


once
 you
 start
 calling
 something


existential,


the
 limit
 on
 spend,
 well,
 it
 becomes


unlimited,
 right?
 It's
 about
 survival,


so
 you'll
 spend
 anything.


>> That's
 why
 the
 conversation
 has
 turned


in
 recent
 weeks
 to
 the
 one
 entity
 that


actually,
 at least
 in
 theory,
 can
 print


as
 much
 money
 as
 possible,


>> right?
 That's
 the,
 you
 know,
 the
 Sarah


Friars
 accidental
 footed
 mouth
 thing


earlier
 the
 week.
 But
 that's
 right.
 But


that's
 again
 goes
 back
 to
 my
 original


point
 about
 what
 makes
 this
 bubble


unusual.
 It's
 that
 the
 this
 element
 that


not
 only
 is
 there
 a
 kind
 of
 bag
 stop,


but
 there's
 actually
 a
 notion
 of


wrapping
 it
 in
 the
 flag.
 We
 have
 to
 win


this
 competition.
 We
 have
 to
 do
 what
 it


takes.
 This
 is
 existential.
 It's
 us


versus
 China.
 And
 it's
 not
 just
 the
 US


doing
 this.
 I
 was
 talking
 to
 some


Canadian
 policy
 makers
 just
 earlier
 this


morning.
 Exact
 same
 thing
 going
 on


there.
 We
 have
 to
 build
 out
 a
 domestic


indust.
 Same
 thing
 in
 the
 UK.
 Same
 thing


in
 Germany.
 And
 so
 there's
 this
 idea


around
 the
 world
 that
 sovereign
 AI
 is


something
 that's
 incredibly
 important.


So
 this
 this
 government
 backs
 stop
 isn't


just
 mythic.
 It's
 it's
 global.
 It's
 this


idea
 that
 we
 all
 have
 to
 win.
 we
 all


have
 to
 win
 which
 obviously
 can't
 happen


but
 that
 the
 government's
 playing
 a
 role


in
 it
 that
 be
 creates
 this
 kind
 of


limitless
 source
 of
 capital


>> you
 know
 so
 one
 of
 the
 things
 that's


going
 on
 and
 maybe
 it's
 part
 of
 the
 same


the
 sort
 of
 maximalist
 strategy


mentioned
 anthropic
 wants
 to
 get
 into


data
 centers
 so
 everyone's
 sort
 of


looking
 at
 how
 they
 can
 expand


vertically
 can
 I
 own
 the
 data
 centers
 I


think
 you
 know
 Sam
 Alman
 has
 talked


about
 owning
 chips
 or
 owning
 a


semiconductor
 fab
 at
 some
 point
 like


maybe
 that'll
 be
 part
 of
 the
 story.
 Who


knows?
 There's
 one
 thing
 that
 I
 don't


I'm
 sort
 of
 curious.
 I'd
 love
 to
 have


your
 take
 on.
 There
 was
 at
 the
 end
 of


September,
 Meta
 announced
 a
 deal
 to
 buy


compute
 from
 Coreweave,
 one
 of
 these
 neo


clouds.


>> I
 don't
 totally
 get
 that
 because
 Meta


has
 its
 own
 data
 centers,
 etc.
 Do
 you


have
 some
 intuitive
 sense
 about
 what
 an


established
 hyperscaler
 needs
 a
 neocloud


for
 in
 this
 arrangement?
 What
 core
 can


supply
 that
 Meta
 can't
 provide,
 build
 on


its
 own
 or
 buy
 on
 its
 own?
 nothing.


[laughter]


So
 that's
 the
 answer.
 So
 here's
 what's


going
 on.
 This
 is
 what's
 going
 on
 is


that
 there's
 this
 form
 of
 hoarding
 going


on.
 So
 what's
 happening
 is
 is
 people


saying
 you
 have
 capacity.
 I
 can
 lock


that
 up.
 I'll
 lock
 that
 up.
 And
 because


I
 can't
 lock
 it
 up
 yet
 by
 building
 a


data
 center
 quickly
 enough,
 I'll
 lock
 it


up
 in
 the
 marketplace.
 So
 once
 you
 start


thinking
 of
 compute
 as
 a
 hoardable


commodity
 and
 what
 people
 are
 doing
 is


trying
 to
 hoard
 it,
 control
 it
 before


someone
 else
 can
 do
 it
 because
 until


they
 bring
 on
 their
 own
 excess
 capacity,


that's
 really
 what's
 going
 on
 in
 a
 lot


of
 these
 transactions.
 This
 is
 a
 way
 of


making
 sure
 that
 I
 may
 not
 need
 this
 but


you
 sure
 can't
 have
 it.
 And
 so
 there's
 a


there's
 an
 element
 of
 compute
 hoarding


going
 on
 across
 the
 map
 because
 of
 you


know
 this
 backlog
 in
 building
 data


centers
 that
 may
 or
 may
 not
 ever
 get


built.
 So
 that's
 the
 answer.
 The
 answer


isn't
 that
 they
 care
 at
 all
 about


whether
 or
 not
 they
 can
 run
 giant


workloads
 on
 any
 particular
 neocloud


provider.
 It's
 the
 idea
 of
 hoarding


capacity
 and
 making
 sure
 that
 no
 one


else
 can
 have
 it
 like
 trying
 to
 like
 the


Hunt
 brothers
 and
 the
 getting
 a
 corner


on
 the
 silver
 market.


>> You
 know,
 I
 want
 to
 go
 back
 to
 China


because
 it
 is
 true
 that
 the
 US
 and
 China


seem
 locked
 in
 this
 existential
 race
 for


AI
 supremacy,
 but
 they
 seem
 to
 be
 taking


very
 different
 approaches
 to
 it.
 And
 in


the
 US,
 it's
 all
 about
 spending
 as
 much


money
 as
 you
 can
 developing
 these,
 you


know,
 state-of-the-art,
 mostly
 closed


source
 models.
 Whereas
 in
 China,
 it


seems
 to
 be
 much
 more
 about
 rapid


adoption
 and
 creating
 open-source
 models


that
 just
 get
 out
 into
 the
 market
 much


faster
 and
 much
 more
 cheaply.
 And
 so
 I'm


curious
 like
 which
 of
 those
 approaches


do
 you
 think
 is
 going
 to
 win
 here?


>> Yeah.
 So
 that
 that's
 a
 really
 good


question.
 So


I
 think
 it's
 going
 to
 be
 something


closer
 to
 the
 Chinese
 approach
 but
 not


for
 the
 reasons
 they
 expect.
 So
 the


reason
 is
 because
 so
 what
 let's
 I I'll


reframe
 what
 the
 Chinese
 are
 doing


slightly.
 So
 I'll
 say
 that
 instead
 of
 it


just
 being
 a
 sort
 of
 an
 example
 of
 open


source.
 I
 don't
 think
 that's
 the
 right


the
 right
 way
 to
 think
 about
 it
 is


they're
 using
 this
 kind
 of
 distillation


approach
 increasingly
 where
 there's
 kind


of a
 you
 think
 about
 it
 like
 okay
 I'm
 a


sales
 manager.
 I
 don't
 want
 to
 train
 all


my
 sales
 people.
 I'm
 going
 to
 train
 this


dude
 and
 they're
 going
 to
 train
 all
 the


sales.
 That's
 distillation
 right?
 You


train
 the
 trainer.
 I
 train
 somebody
 who


trains
 something
 else
 and
 the
 something


else
 in
 this
 case
 are
 these
 smaller


models.
 So
 that
 approach
 of
 kind
 of


training
 the
 trainer
 really
 speeds
 up


the
 process
 of
 creating
 new
 models


because
 I
 distill
 them.
 I
 train
 them
 out


of
 out
 of
 other
 models
 that
 are
 really


computensive
 like
 anthropics
 or
 open
 AIS


or
 whomever
 else
 is
 right.
 The
 notion
 is


so
 is
 there
 are
 huge
 efficiency
 gains
 to


be
 had
 in
 training
 and
 ch
 the
 Chinese


are
 showing
 the
 huge
 efficiency
 gains
 to


be
 had.
 And
 one
 way
 to
 think
 about
 it
 is


that
 the
 transformer
 models
 that
 underly


large
 language
 models
 that
 are
 so


computationally
 intensive
 went
 from
 the


lab
 to
 the
 market
 faster
 than
 any


product
 in
 technology
 history.
 So


they're
 absolutely
 bloated
 and
 full
 of


crap.
 Right?
 So
 these
 things
 are
 wildly


inefficient.
 There's
 all
 kinds
 of
 other


ways
 to
 do
 the
 same
 sorts
 of
 things.
 one


of
 which
 is
 distillation.
 So
 what
 you're


really
 seeing
 is
 a
 kind
 of
 an
 accident


of
 history
 that
 we
 came
 down
 the
 US
 came


down
 this
 path
 that
 led
 directly
 out
 of


the
 the
 original
 transformer
 paper
 in


2017
 and
 the
 Chinese
 have
 said
 yeah


we're
 not
 going
 to
 be
 able
 to
 do
 that


for
 a
 bunch
 of
 different
 reasons
 but
 we


don't
 have
 to
 do
 that
 because
 I
 can
 take


this
 approach
 of
 distillation
 which
 lets


us
 get
 you
 if
 you
 look
 at
 Kimmy
 this


sort
 of
 relatively
 recent
 open
 source


these
 things
 are
 actually
 really


effective
 and
 benchmark
 very
 well
 and


it's
 not
 surprising
 because
 they've
 been


trained
 by
 really
 good
 trainers
 which
 is


to
 say
 some
 of
 the
 other
 models
 that
 are


out
 there.
 But
 it's
 these
 are
 about


efficiency
 gains,
 which
 should
 then
 ask


the
 next
 question
 is
 whoa,
 wait
 a


minute.
 If
 there's
 all
 these
 efficiency


gains
 ahead
 from
 training
 and
 training


is
 70%
 of
 the
 workload
 on
 data
 centers,


hang
 on
 a
 second,
 aren't
 we
 completely


misforing
 the
 likely
 future,
 the
 arc
 of


demand
 for
 compute?
 And
 the
 answer
 is


yes.
 And
 this
 is
 rather
 than
 looking
 at


it
 as
 an
 example
 of
 why
 China
 is
 doing


something
 better
 for
 worse.
 Another
 way


of
 looking
 at
 it
 is
 saying
 this
 just


refuted
 the
 approach
 that
 we're
 taking


to
 training
 altogether
 because
 it
 shows


how
 bloated
 and
 inefficient
 the
 approach


we're
 taking
 is
 and
 yet
 we're
 projecting


on
 that
 basis
 what
 future
 data
 center


needs
 are.


>> Part
 of
 the
 question
 it
 seems
 to
 me
 and


this
 is
 where
 it
 gets
 a
 little
 bit


philosophical
 is
 what
 do
 these
 AI


companies
 think
 they're
 building?


Because
 one
 theory
 is
 like,
 well,
 maybe


they're
 building
 business
 tools,
 right?


Maybe
 they're
 building
 business
 tools
 of


various
 sorts.
 And
 if
 they're
 building


business
 tools
 of
 various
 sorts,
 that


implies
 the
 possibility
 that
 eventually


they
 get
 good
 enough.
 This
 does
 the
 job,


right?
 This
 makes
 it
 easier
 for
 this


website.
 You
 can
 uh,
 you
 know,
 use
 an


agent
 to
 book
 your
 travel
 and
 the


technology
 works
 and
 we
 don't
 have
 to


keep
 building
 it
 because
 we
 got
 to
 the


point
 where
 it
 works.
 And
 then
 there
 is


this
 other
 question
 of
 like
 well
 maybe


they
 want
 to
 build
 something
 called
 AGI


or
 ASI
 that's
 like
 so
 sci-fi
 etc.
 In


which
 case
 you
 could
 never
 get
 enough
 or


simply
 having
 built
 the
 thing
 that


allows
 you
 to
 book
 your
 travel
 or
 book
 a


dinner
 reservation
 or
 translate
 a
 text


or
 whatever
 that's
 not
 nearly
 enough.


You
 hear
 different
 things
 but
 what
 do


you
 think
 the
 builders
 at
 the
 cutting


edge
 of
 these
 labs
 are
 going
 for?
 Is
 it


really
 the
 sort
 of
 sci-fi
 building
 god


cliche
 or
 do
 they
 want
 to
 build


profitable
 business
 tools?


>> So,
 it's
 the
 first
 thing
 until
 you


challenge
 them
 and
 then
 it's
 the
 second.


So,
 what
 happens
 is
 if
 you
 have
 the


conversation
 internally,
 they'll
 say,


"Yeah,
 no,
 no,
 no.
 We're
 building
 just


really
 effective
 productivity
 enhancing


tools
 that'll
 be
 used
 across
 a
 host
 of


businesses
 and
 these
 all
 sounds
 really


good."
 But
 then
 when
 you
 walk
 through


some
 of
 the
 math
 in
 terms
 of
 justifying


the
 ROI
 on
 the
 spend,
 all
 of
 a
 sudden


then
 it
 turns
 into
 what
 I
 call


faith-based
 argumentation
 about
 AGI.


Yeah.


>> And
 they
 say
 it's
 like
 the
 the
 greatest


call
 option
 ever.
 Like
 what
 would
 you


pay
 for
 a
 call
 option
 that
 could
 get
 you


anything?
 And
 it's
 like,
 well,
 wait
 a


minute.
 This
 isn't
 a
 way
 of
 justifying


any
 particular
 expenditure.
 This
 is
 just


faith-based
 argumentation
 where
 you're


saying,
 you
 know,
 with
 the
 Uber
 call


option
 for
 anything,
 you
 should
 be


willing
 to
 pay
 anything
 for
 it.
 And


obviously
 that
 that
 kind
 of


justification
 doesn't
 get
 you
 anywhere.


So
 in
 in
 house
 they'll
 armwave
 a
 lot


about
 these
 different
 models
 that
 will


emerge.
 Who
 knows?
 I
 had
 someone
 at


Nvidia
 tell
 me
 the
 other
 day
 that
 we


really
 are
 just
 waiting
 for
 the
 Uber
 of


AI
 to
 come
 along
 and
 show
 us
 the
 future.


And
 I'm
 like
 okay.
 So
 that's
 but
 it's


not
 an
 answer,
 right?
 So


>> because
 in
 theory
 if
 you're
 building
 a


business
 productivity
 tool
 then


eventually
 you
 could
 solve
 your
 unit


economics
 problem,
 right?
 If
 you're
 just


trying
 to
 build
 a
 really
 great
 business


opportunity,
 then
 it's
 simply
 you
 know


what,
 we
 don't
 have
 to
 build
 anymore.
 It


works
 and
 then
 the
 cash
 flow
 just
 starts


pouring
 in
 and
 the
 cost
 per
 token
 goes


down.


>> You
 can
 and
 there's
 a
 bunch
 of
 that


already
 happening.
 It's
 really


interesting.
 But
 what's
 increasingly


happening
 is
 the
 problems
 they're


solving
 are
 really
 mundane.
 And
 so
 it's


things
 like
 I'm
 trying
 to
 onboard
 a


bunch
 of
 new
 suppliers.
 Right
 now
 the


people
 have
 weird
 zip
 codes
 and
 they


sometimes
 don't
 match
 up.
 I
 have
 a
 dude


in
 the
 back
 who
 fixes
 that.
 I'd
 rather


have
 someone
 who
 could
 do
 it
 faster
 so
 I


could
 onboard
 a
 lot
 more
 suppliers.
 Oh,


it
 turns
 out
 these
 small
 language
 models


are
 really
 good
 at
 that.
 These
 micro


models
 like
 IBM's
 Granite
 and
 whatever


else,
 but
 those
 things
 require
 a


fraction
 of
 the
 training,
 are
 very


cheap,
 are
 not
 going
 to
 justify
 anywhere


near
 the
 economics
 needed
 to
 pay
 for
 the


current
 spend.
 And
 yet
 those
 things
 are


almost
 like
 very very
 likely
 the
 future


because
 it'll
 be
 proflegate
 token
 use


from
 micro
 models
 often
 hosted


internally
 to
 do
 really
 mundane


background
 tasks.
 Not
 very
 glamorous


onboarding
 new
 suppliers,
 matching


records.


>> Yeah,


>> great
 stuff.
 Just
 not
 really
 very


exciting,
 but
 large
 language
 models
 are


amazing
 at
 it
 and
 small
 language
 models


are
 amazing
 at
 it
 and
 almost
 free


>> and
 writing
 songs,
 right,
 Joe?
 They
 can


do
 that.
 [laughter]
 I'm
 actually
 I'm


still
 annoyed
 that
 AI
 is
 like
 getting


into
 art
 and
 music
 writing
 and
 all
 the


fun
 stuff
 versus
 the
 stuff
 that
 I
 don't


want
 to
 do
 like
 folding
 laundry
 to
 your


classic
 example


>> or
 matching
 customer
 records


>> or
 that.
 So
 going
 back
 to
 the
 beginning


of
 this
 conversation
 when
 we
 were
 just


talking
 about
 the
 scale
 of
 AI
 investment


and
 its
 impact
 on
 the
 US
 economy,
 I'm


pretty
 sure
 you
 are
 one
 of
 the
 ones


who's
 described
 AI
 capex
 as
 like
 a


private
 sector
 stimulus
 program
 for
 the


US
 economy.
 What
 are
 the
 actual


consequences
 either
 positive
 or
 negative


of
 having
 this
 massive
 private
 sector


spend
 in
 the
 economy
 versus
 something
 I


guess
 more
 typical
 which
 would
 be
 a


government
 stimulus
 or
 maybe
 growth


driven
 by
 consumer
 spending
 or
 something


like
 that.


>> Yeah.
 So
 to
 an
 orthodox
 economist
 the


old
 line
 is
 like
 it
 really
 doesn't


matter
 what
 we
 pay
 people
 to
 do
 as
 long


as
 we
 pay
 them.
 Right.
 is
 the
 idea
 of
 I


should
 be
 I
 should
 be
 you
 should
 be


willing
 to
 pay
 people
 to
 dig
 holes
 in


the
 ground
 and
 people
 over
 there
 to
 fill


the
 holes
 back
 in
 again.
 It
 really


doesn't
 matter
 as
 long
 as
 the
 money
 is


out
 there
 and
 in
 circulation,
 right?


That's
 just
 it's
 all
 just
 stimulus,


right?
 So
 to
 that
 way
 of
 thinking,
 it


doesn't
 matter
 because
 the
 money
 is
 all


finding
 its
 way
 back
 into
 the
 economy.


But
 I
 think
 that's
 obviously
 hugely


misleading
 because
 in
 this
 context,


these
 are
 investments
 created
 with
 an


expectation
 of
 a
 return.
 If
 they
 can't


then
 that
 flows
 backwards
 into
 all
 the


entities
 that
 are
 built
 on
 that
 basis


whether
 it's
 private
 credit
 firms
 and


their
 returns
 the
 S&P
 500
 what
 is
 it


like
 35%
 now
 is
 AR
 related
 mag
 7
 mag
 10


whatever
 40%
 50%
 now
 the
 last
 two
 years


return
 so
 this
 is
 a
 massive
 negative


wealth
 effect
 when
 you
 unwind
 it
 not


just
 in
 terms
 of
 the
 direct
 spending
 but


in
 terms
 of
 the
 wealth
 effect
 with


respect
 to
 what
 people's
 holdings
 are
 so


this
 is
 not
 as
 simple
 as
 saying
 this
 has


just
 been
 a
 wonderful
 stimulus
 program


we're
 paying
 people
 to
 dig
 holes
 and


filling
 them
 back
 in
 again
 this
 is
 a


wasting
 asset
 on
 something
 that's
 likely


to
 be
 produced
 in
 quantities
 that
 we
 can


never
 earn
 an
 economic
 return
 from
 in


part
 because
 of
 wildly
 flawed


assumptions
 uh
 and
 projections
 about
 the


future
 of
 demand
 for
 those
 units.
 And
 so


that's
 that's
 the
 deep
 structural


problem.
 And
 then
 you
 can
 get
 into
 this


whole
 question
 of
 like,
 well,
 if
 it's


just
 private
 equity
 guys
 get
 hurt,
 you


know,
 who
 cares?
 Screw
 those
 guys,


right?
 And
 it's
 not,
 of
 course,
 because


as
 we
 just
 talked
 about,
 it's
 it's
 in


it's
 in
 equity
 funds.


>> It's
 firefighters
 and
 teachers
 money.


>> Yeah.
 Yeah.
 And
 it's
 in
 REITs
 now.
 Look


at
 the
 the
 larger
 holdings
 in
 reads
 now


increasingly
 our
 data
 centers
 and
 it's


even
 in
 sort
 of
 sneaky
 backdoor
 ways


like
 we're
 seeing
 increasing
 I
 don't


know if
 you
 guys
 are
 familiar
 with
 these


new
 interval
 funds
 they're
 appearing


there
 it's
 all
 over
 now


>> Paul
 Kadski
 we
 could
 I
 have
 a
 million


more
 questions
 I
 could
 ask
 you
 but
 much


like
 the
 race
 towards
 AGI
 itself
 that


would
 imply
 that
 we'll
 ever
 actually
 get


to
 the
 end
 of
 this
 conversation


[laughter]


so
 how
 about
 we
 uh
 wrap
 here
 and
 then


just
 plan
 on
 you
 know
 revisiting
 the
 com


six
 months
 maybe
 three
 years
 we
 just


keep
 revisiting
 down
 the
 line
 where
 we


are
 uh
 in
 the
 cycle.


>> As
 long
 as
 we
 haven't
 been
 turned
 into


paper
 clips,
 I'm
 good.
 I
 [laughter]


Yeah,
 that's
 the
 No
 one
 talks
 about
 the


>> nightmare
 clippy.
 I
 feel
 like
 uh
 that


was
 No
 one
 talks
 about
 the
 old
 school


paperclip
 maximizer
 stuff.
 Everyone's
 on


to
 more
 esoteric
 fears.


>> I
 know
 people
 have
 moved
 on.
 We
 need
 to


worry
 about


>> Did
 anyone
 wait,
 did
 anyone
 ever
 try
 to


securitize
 Clippy?
 They
 didn't,
 right?


>> I
 don't
 think
 so.
 No,
 they
 never
 did.


>> Thanks,
 Paul.
 Okay.
 Thanks,
 guys.


>> [music]


>> Paul's
 so
 good.
 That
 was
 a
 lot
 of
 fun.


>> He's
 so
 good.
 Here
 is
 my
 highest
 form
 of


praise
 for
 an
 OddLotss
 guest.
 I
 am
 going


to
 go
 back
 and
 read
 that
 transcript
 from


beginning
 to
 end.


>> That
 is
 a
 very
 good
 um
 That
 is
 a
 very


good
 practice
 to
 do.
 Wait,
 you're
 not


going
 to
 listen
 to
 it?
 You're
 only
 going


to
 read
 it?


>> No,
 I'm
 going to
 read
 it.


>> Yeah,
 I
 can't
 read
 it.
 I
 can't
 listen
 to


it.


>> I
 I
 just
 listen
 to
 it.
 I
 need
 to
 read


it.
 I
 can't
 listen
 to
 our
 episodes.
 No,


I
 just
 um
 you
 know,
 I
 think
 there's
 a


lot
 there's
 a
 lot
 more
 to
 do
 on
 all
 this


topic,
 but
 the
 financing
 in
 particular


and
 some
 of
 these
 arrangements,
 it's


just
 incredible
 how
 the
 speed
 with
 which


I
 guess
 I
 would
 say
 the
 financing
 has


gotten
 interesting.
 Do
 you
 know what
 I'm


saying?
 Like
 I
 think
 like
 a
 data
 center


project
 10
 years
 ago,
 a
 Microsoft
 AWS


thing
 just
 seemed
 like
 a
 fairly


straightforward.
 It's
 probably
 more


complicated
 than
 I
 appreciate
 at
 the


time,
 but
 basically
 straightforward.
 we


make
 this
 money
 and
 part
 of
 it
 is
 going


to
 go
 to
 building
 more
 data
 centers
 to


you
 know
 serve
 you
 know
 Amazon
 Prime


streaming
 or
 whatever
 it
 is
 or
 some


client
 thing
 or
 whatever
 and
 then
 the


degree
 of
 complexity
 with
 these
 SPVS
 and


rollover
 risk
 and
 depreciation
 schedules


and
 trunching
 of
 who
 it
 it's
 gotten
 very


interesting
 very
 fast


>> life
 uh
 finds
 a
 way
 life
 finds
 a
 way


yeah


>> that
 was
 my
 terrible
 terrible
 impression


I
 think
 that's
 absolutely
 right
 one


thing
 I
 would
 say
 is
 the
 fact
 that
 a
 lot


of
 these
 big
 supposedly
 cashrich


companies
 are
 doing
 this
 through
 SPVS


that
 effectively
 preserve
 their
 balance


sheet
 and
 their
 cash
 flow
 so
 they
 can
 do


something
 else
 with
 it.
 I
 mean


>> a
 lot
 of
 companies
 use
 SPVS.
 Sure.


>> Yeah.


>> But
 I
 do
 think
 it
 says
 something
 about


the
 scale.
 Yes.
 Right.
 Like
 there's
 a


scale
 problem
 here
 where
 if
 all
 your


spending
 was
 appearing
 on
 balance
 sheet,


investors
 might
 think
 very
 very


differently
 about
 your
 company.
 And
 then


the
 other
 thing
 I
 would
 say
 is
 I
 still


think
 the
 compare
 and
 contrast
 between


the
 US
 and
 China
 and
 their
 approaches
 to


AI
 both
 you
 know
 both
 of
 them
 I
 think


would
 agree
 that
 this
 is
 an
 existential


problem
 of
 some
 sort
 or
 an
 existential


competition
 but
 they're
 following
 very


different
 paths


>> and
 it
 does
 seem
 to
 me
 like
 the
 arc
 of


history
 kind
 of
 leans
 towards
 stuff


becoming
 cheaper.


>> I
 think
 the
 arc
 the
 arc
 of
 history
 bends


towards
 China
 is
 what
 I
 thought.


>> Well
 that
 too
 that
 too.
 Um
 but
 it
 bends


towards
 you
 know
 people
 generally
 want


the
 cheaper
 thing
 and
 they
 want
 the


thing
 that's
 like
 available
 now
 and
 I


China
 seems
 to
 be
 going
 for
 that.


>> The
 counterargument
 is
 that
 if
 you're


going
 to
 use
 an
 open-source
 model
 for


some
 purposes
 you
 have
 to
 supply
 your


own
 electricity
 right
 you
 have
 to
 supply


your
 own
 inference
 you
 got
 to
 host
 on


your
 service
 like
 you
 still
 run
 into


some
 constraints
 and
 so
 rather
 than


having
 it
 be
 on
 whatever
 whoever
 else's


data
 center
 you
 got
 to
 find
 a
 way
 to
 run


it
 yourself.


>> Yeah.
 Okay.
 But
 China
 has
 a
 leg
 up
 in


electricity.


>> They
 have
 a
 lot
 which
 was
 the
 point
 that


Jensen
 Wong
 made.
 I
 mean
 part
 of
 the


reason
 like
 there's
 so
 much
 talk
 about


this
 these
 days
 right
 now
 is
 that
 the


industry
 insiders
 are
 saying
 a
 bunch
 of


weird
 things.
 Paul
 mentioned
 the
 Sarah


Frier
 comment.
 Oh
 yeah.
 And
 she
 which


she
 sort
 of
 had
 to
 walk
 back
 but
 then


she
 said
 the


>> that
 Sam
 Alman


>> then
 there
 was
 the
 Sam
 Alman
 thing
 where


he
 was
 asked
 how
 are
 you
 going to
 pay


for
 all
 this
 and
 he
 said
 look
 you
 want


to
 sell
 your
 shares
 or
 not
 which
 is
 like


the
 interviewer
 probably
 thought
 he
 was


>> a
 little
 defensive.
 Obviously,
 Jensen


Wong
 talking
 at
 recently
 about
 how
 China


was
 going
 to
 win.
 Maybe
 he
 was
 saying


that
 because
 he
 wanted
 to
 catalyze
 more


action
 on
 solving
 some
 of
 the


electricity
 problems
 in
 the
 US.
 But,
 you


know,
 the
 very
 people
 at
 the
 center
 of


this
 are
 saying
 things
 right
 now
 that


you
 know
 what's
 interesting
 too
 is
 um


you
 know
 this
 bullwhip
 phenomenon.


Everyone,
 as
 Paul
 described
 it,
 he


didn't
 use
 the
 word
 bullwhip,
 but
 when


everyone
 is
 trying
 to
 get
 their
 hands
 on


the
 same
 gear,
 you
 got
 to
 wonder
 how


sustain
 what's
 the
 other
 side
 of
 a


bullwhip
 could
 look
 like.
 I
 don't know.


We
 just
 got
 to
 do
 more
 episodes
 on
 this.


>> Yeah,
 we
 have
 to.
 Shall
 we
 leave
 it


there
 for
 now?


>> Let's
 leave
 it
 there.


>> All
 right.
 This
 has
 been
 another
 episode


of
 the
 All
 Thoughts
 Podcast.
 I'm
 Tracy


Aloway.
 You
 can
 follow
 me
 at
 Tracy


Aloway.


>> And
 I'm
 Joe
 Weisenthal.
 You
 can
 follow


me
 at
 the
 stalwart.
 Check
 out
 Paul


Kadroski's
 writing
 at
 paulcadrski.com.


Follow
 our
 producers,
 Carmen
 Rodriguez


at
 Carmen,
 Dashelob
 Bennett
 at
 Dashbot,


and
 Kaleb
 Brooks
 at
 Kaleb
 Brooks.
 And


for
 more
 oddlots
 content,
 go
 to


bloomberg.com/odlots.


We
 have
 a
 daily
 newsletter
 and
 all
 of


our
 episodes.
 And
 you
 can
 chat
 about
 all


these
 topics
 24/7
 in
 our
 Discord,


[music]
 discord.gg/odlotss.


>> And
 if
 you
 enjoy
 OddLots,
 if
 you
 like
 it


when
 we
 talk
 about
 the
 AI,
 private


[music]
 credit,
 leverage,
 subprime,


economy,
 nexus,
 then
 please
 leave
 us
 a


positive
 review
 on
 your
 favorite
 podcast


platform.
 [music]
 And
 remember,
 if
 you


are
 a
 Bloomberg
 subscriber,
 you
 can


listen
 to
 all
 of
 our
 episodes
 absolutely


adree.
 All
 you
 have
 to
 do
 is
 [music]


find
 the
 Bloomberg
 channel
 on
 Apple


Podcast
 and
 follow
 the
 instructions


there.
 Thanks
 for
 listening.


[music]


[music]


>> [music]


[music]