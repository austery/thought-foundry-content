好了，不玩梗了
我认真锐评一下skill这个东西
我们都知道，作为业界三巨头
OpenAI最擅长炒作
Google最擅长算法
而Anthropic最擅长开发
自从24年年底发布了MCP标准之后
25年的年底，Anthropic又给我们带来了agent skill这个新概念
skill一发布，圈子里的大家就都知道
又一波AI开发的升级即将到来
其实skill这个概念没有什么很重大的突破
你甚至可以说它有点返璞归真了
它解决的是一个很现实的问题：
如何用最少的token办最多的事儿
答案就是把提示词拆解
按照能力范围打包
互相保留指针
然后再实时按需导入，实现动态的提示词构建
这其实也是为什么
我觉得skill是目前那么多个AI应用的概念里
最有机会成功的那个
因为它让我想起了maven、npm、crate、pip
也就是大家熟悉的依赖管理
你可以骂现在的一些技术框架过于依赖依赖
一个hello world就要安装上千个依赖
但不可否认的是
正是因为这种积木结构，才可以带来无穷的可能性
从技术层面上看，比起大模型、MCP这些
skill被整合进到工作流的难度更低、可接受度也更高
咱们就说大模型，天天更新的VSCode
到现在还得靠第三方插件来支持其他的模型
而MCP的整合则是更折腾
尤其是去年一连串的MCP安全漏洞事故之后
现在稍微专业一点的平台
对于MCP的接入都加上了很多层的验证机制
我之前试过把AWS上面的一个AI服务接上GitHub的MCP
从查资料到生成各种密钥，搞了接近一个小时才搞好
而skill则是用一种最简单的方法解决了这些问题
那就是完全本地运行
所有代码都在本地储存，所有指令都在本地运行
一切都是公开透明的
没有跨网络通讯，自然也不会存在RPC漏洞之类的安全问题
我认为skill的出现是第一次
让 prompt engineering 这个概念真正像一个“工程”
而在此之前，我们对提示词的使用更像是在做实验
因为还没有摸清楚大模型这个生物的特征
我们就在这儿给它一点酸，在那儿给它一点碱
然后再观察它有什么反应
而现在大模型对function call之类的基本机制都已经稳定下来后
skill这种有结构、有规模的软件工程范式才可以真正的普及开来
对我这种软件工程师，它的出现是一种契机
因为在大模型迭代的上半场，主角是那些算法科学家
上半场的那些概念，我们看都看不懂，只能乖乖地当个用户
而现在进入了应用落地的下半场
软件工程的理念会更加发挥作用
我们就变成了懂行的那个了
为了搞清楚现在的skill生态
我找遍了互联网，搜集了大约300个开源skill
覆盖了文件处理
数据分析
网页生成
安全检测
项目管理等各个领域
全部都安装到了IDE里
因为现在还没有npm这种包管理框架
所以这些skill还得一个个导入，略显繁琐
之所以要一股脑地把所有的skill都安装进去
而不是用什么装什么
是因为我们永远都不会知道在什么时候需要用上什么skill
比如说我们这里让AI去做一个完整的数据可视化项目
它经过对于需求的拆解、分析之后
得出的设计方案里面就包括了
需要处理CSV这个数据源
需要用D3.js这个可视化框架
需要用Playwright做前端测试
正因为我把什么都装进去了，这些我都有对应的skill
所以AI就会在系统提示词里面发现它们之后
直接去到对应的那个skill里，导入相关的提示词和参考代码
那么假如下次AI出的方案里面
还包括了要用Excel作为数据源
又或者它把可视化框架换成了echarts
又或者它要用property based testing做测试
我也不需要着急，因为这些skill也都被安装好了
这种按需导入的机制
就决定了我们在安装skill的时候，要遵守“宁滥勿缺”的原则
能找到多少就安装多少
找不到的就自己造，因为造这个东西比想象中的更容易
就像那些只有一行代码的Node.js工具包
你的skill也可以是只有一句话的一个markdown文档
然后在此之上，你再去逐步的拓展你的skill内容
增加步骤、增加可执行的脚本、补充更多的案例
比如我前些天做了这个用来分析CVE漏洞和各种漏洞事故的skill
在一开始就是很简单的：
找到官方报告
提取里面出漏洞的代码和官方解释
最后生成总结
后面我陆续地补充了更详细的拆解要求
而在让它做分析的时候，也专门指出那些要关注的点
并且引导AI去做更有针对的解读
再后来，我还给一些步骤加上了执行脚本
比如在收集官方报告的时候
我指定它用什么脚本去爬取网页
可以保证这个数据获取的准确性
后面有了这个漏洞分析的skill
在平时问AI一些技术问题的时候
它就能给我更专业的回答
因为没有这个skill的时候
它就只会像播报新闻那样，给我一个很笼统的漏洞分析
作为一个实用主义者，在我看来
skill最大的价值是对输入的token数量有了可控度
因为在没有skill的情况下
你完全无法控制AI要花多少token
爬取多少外部网页
导入多少参考代码
才会完成一个小动作
而在skill的基础上，你能够精确地控制每一个输入的字符
你如果想要更细致的操作，那你就多一点提示
你要想要它的输出更稳定，那你就多一些参考案例
反之亦然
你也可以在不影响输出效果的前提下
适当地削减一些提示词，减轻token的负担
最近我在粉丝群里面听到最多的抱怨
就是“token额度又没了”、“基础套餐完全不够用”
我自己还好，因为我连基础套餐都不买的
专门挑那些免费来薅
要不然实在是耗不起
你就说GPT、Gemini、Claude这些国外大模型
每一个烧的都是美元
而且一个个都是token吞噬者
我都怀疑他们是不是故意的
所以我大胆地推测
以后skill的发展会有点像大模型那样
开始出现不同等级的分类
比如更节省token的 Lite Skill
提示词更详细的Pro Skill
完全不差钱的Max Skill之类的
而像我这种羊毛党
就会用着免费的IDE
跑着最省钱的Lite Skill
做个勤俭持家的好男人~