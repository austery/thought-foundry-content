 So, I got ripped off by a group that operates
 here on YouTube to the tune of $10,000 or
 so, and a couple of months wasted, and what's
 worse, they used AI to do it. Kind of. More
 on that later.
 Now, before you click off, this isn't a request
 for money, no GoFundMe here, nothing like
 that.
 I'm going to be fine.
 I just passed 100,000 subscribers.
 Thanks for that, by the way,
 to those of you that are subscribed. I will do
 my best to be worthy of your time. Anyway.
 So, things are going fine with me as far as I'm
 concerned.
 And just to set your expectations for YouTube
 drama, I'm not going to be naming the group
 specifically in this video.
 This video is about recognizing scams like this,
 and how to avoid them, no matter what
 group is trying to scam you.
 It wasn't a scam I'd thought about before,
 although in retrospect, it's an obvious one,
 and it's one that I'm sure is going to get
 worse and worse, and it's hard to defend
 against, or to detect, for that matter.
 It really isn't anything to be done now about
 what happened to me, but I can at least tell
 you about it so that hopefully you can avoid it,
 and I'll at least feel like something
 good came out of my experience.
 I'll get into plenty of detail about exactly
 what happened to me in a little while, along
 with some recommendations about how you might
 protect yourself and some discussions about
 the wider societal implications.
 But first, just so you can decide if you'd care
 to stick around for the details, let me
 give you the short version.
 So there are people out there, on YouTube, and
 I'm sure elsewhere, who are selling information
 or coaching or courses, but really what they're
 doing is just charging hundreds or thousands
 of dollars for them to run ChatGPT and then
 pass the output on as if it was valuable.
 So the way I see it, there are three
 possibilities:
 Option one: the output of ChatGPT is
 completely useless for your purposes, in which
 case you
 are paying for useless information and you're
 getting ripped off.
 Option two: the output of ChatGPT should work
 for your use case, in which case you
 should ask ChatGPT yourself and save the money.
 Or, option three:
 You're working on a project that is so
 important that you can't afford any mistakes or
 delays,
 and so it's worth paying a group that's domain
 experts to sit between you and the AI and
 make sure that what comes out matches your
 requirements.
 So for example, if you don't know anything
 about writing secure code and you were going
 to be getting an application generated by ChatGPT,
 it might be worth paying someone
 so that they can make sure that there aren't
 any security issues with the code before you
 put it on the Internet and get yourself hacked.
 In that case, I think it would be the developer's
 responsibility to disclose to you that they
 were using ChatGPT and what parts of your
 deliverable were from them and what parts
 were deliverable from ChatGPT.
 And I would argue that there's never a case
 where it's okay for any vendor to not disclose
 their use of AI.
 And if they do hide it, and like me, you don't
 catch it until it's too late, then you, like
 me, are probably going to get F------
 This is the Internet of Bugs.
 My name is Carl.
 I've been a software professional since the
 1980s, and I'm trying to do my part to make
 the Internet a safer, more reliable, and less
 buggy place, which lately has meant a lot
 of pushing back against. and warning about, the
 dangers of AI.
 So, here's what happened to me:
 I've been working for a while on creating an
 online course and a community for software
 developers to learn how to create their own
 Software-as-a-Service business, and in the
 process, learn a whole bunch of skills that are
 really hard to acquire otherwise.
 I've done a lot of corporate training over the
 years, so I feel comfortable with teaching,
 putting together a curriculum and all that
 stuff, and of course, I've spent decades
 building
 and working with software businesses, so I know
 what information to put in the course.
 But I've got no experience with any of the
 business side of that.
 I don't know how to deliver such a class over
 the Internet, how to figure out what scope
 makes sense, what and how to charge for it,
 what kind of community a class needs, how
 best to host and manage such a community, and
 what other best practices I might not
 know about.
 It seemed reasonable to me that the best way to
 learn those things was to take an online
 class myself, and so I found and signed up for
 a class on how to package career experience
 into an online education business.
 I gave them a lot of money up front and then
 realized they had no more idea of how to do
 this than I did.
 Yeah, well, oops.
 Now several wasted months, several thousand
 dollars later, I regret having gotten involved
 with them at all, but hindsight's 20/20.
 Now I'm sure the group that fooled me aren't
 the only group doing this, and I expect that
 more and more people are going to be running
 this scam as time goes on in the online course
 space, but probably a ton of other spaces as
 well.
 So instead of just telling you to avoid a
 particular channel, I'm just going to teach
 you how to spot the scam, the extent that you
 can, and that will hopefully protect you
 not just from them, but from other people doing
 similar things. And I'm expecting that you
 might need that because one of the core
 teachings of the group that ripped me off was
 instruction
 on how to use AI to rip other people off.
 Now they don't say it that way, of course.
 They're talking about "How easy it is to use AI
 to start your own coaching business", but
 the effect is they're teaching people how to
 sell ChatGPT output for thousands of dollars.
 Not only was that group a scam, but they're
 arguably just a scam factory.
 So let me zoom out for a couple of minutes.
 Let's talk about the bigger picture and then I'll
 dig more into the details of my experience
 and what I would recommend that you do
 differently.
 One huge problem that AI has started causing
 for us, for all of us, that we don't talk
 about much is the way that AI is messing with
 our ability to rely on our learned intuition
 about the effort put into something or the
 quality of something.
 Up until the last few years, it was a decent
 shortcut to estimate the quality of a product
 or a service by looking at the quality of its
 presentation, using the layout, the structure,
 the format, as signals to tell you about how
 much effort was put into the product.
 It's the proverbial judging a book by its cover,
 as it were.
 This loss of signaling regarding quality has
 happened to us before.
 Once upon a time, believe it or not, we could
 make a pretty good guess on how good a video
 game was going to be based on how good the
 graphics looked, because games that had the
 most effort put into their presentations
 generally also had the most effort put into
 them overall.
 Then two things happened.
 First, was that game companies started
 realizing that if they made their graphics
 pretty enough,
 they could get away with skimping on everything
 else and still make a profit.
 And the second thing was that third-party game
 engines like Unreal became commonplace
 enough that all the games started to look alike
 regardless of quality.
 As a result, these days, a lot of the prettiest
 games are mediocre or worse, and many of the
 best games don't require high-end graphics
 hardware at all.
 And we've lost the ability to estimate how good
 a game is likely to be by watching the
 trailers or playing the demos.
 AI is causing the same problem with things that
 we buy and subscribe to online, and
 I expect this is going to be getting worse.
 It's going to be more and more difficult to
 tell whether what we're looking at online
 was produced by a quality organization that
 cares about their customers and their
 reputation,
 or something that just has a polished but AI-created
 exterior with no depth, reliability, or quality
 underneath.
 This same issue is also one of the big problems
 currently affecting the job market.
 When every resume looks the same, and every
 cover letter looks the same, it breaks the
 way that resume screening has been done for
 years.
 AI is also complicating the signaling in
 judging the submission of journal articles in
 fake
 product reviews and in judging the veracity of
 fake news.
 There are a few papers about this all linked
 below.
 The things AI's generate seem perfectly
 reasonable at first glance, even well-researched
 and
 high quality.
 But in fact, there's no rigor underneath, and,
 as many lawyers are figuring out, often
 the facts or research the generated output is
 based on don't exist at all.
 When that output is given to you or me though,
 it's not at all clear whether any relation
 between the context of that document and our
 reality exists at all.
 And that's a problem for those of us who want
 information from people on the Internet
 and are willing to pay for it.
 I don't know of a good way to quickly tell
 whether or not informational or educational
 materials given to you are just ChatGPT output
 or not.
 The AI detector services are notoriously
 unreliable, but honestly, by the time you've
 been given
 the materials and you have the opportunity to
 look at them, chances are it's already
 too late because you've already given the money.
 So let's talk about how you might avoid what
 happened to me.
 So step one avoiding getting ripped off by
 paying for someone to prompt ChatGPT for
 you is to decide for yourself what being ripped
 off would mean in your case, specifically
 deciding what things you think AI is
 appropriate for and what things you don't.
 If you want to pay someone thousands of dollars
 to prompt ChatGPT for you, I'm not going to
 tell you that you're wrong.
 It may be worth it to you and you might not
 consider it a ripoff and that's fine. You do
 you.
 On the other hand, you might think that any use
 of AI is inappropriate, in which case
 it'll be a lot easier for you to decide who you
 don't want to do business with, although
 the list of people that are not using AI at all
 is getting smaller and smaller these
 days.
 My recommendation is to take a page from the
 startup playbook and decide what counts as
 core business or competitive advantage and what
 doesn't.
 In the business world and especially in the
 startup world, there are things that companies
 are expected to keep in-house and things are
 encouraged outsource.
 For example, lots of small businesses these
 days outsource functions like benefits and
 payroll because for most businesses, there's no
 way doing a better job of payroll will
 make them any more profitable or any more
 likely to succeed.
 On the other hand, if the function in question
 does have the potential to make the company
 more successful with it's done well, then they
 should probably keep it in-house and do
 it the best they can.
 Likewise, if you're trying to decide whether or
 not to do business with someone, the fact
 that they use AI for things unrelated to the
 services they are providing to you might
 not matter to you at all, at least doesn't
 matter to me.
 For example, if I were going to be paying a
 company to teach me how to use a new AI-based
 programming tool and that company used AI to
 lay out their website or to create marketing
 copy text or stock images for their social
 media posts, that wouldn't bother me at all.
 On the other hand, if that same company used
 ChatGPT to create their lesson content for
 what they were selling to me, then I'd feel
 ripped off and I think I'd be justified in
 filling that way.
 Or for another example, I don't use AI to write
 my scripts or suggest ideas for my videos
 on this channel.
 I mean, I've looked at suggestions that AI
 makes for video topics and they're worse
 than useless because, you know, I only make
 videos based on my best understanding of,
 you know, facts and reality and I expect that
 you would be upset if I started making videos
 based on large language model hallucinations,
 and rightfully so.
 Also if what you want is a video like the
 videos on this channel that were made by AI
 and have nothing behind them, you can just ask
 ChatGPT yourself and you don't need me.
 On the other hand, I do use AI for some things
 related to this channel.
 Lately, after I upload a new video, I've
 started giving the transcript to Gemini and
 then
 asking what hashtags and keywords I should put on
 the video because otherwise, I'd just
 be guessing because I don't have an idea.
 Also the last few months, I've been paying a
 service to level and clean up the final audio
 for each new video right before I upload it
 to YouTube and I'm pretty sure that service
 uses AI.
 I'm assuming that my ability or lack thereof
 to use my old damaged hearing to try to clean
 up audio is not why you watch my videos, and for
 those of you who have been watching my
 content since back when I was trying to use my old
 damage hearing to edit my audio, you
 have my sincere condolences.
 Anyway, back to me getting ripped off.
 I didn't think about AI at all before I handed
 over my money to the group that ripped me
 off because they had a history on YouTube that
 went back years before ChatGPT, so I
 figured that what they were selling also predated
 ChatGPT.
 Turns out I was wrong, but let that be a lesson
 to you, even established businesses that predate
 the current AI craze are getting on the grift.
 So step two:
 Now that you've decided what uses of AI you
 consider unacceptable in someone that you're
 paying, is to do some research.
 Look at their website, look at their marketing
 material, look at their free giveaways that
 they ask you for your email and in exchange, and
 watch their YouTube videos.
 If you see mentions of AI, it's probably a bad
 sign. (Unless of course teaching AI is
 their core business in which case things are
 going to be a little more complicated for
 you.)
 Also, if they have a long enough track record,
 take a look at how their post 2022 and recent
 materials compare to their pre 2022 material,
 as near as I can tell about the group that
 got me, they started off years ago as yet
 another like "how to grow your social media
 audience" channel.
 And prior to 2022, there were a few mentions of
 starting an online course, but only a handful.
 And then in late 2022, the year that ChatGPT
 came out, their content started mentioning
 creating online courses more and more until it
 was almost all they talked about.
 I don't know if that was because of ChatGPT,
 but it seems possible and it's probably
 something
 I should have paid a lot more attention to.
 The content from that group about "how to use
 social media to sell things",
 in this case online courses, seemed legitimate,
 but that wasn't what I needed to know.
 The content about "how to build the course" and
 most importantly, "how to make sure that
 the course that you're building provides value
 to your students",
 to the extent the group talked about that at
 all, it was just the kind of vague crap
 you get from ChatGPT. More on that in a bit.
 So step three, assuming you didn't see any
 indication from looking over their online
 presence that they were just selling chatbot
 output is to ask directly.
 I know asking is uncomfortable, but they're not
 likely to volunteer that information.
 Start by asking if they have an AI policy or an
 FAQ.
 Ask whether or not they use AI to generate the
 products or services that you're buying
 and if not, ask them if they plan on adding AI
 to their offerings and ask to get that
 in writing.
 And last part is important.
 Let me tell you more about what happened with
 me.
 I signed up for the service early this year,
 which is 2025 in case you're watching this
 later.
 There was no indication to me that they were
 repackaging AI at first.
 There was some text that sounded a little AI-ish
 in some of the lessons.
 So I started to get a little suspicious and
 then I started using their processes for
 getting
 personalized advice and help.
 Part of their offering, the part that I needed
 the most, was a customized plan to help each
 person who paid for their service to get step-by-step
 instructions tailored to their specific
 circumstances after they answered a few
 questions.
 And you had the opportunity to get a couple of
 different customized plans so you could
 compare and decide.
 This customization was one of the biggest
 selling points to me, but it turned out just
 to be wrapped chatbot slop.
 I talked to one-on-one with some of the other
 students who, like me, paid for the class.
 And we figured out that by getting a second
 plan and just by rephrasing the answers to
 the questions that we used for the first plan,
 we would get wildly different recommendations
 with completely different pricing guidance.
 And other core pieces of information would be
 different too.
 I explicitly asked them where the information
 the individual's reports came from and I
 was told that it was "a result of their process
 they'd refined over years of experience" or
 some such nonsense and they studiously avoided
 admitting it was just AI.
 And if that wasn't bad enough, after I'd been
 in the program for six months or so and
 despite the fact that one of their selling
 points when I signed up was "lifetime access"
 to their program, the program that I signed up
 for was discontinued.
 The new program that replaced it that they
 considered the continuation of my "lifetime
 access" was much more limited and even more
 obviously full of AI slop, and if I wanted
 the full blown package, I had to pay an extra $600
 a month forever.
 In fact, they weren't even hiding it anymore.
 They started talking about their use of AI as
 if it were a selling point.
 I guess that might be a selling point for some
 people but hopefully if you're watching
 my channel, you know better by now.
 Unfortunately for me, they already had my money
 and they never actually said that they
 would not use AI to create the content I was
 buying, and I didn't think to ask.
 I have no excuse for not having thought to ask,
 but I didn't, and I paid the price for
 it. So don't make my mistake.
 Then, step four is to figure out what their
 refund policy is or how to cancel future
 payments 
 if you've discovered that they're using AI in
 ways that they didn't disclose.
 They're likely to balk at this, and as a
 provider I get that, but if they insist that you
 can't
 get your money back even if they violate their
 stated AI policy, then it's an indication
 that they might not be so trustworthy after all.
 Then, once you have the information from your
 steps one through four, you hopefully have
 enough information to make your decision.
 I strongly advise you not to sign up for any
 service that refuses to commit to not using
 AI for their core offering, but it's up to you.
 At least if you ask, you'll be able to have the
 relevant information before you make
 your decision.
 The most important thing is I want you - and
 really everybody - to think about, and to ask
 about, what AI output you and they are willing
 to pay for.
 That awareness itself will hopefully help a lot
 of people avoid what happened to me.
 Best of luck to you all.
 Thanks for watching.
 Let's be careful out there.