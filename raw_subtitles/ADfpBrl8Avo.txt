[music]


Bloomberg
 Audio
 Studios
 podcasts,
 radio,


news.
 [music]


[music]


>> Hello
 and
 welcome
 to
 another
 episode
 of


the
 OddLotss
 podcast.
 I'm
 Jill


Weisenthal
 [music]


>> and
 I'm
 Tracy
 Aloway.


>> Tracy,
 I've
 I've
 always
 had
 this
 idea


for
 the
 podcast
 or
 a
 thing
 that
 I've


wanted
 to
 do.


>> Okay.
 conceptually
 with
 podcasts
 is


schedule
 every
 guest
 for
 two
 interviews.


So
 you
 have
 the
 opening
 interview
 and


you
 ask
 a
 bunch
 of
 questions
 and
 then


it's
 oh
 god
 I
 really
 wish
 I
 had
 followed


up
 on
 that.
 I
 had
 more
 I
 was
 just


starting
 to
 sort
 of
 get
 my
 head
 around


this
 thing.
 Now
 I
 could
 have
 asked
 the


good
 questions
 and
 then
 like
 have
 the


person
 come
 back
 next
 week.
 Also
 the
 the


audience
 complains.
 I
 wish
 you
 would


asked
 that
 and
 then
 fill
 in
 all
 those


gaps
 that
 had
 been
 inspired
 by
 the


previous
 conversation.


>> I
 don't
 think
 it's
 a
 bad
 idea.
 I
 think


it
 would
 double
 the
 number
 of
 episodes


that
 we
 put
 out.
 But
 sure,
 there
 are


topics
 that
 come
 up,
 usually
 things
 that


we're
 just
 kind
 of
 new
 to
 and
 we're


trying
 to
 learn
 about
 specifically


technical
 things
 and
 one
 of
 those
 has
 to


be
 AI,
 right?


>> AI
 and
 also,
 you
 know,
 I
 really
 had
 a


great
 time.
 I
 guess
 last
 month
 we
 were


in
 Chicago.
 We
 talked
 to
 a
 bunch
 of


different,
 it
 was
 like
 a
 trading
 related


trip.
 We
 uh
 interviewed
 Don
 Wilson.
 We


interviewed
 the
 head
 of
 the
 CME.
 We
 had


some
 other
 chats
 and
 they're
 all
 about


the
 world
 of
 trading.
 When
 it
 comes
 to


trading,
 it's
 like,
 you
 know,
 we
 talked


to
 long-term
 investors,
 portfolio


managers,
 endowments.
 [clears throat]
 We


talked
 to
 some
 people
 in
 the
 hedge
 fund


space
 who
 like
 maybe
 have
 a
 holding


period
 of
 several
 weeks
 or
 whatever.
 I


actually
 really
 want
 to
 learn
 more
 about


the
 trading
 like
 these
 people
 who
 have


like
 a
 holding
 time
 of
 1
 second
 or


something
 like
 that
 because
 that's
 where


a
 lot
 of the
 tech
 and
 a
 lot
 of
 the


actual
 like
 action
 is
 and
 how
 that
 world


makes
 money
 and
 how
 they
 actually
 deploy


technology
 is
 very
 interesting
 but
 still


something
 I
 don't
 have
 my
 handle
 on.


Well,
 the
 practical
 application,
 right?


And
 also
 the
 culture
 of
 AI
 on
 Wall


Street.
 I
 find
 that
 really
 interesting


because
 I
 remember
 I
 guess
 it
 was
 like


more
 than
 a
 decade
 ago.
 But
 remember


Lloyd
 Blankfine
 saying
 that
 Goldman


Sachs
 is
 a
 technology
 company.


[laughter]


>> Yeah.
 And
 all
 these
 bank
 CEOs
 saying


we're
 going
 to
 install
 ping
 pong
 tables


to
 get
 all
 the
 coders.
 And
 now
 I
 see
 ads


at
 trading
 firms
 and
 it's
 like
 we
 have a


data
 center
 full
 of
 B200s
 or
 we
 have
 a


data
 center
 full
 of
 G300s.
 Come
 work
 for


us.
 The
 only
 thing
 besides
 all
 their


tech
 that
 I
 know
 is
 like
 every
 time
 you


read
 a
 profile
 of
 any
 trading
 company,


they're
 like
 and
 they
 love
 to
 play
 back


gammon
 there.
 They
 love
 to
 play
 like
 all


the
 article
 the
 chess
 boards
 are
 out
 and


they
 could
 be
 seen
 playing
 chess
 over


lunch
 etc.
 I
 get
 it.
 Okay,
 they
 like


odds,
 they
 like
 games,
 they
 like


whatever.
 Let's
 move
 the
 ball
 forward.


>> Well,
 there's
 also
 the
 underlying
 theme


of
 is
 this
 all
 hype?
 Right.
 Because
 you


do
 get
 the
 sense
 sometimes
 that


companies
 are
 putting
 out
 press
 releases


where
 they
 just
 mention
 AI
 to
 tick
 a
 box


to
 be
 seen
 to
 be
 doing
 something
 and


hope
 that
 their
 stock
 actually
 goes
 up.


And
 because
 so
 much
 of
 this
 is


proprietary
 and
 people
 kind
 of
 have
 an


excuse
 not
 to
 go
 into
 detail
 about
 it,


>> sometimes
 you
 do
 get
 the
 feeling
 that


people
 are
 just
 talking
 about
 it
 and
 not


actually
 using
 it.


>> Cynics,
 and
 I'm
 not
 saying
 this
 myself.


>> I
 know
 you're
 not
 a
 cynic.
 Speaking
 of


trading
 and
 technology,
 Cynics


would
 say
 that
 CME's
 deal
 with
 Google
 to


build
 a
 cloud
 to
 you
 put
 trading
 on
 the


cloud
 was
 hyped.
 That
 was
 a
 press


release.
 People
 have
 said
 that
 people


have
 made
 that
 charge
 and
 they
 don't


understand
 why.
 You
 don't
 have
 to


comment.
 You
 don't
 have
 to
 say
 anything


further
 on
 that.


>> I
 do
 have
 a
 comment,
 but
 I'll
 hold
 it


for
 our
 guest.


>> I'm
 just
 saying
 there
 is
 this
 world


where
 people
 do
 press
 releases
 and


cynics
 go,
 I
 don't
 really
 understand
 the


point.
 Anyway,
 there's
 a
 very
 long
 wind


up.
 Let's
 learn
 more
 about
 the
 world
 of


trading.
 Let's
 learn
 more
 about
 AI
 and


tech
 specifically.
 What
 does
 it
 even


mean
 to
 apply
 AI
 within
 the
 realm
 of


trading?
 We
 are
 going to
 be
 speaking


with
 Ian
 Dunning.
 He
 is
 the
 head
 of
 AI


at
 Hudson
 River
 Trading.
 He
 was


previously
 at
 Deep
 Mind.
 So,
 his
 uh


trading
 and
 AI
 bonafides
 are
 about
 as


good
 as
 it
 gets
 with


>> you've
 established
 them.


>> We've
 established
 that
 really
 the


perfect
 guest
 to
 answer
 all
 our


questions.
 So,
 Ian,
 thank
 you
 so
 much


for
 uh
 coming
 on
 the
 podcast.


>> Yeah,
 I'm
 really
 happy
 to
 be
 here.
 I
 I
 I


agree
 is
 the
 mystic
 the
 mystique
 factor


is
 kind
 of
 overblown
 even
 if
 it's


understandable
 why
 people
 embrace
 it


sometimes.


>> We're
 going
 to
 blow
 past
 the
 mystique.


Let's
 start
 with
 some
 like
 really
 just


like
 rudimentary
 questions.
 Just
 the


first
 one
 is
 like
 Hudson
 River
 Trading


as
 a
 company.


>> Yeah.


>> How
 does
 it
 make
 money?


>> Yeah.
 So
 we
 are
 a
 sort
 of
 quantitative


>> Yeah.


>> automated
 proprietary
 trading
 firm
 which


is
 a
 lot
 of
 words
 but
 I
 guess
 the
 way
 I


see
 it
 is
 we
 are
 a
 service
 provider
 to


markets.


>> Okay.
 The
 most
 clear
 example
 is
 market


making.
 There
 is
 like
 a
 sort
 of
 utility


to
 the
 world
 of
 being
 ready
 to
 buy
 or


sell
 any
 product
 anytime
 anywhere.
 And


for
 us
 that
 means
 stocks,
 futures,


options,
 crypto,
 bonds.
 And
 if
 you
 could


say
 build
 a
 magical
 machine
 to
 quote
 a


price
 to
 buy
 or
 sell
 at
 any
 instrument


and
 you
 would
 want
 to
 be
 like
 the
 best


possible
 price,
 like
 the
 tightest
 price,


people
 would
 trade
 with
 you.


>> Yeah.
 they
 would
 be
 happy
 because


there's
 a
 counterparty
 for
 their
 trade


and
 they
 get
 a
 kind
 of
 good
 price
 like
 a


low
 spread
 and
 we're
 happy
 because
 we


essentially
 pick
 up
 a
 penny
 in
 front
 of


a
 steamroller.
 Like
 we
 are
 making
 sort


of
 money
 from
 that
 spread
 and
 we
 can


pick
 up
 the
 pennies
 in
 front
 of
 a


steamroller
 if
 we
 have
 a
 really
 magical


device
 which
 tells
 us
 how
 everything


should
 be
 worth
 the
 steamroller
 is


coming.


>> Yeah,
 it
 tells
 us
 when
 the
 steamroller


is
 coming.
 And
 so
 I
 I
 think
 that's
 kind


of
 the
 very
 very
 sophisticated
 sort
 of


middleman
 in
 some
 sense
 in
 the
 same
 way


that
 Amazon
 is.
 Amazon
 doesn't
 make


stuff
 but
 is
 a
 very
 valuable
 profitable


company.
 Provides
 a
 service
 people
 get


value
 of.
 Same
 thing.
 We're
 moving
 stock


spawns
 through
 time
 and
 space
 between


different
 counterparties.
 And
 yeah,


>> we
 will
 ask
 you
 about
 the
 steamroller
 in


a
 few
 minutes.
 But
 before
 we
 do
 that,


how
 does
 AI
 or
 the
 way
 you're
 using
 AI


actually
 differ
 from
 the
 algorithmic
 or


quant
 trading
 of
 old?
 Because
 I
 guess


that
 one
 of the
 questions
 is
 is
 this,


you
 know,
 a
 sort
 of
 evolutionary
 change,


you
 know,
 maybe
 a
 marginal
 improvement


on
 what
 already
 exists
 or
 is
 this


something
 seismic
 and
 a
 step
 change
 the


big
 shift
 in
 the
 way
 trading
 actually


works.


>> Yeah,
 I
 mean
 I
 don't
 want
 to
 over


overstate
 ourselves
 in
 some
 sense


because
 in
 the
 space
 as
 you
 mentioned


before
 it's
 very
 like
 opaque
 what
 sort


of
 different
 firms
 of
 this
 class
 are


doing.
 I
 can
 certainly
 speak
 to
 our
 own


experience
 which
 is
 we've
 been
 doing


this
 type
 of
 trading
 for
 20
 plus
 years


and
 much
 like
 everyone
 who
 was
 doing


this
 the
 way
 it
 kind
 of
 worked
 was
 you


handcraft
 features
 that
 sort
 of
 based
 on


human
 intuition
 oh
 I
 don't
 know
 the


order
 book
 looks
 imbalanced
 there's
 more


people
 wanting
 to
 buy
 than
 sell
 the


price
 is
 going
 to
 go
 up
 soon
 or


something
 like
 that
 and
 maybe
 you
 you


get
 a
 bunch
 of
 very
 smart
 people
 and


they
 think
 very
 hard
 like
 it's
 almost


like
 making
 a
 very
 fancy
 watch
 you
 kind


of
 artistically
 craft
 all
 these
 pieces


and
 then
 maybe
 you
 use
 relatively
 simple


meth
 mathematical
 techniques
 like
 linear


regression
 to
 combine
 those
 predictors


and
 I've
 been
 going
 to
 conferences
 and


things
 and
 recruiting
 for
 a
 long
 time


and
 even
 if
 today
 just
 go
 on
 the


internet
 you'll
 people
 say
 things
 like


oh
 that's
 all
 you
 can
 do
 in
 finance
 for


some
 reason
 they'll
 say
 this
 they'll
 say


something
 like
 oh
 it's
 too
 noisy
 or


markets
 are
 too
 non-stationary
 or
 things


like
 this
 and
 so
 that's
 all
 you
 can
 do


and
 I
 guess
 that
 belief
 isn't
 really


backed
 up
 by
 anything
 in
 my
 my
 opinion


and
 like
 lived
 experience
 I
 guess
 and
 so


we
 sort
 of
 viewed
 it
 horror
 for
 a
 long


time
 is
 well
 basing
 in
 the
 world
 and


ideally
 you
 would
 put
 this
 into
 kind
 of


like
 a
 machine
 that
 does
 not
 have
 any


human
 biases.
 I
 don't
 know
 how
 to
 trade


stocks
 myself
 like
 I
 I
 buy
 broad
 market


ETFs.
 What
 do
 I
 know?
 And
 so
 we
 but
 if


you
 could
 put
 all
 the
 m
 data
 into
 a
 box


and
 it
 kind
 of
 could
 turn
 all
 that
 data


it
 would
 find
 things
 that
 you
 would


never
 be
 able
 to
 do
 this
 handcrafted


thing.
 And
 we
 started
 doing
 that
 very


early
 relatively
 in
 2014
 2013
 period.


And
 over
 time
 over
 the
 last
 sort
 of


decade
 or
 so
 much
 like
 in
 other
 contexts


that
 are
 not
 finance
 there
 has
 been
 sort


of
 a
 hockey
 stick
 and
 you
 can
 measure
 it


by
 the
 size
 of
 the
 models
 the
 compute


deployed.
 And
 over
 time
 that
 way
 of


modeling
 the
 markets
 initially
 was
 not


like
 a
 hybrid
 with
 the
 traditional
 way


kind
 of
 just
 like
 overtook
 it
 entirely.


And
 so
 now
 our
 trading
 is
 entirely


driven
 by
 this
 magical
 machine
 that


consumes
 all
 our
 data.
 I
 kind
 of
 keep


saying
 this
 magical
 machine
 that


consumes
 our
 data
 for
 a
 reason
 which
 is


that
 this
 is
 how
 chat
 GPT
 is
 trained.
 It


consumes
 all
 the
 data
 all
 the
 internet.


It's
 kind
 of
 scraped
 and
 connected
 into


one
 place.
 You
 train
 a
 model
 that
 kind


of
 takes
 it
 all
 and
 something
 emergent


comes
 from
 it.
 And
 that's
 why
 I'm
 kind


of


>> a
 bit
 leading
 but
 that's
 why
 I'm
 talking


about
 in
 the
 sense
 and
 I
 think
 that
 is


materially
 different
 from
 the
 like
 I'm


using
 my
 intuition
 of
 the
 markets
 to


kind
 of
 construct
 a
 predictive
 model.


>> So
 just
 to
 be
 clear
 how
 much
 of
 the


usefulness
 of
 AI
 here
 is
 about
 execution


and
 the
 fact
 that
 you
 can
 crunch
 a
 lot


of
 data
 really
 quickly
 with
 hundreds
 or


thousands
 of
 GPUs
 versus
 spotting


sophisticated
 patterns
 or
 discrepancies


that
 you
 can
 exploit.


>> I
 think
 it's
 both.
 I
 think
 one
 of
 the


things
 that
 people
 sort
 of
 missed
 with


the
 whole
 like
 do
 a
 linear
 regression


type
 thing
 is
 when
 you
 really
 think


about
 how
 much
 data
 there
 is
 in


financial
 markets
 generated
 and
 when
 I


say
 data
 I
 think
 it's
 important
 to
 think


of
 it
 as
 every
 event
 that
 happens
 in


markets
 not
 the
 sort
 of
 time
 series
 of


prices
 but
 like
 the
 actual
 low-level


substrate
 people
 are
 quoting
 trading


retracting
 quotes
 that
 like
 low-level


stuff
 is
 internet
 scale
 data
 set
 sizes


and
 one
 of
 our
 sort
 of
 bitter
 lessony


type
 things
 of
 AI
 was
 like
 You
 shouldn't


think
 too
 hard
 about
 how
 to
 feature


engineer
 this
 and
 pre-process
 it.
 You


should
 kind
 of
 throw
 it
 all
 in
 just


something
 a
 form
 of
 computation
 that
 can


kind
 of
 make
 use
 of
 internet
 scale
 data.


In
 the
 2010s,
 it
 was
 like
 computer


vision.
 People
 used
 to
 make
 detectors


for
 edges
 of
 images
 and
 things
 and
 they


would
 combine
 them.
 And
 same
 thing,
 it's


like
 that
 was
 a
 good
 approach,
 but
 you


know,
 it's
 completely
 dominated
 by
 the


idea
 of
 getting
 a
 very
 large
 number
 of


GPUs
 and
 a
 kind
 of
 a
 pretty
 generic


neural
 network
 form
 and
 powering
 through


it.
 As
 for
 like
 the
 how
 is
 it
 finding


things
 that
 other
 methods
 could
 not,


it's
 very
 hard
 to
 say.
 Our
 models
 are


not
 very
 interpretable.
 And
 I
 think


that's
 fine
 because
 as
 Joe
 mentioned,


our
 sort
 of
 trading
 style
 and
 holding


times
 are
 better
 thought
 of
 as
 like


minutes,
 hours,
 maybe
 like
 a
 low
 single


digit
 days
 for
 the
 most
 part.
 And
 I


guess
 in
 my
 mind
 it's
 unreasonable
 to


expect
 them
 to
 be
 interpretable
 because


I
 I
 don't
 know
 if
 I
 looked
 at
 the


orderbook
 data
 for
 Tesla
 or
 something.


Am
 I
 really
 going
 to
 be
 able
 to
 tell
 you


better
 than
 random
 what
 the
 price
 of


Tesla
 will
 be
 in
 a
 minute's
 time?
 And
 so


I
 kind
 of
 think
 it
 like
 that.
 If
 you


have
 something
 that's
 clearly
 superhuman


already,


>> what
 level
 of
 interpretability
 could
 you


expect?
 Like
 that's
 very
 different,


right,
 to
 normal
 AI,
 right?
 This
 is
 gets


into
 some
 areas
 that
 I'm
 very


interested,
 but
 just
 to
 like
 establish


what
 we're
 talking
 about.
 Yeah.
 You're


trading
 a
 stock
 like
 a
 Tesla,
 Nvidia,


etc.


>> With
 your
 magic
 machine,


>> magic
 machine.


>> Now,
 we
 had
 another
 episode
 where
 we


Well,
 that
 was
 the
 money
 box


>> as
 a
 magic
 box.


>> That's
 a
 different


>> That's
 a
 different
 one
 with
 this
 AI


machine
 that
 is
 sort
 of
 arguably
 grown,


right?
 It's
 sort
 of
 grown
 in
 a
 lab
 more


than
 it
 is
 programmed.
 Much
 like
 a


chatbot.
 I
 know
 it's
 a
 very
 different


technology.
 like
 what
 is
 the
 price
 of


Nvidia
 going
 to
 be
 tomorrow
 or
 what
 is


the
 price
 of
 Nvidia
 going
 to
 be
 this


afternoon?
 What
 you're
 saying
 is
 with


your
 technology
 you
 have
 a
 better
 a


better
 chance
 of
 getting
 that
 right
 that


you
 actually
 might
 be
 able
 to
 make
 an


informed
 prediction
 about
 the
 future
 in


a
 way
 that
 you
 couldn't
 have
 done
 say
 10


years
 ago.


>> Yes.


>> And
 that
 people
 who
 talked
 about
 this


they
 would
 come
 up
 with
 reasons
 oh
 the


stock
 market
 it's
 not
 like
 chess
 or
 go


and
 therefore
 you
 can't
 really
 do


predictions
 the
 same
 way.
 But
 what


you're
 saying
 is
 that
 with
 these
 models


which
 are
 different
 than
 LLMs,
 there
 is


some
 at
 least
 on
 a
 short
 time
 scale


predictive
 capacity.


>> Yes.
 I
 think
 I
 find
 this
 still
 to
 this


day
 a
 little
 bit
 hard
 to
 believe.
 I


think
 you
 get
 this
 kind
 of
 efficient


market
 hypothesis
 stuff
 jumped
 into
 your


head.
 It
 seems
 like
 someone's
 saying


they
 can
 predict
 like
 the
 price
 of
 a


stock
 in
 an
 hour.
 Your
 instinctual


reaction
 is
 incredulously
 like
 just


sounds
 like
 you're
 kind
 of
 bluffing
 or


making
 it
 up
 and
 but
 no,
 these
 models


can
 predict
 this.
 I
 think
 it's
 the
 way


to
 kind
 of
 reconcile
 the
 like
 really
 man


like
 kind
 of
 instinct
 is
 that
 the


predictions
 are
 very
 bad
 in
 some
 sense.


We
 don't
 normally
 talk
 about
 like


accuracy,
 but
 I
 think
 the
 way
 to
 think


about
 it
 is
 like
 the
 accuracy
 is
 like


50.1%
 type
 thing.
 Like
 they're
 only
 a


little
 bit
 better
 than
 random.


>> But
 I
 suppose
 an
 extra
 1%
 like
 blows
 up


your
 profits
 if
 if
 you're
 doing
 it
 at


scale.


>> Doing
 doing
 it
 at
 scale
 doing
 it
 enough


times
 and
 over
 time
 you
 kind
 of
 realize


the
 biased
 coin
 flip.
 And
 as
 for
 why
 it


might
 be
 possible
 to
 do
 this
 without


kind
 of
 invoking
 magic,
 it's
 like


>> markets
 are
 very
 beautiful
 interaction


of
 like
 many
 different
 parties,
 all
 the


different
 kind
 of
 utilities,
 risk


preferences
 and
 things


>> and
 the
 only
 way
 you
 really
 see
 what


people
 are
 doing
 is
 by
 like
 the
 actions


they
 take
 in
 markets
 and
 you
 kind
 of


>> it's
 sucking
 up
 all
 that
 like
 signal


micro
 signal
 and
 extrapolating.


>> The
 cynicism
 or
 the
 skepticism
 about
 the


possibility
 of
 machines
 that
 could


predict
 the
 price
 of
 stocks
 is
 a
 little


strange,
 right?
 Because
 machines
 ingest


data
 then
 whatever
 maybe
 they
 see
 a


pattern
 more
 likely
 than
 not
 this


constellation
 of
 data
 means
 tomorrow


will
 be
 green.
 Humans
 do
 this
 all
 the


time.
 What
 else
 do
 we
 have
 besides
 data?


Right?
 You
 have
 an
 analyst
 and
 they
 put


out
 a
 Tesla
 or
 whatever
 Nvidia
 is
 going


to
 go
 to
 $500
 a
 share.


>> How
 dare
 you
 insinuate
 I'm
 not
 smarter


than
 a
 computer.


>> We
 we're
 like
 all
 humans
 have
 this
 data


and
 much
 less
 data
 and
 yet
 humans
 are


making
 predictions
 all
 the
 time.
 There's


a
 whole
 industry
 of
 it.
 So
 the
 idea
 that


therefore
 a
 was
 for
 some
 reason
 a


computer
 couldn't
 do
 this
 with
 much
 more


data
 than
 analysts
 ever
 have
 this
 I


understand
 why
 the
 cynicism
 is
 comes
 off


as
 a
 little
 strange.


>> I
 think
 some
 of
 the
 doubt
 stems
 from


this
 idea
 that
 a
 lot
 of
 these
 models


tend
 to
 be
 backward-looking
 right
 and


some
 of
 them
 occasionally
 are
 pretty
 bad


at
 spotting
 or
 reacting
 to
 big
 regime


breaks.
 And
 I
 guess
 the
 thinking
 again


sometimes
 is
 that
 maybe
 humans
 are
 more


flexible,
 maybe
 more
 adaptive
 in
 their


thinking
 and
 they
 can
 kind
 of
 spot
 these


big
 cultural
 shifts.
 How
 do
 you
 actually


I
 guess
 prepare
 for
 those
 big
 pattern


changes?


>> Yeah,
 I
 was
 at
 HIT
 for
 CO
 and
 I
 thought


that
 was
 kind
 of
 like
 the
 most


>> that
 was
 a
 big
 pattern.


>> That
 was
 a
 big
 pattern
 break
 and
 things


went
 totally
 fine.
 Actually,
 it
 was
 more


of
 an
 engineering
 crisis
 in
 some
 ways.


stock
 market
 volumes
 exploded
 and
 every


system
 was
 just
 like
 screaming
 trying
 to


keep
 up
 with
 the
 volume
 of
 activity.
 But


in
 terms
 of
 the
 predictions,
 they
 stayed


quite
 good
 and
 I
 had
 to
 like
 reconcile


this
 in
 my
 head
 as
 well.
 I
 guess
 this
 it


is
 a
 matter
 of
 like
 horizon
 and
 like
 how


far
 in
 the
 future
 are
 we
 talking


intraday
 I
 think
 a
 lot
 of
 the
 price


movement
 is
 driven
 by
 just
 observing


like
 the
 flows.
 It's
 hard
 for
 us
 as


humans
 to
 observe,
 but
 it's
 like
 the


relative
 patterns
 of
 buyers
 and
 sellers


in
 the
 markets
 and
 it's
 like
 yes
 during


COVID
 the
 volatility
 was
 massive
 and


prices
 were
 moving
 up
 and
 down
 a
 lot
 but


they
 were
 going
 up
 and
 down


>> during
 say
 March
 2020
 and
 so
 these


models
 it
 was
 sort
 of
 out
 of
 domain
 for


a
 human
 but
 I
 don't
 think
 in
 out
 of


domain
 in
 some
 sense
 for
 the
 models


>> but
 I
 guess
 I
 also
 don't
 know
 how
 you


would
 apply
 this
 thinking
 if
 you
 were


trying
 to
 make
 sort
 of
 month
 ahead


predictions.
 I
 often
 get
 like
 people


being
 like,
 "Oh,
 everyone
 knows
 hedge


funds,
 which
 we're
 not
 a
 hedge
 fund,
 is


like
 a
 they're
 like
 flipping
 coins
 and


it's
 some
 survivor
 bias
 thing."
 And
 you


know,
 I
 genuinely
 don't
 know
 about


months
 out
 prediction
 stuff.
 That
 is
 not


a
 data
 rich
 environment.


>> I
 mean,
 just
 by
 definition,
 there
 have


been
 more
 days
 than
 months,
 right?
 And


so
 therefore,
 prediction
 on
 a
 day
 basis,


you're
 offered
 a
 lot
 more
 data.
 Is
 that


what
 you're
 saying?


>> That
 rule
 of
 thumb
 is
 basically
 very


useful.
 It
 is
 a
 and
 it
 extends
 all
 the


way
 down
 to
 seconds.


>> Yeah.
 And
 we
 see
 that
 empirically
 all


the
 time.
 And
 so
 yeah,
 I
 guess
 all
 the


things
 I'm
 saying
 do
 have
 this
 caveat


that
 it
 does
 rely
 on
 being
 a
 certain


level
 of
 signal
 to
 noise.
 I
 definitely


cannot
 make
 reasonable
 claims
 about
 the


price
 of
 things
 in
 like
 a
 month
 using


the
 same
 kind
 of
 like
 AI
 hammer.
 I
 guess


also
 to
 be
 specific,
 I'm
 talking
 a
 lot


about
 using
 market
 data
 to
 make
 these


predictions.
 And
 that's
 because
 on
 the


sort
 of
 intraday
 time
 scale,
 that
 is
 the


most
 important
 thing.
 It's
 all
 about


flows
 and
 things
 back
 and
 forth.
 If


you're
 thinking
 about
 things
 in
 a


month's
 time
 scale,
 I
 think that's


fundamentals.
 And
 can
 AI
 be
 used
 for


that?
 I
 don't
 know
 to
 be
 honest.
 And


it's
 definitely
 outside
 my
 wheelhouse.


And
 I
 guess
 people
 have
 various
 opinions


about
 that.
 And
 maybe
 some
 people
 very


much
 would
 like
 to
 claim
 that
 they
 can.


And
 you
 know,
 others
 maybe
 don't,
 but


it's
 definitely
 outside
 of
 my
 area
 of


expertise.
 And
 I
 I
 don't
 know.
 Wait,


talk
 to
 us
 about
 the
 data
 that
 you're


using
 or
 talk
 more
 because
 this
 is


another
 area
 where
 people
 tend
 to
 talk


in
 PR
 speak.
 Sometimes
 we


[clears throat]
 have
 access
 to
 all
 this


data,
 unusual
 data,
 alternative
 data,


and
 that's
 going
 to
 enable
 us
 to
 use
 AI


better.
 What
 are
 you
 actually
 looking


at?
 And
 what
 have
 you
 found,
 I
 guess,


most
 useful?
 Well,
 I
 think
 the
 thing


that
 I
 found
 most
 counterintuitive
 when


I
 started
 was
 that
 when
 you're
 thinking


about
 predicting
 the
 prices
 of
 anything


a
 minute,
 an
 hour
 out,
 by
 far
 the
 most


useful
 thing
 is
 just
 market
 data.
 This


is
 the
 market
 data
 feeds
 you
 can
 buy


from
 the
 exchanges
 for
 a
 pretty


reasonable
 price.
 People
 often
 think


this
 is
 some
 sort
 of
 like
 competitive


moat.
 the
 data
 fees
 for
 these
 exchanges


are
 not
 particularly
 high
 and
 in
 crypto


you
 know
 where
 it's
 like
 a
 wild
 west
 but


everyone
 can
 collect
 these
 feeds
 and
 so


that
 is
 the
 most
 useful
 raw
 ingredient


that
 is
 the
 most
 true
 expression
 of


everyone's
 intents
 right
 they're
 going


to
 the
 market
 they're
 quoting
 the
 buying


selling
 that
 is
 the
 primary
 ingredient


people
 get
 kind
 of
 caught
 up
 on
 the


whole
 like
 oh
 no
 do
 you
 have
 a
 Twitter


feed
 type
 of
 thing
 and
 Bloomberg
 sells
 a


Twitter
 feed
 through
 a
 state
 of
 products


and


>> buy
 that


>> buy
 that
 so
 it's
 every
 now
 and
 then


obviously
 something
 happens
 news
 happens


during
 market
 hours
 that
 moves
 the
 price


dislocates
 the
 price.
 But
 if
 you
 really


coldly
 rationalize
 that,
 that
 is
 a


relatively
 infrequent
 thing
 compared
 to


the
 overall
 massive
 markets.
 So
 for


thinking
 intraday,
 think
 these
 market


data
 feeds.
 It's
 literally
 like
 a
 little


events
 someone
 quoted
 at
 this
 price
 and


this
 size.
 It's
 all
 anonymous.
 Market


data
 feeds
 are
 anonymous.
 And
 so
 that
 is


the
 raw
 stuff
 and
 it
 is
 vast.
 There
 are


just
 millions
 and
 millions
 of
 events
 per


day
 per
 stock
 per
 future.
 When
 you
 get


to
 the
 day
 days
 time
 scale,
 that's
 where


the
 alternative
 data
 quote
 unquote
 kind


of
 really
 comes
 in.
 As
 in
 alternative
 to


market
 data,
 the
 SEC
 filings,
 the
 news


feeds,
 balance
 sheets,
 broker
 reports,


things
 like
 this.
 That's
 where
 that


comes
 in.
 And
 there's
 a
 vast
 sea
 of
 data


offerings
 that
 people
 try
 and
 sell
 that


I
 think
 in
 that
 kind
 of
 situation,
 you


it's
 a
 very
 low
 sharp
 environment
 you


start
 getting
 into.
 And
 it's
 it
 can
 be


hard
 to
 attribute
 the
 extra
 sharp
 each


of
 these
 things.
 But
 in
 some
 sense,
 it's


also
 very
 democratized.
 There
 are
 maybe


people
 collecting
 very
 secret
 data
 sets,


but
 my
 inbox,
 and
 I'm
 not
 even
 the


person
 in
 charge
 of
 buying
 these


alternative
 data
 sets,
 is
 often
 full
 of


people
 trying
 to
 sell
 me
 the
 latest


alternative
 data
 set.
 And
 I
 think
 a
 lot


of
 them
 don't
 necessarily
 have
 much


predictive
 value,


>> but
 clearly
 there's
 there's
 a
 market
 for


it.


>> What's
 the
 craziest
 one
 you've
 seen?


>> Huh?


>> Can
 you
 remember?
 I
 mean,
 people
 have


definitely
 reacted
 very
 strongly
 to
 the


Wall
 Street
 Bets
 era
 and
 tried
 to
 kind


of
 bunch
 of
 Reddity
 extracted
 thing
 and


go
 beyond
 just
 like
 raw
 captures
 of


Reddit
 and
 trying
 to
 distill
 it
 into


something.


>> But,
 you
 know,
 I
 just
 even
 just
 thinking


about
 it,
 the
 meme
 stock
 thing
 is
 kind


of
 almost
 talked
 about
 more
 after
 it


happens
 than
 it
 happens
 before.
 [music]


And
 so,
 like
 I
 I
 don't
 know.


>> [music]


[music]


>> This
 sort
 of
 a
 sideways
 question.
 You


mentioned
 interpretability
 and
 this
 got


me
 something
 I've
 been
 wondering
 about


AI
 for
 a
 while.
 Not
 even
 in
 the
 finance


realm
 specifically.
 You're
 a
 deep
 mind


which
 of
 course
 produced
 a
 great
 go


player
 better
 than
 the
 greatest


grandmaster
 in
 the
 world.
 I
 played


chess.
 We
 know
 that
 chess
 engines
 are


much
 better
 than
 any
 human.
 On
 the
 other


hand,


>> as
 far
 as
 I
 could
 tell,
 there
 is
 no
 good


AI
 chess
 tutor.
 So,
 in
 other
 words,
 the


chess
 crush,
 but
 like
 I've
 never
 been


able
 to
 like
 get
 a
 thing
 where
 it's


okay,
 you
 did
 this
 move,
 but
 you
 know


what,
 you're
 closing
 this
 rook
 file
 and


down
 the
 line
 because
 his
 like
 it


doesn't
 do
 that.
 The
 chess.com


human
 talk
 is
 very
 rudimentary,
 etc.
 Can


you
 talk
 a
 little
 bit
 about
 why
 there


are
 these
 problems
 where
 some
 version
 of


AI
 or
 machine
 learning
 or
 whatever
 can


do
 fantastically
 well,
 but
 then
 the


actual
 explanation
 of
 what
 it's
 doing,


which
 I
 think
 is
 kind
 of
 what


interpretability
 is,
 can't
 articulate
 in


a
 plain
 English
 why
 it's
 able
 to
 do
 what


it
 does.
 I
 think
 it's
 just
 because
 these


neuronet
 networks
 are
 some
 sense
 just


like
 a
 big
 old
 blob
 of
 numbers
 and
 what


we're
 aiming
 to
 do
 when
 we're
 training


these
 models
 is
 to
 almost
 like
 free


ourselves
 from
 almost
 all
 structure
 and


they
 might
 learn
 things
 in
 a
 way
 that
 is


nothing
 at
 all
 like
 how
 we
 learn
 things.


And
 so
 my
 my
 my
 best
 guess
 for
 like
 why


it's
 hard
 is
 because
 they
 might
 be


reasoning
 in
 some
 sense
 internally.
 And


people
 use
 these
 words
 like
 reasoning.


It
 kind
 of
 makes
 me
 wse.
 I've
 seen


imagination
 and
 things
 used
 about
 neural


networks.
 My
 god,
 I
 don't
 know.
 It's


like
 kind
 of
 anthropomorphization
 of


them
 is
 kind
 of
 dangerous
 because
 they


are
 essentially
 processing
 things


internally
 in
 this
 way
 that
 I
 think
 is


inherently


>> not
 like
 how
 we
 do
 and
 that
 is
 my
 best


sort
 of
 guess.
 There
 are
 some


interesting
 counter
 examples.
 One
 of
 my


favorite
 sort
 of
 things
 in
 the
 past


couple
 years
 was
 Golden
 Gate
 Claude


which
 was
 anthropic
 made
 the
 model


basically
 get
 very
 interested
 in
 the


Golden
 Gate
 Bridge
 and
 every
 question


they
 asked
 would
 come
 back
 to
 the
 Golden


Gate
 Bridge.
 And
 so
 they're
 not


completely
 impenetrable.


>> Yeah.


>> But
 it's
 clear
 that
 like
 it
 gets
 hard


beyond
 a
 point
 to
 kind
 of
 map
 this
 back


to
 how
 anyway
 like
 we
 think
 and
 it's


it's
 very
 tempting
 to
 and
 exciting
 to


and
 especially
 for
 like
 AI
 safety


applications
 which
 aren't
 really


relevant
 to
 me
 so
 much
 but
 I
 think
 it's


very
 tempting
 to
 try.


>> Yeah.


>> No,
 it
 strikes
 me
 is
 that
 if
 you
 could


solve
 that
 many
 jobs
 would
 you
 could


actually
 make
 a
 lot
 of
 productivity


gains.
 But
 I
 do
 think
 that's
 an


important
 hurdle
 when
 you're
 training


your
 models.
 So
 your
 models
 are


different
 than
 large
 language
 models


etc.
 But
 what
 they
 have
 in
 common
 is


this
 incredible
 amount
 of
 data,


incredible
 amount
 of
 compute
 demand.
 How


applicable
 if
 someone
 had
 worked
 on
 LLMs


would
 your
 training
 process
 be
 to
 them?


How
 interpret
 how
 could
 they
 move
 from


that
 environment
 to
 yours?
 Are
 there


enough
 similarities
 in
 the
 basic
 notions


and
 compute
 and
 requirements
 to
 train
 a


model
 such
 as
 yours
 versus
 what
 people


are
 doing
 at
 the
 major
 labs?


>> I
 would
 say
 now
 in
 2025
 absolutely.


>> Okay.
 But
 I
 would
 not
 have
 said
 that
 in


2020.
 And
 this
 is
 something
 that
 kind
 of


just
 caught
 me
 by
 surprise
 having
 done


this
 for
 a
 while
 now
 is
 that
 our


problems
 are
 kind
 of
 defined
 by
 long


sequential
 strings
 of
 information
 in


some
 sense
 and
 extrapolating
 from
 that.


If
 I
 think
 back
 to
 the
 past
 of
 AI,
 it


was
 like
 is
 this
 a
 is
 this
 is
 this
 like


a
 hot
 dog
 or
 not?
 It's
 kind
 of
 like
 the


like
 image
 classifier,
 you
 know,
 test.


>> Then
 uh
 there
 was
 some
 stuff
 with
 audio


and
 things
 that
 was
 a
 little
 bit
 more


familiar.
 robotics.
 Eh,
 but
 when
 we
 got


to
 this
 sort
 of
 LLM
 era,
 it
 got
 very


interesting
 because
 suddenly
 the


problems
 were
 very
 similar
 in
 that
 you


have
 you
 want
 to
 think
 back
 over
 like


long
 histories,
 long
 context.
 Okay,
 that


sounds
 good.
 You've
 got
 a
 lot
 of
 data


and
 you
 want
 to
 turn
 through
 it
 in
 as


efficient
 way
 as
 possible.
 You
 also
 have


to
 serve
 this
 model.
 This
 model
 has
 to


run
 in
 like
 a
 relatively
 reasonable


speed.
 uh
 especially
 for
 the
 LM
 places


there
 are a
 million
 people
 typing
 into


chatgbt.com
 and
 they
 want
 to
 hear
 a


response
 in
 a
 relatively
 prompt
 manner


of
 course
 for
 us
 also
 the
 models
 have
 to


make
 their
 predictions
 in
 a
 prompt


manner
 of
 ways
 the
 predictions
 aren't


useful
 so
 all
 these
 things
 mean
 that
 our


sort
 of
 way
 of
 thinking
 about
 it
 has


become
 very
 similar
 to
 the
 frontier
 LLM


things
 it's
 just
 a
 very
 different


modality
 we're
 operating
 on
 I
 guess


primarily
 text
 and
 we're
 operating
 on


this
 fileless
 interpretable
 but
 still
 a


sequential


stream
 of
 tokens


except
 our
 tokens
 are
 market
 events.
 And


so
 it's
 a
 lot
 of
 fun
 because
 you
 know
 in


terms
 of
 like
 the
 research
 that
 is
 still


published
 you
 can
 kind
 of
 look
 at
 it
 for


inspiration
 and
 draw
 comparisons
 but


it's
 also
 it's
 very
 much
 its
 own
 problem


which
 is
 kind
 of
 keeps
 me
 interested


every
 day
 because
 it's
 like
 its
 own


unique
 thing
 but
 it's
 different.
 I
 want


to
 go
 back
 to
 the
 point
 you
 made
 about


data
 and
 I
 guess
 democratizing
 finance


in
 many
 ways
 and
 maybe
 this
 is
 a
 weird


question
 but
 I'm
 thinking
 back
 to
 the


2010s
 and
 we
 used
 to
 talk
 about
 the
 big


investment
 banks
 as
 flow
 monsters.
 They


see
 all
 these
 orders.
 They
 get
 all
 these


orders.
 They
 see
 all
 the
 flow
 and
 that


allows
 them
 to
 optimize
 on
 funding
 costs


and
 other
 expenses.
 is
 the
 idea
 that


data
 and
 AI
 can
 kind
 of
 replicate
 that


advantage
 so
 that
 everyone
 or
 not


everyone
 but
 Hudson
 at least
 becomes
 its


own
 little
 flow
 monster.
 Yeah,
 I
 think


there's
 still
 some
 trends
 and
 markets


that
 worry
 me
 a
 little
 bit
 in
 terms
 of
 I


guess
 our
 platonic
 ideal
 market


structure
 is
 probably
 like
 everyone


trades
 on
 exchange
 in
 a
 centralized


place,
 but
 that
 is
 not
 really
 how
 things


seem
 to
 be
 going
 and
 there's
 a
 huge


amount
 of
 like
 off
 exchange


dark
 quasi
 dark
 volume
 and
 I
 think


there's
 still
 a
 lot
 of
 corners
 of
 the


trading
 world
 where
 like
 being
 in
 the


room
 is
 kind
 of
 like
 this
 big
 advantage


and
 this
 is
 a
 very
 much
 anti-AII
 play
 in


some
 sense.
 data
 is
 hidden.
 The
 data
 the


flow
 data
 is
 hidden
 and
 it's
 not


something
 that
 you
 can
 feed
 into
 a


machine
 because
 there's
 very
 sparse


amounts
 of
 it.
 And
 so
 that's
 kind
 of
 a


an
 interesting
 trend.
 A
 lot
 of
 this
 data


gets
 reported
 in
 a
 centralized
 place


later,
 but
 it's
 not
 prompt
 enough
 to
 be


useful.
 And
 so
 to
 extend
 that
 AI
 thrives


on
 data,
 this
 is
 in
 some
 sense
 like
 an


issue
 for
 the
 long
 run,
 you
 need
 to
 kind


of
 be
 in
 the
 rooms
 where
 the
 sort
 of


trading
 is
 happening.
 I'm
 glad
 you


brought
 that
 up
 because
 that's


specifically
 what
 I'm
 curious
 about
 from


the
 sort
 of
 physical
 infrastructure


side.
 Like
 if
 I
 have
 a
 query
 at
 a
 chat


GPT,


>> I
 don't
 care
 if
 the
 model
 is
 like


trained
 in
 like
 Ebene,
 Texas
 or
 yeah,


wherever
 it
 gets
 back
 to
 me,
 I
 don't


whatever.
 But
 I
 know
 that
 for
 high


frequency
 trading
 at least
 on
 the


execution
 side
 there
 are
 certain
 parts


that
 you
 want
 to
 be
 literally


coll-located
 and
 you
 want
 to
 have
 the


shortest
 possible
 wire
 and
 however
 short


it
 is
 ideally
 you'd
 like
 it
 to
 be


shorter.
 Can
 you
 talk
 about
 the


differences
 and
 similarities
 between


essentially
 your
 physical
 hardware
 stack


versus
 what
 would
 be
 required
 at
 a
 large


language
 model
 frontier
 lab.


>> Yeah
 like
 that.
 I
 think
 at
 a
 bulk
 level


there's
 actually
 some
 pretty
 similar


things.
 So
 there's
 often
 think
 about
 it


as
 like
 latency
 and
 throughput.
 Latency


being
 the
 time
 to
 react
 and
 then


throughput
 kind
 of
 like
 how
 much


thinking
 you
 can
 do
 in
 a
 certain
 period


of
 time.


>> And
 so
 you're
 right
 that
 like
 this
 space


demands
 like
 low
 latency.


>> Early
 in
 the
 2010s
 it
 was
 a
 sort
 of


flash
 boys
 book
 and
 perception
 where
 it


was
 like
 really
 kind
 of
 about


arbitrageing
 latency.
 I'm
 happy
 to


report
 that
 in
 some
 sense
 all
 the


latency
 has
 been
 arbitrageed
 for
 the


most
 part.
 [laughter]
 There's
 no
 more


edge
 in
 shortening
 the
 wire.


>> There's
 there's
 probably
 like
 a
 little


bit,
 but
 it's
 it's
 relatively
 small.
 And


like
 I
 think
 if
 you
 look
 at
 the
 big


quant
 trading
 firms,
 the
 the
 need
 to


like
 really
 make
 the
 wires
 as
 short
 as


they
 possibly
 can
 is
 done
 or
 no
 longer


relevant,
 which
 is
 great
 cuz
 I
 find
 that


stuff
 pretty
 boring.
 Personally,
 I
 think


about
 it
 more
 as
 like
 for
 a
 given
 kind


of
 like
 speed
 of
 response,
 you
 should
 be


the
 smartest
 person.
 So
 there's
 like


this
 curve.
 If
 you're
 going
 to
 take
 a


second
 to
 come
 up
 with
 your
 trading


decision,
 better
 be
 a
 really
 really
 good


decision.
 And
 then
 it
 doesn't
 kind
 of


matter
 that
 it
 took
 a
 second.
 And
 if


you're
 going
 to
 take
 a
 microscond,
 well,


a
 you
 probably
 can't
 do
 too
 much
 in
 a


microcond,
 but
 you
 know,
 it
 better
 still


be
 the
 best
 response
 in
 a
 microcond.
 And


so,


>> but
 you
 could
 be
 a
 little
 worse.


>> You
 could be
 a
 little
 worse.


>> And
 then
 the
 second
 the
 second
 for
 sure.


And
 so
 essentially
 for
 our
 training,
 we


use
 the
 cloud.
 We
 have
 our
 own
 training


data
 centers
 that
 we've
 built
 ourselves.


That
 is
 basically
 the
 same
 although
 much


much
 smaller
 scale.
 the
 scale
 of
 Googles


and
 things.
 I
 don't
 know.
 It
 blows
 my


mind
 for
 spending
 on
 on on
 stuff
 like


this.
 We
 are
 I
 think
 big
 if
 you're
 not


comparing
 us
 to
 Google
 or
 Meta,
 but
 not


that's
 not
 like
 bajillions
 of
 dollars.


So
 training
 is
 is
 kind
 of
 the
 same


inference.
 You
 we
 need
 to
 put
 the


devices
 close
 to
 the
 exchanges


>> and
 we
 need
 to
 think
 very
 hard
 about
 the


power
 usage
 and
 the
 latency,
 but
 we
 have


hardware
 teams.
 We
 make
 our
 own
 FPGAAS.


We
 make
 our
 own
 chips
 and
 we
 use


off-the-shelf
 GPUs.
 And
 what
 we
 try
 and


do
 is
 we
 try
 and
 make
 sure
 that
 for
 any


given
 sort
 of
 speed
 of
 response,
 we're


making
 the
 smallest
 possible
 decision
 we


can.
 So
 you
 can
 kind
 of


>> field
 programmable
 gate
 array.


>> Oh,
 there
 you
 go.
 Sorry.
 FPGA.


>> FPGA.
 Yeah.
 Basically,
 all
 these


different
 devices
 have
 different


latencies
 and
 throughputs.
 GPUs
 have


very
 high
 throughput.
 They
 are
 that's


what
 they're
 useful
 for,
 right?
 And
 so,


but
 the
 problem
 with
 markets
 is
 they're


kind
 of
 like
 narrow.
 The
 amount
 of


traffic
 flowing
 into
 these
 like
 LLMs


from
 everyone
 typing
 into
 their
 web


browsers
 is
 just
 massive.
 and
 they
 do


all
 sorts
 of
 clever
 things
 to
 kind
 of


batch
 up
 requests
 and
 process
 and


things.
 We
 don't
 really
 have
 that
 luxury


really
 like
 the
 markets
 are
 going
 to


happen
 at
 the
 speed
 they
 happen.
 We


can't
 kind
 of
 like
 duck
 out
 for
 a
 while


and
 catch
 up.
 We
 kind
 of
 need
 to
 stay
 in


the
 game.
 So,
 we
 have
 all
 these
 sort
 of


interesting
 design
 challenges
 around
 how


do
 we
 use
 GPUs
 which
 are
 relatively
 high


latency.
 They
 take
 a
 while
 to
 get
 back
 a


result,
 but
 they
 can
 process
 the
 whole


stock
 market
 on
 one
 GPU
 type
 of
 thing


versus
 the
 fast
 response.
 And
 so,
 we


have
 whole
 teams
 dedicated
 to
 thinking


about,
 okay,
 I've
 got
 this
 like


intelligent
 blob.
 How
 do
 I
 get
 answers


out
 of
 it
 in
 different
 ways
 at
 different


speeds?
 And
 that
 I
 think
 is
 where
 a
 lot


of
 us
 smarts
 are
 going
 in
 this
 world


these
 days
 rather
 than
 the
 like
 how
 do
 I


make
 sure
 my
 microwave
 towers
 are
 like


slightly
 better
 aligned
 somewhere
 in


like
 rural
 Pennsylvania
 like
 which
 is
 a


cool
 challenge
 in
 its
 own
 right
 but
 it's


done.
 I
 think
 I
 think
 people
 have
 found


the
 straightest
 line
 from
 New
 Jersey
 to


Chicago.


[music]


>> [music]


[music]


>> Joe
 brought
 up
 some
 of
 the
 cynicism


around
 CME's
 cloud
 deal
 with
 Google
 and


this
 came
 up
 speaking
 of
 a
 specific


cynic
 who
 went
 on
 the
 record
 in
 one
 of


our
 episodes.
 Don
 Wilson
 basically
 made


the
 argument
 that
 matching
 on
 a
 cloud


doesn't
 necessarily
 make
 sense
 because


you
 might
 put
 in
 two
 orders
 and
 you're


not
 really
 sure
 which
 order
 gets
 filled


first.
 I
 guess
 you're
 kind
 of
 back
 in


that
 blackbox
 environment
 or
 maybe
 it's


a
 latency
 issue.
 I
 don't
 know.
 Is
 that
 a


problem
 that
 you're
 seeing?


>> It's
 something
 that
 I
 I
 worry
 about.
 Our


general
 philosophy
 is
 market
 should
 be


very
 like
 transparent
 and
 as
 fair
 as


possible.
 So
 like
 equalizing
 access
 is
 a


good
 thing
 in
 terms
 of
 participants


shouldn't
 be
 able
 to
 like
 basically
 pull


weird
 tricks
 to
 be
 faster.
 On
 the
 other


hand,
 I
 think
 you
 want
 reliability.
 So


like
 this
 concept
 of
 like
 orders


arriving
 at
 different
 times
 and
 being


filled
 in
 different
 orders
 just
 doesn't


seem
 like
 a
 very
 sensible
 way
 to
 run
 a


market.
 It's
 something
 that
 requires
 a


lot
 of
 effort
 to
 engineer
 around
 and


it's
 just
 a
 good
 market
 design
 to
 have.


It
 is
 a
 very
 widespread
 though
 in


existing
 exchanges
 across
 the
 world.
 We


trade
 in
 like
 a
 vast
 number
 of
 countries


and
 some
 of
 the
 exchanges
 have
 such


amazing
 hardware
 that
 like
 if
 two
 orders


are
 sent
 within
 like
 a
 nancond
 of
 each


other,
 this
 exchange
 will
 never
 process


them
 in
 the
 wrong
 order.
 Even
 if
 there's


a
 100
 different
 network
 ports
 and


they're
 all
 connected,
 they
 have
 this


amazing
 timestamping
 stuff.
 On
 the
 other


hand,
 you
 might
 have
 like
 a
 crypto


exchange
 where
 it
 kind
 of
 feels
 like
 a


kid
 learned
 JavaScript
 and
 and
 ran
 set


up
 a
 website
 and
 you're
 kind
 of
 like
 you


send
 an
 order
 and
 you
 may
 or
 may
 not
 be


confirmed
 that
 they
 even
 received
 it
 and


then
 you
 kind
 of
 have
 to
 refresh
 your


like
 account
 balance
 page
 like
 5
 minutes


later
 to
 see
 if
 there's
 money
 in
 it
 or


not.
 And
 we
 kind
 of
 we'll
 take
 we'll


deal
 with
 it
 as
 it
 is.
 But
 certainly
 we


have
 a
 preference
 for
 kind
 of
 equalized


access
 but
 sort
 of
 predictable
 outcomes.


And
 I
 think
 that
 kind
 of
 leads
 to
 like


people
 spending
 effort.
 I
 think
 it's
 not


a
 necessarily
 a
 very
 great
 thing
 for


society
 for
 people
 to
 be
 like
 stressing


very
 hard
 about
 YLM.


>> Yeah.
 No,
 probably.
 I'm
 glad
 I'm
 glad


that
 you
 report
 that
 we've
 uh
 moved
 on
 a


little
 bit
 since
 then.
 Where
 are
 your


constraints?
 You
 know,
 when
 you
 talk
 to


LLM
 people,
 there's
 debates
 about
 right


is
 it
 electricity?
 Is
 that
 the
 big


constraint?
 Is
 it
 there
 just
 aren't


enough
 GPUs?
 Is
 it
 talent?
 Is
 it


whatever?
 when
 you
 think
 about
 where
 you


are
 now
 versus
 the
 optimal
 version
 of


where
 or
 is
 it
 I
 mean
 data
 is
 the
 other


big
 one
 because
 there's
 all
 this
 concern


that
 LLMs
 are
 going
 to
 run
 out
 of


training
 data
 etc
 where
 is
 the
 big


constraint
 for
 you
 that
 you
 feel
 like


you're
 solving
 for
 right
 now


>> I
 think
 in
 terms
 of
 like
 really
 the


long-term
 strategic
 planning
 electricity


is
 like
 quite
 clearly
 a
 very
 binding


consideration
 when
 we
 think
 about


spinning
 up
 new
 like
 GPU
 based
 training


data
 centers


>> it
 really
 feels
 like
 is
 there


electricity
 like
 finding
 pie
 piece
 of


land
 to
 put
 a
 building
 in.
 There's
 a
 lot


of
 land.


>> Yeah.


>> The
 electricity
 negotiations


>> and
 that's
 an
 issue
 at
 HRT
 that
 thinking


about


>> even
 for
 us,
 you
 know,
 because
 we
 have
 a


sort
 of
 hybrid
 mix
 of
 using
 cloud


providers
 and
 building
 our
 own
 data


centers
 and
 yeah,
 the
 negotiations
 and


thinking
 about
 power
 constraints.
 We


have
 an
 existing
 data
 center
 in
 a
 very


cold
 place
 and
 we
 want
 to
 make
 it
 bigger


and
 the
 data
 center
 people
 are
 fantastic


to
 work
 with
 but
 they're
 saying
 like


well
 we
 need
 to
 go
 talk
 to
 like
 the


power
 grid
 and
 negotiate
 this
 next


trunch
 and
 so
 on
 and
 it's
 just
 it
 often


feels
 like
 that
 is
 the
 bottleneck
 and
 on


the
 terms
 of
 a
 GPU
 availability
 it


definitely
 was
 a
 crunch
 uh
 at
 some
 point


in
 the
 past
 but
 I
 don't
 feel
 like
 that


is


>> can
 you
 say
 a
 little
 bit
 more
 the
 entire


stock
 market
 is
 riding
 on
 say
 a
 little


bit
 more
 about
 how
 you
 perceive
 the
 GPU


I
 think
 I
 think
 if
 we
 ask
 for
 GPUs
 we


will
 get
 them
 delivered
 in
 a
 prompt


manner
 not
 necessarily
 like
 next
 day
 but


I
 don't
 feel
 like
 that
 is
 the
 thing
 that


we
 have
 a
 long
 pole
 and
 spinning
 up
 more


>> when
 was
 the
 when
 was
 the
 worst
 of
 the


crunch


>> I
 guess
 2023
 late
 2023
 felt
 pretty
 bad
 I


was
 I
 guess
 that
 was
 like
 the
 Nvidia


hopper
 generation
 and
 I
 saw
 some
 number


in
 Bloomberg
 yesterday
 that
 I
 think
 it


was
 like
 Nvidia
 conference
 yesterday
 and


they
 said
 something
 like
 it
 was
 like
 1


million
 hopper
 class
 GPUs
 have
 been


made,
 but
 already
 like
 4
 million


Blackwell
 class
 GPUs
 have
 been
 made.
 So,


I
 think
 there's
 been
 a
 ramp
 up
 of


supply,
 but
 I
 don't
 think
 they're
 also


sitting
 on
 unsold
 inventory
 either.
 I


think
 it
 is
 being
 consumed,
 but
 yeah,
 in


terms
 of
 like
 what
 is
 the
 hard
 thing?
 I


think
 electricity
 and
 I'm
 it's
 insane.
 I


as
 a
 very
 millennial
 person,
 I
 guess


climate
 change
 was
 a
 big
 thing
 growing


up
 in
 college.
 a
 lot
 of
 discussion
 about


climate
 change.
 And
 to
 see
 people


spinning
 up
 data
 centers
 very
 fast
 by


basically
 buying
 as
 many
 gas
 turbines
 as


they
 can
 and
 putting
 them
 outside.
 I'm


like,


>> whoa.
 Like
 what
 are
 we
 doing?
 It's
 wild.


But
 that's
 like
 the
 only
 way
 to
 get


electricity
 promptly.
 You
 just
 have
 to


throw
 gas
 turbines
 outside
 the
 building


and
 turn
 them
 on.
 I
 It's
 pretty
 radical


stuff.
 And
 I
 don't
 know
 how
 all
 the


numbers
 that
 people
 are
 talking
 about


for
 future
 data
 center
 expansion
 kind
 of


math
 out
 because
 you
 just
 back
 of
 the


envelope
 that
 power
 usage
 and
 things
 and


I
 I
 know
 that
 the
 Sam
 Almans
 of
 the


world
 have
 thought
 about
 this
 talked


about
 this.
 Oh,
 we
 need
 to
 be
 generating


this
 much
 new
 power
 generation
 per
 unit


time
 but
 there
 there's
 such
 daunting


numbers.
 I
 just
 don't
 know
 how
 that
 is


all
 going
 to
 work
 out.
 But
 yeah,
 even


for
 us
 in
 the
 grand
 scheme
 of
 things


like
 a
 much
 smaller
 player
 in
 terms
 of


power
 consumption.
 We
 think
 in
 terms
 of


like
 tens
 of
 megawatts
 and
 not
 gigawatts


which
 is
 more
 in
 most
 towns
 and
 cities


and
 things
 but
 still


>> and
 but
 we
 find
 it
 like
 a
 challenge
 to


find
 electricity
 at
 a
 reasonable
 price.


Wait,
 on
 this
 note,
 can
 you
 talk
 to
 us
 a


little
 bit
 more
 about
 where
 competitive


advantage
 actually
 comes
 from
 in
 this


space?
 Because
 if
 the
 GPU
 crunch
 is


somewhat
 solved
 and
 if
 latency
 isn't
 as


big
 an
 issue
 as
 it
 used
 to
 be,
 where
 are


people
 actually
 getting
 their
 edge
 from?


>> Right.
 I
 mean,
 people
 talent
 was
 one
 of


your
 other
 things
 as
 a
 constraint.
 Yeah,


it
 is
 it
 is
 a
 very
 competitive
 people


market.
 We're
 essentially
 asking
 for


people
 to
 know
 a
 lot
 of
 things,
 be
 both


good
 researchers
 and
 good
 engineers


because
 I
 don't
 know
 in
 this
 AI
 era
 of
 a


distinction
 is
 pretty
 blurry.
 It's
 not


something
 you
 can
 just
 whiteboard
 and


then
 the
 coding
 is
 a
 little
 bit


afterwards.
 Any
 kind
 of
 research
 idea


you
 have
 is
 intimately
 connected
 to
 how


you
 implement
 it.
 So
 that's
 already
 like


a
 tough
 ask.
 So
 people
 are
 constrained


people
 that
 we
 like
 I
 want
 to
 find
 and


we
 pay
 well
 for
 those
 people
 as
 a
 result


and
 it
 is
 competitive.
 But
 I
 think
 the


more
 subtle
 edge
 is
 almost
 like
 putting


[snorts]
 it
 all
 together.
 Do
 you
 have


people
 who
 can
 like
 an
 engineering
 team


that
 can
 collect
 all
 the
 data,
 record


it,
 make
 it
 available
 to
 the
 GPU


training
 data
 center?
 This
 is
 like
 many


I
 guess
 it's
 pabyte
 scale
 data
 set
 of


sets
 and
 just
 storing
 that
 much
 data


streaming
 it
 from
 wherever
 it's
 stored


to
 wherever
 in
 the
 world
 the
 training


data
 center
 is
 reliably.
 These
 training


runs
 are
 very
 expensive.
 And
 then
 once


you've
 got
 that
 model
 serving
 it,
 so
 it


kind
 of
 sounds
 do
 everything.
 And
 maybe


that's
 kind
 of
 like
 a
 lame
 answer,
 but


it
 really
 is.
 It's
 I
 think
 you
 need
 to


be
 just
 optimizing
 the
 whole
 stack.
 And


so
 like
 my
 team
 is
 like
 the
 AI
 team.
 And


so
 and
 that
 what
 that
 really
 means
 in


practice
 is
 we're
 focused
 on
 training


the
 models
 which
 is
 an
 important
 but
 not


sufficient
 part
 of
 a
 whole
 stack
 because


we
 would
 be
 kind
 of
 dead
 in
 the
 water


without
 the
 teams
 at
 HRT
 who
 who
 think


about
 how
 to
 like
 actually
 kind
 of
 get


the
 data
 and
 and
 things
 to
 these
 systems


and
 then
 the
 decisions
 out
 to
 the


markets
 and
 keep
 up
 when
 things
 get
 busy


all
 these
 things.
 So
 when
 I
 think
 about


our
 competitors
 I
 think
 there
 is
 a


benefit
 to
 to
 scale.
 I
 can't
 imagine
 how


you
 would
 start
 a
 new
 company
 like
 HRT


in
 the
 year
 2025
 because
 of
 the
 huge


initial
 lift
 to
 kind
 of
 build
 enough


engineering
 scale
 to
 to
 achieve
 this


sort
 of
 thing.
 And
 so
 I
 think
 our
 sort


of
 peer
 companies
 also
 have
 invested


very
 heavily
 in
 engineering
 and
 will


continue
 to
 do
 so.
 And
 there
 was
 an


article
 in
 the
 FT
 like
 a
 little
 like
 a


week
 or
 two
 ago
 about
 how
 firms
 like
 HIT


are
 kind
 of
 extending
 themselves
 more


into
 slower
 trading
 and
 there
 are
 firms


that
 are
 kind
 of
 you
 know
 those
 slower


firms
 are
 trying
 to
 kind
 of
 go
 faster


and


>> yeah
 I
 was
 just
 going
 to
 ask
 about
 just


like
 on
 the
 prediction
 standpoint.
 Okay,


maybe
 you
 could
 predict
 what's
 with
 some


reasonable
 confidence
 what's
 going
 to


happen
 in
 the
 next
 hour
 or
 sometimes
 if


you're
 lucky
 maybe
 a
 day.
 Like
 maybe
 a


month
 is
 just
 ridiculous.
 But
 do
 you
 in


your
 work
 is
 that
 horizon
 has
 it


broadened?


>> It
 is.
 Yeah.
 I
 think
 one
 of
 the
 things


for
 people
 who
 are
 aware
 of
 HRT
 even
 at


all
 I
 think
 is
 still
 a
 perception.
 It's


sort
 of a
 pre2020
 perception
 of
 like
 we


are
 purely
 high
 frequency
 trading
 firm.


But
 we
 would
 say
 we
 are
 both
 high


frequency
 and
 medium
 frequency
 trading


firm
 and
 it's
 like
 a
 big
 part
 of
 our


business.
 One
 way
 to
 think
 about
 it
 I


think
 is
 that
 by
 if
 I
 really
 have
 a
 view


on
 what
 a
 stock
 should
 be
 in
 like
 five


days
 time.
 Let's
 say
 I
 want
 to
 buy
 that


stock.
 I'm
 going
 to
 acquire
 that
 stock


overtime
 and
 maybe
 it's
 what's
 the
 best


time
 to
 buy
 that
 stock
 over
 the
 5day


period.
 Well,
 I
 have
 a
 model
 that
 tells


me
 that
 the
 best
 pricing
 in
 an
 hour.
 So


maybe
 the
 shorter
 term
 model
 should


inform
 the
 longer
 term
 trade
 and


cascading
 all
 the
 way
 down
 when
 you're


doing
 this
 sort
 of
 slightly
 longer
 term


or
 slightly
 slower
 frequency
 trading.
 Is


the
 fundamental
 job
 still
 the
 same
 which


is
 you're
 in
 the
 liquidity
 provision


service
 business
 just
 over
 longer
 you


want
 to
 hold
 that
 warehousing
 or
 does
 it


some
 because
 when
 I
 think
 of
 a
 fund
 when


I
 think
 of
 a
 hedge
 fund
 I
 certainly


don't
 think
 of


>> maybe
 to
 some
 extent
 some
 of
 their


strategies
 might
 be
 sort
 of
 liquidity


provision
 but
 it's
 more
 directional
 is


it
 still
 that
 or
 is
 the
 fundamental


reason
 why
 you
 make
 money
 the
 service


you
 provide
 does
 it
 change
 by
 definition


change
 over
 that
 horizon


>> I
 think
 the
 market
 making
 service


provision
 does
 break
 down
 I
 think
 It


stretches
 the
 analogy
 too
 far.
 I
 think


you
 have
 to
 think
 of
 it
 as
 like


liquidity
 taking
 which
 somehow
 seems


more
 like
 aggressive
 or
 something


>> but
 the
 we're
 trading
 against
 orders


resting
 on
 the
 books.
 Someone
 was
 like
 I


want
 to
 sell
 this
 stock
 and
 we're
 like


we
 will
 buy
 it
 from
 you
 because
 we
 think


that
 in
 the
 long
 run
 it'll
 be
 worth


doing
 it
 and
 so
 we
 do
 cross
 the
 spread


and
 we
 do
 pay
 this
 transaction
 cost


sometimes.
 You
 know
 you
 can
 also
 kind
 of


acquire
 position
 by
 market
 making
 but


with
 a
 tilt.
 So
 really
 at
 the
 longer


horizons
 I
 think
 the
 sort
 of


marketmaking
 service
 analogy
 does
 break


down
 but
 in
 some
 sense
 there's
 always
 a


counterparty
 and
 they
 wanted
 to
 trade


for
 a
 reason
 and
 I
 think
 a
 mental
 model


that


>> I
 don't
 know
 you
 tell
 me
 if
 this
 sounds


like
 too
 too
 wishy-washy
 but


>> I
 love
 a
 mental
 model.
 Uh
 you
 mentioned


go
 and
 chess,
 right?
 So
 the
 thing
 about


those
 is
 that
 they're
 they're
 zero
 sum


games
 is
 only
 one
 winner.
 It's
 truly


like
 a
 no
 like
 someone
 someone's


unhappy,
 someone
 wins
 and
 maybe
 equally


unhappy
 plus
 one
 minus
 one.


>> I
 think
 the
 reason
 that
 trading
 works
 is


because
 it
 is
 in
 some
 sense
 positive
 sum


you
 know
 money
 is
 conserved
 and
 I
 guess


a
 little
 fee
 goes
 to
 the
 exchange.
 So
 in


some
 sense
 money
 is
 at
 that
 moment
 of
 a


trade
 is
 actually
 negative
 a
 little
 but


utility
 people's
 general
 happiness
 I


don't
 know
 my
 paycheck
 goes
 into
 my
 401k


provider
 and
 it
 buys
 some
 ETFs
 I'm


relatively
 like
 insensitive
 to
 how


exactly
 that
 happens
 I
 just
 I'm
 not


going
 to
 look
 at
 it
 for
 another
 40
 years


right
 um
 don't
 lie
 my
 I
 try
 not
 to
 look


at
 it
 especially
 lately
 but
 uh
 yeah
 like


the
 utility
 my
 utility
 is
 a
 very
 long


horizon
 and
 so
 if
 someone
 sells
 it
 to
 me


like
 at
 1
 cent
 different
 I
 don't
 really


care
 so
 but
 like
 the
 person
 who
 made
 the


scents
 happy
 and
 I'm
 happy
 because
 I
 got


good
 liquidity,
 didn't
 cross
 a
 huge


spread.
 So
 that
 is
 kind
 of
 why
 I
 think


it
 it
 all
 kind
 of
 makes
 sense
 and
 why


people
 are
 trading
 together.
 But
 it's


also
 why
 like
 thinking
 about
 markets


like
 an
 alpha
 go
 sense
 doesn't
 make


sense
 because
 it's
 kind
 of
 doesn't


really
 apply.
 If
 you
 thought
 of
 markets


as
 HRT
 and
 and
 all
 our
 competitors
 all


kind
 of
 in
 some
 sort
 of
 like
 death


match,
 who's
 the
 smartest?
 Who's
 trying


to
 pick
 each
 other
 off?
 Then
 well


markets
 would
 be
 kind
 of
 like
 this
 giant


standoff
 where
 no
 one
 would
 be
 trading.


Everyone
 would
 be
 kind
 of
 be
 like


waiting.
 But
 obviously
 markets
 are
 very


vibrant.
 I
 think
 it's
 because
 even
 when


we're
 crossing
 the
 spread,
 it's
 because


we're
 crossing
 the
 spread
 against


someone
 who
 wanted
 to
 sell
 for
 whatever


reason.
 If
 we
 were
 right,
 I
 guess
 in
 5


days
 time
 they
 might
 be
 like
 less
 happy.


But
 maybe
 they
 weren't
 actually.
 Maybe


they
 were
 just
 like
 hedging
 a
 position.


They
 don't
 care
 what
 the
 stock's
 price


was
 in
 5
 days.
 They
 just
 wanted
 to
 like


hedge
 their
 position
 and
 we
 traded
 with


them.
 So
 that's
 the
 way
 I
 tell


reconcilers
 in
 my
 head.
 It
 could
 still


be
 like
 a
 sort
 of
 service
 provision.
 We


make
 money
 only
 because
 someone
 else


wants
 to
 trade.
 If
 no
 one
 was
 trading,


we
 wouldn't
 exist,


>> right?
 And
 different
 market
 participants


with
 different
 motivations
 and
 goals
 and


aims.
 I
 want
 to
 go
 back
 to
 the
 talent


question
 for
 a
 second.
 And
 I
 get
 the


sense
 that
 engineers
 like
 open
 source


and
 they
 like
 contributing
 to
 the


research
 ecosystem
 on
 AI.
 And
 then
 I
 get


the
 sense
 that
 trading
 firms
 probably
 do


not
 like
 open
 source
 and
 they're
 much


more
 into
 protecting
 their
 proprietary


models
 or
 data
 or
 whatever.
 How
 does
 a


company
 like
 HRT
 how
 do
 you
 actually


balance
 that
 tension?


>> Yeah,
 I
 mean
 this
 is
 also
 like
 a
 sort
 of


really
 honest
 answer
 and
 that
 many
 years


ago
 this
 was
 a
 relative
 comparative


disadvantage
 for
 us
 for
 recruiting.
 Some


we
 would
 often
 have
 conversations
 with


maybe
 especially
 PhDs
 who
 are
 graduating


and
 they
 would
 say
 like
 well
 I
 can
 go
 to


Google
 and
 I
 can
 still
 publish
 my


research
 and
 that
 kind
 of
 gives
 me


optionality.
 People
 will
 know
 who
 I
 am.


If
 I
 go
 into
 an
 HRT
 or
 HR
 like
 firm,
 I


essentially
 go
 behind
 this
 veil
 and
 I


never
 emerge
 and
 people
 just
 have
 to


kind
 of
 take
 it
 on
 faith
 I
 did
 smart


things
 for
 many
 years
 and
 I
 would
 have


basically
 no
 strong
 counter
 argument


apart
 from
 the
 fact
 that
 actually


writing
 papers
 is
 kind
 of
 overrated.


I've
 been
 there,
 done
 that.
 As
 when
 you


get
 older,
 you
 will
 not
 care.
 Now


though,
 there's
 this
 interesting


situation
 where
 this
 golden
 era
 maybe
 of


like
 being
 able
 to
 be
 work
 at
 a
 big
 tech


company,
 be
 paid
 for
 publishing
 research


is
 very
 much
 over.
 the
 papers
 that
 do


come
 out
 of
 the
 big
 AI
 labs
 are


essentially
 kind
 of
 either
 very
 stale
 or


not
 important
 and
 if
 you're
 working
 on


the
 most
 important
 cutting
 edge
 things


you
 can't
 share
 what
 you're
 doing
 and


it's
 very
 secretive
 so
 in
 some
 sense
 the


problem
 solved
 itself
 a
 little
 bit
 for


me
 and
 people
 now
 recognize
 that
 IP


should
 be
 protected
 I've
 even
 seen
 some


of
 the
 sort
 of
 AI
 lab
 people
 think
 out


loud
 about
 non-competes
 in
 public


thinking
 tweeting
 about
 non-competes
 and


things
 which
 is
 like
 an
 amazing
 turn
 of


events
 because
 I
 feel
 like


>> that
 was
 very
 anothetical
 Right.
 I
 mean,


they're
 like
 literally
 effectively


banned
 in
 the
 state
 of
 California.
 And
 I


think
 people
 were
 almost
 like
 proud
 of


this
 fact
 and
 would
 also
 kind
 of
 hold
 it


against
 the
 New
 York
 sort
 of
 trading


world
 being
 like,
 "Oh,
 look
 at
 these


people
 with
 their
 non-confers."


And
 a
 lot
 of
 that
 money
 is
 being
 paid


for
 talent,
 but
 it's
 also
 in
 some
 sense


paying
 for
 intellectual
 property.


>> Yeah.
 And
 like
 those
 people
 know
 how
 the


soup
 is
 made
 and
 they
 are
 not
 writing
 it


down
 and
 not
 committing
 any
 like


explicit
 sort
 of
 IP
 theft.
 But
 if
 you


hire
 five
 people
 who've
 been
 making
 the


soup,


>> they
 process
 knowledge.


>> They
 know
 they
 know
 a
 lot
 of
 process


knowledge.
 And
 you
 might
 suddenly
 feel
 a


little
 differently
 about
 protecting
 that


we
 spend
 a
 lot
 of
 time
 training
 our


employees.
 Takes
 a
 long
 time
 for
 them
 to


be
 productive.
 In
 some
 sense,
 it
 would


be
 a
 shame
 if
 people
 could
 just
 take


that
 knowledge
 and
 immediately
 leave.


And
 so,


yeah,


>> just
 going
 back
 to
 the
 steamroller,
 I


promised
 I
 promised
 we
 would
 when
 I
 hear


AI
 in
 trading
 or
 I
 know
 people
 are
 very


excited
 about
 agentbased
 AI
 nowadays.


Part
 of
 me
 thinks
 back
 to
 one
 of
 the


more
 amusing
 events
 in
 financial


history,
 which
 is
 Joe,
 I'm
 sure
 you


remember
 the
 time
 that
 one
 of
 Knight


Capitals
 ALOS
 went.


>> Many
 people
 would
 not
 find
 that
 to
 be
 an


amusing
 event
 at
 all.
 the
 worst


nightmare
 possible
 by
 using
 from


>> for
 them


>> the
 peanut
 gallery.
 Yes.
 Right.
 Shod
 and


Freud.
 So
 this
 Algo
 went
 rogue
 and


bought
 like
 7
 billion
 to
 the
 whole


company.


>> Yeah.
 Exactly.


>> What
 are
 the
 guardrails
 that
 you
 put
 in


place
 to
 avoid
 the
 destiny
 of
 night


capital.


>> So
 every
 training
 cycle
 we
 have
 a
 talk


about
 the
 nightmare
 with
 a
 K
 and
 we
 have


multiple
 ex
 the
 night
 employees
 at
 HRT


as
 you
 might
 expect
 just
 from
 a
 lineage


of
 a
 successful
 trading
 firm
 that
 ended


in
 a
 kind
 of
 an
 unhappy
 way
 and
 we
 have


many
 people
 who
 are
 at
 night.


>> The
 story
 is
 crazy.
 A
 successful


training
 firm
 that
 ended
 in
 about
 15


minutes.


>> Yeah.
 Yeah.


>> So,
 it's
 fair
 to
 say
 that
 that
 stuff


haunts
 us
 and
 we
 try
 and
 take
 as
 many


lessons
 away
 from
 that
 as
 possible.


Defense
 and
 layers.
 So,
 I
 think
 one
 of


the
 things
 that
 I
 like
 to
 emphasize
 with


the
 AI
 stuff
 in
 particular
 is
 that
 it
 is


not
 like
 there's
 some
 neural
 network


directly
 sending
 orders
 to
 NY.
 It
 is
 in


some
 sense
 providing
 a
 plan
 and
 then


traditional
 human
 heavily
 audited
 risk


checked
 layers
 take
 the
 actions
 and


that's
 just
 kind
 of
 how
 it
 has
 to
 be.


And
 so
 for
 us,
 we
 are
 kind
 of
 on
 a
 on
 an


operational
 day-to-day
 basis,
 it's
 just


many
 many
 layers
 of
 sanity
 checking


throughout
 the
 day.
 And
 then
 at
 a
 sort


of
 high
 level,
 it's
 very
 careful


process,
 including
 processes
 to


specifically
 avoid
 the
 the
 KCG
 type


scenario
 of
 how
 are
 you
 even
 releasing


new
 versions
 and
 what
 pre-release
 checks


do
 you
 run
 and
 audits
 and
 we
 even
 during


the
 day
 we
 have
 some
 I
 don't know
 I


guess
 you
 call
 them
 like
 sanity
 checks


of
 the
 neural
 networks
 to
 make
 sure
 that


they
 are
 producing
 the
 values
 that
 we


expected
 they
 would
 be
 producing
 and
 and


those
 sort
 of
 checking
 processes
 are


kind
 of
 a
 little
 bit
 behind
 because
 they


can't
 keep
 up
 with
 the
 like
 flow
 but


they
 were
 enough
 to
 kind
 of
 Just
 again


like
 every
 of
 a
 numeric
 stability
 of
 the


model
 sane
 and
 things
 it's
 not
 it's
 not


about
 losing
 money
 or
 making
 money
 in


these
 are
 not
 like
 oh
 like
 risk
 in
 the


kind
 of
 financial
 sense
 it's
 like


operational
 risk
 but
 paranoia
 is
 deep


and
 that's
 probably
 something
 that's


still
 very
 different
 I
 think
 from
 this


market
 from
 the
 sort
 of
 other
 AI
 world


which
 I
 guess
 anything
 goes
 and
 like


failure
 rates
 are
 kind
 of
 just
 priced


in.


>> Yeah.
 But
 yeah,
 you
 could
 you
 could


imagine
 just
 ruining
 everything.
 And
 I
 I


guess
 we
 worry
 about
 losing
 money,
 but
 I


think
 we
 worry
 more
 about
 taking
 action


that
 a
 regulator
 would
 not
 want
 us
 to
 do


because
 if
 you
 lose
 that
 trust
 of


regulators,
 you
 lose
 it
 for
 a
 very
 long


time
 and
 we
 trade
 in
 a
 lot
 of
 markets


and
 we
 pay
 very
 close
 attention
 and
 have


deep
 respect
 for
 the
 regulators
 and


their
 decisions
 in
 all
 those
 markets.


And
 this
 the
 rules
 are
 sometimes
 very


complex.
 And
 man,
 do
 we
 watch
 that
 stuff


like
 a
 hawk
 because
 you
 don't want
 to
 be


kicked
 out
 of
 a
 country


>> for
 making
 an
 operational
 error.
 And


this
 is
 a
 very
 low
 tolerance
 culture


from
 regulators
 in
 terms
 of
 making


mistakes.
 So
 we
 stress
 it
 a
 lot
 and
 I


think
 we
 should
 because
 it's
 it's
 you


know
 like
 the
 profit
 you
 make
 in
 10


years
 by
 still
 being
 in
 the
 game
 versus


move
 fast
 and
 break
 things.
 It's
 not


move
 fast
 and
 break
 things,
 but
 you


still
 want
 to
 move
 fast.


>> I
 have
 like
 a
 million
 more
 questions.
 I


ju
 but
 for
 the
 sake
 of
 time
 I'll
 just


ask
 one
 more
 and
 I
 don't
 know
 even
 know


whether
 it's
 something
 you're
 in


position
 great
 position
 to
 answer
 about


it's
 something
 I
 actually
 want
 to
 do
 an


entire
 episode
 about
 at
 some
 point
 but


as
 you
 would
 characterize
 it
 what


happens
 in
 the
 second
 after
 a
 jobs


report
 is
 released
 and
 the
 what
 I'm


talking
 about
 specifically
 is
 numbers


either
 flash
 on
 a
 screen
 or
 a
 piece
 of
 a


text
 appears
 on
 a
 website
 and
 markets


move
 around
 a
 lot
 all
 that
 and
 there's


people
 then
 suddenly
 unless
 actually
 the


jobs
 report
 was
 good
 and
 if
 you
 actually


look
 at
 the
 wage
 number
 and
 then
 the


stocks
 but
 in
 that
 instant
 in
 that
 first


microcond
 after
 the
 release
 markets
 are


already
 moving
 certainly
 before
 any


human
 has
 had
 a
 chance
 to
 read
 the
 thing


or
 form
 of
 use
 so
 what
 I
 assume
 is
 that


there's
 training
 on
 here
 is
 the
 text
 and


here
 are
 the
 things
 and
 whatever
 but
 to


as
 you
 would
 put
 it
 or
 from
 the


perspective
 of
 HRT
 what
 happens
 in
 the


millisecond
 after
 an
 event.


>> Yeah.
 So


>> could
 be
 an
 earnings
 report.


>> Yeah.
 I
 mean,
 so
 we
 have
 like
 a


Bloomberg
 headlines
 feed
 that
 is
 like


pretty
 low
 latency
 and
 if
 it's
 like
 a


important
 article
 has
 like
 a
 star
 in
 the


feed,
 things
 like
 this,
 right?
 You
 can


do
 everything
 from
 having
 kind
 of
 a


handcrafted
 logic
 to
 look
 for
 keywords


through
 to
 putting
 it
 through
 like
 an
 AI


model.
 One
 of
 the
 things
 that
 I
 like


still
 can't
 kind
 of
 wrap
 my
 head
 around


is
 I
 guess
 without
 saying
 specific


company
 names,
 there
 are
 options
 trading


firms
 that
 have
 thousands
 of
 people
 that


are
 essentially
 cyborg
 trading
 options.


They
 have
 maybe
 10
 people
 trading
 like


the
 options
 for
 a
 single
 big
 stock
 like


Nvidia
 say


>> and
 they
 are
 humans
 staring
 at
 the
 feeds


for
 these
 things
 and
 clicking
 buttons


and
 they
 have
 user
 interfaces
 that
 are


set
 up
 for
 them
 to
 hit
 the
 green
 button


or
 the
 red
 button
 essentially
 very
 fast


>> that
 job.


>> It's
 weird.
 We
 actually
 once
 a
 monkey
 on


a
 computer


>> for
 a
 hackathon.
 We
 we
 got
 a
 PlayStation


controller
 and
 kind
 of
 gave
 people
 a


chance
 to
 try
 and
 practice
 reacting
 to


events
 very
 fast.
 It's
 really
 tough
 but


it's
 a
 learnable
 skill.


I
 I
 think
 in
 an
 efficient
 market
 sense


this
 should
 be
 AIable.


>> Yeah,


>> it
 is
 challenging
 though
 because
 if
 you


imagine
 kind
 of
 plumbing
 it
 into
 chat


GBT,
 it
 would
 be
 too
 slow.
 Like
 the


latency
 would
 probably
 be
 sufficiently


high.
 I
 mean


>> it
 it's
 not
 that
 fast,
 right?
 It's
 fast


for
 any
 normal
 day-to-day
 thing,
 but
 for


markets
 it's
 kind
 of
 slow.


>> Also,
 and
 this
 is
 like
 a
 very


interesting
 research
 challenge
 is
 like


you
 can't
 literally
 use
 chat
 GBC
 to
 back


test
 anything.
 It
 knows
 every
 Jerome
 Pal


speech
 and
 knows
 what
 happened


afterwards
 because
 it's
 trained
 on
 the


whole
 internet.
 So
 how
 do
 you
 really
 get


confidence
 that
 for
 the
 next
 Federal


Reserve
 speech
 it's
 going
 to
 do
 the


right
 thing?
 Traditionally
 in
 finance


you
 back
 test
 things
 to
 see
 how
 it
 done


in
 the
 past.


>> But
 if
 in
 this
 case
 it's
 all
 kind
 of
 in


sample
 like
 it's
 seen
 it
 all
 before


>> and
 I've
 seen
 academic
 finance
 papers


where
 they
 try
 and
 like
 grapple
 with


this
 and
 they
 say
 it
 still
 works
 and


they
 try
 and
 account
 for
 this
 but
 I
 know


just
 this
 stuff
 is
 really
 that
 smart.


Yeah,
 that
 whole
 kind
 of
 thesis
 is
 that


it's
 memorized
 everything
 it's
 been


trained
 on.
 So
 why
 would
 it
 be
 reliable?


And
 so
 whenever
 you
 see
 someone's
 being


like,
 "Oh,
 I
 ran
 every
 Federal
 Reserve


speech
 through
 J
 GBT
 and
 it
 got
 it
 right


like
 nine
 out
 of
 10
 times."
 It's
 like


>> only
 nine
 out
 of
 10
 times.
 Like
 why
 not


100%.
 So
 I
 do
 find
 that
 I
 do
 think
 it
 is


interesting
 there
 how
 many
 humans
 are


still
 involved
 on
 relatively
 high-speed


trading.
 There
 are
 a
 lot
 of
 people
 still


doing
 this
 in
 in
 sort
 of
 niche
 products


and
 it's
 presumably
 because
 it's
 very


hard
 to
 integrate
 all
 the
 information


>> this
 AGI
 20
 I
 don't know
 2028
 2030
 I


don't
 know
 there's
 still
 a
 lot
 of
 humans


trading
 stocks
 and
 options
 and
 so
 like
 I


don't
 know
 how
 to
 reconcile
 that
 but
 I


think
 about
 that
 when
 I
 read


>> Ian
 Dunning
 that
 was
 uh
 fantastic
 there


really
 are
 like
 hours
 more
 of


conversations
 are
 we
 going
 to
 have
 you


back
 next
 week
 looking
 forward
 to
 next


week's
 episode
 but
 no
 that
 was
 uh
 great


for
 me
 really
 appreciate
 Yeah,
 a


pleasure.
 Thank
 you.


[music]


Tracy,
 I
 thought
 that
 was
 uh
 really


great.
 I
 like
 this
 idea,
 the
 sort
 of


anti-ynicism
 because
 you
 do
 hear
 a
 lot


of
 people
 say,
 "Oh,
 no,
 like
 AI
 could


solve
 things
 like
 chess
 or
 whatever,
 but


the
 stock
 market
 is
 fundamentally


different."
 And
 I've
 never
 been
 totally


satisfied
 with
 some
 of
 the
 theories
 for


why.
 And
 like
 I
 get
 stocks
 are
 not
 like


necessarily
 like
 a
 solvable
 problem
 in


quite
 the
 same
 way,
 but
 humans
 make


money
 on
 the
 market
 by
 matching


patterns.
 Why
 can't
 smart
 silicon
 brains


do
 the
 same
 thing?


>> Well,
 there's
 also
 history
 now.
 We
 have


many
 years
 of
 HFT
 trading
 and


algorithmically
 driven
 trading
 where


people
 have
 made
 a
 lot
 of
 money.
 So,
 it


seems
 to
 be
 working.
 The
 light
 bulb


moment
 for
 me
 was
 where
 Ian
 talked
 about


the
 time
 frame
 and
 the
 importance
 of
 the


time
 frame.
 And
 I
 think
 that's
 really


the
 key
 in
 many
 ways.
 It's
 adapting
 what


you're
 doing
 with
 AI
 to
 the
 data
 that's


available.
 And
 the
 data
 on
 markets,
 most


of
 it
 is
 going
 to
 be
 very
 short
 term
 and


more
 seconds
 than
 minutes,
 more
 minutes


than
 days,
 etc.,
 etc.


And
 a
 lot
 of
 the
 data
 is
 also
 biased
 to


immediacy
 versus
 past
 analysis
 which
 he


spoke
 about
 as
 well.


>> It
 is
 always
 funny
 in
 finance
 people


like
 oh
 17
 out
 of
 19
 times
 there's
 been


this
 death
 cross
 of
 the
 S&P
 500
 stocks


went
 down.
 It's
 like
 any
 serious
 data


scientist
 would
 spit
 at
 that
 sample.


[laughter]
 It's
 like
 beyond
 a
 joke
 level


to
 talk
 about
 a
 sample
 size
 of
 19
 as


being
 all
 the
 time.
 death
 cross
 in
 a


headline
 is
 so
 tempting.


>> That's
 true.
 You
 all
 you
 cannot
 advice


to
 journalists
 never
 pass
 up
 a
 chance
 to


put
 a
 death
 cross.
 I
 was
 glad
 to
 hear
 I


thought
 a
 few
 things
 were
 interesting.


One
 is
 I
 was
 glad
 to
 hear
 that
 the


wirelength
 problem
 is
 no
 longer
 a
 thing.


It's
 not
 just
 this
 race
 to
 get
 closer
 to


the
 extreme.


>> That
 was
 kind
 of
 boring
 when
 people
 were


talking
 about
 the
 cold
 war
 and
 HFT
 and


all
 of
 that.


>> It's
 interesting
 that
 the
 GPU
 market
 is


eased
 versus
 where
 it
 may
 have
 been
 a


couple
 years
 ago.
 And
 it's
 interesting


that
 even
 at
 a
 scale
 like
 a
 trading
 shop


that
 electricity
 is
 proving
 to
 be
 a
 main


constraint
 which
 does
 raise
 questions


about
 are
 we
 just
 going
 to
 hit
 up


against
 a
 wall
 given
 some
 of
 the
 AI


plans
 that
 so
 many
 people
 are
 banking
 on


for
 the
 chat
 bots.


>> Yeah,
 I
 thought
 also
 I
 guess
 the


cultural
 shift
 in
 some
 of
 the
 labs
 was


really
 interesting.
 this
 idea
 that


they've
 become
 more
 proprietary
 and


perhaps
 more
 uh


>> mysterious
 in
 some
 ways
 rather
 than
 the


trading
 firms
 becoming
 more
 open.


>> Yeah,
 lots
 of
 great
 conversation.
 Answer


some
 questions.
 Plenty
 more
 plenty
 more


to
 go.


>> That
 was
 helpful.
 And
 uh
 I'm
 sure
 we'll


talk
 to
 him
 again.
 Maybe
 not
 next
 week,


but
 soonish.


>> Maybe
 next
 year.


>> All
 right.
 Shall
 we
 leave
 it
 there?


>> Let's
 leave
 it
 there.


>> This
 has
 been
 another
 episode
 of
 the
 Odd


Thoughts
 podcast.
 I'm
 Tracy
 Aloway.
 You


can
 follow
 me
 at
 Tracy.
 [music]


>> And
 I'm
 Joe
 Weisenthal.
 can
 follow
 me
 at


the
 stalwart.
 Follow
 our
 guest
 Ian


Dunning.
 He's
 Ian
 Dunning.
 Follow
 our


producers
 Carmen
 Rodriguez
 at
 Carmen


Arman.
 Dash
 o
 Bennett
 at
 Dashbot
 and


Kell
 Brooks
 at
 Kellbrooks.
 [music]


For
 more
 OddLots
 content,
 go
 to


bloomberg.com/odlots


for
 the
 daily
 newsletter
 and
 all
 of
 our


[music]
 episodes.
 And
 you
 can
 chat
 about


all
 of
 these
 topics
 24/7
 in
 our
 Discord,


discord.gg/odlots.


[music]
 And
 if
 you
 enjoy
 OddLotss,
 if


you
 like
 it
 when
 we
 dive
 into
 how


companies
 are
 actually
 using
 AI,
 then


please
 leave
 us
 a
 positive
 review
 on


your
 favorite
 podcast
 platform.
 And


remember,
 if
 you
 are
 a
 [music]
 Bloomberg


subscriber,
 you
 can
 listen
 to
 all
 of
 our


episodes
 absolutely
 adree.
 All
 you
 need


to
 do
 is
 find
 the
 Bloomberg
 channel
 on


Apple
 [music]
 Podcast
 and
 follow
 the


instructions
 there.
 Thanks
 for


listening.


Yeah.


Heat.


[music]