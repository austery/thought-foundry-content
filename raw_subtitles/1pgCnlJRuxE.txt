and the state of the art, Sota model, and the direction of future development. What I'm most interested in today is to take this opportunity to discuss with our guests, who are also very advanced AI scientists, what other branches besides LLM and the most advanced research are you concerned about? So let's start with Gemini. And then we'll talk about Beyond Gemini, the direction you are researching. Okay, first of all, we still need to talk about the new Gemini story that has just been released. Anyway, I see that all the communities, the media, and everyone is praising it. Can you first tell us about your feelings about using it? It's really like the ranking on these different rankings. Can you tell us how you feel about it? Let's start with Nathan, then Dr. Tian, Yu Bei and Gavin. I can share my experience of using Gemini 3 and its apps. I mainly used three apps, one of which is Gemini 3 Pro. 第二个其实是它针对开发者放出来模型叫做Google Anti Gravity大家可以把理解成就有点像是一个Google放出来Agentic的IDE然后是方便开发者还有编程演员去编程就有点像Cursor或Code的这样的一个竞品 第三个我用的可能就是Nano Banana Pro也是我今天才发布的然后大概会从这三个点给大家来介绍一下我个人因为从开发角度更多是关注于就是说这个模型的编程能力其实我去看了一下它的benchmark跑分了Switch Bank它其实不是最高的Switch Bank是最高的其实还是Cloud The Sony 4.5 is actually a little bit lower, but it is already very close to such an ability. Then I found a very new feature in the process of using the entire Gemini app. That is, you can directly let it be compiled in the app of its group. 然后它可以去生成很多前端的这种小程序然后包括像网上有很多人去用比如说它甚至可以去调用你的计算机的摄像头然后让它看你的表情然后听你的声音然后给到你一些的反馈所以说科学各样的这种小程序在网上包括X上都发布出来我觉得这一点上来讲的话它可以让很多人去尝试怎么去开发一个APP然后并且很快的就能使用上去 但是我觉得它 limitation 可能更多它是注重于前端比如说像后端的一些部署包括在电用其他一些agentic的这种 framework它可能没有办法是在它的主app中完成我觉得它第二步走的那个事情就是说它发布了 anti-gravity 也就是一个完全针对开发者或者编程人员的这样的一个Agentic IDE我觉得它的一个好处跟像Cursor或者Cloud不太一样的地方就是说它完全是希望AI coding agent能够非常自主的帮你去完成任务所以它在做界面设计的时候其实是分了两个大块一个叫做Manager view 还有一个是叫做Editor view Editor View就是希望大家可以理解成就传统的编程的这种Editor你可以看这个程序它不断的修改的变化包括美国在做什么事情但是它只是针对一个agent去给你看这个agent在干什么Manager View它其实想做这个事情就是说Instagram让你只跟一个agent的工作你可以跟一系列agent 可能比如说8个9个10个你可以不断的给这些agent的布置任务然后就像你是一个manager一样坐在那里然后看底下这些小弟在写程序然后这样的话你可能在做一些系统工作的时候就可以有更多的这样的玩法比如说你可以create一些agent帮你去review你的程序甚至有run一些unit test然后包括我觉得它最新的功能可能是其他这些ID没有的就是它用到了它Gamut 3.0 Pro里面的一个这个browser use的一个功能 我不知道大家没有用过Manus AIManus其实它很多就是based on browser use可以让大模型去使用你的浏览器然后帮你做一些操作但是Gemini这个模型它的browser user跑分应该现在是最高的它有个叫Screenshot Pro好像那个跑分应该是所有模型中现在是跑得 significant的高然后我觉得它利用这个功能就是说可以让你调用它的Chrome浏览器因为Google也用了Chrome它可以拿到底层的一些API然后让浏览器帮你去测试你前端的程序这样来讲的话等于说你的测试加上开发就完全自动化了然后变成一体式的这样一种开发我觉得这是它一个非常好的亮点 但是我在实际使用过程中其实还是会发现它在做这个browser use的时候有一些复杂操作它是没有办法完成比如说你让它去上传一个文件去做测试的时候它很多时候就停在那了需要人的这种manual的干预最后一个nano banana我发现它最好的一个功能就是说它可以去生成一些 复杂的这种图片甚至是换灯片就比如说大家如果想要去解释说Gemina 3.0 Pro它从1.0到1.5到2.02.5到3.0发展的路线是怎么样的然后每一个模型它的特点是什么像以前如果你让Nano Banana去做的话它是没有办法完成整个逻辑念包括把它 调理你的非常清楚但是现在如果用NanoBeta Pro去做这个slides的话它已经是能够非常好的完成所以说我觉得市面上可能那些做slides相关的这些软件可能都要被NanoBeta Pro给取代了这就是我大概使用到现在三点主要的一个观察好的那田博士 I've been using Gemini 3 for the past few days. I haven't used it yet because it needs a paid project to get in. I can't do that right now. I mainly use it to write novels. This is my second job. I usually take the Star Wars Star Wars to my office. The first thing is to see if it can do better novels. This is my personal benchmark. One is that it's not overfitting, because apart from a few people in the world, no one would take it as an official benchmark to test, right? So it's more objective. And then, if I have domain knowledge, I can see a lot of subtle changes. So in this case, I can roughly see how strong the model itself is. So this is also a more important and interesting event, right? After I tested it, I think... I feel like Jamf Sine's model is better than before. This is a big breakthrough. Before, you would put a short clip of a small game to the model. At the beginning, I think that one or two years ago, The novel can only be translated into official language. It's completely different from the previous novel, the context, the writing style. This is the state of the novel, 1-2 years ago. Whether it's GPT-4 or Lama, it's like this. When you start from last years, you will find that the quality of the written works are getting better. The style of the original and the text style of the original works are matching with the previous one. And the characters also start to have a certain continuity. This is a good improvement. But it's still not like writing. Because sometimes you will find that when you write it to the end, it will say what you are thinking about, what you are going to do. There is a kind of... It's a very simple way to write a novel. You write down everyone's thoughts and thoughts. It's not like you write it down as a complicated novel. You let people guess what they're thinking. So after writing this kind of novel, it's very good. It's like you're back in the state of writing a novel. And then you can find that, especially with the crowd, you can see that when he started writing, he started to pay attention to not only the protagonist, So, at this time, his ability is better than the previous single-player hero or single-player environment. So you will find that his model ability has improved a little bit. And then, this time, I was actually a little surprised when I saw Jamf 3. 他不仅写了人物的一些描写隐瞒了一些氛围而且还能知道这些人在小说里面以用什么样的情节可以抓住人物抓住读者的心我觉得这很有意思就是说这个写法已经跟以前的小说续写不一样我以前在用《雅米奈2.5》的时候我会觉得《雅米奈2.5》它比较好的地方它文明比较好就是它会做比较详细的描写 He said that this is a waste area, and it will be very detailed. Where the wall has fallen, where the building is not working, and the whole environment is very simple. So this environment description should say that JMJ 2.5 has done a good job. This is compared to ChaiGBT. It's like a literature student, written by Peng Peng. But in terms of plot, it's more simple. There's nothing to catch people. After I used the Gemini 3, I thought that some of the plot's ideas, even some of the twists, were very interesting. It really satisfies the previous character. and he can interact with people in a creative way. I think this interaction is very interesting. Maybe I should save it, maybe I can use it as a part of my novel. I have this idea. So this is a big difference, a surprise. I should say so. So I used to use novels, I can save some of the descriptions of the environment to be used better. But this is the first time I've seen the interesting interaction between the plot and the characters. This is the first time this has happened. 所以这是一个比较有意思的地方那么从技术上来说我觉得像这样的一个方向应该说不会是有特定的后训练的任务去做的一般就是因为这个模型计模比较好所以他对小说的理解更加深入了他对作者写这样小说的动机和深层次的这样的一个思路展开他可能理解的更深了 then it can consciously incorporate this understanding into the sequence. I think this is a very interesting structure. In addition, the large model also helps me to brainstorm. I discuss some interesting topics and ideas with it. I don't think there's much progress in this area. I've been using GBT5 for a while now, and I think it's not bad. It does give you an idea. But in most cases, when I talk to it, it feels like it's a... 刚刚入学的博士生知识非常广播什么东西都知道有很多时候他会挑出一个你知道一个新的想法新的一个框架或者新的一个数学工具你可以用然后说这个我们没见过这很好这个是很不错的但是如果对一个问题如果有深入了解的话他没有办法去做一些比较深层次的思考这个思考之间只有人才能做而且人给他一些比较好的建议 and tell him that he can't do this, he should do something else. This way, the model can continue the way you want it to be. Now, I think Gemina hasn't made any breakthroughs. She's still the same as before. She's a great questioner. I believe that so many scores are actually because a lot of people have put a lot of questions into it and trained it. But it didn't exceed the level of the writer. Creative thinking, especially on the scientific side, is not very good. So it still needs people. So these are my two main feelings. These two parts are the direction of my heavy use. I don't use a lot of coding and other programs. I just wrote some random things. For example, I created a three-dimensional game. and it can be written. Of course, I found out that the direction key was wrong. You press the forward key and it goes back. Of course, this kind of bug should not be a big deal, but it does lower the threshold of front-end development. I don't understand anything. I don't know what 3D3.js is, 3C.js is, but it can write something that can run. I think this is a great convenience for the programming of DALANG. That's all I have to say. Okay, I feel that its reasoning ability is still greatly enhanced, but it may be a little bit more. (speaking in foreign language) Next, I want to ask Gavin. After Gemini 3 came out, I talked to Gavin for a while. He told me that he was very surprised by the concept of a full model. Can you tell us what the definition of a full model is? And how do you think Gemini is designing a full model? 首先我改看一下Google大肠之力恐怖如斯它有一个很完整的一个Ecosystem就是N2N的关于AI的一个Tech Stack然后我们先看Technical-Wise Foundation Model的一些Benchmark我其实最惊艳的一个是Arch-HRI2因为那个Benchmark我之前稍微研究过一点它是一个Future Learning 少样本学习 or called Meta-Learning. It actually tests that we are now doing a large amount of model training and we need to put in a lot of data. But the founder of Arc AGI thinks that this is not the real intelligence. 就是你是一個做題家就是說真正的人的智能是說你就算是看過一兩倍example你也能夠快速地獲取某種pattern那才是真正的intelligence所以說就有了RKGI這樣一個benchmark然後它的話就是GN3可以說在RKGI上這個benchmark上有了一個智的突破之前我看它們搜到好像是百分之十幾或者說是個位數 它搜到百分之三十幾這樣的話就是說它其實 through some simple examples and patterns, we can fetch human reasoning capability. I think this place should rely on its multi-model reasoning capability. Because before, our reasoning model, the four-way chain, we saw the chain of thoughts. 就是模型在那里自言自语 对吧它是一个single modality它是通过语言的层面在自我地去思考去推进的所以我觉得这个地方Multimodal reasoning可能是对它有很大的帮助不过这个地方的话还是要请教田老师和陈老师而another thing就是它的Math Arena Apex 它是对于数学,基于符号学的一个表征做 reasoning也有一个值得突破我知道有些公司像Xeon和Symbolica他们也在做这方面的探索然后看到Google在这方面突破我觉得是very impressive Another one is the ScreenSport Pro mentioned by Nathan. I've seen some OS agents or browser agents who understand the screen through a vision model. They also need to annotate the image on the screen and throw it into a JSON blob. It still has a structural representation. Language Model去做一個Reasoning因為真正的Reasoning Capability在Language Model裡面現在的話相當於就是它能夠在模型本身 仿佩適模特本身就一邊看著那個屏幕一邊就在語言裡面進行Reasoning我覺得這個地方就是Impressive就是我知道它們那個就是Multi-Model的這個pre-training已經從之前的那個Glu Era就是說就是我一個Language ModelArchitecture和一個Image或者Video的Architecture拿過來 就是中間加一些AdapterInvading的這個alignment現在的話就是說他們是可以把這些多模態的數據全部放到一起Mesh up together給那個模型去做預訓練所以說這些大模型尤其是GEMNAT3它效果已經很好了就是它是Model Native的一個Multi-Model就是和去年我們說的都完全不一樣所以這個地方我覺得它就Open up a lot of doorsA lot of new opportunities 去年的話還有就是我有一位很尊敬的前輩他跟我說這個Model這個東西吧就是文科生藝術生他給你generate那個圖片出來吧一個人有六根手指因為它是分成一張一張的就是他其實不知道就是人這樣一生五世應該是只有五個手指 所以它并没有一个像我们人一样去基于Cosolite或者说是Common Sense of Physics理解它的能力但是现在从GEMLAT3就是它可以self-evaluate的一个角度来说因为这个地方我昨天跟GEMLAT3做了一些讨论我说你为什么那么厉害能不能告诉我他跟我剖析了一下就是讲到它们里面其实采用了一个Tree of Thoughts 就是因为我们之前都是Channel thoughts就是从软件工程的角度来说它是一个线性的一个推理的一个链表但是GMF3的话它其实它是一个思维数就是它其实是有多条思路并行的并且在model内部它的architecture就是一个self rewarding就是它里面是打分threshold然后哪些思路我要drop哪些思路我要adapt这样一个状态而且它还基于就是说Foundation model它上面还wrapped一层Engineering wrapper就是说像我们传统的说search 对吧 就原来你就是有linked list现在我是一个search in a tree然后我可以从这里面寻找就是我觉得真正那个就是好的思路我能够给你一个validation那这个东西就跟之前的另外一个philosophy就趋势是吻合了所以一开始的时候我们是prompt engineering后来我们要做context engineering现在我们要做environment engineering这个东西它那个Google gemini已经adapted了就是说我有一个engineering environment我去给你很多的feedback 讓你validate你現在在推演的這個東西是不是make sense這條思路還有沒有必要搞下去首先它是一個performance想優化其次它的appearance也有了顯著的提升對我來說最驚喜的部分就是說我們既然可以Engineering和ModelScience結合起來然後我們可以繼續去突破這個Scaling Law的一個壁壘因為之前就是我們完全的去vertically的 这个scale就是 Foundation Model 本身可能就是它已经遇到了一个平均一个 bottleneck但是现在他们相当于就是adapted to the mixture of expertMOE 的那个architecture以后它又能够model本身能够horizontally scale同时engineering又可以让它就是不断的能够self validate所以说我觉得就是technical wise这个可能不亚于三年前的那个GPD时刻对于我来说 另外一个是Google他们确实真的是全家桶Gamut X3全家桶Nano Vana Pro也出来了然后Coding的ID也出来了直接对标Codex加Cursor对吧就是它首先前端它一边看着网页一边跟你编程这个体验我认为是完全next level的跟之前我们说的像VoguaFigma这些就还是说它是个Chatbot 但现在的话它真的就是说至少就是在视觉效果上它的attention being aligned on the same page这个就是因为我之前也做过一些类似方面的探索和尝试然后Google这个一做的话我觉得这个方向没什么好做的就等着Google给我们包围了就完事了 So I think Google has a very complete ecosystem of products that allows it to have enough problem space to iterate its foundation model and verify it to improve. I'm very impressed and glad that's happening. Wow, Gavin's evaluation is very high. I saw a lot of people in the social media these two days who came to the conclusion that the coding dispute So, what do you think about this? the completeness and beauty of the program itself. I think that's what they saw. But the real code-makers are more concerned about whether the model can do better in the following. I said I just want this code to change into what I want it to be. or I want to do something very detailed and hope this model can follow. Whether this thing works or not depends on the deeper evaluation of everyone later. So it's not necessarily... This thing may come down a little earlier next month. 我是看到网上是有人说Intro and Following不够强Gemini 3这个不是很清楚但是可以再过一阵子看看大家的想法是什么Gemini 3的话它的Benchmark也是打得不错但是Coding的话It's a much more complicated engineering problem就是说现在的这些档口已经都是写写前端可以因为那个东西非常简单 但是说后段的话还有一些我觉得现在还缺了很多modality这也是为什么我对于动物它这么感兴趣我觉得你后面的production log还有很多一些就是你code真的跑起来以后你code index这些东西都是signal它可能就是说不一定是按照现在这样就你静态的去读code的形式给model做一个理解对 有很多的具体的use case比如说你真的拿它来做codex或者拿它来做一些具体的reported一些task的时候 Many tasks are very complicated. There are many corner cases. I don't know if they can solve this problem. Yes, this may also talk about the robustness of this model. Yu Bei is very good at this. Yu Bei, please tell us about your observation of Gemini 3. I'm not sure if I'm good at using Robots. I have some experience in the team. I'm going to be honest with you today. I've been busy lately with the release of Gps3. So I haven't had time to use Gps3. So I'm going to find different partners today. And then each group of AISB. And then go see everyone's user experience. So basically, everything I've said today is second-hand. But I think there may be some useful early feedback that may be valuable. First of all, I think it's a good thing. I found that after the release of the GNI3, everyone's response to general questions and general agendas I think it's a good answer. Because when we were using it in 2.5, we always felt that it had a strong hallucination. And we often felt that it didn't answer the question. But after the release of Gemini 3, I heard that several groups said that they felt that the Gemini 3 and the pre-training and post-training were all done well. So the answer this time is not only simple, but also quite accurate. I think this is a good point. And then, another early feedback came from the Vision team. The Vision team did a test in the early stages, using some internal benchmarks. 然后反馈反而是Negative然后就是说在GminI 3的时候在Real-world的visual understanding反而下降了但是这个是一个非常early stage的因为benchmark的级别比较小所以它的variance可能会比较大所以不敢说一定是一个conclusive但是毕竟是一个很早期的然后所以他们去看了这个测评原来的GminI 3的测评报告 In the GNI 3 test report, there was only one benchmark that was really about visual understanding. And it wasn't really about visual understanding or video understanding. So, there was no improvement in the results. Some important tasks were not included. This is a feedback from Vision. I'm sorry, I'll interrupt you a little. What is the ability of the real world vision understanding you mentioned? Can you explain to our audience a little bit? When you use cameras in real-world situations, such as security cameras, you have to analyze the user's behavior, whether there are any incidents, potential risks, or a series of things. We have to analyze the cameras and the gateways that we deploy in the real world, and analyze them in various situations. 反正就是说在小范围的这个benchmark上发现它性能下降了然后但在这里面反而它的 reasoning 的长度上升了由原来的基本上上升了2到3倍3.5倍 两倍到三倍就 reasoning 长度上升了两到三倍但是实际的在小范围的benchmark 上下降了但是 again 这个是一个小规模的一个benchmarking And then the small-scale benchmarking, its variance may be relatively large. So you can't say that this is an objective evaluation. So I think we need more testing, from different angles. So this also raises a question. This is something we've been discussing a lot lately. benchmarking on the workbench may not reflect the performance of the actual product. Because the real product teams have their own measurement within them. These measurements are actually very important indicators. Because how you optimize models often depends on how you measure it. 那么如果我的measurement就比你更贴近于实际或者更好的话那么无论你如何优化在工榜上的task的话有可能会走偏 因为它的gradient错了然后所以这个可能也是OpenAI像其他的一些team他们也有的一些优势我觉得可能大家的套路内部的套路和外部的套路未必是一样的对吧 这个需要更多的context来建立一个更好的一个measurement And then, the language group's response is that although the GminI 3 has some major improvements, but it involves repetitive multi-hop, external search, and aggregation. 这种就是要搜索然后比如说我要分析这家公司从2005年到今天20年的这个财报它里边的一些问题然后我要做这样的一个比较复杂的搜索任务的时候呢JM3它的performance似乎还达不到就是这个Chad的GBT Pro的这个能力 But the advantage of the Jimmy Night 3 is that it's very fast. And for some simpler tasks, you might not want to wait for a few minutes and let it do some long reasoning. So, on some more common issues, people might prefer to use the Jimmy Night 3. But when it comes to complex issues, they might still consider using the 5 Pro from GPT. The next task is more subjective. In the scientific writing, because we are writing a scientific article, students' reactions are that the performance of the scientific writing has also dropped. 就是说不如JMNi2.5的效果好然后当然这个都有可能是没有用对啊然后还有就是做这种不是web coding但是就是说有辅助coding的时候接入JMNi3的时候似乎性能也下降了 If you ask them whether they use Gemini 2.5 or Gemini 3, they will say that they are using Gemini 2.5 for coding. But this is probably a new product. After the release, you can't make it reasonable and use it correctly. 所以这些结论都是比较early的所以只是一个早期的分享但overall大家还是觉得这一次的Google对于Scaling Law的执行较为彻底就是说似乎在这个当然也有它得天独厚的优势了然后反正就是说这是大家给我的一些信息然后我就把这个二手的信息传递给大家 Very good. I think it's very valuable and meaningful to give different angles of feedback and testing. But as Yu Bei said, it may be just released a few days ago, and everyone is still in the stage of testing. How much robustness can it bring to the application and to the development? We can wait for a couple of days and then look at the feedback from the developer community. So, for Gemini, I have another question. In general, Google is now almost over the top in terms of a tracker. For example, OpenNL has some of the most popular models. I want to ask how people understand Google's advantages in the model. Is it its ecosystem, its algorithm, or its dormant? I saw the project manager of Gemini himself. Gemini 3's secret is to improve pre-training and post-training. What does this mean? Can you understand that scaling law is not as strong as what we said before? In fact, there is still room for algorithm optimization and improvement. I want to hear what you think of this conclusion. Who wants to go first? Let's start with Dr. Tian. Yes, of course. The sentence "pre-training and post-training have improved" is nonsense. Both sides will improve. For example, the data will be better, new structures will be built, and the training will be more stable. And the post-training will be more difficult. whether it's done well or not, or whether it can be more skill-up. These are all some of the more detailed things. If you do every part well, it will definitely be better than the previous model. I think this is no problem. This is a project-oriented challenge. If you do every part very well, better than the original, then the model will become stronger. But I'm curious about the secret of his training. How to make pre-training stronger. I think this is very important. If pre-training is very strong, the problem of post-training is not a problem. It will be easier to solve. This is basically it. Pre-training is like turning a model into a smart one. It's easy to learn the tasks of post-training. You don't need to pay a lot of money to teach it. If you can't do pre-training, the problem with post-training is that you have to spend a lot of money to teach it. And it won't work if you teach it. It's like teaching a stupid student. But if you teach smart students, they will understand it. So, I think the feedback is pretty good. So, there are many things that he can understand easily. It should be like this. But it's probably like this. So in the training, one is the structure, and the other is the data. If both sides do better, the model will become stronger. And of course, there are rumors that Google has fixed some bugs in the previous training. Yes, of course, this is a rumor. I can't prove its authenticity. Did NOM do it? NOM went back and fixed Gemini's bug, and Gemini was good. I don't know. These are all rumors. [BLANK_AUDIO] Kevin? (speaking in Chinese) 應該是傑森·韋就是O3的一個Channel Floss的作者他之前提到過所有有確定方法論的領域eventually都會被模型所吞噬我覺得GEN3也看到了這樣一個趨勢就是說大家先是用engineering的wrapper去build一些agent就是在那個orchestration layer裡面加一些prompt這個也 echo到剛高瑜被講的那個問題就是每次新的那個模型就launch出來的時候大家的agent performance都會下降因為你那個orchestration裡面放的那些prompt是給上一代模型用的 然後它不一定對這代模型work very well因為它是一些不一樣的embedding in the default就是Heroic Stixxers的space所以說我覺得既然它的這些公共的公保上打得特別好後面一般注意會有一個水上船高的過程但是我們更關心的現在其實不是基模的能力了而是就是說 to see if the improvement of its loneliness ability actually adds value to our product. And then let each user experience or improve their KPI for specific problem-specific problems. This is actually a part of the product strategy. So I think this is the bottleneck. For agents, they are still... to automate the things that people have been doing. The cake has not grown. So the job positions are probably getting smaller. I think we need to create new business model, new product shapes, new job positions in a different way. For example, when it comes to coding, web coding is more like the new product that they have introduced. This engineer is a commercialization, which is the product definition, PM, and then the engineering, the front end and the back end. A network is completely open, one person for three people. I think some of these strategies are very useful. 我希望看到更多的這樣的strategy的出現就是讓大家能夠跟就是說這個水漲船高的這個基模的能力不斷的提升就是我們應該要造一艘小船在那個基模能力這個就是逐漸升高的水面上我們也能夠站得更高 創造更多的價值然後我覺得就是說 對既然Google的反對勢已經做得這麼強了希望它的那個生態裡面能夠有更多的這樣子的KillerApp product出來嗯 好的 那這你有什麼補充嗎? 对 我可能补充一点就说我其实觉得Google整个这个Gemini模型的生态念从1.0 1.5 2.0 2.5到现在3.0我觉得他一直做的比较好一个事情就是他一直在坚持做多模态这个事情其实我仔细去查了一下其实他在1.0的那个technical报告就已经写了他们已经开始使用这种native的 Multi-modality的训练也就是说把文字 图像 视频 包括声音都放到embedding system里去进行一系列的这种pre-training只不过当时可能效果不是特别好然后到1.5的时候它已经开始在用MOE了然后到2.0的时候加上了很多这种脱靠的这种improvement因为那时候agent非常的火 然后到2.5的时候也就是deep sick发布deep sick是比他早发大概三个月然后他是在2.5的时候去上了这个thinking mode就是raising mode我觉得应该也是借鉴了deep sick当时的那篇报告然后很快的去迭代出来了然后到3.0的时候其实我也跟 Gemini去討論一下為什麼你這麼好用然後得到結果其實跟Gammon剛才說的很像他剛講的decision tree的概念然後當時Gemini給我的答案他也是說叫做他意思說我們用了叫deep thinking的這樣的一個mode大概就是說我們去試很多多輪的這樣的步驟去嘗試得到這樣的結果可能最後我比如說我把一個問題run了十幾次然後得到十個不同的方向然後最後我會去reflect 然后去思考说哪一个可能更好然后再得到这些结果的时候然后我再去生成最终这样的结果我记得央乐困其实在一年前的一个讲座的时候就提过类似的概念他也讲到在embedding system的时候如果是想train一个很好的war model的话你其实也是需要让这个模型可以有各个思路的去思考然后找到一个最好的这样的一个思路而不是说在最终结果的时候去完成这个事而是在整个embedding system去完成这个事情 所以我觉得就是说是不是他们也接近了亚当坤当时的那个想法这个可能不表然后最后一个我其实想讲的就是说我去看了开发者的API这些开发者API的Dock藏了一个彩蛋他当时的彩蛋你可以去搜现在他Gemini3如果你想用他的API去调达模型去做他这个彩蛋他现在的彩蛋里面写的就是说context engineering is a way to go When it was in an example, it was specially written, and then everyone was found out and thought that context engineering has now become one of Google's most important ones. I suddenly thought about what I would do when I was using this big language model. For example, I want him to help me write a very good Twitter post. 我一开始会跟这个模型讲说你帮我到网上搜索怎么样写一个viral的推特post然后帮我把这些资料收集下来然后整理好然后根据这些learning你再根据我想要写的内容帮我把它adapt这些东西所以我发现这个context engineering我在想说谷歌是不是也在train的过程中 通过一些数据或者或者通过一些思维链可以让他自动产生这样的一个行为不过谷歌自己其实他的这个做色尺其实是非常强的是不是他在这个模型使用的过程他已经可以自动的去抓取这些信息然后再把这些信息放到他整个这个思维链和这个context里面去然后最后再生成这样的结果 因为相当于说每一次我去生成一个response的时候我都可以去抓各式各样的这种contacts然后再完成这个我觉得这样的话其实我个人就是手动这样去做使用的效果其实就已经非常好包括可以让他写出来比较好的比较viral一些extr这个post 所以我觉得这一点上是不是谷歌也在这方面包括从他EPI的这个彩蛋里面他也提到这个contact centering我觉得可能也是下一轮模型训练是不是一个新的方向当然这个我是一个外行来去讨论这种我觉得各位可以再补充一下 I want to say that you shouldn't ask how the model is made, because it will hallucinate. So you should read the specific article, the model card, and see how the model is made. If he tells you that he made it with a trio of sauce, he doesn't really have a trio of sauce, he just hallucinates a trio of sauce. So this is not the real news. I know a lot of people who are watching my videos. So they already have a thinking mode in the 2.0 era. It's not like they copied the Deep Sea and then made it. It's not like that. They have their own original ability. At that time, Danny Zhou had some ideas. And then the whole team made the thinking mode. I think there are many original things that came from Google. Yes, Google's talent storage is really very strong. Yubei, do you have anything to add? This is what I got from the other members of the team. Especially Brian Cheng, a good friend of mine, I think his point of view is very interesting. 我也比较认同然后就是说很显然就是Google这几次GminI的迭代其实也体现了Google可以其实正确的之前的一些问题对吧就是显然在这个不见得在AI上已经赶上了尤其是这次GminI3发布以后我们确实觉得它确实比较极致的在执行这个skilling law If we can get it in time, we might be able to reach OpenAI's performance. Even if it's not today. Of course, there is a Gmini 3 Ultra, I don't know if it's still there. But I have no information about it, so I won't comment on it. but it feels like it can be done in a matter of days. So, this is a bottom-up logic. I think Brian has a point that is interesting. Why is Google more ready to implement the scaling law? It's because of its hardware advantages. Because only its TPU is a complete software hardware integration. and the combination of software hardware. If we look at the hardware of NVIDIA, it has a margin of 70%. This means that AI companies that don't have hardware capabilities don't have such an economics that can firmly execute scaling law. Google has the advantage of such hardware. It can firmly execute larger models and more training. and other post-training data curation, more expensive multi-model, are all following. Because of the infrastructure, it can more firmly execute the skinny law. So it will be a big challenge for other teams. Of course, OpenAI is also having its own hardware. Anthropics should also have its own hardware. So the hardware limitations are higher than the margin of the mainstream hardware. This leads to the fact that they will be hindered in the process of implementing the scaling law. This is mainly an economic problem. This may also be a warning to everyone, that is, everyone should pay attention to the hardware, and then this will allow the implementation of this kind of scaling law to be continued. Of course, if the margin of NVIDIA is reduced to no margin, then perhaps everyone will not have this obstacle. Of course, this is just an angle of scaling law. So overall, we still have a feeling that in multi-model, especially when it comes to vision, The scale of a multimodal is not as simple as a language. The scale we want to achieve from a language is slower than that of a vision. This is also a challenge for a multimodal, especially for vision. I was inspired by Brian's ideas. So I made a small ad for him. Brian is going to be a professor at UCSF Biophysics this year. If there are other friends who want to apply for PhDs, you are also welcome to apply for Brian's PhD. 我认为布莱恩是一个非常weird的人然后他很好original我觉得这样的人是作为PhD的导师是很不错的我经常可以被他inspire然后他也在Azure一起我们一起来做一些事情所以我觉得欢迎大家申请布莱恩的组 太棒了太棒了下次那个请Brian来上我们的节目然后跟我讲讲他在研究什么对非常感谢各位然后我们最后还剩一点时间我来想来聊聊除了这个大语言模型之外然后大家正在研究什么样的东西对因为我觉得就是现在虽然就是大家说Google这次比较极致的贯彻了 or executed scaling law, and pushed the frontier forward. But we see that in Silicon Valley, there are many teams still exploring some non-mainstream ways to reach AGI. These non-mainstream teams are called NeoLab here. The information I recently saw is that there is an article that says that NeoLab's recent financing has also been very well received by the VCR. In the past month, five new lab companies have reached a total of $25 billion in funding. For example, Reflection AI, which was founded by two deep-minded researchers, and they want to compete with OpenAI and Androbyk. They want to be the opening. Periodic Labs was founded by the former OpenAI research director Leon Feddas. They want to do AI automated scientific research. Their goal is to explore the field of low-energy supercells. So we can see some small models of the hammer, and some non-mainstream models of the pathe. There may be some pathe and lab, including the safe of Elias Soskever. and Mira Murati's Thinking Machine Lab, etc. So the next question is, I would like to ask you all, what are the researches that are particularly eye-catching in addition to LLM scaling law and AI development trends? Which ones are worth our attention? Let's start with Dr. Tian, okay? Because yes, Dr. Tian has recently published a thesis describing some researches on AI in terms of the theoretical and explainable aspects. Yes, this is also a direction I've been sticking to. I personally think that skin law is a very interesting and practical direction. But one day you will find that all the resources on the planet will not meet the needs of the computer. Are we going to turn the planet into a huge graphics card? This is a big problem. If the horizontal axis is a index and the vertical axis is a linear axis, it's hard to maintain the normal operation of the skin load. That's what I should say. If we go back to the previous method of learning machine learning, you may think that using index samples to obtain a linear-level effect is not worth it. This is the thought of the previous researcher. Because even if you use the nearest neighbor or the support vector machine, it can do this. So we think that skin-law itself means that we know nothing about the structure of the world. We just hope that this model can learn this structure. Learning from this model's structure and replacing people's thoughts. Of course, because the current model is getting stronger, every single point of it can make a lot of work in the world become automated. So it has its own meaning. So even if you're playing with a graphics card, it's not a bad thing. But as a researcher, I still hope that there are some... I think this is a more interesting direction. Recently, I have been doing some work here, such as exploring how the neural network generates a limitless mechanism. How did you learn this knowledge? and how to express their knowledge. We often say that the mother-of-pearl business network has a good model. It has a better internal structure and makes the model smarter. This will make the post-training process more efficient. So these are all some of the more vague or more high-level concepts. Or some people say that the neural network is used to compress data. For example, as Elia said, compressing data is compressing intelligence. But these words should be said to be of a higher level. What kind of data can compress? What kind of data cannot be compressed? For example, if compressing has intelligence, why can't we compress the software to compress the software and create new intelligence? But in fact, compressing software does not produce intelligence. The one that produces intelligence is still the neural network. So what structure is it that makes the neural network able to work? I think this is a very important direction. I think I will continue to stick to this direction. And of course, now... and the ability to use the big circle model, the traditional research thinking also needs to be improved. How to use the big circle model, how to use the tools to speed up the process of research, and how to make the research more efficient. I think this is a very interesting direction to continue doing. Recently, ICML has a review process, and it's also a rebuttal deadline, or something is going to be done tonight. I think when I'm doing experiments for my own articles, The efficiency of using modern AI tools is 100 times higher. It's very fast. I have an idea. I might have just come up with it in 20 minutes. I'll write it directly in cursor. I hope the code looks like this. After three minutes, the code is finished. Then you can run directly and make the effect. Then you can draw the whole picture. Then you can see the picture and you'll know how my experiment is. So I think it should be said that The efficiency of this is very hard to believe. I think this can increase the speed of AI research. If the speed of AI research is faster, maybe the understanding of the whole problem, the understanding of the neural network itself, will be much faster. I believe that one day we will know why our neural network can do so well. Maybe we will discover completely different algorithms. For example, the algorithm for T-Rex has been used for many years. Maybe one day we will suddenly realize that maybe we can get better results without T-Rex. If that is the case, there will be a big change in the trend. I think this is a very interesting direction to go. If that's the case, there will be a big change in the way things are done. I think this is a very interesting direction to take. So you are very understanding. Yes, I have always been doing a lot of theoretical work. And I have been doing some practical work in this field. This is a big piece of my research. Without this main line, you can do anything, but whether you can do it better than others, or whether you can do it more deeply than others, the main reason is that you need to have a deeper, continuous exploration of this problem. After having a deeper understanding, you can then return to research that is more applied. This way, you can go further. Yes, I think several big companies are doing the research on the explainable model. Mopernaheim actually has a group of people doing this. Not to mention Androbik, they claim that they want to do the explainable model. What do you think is the difference between what people do now and which company is doing the best? I think this is a common approach, but the mainstream is still that the neural network is finished training, and then I take the neural network out and study the connections between the neural units and their internal connections. and find out the weight of the object. Then we can find some interesting structures. This is what we call mechanical interoperability. This is the direction. In this direction, we need to do a lot of experiments and find some interesting rules in complex experiments. This is a method. My method is not exactly like that. I might have started with the first principle. I know that the training model is a training process that is optimized for QQ. So, based on this optimization process, can we get some kind of interesting conclusion? Can this conclusion be verified by the experiment? If I find an interesting mathematical framework, I can explain many things that happened in the experiment. In this way, the efficiency is higher than the efficiency of doing experiments and then summing up the rules from the experiments. This is my idea. Of course, this aspect is very difficult. Because the mathematical structure of the neural network is very complicated. 有很多人在上面做了很多很多的工作然后也没有特别多的特别大的进展但是我相信就是如果现在有更好的工具比如说我们拆了GBT 对吧或者没有更好的那个手段和加速的这个是连接工程的这样一些AIM的这样一些帮助的话AF和Covid的帮助的话其实这个进展应该会更快一点 I believe that a very beautiful or effective model with such simple rules and training patterns, why would it have such an effect? In fact, there must be a perfect or wonderful internal harmony in mathematics. I believe this will definitely happen. It's just that this problem is very difficult. We can continue to do it. Great. Yubei, I know you've studied the explainer model and the white-core model for a long time. What direction are you looking at now? I've already talked a lot about this, and I've shared a lot of similar research tastes. I think this direction is very important. It needs some reliable scientists to invest in it. Because sometimes it's not easy to stick to this direction. Because it's not directly produced. 而直接的产出又是我们这个时代就比较鲜明的一个特色然后当然从另外一个角度我们也可以看出来就最近的这个SSI然后以及Thinking Machine Labs然后他们这个市场对他的估值其实也是信仰的力量 You don't have a product, but the value has reached 50B, 56B, etc. I don't think traditional economics works. But the power of belief has some advantages. So I think that studying the white-core model and or the basic principles of AI or intelligence. From the perspective of the first principle, I think it's a very important direction to study intelligence. It requires more and more of the participation of the religious students, the participation of the researchers, and the persistence of the existing researchers. This is an important direction for me. I think I will do some of the mechanical explanation. On the other hand, I like to do some extreme questions. When you think about problems from an extreme perspective, you may ask some different questions. I think it's important to understand such a complex phenomenon, whether it's human or machine intelligence, how it works. and turn it into a scientific subject from a engineering point of view, we should look at these issues from an impossible perspective. From a normal perspective, we may not necessarily find the answer. Perhaps we need to... Let's go back to... and how to build a scientific domain in the past. Let's go back to that era and look at the perspective of those works. Then, today, back to the field of AI, we can ask whether we can view this question from an impossible perspective. 然后这个不可能是能带给我们什么样的灵感我觉得这个就需要我们每一个researcher变得weird一些就是或者crazy一些就是问出来一些别人都觉得crazy的问题但这些crazy的问题可能恰恰是引领我们走向一个不一样的未来的一个结果然后有一点我非常同意袁中学长的说法就是说如果skinning law只是我们唯一的我们可以大胆的把它叫做the first principle of learning Right? It's a Gilling Law. I hope it's not the only law. Because if it's such a law, then it's indeed a pessimistic human. You don't have electricity, you don't have computing power, you don't have data. In the future, you will hand over all your memory and context. What's left of the value of an ordinary person? It seems that we have become a pet. Our value is historical. It's really valuable from the perspective of Ante Rappi. Otherwise, it's not valuable. So I hope he is not the only one. As researchers, we have a duty to search for Another loss. This is what I believe in. But I think there are many basic questions that have not been answered. For example, what does the atomic structure of the signal look like? And how do we get the intelligence out of language? In my opinion, language is a shortcut from a very large perspective. It is the existing singalization that we have in De-Steal. But if we have to replace ourselves with machines, I hope that machines can reinvent a new civilization, instead of just distilling our existing civilization a little better than everyone on everything, but a little bit better, just. That's not ideal, right? It's like we create a machine that replaces us, but stops exactly there. This is a very pessimistic future. So, we are using this kind of machine to solve scientific problems. In fact, in some sense, we are also starting to attack with this kind of problem. The highest level of human activity is probably the most difficult for machines. The last bit. Can we create a machine that can really I think we need to make breakthroughs in this area. And I think we need to make breakthroughs and innovations not only in the field of skill and love. Of course, I think nature has given us evidence that humans and animals are quite efficient in the process of learning. Let's not talk about PoK Vision. Let's talk about the language token. The token we can obtain before we turn 13 must be less than 10 billion, or less than 1 billion. Can you use such a small amount of data to train a model? I don't think the size of the model is a problem. 然后也许功耗是一个很大的问题但是也许我对他理解其实不是那么深刻但是模型的尺寸其实primitive数量这些我认为不是最大的问题因为人其实神经元他有80billion到100billion如果你算上神经元的话就2-2的话对吧他的要再乘上1000到10000这样一个量级 So the human model is very large, but the data is very small. We are not that big on data. So how do we learn in this way? How can we break through the current learning curve in the number-level way? I think this is an important question. There is another question that I think is also interesting. Robotics. Today's robotics gives me a feeling that Because when I was talking to the control theory lab, I felt that we didn't need to learn. Why? Because we designed robotics. We have a model. If you have a model, why do you need to learn? Even if you need to learn, you can't learn it. you may only need to make minor corrections in each step. You need to do a system identification. You can use the theory of the same-level learning. You can do it very precisely. But fundamentally, it's not a method of learning or native control. But again, when you see biology and natural intelligence, in fact, the more advanced our intelligence is, the less we know how to use our bodies. You can stand up in 15 seconds. A kitten and a dog may need a month to be able to be more robust and local. So, a person needs a year. The higher level of intelligence is more dependent on learning. I think in robotics, of course, many big companies are dividing, the one they like to step on is the robotics team, right? Because it may have the most indirect impact on revenue, so it also needs the most long-term horizon. But this is exactly the opportunity for researchers. Today's robotics is a bit like the time when AlexNet came out. It's not very work-like and inefficient. Many places are not very good. But at this time, there are some... Maybe it's the research that's not very good. and we can do something that is useless. Maybe in the future, I think some of these things will slowly become an industry. It's not an industry today, but a good thing. It allows our researchers to have some time to think about it. So real-world robotics is also something I've been working on recently. Of course, I need to focus on not doing too much. and my team, the research team, and a small school team, can't really hold up a scope. So, yeah, that's what I've been thinking about recently. Okay, great. I think it's valuable that the first-line researchers have provided us with a lot of thought and perspective on the latest models. We have limited time today. Thank you for your time. Let's leave a little bit of time for our audience to ask two questions. I see that some audience asked, "Do you think that in the next three to five years, will big companies use new structures different from Transformers?" This has something to do with my contact engineering and long memory. In the case of Transformer, there are two competitors, one is Mamba, and the other is AduoKeyV. They can turn some of the old memories into states, like compact. 然后以OE的时间复杂度去做一个检索就是放在KB cache里面然后包括在model ARP内部也记录一些hidden states这个话我觉得就是在后面AI需要做长期记忆的时候会跟Transformer架构之间做一些trade off因为现在Transformer架构的这个model它相当于是就是直接回到那些markdown files里面或者说一些就是说persistent的一些external DB里面去找信息对 Okay, Dr. Tian. Yes, I think these things are already used. For example, like DATA.NET, and the KDA that Kimi recently created. These things are already used in large models. Of course, this kind of use can be mixed with Sliding Window Attention and Fooer Attention. Every three layers plus one layer can be used together to increase efficiency and not affect the long text performance. So this is already useful. There are no examples that can be used in completely different areas from Transmog. Yes, that's it. In order to have a 3-5 year experience, if the competition is very intense, it's actually quite difficult. Because the result of the competition is that everyone is not willing to spend a lot of time on architecture. They will still make some small improvements and see if there are any results. I think that big companies may still have more work space. Because for big companies, they have time and energy, they also have the card, they have the resources to explore these things. That's probably it. What about you, Yubei? I agree with what Yang said. Before Skilling Law ended, I felt that there was a lot of space within the short term. Because we are distilling our civilization. I think we have already accomplished this. Far from it. Since we haven't done that, perhaps optimizing architecture for many leading labs is not necessarily the most important thing. It may not be the biggest ROI for them. So I think SkimmingLog, including the Anthropic Julian, Everyone said that the skin law has no signs of slowdown. If you believe what they say, and if they are responsible researchers, then architecture is the most important thing. Of course, there will be various innovations. I think... My personal opinion is that when you are pursuing your limit, architecture should not be a transformer. When you pursue your limit, but you don't care about redundancy, then the transformer is not necessarily a bad thing. Because there are more important things to think about than it. So maybe you can still go. And then from my personal belief, I think I don't think we should find the transformer is all you need. It's a bit like a god. You figure out the genes, and the genes will stop here forever. I think it will change slowly. We were very popular back then. We don't talk about many architectures today. For example, LSTM. We talked a lot about LSTM back then. Today, you don't hear much about LSTM. I think eventually, there are still many opportunities for innovation in architecture. Especially, for instance, the state-space model has an advantage over the transformer in terms of physical processes. And the diffusion policy has been working quite well recently when we were learning these prior actions. So in the long run, I think there will be more architecture. Especially when we are pushing the limit, the architecture will have a bigger impact. I see many people asking about the concept of "Deep City UI". They say that the front-end capabilities of Gemini 3 are flying. The dynamic image mode has been added to the Gemini app. So this opportunity is to understand your views on Deep City UI. I can talk about it, because I have used some before. I personally feel that it may give users a better sense of texture in the interaction. For example, you may have used the word "absorb" before. 对吧 或者说你跟文字之间或者信息之间没有太多互动但是 Gemini 通过这样模式可以生成一个生成式的这种 UI让你跟它进行互动 它可以生成图片然后包括一些动态的这些效果 可以让你更好 Observe 这个信息 那像今天我用Nano Banana做的一个例子就是我看到一个推特他大概是在讲就是OpenAI包括NVIDIA之间的一个经济上的一个一个就是相互买卖然后相互有bill的过程当时我看的文字大概有一千多字非常长那我直接就把这个文字让Nano Banana帮我转换成一个illustrate这样的图然后一步步让我去理解 我就会发现被我看这个文字要快很多所以说我觉得在虚拟生态就是让用户的一种交互得到了一种很好体验获取信息的速率大大的加强了包括有很多这种interaction但是我觉得它的局限可能在于它只可以很快的针对某一个user case 去帮你去做这样一个事情但是他可能没有办法去大范围的普及化就是说想把同样的体验再给到另一个人可能那个人就会需要根据他的需求根据他看到的信息然后及时的Dynamic的生成这样一种UI来让他去招所以说我会觉得这可能是会更加个性化一点的一种获取信息的一种方式 And besides the three major North American factories, from exploration and commercialization, are video models returning to normal? Is this what Gavin can answer? Sorry, what is the question? (Speaking Chinese) It is actually a 2D, but it represents a 3D world and immersive experience. There are two other paths in the world model, such as Mesh Jam, which is an object with a physical collision size. The third is Gaussian Spread, which is the main thing that Margo released recently. It is a point in space. It doesn't have physical collision, but it has a lot of space in the game, especially in the art world. I think this also echoes the question about the model structure. I think the model structure in the LLM, Large Language Model, is more stabilized in the back. We will do more of the small language model in the future. We will optimize edge computing. This is also what Ecuador mentioned just now. Can AI understand the world like us? It sees and hears just like us. This is also a positive effect on the explainability of our models. This is not completely from the science perspective. This is AI for everyone. I have a place that I want to promote. I am very supportive. Open source model. Because our infrastructure has gone through a long process, from the railway transport to the power supply to the network to the computing power, now it's smart. Now this smart is trapped in those GPU-based data centers. We usually have to pay for the API to get these smarts. 是不是如果就是端策small language modelsmall world model這些東西的發展一個趨勢就是能夠讓我們普通人也能夠更多的被智能負能instead of paying for it因為unpaying for electricity我給電力算力付費現在我還要給智能付費這個其實就是我覺得是一個數字極權就是我現在非常support open source These are the models. And this is one of the most important parts of the world model. Because language models are not important. Next, spatial intelligence is going to be combined with those sensors, that is, hardware, to be integrated. I think this part is the hope that we can have a better immersive end user experience. Thank you, Gavin. We still have a lot of questions for our comment section. But we are very busy today because we are running out of time. So we won't be asking you questions one by one. I know you are very interested in the world model. We will have a video about the world model. We will also interview Gavin in the future. Please subscribe to our channel and don't miss our updates. That's all for today's live stream. You can watch our live stream replay on our channel. If you have any questions or comments, please leave them in the comments section. If we have a chance, we can invite our guests back to continue our communication. That's all for today. Thank you for your time. 好,拜拜,感谢各位,拜拜。