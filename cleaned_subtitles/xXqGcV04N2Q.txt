All right, hello everybody. Welcome back to another episode of the market close. This is a very special edition of the market close because we got Nvidia earnings and all of us are here. Tanner, Neil, Jose, myself. Very excited to be here. Thank you all for spending your time with us. We've got a lot to talk about. In about 20 minutes, we're going to get Q3 2025 earnings. These are going to be the most important Nvidia earnings ever. We say that every quarter, but this time, I promise we mean it.
>> We really need these
>> until next quarter.
>> Until next quarter. So, we got a lot to talk about. Uh Tanner, how you doing?
>> Doing awesome, man. Um really excited about this quarter. Uh I think Jensen will be able to pull it off and that the whole market can rely on him to keep this train going. So, um, yeah, I mean, it always feels like it comes down to Nvidia, and it does, but once again, I think we'll we'll be fine.
>> Okay, Jose, uh, you've been holding Nvidia for a pretty long time. How are you feeling going into this?
>> Um, pretty good. I mean, it it's I I expect a nice B and a nice guidance. Overall, how the market reacts is a whole different story, but I think at the end of the day, as an Nvidia investor, I'm going to be happy for the long-term opportunity of this company.
>> All right. And Neil, I I know you're a little bit heavier into AMD versus Nvidia, but how are you feeling for Nvidia here?
>> I mean, for Nvidia, I feel pretty good. I think I'm I mean, with Jose with this, I think it's an easy I would say a beat. Guidance would be fine as well. I think it's all about the comments of Jensen and on the whole industry and that's what the market is looking for more maybe accelerated demand um more conversations with other with other companies extra enterprises maybe already some signs of oh they're seeing a return on investment I think that would be great um but yeah I think it's a beat I think they they'll they'll easily beat the number
>> okay yeah look I'm very excited. I uh I got into Nvidia earlier this year after DeepSeek. Uh U3 were part of the reason for why I started taking it much more seriously. And now I have a full position that is up about 50% since I entered and I'm excited to see what show Jensen can put on. Uh in my chat, TripleV, thank you for being here. Thank you for the $200 super chat. He did text me today that he bought another 100,000 shares of Nvidia this morning uh at 185. So
>> true legend. He completed a million shares today officially with this 100,000 share purchase and so he's pretty bullish on Nvidia. Um, all right. So, let's get started. Tanner, I'll head it to you. The street is expecting about a$125 of EPS and 56 billion of revenue, 61 billion on the whisper or on the guide for Q4. I guess simple question. Do you think Nvidia is going to be able to beat these numbers?
>> Uh, simple answer, yes. It's just a matter of how much. um the the beats have been tightening and we've uh sort of, you know, gotten around the the 2% surprise on topline. So, I wonder if we're going to stay within that range. Um I haven't done too much uh deep diving this quarter into uh really taking my own stance on what I think is going to happen this quarter. I I'm more looking forward to the commentary by Jensen rather than just Q3 numbers. I also have um a question for Neil and Jose. If you guys think that uh data center revenue is going to reacelerate this quarter, year-over-year. Well, I I I think we were I forget we were just looking at this, right, Neil? I mean revenue growth for this um I I I don't know the data center itself but the revenue was 55% expected to be up this year and then next the next two quarters it was still expected to be 55% on the year-over-year growth um based on what the market was expecting and I do believe we're going to get a little bit better um in in in some of those. Uh, so I I mean I I think we're still going to continue to see that 55% year-over-year growth for at least the next two quarters at minimum, especially due to the crazy demand that I mean we we we see with Blackwell right now. And then uh the crazy half a trillion dollar number we got from Jensen during the GTC DZ. Um so a little I'm pretty sure that's going to be a question that's going to be uh asked a lot during the earnings call. Um but just the demand for Reuben and and when it comes out next year and right now for the Black Wall Ultra which just came out I think is going to definitely push some massive growth and we saw capix right overall capix grew dramatically from from all the hyperscalers this this quarter. So um growth still going to be in the 55 percentage overall. I haven't looked at the actual data center. Uh Tanner.
>> Yeah. So last quarter was 56% year-over-year growth. Two quarters ago 73. I mean, you pulled up something right now. How much was the the expected 59? So, expecting a reaceleration.
>> Yeah. But but do you do you also think that's going to happen? And really just uh you know, where do we actually end out at? Do you think that we can break that $50 billion mark? I mean, with all the positive comments that we got, especially from analysts and well, for Blackwell specifically, wouldn't surprise me cuz it seems like they are past the supply issue that they had previously. Maybe we might not be seeing this already this quarter, but then definitely the next quarter. Could we get 50 billion in just data centers? I mean it's possible would be with an extra billion to the estimates.
>> Yeah. And and and I mean the great thing is all of this right doesn't even include any kind of international um markets that are that are disallowed by or or prohibited by Nvidia right now. So, if we even hear anything um any updates on if we can finally start shipping to Saudis or or or to China, any little updates there, I mean, could could push this to definitely a 50 billion uh this quarter, but uh by next quarter estimates are 62 billion. I actually expect from the excitement to actually be closer to 64 uh to 65 billion. Uh so, and that's definitely going to be pretty much lead led by the data center space. Agreed. Uh I mean the other reason this is really important is because obviously we've had a 4% draw down in the S&P 500 since the start of November, we've had a variety of different macro things happen today. I mean if you're looking at rate cut probabilities which are very very important to kind of keep the health of this bull market alive. Uh not only did the Bureau of Labor Statistics say we're not going to be getting the October data today. So that was one thing that was really not the best piece of news. Uh but number two, you had the Fed FOMC minutes come out about an hour ago and uh participants, several of them said that they are more concerned about adding to the risk of higher inflation and suggested it's appropriate to keep rates unchanged for the rest of the year. Now, Nvidia, does it need low rates to thrive, but the macro definitely needs low rates? Nvidia is probably going to do their job and put up the numbers. The question is, will the macro uh also do their job in the context of rates coming down to kind of get us to that end of your rally? Do you guys think, Tann, I'll give it to you first, that even without the rate cuts, Nvidia can put up such a strong number of earnings that it can overcome the expectations of the market to get this end ofear rally, particularly because Jensen said there's a $500 billion opportunity at GTC over the next five quarters. Are you expecting that type of a quarter in terms of just the the overall numbers to really get the street to be a bit more excited again?
>> Yeah, I mean, you you you've already said it. I don't think Nvidia is, you know, what's making or breaking their business is 25 basis points of cuts. Like I think Powell even reiterated that, you know, like the the data center play is such a massive total addressable market and there's so there's such a massive opportunity here that a quarter point of uh rates is not going to change Meta's outlook, Google's outlook, Microsoft's outlook or any of the NeoClouds or any of the enterprises that are tapping into those customers. So, um I think for financials and and certain industries that that cut it close on margin, like they really need that quarter point, but you know, we're we're we're talking about 74% gross margins here on Nvidia. If their customers are complaining about the quarter point, we'll drop it a quarter point. Like, you know, what's the complaint here? Yeah, the complaint is more on the on those that have debt that does get influenced by higher rates, right? If rates do come down, then you have companies like Cororeef who will pay less interest every quarter,
>> right?
>> And I think that's also why we've seen a lot of weakness on Cororeef. We've seen them in CDS for uh or cororeweave for Oracle. Um the pressure is on those stocks. Again, 25 basis points might not seem a lot, but for for the likes of Core Weave, definitely Oracle, I mean, Oracle is still Oracle, but they they still they don't really have the free cash flow to support all of the all of the projects.
>> Well, I I I think that if they are going to their customers and their customers are saying, "Hey, we're having a hard time meeting you at your prices." I think the advantage that Nvidia has is such a massive margin on price that they could potentially cut price in order to meet those customers needs. So, um, yeah, we're we're still talking about them taking very advantageous pricing here, 70 plus% margins, and that's just because they have the best TCO versus any of the other chip suppliers. So, I don't know. I don't know if they'll be affected by it at all. Um, in terms of what we'll hear from Jens, and this is just my opinion, we're already talking about this $500 billion uh expectation of revenue for for from their large customers. What more do we want to hear from them? I I I think just a reiteration of that comment alone would be um you know some sort of reassurance, but I don't know if necessarily the stock is going to turn around on like ju just so just so we're clear, my expectations of Nvidia is good fundamental numbers and them continuing to grow. I'm not necessarily calling for green in the aftermarkets or that the market is going to react positively. We saw this last quarter, great quarter, and then you know the stock sold off and even in the next day I think we were down like 7% or something. But it it doesn't change the the long-term thesis and I think so or Nvidia is going to really benefit on you know the GTC's and the press releases and the uh you know multi-gawatt deals that they end up signing and talking about over time, not just the quarterly releases of their numbers. I I have a similar take there to Tanner because I mean we already know a lot of what more can Jensen tell us like he already gave us everything during GTCDC. We already seen kind of all these great updates and and all these announcements of various AI investments. Like what more can he say during earnings to really get us a little bit more excited? I mean, obviously guidance is is is is more than enough if he gives us a great guidance, but outside of that, I don't know. And and hopefully I'm I'm I'm hopefully I'm I'm I'm wrong and he gives us something that that gets us pretty excited after hours. But like Taylor mentioned, for overall, I'm excited for the company's fundamental after hours is pretty much a coin flip.
>> Okay, so people are pretty bullish. I just put a poll in my chat. Four options. Nvidia after earnings 180 to 185, 185 to 190, 190 to 200 or below 180. 44% of people are saying 190 to 200. And by the way, the options market, so there's a 7.5% implied move. Uh there are a lot more calls than there are puts, especially in that 190 to 200 range. So I mean, if there is a move, you could tell that the options market is trying to foreshadow a move upwards to 200. Now the options market has been wrong many times in the past but uh I think it is going to be a very very interesting move because again just like Tanner said Nvidia's already given us so much information the whole 500 billion in five quarters is they said that edge ETC and that was kind of the bombshell what more can you say so really I think the question on this call is going to be can they live up to that can they show that they're having the foundation to execute against that mission and this whole GPU argument right the GPU depreciation I'm sure Jensen's going to be asked about that can they clearly say that the GPU depreciation is good for their customers and not stopping their customers from upgrading to the next model which is what's necessary for Nvidia to continue selling chips.
>> And one thing I mean I would say with the $500 billion number there's I feel like some confusion um happening uh in Wall Street and online um because some people are saying it's $500 billion for Blackwell and Reuben counting quarter one and quarter two quarter uh come the previous quarters. Now, some people are saying that is just counting the next five quarters. I believe it's actually the prior opposed to the latter. Even though um even if it's the prior, it's still very bullish because it's still much higher than the overall consensus. But I do believe the that's going to be a question that we're going to finally get a confirmation from um from from Jensen and more importantly from from Colette uh which really deals with the numbers there.
>> All right, folks. Here we go. It is a Wednesday, November 19th, 400 p.m. Nvidia Q3 earnings. Thank you everybody for being here. The stock market is now closed. And now we wait to see hundreds of billions of dollars either go up or down. and for us to either be rich or poor.
>> That's basically it. That's basically basically it.
>> That's basically it.
>> All right. Nvidia 18652. We should be getting their earnings in about 5 to 7 minutes. Oracle was down about 21% on the day. Tesla up about 68%. S&P actually ended green on the day 662.72. Robinood nice little day 3.38%. Palunteer did get to the 162s 16542 still ended red for the day. Broadcom was up because of the googs. The googs was up because Gemini 3.0 is very very real. Google hit uh 3003 at one point ended at 293. Broadcom was up about 4 and a.5% on the day. Amazon actually ended green after going red below 220 on the day. SoFi 2672 that was up about 1.82%. Bitcoin and Ethereum and we didn't talk about it but obviously those got hit pretty bad. Bitcoin right there 89,000.5 on the day and Ethereum at 2945. It did get to 2,800 at one point as well. Nvidia right here 18657. All right. So, we should be getting these numbers soon. Uh Tanner, any thoughts on Gemini 3.0 coming out a day before Nvidia earnings and any implications on that you think for the quarter?
>> Um for Nvidia's quarter? I don't think about it too much. Um but it's a great model. I mean I I'm I'm very excited for Google stock in general and I I've been calling this for some time that I do think that they have you know by the way guys to these red candles uh Nvidia is not expected to show earnings till 420 or so.
>> Oh really? It's 20 minutes.
>> Yeah we have time. Okay cool.
>> Yeah. So uh let's focus on Palo Alto and stuff. Well well obviously look at this but um Palo Alto is going to be coming out before that. Um,
>> wait. Other for today.
>> Sorry,
>> I said other competition for today.
>> I don't know which CEOs are brave enough to line that up with Nvidia. Watch five people be watching any of the other companies other than Nvidia today. Um, but that being said, uh, Google, I mean, they have they own their own silicon. They own their own data. They have proprietary data through YouTube. They have all the customers, billions of people going to YouTube and and Google Workplace and and Google Search and all these things. I've just it was hard to bet against Google and their advantage in artificial intelligence. And you know, we're we're here to talk about Nvidia, but I think that TPUs are going to do well for uh Google as well. I just think they're extremely well uh positioned right here. But um yeah, you asked me what does Gemini 3 mean for Nvidia? I don't think much. I just think that it shows off that uh you know we're still advancing in these models and people think that you know somewhere we're going to start not being able to hit higher and higher benchmarks. It's not today. We haven't found it.
>> Uh Neil, same question to you and then Jose as well. Do you think just the the raw model capacity that Gemini introduced kind of got people to feel a little less scared about the AI bubble narrative that's been going on? Um I don't know. I think it's it's interesting and funny how today we are looking at Google and we're saying oh Google is a threat to perplexity to open AI when what was it 12 months ago start of this year it was perplexity chat GPT they're all coming for Google they're going to destroy Google and now look look who's back the return of the king I mean Google is there at the top and again Google's strength is the fact that they are printing cash. So they they can offer so many things for free. It doesn't really matter much. The other companies they cannot the the perplexities the core weaves the core the core weaves the core reefs the chipt they cannot offer things for free. I mean chaptt is they expected to burn god knows how much money for the next couple of years. Sam you cannot ask him how much he's going to generate in revenue because he would want you to sell your shares. But yeah, I I I mean Google again is showing why Google is Google and why I still think that Google should be top two uh biggest comp most valuable companies on the planet right now.
>> You know who else thinks that? Warren Buffett.
>> Well, maybe not, but Berkshire Hathway.
>> Yeah. Um Jose, any updated thoughts that you have on this whole AI bubble argument?
>> Um I just I don't know. I'm I'm just too bullish in AI right now to um even take some of these three year GPU depreciation rates serious. Like I mean I I don't know. It's there are certain things to watch out for. There are certain companies to watch out for but the ones that I follow pretty much like the hyperscalers uh obviously your Nvidia like those I'm not worried about. Um now with Gemini right there are there is actually one thing that Nvidia and Google partner up. Uh we know that Google doesn't use their TPU uh Nvidia GPUs to train Gemini but there is a enterprise market that sometimes doesn't like to run things on the cloud um due to national security reasons. They just like to have their own uh location um data centers and on premise data centers and Nvidia has partnership with a partnership with Google where um you buy their servers to kind of run uh these Gemini models. So, if you kind of see this excitement for Gemini, it could maybe in the long-term thesis be a nice kind of tailwind for that product that Nvidia and Google have together.
>> Agreed. I think that's fair. I I think given, you know, the the sort of lack of uh excitement that people have been having over the past couple weeks with the AI trade, it was nice to see a foundation model come out that was just lights out in terms of its applications and it's getting universal praise across the board, which is also very important. Um, we have about 15 minutes until we get earnings. I don't see PaloAlto numbers yet. The stock is moving a little bit. We'll see if we can get the numbers in a second. Um, Neil, price action. I mean, if you had to pick, do you think this one gets closer to 200 or kind of stays flat around this range given everything that's already baked into it?
>> I already know what Jose is going to say. So, I'm taking the other side.
>> What am I going to say, Neil? Tell me. Well, this morning you said you don't like predictions and you didn't want to take the upside. So, I'll take the upside. We go up 7.5. We go we go the the 7.5 on the upside this time. Although sentiment is is completely horrible, but we can still see Nvidia go up and the rest not move. It's also possible, but we go up. That's my prediction.
>> Jose, you think we're going to dump?
>> No. No. I actually was I woke up from my nap a lot more bullish. Uh, so
>> you have a dream about Jensen?
>> I was about to say
>> um um if I can't pick flat, I'm going to go green.
>> I'm closer to 200. If we don't, it's either flat or 200. No going down.
>> And if it is, I'm thinking a nap.
>> Tanner, what about you?
>> Uh, I think bullish, but um I agree with Jose. I I I don't know if it will be uh if it will be a lot, but yeah, the surprises are just getting tighter and tighter. Um I don't know how much that's going to change this time around. Maybe there's some China uncertainty and stuff like this where they could squeeze out some additional revenue that maybe Wall Street is not expecting. But um overall I think where where Nvidia is going to move is the 3 months between the reports rather than the reports themselves these days.
>> Yeah. Yeah. I I think the biggest thing would be if TSMC did really open up a nice amount of um extra capacity that allowed them to kind of allow us to beat the norm of how much Nvidia usually beats. And and that's the thing is it's analysts have gotten better at kind of determining how much capacity usually TSMC can add. If these analysts are wrong, then TSMC did so much better. Um and and we did see Nvidia's inventory of working goods increase dramatically in just the past quarter. So if those working goods turn to finished products and we're able to ship, um then the ability to be is is there. It's there, but I guess that's what we're going to have to wait for the next 10 minutes to see if it's it actually happened. Wouldn't we have seen a lot of color from you know many of their largest customers like unlike many c or unlike many uh other businesses that we follow
>> Nvidia is like the number one question that is asked at all of these large companies earnings would we have not heard some sort of massive uptake in in chips that sort of broke the norm? I I think the biggest thing was um I don't know that is true. I mean what do we hear
>> said they're spending more money.
>> Yeah.
>> Capex agree but we're expecting to grow at 60%. Like we're 59%. So
>> um they are all spending more but we are expecting more in earnings. So in order for them to surprise on earnings we need to see 65% growth on data center revenue. like there needs to be such a high amount of a beat in order to surprise Wall Street here.
>> I think the craziest thing about Nvidia is that it's 8% of the S&P 500. Uh the S&P 500 is a majority of a lot of people at least in the United States retirement accounts. Like this company, as much as we don't want to say we are topheavy as an economy, if we didn't have capex for the past two and a half years, 50% of GDP would be gone. So, it's just like it is so important that they deliver the right numbers. And at the end of the day, Jensen's a human being, right? Like if they miss numbers, they miss numbers. But like it is so freaking important that they live up to the expectations and surpass the expectations. And also for the Trump administration to boost about a good economy, you've got to have the market doing well. And Nvidia at the end of the day is the market. So, I think that's why there's so much pressure on this quarter as well. Um, PaloAlto numbers should be out. I don't see a big move here.
>> If I don't know if you care to add this to the list as well, but oddity,
>> we're up about 11.7% right now in after hours.
>> Uh, okay. Tanner, can you explain Tanner this one to people who don't know what this is
>> or?
>> Nope.
>> Okay. So, why do we add it?
>> Uh, well, I mean, it's a decent it is a
>> You have no idea what the company does, but you're like,
>> it's a popular retail name. I don't follow it, but I do have them on my chart here. Up 12%. I thought maybe you could pull some numbers. I don't know anything about them.
>> Okay. Well, PaloAlto beat by 4% on EPS, 93 cents versus 89 cents. Revenue 2.4 versus 2.47. Revenues up 16% year-over-year. EPS up 19% year-over-year. Palo Alto is flat. Literally flat. Not getting any move. Oddity, whatever these guys do.
>> Oh, look. He found some numbers. um triple beat and raise 148 million on guidance, 29 million on revenue, 71.6 on margins, 40 cents of EPS versus 33 cents.
>> Well, that's why it's up 11%.
>> Yeah. All right. Next.
>> What the hell does this company do? Oddity.
>> It's something with uh health and wellness. I know that they have some uh beauty something. I don't know.
>> Yeah.
>> Okay. So there you go. Nvidia, eight more minutes. Uh Jose, what are you thinking about circular financing? We saw the anthropic Nvidia Microsoft deal yesterday. Is this scary or is this just inevitable given Nvidia has so much free cash flow?
>> I mean, I think you only have a selected amount of customers that can pay for these types of clusters and and orders that you're going to kind of see these types of circular deals. Um I think Anthropic coming into the um into the mix now be before it was open AI was the only one holding up this house of cards. Now I think with Anthropic coming here it shows that now you have two kind of pillars holding up this house of cards. So it to me it seems like now it's it doesn't matter who ends up winning someone's going to need that compute via Anthropic via OpenAI via whoever. Uh and I think in the upcoming um months we're most likely going to see other AI companies with similar deals. So um Anthropic massive deals with I mean they have a deal with Amazon, they have a deal with Google, they have a deal with AWS. The only reason they're doing that is because they need the compute. Um they're seeing massive revenue growth. Uh they're seeing strong demand for their coding solutions. Uh so it's it's for them it's an actual great revenue business and um it seems like they have a better business model than OpenAI. So, I'm happy they are added to this pillar of of House of Cards of AI.
>> Uh, sorry, I was muted. Neil, are you concerned about circular financing? Um, I would have been concerned if if the companies that finance it have no actual profit and free cash flow to finance since since we're talking about Nvidia, Microsoft,
>> um,
>> and companies that have way more than 13 billion in revenue.
>> Exactly. Um, then a bit less because I mean it's like VCs, private equities and all of that. They invest in companies and then they have a portfolio of companies and they want that company to then use maybe a service of another company that they own just because it makes it easier. I mean why why not if it if it makes the whole ecosystem run better and grow faster and they have the money because we've had this conversation earlier this year. What does Nvidia do with all that free cash flow? Buy back more shares, add an extra cent in dividend. I mean so they're doing this. So they're doing this. They're helping other companies. They're investing other companies. And some people don't like it, but why why not? Like, why wouldn't they do it? It it makes sense since eventually the money comes back to Nvidia and the ecosystem grows and it makes sense. That's not to say that there won't be some small AI companies that will bank be bankrupt and blow up in the future. Like every cycle, we see a lot of companies succeed. We do we do see some companies that will that will blow up. It's just the nature of of of of what evolution, I I'd guess.
>> Tanner, your thoughts on the circular stuff?
>> Um, I'm actually perfectly fine with it. If if you guys remember from Well, I'm perfectly fine the way that Nvidia is doing it. I think there's a difference between the way that Nvidia has done it and the way that AMD has done it, by the way. Uh, one is taking equity as payment. The other one is giving equity as an incentive. Um, so if you go to buy a business or something like this, you see it all the time. Companies can either give cash or equity a as uh as deals to buy companies. In the way that I look at it, Nvidia is essentially buying parts of businesses, giving them their product, and then well well buying parts of their business and then those companies are ordering from them. I'm buying Jose, Neil, Emit. We're all buying Nvidia and they're buying nothing from us. So imagine if Open AAI, we're we're we're going to Open AAI and then Open AAI is saying, "Okay, we'll give you back some more money." Great. Love it. They have so much cash. What does Nvidia do outside of creating a massive venture arm, which is exactly what we talked about last quarter? I said this was going to happen. It's what happened with Google. It's what happened with Microsoft. It's what happened with Apple. They have to have some level of just a massive venture arm to go out and invest because that's the only thing they can do whenever they're the most profitable business in the world or or will be the most profitable business in the world essentially by the end of this year. But um so I think it's fine. They're buying OpenAI which is historically the fastest growing company in the world ever. um Intel, Anthropic, all of these companies and they know that those companies are going to do well because well, you know, a little different on the Intel side, but they know that those um you know, AI businesses are going to do well because they're using Nvidia's products. They are going to the products that they think are the best in the market, have the uh lowest total cost of ownership, and in return, they're taking an equity stake in those businesses. If we ever look at any of those deals, the OpenAI deal, the anthropic deal, any of these, they are buying way more chips than what they're giving them in uh to to purchase in equity, they're buying something that is expected to continue to grow. Now, people can say that, you know, OpenAI at 500 billion might be a lot. Anthropic at, you know, nearly a similar valuation is is also a lot. But um you know those same similar characters probably said that open AAI was overvalued at the first time whenever uh Microsoft did a a you know their first buy at 50 billion. I don't think we know where this market settles out at. The growth in users, the growth in revenue, the growth in in total take rate continues to climb. Nvidia wants a part of that. I think it's one of the only natural ways that they can grow at this size.
>> I agree. Numbers are not out yet, folks. We got two minutes. Here's Palo Altos real quick and in about two minutes we should have Nvidia officially coming up.
>> I have a question. H
>> 93 versus the 89 cent adjusted estimate revenue a slight beat at $2.47 billion. And then if we look at some of the other metrics that investors follow, whether it's annual recurring revenue for its nextgen security at $5.9 billion that came in ahead of expectations as well as its remaining performing obligations. It's second quarter guidance, so its outlook for the second quarter in line with expectations. And going into this report, the uh the bar was set high with a stock up about 55% over the past six months. The company also announcing a new acquisition, a next generation of platform called Chronosphere. And as you know, John, it follows that mega acquisition of Cyber Arc for $25 billion. So, we will look to hear from CEO Nesh Aurora on his company's M&A strategy.
>> All right. So, you got another acquisition. They did beat on the top and the bottom. Stock is down 6.5% on PaloAlto at 188. Nvidia is left one minute. We are going to see the numbers soon. I'll be looking at the stock. These three guys will be trying to get the numbers. I'll also see if I can get the numbers, but I'll get the immediate reaction to the stock. 18675 up about 3% on the day. We should be getting a move very soon.
>> I have a question for you, Amit. First, is OpenAI too big to fail.
>> I think so. Yeah.
>> Yeah.
>> I think they've just committed too much money to a lot of public companies that are now in deal with deals with them. Like, if they do fail, could they be replaced? Yes. There's other model companies that are out there, but a lot of that spending commitment goes out the window, right? And that's why I feel like they are too big to fail.
>> I I'm on the other side of that. I I don't think any consumerf facing business is too big to fail.
>> We're green. 189 initial reaction is positive. 18940. That green's got to hold. This earnings has been a lot of green candlesticks and then reversals immediately. So, we got to see if that can hold. Can we break 190? 190 has been broken. We're up about 3% after hours. It's continuing to hold. Nvidia 1 8%. 190 now back down to
>> Okay. Uh EPS is a$130 up from A1.26 expected and revenue was 57 billion. Both beat by 3%.
>> Revenue was up 62% year-over-year. I mean,
>> even though that's six, no, we were expecting 55% year-over-year growth.
>> That is not bad. Revenue is up 62% year-over-year on a company of this size. EPS is up 60% year-over-year. Do we have the guide? That's the important one. Nvidia now 193. Street likes it.
>> I can finally take a breath. Holy. All right, we're fine. I almost forgot to until you reminded me. Terrifing. Yeah, I was turning red here. I'm trying to look for this guidance.
>> I'm trying to see the guide as well. That's the big number. Let's see if we can get you guys that. Wow. 194 street likes it. The street likes it. Now again, it's got to hold it, but it's doing a pretty good job. That's up almost
>> and corweave. Cororeef is up 4.5. Nebia's 4.5. I run 5%. Everything's Everyone's up.
>> Can we just close it and leave? That's it. That's it. Can we
>> It's up,
>> guys. Is this right? Are you seeing 65 billion on Q4? Cuz that's a $4 billion beat if that's correct.
>> I'm seeing 65 billion. I'm trying to confirm, but
>> yeah, that's what I see. I just opened up the press release of 65 billion.
>> Wow, dude. That's a $4 billion beat on the guide. And you know they're going to beat 65 in Q4.
>> Yeah. Yeah. Yeah. That's their conservative number which is crazy. Which is their conservative number is still bit almost as equal as the most bullish. I think the most bullish was Bank of America with 65. Uh so that is insane.
>> And then center
>> if we ever see a market like the China market or we say yeah we can actually ship to to the Middle East right now. I mean that's an easy beat even from there. So it's conservative conservative.
>> So the guide is 63.7 to 66.3. So on the low end they're saying 64. Street thought it would be 61. Maybe the whisper number was 62. So they beat that again. But they're guiding on the high end for 66 which means they if they come in at like 68. That is a massive beat on the I mean what more could you want from them at that point?
>> Man look at just data center alone increased by$10 billion quarter over quarter. 25% quarterover-arter growth, 66% year-over-year growth for data center alone.
>> The the only person that probably cares about this is Jose, but uh professional visualization as well was up 26% quarter over-arter and 56% year-over-year to $760 million. Uh I I mean now all those workstations are being just gobbled up by AI engineers and anybody else that can use those nice RTX Pro GPUs.
>> Very small line item but still
>> fun to watch.
>> Some cash equivalent $60 billion.
>> Wow.
>> They have plenty of cash. So Jensen quote blackwell sales are off the charts and cloud GPUs are sold out. Compute demand keeps accelerating and compounding across training and inference each growing exponentially. We've entered the virtuous cycle of AI. The AI ecosystem is scaling fast with more foundation model makers, more AI startups across more industries and in more countries. AI is going everywhere doing everything all at once. Uh revenue again you can see 57 billion. That's up 62% year-over-year. Gross margins inching towards 74%. Opex at 5.8 billion. operating income 36 and then you have net income 31 billion of profit which is a uh 55% 54% net income margin incredible and then fourth quarter outlook 65 billion here's a bit more coverage and then we'll get deeper into the numbers EPS earnings per share higher than the street 5 cents higher on revenues of 57 billion also higher higher not only than the street but higher than buy side numbers uh in regards to data center revenue which is contributing about almost 90% of total revenue. So a big factor that is stronger $51.2 billion. And then gross margins, we keep worrying about input cost, memory cost, etc. Gross margins coming in slightly above 73.6%. Street was anticipating 73.4. There is a very bold statement from Jensen Wong uh the CEO of Nvidia. Blackwell sales are off the charts and cloud GPUs are sold out. compute demand keeps accelerating and compounding across training and inference. So, uh, and he said, "We've entered this virtuous cycle of AI." So, I'll go through it to get you some more numbers, but so far quite bullish. The stock reacting positively, guys.
>> All right, Christina, thank you. Stocks up above.
>> I mean, this is a good quarter, dude. Sold out. What What is the biggest fear of this AI bubble that there's like we're overbuilding these data centers, these GPUs? Jensen's like, "We can't build them fast enough for people.
>> Send them to space.
>> Send them to space." I mean, goodness, we're at 19140. Maybe the stock sells off a bit, but I mean, realistically, if we can just detach ourselves from the stock that quarter once again, we'll go deeper into the numbers, is legitimizing this entire AI revolution that all of us have uh been invested in for the past couple years. And eventually, the street's going to have to allocate capital to the companies that are growing. Nvidia is showing that growth
>> and and I would say just the guidance alone right it showcases that even though analysts think that they know the stock it's still even um breaking those right we we were in the port portion where we were just talking a few minutes ago that analysts were getting a lot closer at kind of determining and again not not looking at stock price but just the percentage of beat is is I I would expect this to be a lot higher than um prior beats and it it showcases that Nvidia can still shock us even though everyone and their mothers are watching this and looking at the revenue numbers. Um they they still give us the that curveball.
>> Yeah. I mean we we essentially tightened on the the revenue beats was going almost down to under 2% a quarter. This time nearly 4%. You know, so um this was a little bit of a of a shock and the market likes it. The market actually doesn't like it as much as I think that they probably should. But that being said, there's an overall bearish sentiment on the market right now. I mean, we were we were trading on this stock at 5 trillion not too long ago. Now we're at 4.5 trillion. Essentially$500 billion dollars removed from Nvidia. Maybe a little bit of that pouring back in, but only a small bit.
>> Agreed. Um, so let's keep going through some of these other numbers. Uh, this is pumping all the data center plays by the way. Coreweave pushing almost a hundred or not core, Nebius pushing almost 100. You gave me a heart attack for a second there. Man, I hate you.
>> Well, Cory was up 4%, so you shouldn't be too upset. Uh, you got Bitcoin back to 90. Jensen somehow single-handedly created a $1,500 pump on Bittycoin. Uh, Nvidia again up 2.45%. Google's up half a percent. Nebia's up 3.92%. Tesla's up a little bit. Google's up 2%. Broadcom up another 1.5%. Oracle getting some love. Meta getting some love. You got the S&P itself that's up.3%. I mean, we really needed a good quarter, and we got a hell of a quarter. We got the quarter that we needed. Uh, let's see if we can pull up some of their deeper numbers and try to see what else we have. Man, I'm still trying to get their press release.
>> You don't see it on their website?
>> No, I don't see it.
>> I'll send it to you.
>> Okay.
>> Sometimes anything, I'll show it on chat. Um okay. Yeah, let me share this. Oh, okay. You shared it already. Okay. So, some other highlights. Um third quarter revenue was 51.2 billion up 25% from the previous quarter for and that's just uh that's excluding or that that's just for data center. Blackwell had achieved the highest performance and best overall efficiency in the semi- analysis inference max benchmarks. Dude, shout out to Dylan Patel getting referenced on Nvidia's earnings. That's crazy. It's incredible. Strategic partnership with OpenAI to deploy at least 10 gawatts of NVIDIA systems revealed plans to accelerate seven new computers including with Oracle for the Department of US energy. Uh 600,000 GPUs being deployed with Humane, which is the subsidiary in Saudi Arabia. Gaming, third quarter gaming revenue was 4.3 billion. We forget Nvidia's graphics card company for video games as well. So that's another 4.3 billion. Um that's up 30% year-over-year. And then professional visualization 760 million that is up 60% year-over-year. Automotive 592 up 32% year-over-year. Nvidia with their Cosmos synthetic platform to be able to help companies like GM bring in the world of self-driving. There you go. Almost half a billion in revenue one quarter for that. Okay. So one thing I also did notice um in the within the data center market I I have on the other press release they talk about networking. networking was um out of the $51 billion in data center revenue, networking was $8 billion and it was up $1662% year-over-year. Um so this is kind of what Nvidia is is right is the whole rack scale solution and now kind of this whole data center infrastructure. They're not just building or helping build the racks, they help kind of connect everything together. So net networking demand I think is going to continue to grow and and $8 billion this is uh crazy. It's it's their networking revenue is probably bigger than some of the actual companies that do networking itself. Uh so uh it just showcases how this company is just taking everyone's market.
>> Yeah. 13% quarter over quarter networking revenue. They did say that was going to happen though right on the second half of 2026. I think they did they did state that it was going to accelerate, but um it still is pretty shocking. I I'm surprised like purchase of property and equipment like their their cap Xpend went down quarter over quarter. It's only 1.6 billion. They brought in $22 billion of free cash flow. I mean like everyone else is paying the cost to get Nvidia's chips and they remain such an asset light business for what they really are. I mean, it's incredible. I It's such a magical business. And then people complain about them going and buying OpenAI and Enthropic. It's like, what do you want them to do with all this money? Like, just sit on it. Like, I don't know.
>> You're right, dude. Like, what? Giving me another penny for a dividend is not going to make a difference. They have to invest in the ecosystem.
>> Yeah. Yeah. And if they are truly a big believer in artificial intelligence, which they are, the dividend is not going to do anything for shareholder value. what it's going to do if they truly believe in it, which they get, you know, a firsthand look at all these products that that these companies are making, they're realizing, oh my god, this is going to change the world. Investing in Enthropic and Open AI and all of these businesses is going to multiply our investment. That's way better than throwing it in some US treasuries or something like this like like they're really making the long-term bet. And Tether, you mentioned one thing is like they are in the front row seat of these AI companies. like these AI companies come to them and say look I need to have your GPUs do this type of thing because the next model I'm going to create I expect it to do this. So it's like I don't know if you're I don't want to say it's like they have that insider knowledge within there of how well these companies are going to go. Um that's like for them it's almost like yeah might as well just invest in these they're going to like you mentioned buy more GPUs from me but for me it's going to also be an asset growing investment at the end of the day. So it's it's uh with that amount of other free cash flow and I don't know with the current administration but I would say um prior acquisitions would have probably been blacked off blocked off. So um maybe instead of doing acquisitions they rather do these types of investments to keep the ecosystem uh fully um in full survival mode if ever needed to be. and and no administration even even the next one would complain if they have a little cut of the entire industry rather than trying to buy up certain strategic uh acquisitions which might fall apart later on. I I am just so happy when stocks go higher like like like like I'm just so happy that stocks like it kind of sucked the past three weeks just like happiness-wise like now that stocks are back to at least for today Nvidia pushing 194 just makes you happier dude
>> today's dinner was honestly going to be frozen pizza I was just going to throw it in the oven I I'm about to call a wife in a day and tell her that's not Just frozen pizza. Not even in the oven. There's no oven.
>> There's no oven. No heat right now. The heat is not on. All the money being saved to buy more.
>> I don't use the oven. It's going to help the cost of it of the data centers spending all that money on energy. I can I can help the companies I'm investing in.
>> There you go. Um but honestly whenever a a c or a company like Nvidia continues to sell out their products over and over and over another thing that needs to be recognized is that they are not selling their chips to just you know the first customers. They almost need to be a kingmaker in some sort of respect because they want their customers to come back. So they need to kind of pick winners a little bit. Um so it is interesting uh you know Nvidia is almost getting pitched to in the AI space to be like this is what we are working on give us your chips you know
>> it's the VC of the space
>> 100% 100%.
>> The S&P 500 up almost half a percent after hours. Nebius is up 11%. Core Reeves's up seven. I ren's up 8%. Cipher is up 10%. Every data center play getting a boost because Nvidia basically just said demand is real and there's going to need to be a lot more data centers built out for this demand. 1935. Here's what DA Davidson has to say on this quarter.
>> Circular deals. All these things are valid concerns. They've put pressure on Nvidia's stock. But sometimes the most important thing is the only thing. The demand for AI compute is growing so fast. The models are getting so good that all of these companies will need to continue to buy Nvidia in into the foreseeable future in order to be able to provide us access to the AI compute we want. Just yesterday at um Google came out with Gemini and we've been talking about how that that's on top of TPUs. But the more important takeaway is that this is by far the biggest model trained on the most chips which tells us we're still on the scaling for compute. So our models are still getting better even though we're now using uh gargantuan clusters of chips to train them. That is a very good sign for the demand for Nvidia. Okay, we want to get
>> Jose, would you kind of agree with that core argument?
>> Yeah, I agree. I mean, the other thing is like we're still just in the chatbot era. Like I people still forget that we're still only the 8second video making. All right. You're you're only can make 8-second of videos. What happens when companies are out there using this to make an hour movie or or make some uh 50 hour gameplay of of video games? the healthcare industry, the automotive industry, all of these don't need to succeed at one time or don't need to succeed, but the opportunities for one of these to become a huge the healthcare, I don't know if I mentioned that, um, for this to become a multi-undred billion dollar opportunities is out there for every single market and we only need that one that can take this even higher and higher. Yeah, that that is not um stated enough like the the need I think Sam was was on a podcast recently talking about how Agentic AI is going to go from doing tasks that take minutes to tasks that take days. What is the token generations or generation required in order to handle those types of tasks? And you're not going to run one per enterprise. there's going to be running as many as they possibly can to continue to grow their business. So like I do think to some degree I think CERN Basher said this or someone like this we are almost at that phase of electricity where we're we're starting to get like the the street lamps outside are now being powered by electricity and yet people are calling it a bubble like like nobody's homes are run on electricity. No businesses, just the street lamps outside and people are like, "Man, these valuations are crazy at forward pees of 30 times. What are we talking about?" Like, and and by the way, after this quarter that they just put up, it's really showing like four PS of like what, 27 times or something like this for Nvidia. It's like cheaper than Microsoft. It's cheaper than most of the Mag 7. I don't know. And I like those businesses, too. And the other thing that I think is really important about this is that let's say the stock does sell off, right? Let's take the super skeptical view that all right stock goes back to 185. It becomes cheaper now that the earnings have gone up and the stock continues to go down. Number two, the people that didn't have exposure or the people that were on the fence of AI bubble, the people that are like listening to Michael Bur, they have a chance to see a new quarter that we just got listen to Jensen over the next 90 minutes and really ask themselves, do I want to be a pessimist for the next five years or do I want to side with everything that I see is happening in front of me and that has the numbers to back it up. This is not a fairy tale meme stock. These are real numbers trading at a reasonable multiple. You're not paying 700 times earnings, 800 times, you're paying 27 times next year's earnings on like and they get to make a decision. And if it does sell off, I think you get a lot of people that get excited to get some exposure and buy that debt.
>> I mean, it's definitely possible that we do have a pullback because we do have some macro data that's expected right this week. Um I don't know when, maybe tomorrow or Friday. Uh so it is possible that we get a pullback but then like you said if we get a pullback we just got numbers it is getting cheaper even for a company that is worth what $4.6 trillion still growing 50 60% year-over-year quite quite astonishing. Let me actually call Michael Bur. You mad bro? You mad?
>> You might be a little mad. You might be a little bit mad. Yeah. There could be reasons for a stock stock market selloff that has nothing to do with Nvidia, right? Jobs, Fed, Trump tweets, all this stuff. But the point is, if Nvidia sells off after these numbers given all the fears of AI bubble, I mean, you got you're going to have a lot of people wondering if that's a really good opportunity, just like DeepSeek was a great opportunity for a lot of people to build their positions for the first time. And that might happen with Nvidia here. Uh, we got about 20 minutes until we get the numbers. Uh let's get a little bit more coverage right here and then uh I'll I'll give these guys a couple minutes to think about what question they would ask if they're on the earnings call. But if you are on the call, put in the chat what would be your question you would ask to Jensen%
>> increase in capex into 2026. I think that pretty much secures 2026. So, for the most part, we're talking about 2027, which is can we get enough power and is there enough downstream demand to monetize the previous investments?
>> All right. Well, James Demer back with us here on set. Uh, you already own Nvidia, so you're happy. You probably don't sell it, but do you buy more?
>> Uh, I think if you don't own enough of it, you got to add more here, John. And I think a lot of people don't own it. I think a lot of people are just again underestimating how incredible these numbers can be. Probably going to be that way all the way into 26. So, uh, if I own it, uh, which we do a lot of it, um, we want to continue to have that position. If your position is not big enough, I think you use this chop. I mean, the stock's down 10% from the high. Here's a great window to go in there and acquire more shares. And I don't think they're going to have any problem with competition in 26. Let's keep in mind the the real risk in in in Nvidia isn't the AI cycle because we're early, but it is the product and you've got Google and Amazon coming along with some uh chips as well and that could be something we look at in 26. But boy, this clear ceiling from here.
>> Yeah. Barbara Dan is here on set as well, also a shareholder. Barb, I want to get your thoughts on this report. We just talked about it. The fact that H20 sales were insignificant in the quarter according to the to CFO comments. I mean earlier today you had Jensen Wong in Washington for this Saudi investment summit as well and one of the headlines that came out of that is the fact that it looks like the US is now greenlighting these advanced chips for investments in Saudi Arabia. How much does sovereign AI still have a role to play especially if you do start to see a petering off in coming years uh of hyperscaler capex? I think sovereign has a has a big role and we haven't even talked about China because that's still very caught up in political waves but that could be another if we they get permission to sell the black well current generation chips that could be another 50 billion to them but the sovereigns are definitely coming and it's was the hyperscalers at first that's those are the ones that are spending hundreds of billions but the sovereigns will be quite large and as long as there's not a political issue in selling to them this could be big big new markets that are happening so the Saudi Arabians you know are going to be one of many and we've already seen you know a bunch the country stepping up for this. So,
>> got the sovereigns that are coming in. Jose, if you had to ask a question on the call, what do you think your question would be?
>> I I don't know. I I know what supposedly thinking. Maybe like if if you can J, if you can honestly say like if we're between level one to level 10, where are we in the AI stage right now? Um I'm pretty sure he's going to say level one, but would just love to hear him say it to the overall market. Okay, Tanner, any thoughts on a question you'd ask?
>> Um, you know, we heard some commentary around the $500 billion. It's just, you know, what happens to margins up or down during that next five, six quarter buildout? Um, is there going to be some compression or can they keep it at these certain levels? I mean, I'd like to hear some commentary on that.
>> Neil, any question you'd ask?
>> Maybe just on the ecosystem, right? the health of the ecosystem because that's been I mean the whole market is questioning Oracle Corwe and all the other players maybe his thought around that subject and moving forward what he's what he's seeing there I think that could calm the markets as well in this whole is AI bubble type of
>> I agree that's going to be my question my question would be on the Neil clouds is like can you give us a little bit of clarity on why these business models like why do you have four billion dollars of a stake in cororeweave right so I I would like him to explain why these business models matter what's going on with their debt profiles, why their debt is necessary for them to be able to finance the GPU buildout that they're leasing to customers. And you know, if you could calm the markets down about that, I think that would be important.
>> The the funny thing is, well, I'll talk about this and then I'll talk about that. Um, now I can make it a little bit bigger. Uh, in case there are some visual learners out there, if you take a look at the numbers that we just saw in this quarter, this is what just happened.
>> Like we saw a massive. so hard to continuously grow at this rate. And many of the bears said, "Okay, but now you're seeing the downtrend from 265% year-over-year growth, and now it's going to peter out into the, you know, teens level growth and potentially negative if we end up seeing uh some real competition come in." What we actually saw was a reaceleration of growth, data center growth especially, and just the unbelievable breakout that we are seeing at this scale. This is $57 billion in revenue. That's more than Meta. Okay, $7 billion more than Meta. It's just incredible the size that they've gotten to in two three years. And and Tam, it's crazy to think that this is without China, right? Imagine if that market ever this would have been what 60 plus billion dollars this quarter if the China market had ever open will ever open up to them. So, I mean, it's it's uh that is just now back to being a huge tailwind if we ever open up that space.
>> Yeah. Yeah. That's crazy. That's crazy.
>> Oh, man. Tanner, what were you going to say about the the Neoclouds?
>> Oh, um yeah, just that their stake in Coreweee wasn't a three to4 billion investment. It was actually much lower than that, but they've built into it. I think it was a $700 million investment, something like that. Um, and they had done very well to to to grow into that $4 billion stake.
>> Got it.
>> That is fair. Uh, the call will be in about 15 minute, folks. Nebius right there 101. Coreweave is at 80. Hoodie getting a pump at 122. S&P trying to get to 667. And then Nvidia trying to bust 195 here. I mean, if the call goes well, you know, maybe 200 is back on the way. We are getting into the best part of November. November historically supposed to be good, but if you really go granular, like the 21st to the 30th is actually when a lot of the gains happen. So, I mean, do have that coming up and maybe uh Nvidia setting up for that as well. Do you think Tanner, I'll go to you on this. Do you think the GPU depreciation thing is going to be a big concern for for this quarter in terms of questions?
>> Um, a big concern, I don't know. It's definitely real. I mean, Bur's not wrong and and I don't think to anyone that's been looking in the space that's that that's even a new subject at all. Um, depreciation is something that that you know, they could put many more years out than potentially what those chips are actually going to live through. But um I think if you are in that space, you just you have a little bit of caution whenever their numbers are much higher than maybe you would suspect versus their competitors. And uh you add a little conservatism for the companies that are putting their depreciation of their chips at really really low levels like you know 3 years or something. It's almost like a benefit knowing that it might actually be a lot better than that. And I would say Jensen has really done I mean in prior discussions with uh Jensen has mentioned that he directly tells his customers don't use all your money for one generation because the next generation is going to be better and the generation after that is going to be better. U Microsoft CEO was recently at uh uh with Dylan Patel in an interview and he mentioned that there was a slowdown in Microsoft's capex last year but it wasn't for any risk demand um happening. what they just didn't want is to have massive clusters of the hopper uh generation because they were on it to get the black walls. They wanted to get the Reuben and so on and so forth. And he even mentions that Jensen tells them to do that as well. So Jensen controls some of these companies would open wallet to Jensen and Jensen would say you could do that but I would recommend this instead. um which what other business is out there kind of telling their customers, you know, you can buy everything you want, but I recommend you slow it down and purchase over time instead.
>> It's a fair point. It is a very fair point and I think Jensen will address this depreciation issue head on today as well. Uh we got the call in about 12 minutes. Let's get a little more coverage then we will get into the call.
>> See more Tim, it's great to have you back on.
>> Great to be here Morgan. Thank you.
>> All right. What are your thoughts?
>> I think, you know, so much for not wanting to see AI spend and so much for people actually getting that chance to buy Invidia on a dip. I think there's a lot of disappointed people. The fact of the matter is GTC told us we were going to be north of 500 billion in terms of where they're going to be on 26 for for Blackwell and Reuben. The dynamic on the gross margins was where you wanted it. Uh I like Nvidia here. I like it not only because it's 29 times forward, but because I think actually you you you actually took a lot of that fast money out of this, pardon the the fast money environment that we're in, where of course everybody wants more fast money. But other than that, I I really thought these numbers were were strong. Let's see where we kind of settle in. I mean, this this uh this reaction is probably even a little bit more muted considering this was supposed to be the Super Bowl. Uh but they hit the numbers that we kind of knew they were going to hit. Yeah, I want to go back to the valuation here because you just touched on it, especially after the stocks sold off uh over the last couple weeks, trading at 29 times forward earnings. That's actually below the 10-year average of 35 times. It's also a slight premium to NASDAQ 100's mult multiple of roughly 26 times, but of course, most companies are not growing the way Nvidia is.
>> No. and and of all the the the hype around the circular AI trades, the fact that Nvidia has positioned itself as an AI infrastructure company in addition to everything else is is probably more hype for everybody else than it is Nvidia. In other words, this to me, I know this is absurd, but it's almost the least hyped stock out there because in fact, they're delivering because they are growing and because you you you mentioned that valuation which I mentioned, which is that this is not a case where you've got a company that that I think is is at least priced in extraordinary growth. They priced in what they're doing.
>> Uh Tim, what do you make of the after hours action here in overtime with some of these other AI related stocks popping a bit? Is this just a a brief short squeeze across AI and some risk? I see Bitcoin back above 90K here in overtime or is this the start perhaps of the risk on trade getting fresh legs? Well, I you know, tactically going into a short holiday week and where we've come and and maybe a sense that you get some some some payroll data tomorrow that's old, but maybe gives you some sense of, you know, the Fed being actually maybe not as hawkish as they've sounded this week and as they've sounded over the last 10 days. I I think you've put some more discernment into the stock picking across the AI space. So, I don't think that Micron should trade where it does. I do think that, you know, memory and some of the dynamics around the trade that have gotten overly frothy should get shaken out a little bit more. I think the stronger hands are going to be there. I think people are still concerned about how much money met Meta spending. Uh I do think there are opportunities to pick up some of these big companies. Look, if you look across the Mag 7, half of these stocks are now down on the year or flat.
>> All right. Well, Tim, thank you. when you can
>> the fun thing about these stocks being down on the earth flat like a meta is that when Nvidia has this type of an earnings you would imagine that the reason these companies are continuing to spend is because they see the ROI so even if there are concerns about capex or where the ROI is coming from you know you got to trust that Zucks and other people will figure it out and is that the case those are bias
>> if if I could quickly touch on what he said he said uh is this just hype and he said this might be the least hyped stock it's completely True. If you were to take out what AI spend and all this stuff, if you were to just say, "Hey, there's a company trading at this multiple growing at, you know, near 60 plus% growth rates. Margins on on net income are staying high. Free cash flow margins staying quite high. I think like 38% something like this this quarter. Like total outstanding shares are going down. So, they're not diluting to find this growth." If you were to pitch that to someone not knowing the name of the company, that is not hype. The the multiple is not meeting up to what we're seeing fundamentally. So there is some concerns that okay, you know, the infrastructure, this is not uh recurring revenue or annual recurring revenue. Obviously, there's talk about the the maintenance and stuff like this, but there are some concerns that maybe there's going to be a breakthrough or some other customer or custom silicon that will end up beating Nvidia in the future. But that is speculation. The numbers we're actually seeing and the numbers they're putting up is the opposite of hype. That's reality. Okay. And it's looking unbelievable right now. Yeah. I'm happy.
>> It's a strange It's a strange bubble, right? When you see these types of numbers.
>> Yeah. Was uh Cisco doing this in the dot bubble? Were they putting up $32 billion of net income at a 56% net income margin? I'm curious.
>> Also, Cisco got to 185 times earnings. The Nvidia's got to is like 60. So,
>> by the way, they've held up that 56% margin for eight quarters in a row essentially.
>> Like, is this a flash in the pan or are we seeing something like a like a true buildout here?
>> Yeah. Uh, some questions from the chat. People are saying, "Do you think Nvidia will add Bitcoin to the balance sheet?" I don't think Nvidia cares about Bitcoin. Um, I don't think they hate Bitcoin or anything like that. I don't even think Jensen would be opposed to it. I just think they have to put a lot more money into the AI ecosystem and they probably don't want to have the volatility of Bitcoin on the balance sheet.
>> I I think you're going to see a lot more uh either private equity or other tech names show up um of of the things that they're actually accumulating with their cash. I think you're going to see a real venture arm from Nvidia. I mean, a big one. And this is if you guys think this is secular sickular financing, I can't say that. We're I honestly think we're just at the beginning.
>> Sick dealer.
>> Circular finance. I can't say circular.
>> No, I can say circular, but circular that is continual. How do you say that?
>> There's a word for that. Maybe I'm making up a word.
>> Circular financing.
>> Maybe I made up a word.
>> I heard. I was like, "Okay, sick dealer." All right.
>> Say, "Oh, cyclical. Is that what you're trying to say?"
>> No, no, no, no.
>> I made up a word, I think. Maybe. But I was thinking circular continually. Okay, we're done. Um,
>> circularity. Okay. But all I'm saying is it will continue that that this is going to continue. They are going to invest in companies that buy Nvidia chips and then those companies hopefully do well. Their equity rises as uh as the market sees the products that they're making are real and then they go and buy more Nvidia chips and and the cycle continues.
>> It is quite incredible.
>> Infinity loop.
>> Yeah. Yeah.
>> Uh falling knife. Thank you for the $200 super chat. Nvidia today at least was not the falling knife. So, thank you for their super chat. Deeply, deeply appreciated. Doug, thank you for the $10 super chat. Chatbots are like tnet and the image and video creation are just like the invention of the GIF format for Usenet boards, ancient internet technology. We are so early. That does feel like it's very true. I mean, the chat bots are the worst they're ever going to be. As Tanner was mentioning, the the the video generation models only being six to eight seconds. It's going to be six to eight hours one day. And every single application in our lives, whether it's in corporate or personal daily use, it's going to be impacted by AI. Which is why, you know, when the bubble concerns pop up, it's it's very annoying to a lot of people because it's like, I'm not going to completely dismiss that there are arguments around circular financing and all this other stuff, these are things to be healthily skeptical of. But I'm using this thing every day. I can't imagine a world without Grock. And so if that's the case in our personal lives, you know, you could imagine 10 years from now, that's only going to get more important, which means Nvidia likely is more valuable than than it is. And one thing that we saw Enthropic, I think about a week ago, mentioned the uh uh they stop they were stopping cyber security attacks with their agents. I mean, is it impossible to think in a world where countries and companies just have compute available to be running these form of cyber defense agents to make sure that they're not getting attacked by some other entity that's using AI to attack them? Uh um attack them, right? So, it's like the random market opportunities here are insane for AI. And like you mentioned, we're still just in the Hello, can you draw me a picture of a cat riding a dragon um with a sword or something like that,
>> which which Go ahead, Tanner.
>> No, I was just going to say I've absolutely killed the chat and I'm so sorry. Uh it's just I don't know what I was thinking, honestly. Circular.
>> You should You should ask Gemini what word you're trying to come up with.
>> It's just going to call me an idiot. I'm going to stick to uh investing and you know, you can have the words of the day at the end. I'm I'm I'm done.
>> Well, that's the good thing about these AI models. They're really supportive. Like last Friday, I like I haven't had like a real hourlong conversation with an LLM in a while. It's been a few months. I was asking something about taxes. I was going back and forth with Grock like and it was so supportive. It was like, "Don't worry, Emit. This is you're not necessarily correct here, but here." I was like, "Wow." Like it was so nice and I really learned a lot and it made me like, "Oh, this is why I pay 50 bucks a month for this thing." You know,
>> you're talking,
>> don't worry, what you're doing is not insider trading.
>> Yeah, exactly. I mean, it's just like when you learn a new concept and you feel good about it after like going back and forth with super intelligence, you know, it just makes you feel more productive. And I think that applied 10x AC or 100x across the entire world, it's going to be a very very big world and very big opportunity. Okay, two minutes until we get this call. Uh, I'll put you guys on the spot spot right here. And same thing with the chat. Um, do we hold these levels after the call? What do you think? Do we hold the mid190s after the call?
>> I hope I know what hoping does, but I hope I I I think so. Yes or no? Take a stance.
>> Yes. Yes. Yes. Yes. This guy relax before I get grock on you. Uh, but yes. Tanner, you think you think we hold it?
>> Uh, I think we raise above it.
>> Okay, Neil.
>> Yeah, I continue with my bullish stance as from before. We We are green. We're green even tomorrow.
>> Yeah, I agree. I mean, look, if the numbers were kind of subpar, I would say maybe Jensen says something and, you know, things go back. I really think if he has a good quarter or a good answer to a lot of these questions,
>> the numbers.
>> Yeah, we know what's going to happen tomorrow. Tomorrow we're going to wake up to all these analysts upgrading their price targets. I mean, that's if if they were projecting lower revenue, it's the only thing they can do. Uh we updated the numbers cuz we were wrong and now we're going to increase our price target with this new uh projection.
>> That is a good point. uh now that you have these analyst updates coming into the uh print tomorrow, after the print tomorrow, I mean I mean you already have a couple that have already went to 300. It seems like you might get those remaining ones at least in the 250s which would be very exciting. Okay, I think we are starting. Here we go.
>> Conference operator today.
>> Good luck everyone.
>> At this time I would like to welcome everyone to Nvidia's third quarter earnings call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question and answer session. If you would like to ask a question during this time, simply press star followed by the number one on your telephone keypad. If you would like to withdraw your question, press star one again. Thank you. Soari, you may begin your conference.
>> Thank you. Good afternoon everyone and welcome to Nvidia's conference call for the third quarter of fiscal 2026. With me today from Nvidia are Jensen Wong, president and chief executive officer and Colette Crest, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on Nvidia's investor relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2026. The content of today's call is Nvidia's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release. our most recent forms 10K and 10Q and the reports that we may file on form 8K with the Securities and Exchange Commission. All our statements are made as of today, November 19th, 2025 based on information currently available to us except as required by law. We assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAP financial measures in our CFO commentary which is posted on our website. With that, let me turn the call over to Colette. Thank you, Toshia. We delivered another outstanding quarter with revenue of 57 billion, up 62% year-over-year and a record sequential revenue growth of 10 billion or 22%. Our customers continue to lean into three platform shifts, fueling exponential growth for accelerated computing, powerful AI models, and agentic applications. Yet, we are still in the early innings of these transitions that will impact our work across every industry. We currently have visibility to a half a trillion dollars in Blackwell and Reuben revenue from the start of this year through the end of calendar year 2026. By executing our annual product cadence and extending our performance leadership through full stack design, we believe NVIDIA will be the superior choice for the three to four trillion dollars in annual AI infrastructure build we estimate by the end of the decade. Demand for AI infrastructure continues to exceed our expectations. The clouds are sold out and our GPU installed base, both new and previous generations, including Blackwell, Hopper, and Ampear, is fully utilized. Record Q3 data center revenue of 51 billion increased 66% year-over-year, a significant feat at our scale. Compute grew 56% year-over-year, driven primarily by the GB300 ramp, while networking more than doubled given the onset of NVLink scale up and robust double-digit growth across Spectrum X Ethernet and Quantum X Infiniban. The world hyperscalers, a trillion dollar industry, are transforming search recommendations and content understanding from classical machine learning to generative AI. NVIDIA CUDA excels at both and is the ideal platform for this transition, driving infrastructure investment measured in hundreds of billions of dollars. At Meta, AI recommendation systems are delivering higher quality and more relevant content leading to more time spent on apps such as Facebook and threads. Analyst expectations for the top CSPs and hyperscalers in 2026 aggregate capex have continued to increase and now sit roughly at 600 billion more than 200 billion higher relative to the start of the year. We see the transition to accelerated computing and generative AI across current hypers scale workloads contributing toward roughly half of our long-term opportunity. Another growth pillar is the ongoing increase in compute span driven by foundation model builders such as entropic mrol openai reflection safe super intelligence thinking machines lab and xai all scaling compute aggressively to scale intelligence the three scaling laws pre-training post-raining and inference remain intact in fact we see a positive virtuous cycle emerging whereby the three scaling laws and access to compute are generating better intelligence and in turn increasing adoption and profits. OpenAI recently shared that their weekly user base has grown to 800 million. Enterprise customers has increased to 1 million and that their gross margins were healthy. Well, Anthropic recently reported that its annualized run rate revenue has reached 7 billion as of last month, up from 1 billion at the start of the year. We are also witnessing a proliferation of agentic AI across various industries and tasks. Companies such as cursor, Anthropic, Open Evidence, Epic, and Abridge are experiencing a surge in user growth as they supercharge the existing workforce, delivering unquestionable ROI for coders and health care professionals. The world's most important enterprise software platforms like Service Now, Crowdstikeke, and SAP are integrating NVIDIA's accelerated computing and AI stack. Our new partner, Palunteer, is supercharging the incredibly popular ontology platform with NVIDIA CUDA X libraries and AI models for the first time. Previously, like most enterprise software platforms, Ontology runs only on CPUs. Lowe's is leveraging the platform to build supply chain agility, reducing costs, and improving customer satisfaction. Enterprises broadly are leveraging AI to boost productivity, increase efficiency, and reduce cost. RBC is leveraging agentic AI to drive significant analyst productivity, slashing report generation time from hours to minutes. AI and digital twins are helping Unilver accelerate content creation by 2x and cut costs by five 50%. and Salesforce's engineering team has seen at least 30% productivity increase in new code development after adopting cursor. This past quarter, we announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs. This demand spans every market, CSPs, sovereigns, modern builders, enterprises, and supercomputing centers, and includes multiple landmark buildouts. XAI's Colossus 2, the world's first gigawatt scale data center, Lily's AI factory for drug discovery, the pharmaceutical industry's most powerful data center. And just today, AWS and Humane expanded their partnership, including the deployment of up to 150,000 AI accelerators, including our GB300, XAI, and Humane also announced a partnership in which the two will jointly develop a network of worldclass GPU data centers anchored by the flagship 500 megawatt facility. Blackwell gained further momentum in Q3 as GB300 crossed over GB 200 and contributed roughly 23 of the total Blackwell revenue of up to 150,000 AI accelerators including our GB300 XAI and Humane also announced a partnership in which the two will jointly develop a network of worldclass GPU data centers anchored by the flagship ship 500 megawatt facility. Blackwell gained further momentum in Q3 as GB300 crossed over GB200 and contributed roughly 2third of the total Blackwell revenue. The transition to GB300 has been seamless with production shipments to the majority to the major cloud service providers, hyperscalers and GP clouds and is already driving their growth. The Hopper platform in its 13th quarter since inception recorded approximately 2 billion in revenue in Q3. H20 sales were approximately 50 million. Sizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China. While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the US and China governments and will continue to advocate for America's ability to compete around the world. To establish a sustainable leadership and position in AI computing, America must win the support of every developer and be the platform of choice for every commercial business, including those in China. The Reuben platform is on track to ramp in the second half of 2026. Powered by seven chips, the Vera Rubin platform will once again deliver an Xfactor improvement in performance relative to Blackwell. We have received silicon back from our supply chain partners and are happy to report that Nvidia teams across the world are executing the bringup beautifully. Reuben is our third generation rack scale system substantially redefined the manufacturability while remaining compatible with Grace Blackwell. Our supply chain data center ecosystem and cloud partners have now mastered the build 2 installation process of NVIDIA's rack architecture. Our ecosystem will be ready for a fast Reuben ramp. Our annual X factor performance leap increases performance per dollar while driving down computing costs for our customers. The long useful life of Nvidia's CUDA GPUs is a significant TCO advantage over accelerators. CUDA's compatibility and our massive installed base extend the life Nvidia systems well beyond their original estimated useful life. For more than two decades, we have optimized the CUDA ecosystem, improving existing workloads, accelerating new ones, and increasing throughput with every software release. Most accelerators without CUDA and NVIDIA's time- tested and versatile architecture became obsolete within a few years as model technologies evolve. Thanks to CUDA, the A100 GPUs we shipped six years ago are still running at full utilization today, powered by vastly improved software stack. We have evolved over the past 25 years from a gaming GPU company to now an AI data center infrastructure company. Our ability to innovate across the CPU, the GPU, networking, and software, and ultimately drive down cost per token is unmatched across the industry. Our networking business, purpose-built for AI, and now the largest in the world, generated revenue of 8.2 two billion up 162% year-over-year with NVLink, Infiniban, and Spectrum X Ethernet all contributing to growth. We are winning in data center networking as the majority of AI deployments now include our switches with Ethernet GPU attach rates roughly on par with Infiniband. Meta, Microsoft, Oracle, and XAI are building gigawatt AI factories with Spectrum X Ethernet switches, and each will run its operating system of choice, highlighting the flexibility and openness of our platform. We recently introduced Spectrum Spectrum XGS, a scale across technology that enables gigascale AI factories. NVIDIA is the only company with AI scale up, scale out, and scale across platforms, reinforcing our unique position in the market as the AI infrastructure provider. Customer interest in Envy Link Fusion continues to grow. We announced a strategic collaboration with Pizutsu in October where we will integrate Pizitutsu's CPUs and Nvidia GPUs via Envy Lake Fusion connecting our large ecosystems. We also announced a collaboration with Intel to develop multiple generations of custom data center and PC products connecting Nvidia and Intel's ecosystems using NBLink. This week at supercomputing 25, ARM announced that it will be integrating NVLink IP for customers to build CPU SOC's that connect with Nvidia. Currently on its fifth generation, Envy Link is the only proven scaleup technology available on the market today. In the latest MLPF training results, Blackwell Ultra delivered 5x faster time to train than Hopper. NVIDIA swept every benchmark. Notably, NVIDIA is the only training platform to leverage FP4 while meeting the MLPF's strict accuracy standards. In semi analysis inference max benchmark, Blackwell achieved the highest performance and lowest total cost of ownership across every model and use case. Particularly important is Blackwell's Envy Link's performance on a mixture of experts, the architecture for the world's most popular reasoning models. On Deep Seek, R1 Blackwell delivered 10x higher performance per watt and 10x lower cost per token versus H200. A huge generational leap fueled by our extreme codeesign approach. NVIDIA Dynamo, an opensource low latency modular inference framework, has now been adopted by every major cloud service provider leveraging Dynamos enablement and disagregated inference. The resulting increase in performance of complex AI models such as models, AWS, Google Cloud, Microsoft Azure, and OCI have boosted AI inference performance for enterprise cloud customers. We are working on a strategic partnership with OpenAI focused on helping them build and deploy at least 10 gigawatts of AI data centers. In addition, we have the opportunity to invest in the company. We serve OpenAI through their cloud partners, Microsoft Azure, OCI, and Corweave. We will continue to do so for the foreseeable future. As they continue to scale, we are delighted to support the company to add selfbuild infrastructure, and we are working toward a definitive agreement and are excited to support OpenAI's growth. Yesterday we celebrated an announcement with Anthropic. For the first time, Anthropic is adopting Nvidia and we are establishing a deep technology partnership to support Anthropic's fast growth. We will collaborate to optimize anthropic models for CUDA and deliver the best possible performance, efficiency, and TCO. We will also optimize future NVIDIA architectures for enthropic workloads. Anthropic's compute commitment is initially including up to one gigawatt of compute capacity with Grace Blackwell and Vera Rubin Systems. Our strategic investments in anthropic mal openai reflection thinking machines and other represent partnerships that grow the NVIDIA CUDA AI ecosystem and enable every model to run optimally on NVIDIA's everywhere. We will continue to invest strategically while preserving our disciplined approach to cash flow management. Physical AI is already a multi-billion dollar business addressing a multi-trillion dollar opportunity and the next leg of growth for Nvidia. Leading US manufacturers and robotics innovators are leveraging NVIDIA's three computer architecture to train on NVIDIA. test on omnib computer and deploy realworld AI on Justin robotic computers. PTC and Seammens introduce new services that bring omniverse powered digital twin workflows to their extensive installed base of customers. Companies including Beldin, Caterpillar, Foxcon, Lucid Motors, Toyota, TSMC, and Wistron are building Omniverse digital twin factories to accelerate AIdriven manufacturing and automation. Agility Robotics, Amazon Robotics, Figure and Skilled at AI are building our platform tapping offerings such as NVIDIA Cosmos World Foundation models for development, Omniverse for simulation and validation and Jetson to power next generation intelligent robots. We remain focused on building resiliency and redundancy in our global supply chain. Last month, in partnership with TSMC, we celebrated the first Blackwell wafer produced on US soil. We will continue to work with Foxcon, Wistron, Amcor, Spill, and others to grow our presence in the US over the next four years. Gaming revenue was 4.3 billion, up 30% year-on-year, driven by strong demand as Blackwell momentum continued. End market sell-through remains robust and channel inventories are at normal levels heading into the holiday season. Steam recently broke its concurrent user record with 42 million gamers while thousands of fans packed the GeForce Gamer Festival in South Korea to celebrate 25 years of GeForce. NVIDIA Pro Visualization has evolved into computers for engineers and developers. Whether for graphics or for AI, professional visualization revenue was 760 million, up 56% year-over-year, was another record. Growth was driven by DGX Spark, the world's smallest AI supercomput built on a small configuration of Grace Blackwell. Automotive revenue was 592 million, up 32% year-over-year, primarily driven by self-driving solutions. We are partnering with Uber to scale the world's largest level 4 ready autonomous fleet built on the new Nvidia Hyperion L4 roboaxi reference architecture. Moving to the rest of the P&L, GAP gross margins were 73.4% and non-GAAP gross margins was 73.6% exceeding our outlook. Gross margins increased sequentially due to our data center mix, improved cycle time, and cost structure. GAP operating expenses were up 8% sequentially and up 11% on non-GAAP basis. The growth was was driven by infrastructure compute as well as higher compensation and benefits in engineering development costs. Non-GAAP effective tax rate for the third quarter was just over 17% higher than our guidance of 16.5% due to the strong US revenue. On our balance sheet, inventory grew 32% quarter-over-arter, while supply commitments increased 63% sequentially. We are preparing for significant growth ahead and feel good about our ability to execute against our opportunity set. Okay, let me turn to the outlook for the fourth quarter. Total revenue is expected to be 65 billion plus or minus 2%. At the midpoint, our outlook implies 14% sequential growth driven by continued momentum in the Blackwell architecture. Consistent with last quarter, we are not assuming any data center compute revenue from China. GAP and non-GAAP gross margins are expected to be 74.8% and 75% respectively, plus or minus 50 basis points. Looking ahead to fiscal year 2027, input costs are on the rise, but we are working to hold gross margins in the mid70s. GAAP and non-GAAP operating expenses are expected to be approximately 6.7 billion and 5 billion respectively. GAP and non-GAAP other income and expenses are expected to be an income of approximately 500 million excluding gains and losses from non-marketable and publicly held equity securities. Gap and non-GAAP taxes are expected to be 17% plus or minus 1% excluding any discrete items. At this time, let me turn the call over to Jensen for him to say a few words. Thanks, Colette. There's been a lot of talk about an AI bubble. From our vantage point, we see something very different. As a reminder, Nvidia is unlike any other accelerator. We excel at every phase of AI from pre-training and post-training to inference. And with our two decade investment in CUDA X acceleration libraries, we are also exceptional at science and engineering simulations, computer graphics, structured data processing to classical machine learning. The world is going is undergoing three massive platform shifts at once. The first time since the dawn of Moore's law, Nvidia is uniquely addressing each of the three transformations. The first transition is from CPU general purpose computing to GPU accelerated computing. As Moore's law slows, the world has a massive investment in nonAI software from data processing to science and engineering simulations representing hundreds of billions of dollars in compute cloud computing spend each year. Many of these applications which ran once exclusively on CPUs are now rapidly shifting to CUDA GPUs. Accelerated computing has reached a tipping point. Secondly, AI is also reached a tipping point and is transforming existing applications while enabling entirely new ones. For existing applications, generative AI is replacing classical machine learning in search ranking, recommener systems, ad targeting, click-through prediction to content moderation, the very foundations of hypers scale infrastructure. Meta's Gem, a foundation model for ad recommendations trained on largecale GPU clusters, exemplifies this shift. In Q2, Meta reported over a 5% increase in ad conversions on Instagram and 3% gain on Facebook feed driven by generative AI based gem. Transitioning to generative AI represents substantial revenue gains for hyperscalers. Now a new wave is rising. Agentic AI systems capable of reasoning, planning and using tools from coding assistants like cursor and quad code to radiology tools like ID do legal assistants like Harvey and AI chauffeers like Tesla FSD and Whimo. These systems mark the next frontier of computing. The fastest growing companies in the world today. Open AAI, Anthropic, XAI, Google, Cursor, Lovable, Replet, Cognition AI, Open Evidence, A Bridge, Tesla are pioneering agentic AI. So there are three massive platform shifts. The transition to accelerated computing is foundational and necessary, essential in a post Moors law era. The transition to generative AI is transformational and necessary, supercharging existing applications and business models. And the transition to agentic and physical AI will be revolutionary giving rise to new applications, companies, products and services. As you com as you consider infrastructure investments, consider these three fundamental dynamics. Each will contribute to infrastructure growth in the coming years. NVIDIA's chosen because our singular architecture enables all three transitions and does so for any form and modality of AI across all industries across every phase of AI across all of the diverse computing needs in a cloud and also from cloud to enterprise to robots one architecture. Toshia, back to you.
>> We will now open the call for questions. Operator, would you please pull for questions?
>> All right. Q& A.
>> Thank you. At this time, I would like to remind everyone in order to ask a question, press star, then the number one on your telephone keypad. We'll pause for just a moment to compile the Q&A roster. As a reminder, please limit yourself to one question. Thank you. Our first question comes from Joseph Moore with Morgan Stanley. Your line is open.
>> Great. Thank you. Um I wonder if you could update us. You talked about the 500 billion of revenue for Blackwell Plus Rubin in 25 and 26 uh at GTC. At that time you had talked about 150 billion of that already having been shipped. So, as the quarter is wrapped up, are those still kind of the general parameters that there's 350 billion in the next kind of, you know, 14 months or so? And, you know, I would assume over that time you haven't seen all the demand, but there is. There's any possibility of upside to those numbers as we move forward.
>> Yeah, thanks Joe. I'll start first um with a response here on that. Um, yes, that's correct. We are um working into our 500 billion uh forecast and we are on track for that as we have finished some of the quarters and now we have uh several quarters now in in front of us to take us through the end of calendar year 26. The number will grow and we will achieve I'm sure additional needs for compute um that will be shippable by uh fiscal year 26. So, we shipped 50 billion this quarter. Um, but we would be um uh not finished if we didn't say that we'll probably be taking more orders. For example, just even today, our announcements with uh KSA and that agreement in itself is 400 to 600,000 more GPUs over three years. Anthropic is also net new. So there's definitely an opportunity for us to have more on top of the 500 uh billion that we announced.
>> The next question comes from CJ Muse with Caner Fitzgerald. Your line is open.
>> Yeah, good afternoon. Thank you for taking the question. Um there's clearly a great deal of consternation around the magnitude of AI infrastructure buildouts and the ability to fund such plans and the ROI yet you know at the same time you're talking about being sold out every stood up GP is taken uh the AI world hasn't seen the enormous benefit yet you know from V300 never mind Ruben uh and Gemini 3 just announced Grock 5 coming soon uh and so the question is this when you look at that as the backdrop do you see a realistic path for supply to catch up with demand over the next 12 to 18 months or or do you think it can extend beyond that time frame?
>> Well, u as you know, we've we've done a really good job planning our supply chain. NVIDIA supply chain basically includes every technology company in the world and TSMC and their packaging and our memory vendors and memory partners and all of our system ODMs have done a really good job planning with us and we were planning for a big year. You know, we we've seen for some time the three transitions that I spoke about just just a second ago. accelerated computing from general purpose computing. And it's really important to recognize that AI is not just agentic AI, but generative AI is transforming the way that hyperscalers did the work that they used to do on CPUs. Generative AI made it possible for them to move search and recommener systems and you know add recommendations and targeting. All of that has been generated has been moved to generative AI and and it's still transitioning. And so whether you whether you uh installed Nvidia GPUs for data processing um or you did it for generative AI for your recommener system or you're building it for agentic chat bots and the type of AIs that most people see when they think about AI. um all of those applications are accelerated by Nvidia. And so when you when you look at the totality of the spend, it's really important to think about each one of those layers. They're all growing. They're related, but not the same. But the wonderful thing is that they all run on Nvidia GPUs simultaneously because the quality of the AI models are improving so incredibly. the adoption of it in the different use cases whether it's in uh code assistance which Nvidia uses fairly exhaustively and we're not the only one I mean the fastest growing application in history combination of cursor and quad code and code openai's codeex and and uh uh github copilot uh these applications are the fastest growing in history and uh it's not just used for software engineers it's used Why? Because of vibe coding, it's used by engineers and marketeteers all over companies, supply chain planners all over companies. And so I I think that that's just one example and the list goes on you know whether it's uh open evidence and the work that they do in health care or um the work that's uh being done in in digital video editing runway and I mean the number of really really exciting uh startups that are taking advantage of generative AI and agentic AI is growing quite rapidly and not to mention we're all using it a lot more and so all of these exponentials not to mention you know just today I was reading a text from from Demis and and he was saying that that pre-training and post-training are fully intact you know and Gemini 3 takes advantage of the scaling laws and got you know received a huge jump in quality performance model performance and so we're seeing all of these exponentials kind of running at the same time and uh and just just always go back to first principles and think about what's happening from each one of the dynamics that I mentioned for uh general purpose computing to accelerated computing, generative AI replacing classical machine learning and of course agentic AI which is a brand new category.
>> The next question comes from Vivc area with Bank of America Securities. Your line is open.
>> Uh thanks for taking my question. I'm curious what assumptions are you making on Nvidia content uh per gawatt uh in that 500 billion number because we have heard you know numbers as low as 25 billion per gawatt of content to as high as 30 or 40 billion per gawatt. Uh so I'm curious what power and what dollar per gigaw uh assumptions you are uh making as part of that uh 500 billion um number and then um longer term Jensen the the 3 to 4 trillion in data center by 2030 was mentioned how much of that do you think will require vendor financing and how much of that can be supported by cash flows of your uh large customers or governments or or enterprises? Thank you. Um in each generation from Ampier to Hopper uh from Hopper to Blackwell, Blackwell to Reubin we our our um a part of the data center uh increases and and um hopper generation was probably something along the lines of 20 some odd 20 to 25. uh Blackwell generation, Grace Blackwell particularly is probably 30 to 30 30 you know say 30 plus or minus and then Ruben is probably higher than that and and in each one of these generations the speed up is X factors and uh therefore their TCO the customer TCO um improves by X factors and the most important thing is in the end you still only have one gigawatt of power you know one gawatt data centers one gawatt of power and therefore performance per watt the efficiency of your architecture is incredibly important and the efficiency of your architecture can't be brute forced. There is no brute forcing about it. That one gigawatt translates directly your your performance per watt translates directly absolutely directly to your revenues which is the reason why choosing the right architecture matters so much. Now you know the world doesn't have an excess of anything to squander and so we have to be really really uh you know we we use this this concept called code design across our entire stack across the frameworks and models across the entire data center even power and cooling optimized across the entire supply chain and our ecosystem. And so each generation uh our economic contribution will be greater, our value delivered will be greater. But the most important thing is our energy efficiency per per watt is going to be extraordinary every single generation. With respect to growing uh into into um uh uh continuing to grow our customers our customers financing is up to them. uh we are we we see the opportunity to grow uh for quite some time and remember you know today most of the focus has been on the hyperscalers and one of the areas that is really misunderstood about the hyperscalers is that the investment on Nvidia GPUs not only improves their scale speed and cost for gen from general purpose computing that's number one because Moors law has mors law scaling has really slowed. Morse law is about driving cost down. It's about it's about deflationary cost the incredible deflationary cost of of computing over time but that has slowed. Therefore, a new approach is necessary for them to keep driving the cost down going to Nvidia GPU computing is really the the best way to do so. The second is revenue boosting in their current business models. You know, recommener systems drive the world's hyperscalers. Every single whether it's, you know, watching watching short form videos or recommending books or recommending the next item in your basket to recommending ads to recommending news to it's all about recommenders. The world has the internet has trillions of pieces of content. How could they possibly figure out what to put in front of you in your little tiny screen unless they have really sophisticated recommener systems to do so? Well, that has gone generative AI. So, the first two things that I just said, hundreds of billions of dollars of capex is going to have to be invested is fully cash flow funded. What is above it therefore is agentic AI. This is revenue is net new net new consumption but it's also net new applications and some of the applications I mentioned before but these are these new applications are also the fastest growing applications in history. Okay. So I I think that that um I you're going to see you're going to see that once people start to appreciate what is actually happening under you know under the water if you will uh you know from from the simplistic view of what's happening to uh capex investment recognizing there's these three dynamics and then lastly remember we were just talking about the American CSPs uh each country will fund their own infrastructure and uh you have multiple countries you have multiple industries indries um most of the world's industries haven't really engaged agentic AI yet and they're about to you know all the names of companies that that you know we're working with you know whether whether it's autonomous vehicle companies or uh digital twins for for physical AI for for factories and the number of factories and warehouses being built around the world um just the number of digital biology startups uh that are being funded so that we could accelerate drug discovery um all of those different industries are now getting engaged and they're going to do their own fundraising. And so don't just look at don't just look at the hyperscalers as a way to build out for the future. You got to look at the world. You got to look at all the different industries. And you know, enterprise computing is going to fund their own industry.
>> The next question comes from Ben Ritz with Melius. Your line is open.
>> Hey, thanks a lot. Um, Jensen, I wanted to ask you about cash. You know, speaking of half a trillion, you you may generate about a half a trillion in free cash flow over the next couple years. What are your plans for that cash? How much goes to buyback versus investing in the ecosystem? And how do you look at investing in the ecosystem? I think there's there's just a lot of confusion out there about uh how these how these deals work and your criteria for doing those like the anthropic the open eyes etc. Thanks a lot.
>> Yeah, I appreciate the question. Um, of course, uh, using cash to fund our growth. Uh, no company has grown at the scale that we're talking about and have the connection um and the depth and the breadth of supply chain that Nvidia has. Uh the reason why our our entire customer base can rely on us is because we've secured um a really, you know, really uh resilient supply chain and we have the balance sheet to support them. When we make purchases, uh our suppliers can take it to the bank. When we make when we make forecasts and we plan with them, they take us seriously because of our balance sheet. We're not we're not making up the offtake. We know what our offtake is and and because they've been planning with us for so many years. Um our reputation and our credibility is incredible. And so so uh it takes really strong balance sheet to do that to support the level of growth and the the rate of growth and the magnitude associated with that. So that's number one. The second thing, of course, we're going to continue to do stock buyback buybacks. We're going to continue to do that. But with respect to the investments, this is really really important work that we do. All of the investments that we've done so far, well, all the period uh is associated with expanding the reach of CUDA, expanding the ecosystem. If you look at the work that the investments that we did we did with OpenAI um it's of course that relationship we've had since 2016. I deliver the first AI supercomputer ever made to OpenAI and so we've had a close and wonderful relationship with OpenAI since then and everything that OpenAI does runs on Nvidia today. So all the clouds that they they deploy in whether it's training and inference runs uh Nvidia and we we love working with them. The partnership that that we have with them is one so that we could work even deeper from a technical perspective so that we could support their accelerated growth. Um, you know, this is a company that's growing incredibly fast and don't just look at don't just look at don't what is said in the press. Look at all the ecosystem partners and all the developers that are connected to OpenAI and they're all driving consumption of it. And the quality of the AI that's being produced, huge step up since a year ago. And so the quality of response is extraordinary. So we we invest in open AAI for a deep deep partnership in co-development to expand our ecosystem and support their growth. And of course rather than giving up a share of our company, we get a share of their company and we invested uh in them uh in one of the most consequential once in a generation companies once in a gener company that we have a share of and so I fully expect that investment to uh translate to extraordinary returns. Now in the case of Anthropic uh this is the first time that Anthropic will be on Nvidia's architecture. The first time Nvidia be Anthropic will be on Nvidia's architecture is the the second most successful AI um in the world uh in terms of total number of users but in enterprise they're doing incredibly well. Cloud code is doing incredibly well. Cloud is doing incredibly well all over the world's enterprise. And now we have the opportunity to have a deep partnership with them and bringing Claude onto the Nvidia platform. And so what do we have now? Nvidia's architecture, taking a step back, Nvidia's architecture, Nvidia's platform is the singular platform in the world that runs every AI model. We run OpenAI, we run Anthropic, we run XAI. because of our deep partnership with Elon and XAI, we were able to bring that opportunity to uh Saudi Arabia to the KSA so that Humane could also be uh hosting opportunity for XAI. We run XAI, we run we run Gemini, uh we run uh thinking machines, uh let's see, what else do we run? We run them all. Um and so not to mention we run the science models, the biology models, DNA models, gene models, chemical models, and all the different fields uh around the world. It's not just cognitive AI that the world uses. AI is impacting every single industry. And so we have the ability through the ecosystem investments that we make to partner with deeply partner on a technical basis with some of the best companies, most brilliant companies in the world. We're expanding the reach of our ecosystem and we're getting a share in investment in what will pro what will be a very successful company oftentimes once in a generation company. And so that basic that's our that's our investment thesis. The next question comes from Jim Schneider with Goldman Sachs. Your line is open. Good afternoon. Thanks for taking my question. In the past, you've talked about roughly 40% of your shipments tied to AI inference. I'm wondering as you look forward into next year, um, where do you expect that percentage could go in in say uh, a year's time? And can you maybe address the Reuben CPX product you expect to introduce next year and contextualize that? How big of the overall TAM you expect that can take and maybe talk about some of the target customer applications for that specific product. Thank you. uh CPX is designed for long context um uh type of uh workload generation and so long context basically before you start generating answers you have to read a lot basically you know long context and it could be a bunch of PDFs it could be watching a bunch of videos uh studying 3D images so on so forth you have to you have to absorb the context And so CPX is designed for long context type of uh workloads and and it's perf per dollars is perf per dollar is excellent. It's perfect for what is excellent and uh which made me forget the first part of the question.
>> Inferencing
>> oh inference yeah there are three scaling laws that are that are scaling at the same time. The first scaling law uh called pre-training continues to be very effective and um uh the second is post-raining. Post-training basically has found incredible algorithms for improving uh an AI's ability to break a problem down and solve a problem step by step. And post-training is scaling exponentially. Basically the more compute you apply to a model the smarter it is the more intelligent it is and then the third is inference. Uh inference because of chain of thought because of reasoning capabilities AIs are essentially uh reading thinking um before it answers and uh the amount of computation necessary as a result of those three things has gone completely exponential. I I think that that um it's hard to to know exactly what the percentage will be at any given point in time and who but of course our hope our hope is that inference is a very large part of the market because if inference is large then what it suggests is that people are using using it in more applications and they're using it more frequently and that's you know we should all hope for inference to be very large and this is where Grace Blackwell is just an order of magnitude better, more advanced than anything in the world. The second best platform is H200 and it's very clear now that GB300, GB2000 and GB300 because of MVLink 72, the scaleup network that we have um achieve and you saw and Colette talked about in the semi analysis benchmark. It's the largest single inference benchmark ever done and GB GB 2000 MVLink72 is 10 times 10 to 15 times higher performance and so that's a big step up. It's going to take a long time before somebody is able to take that on and and uh our leadership there is is surely multi-year. Yeah. And so so I think I'm hoping that inference becomes a very big deal. Our leadership in inference is extraordinary.
>> The next question comes from Timothy Aruri with UBS. Your line is open.
>> Thanks a lot. Um Jensen, many of your customers are pursuing behind the meter power, but um like what's the single biggest bottleneck that worries you that could constrain your growth? Is it power or maybe it's financing or maybe it's, you know, something else like memory or even foundry? Thanks a lot. Well, these are all issues and they're all constraints and the reason for that when you're growing at the rate that we are and the scale that we are, how could anything be easy. Um, what Nvidia is doing uh obviously has never been done before and we've created a whole new industry. On the one hand, we are transitioning uh computing from general purpose and classical or traditional computing to accelerated computing and AI. That's on the one hand. On the other hand, we created a whole new industry called AI factories. The idea that in order for software to run, you need these factories to generate it uh generate every single token instead of uh retrieving information that was uh pre pre-created. And so so I think this this whole this whole transition uh requires extraordinary scale and all the way from the supply chain of course the supply chain we have we have much better visibility and control over it because you know obviously we're incredibly good at managing our supply chain. We have great partners that we've worked with for 33 years. And so, so um uh the supply chain part of it, we're quite confident. Now, looking down our supply chain, uh we've now established partnerships with so many players in land and power and shell um and uh and of course financing. Um these things, none of these things are easy, but they're all tractable and they're all solvable things. And the most important thing that we have to do is do a good job planning. We plan up up the supply chain down the supply chain. Uh we have established a whole lot of partners and so we have a lot of routes to market and uh uh very you know very importantly our architecture has to deliver the best value to the customers that we have. And so I'm at at this point, you know, I'm I'm very confident that Nvidia's architecture is the best performance per TCL. It is the best performance per uh watt and therefore for any amount of energy that is delivered, our architecture will drive the most revenues. And I think the the inc the increasing rate of our success, I think that we're more successful this year at this point than we were last year at this point. You know, the the number of customers coming to us and the number of platforms coming to us after they've explored others is increasing, not decreasing. And so I think the the uh uh I think all of that is just you know all the things that I've been telling you uh over the years are really coming are coming true and or becoming becoming evident.
>> Next question comes from Stacy Rascin with Bernstein Research. Your line is open.
>> Questions. Colette, I had some questions on margins. You said for next year you're working to hold them in the mid70s. So I I guess first of all, what are the biggest uh cost increases? Is is it just memory or is it something else? What are you doing uh to work toward that? Is it how much is like you know cost optimizations versus pre-byss versus pricing? And then also how should we think about opex growth next year given the revenues seem likely to to grow materially um from from where we're running right now? Thanks Stacy. Let me see if I can uh start with uh remembering where we were with the current fiscal year that we're in. Remember earlier this year we indicated that through cost improvements and mix that we would exit the year and our gross margins in the married 70s. We achieved that and getting ready to also execute that in Q4. So now it's time for us to communicate where are we working right now in terms of next year. next year. There are input in input prices uh that are um well known um in the industries that we need to work through and our systems are by no means very uh easy to work with. There are are tremendous amount of components, many different parts of it as we think about that. So, we're taking all of that into account. But we do believe as if we look at working again on cost improvement, cycle time and mix uh that we will work to try and hold at our gross margins in the mid uh seven days. So that's our um overall plan for gross margin. Your second question is around opex. And right now our goal in terms of opex is to really make sure that we are innovating with our engineering teams with all of our business teams uh to create more and more systems for this market. As you know right now we have a new architecture coming out and that means they are quite busy in order to meet that goal. And so we're going to continue to see our investments on innovating more and more both our software, both our systems and our hardware to do so. I'll leave it turn it to Jensen if he wants to add in a couple more comments.
>> Yeah, I think that's spot on. I think the only thing I would add is is remember that we plan, we forecast, we plan, and we negotiate with our supply chain uh well in advance. uh our supply chain have known for quite a long time our requirements and they've known for quite a long time our demand and we've been working with them and negotiating with them for quite a long time and so so I think the the recent surge um obviously quite significant um but remember our supply chain has been working with us for a very long time and so so in many cases we've secured a lot a lot of supply for ourselves um because you know obviously they're working with the largest company in the world in doing so and and um and we've also we've also um been been working closely with them on the financial aspects of it and and securing forecasts and plans and so on so forth. So I think all of that has worked out well for us.
>> Your final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.
>> Yeah, thanks uh for taking the question. Um, Jensen, the question's for you. You know, as you think about the enthropic uh deal that was announced and and just the overall breath of your customers, I'm curious if your thoughts around the role that AI A6 or dedicated XPUs uh play in these architecture buildouts that has changed at all. Have you seen, you know, I think you've been fairly adamant in the past that that some of these some of these programs never really see deployment, but I'm I'm curious if if we're at a point where maybe maybe that's even changed more in favor of of just GPU architecture. Thank you.
>> Yeah, thank you very much. And I re I really appreciate the question. So, first of all, um you're not competing against teams. You're excuse me against a company. You're competing against teams. And there are there just aren't that many teams in the world who are built who are extraordinary at building these incredibly complicated things. You know, back in the Hopper day and the Ampear days, we would build one GPU. That's the definition of an accelerated AI system. But today, we've got to build entire racks, entire, you know, three different types of switches. A scale up, a scale out, and a scale across switch. And it takes a lot more than one chip to build a compute node anymore. Everything about that computing system because AI needs to have memory. AI didn't used to have memory at all. Now it has to remember things. The amount of memory and context it has is gigantic. The memory the memory architecture implications incredible. The diversity of models from mixture of experts to dense models to diffusion models to auto reggressive not to mention you know biological models that obeys the laws of physics. The the list of the list of different types of models has exploded in the last last several years. And so so the challenge the challenge is the complexity of the problem is much higher. The diversity of AI models is incredibly incredibly large. And so this is where you know if I will say the five things that makes us special if you will you know the first thing I would say that makes us special is that we accelerate every phase of that transition. That's the first phase that CUDA allows us to have CUDA X for transitioning from general purpose accelerated computing. We are incredibly good at generative AI. We're incredibly good at agentic AI. So every single phase of that every single layer of that transition we are excellent at. You can invest in one architecture use it across the board. You can use what one architecture and uh not worry about uh the the changes in the workload across those three phases. That's number one. Number two, we're excellent at every phase of AI. Everybody's always known that we're incredibly good at pre-training. We're obviously very good at post- training and we're incredibly good, as it turns out, at inference because inference is really, really hard. How could thinking be easy? You know, people think that inference is one shot and therefore it's easy. Anybody could approach the market that way, but it turns out to be the hardest of all because thinking, as it turns out, is quite hard. We're great at every phase of AI. The second thing, the third thing is we're now the only architecture in the world that runs every AI model, every frontier AI model. We run uh open- source AI models incredibly well. We run science models, biology models, robotics models. We run every single model. We're the only architecture in the world that can claim that. It doesn't matter whether you're auto reggressive or diffusion based. We run everything and we run it for every major platform as I just mentioned. So we run every model. And then the the fourth thing I would say is that we're in every cloud. The reason why developers love us is because we're literally everywhere. We're in every cloud. We're in every you know we could even make you a little tiny cloud called DGX Spark. And so we're in every computer. We're everywhere from cloud to onrem uh to robotic systems, edge devices, PCs, you name it. one architecture, things just work. It's incredible. And then the the last thing, and this is probably the most important thing, the fifth thing is if you are a cloud service provider, um if you're a new company like Humane, if you're a new company like Core Wee or Nscale or Nebius, um or OCI for that matter, the reason why Nvidia is the best platform for you is because our offtake is so diverse. We can help you with offtake. It's not about just putting a random ASIC into a into a data center. Where's the offtake coming from? Where's the diversity coming from? Where's the resilience coming from? The you know the versatility of the architecture coming from the diversity of capability coming from Nvidia has such incredibly good offtake because our ecosystem is so large. So these five things, every phase of acceleration and transition, every phase of AI, every model, every cloud to onrem and of course finally all leads to offtake.
>> Thank you. I will now turn the call to Toshihari for closing remarks. In closing, please note we will be at the UBS Global Technology and AI conference on December 2nd and our earnings call to discuss the results of our fourth quarter of fiscal 2026 is scheduled for February 25th. Thank you for joining us today. Operator, please go ahead and close the call.
>> All right, Nvidia Q3 2025, that was the call. We got a lot of quotes from Jensen. A lot of questions that I think people had have been answered to an extent. Jose, I'll give it to you. Raw thoughts on that call.
>> Um, call was good. Like you mentioned, uh, a lot of questions were were answered. Some of them, I have a few notes. I'm just going to go through them really quickly. What I found pretty interesting. Um, clouds are sold out for Blackwell Hopper. And he even mentioned his Ampere. Ampier is a GPU that was is was made six years ago. So it kind of just showcases that GPU depreciation of three years just doesn't make sense. They they gave a perfect example of a GPU that's 6 years old. Um they mentioned the GB300 which is the Blackwell three uh Blackwell Ultra is now 2/3 of the Blackwell revenue. Um which was also crucial because that just came out. So that ramped up pretty insane for them. Uh so the ramp up process of of their supply chain is pretty impressive. Um what else did I I saw? You had mentioned Ruben was doing good in forms of of the design and everything. So nothing like nothing that should scare us off schedule. Um and I'll pass it over. But the last one was that $500 billion number that they gave. There's upside to it, right? They the anthropic wasn't included into that. The new I I think you just posted on X uh some of the chips can be sent to to the Middle East. Now that wasn't included in that $500 billion number. So now that's net new numbers added to to to that. So uh I wouldn't say those were probably some of my my my um my favorite points. Um and I'll pass it over to to someone else though.
>> Tanner, your thoughts on the call?
>> Uh yeah, it was good. I think too many people paid attention to the stock price during the call. um
>> whenever really they were just talking about, you know, some of the comments that Jensen made just about like, you know, how hard it is to continue to grow at this level at our size. Like it's never been done before. They're solving problems that have never ever been done before. Um I mean, the way that he started the call was extremely strong. The way um yeah, I I don't know. I I'm I'm overall positive on it. Uh Jose said it pretty well. Um there was a comment made about the uh what what exactly their take is going to be on a per gigawatt data center and they said about 20 to$25 billion of that um is going to go for Hopper about we're at 30 plus for Grace Blackwell and Reuben is probably going to be even higher than that. Um, so I'm interested how you guys are thinking about that as well. But yeah, great call. Yeah, I agree. People were stressing that it went from 198 to 194. I mean, like again, I think that's like really missing the point of this quarter. Even if the stock goes down to 190 185 tomorrow, first of all, I think there's going to be a lot of dip buyers because again, you're going to get a stock that becomes incredibly cheap with the earnings growth. But number two, I think Jensen just saved the market. I don't know what happens with the Fed. I don't know what happens with rate cuts. But the entire market for the past three weeks was wondering. Every single segment on every financial news channel was are we in a bubble? I mean, there's still going to be those concerns, but I think Jensen just showed the numbers and the guidance that shows that there is so much demand for this to be a bubble. Every single supply chain partner we work with, every single customer we work with, every single investment we're making, all of it would have to be go to zero. All of it would have to be fake. And reasonably that's probably not the case. And so having said that, I mean the stock price really is irrelevant here. The question is can they grow at the scale they're growing at as Tanner said and the fact that they are is why this is so exciting. Neil, your thoughts on the quarter and the call as well.
>> I mean again this seemed like a educational call from Jensen yet again to then explain what the heck is going on here. He they also started the call by explaining what other companies are already seeing, right? Meta was an example. They had some other companies out there that are already seeing some benefits from these AI investments. They talked about also expanding the CUDA ecosystem that I mean it is again a no-brainer. um some name drops right core rewec uh nebus but all all in all it's it's a $4.6 $6 trillion company that's growing 60% extremely profitable. Every other big tech company that has reported has be has basically beat estimates. Um they are all growing. They're all seeing some some positive returns already on their core business. Um the smaller companies, okay, the smaller companies are getting help from Nvidia. But again, why why not if it expands the ecosystem and if if that means that the ecosystem is healthier because imagine if these companies did not get or were not or Nvida did not invest in those companies then they would be probably raising debt at ridiculous levels. They could not repay it. They don't have the backing of the Nvidas, the Microsoft, the Amazons, you name it. I would rather be in the situation that we're in right now than if there was no Nvidia. That was let's say the the sugar daddy, let's call it. And so again, this is a quarter where Jensen is explaining the thesis yet again to analysts that for some strange reason still have not figured out what's going on. Three years ago, Chad GPT came out and I don't know why we think that three years later it's over. I mean, literally three years ago, Chad GPT came out. You're going to tell me that it's over today already? It It doesn't make any sense. It doesn't make any sense. either every big tech CEO that has built hundreds of billions of dollars in in market value, every or not every but a lot of countries leaderships. All of those people are a bunch of idiots and then there are a select few that are geniuses that think that this is a bubble that nothing makes sense. I don't know. I rather go with the folks that have built huge companies, huge I mean products, services for this for the whole planet than side with the folks that have probably been screaming bubble and market crash and correction and overvaluation for the last 5 10 years or so. It could I add on really quick to what Neil said there? Um, you know, there I did feel like he was defending not only Nvidia but the industry itself. He talked about Meta, you know, seeing a 5% jump up in uh Instagram ad conversions and 3% gains on on Facebook and stuff. And I feel like he almost needs them to carry a good multiple so then their boards, their their investors are not screaming for them to cut on uh capex spend to try to just save the stock, right? He he almost needs all of their customers and and investors around the world to believe and I don't mean this in a negative way, but to believe in the narrative like like not only do they need to see that it's real, but it is real, but they also need the the multiples on those stocks to to to line up with that growth as well. I would agree. I think the point you're making about the defense of the industry 1,00%. He mentioned OpenAI a good chunk of times along with Anthropic um and at its core I mean these are major customers for Nvidia and they will continue to be major customers but he's got to make sure everyone believes that these are not house of cards open and cropic etc meta I mean he mentioned the recommener model so many times and so this call was a bit different than other calls where he mentioned many many different products in the AI life cycle I mean he always does that but this time I think there was a bit more of a focus on hey you could do this with AI you could do this with AI you can do this I Tesla, FSD, Whimo, so many things were mentioned. I think the one he mentioned the least was robotics this time. But all of those use cases, the market has to believe there is going to be a lot of potential, a lot of opportunity and a lot of chips that need to be bought to make those use cases reality. And as long as the market believes that and with the guidance, it's hard to say the market won't believe that. Nvidia stock should perform. And and and one thing that was pretty cool, I mean, you you reminded me when you talked about Enthropic was uh they mentioned that the number of platform wins has increased where back then people would be like, you know what, let me go try one of these ASIC chips instead. Let me go try maybe one of these players. And he's like, no, that's changing after they went to go try, they're coming back and doing it on our platform. He mentioned this is going to be the first time Anthropic is really going to be set on Nvidia GPUs. Back then, they used to be using Amazon's tranium and Google's TPU. So that is a great showcase of one of the leading players in the market and say, "Yeah, you know what? These A6 are pretty cool, but I I need more. I need more and I need to go jump into Nvidia because they're doing something better." Um if if I'm if I'm not necessarily jumping complete ship, but buying another ship to ride this wave as well.
>> Uh you you guys were highlighting something about um AMD. I had stepped away for a quick second. I didn't end up hearing what the comments were around some some people said shots fired in the chat and stuff. I didn't hear what was going on. Was that what it was about?
>> He basically said we are getting equity. We don't have to give up equity when we make deals with partners.
>> I mean it's it's a thousand% true. He is right. The deals were structured completely opposite. Um Nvidia got the better half. Oh, Thanksgiving dinner just got Jensen and Lisa Sue.
>> Dude, imagine like you know you know you know Thanksgiving is awkward if with your family politically. Imagine one's like all an AMD, you're all an Nvidia. Like
>> No, he means that Jensen and Lisa Sue are cousins or whatever.
>> No, I know. But still, it's funny.
>> Speaking of Thanksgiving, like I feel like at least in the States, Thanksgiving is going to be a little bit easier. Dude, it's not the most fun to eat turkey knowing you're down hundreds of thousands of dollars. Being up is a little makes the turkey a little better. So maybe Jensen did save Thanksgiving for us here.
>> Who needs Santa Claus when you have Jensen?
>> Who needs Santa Claus when you have Jen? No, but seriously, I mean the entire market after hours. He mentioned so many names. Gave us the core we've mentioned. Gave us the Nebus mentioned 103 on Nebius almost. Cory almost at 81. S&P is up a full 1% after hours. Said all the NEO clouds play a valuable role. Iran right there back above 50.
>> And and you know what's funny too is because they show off their numbers at 420. You know that this is not just like oh any old stock. It's specifically Nvidia. If you look at the spy and you look at the cues, they pop at 420. It is. And it's not something that is um uh like like a hidden knowledge. I mean, you could just look at the the waiting in the S&P 500, but it just goes to show you how unbelievably important this company is. It's the biggest company in the world. So, growing at 60%. Never ever has this been done before. Um, and an accelerated growth year-over-year. I mean, what market or macro data are we still expected to maybe get in the next two days that might ruin our uh party?
>> Well, we're not getting jobs GDP.
>> So, we're getting we're getting September data tomorrow. Uh the September jobs report, which is which is fine. Um markets don't care about that, though. They care about October. We're not getting October. BLS came out today and said we're not getting October. They did say we are going to get November, but it's going to be the day of FOMC. So we're which is December 10th. So we I mean to me it's kind of again it's kind of weird because if October date is bad like the administration is going to take a ego hit because like maybe we lost 100,000 jobs but JPAL will easily finally see it's time to cut rates. So it is kind of weird they're not releasing it. But nonetheless hopefully that rate cut probability does go higher. I think that's the only thing that can bring the Grinch back to town. This idea of a 32% chance of a rate cut is unacceptable. Absolutely unacceptable. And the fact that the Fed minutes today uh had many members, several members was the exact terminology, think that we aren't restrictive enough and the upside risk to inflation is higher and that we should keep the Fed rates unchanged. I mean, look, Nvidia's did a great quarter and maybe that's enough, but that is a concern. If we don't get a rate cut, I don't know how the market's going to be able to handle the end of the year, but at least the AI bubble trade narrative maybe dies down a little bit. And then if the Fed can just come through, you know, hopefully we get an end of year rally.
>> Also getting a new Fed chair announcement, right, in December,
>> correct? Which might get the market to not be so worried about what JPAL's going to do.
>> Yeah, because they're obviously going to be very dovish. Yeah, I think look, if you're investing in the stock market in this day and age, first of all, we're all, I think, incredibly lucky and privileged to be able to live in this time to see a company perform at this level, but at the same time, this company has to keep performing at this level. So, if you're in the markets, you're essentially, I mean, unless you're completely in defensives or stuff, if you are in anything that has any level of beta towards it, I mean, Robin Hood's up $7 because of Nvidia earnings, right? like like pounders back at 17 like all of this is due to this company. So really it's a bet on Nvidia and hopefully the rate cuts and inflation stuff works itself out over the next year but they've got to keep executing and on this quarter it looks like they show that they will continue to execute.
>> All right.
>> Yep.
>> That's it. Exciting exciting stuff. Congratulations to everybody. Looks like Jensen was our Santa Claus and came to town. Any last words, Jose?
>> Uh, just no pizza for dinner today. Definitely getting something better.
>> Neil,
>> and be prepared for the upgrades tomorrow. I'm pretty sure we're going to see tons of it.
>> Oh, yeah. That's for sure.
>> Uh, Neil, any last words?
>> Um, no, happy happy to see some green. I mean, uh, it's been it's been a while. Although, okay, I know we we've been green for six months in a row. I know, I know, I know. But I mean for the last 3 weeks it's been heavy heavily red. So it's good to see some green right now. Um I know people are I mean for sure more happy when we see green markets than when we see red. But it does it does give us opportunities and some healthy pullbacks are are always fine. Uh as as long as the companies perform which I think for the last month and a half this earning season we have seen the big companies do exactly what they should be doing. Even the fintech players, I mean, SoFi has done very well, so I'm happy. I um I I don't want to go on a tangent, so I'll keep it as short as I can, but I don't know if the whole market is hanging on Nvidia as much as they're all hanging on the productivity gains from artificial intelligence. Um so so you you need to see what
>> the main companies are doing the chat GPTs the Geminis the metas etc and and that should set the course of how bullish the market is Nvidia is a you know a secondary effect of how good those models are if if we're seeing real productivity and real use cases out of them then more chips need to be purchased um so essentially I think the market is hung up not on Nvidia but artificial intelligence being the most productive asset or or new technology breakthrough that we've ever seen in our lifetime. So, um until that changes, until you know Gemini 4 does not put out new benchmarks or something along these lines, I continue to be extremely bullish and um yeah. Yeah, that's it.
>> Love it. Thank you everybody for spending your time with us. We deeply deeply appreciate it. Uh it means a lot for people to spend their time with us every single quarter. And uh we'll be here February 25th for Q4 earnings for Nvidia and we'll keep going from there. Thank you everybody. Have a good night.