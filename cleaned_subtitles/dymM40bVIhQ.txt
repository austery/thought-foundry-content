反正现在我没有access了 所以也算自由了 想干什么干什么了 我是在准备访谈的时候 才发现你在Meta已经工作10年了 对对 那个时候2015年 很小的公司 2012年上市的 对 你加入的时候Meta多少人 加入的时候 大概有1万多一点 也不小了 不是特别小 但对比现在可能几十万 我们是沿着原来的访谈大纲 去聊你的论文 然后我们address一下这个new development的问题 也行 我们就可以聊一些论文 我觉得这个还是比较好 因为我其实并不想说太多裁员的事情 我也觉得这个不太好 推特上就发了一个帖子 那么多人点赞 小红书上也是 刷到你的名字 这一天刷了好多 其实我这边本意 因为我这边team也有几个人 被影响到了 所以我当然希望他们有更好的机会 因为我无所谓 我最惨 我在家里待着 但是他们很多人身份会有一些问题 如果不能及时找到下一家的话 想办法帮忙找一找 因为我毕竟认识的人比较多 这个也是我的本意 我反正不怕暴露自己被裁 I don't care 但是希望我的下属那些人 能很快找到工作 这也是我的本意 我觉得是这样 不要聊你们在公司的问题 我觉得我已经说够多了 我不想再说了 我一般不太愿意说这些 我觉得我在Twitter上唯一说的是 因为有人跳出来说 你们被裁是应该的 因为东西没做出来 那我要至少给我们的team澄清 对吧 因为我们team做了很多重要工作 你不能把锅扣到我们头上 所以这个肯定是要讲清楚 但是我现在就比较defensive 如果有人说这个是我们的锅 那我会说回去 除此之外 我不会说太多公司内部的事情 那你还有没有什么想澄清的 你觉得没有澄清好的 哈哈 我觉得差不多了 就这样 我觉得 我们其实还是做了很多的工作 把很多之前的一些问题解决了 比如说 包括long context的reinforcement learning 有没有训练得好 还有包括前面的pretraining model 他们的design其实可能有些问题 像有sparse attention的问题 这个其实很多是我们团队解决的 我先发现的 问你这个design有问题 然后去跟他们讲 但是一开始很难 他们不一定听你们 我当时去的时候 相当于一个research team过来的 对方是做大模型的 我这边research team过来的话 他们不一定会听 他们可能会觉得这个事情没问题 肯定是对的 我们这边要用各种实验去证明 我们之前的那些发现 或者说那些insights是对的 后来他们是被说服了 所以他们才会发现这里有问题 这个其实都是我们团队的贡献 还包括 怎么样去让long context的reinforcement learning更加稳定 包括有很多blew up的问题 怎么样去解决 这些东西都是我们这边做的 但这些东西也就属于幕后英雄 毕竟最终我们这个模型 也没有真正official release 至少我们有一些贡献在里面 这个我得说 说出来 至少为后面的人添砖加瓦 做一个比较好的base 就是这样子 我倒有两个问题了 第一 你们作为一个research团队 人家不信你 可能是觉得 你之前没有这个训练大模型的经验 或者怎样 但是你们能很快发现问题 你觉得为什么可以做到 第二个就是 对面那个大模型团队 是个什么样的团队 他们自己本身大模型训练经历丰富吗 他们训练是经验丰富的 那他们有一些 之前的实验有bug 嗯 这个bug导致他们做出错的判断 但是我们这边虽然说没有训练模型 但你毕竟是做过大模型的 有些文章 对吧 包括我以前 做过sparse attention 稀疏的注意力 那我当然对注意力结构 我知道什么意思 怎么回事 那我当然一看这个设计 我知道有问题 这个我相信很多人都能看出来 这个并不是说我能看出来 你肯定能看出来 但我并不知道 当时这个决定怎么做 但是我愿意说 但是没办法 因为其实也很难说服他们 就是 你要花很多时间和精力去跟他们说服 这个是有问题 后来他们自己团队发现了 也是有这个问题 慢慢就会改变这个想法 虽然说研究员 可能我们当时做研究的时候 并没有直接去接触超大模型训练 但是研究的这些直觉 或者说这些经验其实很有用 对吧 它能够很快能够找到问题 能够发现什么地方是有问题 是有出错的 怎么样去解决 我觉得这个是很重要的 这个是作为一个研究员的宝贵财富 说实在的 你如果是一个 完全没有任何insights的人 OK 我天天就跑实验 然后调参数 这个工作其实你说你能做 别人也能做 对吧 那研究员的优势是说 我能不能 根据一些非常稀疏的数据点 能够得到非常重要的结论 这结论能够推广到难的问题上 这个是研究员能力 你说的稀疏的数据点 是不同论文和不同实验的结果 对 就比如说 我如果是个新来的菜鸟 那么对我来说OK 我的任务是调参数 跑程序 比如我跑1万个点 我就得到1万个点的参数的值 然后我就说 我告诉大家这1万个点是我跑的 跑完之后跟大家说OK 跑完了 这个是我的结论 但是跑完之后这1万点就在那边 是死的 你也没有什么insights 没有什么概念 说 这1万点其实代表了后面什么意思 有什么样的结构 那这个 其实只有那些有经验的人才能看到 有经验的人可能看到20个点 我就知道有什么问题 甚至说看10个点 看到 这个training curve刚刚训练了一半 哦 我知道不行了 不要跑下去 可能你这里有问题 这个其实是为什么 AI的研究还是薪资比较高 我觉得很多时候是这样 你的一个insight可以抵 比如说100块卡 或者说抵1000块卡 （还是）多少张卡 我不需要那么多卡 但是我还是有insights 可以得到一些比较好的结论 这个是重要的 你刚才用了两个词 一个是经验 一个是insights 然后我想double click一下 这个到底是个什么东西 有的人会觉得这是一个taste 有的人会觉得是个intuition 我们有好多词去形容这个东西 那你觉得这个东西到底是什么 刚刚已经有四个词了 对吧 四个词说的好像都是一件事 那你能不能给大家讲一讲 从你的经验来说 你用多长时间能判断一个人有这个 还是没有这个 你觉得它有的话 它除了像你刚刚说的 从很小的数据点 就能得出来一个更正确的结论 还有什么展现 以及怎么得到这个东西 我觉得是这样 insights 是一个很难描述的概念 特别是一个有经验的人 比如说在某方面他是个老师傅 那么他怎么做 他要根据很少的数据 然后判断 这个现象背后的真正原因是什么 这个是重要的 比如说一个修车师傅 他可能根据蛛丝马迹 会知道你车哪里坏了 明白 你还没有反应过来 说这个事情就坏了 或者说一个交易员 我做股票交易的 我说我根据这两个迹象 或者看看财报 嗯 所以这种东西是很重要 他讲不清楚到底怎么回事 但他就有种感觉说 这个不行 那个行 有一个mental model 这个mental model大概率是对的 这个其实很重要 有这些东西之后 其实很快能够发现问题在哪 然后有这问题 我们怎么样去解决这个问题 然后往这个方向去走 这个可能比GPU还要重要 当然GPU也很重要 有GPU之后 你会做更多实验 获得更多的insights 这两个是相辅相成的 应该这么说 你能很快判断另外一个人 有没有一个好的mental model吗 这个其实是有一些办法 就是说你是要跟别人聊 大概聊一下 感觉一下他平时对这问题怎么想的 我觉得这个其实挺重要的 其实我可以举个例子 比如说学校里面有这种 PhD exam PhD qualifier 一个学生坐在自己老师面前 然后老师问他 请问你对这个问题有什么了解 比如说我们讨论一些学术问题 对这个老师来说 他想办法问到底 比如说 你对这个偏微分方程有什么想法 你有什么一二三四五这些经验 然后就是抓住一个点 然后使劲问 你就知道他到底懂不懂了 他到底知道这里面之间什么关系 能用最简单的语言讲清楚 对 然后就能够知道 最重要的两个东西的关联是什么 这样的话 就知道他真是懂的 或者说他真的是知道最关键的 关联在哪里 可以用这关联去做更多的推广 这个是重要的 像比如做研究的话 比较忌讳的是说 我就只懂书面知识 一二三四五 背出来了 但是他们有什么关系 什么时候他们两个成立 他们俩不能成立 什么时候imply B 什么时候imply C 这个并不知道的话 其实是比较难搞的 我觉得这个是一个问题 其实这个很重要 说实在的 是我觉得现在的模型做不到的地方 现在模型可能没有办法 用很少的数据 真的去预测将来的结果 那我们就直接到这个话题吧 你的论文是Grokking 但是它是一个底层的 这么一个 在一个时间点 它有了一个学习的这样的东西 顿悟的感觉 是吧 嗯 我在看你跟智源的专访 里边你也提到一个点 就是鸽子问题 你当时和Denny Zhou在 Twitter上 关于chain of thought的一些讨论 就是说确实 理论上也许你的这个逻辑能表述的话 chain of thought似乎可以解 但是模型会用无限的数据 去试图解决这个问题 但是 人似乎一下子就能get到这个问题 我觉得和你刚说的那个东西 有一些联系 但你如果来定义这个能力的话 你会把它定义成reasoning吗 还是你把它定义成一个什么 顿悟呢 它是在reasoning 或者说其他一些task下面 下面是什么意思 是更底层的意思还是 更底层的意思 就是说它是一个表征学习 比如representation learning的一些行为 随着这个训练的拓展 你会发现表征会改变 就相当于看金庸小说 对吧 张无忌一开始被他义父谢逊逼说 你把东西全背出来 现在全背出来 背出来之后你不懂没关系 不懂你可以脑子里存着 过了几年之后 突然之间有点 会了乾坤大挪移 突然懂了 这个是很有意思的一个机制 比如说你当时教小孩子 可能也是这样 特别是有些小孩说你先把它背出来 读书百遍 其义自现 就是你现在先读 并不知道什么意思 但是过一段时间之后 或者说你跟其他的一些事情 能够联系在一起了之后 你就会有一个突然之间你会觉得 这个意思 是跟我这个现实世界是有关系的 或者说这两个意思之间是有关联的 我们知道更深的联系 这种其实是应该说是顿悟的一部分 这个机制其实是在思维链之下的 不管你用思维链做推理训练也好 不管你用那个直觉 来判断那个答案也好 或者不管你用什么方式来判断答案也好 对吧 这些东西 它的下面有一个共同的机制 就是说我到底用什么样的表示 用什么样的对这个世界的理解 导致了这个思维链 比如说那个小学生做一道题 他可能说 我这道题怎么做 我用穷举法 1+1等于多少 1+2等于多少 1+3等于多少 那么有一些穷举的一个路径 可以把这个事情做了 比如说你要证明一个简单的一道习题 那么小学生会说 我穷举一些答案 看答案差不多了 那可能就对了 但是你这种方式 其实可能很多问题解决不了 等到比如说初中生或者高中生 他们的这个思维其实有一种飞跃 什么叫飞跃呢 就是说我们告诉他 我们可以用数学归纳法 来解决这个问题 数学归纳法这个思维 这个层次是高于穷举法的 如果你的数学归纳法 能够证明这个事情是对的 那么它就对所有的自然数都成立 那这样的话 我的穷举法 穷举无穷长的那个思维链 它其实都比不过数学归纳法的 很短的证明 所以这个是一个飞跃 这样的话 你对这个问题的理解 两种方式的思维链 它的后面的理解是不一样的 所以这个理解或者说这个表征 其实就是神经网络 学习的一个重要的地方 我不知道我讲清楚了没有 很清楚 然后我想跟你对齐一个认知 然后给你看一个 就是当时我引用的 我们不是教课吗 然后我们教课的时候 我自己发现当时是Ilya去MIT 几年前了 2016年的时候他去讲的 总之他当时讲了一个东西 我觉得他说的很深刻 就说为什么这个back propagation works at all 然后就是这个 theoretically optimal hypothesis class 等于short programs 对对 就听你刚刚那个意思 也是 就是本来我要去走好多条点 走到这 然后突然找到了一个更好的联系 然后我就有一个更好的压缩 然后它就更generalizable 对 这么说 就是说因为压缩 可能也可以说是更通俗的解释 对吧 但是什么时候这事情能压缩 什么事情不能压缩 其实现在不是很清楚 这是为什么你要去研究Grokking 这个机制 它给你提供了一个动力学过程 让你知道 它怎么从一个不压缩的状态 变成压缩的状态 你可以这么想 我再说一下 就是我接下来问你一个问题的铺垫 就是我会发现 这个和人类理解知识似乎也很接近 人类也是information connect dot 但是这个图是在neural network之前出现了 对 而且 很多教育专家他会发现 就我记得在群里面 赵智沉有讲说 reasoning是一个人类固执的幻觉 对 然后这个是个教育专家说 the most important single factor is prior knowledge 对 你只有prior knowledge就行了 你只教prior knowledge 没有什么聪明不 聪明这种说法 反正 你只要把这些知识全都connect起来了 似乎就可以 这就是我接下来问题的这个铺垫 那接下来的问题就是 我们不知道我们的这些knowledge connections是怎么形成的 对 我们没有办法去讲清楚 你说在大规模预训练的过程中 似乎大家也不是很清楚 对 所以这是为什么搞清楚 其实可能孕育着 就是下一个模型的一个契机 对吧 如果你搞清楚了之后 你就知道什么地方你要修改 这样的话你模型变得更强 所以这是也是一个动力 因为我们现在 你看 可以说 我把它搞清楚 我把它当黑盒子 就相当于一个很大的开关 有很多的开关 对吧 像以前那种电脑 那个大型机 非常多的按钮开关 我们就培养操作员坐在上面 然后把按钮开关打开 各种组合 然后看效果怎么样 那这是一种方案 那另外一种方案就是说 我们要把这个大的机器打开 然后理解里面的机制是什么 有这个机制的理解之后 那我以后再去拨这开关的时候 就非常有感觉 我就非常知道哪些开关要开 哪些要关能把这个做出来 我觉得 这肯定是一个更好的做法 当然 现在可能主流的思维 其实并不是这么说 主流思维是觉得 我们就叫scaling law 我不需要搞清楚你们在干什么 我就机器 很多很多很多 放很多聪明厉害的人进去 然后让他们去拨那些开关 这些开关的某种组合找到了 那我们就能够把这个模型做得很强 两种不同的思维 但哪种是对的呢 现在也不好说 对吧 因为现在确实scaling law有很大的应用 确实那个效果也非常好 至少目前为止看起来 我把它当黑盒子 然后让很多人去拨开关 得到一个更好的解 是一个比较好的方案 另外一方面就是你把那个模型打开 那个时间花的代价其实更大 因为其实并没有多少人真的知道 这模型里面在干什么 但是我觉得长远来说 可能后者 会有更高的天花板 我同意你的判断 但这里边有这么一个点 我觉得 为什么黑盒子现在它是占主流 因为打开了以后 人类似乎也没有办法真的去判断 什么东西 是什么 就是这里边有几种学习范式或者怎样 对对 现在是这样 所以能不能找到一个比较好的 能够理解整个结构的一个大的框架 是重要的 所以是这样 这是为什么我做paper的原因 比如最近有一篇paper 我们做Grokking 对吧 那么这篇paper 为什么要做这个paper 所以我觉得通过这个方式 得到一个对这个问题的 一个大的理解 框架可能对以后的模型的改进 有很大帮助 这个是我的想法 本来已经有点复杂了 但是我觉得我再多引入一个问题 似乎我们在学习AI 怎么学习的过程中 我们会从人类身上 人类的学习过程取得灵感 包括最近很火的Sutton出来说 RL是人类学习的方式 大语言模型这种方式不是学习方式 它也不能学习 因为它没有objective 那另外一派呢 Hinton他说经验 并不是一个只存在人脑中的 你通过语言可以得到经验 这个debate 最后就落到人到底是怎么学习的 然后什么是学习 怎么样子才能产生学习 或者产生新的知识 或者connect the dots 就想请你再就这个问题 来发表一下你的猜想 甚至都可以 我觉得通过经验学习 这个是对的 但说这个经验里面 什么样的经验是更有价值的 我觉得这个是一个比较大的问题 对吧 比如说你要说非常直观的经验 就比如说我有一派是这么说 我没有embodiment 我是没有办法去学到真正的感觉 这个是行万里路 对对 你要行万里路 或者说你要真正感到痛 感到伤心 喜怒哀乐 你才能真正成为人 就是这样的一种说法 或者说比如说 我只能通过看世界 然后才能知道空间结构 或者说只能通过摸才能看空间结构 对吧 那么还有一种说法 就是说我有一些抽象的概念 我还是能够学会这样一些东西 我觉得这两个东西 其实应该说不是说是互斥的 因为是这样的 其实最终我的目的 是要学到一个representation 学到一个表征学习 对吧 因为如果你学到一个representation的话 有个好的表征 那么对的问题你能够解决 表征怎么学出来 的这个完全取决于 你的那个输入有多丰富 结构是什么样子的 不管你是直观的学习也好 还是抽象的学习也好 只要能学到这个表征 就能够 最终得到一个比较好的泛化的效果 我觉得这两个拼起来 应该说是比较好的 那么两边谁能写出表征来 这完全是应该说 是有个定量的方式来预测的 而不是说是非此即彼 有可能是说两边都一半都可以学 或者说一边1/3边2/3也可以学 都行 所以并不是说一定是黑或者白 或者左或者右 很多时候是混在一起的 然后最终得到个表征 这表征就是能够进行预测 或者说能够操纵你的行动 能够泛化到一个新的 没有见过的情况 那我觉得顺着这个问的话 就是你刚刚所说的后者的工作 就是不是black box 然后不是所谓的这种scaling law 而是真的去打开它 然后去梳理它 然后怎么样呢 用不同的方式去学习 对对 那它的意义是什么 就是几种 就是要么它学得更有效率 然而 似乎现在我们数据已经到了一个瓶颈 效率这件事情 不知道它是不是意义那么大 然后可能是在同样的知识里边 能学到新的东西 或它能增加新的数据 就是新的信息 information set 嗯嗯 它的意义是什么呢 就是那样做的意义 我觉得首先第一个就是说 数据到瓶颈的话 其实恰恰就需要这个了 因为如果数据到瓶颈的话 那你意味着 scaling law不一定有效了 比如说你就这么点数据 比如说你就只有这个 hundred trillion tokens （几百万亿tokens）这样一个scale 这个token数目 对一些大众的东西 已经绝对够了 对吧 但是对一些小众的领域 就是 它可能每个小众里它占的比例就很少 所以这样的话 其实你如果数据不够 再加上你的训练算法比较费数据的话 不管怎么样 你学会的永远是一个memorization 或者说是记忆的结构 而不是一个泛化的结构 那这个是一个问题 对吧 那么这种情况下 你怎么样去用scaling law做 你比如说你得去找办法 去做data augmentation 也许这是一个办法 对吧 但是如果你对这个问题有理解 对这个模型有更好的理解的话 也许不需要data augmentation 也许你需要改变 这个训练本身的那个算法 或者说训练的那个架构 那么有这个架构之后 也许这个模型就会做得更好 你觉得我们现在大语言模型 产生出来的inference 生成出来的这些新的token 它是记忆还是泛化 我觉得这个是 我觉得是混在一起的 task比较丰富的 你见了很多很多这样情况 可能是泛化 给它的记忆材料越多 它越有泛化的可能 是这样吗 你可以这么说 就是给它的材料越多 因为它看到各种组合了之后 它在组合里面 可以得到一个比较好的表征 这个表征它能够有预测能力 或者说 这个表征对没见过的那个组合 它有一些比较好的结构可以算出来 这个其实就是泛化 我觉得说实在 所谓我们真的懂这东西 我真的理解这东西 往往意识的一个 是它的泛化能力很强 对新的情况下 这个表征能够得到正确答案 然后第二个 就是说 它能够细化到非常简单的这个逻辑 那么这个逻辑 可以apply to everything或者apply to lots of cases 这两个东西综合起来 就是让你这个学出来的知识 能够apply到很多其他的地方 那么这个叫泛化 应该说我们对泛化下个定义的话 这样一个定义 那么如果大语言模型 对某个领域看了很多很多数据 它有可能学到更好的表征 然后这边就可以泛化 那这个是一个 然后另外一个 就是说如果它看到的数据很少 那这样的话 有可能就说这个模型本身 它没有办法学到很好的那个表征 OK 那它就只能把它背出来 它得到的表征就是更偏于背诵的 这样的结构 就是 它能够至少对付好训练的那个要求 就说 我希望这个训练集上的那个错误率 还是比较小的 但是 它一旦超越了那个训练集的范围 之后 你就会发现这个错误率就会提高了 那么这个其实大家就认为 这个是过度拟合了 对吧 或者说是背诵了 所以大概就是这样子 其实我觉得很多时候 你并不能说神经网络是记忆还是泛化 应该说是完全取决于这个数据的分布 如果数据多 那么这个神经网络是泛化多 如果数据少 那么这个神经网络是记忆多 这个是我的观点 我觉得这里边最fascinating的一点 就是它从记忆到泛化的那一步 到底是怎么发生的 帮我们总结一下 至少从我最近的一篇paper角度上来看 告诉你 就是它有很清楚的一个picture 告诉你就是这是怎么发生的 内在机制是怎么发生 就是我们现在感觉上是 我从记忆突然间跳到了泛化 好像这个变化非常神秘 但是这篇文章其实告诉你说 其实并不神秘 它有非常清楚的一个数学图景 就是比如说 我们要做优化问题 我们可以构造一个 比较复杂的一个非凸的 一个优化的结构 比如说很多山的山峰 然后记忆 对应其中一个山峰 那个泛化 对应其中另外一个山峰 这两个山峰 其实对应着不同的表征 那么这个山峰的这个结构 其实完全是取决于数据的分布的 如果你数据不够 你可能就只有记忆的山峰 如果你数据很多的话 某些泛化能力强的山峰 就会慢慢变得越来越高 然后记忆的山峰就会变得越来越低 这样的话 你再让神经网络 去找到那个好的表征的时候 是相当于是个优化问题 优化这个神经网络这个参数 使得它能够收敛到某个局部的最大点 那么如果你的记忆的山峰缩下去 泛化的山峰提上来 然后泛化的山峰 那么就有很多的那个神经网络 它的参数会收敛到那个泛化的山峰 那么这个 模型就泛化了 那么从记忆到泛化 中间为什么会顿悟呢 其实很简单 就说你两个山峰之间的变化 此消彼长 对吧 然后在某个情况下 我比你高一点点了 然后突然之间所有人都往那边走 那就是因为它可以泛化 把它给泛化 因为它能泛化 所以它可以 只要多一点点的话 它就全都过去了 对对 因为你认为 神经网络 是一个一直在优化的过程 它会看见 如果这边高 那边低点 那么所有人都涌到那个高的山峰上去 那就突然之间你就懂什么意思 所以我觉得是这样的一个结构 也就是这样 从整个数学框架上 能告诉你这件事情 是这么发生的 而不是说是 还是非常神秘的这样的一个东西 那我是不是可以理解为 这个泛化的点一直都在数据里边 只不过我们之前没有找到它 没有搜索到它 或者说搜索到了 但是没有pay enough attention（足够注意） 然后现在 因为它随着越来越多的数据点 凸显了它的价值 然后我们才pay enough attention 对对 你可以 问题是它要存在 对 它存在 然后它有 你要足够的数据让它显得与众不同 可以这么想 就是如果数据不够的话 你可以有很多泛化的那个思想 但是就说这些泛化的思想 它的说服力不足以说服记忆这边 就是因为还不如把它记住 规律可能没有那么显然 对吧 那这又回到了另外一个问题 就是怎么样子做evaluation 怎么样子做reward 现在大语言模型还是你看你next token predict（预测）准不准 作为reward（奖励）吗 还是有其他的方式 可以让这个有泛化能力的 显得更牛一些 应该是这样 就是现在你要看大语言模型 一种是pre-training预训练 和post-training后训练 对吗 这两个都有 所以你很难讲 你说预训练 我们现在还是用大量predict next token 然后后训练 其实我们可以说 有很多办法可以做训练 那么预训练这个结构 或者说这个损失函数其实没有变 因为现在相对来说 这个还是比较好的损失函数 当然现在有一些新的一些方案 比如说reinforcement training（强化训练） 就是我在训练时候加一段思维链 然后希望这个思维链 会导致最后的那个预测是比较准的 这种类型的一些工作 这个就是可能对原来预训练的方式 做了一些改变 大概是这样 那后训练它的花样就很多了 对吧 花样 就比如说 你可以改reinforcement learning的一些函数 比如说改比如说它的值函数 改它的evaluation 对吧 value function（值函数） 对吧 reward 对吧 改rubric（评价细则） 这些东西都可以改 你这些改了之后 可能就是 你其实是希望这个模型 往不同的方向走 对吧 然后你往不同的方向走了之后 那么有些方向 可能就强化模型的某个能力 某些方向强化模型另外一种能力 那这样的话 你这个模型最后就是百花齐放了 当然就是说很多时候 你要优化它到某个能力的时候 你其实还是希望能够优化得比较 一个是避免 reward hacking 有些时候就是 模型还是会最大化你的某个值函数 但是这个最大化的路径是偏的 不想让它这么做 但是它就这么做 这么做有shortcut 比如说你答案就只有ABCD四个 然后拿去瞎猜一个25% 我不希望它瞎猜怎么办 那我就希望我的思维链 一个是希望它的每一步 经得起考验 每一步逻辑是正确的 你可能需要一个另外的模型去做这个事情 这是比较重要的 一个就是怎么样去做这个事情 那么这样的话 你中间肯定要引入各种rubric 引入各种东西去把这个模型给调出来 所以其实花样还是挺多的 而且有很多地方 是可以有一些人类的那个思维和概念 能够放进去 听到现在用比方去理解它的话 就是大语言模型是个非常非常勤奋 算力非常非常高 就是一天到晚学习的人 读了唐诗三百首 结果发现它又找到了唐诗3万首 读了300万首唐诗 然后它会作诗了 是因为它穷尽了这里面所有规律 找到了行之有效的方法 且它有一个好的方式 去可以帮助它evaluate 它自己的诗作得好不好 它找到了这里边的规律 但前提是这个规律要存在在这里边 对对 然后你刚刚所说的 就是希望用另外一种方式去学习 是说我们不光要让它去背300万首唐诗 我们能不能 就是像发现数学公式那种方式 去发现一个规律 阿基米德发现 浮力定律它其实是干了两件事 肯定当时在想很多很多的方案 很多很多的可能性 然后它脑子里边找到了这么一个点 但是第二件事是 它马上意识到这个是对的 这两者在机器都挺难做到的 它很难马上意识到这个东西是对的 我觉得意识到这东西对的是有可能 比如说你发现一个新的假设 这假设能够解释更多现象 而且它假设更简单 那你会马上意识到这个是对的 就比如说地心说跟日心说 其实说实在的 那个地心说也是对的 地心听说你也可以拿来预测 只是在地球上来看 其他行星的运行轨迹非常复杂 本轮均轮这种运行轨迹 就是轮子套轮子 一边这么走 还要换个花样再转再转 就轮子里面套轮子 然后你通过这个方式 你可以预测一个行星的行为 这两个其实都是对的 日心说的时候 你会发现突然之间 所有的轨道都非常漂亮 就是一个椭圆 非常非常简单 这个时候你会马上意识到那个理论 或者说那种解释是更加完美的 或者说更加接近真实 或者更加接近那个更美的 这样的感觉 原来是这样子一个逻辑 你觉得elegance这个东西 在模型现在训练的reward function里吗 我觉得是这样 它不是reward function（奖励函数） 但是它在训练的时候 应该有implicit bias（隐性偏见）往这方向走 就比如说那刚才你说 Ilya说过这个 我希望它压缩 我希望这个模型会自动的 找到一个比较优美 的或者比较少的 压缩比最高的那个 解释 这个我是同意的 这个确实是会发生的 但是这个不是 是一个loss function 是说它内建在神经网络的训练过程里面 这训练过程 会让这个模型自然地发现更加好的 或者说更加优美的解释 那么这样的话 神经网络 它才有这个 能力去学会更好的表征 然后才有泛化能力 在loss function之上 还有一层更隐含的reward 是的 是可以这么说 对对 这个很重要 因为说实在所有的loss function都是surrogate 都是代理 就比如说predicting next token 或者是whatever 或者什么contrastive loss non-contrastive loss 或者说player loss 这些东西都是代理 就是它的目的是产生一个梯度流 这个梯度流 能够让这个表征往正确的方向走 这个是最重要的一个逻辑 至于这个目标函数是什么 其实并不重要 重要的是这个 哦 我直到今天之前 我一直觉得 loss function是整个学习的目标 现在我才知道了它是surrogate（代理） 这个是共识吗 我为什么到今天才知道这件事 因为它听起来很intuitive 然后很重要 我自己 毕竟还是做过很多表征学习的工作的 我知道 很多表征学习的那个目标函数 你做过些拆解之后 你会发现它们其实就是反向传播梯度的 不同形式 你loss function换了 你的反向传播梯度的结构是不一样的 那么这个结构 其实最终能够影响你的表征的学习 但是你这个loss function其实可以 换 你甚至换成一些那个奇怪的东西 你从来没见过 但是你最后得到那个梯度是差不多的 那你求出的表征也差不多 你对梯度这个词的使用 也让我觉得非常的intuitive 我心中就是一个一个等高线 这个等高线最后画出来的 是我们的一个知识 很本质的东西 可能就是刻画我们世界规律的 这么一个 等高线这个逻辑 是经常用的 但是等高线这样的一个思路 其实它忽略了 这个神经网络本身的结构 因为它把整个landscape 把它做成一个高维空间中的 一个非常复杂的一个山峰 但是这个山峰 其实你要知道 山峰其实对应着神经网络的结构 所以这两个是有关系的 应该说 把这个梯度在山峰上的这个指引 去映射到这个神经网络的 具体的哪个梯度 对于哪个神经元的 或者每一组神经元的这样一个过程 那么这个时候你能看见 就是它的表征是怎么学出来的 这个是会比较有趣 但这个可能比较细节 大概是这样的一个逻辑 但这个是一家之言 我们来听的就是一家之言 有教科书的话我们就去学教科书了 当然每个人都会有自己的想法 这边也是做很多research 有这样的一个大概的感觉 在上面有很多文章做一些这样的工作 分析这个梯度的结构 我相信就是再往上走 也许那个理解 是 能够改变这个神经网络的学习的方案 这是我们的最终目的 当然这个方向比较 远 这是long-term的 当然是希望有很多那short-term的东西 可以跟它辅佐在一起一起做 要回顾一下你的这个科研史 看你的工作 其实我能感觉到 它是有一个很强的主线 自己的网站上介绍的时候 我就会发现 你前面一个工作lead到下一个工作 然后再lead到下一个工作 就是每一次 都能在前面非常重要的结果上 再往前走 你到底是怎么决定你的科研方向 你怎么样子把兴趣 商业和自己的追求结合起来的 肯定是要结合的 不然的话就是很有可能就很惨 大家都有家庭 大家都希望能够有一些比较高的收入 小孩也有个比较好的环境 社会地位也比较高 大家都希望这都要 成年人说大家都要 不是说小孩子 要选一个 所以最终你肯定是要找到一个结合点 因为我从博士开始 已经是很多是双线作战了 我可能花9个月时间 去想一些不着边际的东西 然后3个月说不行了 我今天要发paper 不然的话老板不爽 对吧 那我可能会跟老板说 你有什么题目 我来帮你做 我花3个月我就把这个事情做了 几篇paper就要对老板有交代 通过这方式至少让我 我是觉得让我会有工作 我能毕业 对吧 然后老板也开心 这个是重要的 工作之后也是一样的 我们当然希望做一些方向 这方向是迎合时代潮流的 不可能说完全脱离时代潮流 比如大家都在做大语言模型 你偏偏不做 比如我就要做SVM 肯定在公司里面是没有办法活下去的 会想一想 就是说 我这边的一些比较偏理论的研究 对于这个问题有更深理解 比如之前我们有一些关于 attention sparsity 注意力机制如何变得稀疏的 这样一些研究 那么这研究本身是比较理论的 但是你就可以拿来做一些 比较实用的工作 比如说之前的attention sink 我们其实没有太多理论 但是我们可以通过观察 这个神经网络的稀疏性 我们可能得到新的算法 用这新的算法 把上下文扩展到400万以上 这样的话 这个东西有用了 突然之间 你可以拿来做大语言模型的 coding解码的这样的一个应用 这应用 其实本身也可以放在很多手机上 这样的联系应该说还是比较紧密的 应该容易想到 你的attention有稀疏性的话 那我就把大部分的attention的score砍掉 那不就是加速了吗 其实省内存了 对吧 那你有各种办法可以提高这个效率 这两个关系是很大的 你只要稍微想一想 就有一个新的算法 你有新的算法之后 你就有一个新的思路 那么这个新的思路 你就可以拿来做很多 最后一个问题 就是until recently 你的科研 你感觉是按照自己的想法走呢 还是要做很多application的工作 及接下来 可能会吸引你做的事情是什么 是继续你对后一种研究范式 继续探索呢还是 我觉得研究范式探索是很 重要的 当然了 我们现在也要与时俱进 对吧 就是了 我不可能我关起门来说 我就用以前的方式来做这研究 也许我们以后要找到一个AI scientist 或者说我自己写一套比如说agent框架 然后帮我一起做研究 这也是可以的 就是说我们这篇那个Grokking的paper 就是我和GPT-5进行对话做出来的 其实我觉得很有点像这种self-play 我给它一些问题 然后我这边有些想法发给那个GPT-5 让它去思考 给一些比如formulation 就一开始你这么做 它给你的答案都是非常大路的 非常没什么意思 但是你通过思考之后 关键的一个insight给它 它可能会有不一样的输出 这不一样输出 可以往下面深挖一层了 但是你还是要找到它的错误 找到它的一些矛盾的地方 它做不出来的地方 然后继续深入 然后一直深入到 这个问题的那个理解 或者说这个问题的一个数学的 这样描述 已经达到了我想要的这个目的 这部分就成功了 但是我还有一个点 就是那是个solo author paper 你没有把GPT-5放到co-author里边 这篇文章是个conference投稿 conference投稿说 大语言模型不能作为作者 所以你没有放 对吧 那我后面写了一段 这段话是说我们广泛地使用大语言模型 我给大语言模型各种想法 让它去formulate 让它证明一个东西 然后发现问题怎么解决 对吧 它基本上所有 东西都是错的 但是它有一些比较有意思的insights 很多东西可以细化 然后把你的idea从一个想法 变成一个具体的过程 这个它很擅长 就相当于它是一个非常勤劳的 junior的一个PhD 它非常勤劳 我给它一个想法 它马上把它写成一段落 让我能够很快地进入状态 以前你要进入状态 我现在有一个小时的时间 一开始半小时我要进入状态 通过写写公式 看看文章 思考一下 我进入状态了 叫心流 然后才能得到一些结果 这个时间其实比较漫长 有了这个GPT-5之后 进入心流时间很短了 你跟它有一个小想法 然后它给你写一大段 三分钟之内给你写一大段东西 你看完这段东西之后 你马上会进入这个状态 就说我知道我要怎么去想问题 什么地方它做得不好 或者说有什么insight可以进来 这个是很大的一个效率的改进 以前你需要几个月的时间做一篇文章 你现在可能几个礼拜 甚至是更短的时间 这个是非常大的效率的提升 如果用得好的话 是很厉害的 当然 现在还是个非常初级的一个self-play 对吧 也许 说不定 以后我们可以做一个更加自动化版的 就很有意思 嗯 那肯定这方面有很多东西可以做 自己也有一些经验了 就是我跟当时是o1-pro 探讨量子力学的那个many-world theory 我特别感兴趣 然后我一直觉 得它最make sense 但是我们没有对应的哲学 反而那种所谓玄学的哲学 和这个many-worlds theory的哲学是吻合的 就是我如果非要强行地说的话 我就说这个世界的本质 就是一个非确定的many worlds 然后我们之所以现在share一个reality 这个是我们的最大概率 当然这个概率可能极大 就是99.99999 所以说我们就会觉得 这个桌子是确定无疑的存在 但是其实它可能并不是真的存在 嗯 对 大概是这种感觉 对 这个是对的 从科学上也是对的 你可以认为它是一堆波函数的组合 对吧 然后存在一种可能 是这个桌子突然之间跑到另一堵墙 另外一边去了 这概率非常小 但是不是0 这个是存在的 只是因为这个桌子是宏观物体 它的那个量子态不是那种相干量子态 所以就出现这种概率非常非常小 就是这样子一个东西 但是我就发现 这个idea 我没有办法和它写成一个文章 因为我自己的水平不行 就是说现在AI能辅助你写出来 像你这个顿悟的这样的文章 主要是自己 最后还是人还是比较重要了 有很多重要的insight还是要人给 然后AI现在有很多奇怪问题 比如说它就会卡在一个地方动不了 它会跟你说很多车轱辘话 然后它就说不到 本质上 这个很有意思 感觉上就是 你去面试一个新来的PhD 然后说一大堆话 它像背诵概念 但它又绕不到 它就找不到那句最重要的 本质的话能够说出来 这个其实是一个比较大的问题 但是这个就需要人去总结 然后告诉它 这个是我们认为的最本质的东西 然后让它继续往下走 这个是比较重要的 就是说这是一个fresh PhD fresh PhD意味着它可能是可以被训练的 我想到是duolingo的那个founder 他是一个计算机教授 我忘了叫什么 他讲了一个故事 就是他去读博士的第一年 他老师是图灵奖的获得者 对 然后几个月 他去了以后 他老师就只跟他干一件事 就是你这个东西给我讲讲 我没听懂 下次再来 他第二个月的时候就崩溃了 就这个老师肯定不行 怎么回事 结果后来才发现 就是他自己没有讲清楚 没讲清楚说明你这个理解不深 对吧 如果理解深的话 讲清楚了 别人会觉得 你确实理解深了 你确实懂了 然后你可以做 你可以做研究 所以这个是一个 对 他叫那个Luis von Ahn 对 我想起来 对对对 应该是说我当时在CMU读博的时候 他就在那了 对 他有这么一个故事 所以说 不知道模型是不是也可以这么搞定 我觉得有希望 希望可以 是的是的 对 当然了 大模型可能会强行地记住 怎么样讲能讲清楚 但它自己不懂也是有可能 而且就是说 你怎么样才能获得训练数据 能够让大模型 找到最优的讲清楚的这样一个 因为讲清楚这个事情 是一个非常主观的东西 很难用这个模型去model它 在要求大语言模型之前 我们先要求自己 我们先要求自己把一个东西给讲清楚 已经是一个很高的要求了 这个很难 就是说 这部分其实可能就需要人有美感 就是人觉得它的那个讲解 是非常有美感的 或者说非常简单扼要 这个才可以 那么这个怎么样去设计一个loss function 是一个question 通过这个对话 我也更深层次地理解了 这件事多重要 它的context是什么 和它其实对人也好 或者对模型来说 其实都有很多共通的地方 我觉得通过讲这个论文 我们也讲了很多其他的 我觉得挺重要的知识 对对对 好的 那祝你接下来一切顺利 谢谢 好 先这样 拜拜