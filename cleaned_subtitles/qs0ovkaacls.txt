具身智能是2025年的最大的“泡沫”吗？ 这一年机器人感觉突然就从只会走路 迅速学会了做家务 跑步、篮球、足球、乒乓球 还有跳舞、功夫等等 感觉进展惊人 我听说国内也是各种卷 这不 宇树马上就要上市了 所以 人形机器人真的马上就要来到我家了吗 不好意思 我们可能要给大家泼盆冷水 冷静冷静 具身智能 大家看这个词 前面是机器人“硬件” 后面是机器人“大脑” 这两个方向各有各的难 而把两者拼起来 还要要求准确性和稳定性 还要追求商业落地 那就更难了 这期视频我们采访到了 硅谷最明星的几家机器人公司 也去到现场走访了不少前沿的实验室 与业内大佬们聊聊 机器人行业到底是资本炒作的泡沫 还是真的有着技术突破 2025年的人形机器人行业 发生了几件让人惊呼“不可能”的事儿 年初 宇树突然放大招 发布了5900美元的R1人形机器人 要知道 就在一年前 业内普遍认为人形机器人的成本底线 还在2到3万美元 那么宇树这一招 相当于把整个行业的价格预期直接打碎 紧接着Figure AI的估值 就从2024年的26亿美元 一路狂飙到了390亿美元 达到了15倍的增长 投资方名单读起来 就像科技圈的奥斯卡颁奖典礼 微软、OpenAI、英伟达、贝佐斯 英特尔、三星等等 资本市场疯狂押注 仿佛具身智能的未来近在咫尺 但与此同时 特斯拉喊出 要生产5000台Optimus的豪言壮语 实际上只组装了大约1000台 就按下了暂停键 面临重新设计 马斯克那句“特斯拉八成的价值 都将来自于Optimus”的豪言 在现实面前显得有些尴尬 这一冷一热 实在是有点让人困惑 具身智能到底发展到哪一步了 我们这个视频就会从算法、硬件、数据 资本以及主要大玩家路线等等这几个方向 一一给大家展开解读 那么先说结论 答案是 2025年 具身智能正在从“先锋亮相”的Demo秀 转向“有分寸地摸索前进”的务实阶段 行业开始认清现实 不再只画大饼 而是在真实场景中 一步步去验证能力的边界 Demo视频依然精彩 但是落地变得更加谨慎 技术突破让人兴奋 但是商业化的每一步都在计算成本 而好消息是 这种转变恰恰是机器人走向落地的标志 接下来我们就来详细拆解具身智能 那么在聊行业的现状之前 先说清楚什么是具身智能 如果说ChatGPT是“会说话”的AI 那么具身智能就是“会动手”的AI 它的核心是VLA Vision-Language-Action 视觉 语言 动作模型 它把三个东西统一到了一个神经网络里面 Vision（视觉） 看到当前的场景 Language（语言） 理解任务目标和常识 Action（动作） 输出具体的控制指令 简单说就是三个能力 看得懂环境、听得懂指令、做得到动作 这和传统机器人有什么不同 打个比方 传统的工业机器人 就像只会背固定台词的演员 你给它编好程序 它就按部就班地执行 但是具身智能机器人 更像即兴表演的演员 它能理解环境变化 自主做决策 比如说你让它叠毛巾 传统机器人 需要毛巾每次摆放位置完全一样 但是具身智能机器人就能够识别 哦 这次的毛巾皱了、偏了 那我调整一下动作轨迹 照样能够叠好 Dyna Robotics 是硅谷炙手可热的具身智能公司 一年前刚成立 如今A轮融资就达到了1.2亿美元 估值6亿美元 投资人就包括了英伟达 而“叠毛巾”这个任务 正是让Dyna最先火出圈的demo VLA简单来说 就是我们拿了大模型领域VLM 作为所谓的backbone（核心） 但是我们会在最终输出结果的时候 把这个结果转化成 在机器人领域可用的action（动作） action你直观理解就是 你可以把它转化成 比如说我要把这个手臂 移动到某一个坐标点的这一些命令 VLA其实大家诟病最多的是 为什么我们需要L（Language 语言） 因为其实在过去传统的机器人算法里面 很多都是纯基于视觉 但是你仔细去想 其实你大脑其实会产生类似于语言的东西 去告诉你在一个长线任务中 到底你第一步做什么 第二步做什么 L的作用就在于 对于一些非常复杂的任务的时候 它是可以通过在大语言上面 已经训练出来很多逻辑性的东西 它知道比如说你要喝水 那你需要找杯子或者找瓶子 这个是通过大语言模型 已经直接可以给你的一些东西 那利用VLA的主要目的 其实就是如何把Language（语言） 跟Vision（视觉）能够更好地结合起来 否则你如果只有Vision（视觉） 你能做的任务可能就都是短线的 你做不了任何长线的 需要去做推理的一些任务 所以这是我们为什么去非常专注地 引入语言这部分的主要原因 这就是质的飞跃 机器人不再只是执行固定程序的机械臂 而是通过视觉 语言 动作的集合 能够理解、能规划、能适应的智能体 具身智能其实不是新概念 为什么在2025年突然爆发 在这里也有三个因素在 第一就是大模型本身已经趋近于成熟 无论是OpenAI 还是其他公司近期发布的大模型 能力提升已经更多体现为增量式的演进 而非早期从GPT-3.5到GPT-4那样的 跨越式的跃迁 在这一背景下 大模型的整体能力正在趋于稳定 且足以作为具身智能系统的 可靠基础能力层 ChatGPT证明了 大语言模型能够理解复杂的指令 做规划推理 这套能力可以迁移到机器人上 你说“帮我做早餐” 它能够规划出 “先拿鸡蛋、再打蛋、然后开火煎” 这样的多步骤序列 第二是算力价格腰斩再腰斩 整体算力水平正在持续地提升 随着芯片厂商 不断推出性能更强的新一代芯片 等效算力的单位成本呈现长期的下降趋势 往往每隔几年 获得同等算力所需要的成本 就会降至此前的一半 2023年 租一张NVIDIA H100 GPU还是天价 现在云服务的算力价格愈战愈激烈 训练大模型的成本大幅度降低 以前只有头部公司玩得起的游戏 现在创业公司也能上桌了 第三是硬件供应链成熟 机器人硬件整体的零部件成熟度 已经相对较高 尤其是过去一年的 人形机器人热潮的推动下 大量资本和工程资源 被投入到核心基础部件的研发中 包括电机、减速器等关键的组件 使得相关技术持续成熟的同时 成本也在不断下降 宇树直接把价格打到了5900美元 此前 行业普遍认为2-3万美元的区间 已经能够实现规模化生产 成本曲线的陡降 让商业化不再是天方夜谭 那么这三股力量叠加 把具身智能从实验室推向了商业化的前夜 但是这不是盲目的乐观 而是基于技术成熟度的理性判断 所以目前具身智能的能力边界在哪里 它又能够做什么 我们先来说说能做到的事情 工业和商业场景其实已经有实际的应用了 叠毛巾、叠衣服听起来简单 但是Dyna的机器人 能够做到24小时叠700条毛巾 成功率99.4% 这在酒店、洗衣房 已经是实打实的生产力了 而且它们的基础模型里面 包含了各种各样的场景数据 像切菜、切水果、准备食物 早餐清扫和物流分拣 在宝马集团BMW的工厂里 Figure的机器人 在做简单的装配和物料搬运 Agility Robotics的Digit 在仓储物流场景搬箱子 1X也将向瑞典巨头EQT 交付最多1万台1X Neo人形机器人 主要应用于制造、仓储、物流等工业场景 更别提亚马逊已经部署了 100万台专用机器人 几乎要超过其156万人类员工的数量了 这些都不是Demo 是真实在跑的商业项目 这就是“理性前行” 不求全能 但求实用 那目前有什么还做不到 头部公司正在攻克的任务呢 比如说中等难度的任务 像做早餐 这是一个“长线任务” 需要规划多个步骤 拿食材、切菜、摆盘、开火、翻炒 每一步都需要精准执行 还得控制力度 不能把鸡蛋捏碎 也不能切菜切到手 Dyna最新Demo 已经显示攻克了做早餐这个长线任务 而Figure也展示过 两台机器人协同工作的Demo 一台递工具 一台操作 这在家用场景很有用 但是稳定性还在打磨 而最难的是家务 为什么 因为每个家庭环境都不一样 光照变化、物品摆放、家庭成员走动 这些都是“非结构化环境”的挑战 相对来说工厂是“结构化环境” 光线固定、物品位置固定、流程标准化 但是家里面则是完全另一回事 而且家务还有一个致命的要求 就是零容错 机器人在工厂打碎个零件 损失可控 但是在家里面打碎碗、伤到人 那就是事故 比如说你机器人执行任务的时候 比如说你桌布上有一个小的褶皱 你的杯子可能放置不稳 可能有一个透明物体反光 它刚好干扰了你的相机等等 这些微小的物理变化 人类其实可以凭直觉和丰富的经验 去瞬间适应的 但由于非常依赖于数据驱动 AI大模型它面临这些新的挑战 它不一定能真正地去感受到 所以 机器人进家庭 技术门槛要比进工厂高得多 但这不意味着遥不可及 我们是觉得最先肯定是在 像我们当前在开拓的一些市场 就是商用服务商用的一些人工的部分 就是和人工一起去完成一些任务 这样的一些场景 但是我们觉得家用其实也没有那么遥远 并不需要完整的非常通用的AGI 你可能只需要几个任务 就可以进入到家庭的场景里 先让机器人在家里面干起活来 然后逐渐地通过模型的迭代 让它产生更多的能力 当然 我们的硬件成本 降到普通家庭可承担的范围内 我们可能就会优先 比如说我先以叠衣服的功能卖给家庭 然后逐渐去拓展一些其他的功能 对 所以这个时间线应该也不遥远 可能也就在1-2年左右 这就是“理性前进” 不是说等到机器人变成 科幻电影里面的全能管家再推向市场 而是从一个明确的 用户真正需要的功能去切入 逐步地迭代 那接下来我们来聊聊2025年的技术突破 为什么今年这个行业一下子就爆火了 虽然挑战重重 但是2025年 确实有几个值得关注的技术突破 业内人士很坦诚地就告诉我们 每一个突破都不是革命性的 但是都是实实在在的进步 第一个进步就是架构 很多公司开始采用所谓的 “System 1+System 2”的这种架构 System 1是“快思考” 负责反射性动作 比如说抓取、移动 参数量小 反应快 可能只有8000万的参数 System 2是“慢思考” 负责复杂规划 比如说“做早餐”这种多步骤任务 参数量大 可能有70亿的参数 这种分工就很像人类的大脑了 你伸手接球 是本能的反应 但是要规划一顿饭 就需要仔细的思考了 Figure AI的Helix模型 就是这个架构的代表作 它们在和OpenAI“分手”之后 两周之内就迅速推出了这个自研模型 这种架构的成功 证明了机器人基础模型 和大语言模型的Scaling Law可能不一样 不是越大越好 而是要找到合适的参数分配策略 接下来我们来说一下数据上的突破 机器人数据为什么这么贵 原因也很简单 因为人类一天只有24个小时 收集真实操作的数据太慢太贵 英伟达的解决方案是 用模拟器生成合成数据 它们展示过 11小时内生成了78万条操作轨迹 相当于6500小时 或者连续九个月的人类演示数据 虽然合成数据和真实数据有差距 但是至少解决了“数据荒”的燃眉之急 但是这里有个关键的技术权衡 因为我们之前有聊过 挺多做大语言模型的这些人 他们其实有提到 像语言方向的这个数据 现在他们已经发现 哪怕你用很多低质量数据 就是你可能一堆文本 中间插了一段广告 再是接着文本 就这样的数据 它一样能训练出比较好的模型 因为模型它看的数据足够多之后 它自动就会过滤掉广告 但是机器人 当前我们觉得Scaling Law（规模定律） 更多的是来自于 需要比较高质量的数据 你如果囊括了很多 很繁杂的数据在里面 机器人模型可能就不知道 我要pay attention（注意力集中） 在哪一个地方 所以最终它其实出来的效果并没有那么好 2025年还有一个突破点 叫做跨机器人泛化能力 Physical Intelligence的π0模型 开源的OpenVLA模型 都能够控制多种不同的机器人 同一套模型或者策略 不需要为每一种机器人重新训练 就能够在不同形态 不同硬件配置的机器人上有效工作 这就叫跨机器人泛化能力 这很重要 以前每种机器人都需要单独训练模型 成本高昂 但是现在一个模型适配多种机器人 数据可以共享 成本就能够大幅度地降低 但是技术难点也很明显 不同机器人的动作空间差异巨大 手臂长短不一、关节数量不同 那么怎么让一个模型都能够控制好呢 这种在完全陌生环境也能够工作的能力 不是100%完美 但是已经是实质性的进步了 最后的一个突破是多机协同 Figure展示过 用单一神经网络协调两台机器人协作 创新性地用单一神经网络 控制整个上半身的35个自由度 同时还能够控制两台机器人协作 听起来简单 实际上难度很高 两台机器人需要互相地配合 时序、力度、位置都需要精准地同步 这在未来工厂场景会很有用 但是现在还处于早期的验证阶段 那么这些技术的突破 没有一个是颠覆性的 但是每一个都在扎实地推进 这正是2025年的特点 不再追求炫酷的Demo 而是在可验证、可量化、可复现的方向上 稳步地前进 而我在开头说 要给大家泼泼冷水 是因为在具身智能的方向 还有很多没有去解决的核心难题 那么技术突破是一方面 但是行业还有几座大山没有翻过去 清楚地认识到这些难题 恰恰是“理性前进”的前提 也是让现在的具身智能 来到了大爆发的前夜 首先是数据困难 ChatGPT训练用了万亿级的token 相当于把整个互联网的文字都喂给它了 但是机器人操作数据极度的稀缺 Google训练RT-2模型 是花了17个月 在真实厨房里面收集了13万条的数据 场景泛化能力依然有限 为什么机器人数据那么难收集呢 那是因为需要真实机器人 在真实的环境里面操作 每一条数据都要花钱花时间 出错 还有可能会损坏设备 这不像文本数据 爬虫跑一跑就有了 所以目前大多数机器人的基础模型 依然是依赖于少量的真实数据 再加上大量的模拟合成数据 加强化学习或者自监督方法 那我们采访到了 在硅谷的机器人大脑领域明星创业公司 Physical Intelligence的研究员 她就有一个大胆的预测 我想说一个人的一生 假设是100年的话 大概我们很粗略很粗略地算 就是100万个小时 我觉得现在在我的目所能及 或者我公开信息看到的范围里 好像没有人有一个100万小时的数据集吧 我是这么猜想的 我会觉得 什么时候我们能够收到100万小时 等同于一个人一生的物理经验的数据 我觉得可能我们才开始后面的探索 如果说数据是机器人的“石油” 但是现在这口井呢 还没有打出来 而难题之二 就是虚拟世界到现实世界的鸿沟 在虚拟世界训练机器人很便宜 同时可以跑几万个模拟器 但是虚拟世界永远不等于真实世界 就像你玩赛车游戏很厉害 不代表真的会开F1吧 真实世界的摩擦力、柔软度 光线变化太复杂 仿真只能还原部分的真实物理特性 剩下的就是机器人从模拟器到真实世界的 “水土不服”的根源了 英伟达的Genesis和Isaac模拟器 在努力地缩小这个gap（差距） 但是完全消除还需要时间 第三个尚待解决的难题 叫做Embodiment Gap 人手有27个关节 能够感知压力、温度、质地 机器人的灵巧手通常只有15-22个关节 传感器也没有那么精细 即使完美模仿人类的动作轨迹 效果也不同 人类能够轻柔地拿起鸡蛋 机器人可能一用力就捏碎了 第一是人类的手和机器人的手 如果你想让它能力迁移得很好 需要做得非常接近 这也是为什么现在有好多人在做 很灵巧的灵巧手 非常接近人的这个自由度 这件事本身是一件非常困难的事情 第二就是你再接近 它不是完全一样 所以在机器人的数据和人的数据中间 还是会有一个鸿沟 就我们所谓的embodiment gap 这个embodiment gap 在当前学术界也好 工业界也好 大家都是公认的 是一个比较难解决的问题 所以这样的数据的迁移的效率会比较低 就你可以想象 哪怕你采集了很多数据 如果只有30%或者50%可用 其实你的总数量就会 需要去乘以可能性的那个数字 对 所以这个是它的一定的局限性 这就意味着 特斯拉想用YouTube上面海量人类视频 训练Optimus的策略 面临着巨大的技术挑战 这也是为什么 特斯拉在生产了1000台之后就暂停 要重新设计 理想很美好 但是现实很骨感 而第四个难题是可靠性 GPT回答错了 用户笑笑就过去了 机器人动作错了 可能会砸坏东西、伤到人 那么这就是质的区别 具身智能必须要达到极高的可靠性 才能够真正地走进工厂、走进家庭 这个标准要比大语言模型苛刻得多 第五个难题是成本困境 这是一个“鸡和蛋”的问题 目前人形机器人价格 需要降到2万美元左右 才能够在物流等场景形成足够的吸引力 但是价格下降需要规模化生产 规模化生产需要大量订单 大量订单需要价格足够低 那么这是一个循环困局 需要有人先打破僵局 但能否引发价格战 带动整个行业降本 还需要观察 认清这些难题 不是悲观 而是理性 这是因为目前初创公司们 都很实在地去承认这些瓶颈的存在 具身智能才能来到了爆发的前夜 最后我们再来聊聊 目前具身智能的主要玩家 以及他们去选择的路线 那么面对这些难题 各家的公司选择了不同的路线 这一派公司包括了特斯拉和Figure 它们的策略是软硬件一体化 打造数据闭环 特斯拉利用FSD自动驾驶技术的积累 把视觉感知、路径规划的能力 迁移到Optimus上 还能用工厂的生产线积累数据 前工程主管Milan Kovac说得很直白 我们只是从轮子上的机器人 变成长着腿的机器人 但是现实比预期复杂 5000台的目标只完成了五分之一 又不得不暂停 重新设计 这说明即使是特斯拉这样的巨头 在embodiment gap面前也要低头 Figure则是在和OpenAI“分手”之后 独立开发了Helix模型 自己掌控技术路线 展示了它们确实有技术能力 15倍的估值涨幅 也证明资本市场对这条路线的认可 但它们真正商业化部署的也就几十台 Demo很精彩 规模化还在路上 第二派就是我们刚才提到的 Physical Intelligence 还有Skild AI 与多家同时押注硬件的机器人初创公司不同 这些公司的策略是模型先行 跨平台适配 Physical Intelligence的π0模型 不绑定特定的硬件 能适配多种机器人 它们的逻辑是 先把模型能力做强 硬件可以后续选择最优方案 而另外一家则是Skild AI 一家专注于 构建机器人的基础模型的软件公司 Skild AI的核心方向 同样是打造一种 与具体机器人形态无关的通用基础模型 可根据不同机器人平台和应用场景 进行适配和定制 在今年7月 Skild AI发布了其通用机器人系统 Skild Brain 并且公开演示视频 展示机器人完成拿取餐具 上下楼梯等操作能力 近期软银与英伟达 正计划对它投资10亿美元 把它的估值提升到140亿美元 第三类是主打生态的平台 英伟达提供模拟器和算力的基础设施 推出GR00T N1并且开源 但是你要用 就得用全套的英伟达生态 谷歌则是在学术研究上持续地投入 RT系列模型是影响了整个学术界 它们为整个行业提供“水电煤” 谁能够制定行业标准 谁就掌握了生态控制力 这三种路线都在前进 没有哪一派已经占据绝对优势 大家都在试错、迭代和调整 回到开头的问题 具身智能是泡沫还是未来呢 答案是 2025年具身智能正在从“先锋亮相” 转向“理性前行” 技术上 大模型+机器人的结合已经跑通 但是远未成熟 数据、泛化、可靠性 这些核心难题还没有解决 那如果用“GPT时刻”来类比 自变量机器人CTO王浩就认为说 我们现在是GPT-2的水平 我会觉得现在就是在GPT-2的这个阶段 其实我们现在基本上已经知道 规模化它是唯一的一个可靠路径了 所以我们就是要在这个阶段 去疯狂地积累数据 提升模型规模 同时去搭建真实具身的这种基础设施 所以我的预测会在一到两年的时间 我们完全可以达到GPT-3的这个水平 注意 是GPT-3 不是GPT-4 这就是毫不花哨的一个判断 由于研究员们看到了 这种规模化带来的提升 所以路径和目标就更加明确 也更加的唯一 而在商业上 工业场景开始试点 仓储、制造、服务业都有落地的案例 但是大规模地商用 可能还需要两到三年的时间 我们自己的目标其实在明年 我们至少希望在商用场景 有比较大规模的部署 在家用我们会择机看 所以这个时间线应该也不遥远 可能也就在1到2年左右吧 那么在投资上 可以说泡沫和机会并存 有公司的估值飙升 有公司暂停生产 也有公司钱烧光了而破产 开源机器人公司K-Scale Labs 融资失败倒闭 Figure AI拿钱拿到手软 那么这两个极端同时存在 说明市场正在分化 虽然具身智能的长期趋势稳定 但是短期波动剧烈 而具身智能第一个“杀手级”的应用场景 会是什么呢 有可能是家务任务 也有可能是仓储物流 或者是餐饮清洁服务 而无论是哪个场景 都已经有重量级的玩家在布局了 具身智能不是“会不会发生”的问题 而是“什么时候发生” 2025年 我们正站在这场革命的起点 行业不再只展示酷炫的Demo 而是开始脚踏实地地验证技术 打磨产品、寻找场景 特斯拉暂停生产不是失败 是在重新设计 寻找更可靠的路径 Figure AI估值飙升 不只是资本炒作 而是它们交出了Helix这样的实质成果 Dyna从叠毛巾切入 不是格局小 而是在积累数据飞轮 培养模型的学习能力 Physical Intelligence部分开源π0 不是不够开放 而是在商业利益和技术分享之间 寻找平衡 这种在现有基础上稳步提升 恰恰是行业走向成熟的标志 2025年 具身智能行业已经从“画大饼” 进化到了卷起袖子和面团 那么这个饼 正在一点点地有分寸地变成现实 感谢大家收看这一期的《硅谷101》 我是联合创始人陈茜 也感谢大家对我们2025年的支持和陪伴 希望2026年 我们能够创造出更加精彩的内容 那我们就下期视频再见啦 Bye