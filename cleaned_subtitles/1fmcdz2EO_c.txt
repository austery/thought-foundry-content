in one or two years we'll find that you can use them for a lot of um more like involved tasks than they can do now so you could um you could imagine having the models do carry out a whole coding project instead of maybe giving you one suggestion on how to write a function so uh you could imagine the model like you giving it sort of high level instructions on what to what to code up and it'll go and write uh many files and test it look at the output iterate on that a bit so just much more complex Tas moving away from sort of oneoff queries uh like using the model kind of like a search engine a smarter search engine and more towards uh like having a whole project that um I'm like doing in collaboration with the model yeah and it knows everything I've done it's proactively uh like um suggesting things for me to try or it's going and doing work in the background and fundamentally the unlock is that it can act coherently for long enough to write multiple files of code or what what has changed between now and then um most of the uh training data is more like doing single steps at a time and I would expect us to do more uh for training the models to uh carry out these longer projects um so I'd say any any kind of training uh any like doing RL uh to learn how to do these tasks uh however you do it whether it's whether you're supervising the final output or supervising it like each step um I think any kind of training at uh carrying out these long projects is going to make them a lot better and uh since uh the the whole um area is pretty new I'd say there's just a lot of lowhigh fruit interesting in doing this kind of training so i' say that's one thing um also I would expect that as the models get better they're just um better at recovering uh from errors or they have um just uh they're better at um dealing with um dealing with edge cases or when things go wrong they know how to recover from it so uh the models will be more sample efficient so you don't have to collect a ton of data to uh teach them how to get back on track just a little bit of data or or just their like generalization from uh from other um abilities will allow them to get back on the track on track whereas current models might just get stuck and get lost I'm not sure I'm not sure actually how uh understand more supposedly how the generalization helps you get back on track yeah if you collect a divers data set um you're going to get a little bit of everything in it and uh and if you have models that generalize really well uh even if there's just a couple examples of getting back on track or even um like maybe in the pre-training there's examples of getting back on track then like the model will be able to generalize from uh those other things it's seen to the current situation so I think uh like uh if you have models that are weaker you might be able to get them to do almost anything with enough data but you might have to put a lot of effort into um a particular uh domain or skill whereas for a stronger model it might just do the right thing without any training data or any effort right now we have models that are on a per token basis pretty smart like they might be as smart as humans on a per token basis the smartest humans and the the thing that prevents them from being as useful as they could be is that five minutes from now they're not going to be so writing your code in a way that's coherent and aligns with the broader goals you have your project or something if it's the case that once you start this long Horizon RL training regime it immediately unlocks your ability to be coherent for longer periods of time should we be predicting something that is human level as soon as that regime is unlocked or and if not then what what is remaining after you can plan for a year and execute projects that take that long I wouldn't expect everything to be immediately solved by doing any training like this I would think uh there will be other um like miscellaneous deficits that the models have that um cause them to get stuck or not make progress or make um worse decisions than humans so uh I I wouldn't say I expect that this one little thing will unlock every all capabilities but I um yeah it's not clear uh but it might like some improvement in the ability to do long Horizon tasks might go quite far does that imply that unless there are these other bottlenecks which they may or may not be by next year you could have models that are potentially like human level in terms of acting like like you're interacting with this as a colleague and it's like it's like as good as an interacting with the human colleague you can tell them to go do stuff and they go get it done uh what seems wrong with that picture of this is the capabilities you think might be possible yeah it's hard to say exactly what will be the deficit I mean I would say that uh when you talk to the models today they have various um uh weaknesses besides uh long-term coherence in terms of also like um like really uh thinking hard about things or paying attention to the way you ask them uh so um I would say um I wouldn't expect um like just improving the uh coherence a little bit to like um to be all it takes to get to AGI but um I guess I wouldn't be able to articulate exactly what the main weakness is that'll stop them from uh like being a fully functional colleague