现在如果你打开窗户往外看 世界似乎没有什么变化 对吧快递在跑 红绿灯在闪 邻居在遛狗 那就在我们说话这一刻 全球GDP大约1% 也就是数千亿美元的真金白银 正在被疯狂的砸进同一个领域 人工智能 按照常理说啊 这种巨量的资源注入一项技术时 我们应该能够看到 某种惊天动地的爆炸 我们想象中的AI革命 应该是机器人满街跑 或者是超级大脑瞬间解决了癌症 但现实是什么呢 现实就是啊 你早上起来刷抖音 看到某某大公司又融了100亿 某某模型参数量又翻了一倍 然后呢你关掉新闻 继续使用ChatGPT 帮你写一份不太重要的邮件 或者让他帮你把刚才那段难搞的代码 重新再修补一下 伊尔雅苏斯克维 这位曾经点燃了深度学习革命的男人 把这种现象称之为缓慢的腾飞 slow take off 一种非常诡异的常态化 这些新闻放在过去 每一条都能够作为当日的头版头条 但是现在呢 它只是另一条科技新闻 我们人类适应的太快了 快到忽略了一个巨大的反差 即使我们今天造出了 能够通过所有人类考试的AI 为什么在很多时候 它依然给人一种不够聪明的感觉呢 今天呢 我们就来好好拆解一下 伊尔雅苏兹克维 最近做的一个播客节目啊 在这期播客中呢 伊尔雅分享了 他是如何看待AI从模仿走向思考的 关键开关 关键开关 也就是那个价值函数 我也会把这期播客的链接 放在视频的描述栏 大家感兴趣的可以去看英文的原文啊 为了理解现在AI为什么既强大又脆弱 伊尔雅 给主持人讲了一个非常精妙的比喻 想象一下 你要培养一个世界顶级的编程选手 你现在有两个学生 1号学生呢 我们称他为卷王 他的策略就是题海战术 他极度勤奋 练习了整整1万个小时 他做过人类历史上所有的 编程竞赛题记住了所有的算法变体 背下了所有的解题套路 当你给他一道题呢 他能够瞬间调动记忆 快速精准的写出代码 在这个特定的考场里呢 他就像那个自带BGM的乔峰啊 在他的这个BGM中呢 他就是无敌的，2号学生呢 我们叫他天赋型 他只练了100多个小时 但他有一种特殊能力 虽然呢他做过的题少的多啊 但他似乎看透了题目背后的逻辑 他拥有某种啊 说不清道不明的直觉或者品味 那么现在关键来了 如果你让他们离开考场 去解决一个现实生活中从未出现过的 乱七八糟的烂摊子问题 谁会表现的更好呢 直觉告诉我们是那个天赋型的学生 对吧而现在的AI呢 而现在那个AI呢 恰恰就是那个练了1万小时的卷王 我们现在的训练方式呢 也就是所谓的预训练Pre training 本质上呢 就是把人类互联网上所有的文本 代码对话一股脑的塞进模型的脑子里 我们强行让他 变成那个见过所有题的学生 所以呢 当我们看到AI在考试里拿高分时呢 千万别着急着膜拜 他可能并不是真的学会了思考 他只是把那道题啊见过太多次了 基本上所有变题都见过了 这就解释了一个巨大落差 为什么现在这些AI 在某些超难测试里头 表现的像一个神 但在某些简单的任务中 却像一个复读机呢 第二啊提到一个非常具体的 让很多程序员抓狂的现象 完美的暴露这种卷王模式的缺陷啊 我不知道大家有没有用AI去写过代码 啊其实我就遇到过类似的问题 如果你用现在这个AI来辅助写代码 你可能会经历这样的崩溃时刻 你有一段有bug的代码扔给他 你说哎帮我修好它 这个AI会自信满满的说哎呀 你说的太对了 这里确实有个错误哎 你看我怎么修 然后呢他给了你一段新代码 你运行啊 发现哎原来的bug确实没了 但是因为他修改呢 引入了一个新的bug 你就告诉他哎 现在这个报错啊 是有bug b 你赶紧帮我修改一下 这个ChatGPT会非常礼貌的说哎呀 抱歉抱歉 我是个笨蛋 我马上就修 然后呢他把代码又改了回去 这个bug b没了 但是原来bug a又回来了啊 我之前就遇到过类似情况 我在原地不停地打转 很多情况下呢 你可以跟这个ChatGPT 在这两个bug中啊玩上一整天 这不是好笑啊 这是非常惊悚的一个情况啊 为什么一个在编程竞赛里头 能够打败99%人类的超级大 脑会陷入这种非常低级的死循环呢 伊尔亚的诊断是啊 他并没有真正的判断力 他只有概率 在他的这个训练数据里呢 可能有1,000种修复bug a的方式 也有1,000种修复bug b的方式 但缺乏一个核心的东西 他不知道自己在宏观上 是不是在往正确的方向走 他就像一个没有指南针的探险家 每一步做的很自信 但整体呢 是在原地打转 这就是我们必须面对的 一个反直觉的事实啊 只是堆彻更多的数据啊 可能永远无法解决这样一个问题 要理解 为什么我们会在这种问题上卡住 我们要看懂啊 AI到底是吃什么长大的 在过去很长一段时间里呢 训练AI的逻辑非常简单粗暴 就叫做预训练Pre training 这个阶段的原则只有一条啊 就是九品芝麻官里头 那个豹子头的那句话啊 我全都要 你想要教AI懂中文啊 没问题 把中文互联网所有的文章都喂给他 你想教他学编程啊 把GitHub所有的开源代码都喂给他 你不需要思考选什么数据 因为最好策略呢 就是给所有的数据 这就像那种1万小时定律的极致版啊 只要书读得足够多 哎甚至都不用理解 也能够熟读唐诗三百首 不会作诗也会吟啊 但是呢这种暴力美学 现在已经撞上了一堵墙了 首先呢 数据快不够用了 这个高质量的人类文本是有限的 我们快把这个互联网都吸干了 你看到各大领先的模型啊 他们基本上训练的这个数据集 都是一样的 第二呢就是有些东西啊 是书本里头没有的 你在书上读了一万遍 骑自行车要保持平衡 和你真正跨上自行车摔的那一跤呢 完全是两码事 书本数据能够教AI知识 但它不会教给他经验和手感 伊尔亚在访谈中呢 非常隐晦但是也非常坚定的指出啊 那个简单粗暴的为更多数据的时代 也就是那个scaling law啊 缩放定律躺着就能赢的时代 现在呢可能正在发生微妙的变化 这样的论点呢 其实之前我们做过这个Gary Marcus 他的这个节目中啊 也强调了同样的观点啊 最近这个Yann LeCun也跑出来说啊 这个Scaling要不行了 但是呢 我看到这俩人开始在这个推特上 互相开始喷了啊 因为这个加里马库斯说啊 这个我最初提出这个观点的时候 你Yann LeCun还过来喷我啊 现在你跟这个立党一样啊 摇身一变 变成这个scaling up不行的这个鼓吹者啊 这算什么 这里扯得有点远了 那我们回到主题啊 如果说所有数据都喂完了 AI呢还是 那个只会写死循环代码的卷王 那下一步我们应该怎么办呢 伊尔亚在访谈中啊 给了一个非常有意思的视角 他（伊尔亚）自己本人呢 曾经就是这个扩展定律啊 scaling law最坚定的信徒 这是他当年在openAI啊 力排众议啊 喊出哎我们大力出奇迹 把模型做大的口号 才有了今天的这个ChatGPT的突破 但这次对话中呢 他抛出一个震耳欲聋的观点啊 他说这个scaling 已经吸干了房间里的所有空气 伊尔亚认为啊 2012年到2020年是研发的时代 那个时候呢 算力是瓶颈 但是呢 从2020年到2025年呢 AI的进步就变成了工业制造 因为大家发现了一个非常简单的配方 就是算力乘以数据 就等于智能 所以呢大家都不用动脑子 只需要疯狂买显卡 疯狂抓数据 这个模型就会自动变强 这导致的一个结果啊 全世界的公司都比想法多 大家都拿同一个配方在卷 但现在呢 伊尔亚认为啊 我们又从那个扩展时代 退回到了研究时代 这意味着呢 仅仅把模型做大100倍啊 可能也不会发生 奇迹我们需要新的配方 我们需要搞清楚啊 那个练了100小时 就能够学会开车的人类大脑 里头到底藏着什么AI没有的秘密 为什么人类不需要 阅读10亿篇关于驾驶的论文 只需要在这个停车场转个两圈 就能够学会倒车入库呢 为什么人类不需要把代码改错1,000次 就能在心里知道哎 这个方向可能不对 接下来这部分呢 我们就将触及AI领域最核心的圣杯啊 伊尔雅认为 解开这道谜题的钥匙 其实藏在一个 如果你下过国际象棋就会懂的概念里 价值函数value function 如果你教过别人开车啊 或者你自己学过开车 你就知道啊 这事其实没那么难 一个完全不会开车青少年呢 大概只需要10-20个小时的练习 就能够及格上路了 在这个过程中呢 他可能连一次车祸都没有出过 现在来看看AI 为了让这个自动驾驶AI 学会同样的事情 科技巨头呢 为了他数十亿英里的真实路测数据 甚至加上更多虚拟的仿真数据 结果呢 他依然会被一个突然飞出来的塑料袋 或者是一个穿着玩偶的路人啊 搞得不知所措 这就是AI领域目前最尴尬的软肋 这个样本效率sample efficiency极低 人类大脑呢 就像一块海绵啊 你滴几滴水就能够吸饱 而现在AI就像一块石头 你得把整条河 流倒在它身上 它才能湿那么一点点 有的科学家呢 就试图用进化论来解释个差距啊 他们说哎 你看人类之所以学这么快 是因为我们祖先啊 在这个几百万年的进化里 把怎么识别物体 怎么运动的本能 都已经写进基因里了 那个你口中的青少年 他不是从0开始学的 他是带着几万年的外挂在学 这个解释呢 听起来很合理 对吧但是伊尔雅并不认同 他在访谈中反驳道说 如果说 视觉和运动是这个进化送的外挂 那数学和编程呢 我们的祖先可不需要解微积分啊 也不需要写Python代码 进化并没有给我们预装这些编程包啊 但是现实是呢 一个聪明的人类 只要看几本教材 做几十道题 就能够学会微积分 而AI呢 依旧需要把人类历史上所有的数学书 都读一遍 才能够达到类似的水平 这意味着 人类大脑中呢 一定运行着一种 比现在这种深度学习啊 更高级更高效的学习机制 这个机制是什么呢 伊尔亚给出了他的答案啊 我们拥有一个内置的裁判 要理解人类为什么学得快呢 我需要引入一个核心概念 叫做价值函数 value function 这什么意思呢 伊尔亚用下国际象棋 做了一个绝妙的例子啊 想象一下 你正在下一盘棋 你经过深思熟虑 哎走出了一步 就在你手指松开棋子的一瞬间 甚至松开那几毫秒 你心里会突然咯噔一下 你知道你搞砸了 你送掉了 你的皇后 虽然对手还没有动 但是离你被将死可能还有20步 你已经知道这局棋输了 这咯噔一下的感觉啊 就是价值函数在工作 他不需要等这个游戏结束啊 game over才告诉你这个输赢 他在中间过程呢 就能够给你打分 他让你短路掉无数个错误的尝试 你不需要把这盘必输的棋下完 你脑子里的裁判直接吹哨停 哎这个方向是死路 下次别这么干了 这就是目前大多数AI所缺乏的能力 传统的AI训练呢 特别是早期的强化学习啊 往往要等到这个事情彻底做完了哎 比如说车撞了 游戏输了 代码运行报错了 才能够得到第一个反馈信号 这就说啊 你只有考完试拿到0分卷子 你才知道自己学错了 而人类呢 我们其实做题做到一半的时候 就会有一种感觉 这道题越算越复杂 我是不是公式用错了 这种过程中的直觉啊 其实极大地节省了我们试错的成本 如果说能给AI装上这种内置裁判 让它拥有这种预知好坏的直觉啊 它是不是就能够像人类一样 高效地学习了呢 到这里你可能会问啊 人类这个神奇的价值函数 到底长什么样呢 伊尔雅给出的答案既浪漫又硬核 在这个生物体中呢 它经常被称为是情绪 我们通常认为理智是高级的 而情绪是低级的 是这种原始的干扰 如果你看过一些行为心理学家的书 他会认为啊 人类的这个情绪 会导致人类做出错误的判断 的主要原因啊 但是呢从AI科学家的视角来看 这个情绪其实是一个高度情绪呢 其实是一种极度高效的算法 压缩神经科学 里头有一个著名的案例啊 有一些病人 大脑的情感区域受损 但是逻辑区域完好无损 你以为 他们会变成冷酷无情的逻辑机器吗 还并没有 他们变成了决策瘫痪机 比如早上选袜子 一个正常人呢 大概需要2秒钟 凭感觉就选一双顺眼的 但失去了情感能力的病人啊 会站在衣柜前花费几个小时 他会列出所有的逻辑可能性 哎今天的温度 袜子的材质颜色的光谱分析 因为他没有那个喜欢 或者感觉好的价值函数 帮他快速剪断决策树 他就陷入了无限的计算死循环 在伊尔雅看来啊 进化给我们大脑里头 硬编码了一套价值函数 哪怕你还没有吃到那口发霉的食物啊 你的厌恶感啊 这个value function就已经让你想吐了 这就是为了防止你中毒啊 哪怕你还没有被踢出部落 你的羞耻感就已经让你脸红了 这就为了防止你社会性死亡 这其实给AI研究一个巨大的启示 如果说我们想制造这种超级智能 我们不应该试图消除他的直觉 反而应该叫他 形成某种类似于情绪价值判断机制 不是为了让他多愁善感 而是为了让他 从海量的计算泥潭中拔出 腿来快速的做出 快速的做出决定 这个概念其实很有意思 就是我不知道大家有没有读过那本啊 thinking fast and slow啊 思考快与慢 这本书里头呢 提到了两种思维模式 第一种系统一 就是伊尔雅所说的这种 用情绪去做快速决定 系统2呢 是非常耗时的 就是要进行逻辑分析和推理判断 那么在伊尔雅看来啊 这个人工智能 其实恰恰缺的是人类的这个系统一的 这样一个情感的判断啊 这是非常有意思的一个观点啊 那么既然我们不能够把人类的情绪 直接拷贝到代码里 工程师是怎么做的呢 哎这个伊尔亚给出答案 就是让AI成为自己的老师 这其实并不新鲜啊 当年的这个Alphago 之所以能够横扫围棋圈啊 就是因为 他后面就不再看人类的棋谱了 开始左右互搏啊 self play他自己跟自己下了几千万盘棋 在这一局里呢 黑棋赢了 这说明刚才黑棋某种新下法是好的 这就是一种极其清晰的价值信号 在这个封闭的棋盘宇宙里啊 他无师自通 进化出了人类从来没有见过的招数 比如说著名的第37手啊 现在呢伊尔雅和他的同行们 正在做一件更疯狂的事情 他想把这种左右互搏啊 从这个围棋扩展到所有领域 这也就是大家可能最近听到的 这个OpenAI的o1模型 或者是类似模型背后的逻辑 这个思维链chain of thought 现在AI在回答你的复杂问题之前啊 它不再是张口就来了 而是呢它会在心中啊 也就是后台先建立 先进行一场激烈的自我辩论 哎我想这样解题 哎等等 这步好像有点逻辑漏洞 价值函数报警了 我再换个方法试试 嗯这个方法看起来更靠谱 虽然它目前还不完美 但这意味着 AI开始拥有那个虽然还没有交卷 但我知道我写错的能力 一旦这个能力被打通呢 那个需要10亿英里数据 才能够学会开车的笨拙时代 可能就要结束了 最后呢让我们来看一张图啊 这张图解释了为什么e r啊 说啊现在这些AI公司正在把钱呢 花在不一样的地方 在过去几年啊 大家几乎把钱都花在预训练上 这就像给AI啊 送进图书馆 花巨资呢 让他把这些书都背下来 这是一次性投入啊 背完了就是背完了 但你现在看到这个飞速增长的区域啊 就是推理计算 inference compute和强化学习的区域 这什么意思呢 就说把AI从这个背书模式 变换到了考试模式 如果你问AI一个简单问题啊 这个法国首都在哪 他会秒回答巴黎 他不需要思考 这就是预训练的知识 但如果你问他 如何设计一种 不仅能够通过药监局审批 还能够在成本上 打败现有竞品的新药分子 打败现有竞品的新星耀分子 这就不是能靠背就能解决的 现在AI公司呢 正在用算力啊 让模型思考的更久 不是让他马上回答 而是给他10秒一 分钟甚至1小时的算力 让他在后台呢 进行成千上万次推演模拟试错 就像Alphago啊 在脑子里下了1,000盘棋一样 最后呢 再给你那一个经过深思熟虑的答案 这就是所谓的system two慢思考 伊尔雅认为啊 这个转变是质变的前夜 当AI开始花时间思考 而不仅仅是检索时 他就不再是一个在大英图书馆里 翻书的这个图书管理员了 他开始变成一个坐在实验室里 眉头紧锁 在草稿纸上反复推导公式的研究员 而当这个研究员的思考速度 比人类快1万倍时呢 我们之前所提到这个经济奇点啊 可能就要真的降临了 那么当这样一个超级大脑 真的被制造出来时候呢 我们应该如何确保 它还是站在我们人类这一边的呢 或者更激进一点啊 伊尔亚提出那一个让人毛骨悚然的问题啊 就是 我们真的应该让他优先保护人类吗 这个萨顿也提过类似的观点啊 这个萨顿认为不需要啊 但是伊尔亚呢 肯定是有不同的看法的 如果说伊尔亚 关于价值函数和慢思考的预测成真啊 那么我们未来几年呢 将看到AI的形态会彻底突变 现在AI本质上还是一个工具 你需要拿着它呢 像一个锤子一样去敲钉子 但是未来的AI呢 更像一个超级实习生 想象一下 你招了一 个实习生 他刚来的时候什么都不懂 但他呢拥有我们上一集所说的那种 通用学习的能力 你把公司文档告诉他 让他看几个现有的案例 第一天呢 他还是小白 到了第三天 他可能已经像老员工一样能干活了 第五天 他已经读完了行业内所有论文 变成了这个领域的专家 更可怕的是呢 这个实习生他不需要睡觉 而且呢你可以瞬间复制1万个他 伊尔亚在访谈中描绘了这样一个图景啊 一旦AI打通了像人类一样学习的关卡 他就会以数字员工的身份 大规模的进入经济系统 这不仅仅带来效率提升 而且呢 会把这个经济增长的物理极限给打破 当研发工程 甚至是管理工作 都可以被无限复制的算力所替代时呢 我们可能会经历人类历史上 最疯狂的经济大爆炸 但紧接着呢 一个巨大的阴影就会笼罩下来 如果这个实习生比你聪明100倍 比你努力1,000倍 而且他还掌握着这个公司的所有命脉 那么谁才是真正的老板呢 这里 我们就要触及一下房间里的大象了 权力 伊尔亚的对话中非常直白的指出啊 AGI的核心问题其实就是权力的问题 我们在地球上处于统治地位 并不是因为我们牙齿锋利 也不是因为我们力气大 纯粹是因为呢 我们人类啊 比其他物种聪明 我们就凭这一点点智力的优势 决定了老虎你得住在笼子里决 定呢哪片森林被保留 哪片被砍伐 那么如果我们亲手制造出一个 智力远远凌驾于我们之上的东西 那这权力天平会发生怎样的倾斜呢 很多乐观主义者说啊 没关系这个AI只是软件 我们拔电源不就行了吗 但 当你面对一个比你聪明1,000倍的对手 你觉得他会让你有机会拔电源吗 他可能会通过操纵经济操控舆论 甚至雇佣其他人类来保护自己 这就为什么伊尔亚离开了Openai 创造了SSI safe superintelligence 你看这个公司的名字啊 超级安全智能 它把这个安全放在了超级智能的前面 这不仅仅是一个商业决策 更像是一个生存赌注 为了赢得这场赌注呢 伊尔雅采取了一个极其反共识的战略 啊叫做直奔超级智能straight shot 关注我们频道的朋友应该都知道啊 现在这个硅谷AI的战争 就像一个赛车比赛 各家不停的推出各种新的模型 open AI谷歌Anthropic 大家都在争分夺秒的发布新模型 逻辑就是呢 我们必须先把这个产品推向市场 哪怕它不完美 我能从用户的反馈中学习 快速迭代 这确实也是互联网时代这个黄金法则 但是伊尔雅的新公司SSI 选择一条极其孤独的路 它称之为啊 直奔超级智能 它逻辑是呢 如果你陷入了商业竞争 这样的老鼠赛跑啊 你就身不由己了 为了抢夺市场份额 你会被迫在安全线上妥协 你会让模型啊 早发一个月 而跳过那几个关键的安全测试 而在面对超级智能这种级别的力量时 呢一次微小妥协 可能都是全人类的终局 所以呢SSI的计划听起来非常复古 他们不准备像发iPhone一样 每年搞个发布会 他们准备 像当年的这个曼哈顿计划一样啊 在一个封闭的实验室里 用几年时间 利用我们之前所提到这个研究范式 直接攻克那个最终极 最安全的超级智能 在这期间呢 他们可能没有任何产品 也没有任何收入 甚至会被外界嘲笑啊 掉队了这其实需要巨大的定力 掉队了这其实需要巨大的定力 也需要承担巨大的风险 如果他们赌输了 他们 就只是一个烧光了几十亿美金的笑话 但如果他们赌赢了呢 他们带回来的必须是一个好的神 问题是什么是好 我们应该给这个神 设定什么样的道德标准呢 这可能是整个对话中 伊尔雅最具颠覆性的观点 以前我们谈AI安全啊 对齐 大家第一反应就是让AI听人类的话 或者是让AI遵守人类的价值观 这听起来没有毛病 对吧但是伊尔雅反问啊 哪个人类的价值观 是美国人呢 还是中国人呢 是21世纪的人类价值观 还是19世纪的 人类的价值观 本身就充满了矛盾偏见和混乱 甚至我们人类自己 经常为价值观打的头破血流 如果你把这些混乱的规则写 进超级人工智能的代码里啊 你可能会造出一个精神分裂的怪物 这里呢 伊尔亚提出一个更底层更朴实的矛点 对齐感知生命 什么叫做感知生命呢 就是一切 能够感受到痛苦和快乐的存在 包括人类 包括动物 甚至可能包括未来 那个拥有自我意识的AI 他自己伊尔雅认为啊 与其叫AI复杂的人类礼仪 或者是法律条文 不如叫它一个最简单的元规则 关爱那些能够感知痛苦的存在 这听起来有点像佛教的这个慈悲啊 或者是某种宗教情怀啊 这个伊尔雅在采访过程中 也经常提这个佛教的理念 但在工程上呢 这可能比人类价值观更加robust啊 用中文就说更鲁棒 因为这个痛苦 他是生物学上的一个客观信号 比正义或者自由 这种抽象的概念呢 更容易定义 如果一个超级智能 他不仅聪明 而且呢他真的在乎你不受痛苦 像一个慈悲的长者爱护孩子一样 那也许呢 是我们唯一的生路啊 当然了即使AI真的爱我们 那还有一个更现实的问题 就是自尊啊 如果这个AI把一切都做完了 它治好了癌症 管理了经济 甚至写出比莎士比亚更好的文章 那人类干什么呢 我们是变成那种 被精养在动物园里的宠物 还是变成整天戴着VR眼镜 混吃等死的废人呢 伊尔亚 提供了一个不想接受 但是可能不得不接受的解决方案 融合如果说 如果说我们要跟上这个AI的步伐 参如果 我们想要保持在这个世界上的参与感 我们人类可能要通过脑机接口啊 比如像Neuralink这样的技术 直接把AI带宽呢接入我们的大脑 我们将不再是单纯的智人 我们将变成这种cyborgs半机械人 通过这种方式呢 AI的超级智力啊 变成了我们自己的扩展 这时候呢 甚至人类和AI的界限都会消失 我们就是他 他就是我们 这听起来非常赛博朋克啊 甚至有点恐怖 但是就像伊尔雅说的 这个变化是唯一的永恒 这也是一个佛教的概念啊 几千年前呢 我们通过发明语言和文字 把大脑外挂到了书本上 这本身就是一种融合 或许呢 脑机接口只是进化的下一个必然阶段 最后呢伊尔亚 给出 他对于超级人工智能到来的时间 预测 5-20年 这在历史的长河中呢 不过是一眨眼的时间 也许就在你还房贷这几年里 也许就在你孩子上大学之前 这世界将经历一场 比工业革命和电力革命加起来 还要剧烈1,000倍的变革 我们今天所讲的一切 从预训练的平静 到价值函数的觉醒 再到爱众生的伦理 并不是为了吓唬大家 而是为了 让我们在面对一些眼花缭乱的新闻时 呢多一份清醒 不要只盯着那些股价和融资数字 去关注真正 重要的问题AI开始学会慢思考了吗 算力的重心开始转移了吗 我们是否为对齐做了真正严肃 认真的准备呢 正如伊尔亚所说啊 这不仅是关于制造更聪明的机器 这是关于我们如何定义文明的未来