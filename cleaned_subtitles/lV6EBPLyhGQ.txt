Hello 大家好 欢迎收听硅谷101 我是泓君 最近我看到哈佛大学经济学家 Jason Furman（杰森·弗曼） 他的一个研究数据很有意思 他是说在2025年的上半年 整个美国GDP的增长 几乎会全部来自于 人工智能的基础设施建设 如果说我们把信息技术 还有软件这一部分拿掉 那美国GDP的增长 仅仅就只有0.1% 最近还有一个大新闻 大家可能都看到了 OpenAI发公告说 它自己完成了一个公司架构的重组 而这个重组的目的 是为潜在的IPO铺路 核心也是说 它未来会承诺1.4万亿美元 在整个AI的基础设施的建设上 还有一个消息 大家可能没有注意到 就是在它完成架构调整的前一天 它发了一封公开信致信白宫 在这封公开信里面OpenAI提到 中国2024年 新增的电力是429吉瓦 而美国仅仅贡献了51吉瓦 所以它希望美国政府 对AI基础设施的建设项目 能够优先审批 为什么这些公司都那么激进 最根本的一点是因为 大部分公司现在都意识到一点就是 on Underinvestment is riskier than over investment. 就是所谓的投资不够 给你带来的风险 要远远大于 你过度投资带给你的风险 对 因为没有人想当诺基亚 在之前我听到OpenAI这个 5000亿美元的星际之门项目 就已经觉得非常夸张了 但现在这个饼 已经是画到了1.4万亿美元 而美国也需要基础设施的建设 这是一个比想象中更加疯狂的 大基建时代 美国极少数的科技公司 联合金融巨头 正在不成比例地对美国经济 产生决定性的影响 我们先抛开钱从哪里来的问题 我们这一集就来看一看 这一轮AI大基建 它带火了哪些行业 而为何美国的电力建设 又如此得困难 下面就请收听我们今天的节目 今天我们来聊一聊 AI军备竞赛背后 数据中心与能源之争 今天跟我们在一起的嘉宾 一位是Ethan徐 Ethan现在是在字节跳动 做数据中心与能源的项目经理 大家好 Ethan在去字节之前 是在微软负责 数据中心跟能源的项目 再之前是在Bill Gates下面的 突破能源基金 没错 也是做了很长时间的 能源相关的项目 也是在两年前AI大爆发之后 加入到了数据中心和能源 在一起的赛道吧 算是 那还有一位是王辰晟 王辰晟之前是特斯拉的供应链总监 马上也要加入xAI 大家好 如果让大家总结一下 就是现在我们看所有的AI巨头 都在去做数据中心 你们觉得哪几家做得最猛 当然新闻报道上是OpenAI跟微软 5000亿Stargate项目 第二个是最近OpenAI跟甲骨文 也是在合作一个3000亿美元的 数据中心的项目 当然这个中间是有重合的 但我知道其实马斯克他的xAI 在布局数据中心跟抢货方面 也是非常猛的 扎克伯格也是在全力投入的 所以从你们的角度来看 你们觉得哪些公司最激进 以及他们的策略是什么 OpenAI他的野心是非常非常大的 现在他公布出来的数据是 要做10个吉瓦的Stargate的项目 我觉得这可能只是一个刚刚的开始 他的野心可能是这个的10倍 甚至更多 在未来的比如说5-10年 他们想实现的一个目标 十倍 5万亿的一个产业 我觉得这个数量级 是基本上没有问题的 美国现在的GDP是多少 二十几（万亿美元）是吧 差不多它这个就要占GDP的 当然也不是一年 对 整体上占一年 整个美国GDP的25%了 我觉得是很高的 我们可以拭目以待 看一看今年美国的GDP增长当中 有多少是数据中心基础建设贡献的 我觉得这个比例有可能会到70% 我也不会很吃惊的 你有可能低估了 甚至有可能低估 对 我也看过一些黄仁勋 或者是一些咨询公司的观点 他们也认为在未来的五年 整个的数据中心 基础设施建设的投资规模 应该是到5-7个万亿这个级别的 钱从哪来 钱从哪来 确实是一个很有意思的问题 我记得你们之前做过一期节目 就是讲钱从互相之间的循环经济的 AI资本论循环 未来也是一种比较创新的融资方式 辰晟怎么看 哪一家最激进 OpenAI肯定是相对比较激进的 因为你看它现在很多公告 它未来几年跟英伟达 有一个10吉瓦的意向 AMD有一个6吉瓦的意向 同时最近还有博通 还有一个10吉瓦的意向 所以加起来就已经是26吉瓦 500亿一个吉瓦 就已经是一个1.5万亿的一个概念了 未来五年 对 同时它在一些供应链上 它也非常激进地做其他一些布局 最近有跟三星和海力士 包了一个90万片晶圆每月的产能 它基本上占了整个DRAM 就是市场可能1/3 HBM市场60% 就它一家 如果你是马斯克或者你是小扎 你看到这个你会怎么去应对 因为你也不希望被他们卡脖子 所以每一个公司 现在从供应链角度 可能做得都不一样 马斯克xAI去横扫了 所有的小型的涡轮的发电机 Meta其实过去几年来说 就已经做得非常激进 去各种买一些能源 相对成本比较低的地 去建它的数据中心 最近是在爱达荷州还是俄亥俄州 又一个5吉瓦去上线 它的规模基本能占大半个曼哈顿 谷歌它也会做一些供应链上的布局 比方说把他们一些 无论是互联也好 一些光缆也好 他们都会做非常激进的 供应链上的产能的买断 所以说其实每个巨头都在发力 都不想在这个竞争当中 去输人一头 微软我们好像没有提到 微软的话其实也蛮有意思的 它去年的时候跟OpenAI的合作关系 是非常融洽的 但是在年初的时候 大家也看到一些新闻 提到关于OpenAI和微软的关系 已经有了一些变化 包括OpenAI开始去找Oracle 或者其他公司合作建数据中心 所以微软不是它唯一的 数据中心提供商了 同时微软可能也在某一些数据中心 开始暂停施工 或者是退租了一些数据中心等等 我们在看最近这几个月的发展 能够感觉到 微软在数据中心投资这方面 是和其他公司比 是相对比较稳健一些的 OpenAI就完全是另外一种风格 都是每一两个星期 就会有一个非常大的公告 说我要建5个吉瓦 7个吉瓦的数据中心 和普通的公司合作 和整个产业链合作 所以能看出这两个公司 可能在AI数据中心 或者整个数据中心行业的 投资和策略方面 会有一些不同了已经 对 所以就是说 微软中间稍微缓慢了一点 最近又在加速 对 现在能看得到 微软比如说最近刚刚宣布了一个 全世界最大之一的 AI的数据中心刚刚落成 所以今天看到的微软 可能跟年初的时候看到的微软 可能又有一些不一样的变化 我觉得这个行业的变化 确实还是蛮快的 可能年初的时候我记得微软的CEO 也在公开的采访中提到过 他觉得这个行业 是有一些过度建设的 然后他觉得有一些泡沫 他是想用更稳健的方式 去建设数据中心的 但是我们现在看到的是 微软速度也蛮快的 可能并没有像年初的时候说的那样 很快地慢下来 所以我猜想也许各个公司的高层 在这一年过程中 他们的策略和想法上 是有一些波动的 但是此时此刻的话能感觉到 所有人都基本上是全速前进了 我觉得几个巨头 包括Google 亚马逊和微软 他们的态度可能是因为 他们过去在云上其实有很多的 这个data center的投入了 像Google Microsoft他们现在 已经有的data center 可能已经超过10个吉瓦 对于像OpenAI 就从0开始发展的话 大家需要的增长速度是不一样的 因为它的基数不同 反馈出来他们的激进程度 可能也会有不同的地方 这个点很关键 这是为什么 我们现在经常听到的名字 是Meta xAI还有OpenAI 而不是这些云厂商的巨头 像Google 亚马逊和微软 我们刚刚其实提到了OpenAI 它其实在做Stargate的项目在抢地 在跟芯片厂商去达成合作 马斯克其实也是在抢发电机 Meta也在抢地 我是在想 那你的芯片供应其实也就这么多 大家不会在某种程度上 是都有短缺的吗 从纯产业链的产能来讲的话 芯片现在并没有像能源 这么紧缺的一个状态 如果你每一片（芯片） 把它用到刀刃上 从台积电的产能 它也是在积极地去布局 所以它相对是比较充足的 包括像台积电 可能两年之前有在说 CoWoS它的先进封装的产能 会有些落后 但是它最近也在说 在亚利桑那州要建两个晶圆厂 其实这些产能已经在过去两年 经历这个cycle的时候 他们已经有在去做投资了 我只能相信老黄 他的直接声明是对的 在GPU的芯片的供应上 肯定是不缺的 但是可能会有一些 别的配套的产业上面 会有一些额外的缺口 包括我刚刚提到的存储器 无论是说线束也好 甚至于一些数据机柜 但是可能这个缺口相比能源来说 它并没有那么大 我觉得这点可以补充一下 像我能看到的一个比较重要的 几个策略上的观点 一个观点就是 我们刚才一直在聊的 所谓的电力优先 或者是power first这个策略 因为大家都已经明显看到 可能最缺的就是电 谁能拿到电 就意味着你能买更多的GPU 你就更有可能训练出更好的模型 你就可能获得更多的用户 更好的用户体验 从而占据更大的市场份额 而这样的市场份额 可能会给你带来更多的营收和利润 然后又可以再次循环到 我拿这些营收和利润 去买更多的电和地 继续让我的模型变得更好 所以Power First这个策略 在很多大型公司里边 是一个非常重要的策略 还有另外一个策略是 大家都考虑到的 就为什么这些公司都那么激进 最根本的一点是因为 大部分公司现在都意识到一点 Underinvestment is riskier than over investment 就是所谓的投资不够 给你带来的风险 要远远大于你过度投资 带给你的风险 为什么会这样呢 像AI这个行业 大家目前可能有一个大致的共识 就是很有可能谁最先获得 最好的AI模型 或者所谓的AGI的话 这家公司就会占据比较大的 一个市场份额 其他公司的生存空间 就会很快地缩小 所以投资不够的一个风险 是非常大的 我们再看一下 过度投资会有什么样的风险 你无非就是买了更多的地 更多的电 更多的房子建数据中心 最后你发现可能你买多了 无非就是你可以把它用作 自己公司内部的一些使用 效率的提升 或者你可以把它租给其他人 或者就把这些地 电 卖给其他公司 总体来说就是过度投资的风险 它实际上是有一个封顶的 因为它其实都是固定资产 然后这些固定资产你转卖 它也是容易的 也是容易的 比如说GPU你买多了 那你卖给其他公司也没有什么问题 所以它过度投资的风险 相对来说是比较小的 而对于某些大的科技公司来说 如果投资不够 导致它没有在这场竞争中胜出的话 它有可能面对的是一个 生死存亡的一个境地 所以这也是为什么绝大部分公司 他宁愿多投资 哪怕华尔街现在已经有一些质疑了 是不是过度投资了 你们能不能收得回利润来 这个营收 能不能覆盖住你们这个投资 甚至股价上也开始反映出来了 但是这些公司 我觉得现在都没有一个眨眼睛的 都是继续在加大投资 像所有公司今天说的话都是 我们年初的时候 预算今年会投资这么大的规模 已经很震惊市场了 但是现在看起来我们还是投资的 没有我们应该投资的那么多 所以这也是 投资不足比投资过度风险更大的 这个策略 对 因为没有人想当诺基亚 你跟股东说我4万亿的市值 会变成3万亿的市值好呢 还是说我的4万亿的市值会变成0 然后你更多是说有个梦想说 我现在投资 如果我经历过这一场退潮 然后我活下来其他人死掉了 我就从4万亿可以变成10万亿 这是大家更喜欢听到的一个故事 不代表它就一定会发生 还有一点 在硅谷有一句话就是 比尔总会吃掉安迪 Andy是代表Andy Grove 英特尔的一届CEO Bill是比尔·盖茨 所以就是说你只要有基础设施 你只要有硬件 软件总有些办法可以想办法 把你（的资源）运用掉的 这周早些时候OCP Meta的人就在里面说 其实他们目前的GPU 光用来去做他们内部一些AI 比方说Instagram或者Facebook 然后去筛除一些不合适的这些内容 他们其实也已经要需要很多算力了 他就算有多余的闲置的算力 他用来做内部的降本 cost reduction 他其实也是完全是可以用的 所以我觉得现在主流的这些公司 都不会担心说 这些会过度投资 然后他们没有办法去用掉 而更多的是说 我怎么把我有的这些资源 去做更好的配置 去扩大他的利润和收入 我可以稍微补充一下 Ethan刚刚讲的一点 就是为什么大家要建大的数据中心 有两笔账 一笔就是经济账 Google自己也有发布过说 我在爱荷华州去建一个 1吉瓦的AI data center 比同样分布式的 它一年可以省5亿美金的运营成本 因为它更加高效 无论是从输电 冷却 运营来说 这是Google一年在1吉瓦的 这个数据中心可以省5个亿美金 同时从一个AI算力的 训练的这个角度来讲 比方说GPT-4 按照以前一张H100的卡 需要差不多16000张卡 90天的时间去做这样一个 1.7万亿的数据量的模型的训练 如果到GPT-4.5 它可能是10的26次方 它需要的可能是一个两三倍的卡 甚至于说一个GB200 25000张卡也需要90-120天去计算 在这样一个AI军备竞赛的前提下 你肯定是不希望 你需要花一个季度甚至以上 3-4个月才能训练出一个模型 你更加希望的是 你每一周或者每两周 可以去有一个模型 然后你不停地去进步 不停地去迭代 所以它会造成了一个 指数级别（的需求） 所以从一个万卡集群 变成十万卡集群 甚至到百万卡集群 而且你可能需要训练 更大的一些数据模型的体量 这样就会把整个 AI data center的算力 从以前一个30兆瓦的 AI data center 推到一个可能1吉瓦 甚至于5吉瓦的 这样一个data center的体量 因为大家都不想输 那我再问一个更底层一点的问题 大家为什么需要 建这么大的数据中心 我知道大数据中心 跟小数据中心是一个问题 还有一个更底层的问题是 你们觉得这个数据中心 未来用的更多的 是做这个模型的训练 还是用作应用方向 就是说我们还需要 这么大规模的预训练的电量吗 还是说它只是说大家都开始用AI 代替日常的这种搜索 代替日常的这种应用 它的整个的产业规模会很大 就是这个数据中心是支持谁的 两年之前的话 大家主要可能有60%-70%算力 是用于做预训练的 当然预训练也有它自己的瓶颈 包括现在有很多不一样的 工程上的（优化） 无论是从有专家的模型 包括说有一些训练后 去做强化学习的 这些都是一些厂商觉得 怎么样提高这个模型的效率 而从预训练转换成一个 后训练的过程 同时因为这本经济账 大家要确保我有收入 训练是不能给你带来收入的 而一定要从应用 或者订阅交的会费 才能给你带来收入 所以大家现在所有的大厂 都是转型到了 把更多的资源用到推理上 今年早些时候 推理和训练的比例 已经转成推理会占比更高 可能有六成 训练是四成 我的理解是 它之后可能推理的比例会大大增高 甚至占到80%以上 所以我理解现在的数据中心 是给这些AI厂商做推理来用的 我基本上同意这个观点的 就是在未来的话 一定是推理和应用 那方面的数据中心的利用 或者是能源的利用 那个一定是会占比越来越高 而且是占大头的 但是当然了 AI的训练它是需要不断地去迭代的 会有更好的模型出来 所以那个一定也会有一定的占比的 但是很高兴看到 推理的占比越高 意味着它越来越多的 在应用层面开始创造出价值 就像微软CEO之前说的 AI只有在真正创造GDP的时候 才是有价值的时候 那个也是真正关键的时候 所以根据你刚刚的观点 就是现在大公司他们如果激进 他们可能留下的是一堆的固定资产 如果往回撤的话 那他未来可能他要发展 所有这些AI应用 他后面的算力跟不上 整体大逻辑是这样子的 对的 是这个逻辑 那我们一定需要 这种大的数据中心吗 小的数据中心行不行 就是我们零散地把一些 我假设就是居民用电的 这些闲置的电集中起来 然后再做储能 再分配给各个应用或者大厂 这种方式是有可能的吗 它有一个基础 如果是做训练的话 它其实这个规模可能不太允许 它去做这样的一些调整 因为它需要所有的data 再同时进行计算 需要机柜和机柜之间的互联 所以它需要一个大的集群 但是如果去做推理的话 它其实是可以根据用户的需求 去进行一个合理的配置 然后用现在的闲置的算力 或者电力去做的 这个有点像以前PPTV 或者说类似于这样的一些产品 确实现在也有一些公司 在用闲置的算力去做 比方说novita 它是一个新兴公司 更多的就是用闲置的这些算力 提供一个更低成本的算力 相比别的供应商 可是你作为一个大厂的话 你更多的是说 要去算一笔经济账 无论是说我用户需求的时候 我是不是它一直有可用性 它一直能去调用这些算力资源 同时如果是分散的话 它的管理物流各方面 它其实是没有效率的 包括我刚刚也提到 如果它有个大的规模集群 它又可以用来做训练 等到不需要训练的时候 把这些用来去做推理的话 其实这个经济账是更容易算的 因为它能更好地去做 整个电力的分布 以及它的一些备电的备份 甚至于说冷却当中的这些运营成本 它都是可以大大降低的 没错 我也非常赞同 可能要看具体的应用是什么 它可能会决定 对数据中心的要求是什么样的 举一个例子 现在大家也有一个初步的共识 就是对于AI的训练来说 也许这样的数据中心 并不需要离大城市太近 也不需要可靠性太高 因为可靠性不高的后果 无非就是影响了一下 你公司内部的一些 研究人员的进度 一些AI的云厂商 如果他要提供给第三方客户的话 他的可靠性可能需要达到 所谓的5个9这样的可靠性 就是99.999%的可靠性 但是对于AI的训练来说 也许不需要达到那么高 也许3个9 99.9%就可以了 而这些AI的数据中心 又需要很多能源 所以也许它可以建在 离能源更接近的地方 就比如说OpenAI他们这个策略 我觉得就是非常好的策略 他们是把他们的Stargate的 很大一部分项目 放到了德州的西部 而那是一个又有风又有光 同时还有一定的 电网接入能力的地方 而且还有大量的地 这就非常适合做AI的训练了 所以它并不是所有的数据中心 都需要和客户离得那么近 所以这个时候 在资源非常紧缺的情况下 可能就可以根据你的应用的不一样 去看你的数据中心要建在哪个地方 去实现什么样的目标 数据中心首先我们说 它需要有电 其次它还需要有发电机 跟各种各样的小型的 我们可能想不到的设备 比如说变压器 还有一层 就是它需要有芯片 这三个问题怎么解决 我觉得我们今天可以 一个一个地来分析一下 首先是数据中心 现在的电从哪来 Ethan我记得你之前 其实在我们节目上讲过 整个美国的电 它是处在一个比较稳定的增长状态 但从今年的数据来看 还是这个样子吗 我记得在上周 黄仁勋和一个CNBC的采访中 他也提到 它可以生产出 整个市场所需要的GPU没有问题 但是现在最大问题是没有电 你有了GPU你没有电 你也没办法去运行你的数据中心 在过去的20年 美国的整个电力系统的发展 是非常地缓慢的 它几乎是以每年低于1%的增速 在慢慢地扩张自己的电力系统 这和中国几乎百分之五六七 这样的年增速是完全没有办法比的 美国过去20年的GDP 或者是经济的发展 和它的电力系统的发展 几乎是脱钩的 这也导致一个问题 哪怕你现在开始加倍你的增长速度 那也只是2%而已 所以这个增长速度是远远跟不上 数据中心的高速增长速度的 美国的新增电力的负载当中 我们估计 数据中心可能就会占到40%左右 剩下的60% 可能是电动车的增长或者是 生产制造业的回流到美国等等 但是这个也是要看 经济发展的状态的 还有一个数据可以分享的是 像有一些机构他们预估出来是 美国每年应该需要增加 大概80个吉瓦的发电量 才能够大概地满足美国的数据中心 电动车和生产制造业的回流到美国 这样的一个增长的需求 但是目前来说 美国每年的发电量增长 可能只有50多到60左右这个水平 也就是说 每年可能美国面临的是 大概20个吉瓦的发电量的 一个巨大的缺口 如果保持这样的缺口的话 未来5年左右 很可能美国将会面临一个 大概100个吉瓦的发电量的缺口 因为今天的话 美国的总发电量 大概是在1300个吉瓦 所以这个缺口占的比重 也是非常大的 20个吉瓦是一个什么概念 比如说一整个纽约市 或者旧金山的发电量 会有20个吉瓦吗 这个是很好的问题 像纽约的话 它的平均用电量 大概是在6个吉瓦左右 它每年的峰值 可能是在十一二个吉瓦左右 所以如果说是 差20个吉瓦的缺口的话 那这个缺口可能就相当于 可能2-3个纽约的发电量的水平 但现在我们说 居民用电跟工业用电都要保证 AI的数据中心也得建 因为它用户数一直在增长的 所以现在缺的这部分电从哪来 或者说我们拉回到 现在的这个时间点 现在对于AI来说大家缺多少电 我们预估出来 可能今年数据中心 可能会新增大概8个吉瓦的 新增的用电量 这个电从哪里来 美国过去几十年的电网建设中 它有一些余量 还有一个就是 像GE这样的公司 也在大量地制造和出售 自己的天然气发电站 还有一些清洁能源 也有一些研究机构预测 像新增的这些发电 可能60%会需要靠天然气发电站 40%左右可能是需要靠光伏 风能和储能这些来弥补 当然我们希望未来 像核能能够尽快地 成为一个新的主力 现在美国的发电当中 大概20%的发电是来自于核能 但这些都是属于过去几十年 一直存在的存量核能吧 像新增核能这一块的话 我们可能还要等到 比如说2028年左右 才会看到新增的核能上线 像一些新的核能技术 比如说小型或者微型核反应堆 像SMR这样的技术 我个人估计 可能还要等到2030年左右 才会真正地成为主力 我看最近Sam Altman 他投了一家公司 他们是做小型的核裂变的反应堆的 股价也是涨得很厉害 这家公司叫Oklo 它这个股价确实涨得是 非常的疯狂的 但是我也没有想到 它在短短的几个月之内 就能上涨那么快 我觉得这应该更多的 不是反映基本面 而是反映市场对它的期待和情绪 而不是它技术本身基本面 在突飞猛进 或者是施工运营方面在突飞猛进吧 所以这家公司 它现在是已经实际用于发电了吗 还是并没有 现在还并没有 我记得有一次 开一个能源和AI相关的会的时候 Oklo的一个高管 他跟我们观众说的是 他预计最理想的情况 可能是2027年 能够开始实现商业运营 但是据我过去对核能行业的理解 其实核能是一个 难度非常大的一个行业 跟软件行业跟IT行业 是不可同日而语的 所以我觉得这个日期 可能是比较乐观的 但是考虑到美国过去几十年 核能这个行业基本上没有怎么动过 很多人才也去转行做了其他行业 很多地方可以说是断档的 所以如果要很快地 把核能能够开始进行 规模化的商业运营的话 我觉得这个时间 可能没有那么的乐观吧 我补充一点 美国一年增加 五十几吉瓦时的发电量 但是更多其实它的组成当中 如果是按照火力发电 它的组成其实不到5吉瓦 所以更多的是 大概有差不多45吉瓦是太阳能 另外5吉瓦可能是风能 这些发电都是不可持续的 它会有一个根据日照 根据天气的变化 所以它实际真的有效的发电量 可能一年就不足20-25吉瓦 我觉得这个是更加 去增加一个缺口的 算一笔账 我们按照DataCenter的 数据中心的投资 老黄有一个数据 就是500亿1吉瓦 所以它整体的话 如果真的有60吉瓦 那它就是一个3万亿资本的投入 但是目前来说 所有的大公司 预计明年的投入量 基本上在1万亿不到一点 所以从整的发电的量来说 只看这个数字 我觉得它更多 没有到一个这么缺的一个状态 如果把美国GDP的增长 全部归功于 AI数据中心的增长来说 因为它可能在电网里 还有一些余量可以去使用 你说的很对 如果是太阳能的一个吉瓦 和一个天然气的一个吉瓦 其实是不一样的概念的 因为太阳能的话 只有在有阳光的时候你才能发电 所以还有一个概念 叫做容量系数 你的平均发电 大概是你的峰值的多少 像太阳能的话 可能只有25%左右 也就是说1吉瓦的太阳能的容量 最后发出来的电的话 平均下来 可能只有1吉瓦的25%左右 但是如果是核电发电的话 就完全不一样 因为核能的话 它可以几乎全年一直都是在 它的峰值发电 只有偶尔它需要维修保养的时候 才会需要把发电站暂时停一下 所以它的那个容量系数 可能已经达到了93%左右 而天然气的话也很高 它在常年运行的历史数据 可能会达到85%左右 所以不同的发电的技术 虽然是同样的Gigawatt 但是它实际的发电量是不太一样的 所以你刚刚说的那个80吉瓦 一年的需求是指 一个混合的数据吗 就是混合起来看 如果我们有一部分的天然气发电站 有一部分的光伏发电站 和风能发电站 所有的这些吉瓦加起来 可能会在80个吉瓦左右 但是我又听说美国的电网 是相对比较脆弱的 这个Ethan 不知道 你能不能多介绍一下 美国的电力系统 确实是有很大的问题的 我们一直在关注发电这个点 但是稍微有一点片面 因为数据中心需要的电的话 它其实是通过整个电力系统 来获得电的 而不只是通过一个发电机 一个电厂来获得电的 所以我们要看的是 从发电到输电到配电 整个产业链 都得形成一个有效的系统 才能够给居民 工业 或者是数据中心以足够的电 当然这里边最重要的一块 确实就是发电 发电大概是占整个电力系统投资的 大概50%左右 输电的话大概会占到 百分之十几到二十左右 然后配电的话 大概是占到20%-30%左右 这个输电网的发展 在过去也是非常缓慢的 理想状况下 如果这些电站 都能进入到美国电网里边 那么数据中心的供电是没有问题的 但问题就在于 电网本身连吸纳这些新的发电站 都能力不足 再并入到新的数据中心的时候 也会有很大的问题 刚刚辰晟有一个数据 你是说60个吉瓦 差不多背后是3万亿的资金支持 所以反推 OpenAI的Stargate 如果说是5000亿的一个项目 它可能就能建成10个吉瓦的电 然后这10个吉瓦 是现在在Stargate的一个规划中吗 如果说我们不管什么方式 就把这个电建成了 它是不是按照Ethan你刚刚的说法 它输入到这个电网 它可能也是有阻力跟难度的 没错 现在我们了解到的Stargate 它目前的目标是 能够建到10个吉瓦 现在可能已经签约和宣布了 这些大概有个7个吉瓦左右 这些都还只是签约和意向 真正要到电网里边 应该还会有一些阻力 就比如说它需要在很多地方 找到现存的容量 对于这么大的一个体量的话 很显然 OpenAI或者它的合作的伙伴 像Oracle 他们需要想办法 去创造新的容量在电网上 现在的很多科技公司 他得自己去建发电机 建发电站 变电站和一些配网的设施 甚至建一些稍微短一点的 电力传输线等等 去满足自己的需求 因为电力公司 已经完全跟不上他们的需求了 我们刚刚提到了 输电是一块问题 建电网跟发电 可能就是一个更大的问题了 我注意到其实 不管是OpenAI的Stargate的项目 还是马斯克的xAI的项目 其实大家现在用的基本上还是说 燃气涡轮机的方式去建电网 但是这一块 辰晟你可能比较了解 涡轮机现在它的供应链 是一个怎样的情况 它是不是也是一个比较短缺的物品 对 因为它本身的产能 完全是不足的 因为你可以去看 包括GE Vernova的财报 它过去10年吧 它的增长其实是非常平缓的 到峰值的时候 可能是2019年 2020年的时候 大概到七十几台一年 每一台大概在30-50兆瓦 我们做一个对比 涡轮的发电机 其实和我们的飞机引擎就非常像 一年大概有将近4000台 飞机引擎下线 而涡轮发电机 市场最大占比的GE Vernova 只有小100台 这是一个数量级的差别 一来是之前的需求没有这么旺盛 二来 之前政府对于可持续能源 零碳排的这些标准 大家对于需要会增加碳排放的行业 其实也没有这么多的投入 因为它相当于是一个夕阳产业 只有在最近 因为有AI数据中心确定的 这样一个背景下 大家才找到了这样一个 短期止损的这样一个方案 而不是说所有的数据中心 现在都愿意去 长期地使用涡轮发电机 更多的是说 如果我并入电网 需要一个两年的许可审批的时间 而我需要数据中心 比方说马斯克需要6个月就上线 那他们一年半的gap 只能使用一些短期的 比方说涡轮发电机的这样一个状态 哪个公司也不一样 比方说xAI 根据公开的信息 它横扫了美国将近70%以上的 燃气涡轮发电机的库存 已经用来给孟菲斯 它两个非常大的数据中心供电 所以70%根据你刚刚一年的产量 差不多就是50多台 不 是存量 存量 所以根据SemiAnalysis 一个博主的分析 如果我没有记错的话 光Colossus 2 它一个数据中心 它基本上有160台的涡轮发电机 在那边给xAI提供发电 我想问一个问题 是不是涡轮发电机 它其实也是分几种类型的 涡轮发电机 比如说像GE的涡轮发电机的话 是几百个兆瓦的这种大规模的 现在可能是不是GE的发电机 我听他们财报说 已经2028年以后 才可能接新的订单了 是不是现在大家就开始买一些 隐形的发电机 是吧 这一部分是不是大家也开始扫货了 对 有一种就是 通过飞机引擎改造的 叫航空衍生燃气轮机 通过一个蒸汽箱 无论是从发热转换以及它的蒸汽 做两个cycle去提高它的燃料效率 做小型的涡轮发动机 比方说Caterpillar 可是它的产能也是一个 需要很长时间去build up的 这样一个过程 当然了 你造十台涡轮发电机 也只抵得上一台300兆瓦的发电机 其实它对于供应链的挑战 还是很大的 所以大的涡轮发电机 它的发电效果是更好的 像你刚刚提到的GE的这种 然后小型的涡轮发电机 它也是可以发电的 只是说它的功率没有那么强 或者它的效率 是比大的涡轮发电机稍微差一点点 对 GE也做小型的 但是大型的更多 只是供给原来的发电站 就像Ethan所说的 它每年美国可能之前 火力发电只有少于5吉瓦 但是我现在需要20吉瓦 它短期供应链 是需要很长的载口去做的 就像你说的 它现在的订单已经排到2028年了 中国可以做吗 中国据我所知 火力发电或者用天然气发电 不是一个非常主流的选项 包括涡轮里面这些叶片 它需要一些专业的合金 这些都是到一个 军工级别的security 中国现在的产业并没有 像美国或者韩国一些工业这么发达 在这一块上 所以我理解其实就是造涡轮发动机 它是一个高技术产业 它并不是一个说 我靠供应链跟制造优势 就可以解决的问题 如果给一定的时间它肯定能解决 但是大家现在是在一个 抢占能源的一个战争当中 所以并没有留给供应链 这么多的时间 对 这个是涡轮发电机的一部分 发电它可能还会有很多的零部件 我记得之前 马斯克有一句话就是说 transformer lead transformer 第一个说的是算法 第二个transformer的意思 就是说变压器 我知道变压器在整个市场上 它也是一个供货周期很长 可能到18-24个月 这样一个非常缺货的产品了 但是它又是在你这个电厂发电中 必须存在的一个环节 是的 先分享一个小故事吧 在大概一年半两年之前 特斯拉还在做Dojo 就是我们自己内部AI training的 这个项目的时候 我们想要在Palo Alto 硅谷的中心去建一个非常小型的 只有十几台training的 这样一个集群 那个时候Palo Alto市政府跟我们说 你们没有电 如果你们需要的话 现在交期已经从3个月 涨到18个月了 当然马斯克的公司最后怎么做 就是我们自己买了两台变压器 然后给Palo Alto市政府装好 然后说我们交付给你 你们让我用 那个时候只是3兆瓦 现在我们动辄是谈3吉瓦 1000倍的差别 变压器这一块 其实它需要的就是一个 基于电磁的原理 从一个高压转化到一个低压 到使用 再传输 里面需要很多的特殊的钢材 硅钢 或者说取向型的硅钢 因为它会带一些磁力的方向 提高它的效率 这种钢材美国只有一家公司可以做 它每年的产能是25万吨 全世界大概有500万吨的产能 中国光宝钢一家 大概有将近200万吨的年产量 所以美国在这个产业链上 是非常落后的 据我所知 2016年 2020年包括2024年 美国政府都出了一些 关于使用这些钢材 无论是反倾销也好 还是说OBBBA法案也好 都会有各式各样的法案 去禁止这些美国的公司 从中国来进相关的材料 因为为了想要发展制造业的回流 可是短期来说 美国的制造业并没有能力 去接载这么大的一个体量的需求 这也造成了过去两年来说 它的交期一直没有有效地去缩短 我理解的所有的这些 包括宝钢这家公司 都是指的是原材料层面 而不是说 真正地做成变压器的这个层面 是的 但我觉得今天我们再来聊 建电厂的时候 可能变压器只是其中的一个环节 而最新的电厂就像英伟达 它其实有在今年的GTC上 也讲了一种新的直输电场的方式 就是高压直流的方式 包括他也提了一个 800伏的高压直流输电的方法 大家可不可以讲一下 现在整个数据中心跟电厂 到底是在用新的这种方式去做 还是在用传统的这种方式去做 它的区别跟效率是怎么样的 英伟达这一次OCP展会上 讲的800伏直流 更多的是用于数据中心以内 整个AI数据机柜的输电 它是用来去替代之前的54伏机柜 我们先退一步来说 整个电是怎么产生的 高压电线如果是跨距离传输 是350千伏的这样一个体量 到本地的一个变电站 大概是3.8-35千伏中压的电 它到数据中心之内 可能通过一个不间断的电源 叫UPS 传到数据中心里面 目前来说一般是480伏或者415伏 它是交流电 通过一个交流转直流 把它转换成54伏 去给所有的芯片或者服务器去供电 为什么我们要去把54伏拉到800伏 是因为目前整个数据中心 就以NVIDIA的几代产品为例 它之前的Hopper 我们所说的H100 它的一个机柜 可能是一个30千瓦左右的数量级 最近一代GB200 它一个机柜就到了100千瓦 它之后的Vera Rubin 包括之后的这个卡 都是要往400千瓦 甚至到1兆瓦一个机柜去做 我们简单算一个算术 功率等于电压乘以电流 NVIDIA自己有一个数据 如果你还是用54伏做柜内的传输 你一个一兆瓦的机柜 就需要200公斤的铜用来做传输电 电流如果纯电阻 就是电压除以电阻 所以功率是和电压的平方 是成正比的 也就是说你去增加电压 可以大大地减少你效率的损失 800伏直流和54伏直流 如果是一兆瓦的机柜 54伏可能需要光在传输电上 会损失22%的效率 那我们现在缺电 当然这个损失是不能去承担的 如果拉到800伏的话 它的损失可以只在铜上会降到0.6% 这是好几个数量级的进步吧 现在数据中心 是不是有做到800伏的DC的能力 目前并没有 现在主要还是以415伏交流为例 为什么并没有 是进不去电网吗 不是 是因为现在 没有按照这个标准去做 有一点很重要就是 NVIDIA老黄说 他能自己造出所有的芯片 但是他没有电去power他的芯片 所以他现在定这样一个标准 是想要整个生态链共同进步 如果你还是415伏的交流 54伏的直流 它一个一吉瓦的数据中心 需要差不多50万吨的铜 这个是没有人可以去提供得了的 如果是做成这样 下一步可能就是缺铜了 所以他不得不要去 促使整个产业链或者生态链 去往一个更高的 高压直流的数据机柜的输电 往这样去做转换 那卡点在哪呢 我觉得更多是在大家怎么去理解 它这一周刚出的规范 以及怎么去把供应链拉起来 去做规范的理解 设计 生产 是不是可以这样理解 就是这个规范其实就是 看到今天的缺点 很严重的现实情况 要重新定义 这个行业里边的各项标准 现在刚刚发布这个新的标准 还需要一点时间 让整个生态链的各个环节的企业 重新设计他们的 比如说各种电器产品能够适应 或者是能够进入到 这样一个新的标准当中 让我们看到了下一代的数据中心 就有可能会根据这个标准 去建立起来 这样的话 整个数据中心的效率等等 都会提高很多 是的 是的 但我看见现在大家虽然没有去建 800伏的高压直流 但是相比于你之前提到的 54伏的直流电 已经有人开始尝试 比如说200伏 400伏 大家已经在往这个方向去靠了 只是说我们还没有把那个标准 一下拉得那么高 对 在英伟达的白皮书里面 也有提到它的几个阶段 就是从415伏交流 到54伏的直流转换 也有415伏的交流 直接转成415伏或者400伏的直流 去做这个机柜 之后再是说 把整个配套的基础设施提到800伏 去内部直接做直流的这个传输 甚至于到最后的ultimate stage 就是用固态变压器 在数据中心的输电入口 就直接做到800伏直流 当中可以去除一些UPS 以及整体的效率 把从92%-98%的效率甚至提到98.5% 甚至99%的end to end的效率 Ethan是不是我们去做这种 数据中心的高压直流电 跟整个居民用电 方式是完全不一样的 就是这个方式 它是不可以提供给居民用电的 就限定了它只能做数据中心 我的理解大概确实是这样的 因为我们现在整个的电力系统 其实都是建立在所谓的 交流电力系统这个基础上的 刚才我们说的高压直流的这个概念 其实在电网侧 其实也是有很多的应用的 尤其是中国 就比如说电网在传输电力的时候 如果是长距离传输的话 你的电流越大的话 你的损耗就越多 怎么让电流变小呢 你就把电压升高 所以这也是为什么 我们在输电的时候 会需要很多的变压器 一方面变压器是要在发电机那一侧 把电压提得很高 在传输的过程中 它的损耗就会比较小 在用电的时候 你又在用变压器 把它的电压给降低 这样的话就在居民 或者是商业工业使用的时候 这个电压是比较安全的 所以在中国的话 其实建了很多的 也是叫高压直流 不过那个是输电线的高压直流 那个可能就是500千伏750千伏 那个电压就比800伏 要高1000倍左右了 而现在我们看到的 基本上整个社会都是以交流电 作为一个主要的用电方式的 但是我觉得现在 确实是到了一个时机 数据中心内部应该用高压直流 来提高它的效率了 2025年很有可能在美国数据中心的 所有用电量加起来 可能会占到整个美国用电量的 大概5%左右 就是整个加利福尼亚州 整个今年的用电量 大概是占美国所有用电量的 大概是百分之六点几左右 也就是说今年数据中心的用电量 就稍微比整个 加利福尼亚州的用电量 要稍微低一点点 而这个数字大概会在 2030年的时候会翻倍 也就是说在2030年的时候 很可能整个数据中心行业的用电量 是加州今天用电量的大概两倍左右 这是非常大的一个用电量 所以我也觉得 到2030年大概会涨10%的话 这意味着这是一个很大的用电行业 完全值得为这个行业 设计一套专有的用电的标准 就比如说英伟达的800伏 这样一个标准 能够让整个占据美国用电10%的 这个行业的效率 比如说提高20%左右 这是非常大的经济收益 我觉得我们可能看到的 比如说上周公布的这个报告 就是这一切的开始 大概给听众一个印象 我们用ChatGPT搜索一次 会有多耗电 它差不多就是用谷歌搜索一次 耗电量的10倍 我另外看到一个数据是说 中国今年整个电力的建设 是有495个吉瓦的 美国今年的整个电力的建设 是50个吉瓦 为什么中国可以建设得那么快 而美国在这么缺电的情况下 它的建设速度还是这么慢 总体来说有几个主要的原因吧 一个就是中国的电网很多时候 它是有一个集中规划的概念 这和政治制度 经济制度 是息息相关的 而美国的很多电网 它是小区域局部规划 但是很少有跨区域的 大规模集中的规划 当然美国也意识到有这个问题了 也开始做出这方面的改进 也有一些政策出来去鼓励这样做 但是这方面也刚刚开始 这和中国一直以来的电力 从西边送到东边 从南方送到北方 通过高压直流 通过整个中国大规模的电网建设 来实现电力的大规模传输 完全不能同日而语的 还有一方面就是 在建设电网的过程中 你需要很多的审批 而在中国的话 它有一个相对集中的 一种管理的方式吧 而在美国的话 很可能你的高压传输线 需要经过一个农场主 这个农场主说 不 我不允许你在这建 你可能就要绕道个几百个英里 而这个过程中 可能你会遇到几百个这样的农场主 你一个个谈下来的话 这个时间是非常漫长的 这就是为什么美国高铁建不成 对 是同样的一个道理 对 所以还有一个数字 可以给大家参考 在美国建一个新的长距离的传输线 大概需要的时间是7-12年 这是非常漫长的一个过程 所以在过去的几年 美国几乎没有大规模的传输线建设 但这只是整个 电力系统建设中的一角了 其实如果你看输电也好配电也好 整个建设都会遇到很多 类似这样的问题 长距离传输线的建设主体是谁 是政府吗 我其实现在的角度是说 如果现在来做这件事情的人 不是政府而是科技公司 因为他们其实有实打实的 利润跟业务需求上的考量 所以他们是不是 在做同样的事情的时候 它的推进速度会更快 我觉得在整个电力系统 建设的某些环节 科技公司是有优势的 但是在传输线进入这个环节 可能跟电力公司 遇到的问题是一样的 你还是要去跟无数人去谈判 这个还是非常难的 所以现在科技公司 采取一个策略就是 我不去参与 很多大规模的传输线的建设 但是我走另外一条路 比如说我自己去建我自己的发电站 而我就把这个发电站 建在我自己的数据中心 附近不远的地方 很多东西是在它的经济资源 政治资源的影响力范围内 它可以做得更快更好的 数据中心的建设是需要大量的水吗 在建设过程中 水用得并不多 在运行的过程中 看你是用什么样的方式去制冷 可能会决定了你的用水的量 液冷用水量就会非常大 其实也看具体的技术 因为有些液冷量它是闭循环的 所以它用的水也不是很多 但是在数据中心运行过程中 用水量和用电量 往往有一个此消彼长的关系 当你想降低用水量的时候 往往意味着你要用更多的电去制冷 如果你想降低用电量的话 可能你要依靠当地的很多水资源 帮助你制冷 这也是一个矛盾的点 所以在数据中心的建设过程中 或者在选址的过程中 每个公司都会看 Ok 在这个地区 是不是电更多一些 还是水更多一些 要根据当地的禀赋 它可能会决定一个策略 对 我看其实现在整个科技巨头 它在建数据中心的时候 还是有遭到很多当地居民的抵制的 不管你说污染还是缺水 就是各种各种各样的问题 可能都会有 所以再回到我刚刚提的那个问题 为什么中国建设得这么快 Ethan你的观点是行政效率的问题 对 我觉得可能还有一个原因 就是成本的问题 一个是设备的成本 一个是人力的成本 中国在过去的可能10年左右 在政府还有政策的推动下 整个清洁能源行业的发展 是非常非常快的 一个简单的数字 可以让大家留下深刻印象 就是中国在一年的 太阳能的装机容量 相当于世界上所有其他国家 加在一起的总和 甚至有时候还更多 这也就意味着整个行业 已经把清洁能源的发电成本 已经压得非常非常低了 比如说我们看到大规模的储能等等 像美国的设备 可能是中国价格的两倍左右 所以这个成本的差异 也是一个比较大的原因 对 现在整个电力的建设 带火了哪些能源股 其实我们刚才聊的天然气涡轮机 像GE的话 可能是最受益的一家公司 因为在过去很多年 我们一直在做清洁能源转型 要降低碳排放什么的 天然气的发电这个业务 其实一直都不是很好 但是因为现在AI的爆发 需要发电特别多 所以天然气 能够上线的速度又比较快 所以像GE这样的公司 已经涨得非常的高了 因为大家都已经明确地看到 它的订单在疯狂地涨 它的溢价能力也非常的高 需求还远远没有得到满足 除了这个之后比如说核能 但核能的话我个人认为 可能不是一个 短期能够实现的一个技术 但是未来的五年左右 可以实现的技术 所以这块也应该是一个 比较受益的板块 还有很多可能就是供应链上的 很多一些规模稍微小一点的企业 比如说做各种电器设备的 可能还有一些做各种原材料的 比如说铜 就是一个很关键的原材料等等 我觉得这些企业和公司 应该都会受益的 对 辰晟 之前有一个公司 它是做化学燃料电池的 它可以短期去解决（问题） （如果）买不到天然气涡轮发电机 最近股票也涨得非常好 但是从资本的角度来说 它其实这笔经济账是算不过来的 同样100兆瓦时 你一个涡轮发电机 可能是在 200个百万美元左右的投入 像一些其他的替代选项 它的资本支出投入 可能要翻3-3.5倍 所以它可能要到700个百万美元 同样一个100兆瓦时 它的能源效率虽然提高了 但是它的燃料其实每年的 运营的费用 可能同样100兆瓦时 它也要花额外可能 20-50个百万美元的 这样一个不等 你可能五年算下来 就要多花将近六亿到十亿美元 去解决一个100个兆瓦的能源 可是现在大家去做一些竞争 我要比你更快到通用人工智能 我要比你更快实现商业化 所以促使了大家 疯狂地去购买这些产能 当然了整条行业上面 现在如果纯从股票 或者纯从供应链来讲 AI其实缺的东西是很多的 它从大到变压器这些基础设施 甚至小到芯片 之前我们过去两年 一直在谈缺芯 无论是说 这个芯片本身的晶圆的产能 包括台积电是全球独此一家 做CoWoS一些特殊封装的这些产能 它其实还是在相对紧缺的这个状态 比方说因为Sora或者Veo OpenAI和谷歌的视频模型 它会转成说 我对于我的储存的存储器 它的需求会有指数级的增长 造成了我看到一个研报说 明年年底如果不考虑现在的这些 新的模型对于储存的需求 它的缺口还有5%-8% 如果我们考虑上的话 它的缺口可能会更加大 这是由于过去好多年 产能没有有效投资 因为有经济的波动而造成的 所以其实各个方面都缺 我再举一个有意思的例子 比方说现在10万张卡的 这样一个AI数据中心 如果之前我们训练 Meta Llama的时候 它用了差不多25000张卡 还是16000张卡 训了54天 它训练平均3个小时会断一次 由于GPU产生的问题占到58% 那OpenAI训GPT 4的时候 或者Meta训Llama 4的时候 它用一个10万卡的级别 它平均32分钟就要宕一次 需要恢复大概15分钟 退下来的芯片当然是退回给NVIDIA 你光一个10万张卡 你每周1%的故障率 它可能就有差不多1000张卡 需要去运回去 这是什么样的体量 它可能需要100吨 连FedEx都要去买额外多的货车 去做这样一个 运回100吨的卡 对 如果只有10万张卡的 前提下的话 我们做一个合理的1%的退货的假设 所以其实整条供应链上 有太多太多的卡点 现在是不能支持到 这样一个体量的 我可不可以简单总结一下 整个现在AI的问题 我们理解前两年它是缺芯片 这两年它的核心问题 就是缺电跟缺能源 以及搭建数据中心 整个供应链环节 各种各样的小的卡点 是的 好的 好的 非常精彩 我觉得我们之前的节目 都还是在聊10亿美元的独角兽 就算很大了 之后我们聊这个大模型 可能是几百亿 几千亿的这种估值 今天我们是在聊一个 trillion dollars 就是万亿美元的市场 感觉我们的野心也是在慢慢变大了 没错 没错 这个投资的规模实在是太大了 对 我觉得这个也可以说是 载入人类史册的一个投资时期 好 非常精彩 谢谢两位 谢谢 谢谢 谢谢 这就是我们看到的 现在整个美国经济 冰火两重天的现状 一端是科技巨头热火朝天的大基建 另一端 是传统的行业那0.1%的增长 那我们说 在这样的一个资金传导链条中 任何一个环节出现信任危机 不管是有公司的造假 或者是整个AI的落地不及预期 会不会是这个多米诺骨牌 倒塌的第一步呢 感兴趣的听众 可以给我们写下你的评论 我们一起来讨论一下 那这就是我们今天的节目 如果大家喜欢我们的节目 记得在小宇宙 苹果播客 Spotify上来收听 订阅我们 同样大家也可以在YouTube 或者bilibili上搜索硅谷101播客 来关注订阅我们 我是泓君 感谢大家的收听