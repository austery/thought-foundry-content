So, the current crop of generative AI companies on balance are currently making the world a much worse place, and things are on track to get much, much worse than they are now. I've made videos about why the AI Doomer narrative is a distraction, and I've talked about how even people with trusted reputations who ought to know better are pushing the narrative that we need to worry about AI killing us all. Today, I'm going to talk about what the biggest problem with AI really is, or at least the biggest problem I know of so far. I certainly hope there isn't anything worse. And unfortunately, none of the regulations of AI that I've seen or the proposed regulations I've seen would help at all. Maybe I can make at least some people understand the danger that we're in. Okay, so here's a short version: The AI companies and the AI Doomers want this to think about AI as if it was Skynet from the Terminator, but that's the wrong Arnold movie entirely. AI is not a machine from the Terminator. It's the machine from Total Recall, and living in a world with that machine is a BIT----- This is the Internet of Bugs. My name is Carl. I've been a software professional since the 1980s, and I'm trying to do my best, my part, to make the Internet a safer and less buggy place. The first thing I want you to understand is that the genie can not be put back into the bottle at this point. AI is not going to go away, no matter what we do, we're stuck with it, and we're going to have to live with it. To those people in my comments that say, "All AI is bad" or "Just ban it all," thanks for the engagement, but you're wasting your time. Even once this bubble pops, as long as the people getting rich off of Generative AI can use it to make themselves even a little bit richer, it's going to be a constant factor in what happens in the world from now on. Which brings us to Total Recall. And for the record, I'm talking about the 1990 version, not the really bad recent remake. But summary with only minor spoilers if you haven't seen it. The premise is that there's a machine that can implant fake memories into a person's mind. Because of this, the good guy doesn't know what's true and what's just an implanted memory, and the billionaire bad guy uses the machine to put any thoughts he wants into people's minds, and in the process changes their values and personalities. I wonder if that's starting to sound familiar to you yet. So we as a society were already having problems with divisive politics before Generative AI. Research says that we, at least American society, is more polarized now than at any time since the Civil War in the 1860s. I've read that Europe isn't as bad as it is here, but that polarization levels there are also increasing. Even before Generative AI entered the mix, it was already the case that people on different sides of the political spectrum were unable to agree on basic facts. Generative AI has already started to make that much, much worse. I can give you lots of examples. AI-generated fake recordings of a politician in Slovakia in 2023 that went viral right before an election, a fake recording of a Chicago mayoral candidate that may have contributed to him losing an election. There's a site that cataloged more than 20 AI-generated political deep fakes leading up to the US 2024 election, but as bad as that is, and it's bad, it's just getting started, and that's not the worst of it. Fake news pictures, audio, and video by themselves aren't really a problem. The thing that makes them dangerous is when those AI-generated fakes get promoted to a lot of people by social media algorithms. This is not a completely new problem, disinformation on social media has been a problem for more than a decade, but AI allows orders of magnitude more misinformation to be generated and put on social media and with a level of polish that could never have been done before. But even worse, research says, is the effect that conversations with chatbots can have on people's political views. Remember that fake stories on social media can be noticed and fact-checked. The stories still do damage and a lot of people will refuse to believe the fact-checking, But at least it's something, and no such fact-checking is possible in a conversation between a person and a chatbot. This is the really new aspect of this that AI makes possible for the first time: individualization. Up until now, everyone has gotten a curated list of the same social media posts that were available to everyone else. The particular combination of posts in your feed might be unique to you, but every post that you see has also been seen by other people, which greatly increases the odds that someone might be skeptical about it and look it up and try to set the record straight. And in a chatbot conversation, no one else can even be aware of what's being said, much less try to correct anything. Up until now, it has never been feasible for a person to receive an isolated individualized feed like that. Soon, it may be the norm. In theory, a chatbot company could be held liable for any falsehoods in such conversations since chatbots are not believed to be protected by Section 230 of the 1996 Communication Disease Agency Act, although that hasn't been really tested in court. However, if no one else can see the content, no one else can object, except maybe in a lawsuit after it's probably too late, but still even then only maybe. In a democracy as polarized as we are becoming, that's an enormous amount of influence a chatbot company could potentially have. The number of people it takes to swing a US presidential election is generally half of 1%, whereas it's been reported that as many as 7% of Americans use chat GPT every single day. We have some research that shows that social media does affect voting patterns. How chatbots might affect voting seems like it will actually be worse. In the limited lab experiments that have been done so far, the effect from chatbots seems much stronger. But the efforts to try to regulate AIs don't address this at all. Note, I'm not a lawyer, I'm just repeating what I've read on the pages I'm citing here from accredited universities. For example, the California AI Act requires the big AI vendors to just publish reports about some of their internal procedures, report any catastrophic issues within 24 hours and protect whistleblowers. The UAI Act, considered the world's strictest, requires chatbot vendors to provide documentation to show AI generated content and prevent illegal content generation. None of those would help at all. This really illustrates the disconnect between the risk that AI actually poses and the concerns of legislatures. Is this fixable? Maybe, but almost certainly not before the next election cycle. We know this is going to have an impact, we just don't know how much or in which direction. And yet, the AI Doomers want you to worry about "If Anyone Builds It, Everyone Dies" and Hank Green invites you to talk to your lawmakers about AI super intelligence. And this is either incredibly disingenuous or incredibly naive because... Yeah, that's not how I should say that. They're either lying or they're stupid. Because if they truly wanted our elective representatives to pass laws that would prevent an AI from killing us all, step one would be preventing AIs from influencing who gets elected. Because as soon as enough pro-AI legislators are in office, the chances of getting any anti-AI laws passed at all becomes zero. And think about it for just half a second. If AI is going to have an effect on an election, do you think it's more likely to favor candidates that think AI is bad or candidates that think AI is good? Welcome to the world of Total Recall, where you can't believe anything that's seen or heard or read online without verifying the original source yourself, where billionaires have a lever they can choose to use to push disinformation directly into people's minds and change people's opinions on critical issues, and even long-time trusted public figures are telling you to look in the wrong direction. And there is absolutely nothing I can think to do about it except rant into a camera and try to gaslight myself into believing that enough people might watch and like and share this video that it might actually have a minuscule chance to make even a tiny difference. Normally, I'd try to give you something hopeful here, but... I've got nothing. We are so FU-----