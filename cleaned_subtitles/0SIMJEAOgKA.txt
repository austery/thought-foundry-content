会员朋友们大家好 大家有没有想过 就是亚马逊Facebook这样的公司 它们有钱有业务 然后有大量的数据 又有卡 看上去是有人才的 而且他们从上到下都是非常重视AI的 那为什么 他们反而在研究大模型这件事情上 掉队而且看上去一直追赶不上来 反而像DeepSeek这样的公司 资源是他们的 可能1/10,000都不到 却能把这件事情给做出来 我在频道里面其实做过几次分享啊 就是我觉得在大厂的这种管理机制 包括领导层不懂 比如说我在2023年初的那个文章里边讲 领导层的认知其实是一个稀缺资源 都已经讲了一些道理 但是我觉得那些东西都不是很具体 我后来发现啊 就是让我有一些具体认知的 反而是一些谣言rumor 这些谣言对我来说其实不是谣言 它们是anecdotes 但是因为我没有办法真的去亲身验证 所以说在我嘴里说出来 它其实就变成了一个rumor 就变成了一个谣言 可是我还是决定跟大家分享一下 因为我觉得它对我形成判断 其实是一些非常重要的依据 那我今天跟大家分享出来 我也希望大家在听的时候 就注意到这个背景信息啊 就是这些东西 是我没有办法去亲身验证的 所以说它有可能就是谣言 但总之我觉得还挺重要 就今天在这里边跟大家这样闭上门 来分享一下 第一个谣言 或者说这个anecdote 是关于亚马逊大模型的发展的过程 这个其实是我多方验证的一个消息啊 起码是有三个比较核心的人物 我跟他们私下聊过 然后交叉验证的信息 我可以讲述一下 我在这里听到的一个前因后果是什么 就是当ChatGPT刚出来的时候 其实是Andy Jassy亲自带队 去做一个亚马逊内部的大模型 代号是Q 同时AWS那边也有一些小的动作 包括bedrock团队 去跟Anthropic进行深度合作 后来betawork又去跟OpenAI去进行合作 就是AWS作为一个Infra 去serve外面的这些模型 但是亚马逊自己呢 他是想开发一个属于自己的模型的 当时其实主要的厂商 都是抱着这样的一个想法 包括Databricks收购了一个模型公司 对吧然后后来创始人现在又出来了 就是哪怕Databricks这样的公司 他也是想做一个自己的模型 我在2023年的那个文章里边就有讲 我觉得不是很看好 很多公司去做这件事情 当时 我其实还跟腾讯的总办领导有过交流 就是我把这个文章 发给了一个总办领导 然后他问我那应该怎么办 我说现在腾讯最好的方式 就是跟微软进行一个官方的合作 通过腾讯的渠道把ChatGPT给用起来 这是我看腾讯最好的一步 当然了 你也应该开发自己的大模型 但是不要对这件事情 抱有一个急功近利的心态 我觉得后半句 反正最后是发生了 就是腾讯在开发大模型上 是没有一个急功近利的心态 但是他也没有去 依托自己的这个渠道优势吧 去能把一个外面的模型给引进起来 当然我知道这里边的困难是非常大的 就是你真的想去做这件事 也未必能做成 总之我当时的判断就是 这些领导们肯定会觉得自己有人 有钱有卡 是可以做一个大模型的 但是不那么容易 因为这件事情 他其实是需要一个非常强的领导力 非常强的对这件事情的原理理解 我不看好这些过去的领导 对这件事有原理理解 尤其是这些领导如果之前做过AI的话 他们很有可能会带着错误的理解 然后带着错误的KPI去盯这件事儿 反而把这件事搞砸 所以说我当时有朋友啊 就是在那个Amazon Q上 会去说他跟Andy Jassy是这个 每周都会开会 基本上资源都给的很好 所有事情都给很多绿灯 但是具体的人就不说了 总之亚马逊内部的人可以知道 就是带亚马逊Q的这个人是一个SVP 他并不是一个真的懂generative AI的人 或者说我对他之前所做的一些业务 也不是那么认可 比如说亚马逊之前 可能人工智能真的拿出手的东西是什么 Alexa 但是大家知道Alexa那个玩意儿 就是它上面有什么人工智能呢 就是很多if-else的condition 然后有很多非常简单模型的应用 我在可能四五年前的视频里边 就有批判过 Alexa的路线只能走向人工智障 是不能走向人工智能的 现在也看就是那条路本来就是一条死路 然后你又让在这条路上的人 因为他做了这件事 然后去招兵买马 build empire（打造版图）然后去领导这个大模型 那到最后其实就是折腾了很久 大概经过了 可能前前后后一年的时间吧 Q这个项目就算是宣告失败 然后就是被高层定性为 这个项目是失败了 然后整个经历了一些重组 但问题是啊 就是在这样的一个企业里边 你虽然这个项目失败了 人其实是没有得到大换血的 就是真正在亚马逊里边 有大模型能力的人 其实是凤毛麟角的 而且这些人是不具备话语权的 这就是我在之前的一个视频里也有讲啊 我当时还讲了《三体》里章北海 的例子 不知道大家有没有记得 就当时《三体》的故事 是要发展公质引擎还是非公质引擎 当时是公质引擎占了上风 但是章北海 知道 我们如果想要进行一个 恒星级别的航行 就必须要非公质引擎 那做法是怎么办呢 做法是 他就把公质引擎的专家们全都暗杀了 我后来就想了 为什么做这么极端 因为这就是做这件事情的唯一方式 你必须要把那些老专家全都干掉 因为这些老专家 他们的expertise（专门技能） 他们的价值 他们的话语权 他们的资源 他们的身份 全都在于他们之前的那些功劳簿 他们是没有办法放下自己 之前的所有身份 去从头去拥抱一个新技术的 因为你在拥抱新技术的同时 就相当于你把自己身份价值给清零了 各方面就是他们从自己的利益角度 情感角度等等理智角度来说 都是非常难做这件事情的 那你真正要去做好这件事儿呢 你真的要去找市场上真正的大模型 这里的一流人才 也就是说这些人能在OpenAI 能在Anthropic 这种顶级的AI lab里边拿到offer的人 你要凑齐这样一批人 你才有可能把这件事给做好 然后我另外一个朋友啊 就是他其实算是被挖过来的 之前 有一个非常好的大模型训练经历的人 就是他是属于这种类型的人 被挖到亚马逊 结果他在亚马逊呢 虽然做的东西是非常核心的 可是有一个事情就让他下定了去意 是什么事情呢 就是当时做完亚马逊的OP1 就是planning之后 SVP跟大家吃饭聊天 然后去打鸡血 说我们明年啊 大家好好干 还是那些话 就是我们其实是有资源的 然后我们也是有业务的 我们也是有数据的 然后我们再去招一堆 这个非常出色的new grad 来做这件事儿就行了 然后他当时一听就'what the fuck' 就是你完全不懂 然后你在这里边你去找了一堆老专家不行 然后你现在又去找new grad 你就是不愿意 去做那个难而正确的事情 难而正确的事情 就是真的去提升自己的技术判断力 去进到你那个不comfortable的地方 去真的在这里边判断谁是专家谁不行 然后去真的打造这么一个人才团队 可是这些SVP或者说这些领导们 他们comfortable的事情是什么呢 要么就是相信 他们已经有track record的人 这个试过了一次不行 接下来呢 他们就可能去找new grad 这些领导是没有判断能力的 那在这里边他就只能说 我看上去给到了对应的资源 所以说我也要对应的KPI 如果你们做不到的话 那说明人不对 那就再换一批 这样的做法就是没有办法做好的 那个人走的时候 他老板也去留他 然后他就跟老板说 你想要留我 那怎么留呢 就是把我顶上的这些人 比我级别高的这些人 全都扔到市场上 能拿到顶级AI offer的人留下 拿不到的全都开掉 这样的话 我们才有可能把这件事情做好 不然的话 我说一个什么东西 就上面一堆人在那说 他要做这个 他要做那个 教他们他们又不愿意学 然后你做一个事情 他们还有各种各样的挑战 各种各样的alignment 在那种语境下就是不懂的比懂得多 那你又没有办法证明你说的是对的 自然而然就很难把这件事做好 所以说老板一听 虽然你说的是有道理的 但是我好像没有办法满足你这个需求 所以说这位同学就走了 然后还有一位在亚马逊的同学 他其实是当时李沐组的一个科学家 他已经接受了我的访谈邀请 暂时先不透露名字 但是如果到时候访谈的话 大家就知道他是谁了 这位同学跟我分享了两个Insights 我觉得是很有道理的 第一个Insights是真正的做大模型的 这个团队 他要干的事情是什么 它要cook出来一个recipe 就好像绝命毒师的那个老白 他去cook一个99%程度的冰毒 就是这个recipe 一定是要有很强的know‑how的人 然后有很强的探索实验 然后去把这个东西给做出来 那你要做出来这个recipe 其实不光是需要顶级的AI研究者 你还需要比如说做Infra的人 你还要需要做data的人 你还需要做很多 比如说处理啊并行运算的人 所以说 你需要有一个相对比较全面的团队 然后他们互相之间呢 合作的一定要非常紧密 就是你data的人不能pre-training和post-training 的人 然后分开做 其实这是做不好的 每个人心中都要有一个big picture 然后他们互相之间了解彼此的工作 又有自己的专精 才能把这件事情比较好的做好 听说在DeepSeek团队里边 基本上都是这个样子的 就是大家其实都很优秀 infra的人是懂模型的 然后pre-training, post-training 都知道自己要干的事情是什么 所以说在这样一个团队里边 就可以很高效的把这件事情做出来 第一就是你需要比较全面的团队 去把这个recipe给做出来 第二个insight是 这样的团队的KPI到底是什么 或者说 这个团队所要optimize for的东西是什么 在他看来应该 是optimize for information gain（以信息增益为优化目标） 就是说你每做一个事情 你每做一个实验 你应该想方设法的最大化 你这个实验所能得到的新信息 什么意思呢 就是你一个实验 如果说它有50%的可能性失败 50%的可能性成功 这个时候 你基本上是最大化了你的information gain 你可以在这里边 test到那个最关键的variation 或者hypothesis 如果说你在一个很大的压力 比如说leadership跟你说 我给了你们这么多钱 你三个月就必须给我做出来 那这个时候 你只能去找那种90%到99%成功率的 这种东西 那其实你到最后 得不到一个非常好的recipe 这是第二点很重要的insights 所以说这件事情 归根结底就是我觉得leadership不懂 然后这里边的老势力太多 那些公质引擎的专家都没有被干掉 然后他们没有用一个正确的KPI leadership没有去干正确的事情 所以导致这件事就是做不好 那我们再看Meta是什么样子的 我觉得小扎在这件事情上 其实还是相对有一定的魄力 可是我觉得 他仍然是 自己没有去搞懂这件事的时候 他希望通过砸钱去做 可是砸钱啊 它带来了一个负面效果 这个rumor确实是一个rumor 就是 我没有从内部的人得到任何verification 我也没有去找内部的人去做verification 但是从一个边缘的人听来的这个八卦 就是在Superintelligence团队里边 其实是有来自于OpenAI的人 和来自于DeepMind的人 他们其实互相看不上 然后甚至互相 有点拆台的这种行为 注意啊这是一个完全的rumor啊 确实没有办法verify 可是我确实又从另外一个信源听到了 就是superintelligence团队 首先对外合作比较少 其次对外合作的时候其实也有点尴尬 你比如说就是 他们是一堆很强的AI researcher 那这个时候 他们需要利用Meta已有的 比较好的Infra 想去跟Infra团队合作 但问题是当你合作的时候 一开会你拿的工资是别人的100倍 你拿的total compensation是别人的100倍 那别人跟你合作的时候 这个心情是个什么心情 在这种情况下 我觉得是比较难facilitate（促成） 比较好的合作的 然后另外一个很重要的点就是 我从外界得到的信息来看 小扎成立这个团队 是要搞所谓的Superintelligence 那我不觉得这个是一个特别make sense的goal 什么意思呢 就是 如果他想做的是一个特别牛逼的模型 这个模型因为他so牛逼 导致他和现在的这个模型 有一个本质的差距 我觉得这个不可能 我觉得现在这个模型 其实它的智力会incrementally地上升 但是它的范式仍然是现有的这个范式 那所以说在这个范式之下 你应该要做好的 其实是把现在的 围绕这个范式的整个ecosystem搭好 就像Andrej Karpathy说的 你要去做10年那些困难的事情 要把它比如说能读懂网页 然后能操作网页 然后可能再能读懂网页背后的东西 把更多的context给搭起来 我们在我们新的这个 教大家做Agentic APP的课程里边 我们教大家的三个方向 分别是Frictionless Interaction Contextual Intelligence和Proactive Intelligence 具体是什么意思 我在这里贴个图 就不细展开了 但是 这些东西都是需要很多的工作去做的 你不把这些东西做好 然后去指望一个特别聪明的模型 解决所有问题 在我看来这是一个演绎法的错误 而不是一个基于第一性原理思考 所能得出来的结果 其实历史上有很多例子啊 就比如说我在课程里边讲 汽车在发明的时候 你如果去看一八七几年 1876年的时候的第一辆车 其实和我们现在这个车 长得几乎是一样的 汽车引擎的这个技术 在一八七几年就已经成熟了 但是汽车在大规模普及是二战以后 一九四几年之后的事情 这个六七十年的时候在发生什么 不是说你的引擎一步一步的迭代 当然现代引擎和那个时候的引擎 确实现代的引擎要好很多 可是 其实大家如果看这个技术范式的话 是同一个技术范式 真正影响汽车的大规模普及使用 和让汽车变得真的有用 是整个它的ecosystem 是要把路给铺好 是要把汽车的流水线制造给打通 是要有大规模的infrastructure的建设 然后是要有加油站 汽车服务 修车行 驾校的配套 这些东西都是一步一步做起来的 才让这个汽车变得真正的有用起来 可是小扎想的 可能就是说 现在我不管路是什么样子的 我不管这个流水线是什么样子的 我不管这个模型跟真实世界的交互 它能控制多少我们的现有的算力 或者说融入多少我们现有的软件算力 我就是发明一个特别牛逼的模型 然后它就可以解决所有问题 在我看来 这是一条错误路线 当然了小扎可能是对的 我有可能是错的 我完全不介意被小扎打脸 我自己作为一个AI降临派对吧 我希望小扎的这个路线是正确的 我希望我被打脸 然后出来一个Superintelligence 把我们所有的这些头疼的问题给解决 但是我不认为这是一个feasible的事情 我认为 他是犯了一个不基于第一性原理的 演绎法的典型错误 如果大家感兴趣 再听 我觉得演绎法的这个典型错误是什么 我到时候可以再单独出一期视频去讲 这是第二个rumor 第三个就不是rumor了 是一个真实的案例 就是我跟亚马逊 我一开始工作的这些同事们 都是一些scientists们一起吃饭 然后他们有在亚马逊的 然后有去了Meta的 然后有在Airbnb的 很搞笑的就是 这三组人 现在全都在用通义千问的模型 就是在Meta的人 我就不透露具体的org吧 他们是在用通义千问的模型 好像使用的原因 除了比LLaMA的效果好之外 就是通义千问 它其实是在很多电商的数据上train的 可能更符合Meta的那种场景吧 Airbnb就不说了 他们的CEO就公开的去说 他们是使用通义千问的模型 觉得比OpenAI效果要好 或者起码不差 然后便宜很多 让我没想到的是 亚马逊也是在用通义千问的模型 后来一想也是有道理的 就是亚马逊内部的模型Q没有做好 那你接下来要么就使用Anthropic 或者说是OpenAI 但是对于亚马逊内部的那种基建来说 他们是可能更prefer使用一个open-weight的model 这样大家可以在上面做更多的花活 比如说浓缩呀 比如说fine-tune啊 比如说做chain of thought啊这些东西 所以说他们去使用一个通义千问 更快更好 然后可以做更多的花活 更多的customization 我觉得也是非常make sense的 总之这些东西我听着就觉得yeah～就是 你如果用正确的方式去做事儿的话 你就会得到正确的结果 你如果用一个错误的方式去做事儿 不管你是去要求KPI也好 还是你要去砸钱砸卡也好 在一个简单的事情上 这样大力出奇迹是可以做到的 但是在一个困难的事情上这样做 就只能适得其反 好以上 就是我对亚马逊和Meta 为什么做不出模型 的看法的分享 again 就是大家注意 这里边有什么是我确信的信息 有什么是我自己没有办法证实的信息 大家形成自己的判断 我提出来的这些观点 是为了激活大家的思考 和让大家形成自己的观点 大家自己在里边进行甄别判断 如果你知道我哪里的信息说的不对 或者说你觉得我哪里的逻辑有问题 或者说是我看到的事情 不是这个事情比较重要的那个侧面 欢迎在视频下面留言跟我讨论 那我们这视频就到这儿 下次见拜拜