In the previous video, I have tested the open source large model of multiple OCR scenes for you. From the model of 1B parameter to the model of 3B parameter to the model of 9B parameter. Through testing, you can find that the more powerful model has higher accuracy of recognition, but also higher requirements for graphics cards.但是对显卡的要求也更高 The model with a smaller parameter is low in graphics card requirements, but the accuracy is often not ideal. Especially the DeepSec OCR model we tested before. When testing, it actually identified the Chinese character "1" very clearly as "2". Also, we may use OCR models in more detailed areas. For example, the specific text or the handwritten body. 在这些场景下小参数的模型表现的就不是非常理想了那么有没有更好的办法来提升这些OCR模型的准确率但又不需要高配的显卡呢答案当然是肯定的我们可以使用微调的方式来提升这些小参数OCR模型的准确率本期视频将会再解演是我们用中文的OCR数据机来微调deep thick OCR这一款小参数的OCR模型专案大幅度提升这款模型识别中文的能力 对于不了解微调的用户来说可能不理解什么是微调我们可以使用更通俗的语言来解释下什么是微调微调就是用自己的数据或者特定领域的知识给模型开小造因为通用大模型更像是一个什么都会却又什么都不精通的通材通过头尾特定领域的知识让通用模型变成某个领域的专家 比如说我们今天的主题就是让DeepSec OCR这款通用的OCR模型从能识别各种语言但是每种语言都识别的不精准变成能精准的识别中文为了提升DeepSec OCR模型识别中文的能力我们将使用制作好的中文数据机使用谷歌collab提供的免费GPU 只需要耗时不到10分钟我们就可以完成对deep thick OCR模型的微调从而提升deep thick OCR模型在中文方面识别的准确率微调后的deep thick OCR模型它识别中文的错误率将降低70%以上好下面为大家想显示我们如何微调deep thick OCR模型并且还会为大家演示我们如何制作中文的OCR视觉机 我们可以直接使用Anthlux他提供的微调脚本这里是Anthlux他提供的微调脚本在他提供的微调脚本中这里的数据机是波斯文的数据机这些图像上的文字都是波斯文并不是汉字所以我们可以将他给出的数据机替换成中文的数据机 如果大家想通过微调提升这款模型在通用中文领域的准确性那么我们就可以使用HuggingFace上开源的高质量的中文数据集这个数据集是开源的高质量的中文数据集我们可以看到这里面包含多种样式的中文内容在左侧的image字段这里面就是对应的图像在右侧text字段这个字段里就是对应的左侧图像上的完整文字 因为这个数据机中涵盖不同样式不同场景下的中文扫描的内容使用这个数据机微调我们就可以大幅提升DeepThick OCR模型在通用中文场景下OCR的准确率如果大家想用特定领域下的数据进行微调那么就可以参考这个数据机来制作我们自己的数据机比如说我这里准备了用于OCR场景的这些图像 这个图像就是扫描版的PDF上的文字内容这上面就是比较模糊的文字内容然后我这里还创建了一个文件在这个文件中就有对应的这张图像所在的路径在右侧就是对应的图像上完整的文字和标点符号然后为了节省时间我这里一共准备了10张图像我们可以打开看一下 放大之后我们就看到了这种扫描键上的文字内容可以看到这种扫描键非常不清晰下面我们就可以来生成数据集了我这里准备了一个脚本这个脚本就可以根据我们刚才准备的图像以及图像上所对应的文字内容 来生成可以用于微调大模型的数据集我们可以点开看一下创建数据集的这个脚本这个脚本其实非常简单而且这里面我都加入了非常详细的注释包括使用方式还有完整的中文注释我们可以直接在中段运行一下这个脚本这里跟上pyse命名+脚本名称然后后面跟上我们准备了这个文件的名称也就是完整的图像路径再跟上图像上完整的文字内容然后我们只需要运行这里就会生成对应的数据集 生成的数据机的后缀是Pucky这和我们刚才看到的中文数据机的这些后缀是一样的而且它生成的数据机的格式也和我们刚才看到的这个中文数据机是一样的包括image字段与text字段像这样的话大家就可以用自己特定领域的数据来制作数据机用于微调大模型好下面就为大家演示我们使用这个通用的中文OCR数据机微调deep thick OCR模型 好 下面我们在谷歌collab中打开aslas提供的微调脚本打开之后我们点击run time 再点击change runtime type在这里我们就选择免费的t4gpu因为用这个t4gpu微调3b参数的deep thick OCR模型速度还是非常快的 然后再点击保存下面就非常简单了 我们先执行安装在collab上安装微调所需要的这些环境与依赖 Now we execute this code to download the full file related to DeepSig OSR. It will store the full file under this path. Now we can execute the code here and add the downloaded model to the memory. Then we can run it directly. Now we can add the data machine. Here I will use slas. The default data machine is changed to the Chinese data machine we just looked at. Due to the difference in the first two data machines, the default data machine is the image path. Then we find the Chinese data machine, the first one is the image. So we have to change the image path in the micro-tool script to the corresponding image. 在这个参数这里就是加载数据集中前2000个样本我们直接执行加载数据集的代码然后我们在执行这段代码从数据集中随机找一张图像进行测试测试没有微调的deep thick OCR模型它的效果再执行保存图像这个代码然后我们可以点击显示一下这个图像在这里有一个汉字1因为deep thick OCR模型很容易将1识别成2所以我们就可以测试一下它能否正确识别这个数据集中的这个图像 下面我们就可以运行这一段代码来使用没有经过微调的模型进行推理让它识别这个图像看一下效果可以看到这里输出的结果它不出意外的将1识别成了2然后我们可以运行这段代码查看一下数据集中对应的真实的文字 You can see that the corresponding true text in the data collection is 1, but the DeepSec OCR model that has not been configured has been identified as 2. Like this, we can see that the accuracy of the identification of DeepSec OCR models that have not been configured is still very shallow. OK, next we can configure this model. We can use LauraAdapters to configure it. It is a high-efficiency configuration for parameters. 然后这里是详细的超参数设置这里我还加入了中文注释这里就不再为大家做过多解释我们直接执行这段代码下面我们就需要准备一下我们的数据机对数据机进行一下处理我们直接执行这段代码将数据机样本转为对话格式 在这里就是加载了我们刚才查看的中文数据机然后在这里我们只加载前1000个样本用于微调打模型我们直接执行这段代码就可以然后我们再执行这段代码将数据机转为正确的微调格式好 下面我们就可以完整的运行这段代码这段代码用于创建Data Collector也就是数据整理器 这段代码中包含完整的中文注释为了节省时间这里我们就不再具体去看这段代码了然后我们直接执行这段代码就可以好 下面我们就可以微调这个模型了然后我们可以执行下面的代码创建训练器以及设置超参数这些具体的参数这里就不再为大家一一去解释了因为在以前的微调视频中我给大家详细的解释过我们直接执行就可以 下面我们还可以执行这段代码查看一下当前的硬件配置这里显示的是T4 GPU最大内存是14G然后我们就可以运行这段代码开始微调我们直接执行就可以现在正在执行微调这里我们要稍等几分钟 5 minutes later 在等待了大概六七分钟左右这个微调过程已经完成可以看到这里它执行了60步好 下面我们就可以运行下面的代码将微调后的LaraAdapter权重和Tokenizer保存到本地目录我们直接执行就可以 下面我们就可以运行这段代码加载刚才未点好的模型因为识别刚才没有正确识别的图像我们直接运行就可以这里它成功识别出来了图像上的文字内容将刚才识别错误的2成功识别成了1然后下面的代码就是将模型保存为支持VRM推理的文件 然后这里我们只需要将FALSE改成"处"就可以为了节省时间这里就不再为大家详细去演示了大家也可以查看我之前发布的关于微调的详细视频通过微调deep thick OCR模型可以发现它之前识别错误的文字在微调之后它就可以正确的识别像这样的话我们就可以针对特定领域或者特定任务场景来微调deep thick OCR大模型或者其他的OCR模型 本期视频所用到的代码和指令我都会放在视频下方的描写栏或者评论区如果你在视频下方无法找到的话也可以通过我的博客去查找本期视频所对应的笔记本期视频就做到这里欢迎大家点赞关注和转发谢谢大家观看