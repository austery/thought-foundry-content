好 那這一堂課呢 是要講有關評量大型語言模型的事情 那我們今天 講了好多有關推論模型的事情 那我們怎麼知道這些模型有好的推論能力呢 事實上啊 今天評量模型推論能力的方法 就是簡單粗暴 直接考他些數學問題 答得對了 就當作你有好的推論能力 答錯了 就當作你沒有好的推論能力 比如說在DeepSeek技術報告的第一頁 他就展示了DeepSeek的模型 還有OpenAI o1系列的模型 在一些數學問題 還有程式問題上面的正確率 AIME呢 是一個數學競賽 那縱軸呢 是這個 答題的正確率 那DeepSeek呢 在這個AIME上 它的正確率 看起來比o1的模型 高了一點點 好 現在呢 評量這些模型推論能力 都是用這麼簡單粗暴的方式 解得出數學問題 就當作你有推論能力 解不出來 就當作你沒有 其實不只DeepSeek的paper是這樣衡量啦 你看這個o系列的模型 它在釋出的時候 也通常會量這些數學的問題 用數學問題來展示模型的推論能力 但是 能解數學問題 就代表他有推論能力嗎 有沒有可能 他只是 我恰好就看過這題數學問題 我知道答案 我裝模作樣的推論一下 然後直接把我知道的答案輸出來 然後你以為他很會推論 其實他只是正好看到一樣的問題而已 有沒有可能是這樣呢 還真的不是不可能的 這篇paper是去年10月的paper 他想知道 有多少答案 可能是記憶出來的 那在衡量模型數學能力上啊 有一個很知名的資料集叫做GSM8K 裡面都是一些比較簡單的應用問題 那今天多數模型 GSM8K的問題 都是可以答對的 那這篇論文就說 那我們把GSM8K這些應用題裡面 的一些symbol 一些符號換掉 看看會不會怎樣 比如說 GSM8K裡面常常出現人名 那這個人名呢 跟解題是 完全沒有半毛錢關係的 比如說這邊有一個人叫Sophia 換成別的名字 會發生什麼事呢 然後這邊還出現了一個親戚關係 Sophia 看到他的侄子在做什麼 那把侄子換成別的親戚 會怎麼樣呢 或者是 把數字換掉 把數字換掉並不會影響問題的難度 但是對模型的正確率 會不會有影響呢 所以這篇paper 就把原來的 GSM8K裡面的題目 裡面的一些詞彙 一些數字改掉 在不影響問題難度的前提下 再去問市面上多數模型這個問題 好 那在這一頁投影片裡面啊 縱軸的數字 代表說 在這個新的 有一些文字被置換的 GSM8K上 相較於原來的GSM8K 模型的正確率掉了多少 那你會發現 多數模型 它的正確率 都是有減低的 尤其是 像這個Mistral啊 Gemma啊 看起來他們的正確率 都受到了 蠻大的影響 所以看來這些模型 它是有稍微背到一些這些問題的答案 不然 為什麼換了一下數字 換了一下人名 你就答錯了呢 好 不過其實啊 從這個結果看起來啊 這些會推論的模型還是蠻厲害的 比如說 o1-mini 這個是去年10月的文章 那個時候就已經有o1-mini了 o1-mini 受到的影響 看起來是蠻小的 其實這篇論文呢 後面還有很多內容 比如說 他們用一個奇妙的方法 打爆了o1的模型 他們在他的題目裡面啊 加上一些完全不相干的句子 然後就可以讓o1模型的錯誤率（此處應為正確率）暴跌 不過我覺得這並不能夠說o1模型 沒有推論能力或者是記憶了那個題目 因為我覺得他們加的那個句子 如果是給人類看的話 人類應該也會有影響 比如說他告訴你說有三個蘋果 然後後面括號說 嗯 其中有幾個爛掉了 然後那你 你作為一個人類你會想說 那出這個題目到底是什麼意思 這個爛掉蘋果到底跟解題有沒有關係 那結果是跟解題沒有關係啊 我覺得就會讓那種reasoning model想太多 最後答錯 那我覺得人類遇到這種題目 也蠻有可能會答錯的 所以我覺得 後面 說這個他們說改了題目以後 o1 performance就很差 這邊感覺可以做一些更嚴謹的測試 比如說讓人也來做一些題目 如果人不會被影響 模型被影響了 我們才比較好說 模型可能是 背到了這些題目的答案 好 但是這樣子的發現其實很多 這邊再另外引用一篇論文 他們嘗試了幾個模型 叫他們解GSM8K的問題 那他們做了兩種題目 那灰色的代表是原來GSM8K的題目 藍色的代表是 把一些句子的順序對調 但是不影響題目的意思 他們發現說啊 把一些句子的順序換掉 這些模型解題的正確率 居然都下降了 所以看起來呢 模型 它學到了一些不該學的東西 那有人可能會想說 那我們要怎麼避免模型學到不該學的東西呢 你想想看 今天這些模型啊 它都是在網路上看過非常大量的資料 所以 他們有偷看到 GSM8K裡面的題目 是非常有可能的 那怎麼解決這個問題呢 有人可能會想說 也許我們就是在訓練的時候啊 把訓練資料裡面 看起來跟GSM8K測試資料一樣的題目 把它拿掉 那避免模型呢 偷看到這些會拿來做測試的題目 但這樣的方法其實 不能夠完全解決問題 因為你想 搞不好有人把GSM8K呢 隨便做個翻譯 翻成蒙古文 然後放在網路上 然後你的這個爬蟲也爬到了 也拿來訓練語言模型 但它蒙古文 所以你也不知道它是GSM8K 所以模型可能還是看到了一樣的題目 只是用不同語言看的 那今天模型蠻有跨語言學習的能力的 所以它等於還是看到GSM8K的題目 只是 但是你又不好 你又不容易檢測出來 你總不能夠把GSM8K英文 翻成所有的語言都去檢查一遍 所以你不太容易檢查出 模型有沒有偷看到這一些你要問他的問題 好 所以今天啊 這些測試的結果 往往不一定那麼可靠 因為你永遠不知道說 這些模型是不是早就看到了 類似的問題了 今天在做這個模型推理能力測試的時候 有一個現在很常被討論到benchmark corpus 叫做ARC-AGI 在o3那個模型釋出的時候 也特別幫ARC-AGI宣傳了一下 那ARC-AGI是什麼樣的題目呢 裡面都是這種有圖形的 智力測驗題目 裡面的題目都是像這樣子的 給你這張圖 然後告訴你說正確答案是這樣 給你這張圖 告訴你正確答案是這樣 給你這張圖 告訴你正確答案是這樣 給你這張圖 然後問你說 正確答案是什麼 這算是一個比較簡單的問題啦 這邊的規則就是 看看在原來圖裡面 哪一種形狀最常出現 就輸出那個形狀 所以這一題 是這個 加號最常出現 正確的答案 就是這個樣子 但像這種ARC-AGI的好處是 模型在回答的時候 它不能夠憑藉著 它已經看過的的東西 它在網路上已經學過的知識 來回答問題 希望模型可以憑藉著它真正的推理能力 來回答這些問題 那我剛才有講說在o3釋出的時候 有特別宣傳了一下 他們在ARC-AGI上面的能力 在o3釋出的demo影片裡面 他們在ARC-AGI放的示範題目是這樣子的 就這是輸入 這是輸出 這是輸入 這是輸出 這是輸入 這是輸出 這是輸入 然後問你說 正確的答案 應該長什麼樣子 那這一題呢 可能就沒有那麼直觀 那這一題其實正確的答案是 外面這個有顏色的框框 它的厚度 就是裡面有顏色點的數目 所以今天這一題呢 要再這一個黃色框框外面框一圈 這個裡外面要框兩圈 這邊要框五圈 這個其實也是ARC-AGI裡面 比較簡單的題目 你在ARC-AGI的官網上面 可以找到很多它的範例題目 有一些蠻難的 裡面有蠻多 人類花一些時間還是想不出來的題目 好 那可能會問說 那這種語言模型是怎麼解這種圖形的問題的呢 難道也要考驗語言模型看圖的能力嗎 其實不是 ARC-AGI呢 丟給語言模型的時候 它的題目 長得像是 這個樣子的 所以它是用文字 來表示那些圖案 然後用數字來表示不同的顏色 比如說0就代表沒有顏色 12345分別代表不同的顏色 就告訴模型說 這是輸入 這是輸出 這是輸入 這是輸出 這是輸入 接下來 你要輸出什麼 那ARC-AGI呢 過去一直被認為是一個蠻困難的問題 事實上ARC-AGI 我記得是 2019年的時候 就已經問世了 但從2019年問世以來 這個ARC-AGI呢 一直沒有人有取得非常重大的突破 順帶一提 ARC-AGI的作者呢 其實就是Keras的作者 欸 現在還有人在用Keras嗎 大家知道Keras是什麼嗎 知道Keras的同學舉手一下 好 很少啊 這個時代 Keras的時代 過去了 這個時代真的變化很快 這個ARC-AGI作者呢 其實就是Keras的作者啊 這一張圖是ARC-AGI 他們有個官網 官網上 截下一張圖 這張圖是要表示呢 ARC-AGI 真的是一個非常困難的問題 這邊縱軸呢 代表的是 正確率 這邊每一條線 都代表一個 benchmark corpus 橫軸 代表的是那個benchmark corpus 被釋出多長的時間 那你會發現說 多數的benchmark corpus啊 都在釋出兩三年之內 就被打爆了 被玩壞了 被模型overfit 可以得到 將近100%的正確率 但是 ARC-AGI 在釋出的五年之內 沒有非常大的進展 正確率的進步 是非常小的 然後這邊有一個peak 就是因為他們辦了一個比賽啦 辦了一個叫ARC Prize的比賽 就如果你做得好 有錢可以拿 比較多人參加 所以正確率就提升了 但現在啊 o3 看起來在ARC-AGI上 居然是可以得到挺不錯的結果的 這個縱軸呢 是ARC-AGI上面的正確率 橫軸代表什麼 橫軸代表 這個模型 回答一個問題的時候 要花多少錢 然後呢 這邊就比了o系列的模型 這個是o1-mini、o1-preview 還有o1 (Low)、o1 (Medium)跟o1 (High) 這指他們的推論的過程有多長 那這邊呢 也有一些人類的結果 比如說這個點 是平均人類的表現 這個點 是數理科的畢業生的表現 那你發現說 o3 最強的模型 是介於 這個 比一般人類還要強 弱於STEM領域學生的能力 所以 哇 他居然可以比 一般人類還要強 不過他付出了非常大的代價 你看這個縱軸 這縱軸是1000啊 1000美金 所以每答一題 需要耗費相當於1000美金的算力 才有辦法回答一個問題 但是我覺得ARC-AGI啊 雖然它當初創立的目標 就是避免模型去網路上 記一些它已經看過的東西 他們相信這些問題 你在網路上可能找不到一模一樣的 而且他們有一個隱藏的testing set 那個testing set是沒有公開的 你 他們最後呢 評比的結果 會看那個沒有公開的testing set上的結果 但是呢 其實也不完全表示 你沒有辦法去fit ARC-AGI這個比賽 因為你想想看 它比賽的題型 它有釋出 它有釋放出一些範例問題 所以你完全可以根據它的範例問題 自己再創造出更多更多的題目 [聽不清楚] 創造了幾千萬題 然後我的模型什麼都不做 就光刷ARC-AGI 搞不好也可以刷出一個好表現出來 也說不定 所以我會覺得 就算是像ARC-AGI這種題目 他說這是比較接近 智力測驗的題目 那你沒有辦法在網路上找到一模一樣的題目 也許可以防止模型 背了這些問題的答案 但是要hack這種比賽 我覺得也不是完全不可能的 好 那要怎麼樣才能夠公平的衡量模型呢 有人說 哎呀 你只要有一個固定的出題方向 就有可能被猜題猜中 就想說 假設是有一個單位在出題的話 那個單位可能就會有固定的出題傾向 有固定的出題傾向 它的呼吸被抓到以後 這個benchmark就很容易被玩壞 那能不能夠讓全世界的人都來測 這樣就沒有固定的出題傾向了呢 所以 有一個benchmark 也它不能夠稱作為benchmark 有一個平台叫做Chatbot Arena Chatbot Arena呢 就是你在那個平台上 你每次登進去的時候 他就隨機給你兩個模型 模型A跟模型B 接下來呢 你就問這兩個模型 一樣的問題 比如說我這邊問他 如何評估模型的推理能力 兩個模型都給我答案 然後你要決定哪一個模型是比較好的 根據這些比賽的結果 每一個模型會有一個分數 然後會有一個排行榜 那有人就會想說 像Chatbot Arena這一種 評量方式 應該就很難被hack了吧 因為它是全世界的人 都可以來問問題 全世界的人都是主考官 你根本不知道全世界的人 會問什麼樣的問題 你根本沒有辦法針對特定的題型 去訓練你的模型 但 真的是這樣嗎 傳說 Chatbot Arena 也是有辦法被hack的 因為人類 還是有他 喜歡的傾向 比如說一個傳說是 假設你的模型輸出比較多的emoji的話 你就可以在Chatbot Arena上打爆其他人 或是如果你的模型 比較會產生這一種 有粗體字啊 或者是有bullet point啊 就會比較容易獲得青睞 或是你的模型呢 比較喜歡長篇大論的話 你就比較容易獲得青睞 所以有人會說 Chatbot Arena 其實也沒那麼準 因為多數人在評比這些模型的時候 你根本就不會仔細去看它的內容 你通常是看他輸出的風格 所以輸出的風格 反而對結果 影響比較大 輸出的內容 現在這些模型都很強了 一般人的知識也沒那麼多 模型是不是在唬爛的 你也看不出來 所以就好像說你要評比一個比你聰明的人一樣 他講的話到底是對不對 你根本就無法評斷 你只能聽他聲音好不好聽而已 所以Chatbot Arena 也不是完美的 那其實Chatbot Arena這個官方呢 他們也有想辦法想要解決這個問題 他們怎麼解決這個問題呢 我們就來先簡短介紹一下 Chatbot Arena的評比機制 他們這邊呢 用的是Elo score 那這也是很多競賽呢 會使用的 評比方式 它算法是這樣子的 每一個模型啊 這個 假設有大K個模型 M1到MK 每一個模型 都會有一個分數 這個分數 代表它的戰力 這邊用β 來代表這個模型的戰力 所以第一個模型它的戰力是β1 第二個模型它的戰力是β2 以此類推 那今天 假設隨機匹配到兩個模型 第j個模型 跟第i個模型的話 這個時候啊 這兩個模型評比的時候 這兩個模型對戰的時候 它的勝率 會取決於這兩個模型 它的戰力的差距 所以 第I個模型 贏過第J個模型的機率有多大呢 它可以根據這兩個模型的戰力 計算出來 這個戰力怎麼計算呢 它這邊的方法就是 把第I個模型的戰力 減掉第J個模型的戰力 除掉一個normalization的分數 這是為了讓分佈比較好看一點 通常都會設成400 前面乘一個負號 再取exponential 這其實就是sigmoid function 如果 I的戰力比J的戰力 大很多的話 算出來的數值就會趨近於1 代表說 I呢 幾乎確定能贏J 如果I呢 比J小很多的話 如果I比J小很多的話 那 β i減β j就會是一個負值 exponential負的β i減β j 就會是一個很大的正值 那算出來的勝率 就會趨近於零 好 但實際上 在這個比賽裡面 你真正能知道的 並不是這些戰力 而是根據比賽的結果 你可以統計 某個模型對戰到某個模型的時候 它的勝率是多少 所以這個Elo score的求法是 我們先得到 先把這些模型 進行大量的比賽以後 你知道模型跟模型間 如果他們對戰的時候的勝率 再根據勝率 你就可以 反推出這些β的值 那這個不是我們今天上課的重點 所以我們這邊呢 就不詳談 總之 你有辦法根據這個勝率 實際觀察到的勝率 去反推出每一個模型的戰力 應該有多少 但在Chatbot Arena上 他們就覺得 會有太多跟模型本身 實力無關的因素 會干擾到評比的結果 所以 當今天計算正確率的時候 只知道β i跟β j是不夠的 要加一項 叫做β0 這個β0 是模型 實力以外的因素 那其實在棋類比賽裡面 有時候也會加上這個β0 比如說 如果在下某些棋類遊戲的時候 先手有優勢 如果先手有優勢的話 那你其實就應該把先手優勢考慮進去 那β0呢 就是考慮先手優勢 好 那如果呢 是在Chatbot Arena裡面 我們剛才講說 有很多事情 可能都會影響 跟模型的本身的實力無關 但是會影響人類對模型的評價 舉例來說 模型 可能回答越長 人類就會越喜歡 所以今天β0裡面 應該把長度的差距 乘上一個常數γ1 當作β0 或者是 emoji的數量 可能會影響模型被喜好的程度 可能會影響模型的勝率 emoji講越多的 可能人類就越喜歡 所以呢 應該計算一下 兩個模型 在這一次評比 在這一次對戰中的 emoji的數量差 然後乘以γ2 總之你可以把所有你覺得 跟模型實力無關 但會影響評比結果的各種factor 通通都找出來 然後前面乘一個γ 代表這個factor的影響的程度 然後全部加起來 變成β0 然後呢 你就可以根據勝率 你就可以根據實際統計出來的勝率 去反推出β 也反推出γ 如果今天 統計出來γ是 正的 就計算出來γ是正的 就是代表說呢 今天長度的差距 是會有影響的 就如果i比j還要更長的話 如果i的答案比j的答案更長的話 那i的勝率就會比較高 那如果γ趨近於零 就代表說這個變量沒有什麼影響 那如果小於零 就代表說這個變量 是負相關的 長度越短越好 等等 好 如果上述講的你沒有聽得很懂的話 反正就是告訴你 有沒有考慮這些實力以外的因素 比如說跟書寫風格有關的因素 其實是有蠻決定性的影響的 好 所以 這個是來自於 那個Chatbot Arena官方blog的一篇文章 他就告訴你說 有沒有考慮 這些風格相關的因素 其實會影響模型的排名 左邊 是 直接根據對戰成績 去計算出模型的戰力 不考慮任何其他跟實力無關 因素的評比結果 右邊 是 把風格的影響 那他們這邊就列舉了一些 他們覺得可能會有影響的 這個變量 比如說 模型回答的長度啦 emoji使用的數目啊 比如說模型的回答有多正面啊 等等 或是模型呢 有沒有使用headline啊 等等 各式各樣的風格都考慮進去 他們發現考慮進去以後 根據模型的戰力 再來做排名以後 這個排名 是有大幅影響的 所以有些模型 你會發現 本來排名在比較前面 經過考慮過風格之後 它的排名就掉了 或有一些模型 它本來排名很後面 但考慮風格之後 它的排名就上升了 其中上升的最多的就是Claude啦 就是Claude Claude系列的模型 所以Claude系列的模型 一直是大家認知 覺得蠻厲害 但是在Chatbot Arena上 不知道為什麼評分起不來的模型 那一個可能就是 Claude的模型講話 太無聊了 你發現Claude的模型 很少輸出emoji 但它並不妨礙說 它是一個很聰明的模型 比如說 它很會寫程式 它很會做網頁等等 所以Claude 雖然是一個蠻聰明的模型 但是它就吃虧在它憨慢講話這樣啊 它不太會講話 所以 它不太會講讓人開心的話 只看人類覺得哪一個模型講話比較好聽的話 那Claude其實佔不到優勢 但是如果去掉書寫風格 所造成的影響的話 Claude其實它的名次 就會大幅向前 所以 這個故事告訴我們 就算是Chatbot Arena 也是有可能被hack的 也有可能會有人訓練了一個模型 就是針對Chatbot Arena的 就是要在這個比賽裡面打贏 比如說我的模型 特別喜歡輸出emoji 特別喜歡講好笑的話 特別喜歡講好聽的話 讓人類高興 然後可能就可以 你的模型 可能不用特別聰明 但可能就可以在 Chatbot Arena裡面佔到優勢 到底什麼樣的指標 才是好的評量指標呢 也許結論就是 沒有好的 評量指標 這個叫做Goodhart's Law Goodhart's Law的意思就是 一旦一項指標啊 被當作目標 它就不再是一個好的指標 有一個講到這個Goodhart's Law的時候 常講的故事 就是眼鏡蛇現象 這個故事是這樣子的 過去在英國殖民印度時期 曾經一度蛇患猖獗 所以英國政府就想說 好 那請大家來捕蛇 每捕到一隻蛇 給你一塊錢 然後印度人呢 為了要賺錢 就在家裡養一大堆蛇這樣 反而蛇就變得更多了 對 這就是Goodhart's Law 那如果要為這堂課下一個結語的話 就是你這麼在意這個評分系統幹什麼呢？ 它會把模型的努力給異化掉的 好 那這個課的結語 就是這句話