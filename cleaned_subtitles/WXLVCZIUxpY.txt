The code is no longer being written by human but by AI system. So much more code is being written now by cursor or Windsor for copilot. AI is going to write so much more code. No one really understands all of it. No one has full context. No team has full context about what's happening because it's such a complex system. When software breaks, it's going to be really difficult to troubleshoot it. Right? One of the biggest problems is downtime is troubleshooting. Global IT cyber outage.
>> Global outage, major IT outage.
>> It's also affecting hospitals, law enforcement departments, banks, and major airlines.
>> The cost of downtime to annually for all enterprises is around $400 billion. So, it's a huge problem.
>> It could be several hours or days before the situation is fully resolved.
>> Fundamentally, what we're doing is when we have large complex software systems, we help figure out and they break, we help figure out what happened. having a team of on call engineers 24/7 looking at all of your data. So by the time an engineer comes onto a Slack channel, the root cause or current root cause is already given. So rather than them spending so much time trying to figure out what happened or you know calling more and more teams because typically what happens is you'll have one team look at the the the data. They're like oh it's not my fault. Then they'll call another team and another team and another team. That's how you go from five people to like 80 people on a channel, right? And so then rather than 50 people over an hour, it's like 5 to 10 people for a few minutes just verifying the answer. My name is Anish. I'm the CEO and co-founder of Traversal. We came ourselves with $48 million in the series A funding which were led by Sequoia and Kleiner Perkins. We just announced our series A raise and we came out of stealth. We're building an AI site reliability engineer. So what that means is when you have large complex software systems and they break, we troubleshoot to help you figure out why it broke and then help fix it automatically. But it's sort of like perplexity when when you ask perplexity a question, it kind of gives you evidence, right? It gives you citations of how it got to that answer. But our world that the citations aren't web links, the citations are links to your observability system that we can now publicly talk about. We've been working with them for the last 6 months now very closely is Digital Ocean. So they're a large public cloud service provider. I think they're the third largest actually by number of people using them as their cloud provider. I think they have over 600,000 people um using them as their core infrastructure. And you can imagine when they break, you know, every person that is using them feels the pain because that's the main thing powering their their system. We've been working with them for 6 months now and we found that in that 6 month period we've dropped the the time to resolution by over 40% like 37% to be exact, which is incredible, right? Because as I said, every minute of downtime is like is worth thousands of millions of dollars. I like sports. I like competing a lot and I always naturally gravitated to math and science. I just liked how abstract and clean it was and it felt quite universal in and what you could do. I came to MIT just because I thought machine learning and AI was really important and I wanted to understand it really deeply. This is like 2016. about like 8 n years ago and once I got there I think the one of the biggest moments in my like academic research career was Europe's 2017 and the keynote was given by the Google AlphaGo team and I just found that incredible that a system can learn this creative thing by itself because the complaint you always had before was that it's just copying people but this was purely it was learning creativity by by selfplay so I was like we should apply that everywhere this kind of architecture I was fortunate enough to get into Colombia's faculty and I like thinking about theoretical problems mathematical abstractions And I think university is an amazing place to do that. The thing that changed and that was the time when everything with Chad GPT was was happening. And so it just felt like something incredible has happened in the world. And it's like a once in a-lifetime thing where the world is fundamentally changed. People don't even realize it. It just felt like this almost religious experience as to what was happening in the world. I really like uncertainty. I like creating something from 0 to one. similar between research and entrepreneurship is that the uncertainty you have no idea what's happening most of the time and you have to find ways of of creating structure from nothing I think obviously the difference is in here the time spans are compressed right in research you get 5 years 10 years to to make an impact here you get 1 month right so the feedback cycle is very quick but I think in this age of AI when AI is shooting so quickly being in that quick feedback cycle is actually very important we've kind of entered into the industrial age of artificial intelligence you And I also saw some of the smartest people around me. They were either at OpenAI or Enthropic or you know Meta or they were creating companies and that's what makes me really excited. And so I think starting a company was felt to me like a great expression of that. I guess I think the best AI companies are always going to be at the edge of where the models are going to be, right? That's how you differentiate yourself is you're always at the edge. If you're the edge and sometimes it works, sometimes it doesn't work. And you need to know quickly when it's working and when it's not working and correct for that. When we started the company in like January of 2024, we started without an idea. But we had a clear taste of the type of problem we wanted to take on. So we wanted to do something that was at the intersection of our research which was in causal machine learning and reinforcement learning and how it intersected with AI agents. Causal machine learning is a study of cause and effect. And what you want to understand is how do you get these AI systems to pick up cause and effect relationships from data. AB test is an example of of learning cause and effect relationships. like clinical trial is another example. So these are like basic ways of of running experiment. And so that's what the study of of causal machine learning is and we're trying to see how did that intersect with AI agents uh which we thought was like super cool and something we followed for like now almost 2 and a half years. We went through a few different ideas. The fourth person who joined us our fourth co-founder Ahmed and so he pitched us the problem of dealing with incidents. And as we looked into it, it kind of felt like a perfect problem finding this needle in a hay stack with many fake needles everywhere. So it fit with our research in causal machine learning and reinforcement learning really well. It fit with LLMs really well because the haststack is composed of like logs and metrics and traces and code and configuration files and so on and so forth. It fits with AI agents really well because you have to automate this complex workflow where you're, you know, querying all these different pieces of software. You're reasoning over them and then you're writing more queries and it's like this like sequential adaptive flow. And so it's a big market because everyone cares about software not going down. And I think it's only going to get bigger, right? because so much more code is being written now by companies like cursor or windsurf or copilot or what have you just like cambrian explosion of code being written no one understands it in some ways and so when software breaks it's it's going to be really difficult to troubleshoot it right and so I think that's what gave us confidence that this is the problem we should be taking on and then honestly the first VC I met in my life was Sequoa and I think they've been looking for a team to solve this problem they reached the same thesis they felt this is the problem where like the AI risk and technical risk is high and the market risk is low because if you can solve it, there's a big market and so people like us who don't come from this world but are good on the AI side are the right people to solve it. And so obviously that validation also give us confidence that this is the right problem. A lot of what these AI agent companies are doing is trying to replicate what humans have done, but there's so much more that can be done. And so thinking from first principles what AI systems are good at and exploiting that versus just trying to replicate what a human has done I think is also going to be very important to reinvent and actually get to the next level of innovation. Creating a MVP is so easy with all the tools out there. You can really iterate quickly with putting a product in people's hands. We built our first MVP probably last year in June or July like about 3 months in. And with small companies it worked great because the scale of the data was small. we could kind of look at their historical incidents, see what the playbook was and then put that into an AI agent. And so like our accuracy was like 90%. Something amazing, right? So we felt really confident that this is going to work. Just because it works in the one time doesn't mean it's always going to work because the world is constantly changing. And then we hit some of the larger enterprises including Digital Ocean, our accuracy went to 0%. Which is very difficult to see. It was a tough week. Creating an MVP is easy, but creating a production system that works in complex environments is really hard. And so I think one should not confuse an MDP with a production AI system. Those are like two very very very different things. But then we rearchitected a lot of things. We said how do we make sure that we're no longer trying to use our creativity and seeing you know get that into an agent but really use what these AI systems are good at which is using computation right using inference. That's really what unlocked us and suddenly our accuracy went back to up to 90%. How do you make sure that your system gets better with the reasoning models? because there are a lot of people we saw in competing companies and so on and so forth where as the reason models came out they didn't get any better. So how do you make sure that you're exploiting what the reasoning models are good at? And the way I put it is that the reasoning models are very good at like detective stories. You have a mystery novel and you're trying to figure out who who did the crime. There's all these different pieces of evidence that you're seeing and you're trying to figure out who is the person who did it. Connecting all those dots and figuring out the thing, you know, the person who did it. that kind of detective story type workflow which I think these reasoning models are very good at where you have a clear answer at the end and you have lots of moving pieces that you have to like connect the dots between to get to the clear answer that felt kind of perfect for us right because for us you have all these different symptoms that happen at the same time you find ways to connect the dots to find that specific right answer like who did it making sure we were exploiting them to the maximum was was crucial I think and so I think that's the way I would put it is going to write so much more code and no one really understands all of it, right? If you wrote all of it, you have in your head just how it all fits. And as you get to bigger and bigger systems already, right, you work with some of the largest fortune 100 companies, no one is full context. No team is full context about what's happening because it's such a complex system. And that's just happening not just at the large companies, but also at the small companies because this the code is no longer being written by human but by or engineer but by AI system, right? So the lack of context means that when it's when an incident happens, it's just so much harder to debug it because you just don't have all of the context you need. And actually it's already happening like most people now are not developing code. They're starting to like validate QA code or troubleshoot code and that doesn't scale. So that's the big problem. And I think the second big problem I think is that you know with all all the developments happening with AI software engineering, our belief is that as engineers we get to do the really creative fun work architecting system design. Over time, all engineers will be doing will be troubleshooting, which would be sad in my opinion. Like they should be doing the most we as a as engineers should be doing the most creative work, right? And to to make that a reality, you you need to have systems, not just developing your software and building it, but also maintaining it. And so I think all of software maintenance needs to be reinvented. You have to just kind of persevere. If something goes wrong, that's okay. I think it in some ways it's a good thing because if it was easy, then everyone could do it, right? I think this is one of those problems where the problem statement is very easy to state, but to actually solve it is really hard. And I think that's where there's like a lot of companies trying it, but very few actually succeeding. And I think having the ability to like stay resilient and have grit when something doesn't work and just stick with the problem is, I think, a big part of what differentiates us uh as a company. Think about what's going to be important 10 years from now regardless of whatever happened in the world. You have no idea what's happening most of the time. And you have to find ways of of creating structure from nothing. And so like one way I say it is that you know in typically hard jobs whether it's in finance or it's in technology as an engineer like you have a point A if you get a point B and it's very hard to get from point A to point B in the world of research and also in the world of entrepreneurship you don't really know where point A is you don't know where you are you don't know where point B is you don't know where you want to go and if you did know it's still very hard and so you're constantly like in this game of trying to just decide where you are and where you're trying to go and that's exactly the same thing in research as well. What's interesting in this job is that the the stresses are are can be very high, lows can be very low. So, I think getting used to like just very high highs and low lows is important. But I think that one thing I've learned is that time it takes me to to recover is very fast. Even if I'm super stressed, I'm super tired, within one or two days, if I just take it off, I'm back to full force. And so I think that's been like a good learning is that if you're really enjoying what you're doing and even though there's these moments of massive stress, levels of stress that you'll never face otherwise, if you really love a problem and you're you're attracted by it, that's where attracts other people, right? We all love the problem. We're all faced in our lives. And so we really feel like a great deep desire to solve it. And probably the most important thing out of anything is surround yourself with people that you care that you like that you want to be like. And if you do that, life will be okay. I think about my research life. I found the right PhD adviser advisers that really molded me and guided me the right way. If I think about this world, I found the right investors that guided me at the start, the right customers that you know that helped define the product. You live and die by the people you you surround yourselves with and the people will kind of guide you through these different parts. And so I think building a taste for the right people to mentor you and and be a partner with you is the most important thing. The rest of it, I think, will figure itself out if you can find the right people around you. But I wouldn't just start a company for the sake of it. I think you should you should feel like some thing deep in you cuz it's not easy. And so you need that kind of deep belief or you know or motivation to sustain you over time.