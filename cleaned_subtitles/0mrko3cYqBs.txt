2025年10月底 Meta AI部门宣布裁员600个职位 甚至核心部门的研究总监 掌管AI业务的高管纷纷离职、被边缘化 就连图灵奖得主Yann LeCun 也被认为自身难保 在看到新闻的时候我很震惊 一方面扎克伯格在用上亿美元的年薪 去挖AI人才 但同时又如此决绝地裁员 这样割裂的行为背后是因为什么 于是我们采访了Meta的前FAIR研究总监 AI科学家田渊栋 参与了Llama 3后训练的 前Meta员工Gavin Wang 硅谷资深HR专家以及一些匿名人士 试图还原一下Meta的Llama开源路线 到底发生了什么 为什么Llama 3还让众人惊艳 而仅一年之后的Llama 4就如此拉胯 中间发生了什么 Meta的开源路线 从一开始就注定是个错误吗 AI大模型激烈对战的当下 一个乌托邦式的AI研究实验室 还能够存在吗 不能让不懂的人来做整个领导者 或者说让人来做那个规划的 Llama 4规划的时候 其实就会感觉到 这个地方可能领导层的方向 有一些变化 有钱、有卡、有人、有数据 这四个的话Facebook几乎什么都有 它为什么现在做得不够好 那我们就进入今天的视频 来看看Meta的开源AI路线 是如何碰壁的 首先我们要来说一下 Meta对AI布局的整个公司架构 2013年年底 扎克伯格开始搭建Meta的AI团队 当时谷歌收购了 Geoffrey Hinton的DNN团队 将Hinton招入麾下 同一时间 Meta将Yann LeCun请来坐镇AI的发展 至此 图灵奖三巨头的两位 开始步入商业科技来主导AI研发 在扎克伯格邀请Yann LeCun 加入Meta的时候 后者是提过三个条件 第一是不从纽约搬走 第二 不会辞去在纽约大学的工作 第三 必须开展开放的研究 公开发布所做的所有工作 并且将代码开源 所以我们看到一开始 Meta的路线就是开源的 Yann LeCun进入Meta之后 开始着手前沿的AI研发 组建了Fundamental AI Research实验室 也就是大名鼎鼎的FAIR实验室 主导人工智能的前沿研究 FAIR是负责前沿研究的 就是说做一些现在目前看起来 你没有特别大的那个应用 但是新的想法、新的思路、新的算法 新的框架、新的模型架构 所以这样的探索之后可能会有些大的突破 大概是这样的一个逻辑 但是对于Meta来说 最终还是要看到AI在自身产品上的进展 于是和FAIR组平行设置了一个组 叫“Generative AI” 简称“GenAI”组 这个组里面分别有不同的功能团队 包括了Llama开源模型的研发 将AI能力运用在产品上的Meta AI团队 还有AI算力基建的数据中心团队 其他的还有一些小部门 比如说Search（搜索） Enterprise（企业服务） Video-gen（文生视频）模型等等 GenAI和FAIR是平行关系 就像一个天平 一边是前沿科研 一边是产品化 理想情况下 前沿研究能够带来更好的产品力 而产品赚钱了就能够让管理层 有更大的动力去拨款给FAIR做研发 FAIR提供一些很好的想法和工作 然后想法工作会给那个 比如说给GenAI去用 然后让GenAI去把它放进生产 然后在下一代模型中使用出来 很多人的初心就是说想做一些 不一样的东西 与众不同的方向 与众不同的工作 然后能不能真正地实现AGI（通用人工智能） 这个其实是比较大的问题 所以FAIR的目的是AGI（通用人工智能） 但是GenAI它的目的是 怎么把AI放在Meta现有的产品中 然后让AI发挥效应 应该说主要一个是Llama Llama是一个很大的模型 然后还有就是说怎么样让AI 怎么样做一个比较好的 就是把它用在一些具体的应用上 但是让这样的天平始终保持平衡 是一个很理想化的乌托邦状态 而这个乌托邦状态的前提是 Meta的AI模型水平 一直是要保持最领先的 或者说至少是在开源赛道最领先 而且不落后闭源模型太多的 你觉得在FAIR 最快乐的一段时光是什么时候 我觉得FAIR应该说从我入职之后 到2022年都很快乐 对 我觉得这段时间应该是很开心的 因为大语言模型来之后 大家开始 就是整个生态或者说研究者之间的关系 发生了一些变化 对 因为大语言模型来之后 算力成了很重要的一个因素 算力是有限的 所以就会产生各种问题、各种矛盾 就是大家都要训练一个很大的模型 如果是这样的话 相互之间就开始有一些问题 相互之间比如说因为我卡多了 你卡就少了 但是卡不多就没办法训练出好的模型 所以正因为有这个原因 在2023年之后这段时间之内 其实应该说状态肯定不会像以前那么好 而Meta的AI天平是如何失衡的呢 我们可以从Llama的四代发布中 看到一些端倪和痕迹 那顺便说一句 之所以Meta给自家大语言模型取名“Llama” 据说是因为考虑到 Large Language Model的缩写“LLM” 不太好发音 所以就补上了元音字母 那么“Llama”念起来朗朗上口 也便于记忆传播 也正是这样 大语言模型命名 自此才和“羊驼”扯上了关系 那我们先来看一下Llama 1 这也为Meta的大模型“开源”路线 奠定了基础 2023年2月24号 Meta发布了Llama模型 主打“更小参数更好效果” 发布了7B/13B/33B/65B的多规模版本 强调当时的13B模型可以在多项基准上 超过175B参数的GPT-3 而Llama在官宣之后的一周 权重在4chan上以种子形式被“泄露” 是引发了AI社区对开源模型的广泛讨论 甚至还引发国会参议员致信质询Meta 虽然有不少质疑的声音 但业界对Llama的“意外泄露” 出人意料的支持 而这也被视为 是“大模型开源”的格局重塑 并且很快催生出了 诸多的民间微调项目 我们在这里稍微解释一下 大模型的“开源”的这个定义 其实Meta也不是完全的开源 Meta称之为 “开放权重”（Open weights） 那么这个weights（权重）是什么东西呢 在机器学习中有三个部分 结构（architecture） 权重（weights）和代码（code） 所谓“权重”就是模型学习到的 所有参数数值 模型训练完成之后 所有的参数会存在几个巨大的二进制文件 每个文件里面保存着 每一层神经网络的矩阵数值 而在推理的时候 模型代码会加载这些权重文件 用GPU进行矩阵运算生成文本 所以“开放权重”就意味着 向公众提供训练好的参数文件 外界可以本地加载、部署和微调 但还不是完全的“开源” 因为真正的开源意味着公开训练数据 代码和许可等等 但是Meta并没有公开这些信息 甚至之后的Llama2、3、4代 都仅仅是开放权重 只是在许可证的政策上有些许的松动 那么结论就是 虽然Llama属于“半开源” 但是比起比如说OpenAI Anthropic和谷歌完全闭源 只通过API接口 来提供模型能力服务的这些公司来说 Llama已经算是给开源社区 带来了非常旺盛的生命力了 2023年7月28号 Meta联合微软发布了大模型Llama 2 包含7B、13B和70B参数的三种参数变体 新一代模型的“开源” 虽然也是“开放权重” 但对比Llama 1的 不可商用、只能申请研究用途而言 Llama 2是一个免费可商用的版本 更放宽了许可证的权限 而Wired等杂志更是指出 Llama 2让“开放路线” 对抗封闭模型巨头成为现实 而我们看到 Llama 2很快在开发者社区 是风靡起来 它的可得性显著放大了生态还有AI开发 这将成为大家今后 首选的模型 不用再被 OpenAI API 的限流约束 也不用再跟客户解释 为什么还得按用量 额外多付几美元 关键差别就在这里 Meta和Microsoft这一步大胆之举 彻底改变了行业格局 他们逼得其他公司 不得不更开放 因为他们为 优秀模型应该是什么样 开源许可该怎么做 树立了新的行业标准 那么之后就到了2024年的Llama 3 这也是Llama系列 最为风光和辉煌的时候了 步入Llama 3的时代 Meta已经成为AI开源社区的顶流存在了 2024年的4月到9月 Meta是连发三个版本的模型迭代 2024年4月18号 Meta发布了8B、70B的 两个规格的Llama 3版本 称同等规模“显著超越Llama 2” 并将其作为Meta AI助手的底座之一 之后的7月23号 Meta推出了405B、70B、8B 三档Llama 3.1模型 并且宣称405B是 “全球最强的开放可得基础模型”之一 同时登陆 AWS Bedrock、IBM watsonx等平台 仅两个月之后的2024年9月25号 Meta推出了Llama 3.2 主打小而全的多模态 增加1B与3B轻量文本模型 与11B与90B的视觉多模态模型 面向终端和边缘场景 AWS等平台同步接入 开源框架平台Ollama亦可本地运行 我们采访到了 Llama 3团队的Gavin Wang 他负责Llama 3的后训练工作 对我们表示 当时整个Meta当中 GenAI团队真的是在以“光速”前进 真的有一种 “AI一天 人间一年”的感觉 我当时（Llama）3.1/3.2 确实是有很多很好的进展 比如说多模态 Multi-model 是在这个阶段里面发布的 然后包括后面他们做 Lightweight model（轻量化模型） 1B/3B的 就是非常轻量化的模型 我觉得在这个地方都是 为了产品化生态做出了很多的进展 很多的开源社区支持 包括我有朋友在Llama Stack那个团队 他们就是专门支持 整个Llama的生态 在企业级或者说小企业级的落地 Llama 3的强势出击 特别是450B版本 被认为是在模型能力上 对闭源阵营的逼近 也被认为是 将快速推动AI应用的落地 而对于Meta内部员工来说 特别是在Llama组的AI工程师们 这是一件非常非常 让他们值得骄傲的项目 当时那个narrative（叙事）就觉得 Meta是大厂里面唯一一个剩下 开源的一个模型 而且还对整个开源生态很有贡献 当时我觉得很多人都会觉得 就不仅仅是在做一份工作 而是说我们真的就是在支持整个 AI的前沿的一个发展 就是你做的每一件事情 都感觉非常的有意义 我当时其实是非常自豪的感觉 我出去跟别人说 我是在做Llama Llama 3团队 他们是一些创业公司创始人 他们都会说 非常感谢你的努力 就感觉整个技术圈 尤其是AI创业圈 就是都在指望Llama Meta乘着东风 期望Llama 4的发布能够进一步扩大 自身在AI开发社区的影响力 保持“顶尖大模型中唯一开源存在” 扎克伯格在2025年1月底的 财报会议之后发帖说 我们对Llama 3的目标 是使开源与闭源模型具有竞争力 而我们对Llama 4的目标是领先 然而 三个月之后的Llama 4发布 却是一场彻底的灾难和滑铁卢 2025年4月5号 Meta推出Llama 4的两个版本 Scout与Maverick 宣称多模态与长上下文能力大幅跃进 并在宣传中高调引用 LMArena排行榜上的领先成绩 Maverick版本仅次于Gemini 2.5 Pro 与ChatGPT 4o和Grok 3 Pro并列第二 然而很快 开发者社区的反馈并不正面 认为Llama 4的效果不及预期 市面上开始有流言 质疑Meta 在LMArena上面冲到第二名的版本 有作弊嫌疑 怀疑Llama 4给LMArena排名的 是经过了优化的变体 而这个变体是经过了对话强化的训练 存在误导LMArena、导致过拟合的现象 虽然Meta高层迅速否认了作弊 但是影响是迅速地发酵 一方面媒体纷纷将此视为 “用特调版本刷榜”的 “诱饵调包”（bait-and-switch） 行业对基准公信力 和可复现性的讨论迅速地升温 另一方面 Meta更高端的Behemoth版本推迟发布 公关与节奏严重的受挫 那在我写稿的时候 Behemoth还没有发布 Meta应该是放弃了 接下来就是大家所知道的 扎克伯格开始孤注一掷的 大手笔收购Scale AI 把Alexander Wang挖来领导新的AI架构 之后用上亿美元的支票开始挖人 疯狂搅局硅谷AI人才市场 再之后就是最近的新闻 Alex开始重组整个Meta的AI架构 裁掉600人 但大家来看看这个时间线 是不是还是觉得很割裂 那么在Llama 3和Llama 4的 这一年当中 发生了什么 怎么Llama 4一下子就不行了 这是不是也太快了 那我们通过复盘 也许是找到了一些答案 还记得我们在前面说的 Meta内部的AI架构是一架天平吗 那么Llama 4失败的原因 很可能就是这架天平失衡了 那我们再回到Meta的AI架构上 FAIR和GenAI是并行的两个组 Yann LeCun管FAIR 但Yann LeCun很多时候 都沉浸在自己的研发当中 有时候还在网上跟人 比如说马斯克对战 还经常说不看好LLM路线 让Meta很头疼 于是2023年2月 Meta高层就把Meta AI的 研究负责人Joelle Pineau调到FAIR 担任FAIR的全球负责人 与Yann LeCun两个人一起领导FAIR 而GenAI部门的负责人是Ahmad Al-Dahle 这个哥们儿之前在苹果工作了快17年 而扎克伯格把他挖过来的原因 就是想把AI和Meta的各种产品结合起来 包括元宇宙 智能眼镜的AI整合 以及聊天工具meta.ai等等 而就在经历了Llama 2的成功 公司开始研发Llama 3的过程当中 Meta高层是越来越强调 “要将AI用于自家产品”的属性 于是我们看到2024年1月份 Meta的AI团队进行了一次重组 FAIR的两名负责人开始直接汇报给 Meta的CPO（首席产品官）Chris Cox 整个Llama 1~3算是一个时代 就是说大家很疯狂地 在卷scaling law（规模化法则） 当时整个行业里面 就是说是基础模型的能力的提升 大家在探索foundation model（基础模型） large language model（大语言模型） 本身的一个能力的边界 但是Meta的领导层 像Zuck（扎克伯格） 还有CPO Chris Cox 他们其实很早就意识到 LLM的能力要能够落地 就是真正为社会产生价值 他肯定是从产品力上去出发的 所以说当时Llama 2 和Llama 3阶段 整个GenAI的核心目标是 就是让研究成果真正产品化、工程化 也因此就是在最高管理层层面 副总裁 高级总监这个层面 公司的中高层 可以算是基本上是高层 是有一些 之前更多的是产品背景和工程背景的人 来领导 在Llama 3成功推出 Meta高层开始制定 Llama 4的路线之际 所有的注意力都放在了 与产品结合上 也就是多模态的能力 因此忽视了对模型推理能力上的重视 而就在Llama 3到Llama 4的 这一年研发过程中 2024年9月12号 OpenAI推出了基于思维链的o1系列模型 之后的2024年12月 中国的DeepSeek开源模型横空出世 用MOE混合专家架构 在保证推理能力的情况下 大幅度降低了模型成本 你在被拉去救火Llama 4 之前你手上在研究什么东西 我们这边在做一些 关于推理过程的一些研究 对 主要是关于思维链 关于思维链的形态和训练的方式 做了一些研究 其实我们在o1出来之前 o1是去年9月份出来的 出来之前其实我们就注意到 非常长的思维链 它会对整个模型的Scaling Law（缩放法则） 产生影响 其实FAIR组当中 田渊栋等研究员 已经在着手思维链的研究了 但这样对推理能力的前沿探索 并没有及时地传达到Llama模型的工程上 Llama 4规划的时候 其实就会感觉到这个地方 可能领导层的方向有一些变化 我认为总体来说他们还是想要支持 Meta本身重点去推的一些产品 就是Llama本身的生态 多模态肯定是其中的一个重点 但是DeepSeek 因为是1月份的时候横空出世 他们的推理能力非常的强 推理能力是 就当时也是讨论的其中一个方向 但是因为Meta本身的生态 他们更看重多模态 没有重点去做那个推理能力 但是当DeepSeek出现了以后 当时据说是有在讨论 因为那个时候 我实际上已经离开了Llama的团队 就当时他们有在讨论说 是不是要重新把推理的地方捡起来 这个地方可能在优先级安排上 有一些冲突 时间也非常的有限 就导致大家加班加点地做了很多的尝试 非常的忙 对 我觉得DeepSeek的出现肯定是造成了 公司里面资源还有优先级管理上面的 一些管理上的混乱吧 还有一点就是我觉得Llama 1~3的话 整个模型的架构和组织的架构 就是它其实延续了一开始的一个设计 但是Llama 4的话 因为Llama 3的成功本身 就大家希望把它能够更进一步 能够做一些更大的工程 这个时候可能出现了一些问题 我的观察就是公司比较高层的 像副总裁、高级总监这个层面 他们很多人是infra（基础设施）背景 比较传统的 或者说他们可能有一些比较传统的 计算机视觉方向 可能自然语言处理的背景都比较少 就是技术方面对于AI原生技术 或者说是大语言模型 这些东西就没有一个深度的理解和认识 其实真正懂行的 可能是下面具体做事的 一些学术研究型博士 尤其是我们非常骄傲的 华人的学术研究型博士 其实都是技术非常扎实 但是他们获得的话语权 或者说在公司内部的资源没有那么多 所以说可能不知什么缘故就造成一种 外行管理内行的一些局面出现 因为OpenAI的o1系列 和Deepseek的出现 让Meta在2025年年初是乱了阵脚 于是高层临时让FAIR的研究团队 去支援Llama 4的研发 或者可以直接说是去“救火” 而这个“救火团队” 就是由田渊栋带队的 我觉得现在很大的一个教训就是说 做这样的项目 这种项目其实是不能让 就是不懂的人来做整个领导者 或者说让人来做规划的 对 如果有些东西出了问题的话 应该是大家说好 我们不能在这个时候发布 我们再往后拖 应该是采用一种 就是我拖到什么时候能够正常运作才发布 这样的几个阶段 对 而不能说把最后期限先定好 最后期限先定好的话 其实有很多事情是做不好的 对 我们觉得其实我们组里面 当时很多人非常累 比如说像我是在加州 我有几个团队成员在东部时区 他们晚上12点给我打电话 他们那边已经3点钟了 还在干活 所以非常的辛苦 对 所以这样的话 我觉得这个是一个很大的 为什么他们那么辛苦呢 是因为最后期限压得很紧 就是说我们要在某一天 我们要必须按计划发布版本 就一般是你做项目管理的话 你就要从后面开始往前倒推 然后看2月底或者3月初 一定要做什么事情 3月底要做什么事情 但如果你在做这些事情的时候 你发现这个模型这方面不行 或者说数据有什么问题 在这种情况下 其实我觉得就有一个很大的问题就是 你怎么样能够让大家因为你这句话停下来 就比如说我说这个数据有问题 不行 我这个数据不能用 我们得换一个数据 那这样的话就多出事了 我们得把整个事情往后延 一个星期、两个星期这样子 对 但这个事情能不能做到 是一个很大的问题 如果在很强的最后期限压力之下 最后结果就是这事情做不了 或者说大家没有办法去 就是提出异议 那这样的话 最后质量就会变得很差 这个就是一个比较大的问题 对 对 为什么Meta会有那么强的压力 在最后期限上面呢 因为开源模型 其实它已经是第一了 对 但是当然DeepSeek 在年初的时候出来 大家都没有意料得到 对 但是为什么它有那么强的硬性期限说 我一定要在这个时候把这个东西推出来 应该说有个上面高层拍板定下的最后期限 但这个我就不方便说了 应该说这个可能你要去问一下相关的人 懂的都懂 那我们在这里 基本上能够有一些答案了 从Llama 3开始 “将AI产品化”这样的路线就已经制定 整个模型注重多模态和应用 忙于整合应用和业务 但是却忽略了推理能力 和更加前沿的技术研发 那这是让天平另一边的FAIR团队 不得不跨组来“救火” 就这样 天平失衡了 但实际情况其实是因为 前沿模型的竞争太激烈了 所以基本上很难真的去 比如说用FAIR这边的一些文章 其实有些文章是被用到了 但是我们在交流的过程中 其实还是会存在一些问题 我当时在FAIR的时候我觉得 有时候ping（发信息给）GenAI的人 他们都不理我 是什么情况 对 但是真的我去了GenAI之后我会觉得 确实我也没法理他们（FAIR研究员们） 为什么 因为太忙了 因为你想 你比如说 应该这么说吧 比如说我半小时不看手机 可能就有20条消息 30条消息在那里 然后你要去看 对 所以有很多的人要找 有很多的事情要决定这样子 对 所以这个我也能理解了 就是GenAI这样的一个环境下 很难去有比较长远的 一个长期思考过程 而扎克伯格 是如何修复这个失衡的天平呢 他直接空降了一个特种部队 由Alex Wang带队的TBD团队 我们再回到Meta的AI业务架构上 如今再一次重组之后 高层也是经历了一系列的动荡 Alex Wang带领几十位 高薪聘请来的顶级研究员 单独成立了 这个在Meta内部拥有无限特权 和优先级别的特别小组TBD 那TBD、FAIR和GenAI一起组成了 Meta Superintelligence Labs MSL部门 直接汇报给Alex 而Alex直接汇报给扎克伯格 这也就意味着 FAIR的Yann LeCun如今也要汇报给Alex 而Joelle Pineau 此前被要求汇报给 GenAI组的负责人Ahmad 我们看到Joelle已经在今年5月离职 去了Cohere做首席AI官 而Ahmad也说实话很久没有什么声音了 也没有被任命负责如今任何重要的项目 而CPO Chris Cox也被Alex抢了风头 排除在了AI团队的直接领导者之外 所以现在的架构就是 28岁的Alex一人独大的局面 反正我已经听到Meta内部各种 对Alex和他领导的这支 极度有特权小组的不满了 包括TBD团队里的人 可以三年不用做绩效考评 可以不理不回其它任何VP的信息 Meta AI里面的所有论文 都要给TBD里面的人去审核 才能够给发表 要知道 TBD里面的不少人还比较年轻 这是让很多资深的研究员 是非常的不满 反正就是各种内部政治斗争 感觉又要起来一波 但是不可否认的是 这个特权的等号后面是成绩 那么这个成绩对于扎克伯格来说 不仅仅是要让 Llama 重新伟大 而是“Meta 必须赢” 那么在这场AI竞赛当中 目前的这场重组 也许对于扎克伯格来说是最后的一次 也是最重要的机会 而Alex在团队内部邮件中就写到 他将做出的三个改变 第一 集中TBD和FAIR团队的 核心基础研究力量 第二 提升产品和应用研发的融合 并且继续以产品为模型聚焦点 第三 成立一个核心基建团队 来支持研究押注 你看 第一条就是把基础研究 TBD Lab和FAIR更集中化 就让它两个更紧密地去结合 所以这回裁掉的一些研究人员 邮件上也说 他们可能项目没有那么多高影响力的 就你再做一些前沿的研究 但和我们现在没有关系 因为很多前沿研究是高度抽象的 是从数学的角度 从很多理论的角度 它其实和工程离得比较远 所以你看第一条就是集中化 然后第二个 就是把产品和模型更紧密地结合 和Alex Wang一起进来的人 有一个就是Git Hub的原来CEO 他们两个 等于Facebook 扎克伯格 同时引进了两个高端人才 一个是Alex Wang管模型的 我统一来说来管模型的 一个就是叫Nat Friedman 是原来Git Hub CEO 他是偏产品 因为产品才能给这个模型更好的反馈 在用的过程中进行飞轮效应 第三条你看 组建一个统一的核心基础设施（Infra）团队 就把管这个卡 数据中心 这个团队更集中化 过去很可能是很散的 好几个领导都在 你要卡你得来申请 现在卡这个事也是统一管理 GPU（被）统一管理 所以这个邮件写得还是挺清楚的 而Alex能否撑得起扎克伯格的押注呢 也许很快我们就会有答案 总结一下 Meta在Llama的前三代 都还是领先的开源模型 引领着开源派去对抗 OpenAI和谷歌Gemini这样的闭源派 然而 在Llama 3大获成功之后 公司高层急于将AI结合产品化 在规划路线的时候 用“产品驱动研发”的思维 将Llama 4的升级 聚焦在多模态等工程性能上 但却错失了思维链（CoT）等 推理方向上的前沿技术时间优势 虽然当时田渊栋等FAIR的AI科学家们 已经在研究CoT了 等DeepSeek引发轰动之后 又将FAIR的田渊栋团队临时救火 去优化Llama 4上的MoE架构 反而又中断了 CoT和推理能力上面的研发 导致AI前沿技术研究和产品工程这架天平 彻底失衡 在采访过程中 我脑中不止一次闪现过 历史上那些闪耀一时的前沿实验室 贝尔实验室、IBM Watson Research HP实验室等等 但基本上都因为 无法平衡前沿科研和商业化而日益衰落 十多年历史的FAIR 曾经是一群理想化AI科学家的乌托邦之地 而如今又成了另一个商业化的牺牲品 那我们与田渊栋的采访 其实还有更多精彩的部分 我们放在了下一个视频 以对话的形式上线 他跟我聊了很多与Meta无关 但是与一个资深AI研究员的信仰、兴趣 以及对AI发展的前沿思考有关的内容 我觉得很有价值 也希望能够对大家来说有所收获 所以大家不要忘记订阅我们的频道 不要错过更新哦 我是硅谷101的联合创始人陈茜 你的留言、点赞和转发 是支持我们做好深度科技 和商业内容的最佳动力 那我们就下期视频再见了 bye