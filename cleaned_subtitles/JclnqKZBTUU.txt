with the fraction of Compu that is spent on training that is pre-training versus post training change significantly in favor of post training in the future yeah there are some arguments for that I mean right now it's a pretty lopsided ratio but you could argue that the uh output generated by the model is like high quality compared to or higher quality than what much most of what's on the web so uh it sort of makes more sense for the model to uh think by itself um instead of just um like training to uh imitate what's on the web so I think there's a first principal argument for that and um I would say we found a lot of gains through post trainining so um I'm not sure so I would expect us to keep um like pushing this methodology and probably increasing the amount of compute we put into it the current gbd4 has a ELO score ELO score that is like 100 points higher than the original one that was released and is that all because of what you're talking about with these improvements that are brought on by post training yeah I would say that we've um I would say that most of that is post trining interesting um so there are a lot of um there are a lot of different uh separate axes for improvement like you can uh yeah so we think about um like data quality data quantity just doing more iterations of the whole uh process of deploying and collecting new data and like changing what you're what kind of annotations you're collecting so there's a lot of uh a lot of things that stack up but together they give you a pretty good um like effective compute increase how much of a reme is better posttraining currently companies I distinguish themselves by well how big is our model and so forth will it be a big mode who has figured out all the finickiness that you were talking about earlier with regards to uh all this data I think there's something of a moe because it's just a very complex uh operation and there's uh so it takes uh you have to have a lot of skilled people doing it and uh so there's a lot of tacet knowledge and uh um there's uh a lot of organizational knowledge uh that's required so um so I think um yeah I think post training uh like to create a model that actually um like has all the need the functionality people care about um uh is pretty complicated uh requires a pretty complicated effort um so and this um requires a lot of this is basically an accumulation of a lot of R&D um so I would say um I would say that makes it somewhat of a moe that it's not trivial to spin this up immediately uh it does seem like um like the same companies that are putting together the most serious uh pre-training efforts are also putting together the serious post-training efforts so so uh it seems like it is somewhat um somewhat possible to copy or to to spin up more of these efforts um there's also like one force uh that sort of makes it less of a mode is that you can uh like distill the models or you can take someone else's model and uh clone the outputs or you can uh use someone else's model as a judge uh to like do comparisons so I think uh like the more big league people probably aren't doing that because it goes against uh terms of service policies but and it would also be a sort of hurt to hit to their pride but I would expect some of the smaller players are doing that to get off the ground what what makes for somebody who's really good at doing this sort of R research uh I hear it's super finicky but like what is the sort of intuitions that you have that enable you to find these ways to mess with the data and set up these environments I'd say I just um have a decent amount of experience at this point from uh like the different parts of the stack from like uh RL algorithms obviously since I've worked on those since uh grad school uh to like uh the data collection um like The annotation process uh to um like language playing with language models so I I mean I'd say I just dabbled with these things and uh I'd say the people who um do well at this kind of research uh have some view of the whole stack and have a lot of curiosity about the different parts of it and uh also sort of think about um well you want to be both empirical um and uh like use experiment let experiments update your views but you also want to think from first principles somewhat like uh what um like assuming that um like learning uh Works uh like what would be the ideal type of data to collect yeah and that sort of thing