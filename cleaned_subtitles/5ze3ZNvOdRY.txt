Are we in an AI bubble?
>> Uh, I do not believe we're in an AI bubble today. I was, depending on how you look at it, the privilege and the misfortune of being a tech investor during the year 2000 bubble, which was really a telecom bubble. And I think it's really helpful to compare and contrast today to the year 2000. The year 2000 internet bubble or telecom bubble was defined by something called dark fiber. At the peak, 97% of the fiber that had been laid was dark. Contrast that with today. There are no dark GPUs. And that brings us to our opening fireside chat. We're going to start with a taboo question right out of the gate. Are you ready for it? If AI love it. If AI is the biggest trend in the world right now, where is the evidence for it? Why is it only just beginning to show up in the economy? And as Andre Carpathy asked, are agents really just ghosts? To kick this off and to help us answer this question, please join us in welcoming Gavin Baker, managing partner and CIO of Atrades. Now, some of you may know Gavin as that really thoughtful guy on Twitter. Anytime some big piece of AI news comes out, I know more than a few people who count on Gavin to explain what the f is really going on. So, a huge thank you to Gavin for being with us today. Joining him is our very own David George, general partner at A16Z. [Music] Who knows what that music was from?
>> Glad they got our pump up music right.
>> Yes. Battlestar Galactica, the original 1977 one. in case we have to all fight Sylons in a few years.
>> It's it's uh yeah, good good segue into the topic, I guess. Um so, thank you for being here. I always love talking to you.
>> Same. Um really grateful to you for inviting me, grateful to your colleagues for having me here. I'm really look forward to the next uh two days. I think I'm going to learn a lot. So, thank you.
>> Yeah. Okay. All right. So, the big topic is AI bubble kind of macro view of things. Um, so maybe just to start with a couple stats to set the stage and then I want to get your take on on where we're at. So we have about a trillion dollars of data centers in the US. The plan is to add 3 to4 trillion in the next 5 years. Over the past three years, we have already built out in data center capacity a larger amount of dollars than the entire US interstate highway system, which took 40 years just in terms of dollars. And that's a inflation adjusted. Open AAI alone I think has more than a trillion dollars of deals set up that they've committed to and we can talk about that. Um but at the same time, so those are all like big numbers on infrastructure and they're scary and they say oh bubble and Google uh released a stat recently that they have seen a 150x increase in the amount of tokens processed in the last 17 months. So on the one hand you've got this crazy scary sounding buildout. On the other hand you actually have a bunch of usage that's happening. So are we in an AI bubble? Uh I do not believe we're in an AI bubble today. Uh I was um I had depending on how you look at it the privilege and the misfortune of being a tech investor during the um the year 2000 bubble which was really a telecom bubble. And I think it's really helpful to compare and contrast today to the year 2000. um you know first I think uh Cisco peaked at 150 or 180 times trailing earnings Nvidia is at more like 40 times so valuations are very differently very different most important however is that the year 2000 internet bubble or telecom bubble was defined by something called dark fiber um and if you're a veteran of of the year 2000 you'll know what that was but dark fiber was literally fiber that was laid down in the ground and not lit up. Fiber is useless unless you have the optics and switches and routers uh that you need on either side. Um you so I vividly remember, you know, companies like Level 3 or Global Crossing or WorldCom would come in and they say, "We laid 200,000 miles of dark fiber this quarter. This is so amazing. The internet's going to be so big. Um you know, we can't wait to light these up." At the peak of the bubble, 97% of the fiber that had been laid in America was dark. Contrast that with today. There are no dark GPUs. All you have to do is read any technical paper. And that one of the biggest problems in a training run is that GPUs are melting. And there's a very simple way to kind of cut to the heart of all of this. It is the return on invested capital of the biggest spenders on GPUs who are all public and those companies since they ramped up capex have seen call it a 10point increase in their ROIC's. So thus far the ROI on all the spending has been really positive. It's a really it's an interesting and open debate about whether or not it will continue to be positive with the quantum of spend we're going to have on Blackwell. I personally think it will, but there's no debate that thus far the ROI on AI has been really positive and valuation wise. We're just not in a bubble. I couldn't agree more. The other thing that I would say is you can contrast the actual adoption and usage of the technology from then, right? The internet was actually really hard because you had to build a two-sided network. like you had to build websites and then you had to get users and it's much more difficult in the case of the AI tools you know all you have to do is kind of light them up via API or you know turn on your website chatgpt and everybody has access to them right built on top of cloud computing on top of the internet uh and you know you can get to instant distribution a billion people right away
>> absolutely so uh the other thing is the counterparties so you mentioned this they happen to be the best companies in the history of the world right I think collectively the people who are coming out of pocket. They're writing checks uh for this capex. I think they collectively generate like $300 billion of free cash flow a year. Is that right? Some directionally
>> round numbers.
>> Yeah. And they have $500 billion of cash on the balance sheet. So whenever people are like, "Oh my god, it's a bubble. Is it going to pop?" I'm like, I think it's kind of fine. I mean, you know, it costs like4 or 50 billion to light up one gigawatt.
>> Yeah. If you're on Nvidia chips
>> on Nvidia chips.
>> Yeah.
>> Yeah. So, you know, there's kind of like an $800 billion buffer growing $300 billion every year.
>> Yeah. I mean, um, free cash flow at some of them has begun to maybe uh, you know,
>> well, this this goes to your point on return on invested capital. It might
>> we should see that next down a little bit. A little bit of a mismatch at the buildout,
>> but you know, it's you know, Larry Page apparently internally said, I'm happy to go bankrupt rather than lose this race. And I think that is the mentality for sure at Google and perhaps Meta. um it's just seen as existential and you have to win.
>> Okay. So, uh lots has been written about these roundtpping deals. So, give me the because you know roundtpping is a very scary concept from you know the internet buildout that was a big problem.
>> What do you make of it here?
>> It is objectively happening. Um you know money is fungeible. So Nvidia if they sign a deal with OpenAI they can say hey you can't use our money to buy our chips but money is fungeible. But it's happening at a very small scale. Yes. Yeah. And I think um
>> I didn't know this was like a crypto or blockchain.
>> Exactly. Good.
>> Yeah.
>> And I think what is driving um what is driving this isn't the need to, you know, finance GPU or data center purchases, but it's actually com competitive dynamics. So, Nvidia's biggest competitor, it's not AMD, it's not Broadcom, um, you know, it's it's certainly not Marll. Um, it's not it's not Intel, it's Google. And more specifically, it is Google because Google owns uh the TPU chip. And this is by far maybe perhaps today the only um alternative to NVIDIA for training um and maybe the best uh inference alternative. And what Google and Google's a problematic competitor because they also own a company called DeepMind and they have a product called Gemini. Um and I think you could argue that they are the leading um AI company today. I think they've taken 15 or 20 points of traffic share in the last two or three months and that does not that's just traffic to Gemini. It does not include search overviews. I suspect on a actual traffic basis, Google is bigger than OpenAI, Enthropic, anyone today and that that business is going to run on TPUs. And then we have three other labs that are relevant today. There's Enthropic and that's an Amazon and T that's an Amazon and Google captive. Uh, trrenium is um, you know, Enthropic is really going to run on uh, TPUs and traniums. And so you're left with XAI and OpenAI at the forefront. And if Google is going to a lab like Enthropic and saying, I'm going to help you fund raise and give you chips, I think for competitive reasons, it's very hard for Nvidia not to respond. And as Jensen said, he thinks it's going to be a good investment. Um, so I think the roundtpping concerns are pretty overblown.
>> Yeah. And what I mean what Nvidia really needs is they need you know Meta to get their act together or another American open source player to emerge or you know maybe some sort of um dant with China and AI.
>> Yeah. Yeah. I when people ask me about Nvidia and all the moves and the roundtpping my reaction is everything they've done is completely rational.
>> 100% rational.
>> Yeah. Long term. Yeah. Sure. things they do may not have as high of a return on capital as other things, but strategically I think they're all kind of the right moves.
>> Jensen's one of the two best CEOs along with Elon I have ever known. Um, and I think he's he's playing a strong hand really well.
>> Yeah. All right. So, you started getting into the model companies. Let's just talk about the model. So, we can come back to chips and memory and networking because I want to get your take on that, but you know, since we're on the model side, what do you think happens with market structure? who wins where, you know, who are you most optimistic about? You know, where do you have concerns?
>> So, um I think humility is an important virtue for an investor. And I'm just if we're going to make an analogy and say that chat GPT is to AI has Netscape Navigator was to the internet. At this point in the internet boom, Google had not been founded. Mark Zuckerberg was in middle school. um Travis Kalanick was in was in kindergarten. Um so it's just very early. So I think it's important to be humble um about making high confidence predictions at the application layer. It's one reason I think the the infrastructure layer is often maybe a safe place to be at the beginning of one of these new technology waves. Well, actually talk about the role they play at the infrastructure layer because they are there's a piece of them that like obviously they they serve as an as an infrastructure layer powering other application providers and then they they also have their own application. So I think
>> I would draw the distinction.
>> Yeah, I mean that's most true of of Google. Um but I just um I think it's hard to have high conviction other than to observe you know the internet was a very disruptive innovation. Um, I think there's reasonable arguments that AI could be a sustaining innovation because the raw ingredients of kind of data, you know, the capital to buy compute and distribution, which is what you need. All of the big um, you know, today's biggest tech companies have all of those in spades. So, as long as they execute well, hire good people, um, and have a sound strategy, like I think you could see it be a sustaining innovation for a lot of members of the Mag 7. On the other hand, I do think it's existential and if you don't execute, you know, IBM might be a might be a good fate.
>> Yeah. Yeah. Yeah. That's uh that's tough. Uh, yeah. Data, distribution, compute, dollars, talent.
>> Yeah.
>> And like
>> they have every right to win. Yeah, they have every right to win. And it seems now more than before, they're taking it quite seriously.
>> Yeah, maybe Google in particular, but obviously Meta Meta is making the dramatic moves they're making, too.
>> No, to me, Chat GPT was Pearl Harbor for Google, and we're going to see how they responded, and they're slowly starting to respond.
>> Yeah. And then what do you think what's your forecast for uh that sort of in the platform piece of their business, the infrastructure piece? What do you think? How do you think it shakes out in terms of like business model market structure? So do you think they end up as high margin businesses like the clouds or like aircraft manufacturers or do you think they end up very competitive and low margin businesses like airlines? Um I don't think they will be airlines but you can anybody can just look at the P&L you know of a SAS company circa 2021 and 2022 and you see you know 80 90% gross margins and the nature of AI because of scaling laws Richard Sutton's the better the bitter listen um they're just more compute inensive so their gross margins are structurally going to be lower but that doesn't mean they can't be great businesses is I just I think it's going to be a long time before we see a truly kind of you know an AI lab a frontier lab with gross margins anywhere near SAS or internet era margins now their opex can be a lot lower um and you know maybe that's how you square it but just the gross margins are fundamentally different and until scaling laws change and the importance of test time compute and things like that change which I don't see happening they're they are going to be lower margin.
>> Yeah. Okay. So, let's talk about uh application layer. So, you just you just kind of got into it a little bit with the SAS businesses and uh I don't know if you've waited into this fight on Twitter, but it's sort of you know the the like you know every few months it comes up and it's like SAS is terrible and it's dead and you know it's all going to go away and then you know with uh Andre's uh Darkeesh interview he just did it's you know like the market's reacting positively to it. And it's like a whipssaw reaction. So what do you think happens with SAS and software?
>> You know, I think I, you know, first said probably in early 24 that I thought all of application SAS might be a zero different than than um infrastructure SAS. I I would say I have a more nuanced view now and I think there could be some really big application SAS winners, especially if you serve like a more fragmented SMB customer base. Um, you know, Google has make it really easy if you're a customer of theirs to use your data and essentially make any SAS app you want and then your data isn't shared with anyone else. Um, but the critical mistake that I think a lot of retailers made um in dealing with Amazon is they looked at Amazon's margins and they said we don't want to be in that business. And that was obviously a terrible mistake. And here we are 25 years later and you know Amazon has really healthy uh retail margins. And I worry that application SAS companies are trying to preserve their existing gross margin structures because they believe that if their gross margins go down um their stocks will go down. It is definitionally impossible given what we just discussed to succeed in AI without gross margin pressure. And I do not know why they have concerns because we have an existence proof that a software company can deal well with declining margins in Microsoft in Adobe to the whole AI thing came along. You know, it used to be that companies were scared to go from on premise to the cloud because margins were lower. Cloud margins are are are lower. They're still good. And Microsoft, they transitioned, you know, from, you know, on premise perpetual licenses with maintenance uh to a cloud model. and it was a pretty good stock for 10 years. So I don't if you're an application SAS company like I what I would just say is don't be scared and look at declining gross margins kind of has a mark of success rather than you know a badge of shame or something to be feared. It's actually so funny you say that because whenever we have these discussions about companies, basically every company that comes to present to us is like we're an AI company and um we always look at the gross margins and it's become like a badge of honor for them to actually have low gross margins because like oh my god people are actually using your AI stuff. Yeah.
>> But if you show up and you're like I'm an AI company and it's like I got 82% gross margins. You're like I don't think anybody's really using it. Uh so yeah it's uh it's interesting. Yeah. If you're if you're one of these public companies, would you rather have like 10 bucks of revenue with 90% gross margins or 50 bucks of revenue with 60% gross margins?
>> Not hard.
>> Like it's not that comp Yeah, not that complicated. It's hard to do in the public market.
>> It's hard to do in public, but if you communicate it, you draw parallels to the cloud transition. I mean, I'm an investor and I would be excited about it, you know, and I don't think I'm alone in the world. And then the big advantage these legacy application SAS companies have is they do have these really profitable existing businesses. And so you can run your new AI products at break even um and you know catch up to the leaders etc etc and I'm just surprised more people have not done that like why are none of the public coding companies even trying to compete with cursor and the reality is cursor now they have a trillion trillion tokens and you know there there will be a point where they have enough coding tokens that it's tough to catch them but I think today if you're a public coding and you said, "I'm going to lean in. I'm going to run it break even. I have an existing business. I'm going to attach it to everything." Hey, you have a chance. And you know, the prize is clearly really big. I see Martin is skeptical.
>> Martin's shaking his head. You have a chance.
>> I said a chance. So, I said a chance.
>> That's like a dumb and dumber. You're telling me there's a chance, not like a real chance. You're telling me. You're
>> telling me there's a chance.
>> Yes. Exactly.
>> It's like a
>> Yeah, exactly. I totally agree. Yeah, we actually saw I mean you know we see it uh you know we may if we if we you know Figma for example like when they went out they are extremely high gross margin and they're like hey we're going to you know pretty aggressively distribute our AI tools and our gross margins are going to go down and you know investors asked a few clarifying questions and then they were like oh that actually would be a good thing and so surprised more people in the public markets aren't doing it worked out okay for them
>> it's working out well uh long game to play what about on the consumer side at the application layer so obviously ly Google was the portal to the internet is kind of still is the portal to the internet and the whole business model was predicated upon taking some intent and directing you to someone else's website where they would do stuff with you. It's kind of not going to be that way. It already is not that way uh with uh with AI. Although I tried the browser today and I tried to do some pretty basic shopping stuff and it's you know it's still still some work to do but I think it will get there. So what do you actually think happens with the sort of market structure of the consumer internet companies? Do they get subsumed into a component of a chatbot interface or do you think it's something else? Um so one humility hard to say. to I would just say I think um the AI companies that have launched these AI browsers may come to regret it because there's something called Chrome that has whatever it is 5 billion users and if you're Google um you know you can just go look at what happened with Google Buzz you they are very cautious you know there's you know they're currently in in litigation with the government um and they could easily do this and probably do it even better, but they didn't want to be first. So now you have two AI native companies with their own browsers, let them run for 3 to 6 months, get a little head start, and then wow, here we are. We had to do this. And I don't know how that's going to work. Um maybe for the companies other than Google who don't own Chrome. Um
>> yeah, I guess data and distribution is pretty powerful in that.
>> Yeah, hindsight's 2020. Um, and the one thing I would say is I do think it's tough to bet against the companies with large existing user bases today. Um, and I also think reasoning has fundamentally changed the economics of these frontier models. you know, pre-reasoning. Um, I often said if you are a frontier model without access to unique, valuable data and internet scale distribution, you're the fastest depreciating asset in history. I think reasoning really changed that because the way RL works during post training, having a big user base now kind of unlocks that flywheel that was at the center of every great consumer internet company where um you have a good product, you get a lot of users, the users make the algorithm better, um the algorithm makes the product better and it just spins. And that it's not quite spinning yet in AI, but you can squint and see it. And so I think that fundamentally changes economics for anthropic, for XAI, um, for OpenAI. Um, but I mean Mark Zuckerberg's trying hard.
>> Yeah.
>> We'll see.
>> Yeah. Yeah.
>> Yeah. A lot of smart people in there now.
>> Yeah, for sure. I I think the worry is and I think this is another interesting thing is if you don't like in a strange way the Chinese open source model ecosystem is a godsend to any American company that's trying to catch those four leading labs because the problem is if you don't have Gemini 2.5 Pro or a later checkpoint of it or a later checkpoint of Grock that we don't see or a later GPT checkmate uh checkpoint training the next model you're at a disadvantage. Oh, by the way, one thing I just want to say that drives me crazy is all these people who say that GPT5 is the end of scaling loss. GPT5 is a smaller model. It was not designed to be better. It was designed to be more economical for OpenAI and Microsoft to run it. Any reference to GPT5 its scaling laws is crazy. Um, yeah. Sorry. Rant rant over.
>> We got the pedestal up here if you want.
>> Yeah, exactly.
>> Shaking your hand.
>> Yeah, we could. Yeah,
>> that'd be good. Uh, do you want to talk about chips?
>> Sure.
>> So, okay. I know you love Nvidia. Talk about, you know, your view of Nvidia, AMD, TPUs, AS6, and how do you think sort of market structure shakes out there, you know, competitive advantage that the various players have?
>> Yeah. Um I think it goes I think it is really um it's a fight between Nvidia and um the Google TPU and then something that I don't think is broadly appreciated is the extent to which Broadcom and AMD are effectively going to market together. Nvidia is no longer just a a semiconductor company as I'm sure you'll hear from Jensen tomorrow. you know not it was a semiconductor company then a software company with CUDA now systems company with these rack level solutions and now arguably you know a data center level uh company with the you know level of architecting they're doing with scale up scale across and um scale out scale across networking um so the networking the fabric the software it's all important and what Broadcom is saying to companies like Meta is hey we will build you a fabric that can theor theoretically compete with Nvidia's fabric which is a mixture of NVLink and either Infiniband or Ethernet. Um it will build it on Ethernet. It's going to be an open standard. And hey, we'll we'll make you your version of of TPU, which by the way took Google three generations to get working. And you know what? If your ASIC isn't good, you can just plug AMD right in. Um but I personally believe most of those AS6s are going to fail. um particularly if it's
>> in the fullness of time like over a period of time or in the fullness of time
>> in the next 3 years I think you'll see a bunch of high-profile um ASIC programs canled especially if Google um starts selling TPUs externally which has been all over X and you know they you know who knows exactly how that would work because if you're anthropic you know it's just rumored anthropic wants to buy tens of billions of TPUs if you're anthropic maybe you don't want Google seeing your secret sauce but there's ways around on that. So I think this is really a battle between Google and its TPU enabled by Broadcom for now and Google can take the TPU away from Broadcom whenever they want.
>> Yeah.
>> Now they can't do the Ethernet networking that Broadcom is is doing uh but they control the TPU. Um so it's really Google and the TPU verse um Nvidia you know with with you know Amazon like that's a very talented team arguably the most talented silicon tumidity hyperscaler the anaperna team like I think the tranium 3 will probably be a much better chip than the tranium 2 it took three generations to get the TPU right um and then AMD will you know will always be kind of the second source and you need a second source all right exciting uh what do you think happens Okay. So I want to go back um to business models. So one of the big things that is widely discussed is like you know source of disruption and most of the CEOs in this room are CEOs of startups who are trying to go beat some incumbent or find you know some new market opportunity and the most ripe opportunities tend to come when you have a big platform shift that is also accompanied with a business model shift. Um and so there are a couple of areas where I can see it. I feel like in an obvious way. So, you know, we're investors in decagon customer support like you can pretty easily see a business model that is priced on the resolution of a task because it's so measurable. Um you can see you know like in coding like a lot of the business model has now shifted to consumption and you know obviously especially for developer facing things like that's comfortable um and pretty wellnown. What about the rest of the industry? Cuz I feel like there's sort of this handwave thing that is going on which is like we're going to go get all of services but it's like okay so how do you actually go do that? It's going to be pretty hard. So do you have any prediction on how that plays out?
>> Well I think what you're seeing in customer service which is kind of like an easy first example u where you have a lot of textual data that LLMs are good at text. you can kind of, you know, probably really easily run some RL to make sure that they, you know, get a good verified reward. You know, verified reward being a happy customer or first call resolution or whatever it is.
>> Um, and but I do think you will see that played out like humans, we're fundamentally paid for paid paid based on outcomes and a lot of AI will be augmenting humans, but probably also replacing some humans and that will involve being paid u paid for outcomes. you know, going back to the consumer business model, you know, everybody's talking about affiliate fees. And for sure, I'm going to have, you know, my own AI. It will be a version of Grock, um, because we're both XAI shareholders. It will be a version of Grock that knows me and it likes me. Um, and, you know, when I when I want to, you know, the next time I want to go on vacation, it will know the hotels that I like to go to and it'll say, "Hey, three hotels. I have Gavin, you know, I have Gavin coming. Who's got the best price and the best room?" Um,
>> it's going to massively upgrade the gifts that you give to Becky just in case as Becky Becky's in the audience. She really appreciated your Dumb and Dumber reference. I'll have you know. Um, but um yeah, and then there will probably be some sort of affiliate fee. And again, that's just being paid for an outcome and kind of closing that loop, which will be probably a little bit of a business model degradation because the great why why did Google never start a marketplace? because people overvalue systematically their ability once they've acquired a customer through Google to keep it as an organic customer. So they systematically overpay and they continue doing that. That's why Google never went to outcomes or marketplace because advertising leads to the advertisers systematically overpaying. So that inefficiency will be squeezed out but yeah we'll go to outcomes and you know I think Elon tweeted today that you know work would become optional you know like instead of buying your vegetables um you know at a at a supermarket you can grow your own garden if you want. Now, who knows how long it takes us to get there, but I that doesn't sound wildly implausible to me for how powerful this technology is. And I was just struck Karpathy, you know, whatever two days ago, you know, is being painted as like a skeptic for saying AGI is 10 years away. Are you kidding?
>> Insane. 10 years.
>> Yeah. Yeah. Sign me up. We have shorter timelines, please.
>> Yeah. Well, so no, that's awesome. While we're on the topic of very exciting futuristic things, robotics, do you have a view on
>> Yeah, very real. And it's going to be Tesla versus the Chinese in the same way it's Tesla versus the Chinese in in uh cars.
>> Electric cars. Yeah.
>> Yeah.
>> I would just say cars, not electric cars.
>> Yeah. Cars.
>> Yeah.
>> Do you have a sense of timeline?
>> I mean, you can you can all watch the Optimus videos. Um, every roboticist I know is extremely impressed. Um, you know, there's there's a giant debate. Is it going to be humanoids or not humanoids? I think that debate is over because humanoids can kind of learn, you know, from watching YouTube videos and then it's easier for a human being um, you know, to put on a suit and show the robot how to do it. I mean, it's kind of crazy to watch the video of all, you know, the 50 Optimus robots doing 50 different tasks and then it's very simple, you know, did you did you put the glass in the dishwasher correctly or not?
>> This is so fun, Gavin. I always love chatting with you. Uh, let's give a hand to Gavin.
>> Thank you, David. Thank you.
>> All right. Next up, we have a very exciting panel on building out real world infrastructure. Uh, but first, give us a few minutes. We got to do a quick uh sta uh stage change here. So, thank you.
>> Thanks everybody. Thank you, man.