Friday the 17th of July 1992. Amidst the chaos of the trading floor at Singapore's International Stock Exchange, one of the junior traders makes an expensive mistake. Instead of buying 20 futures contracts for a client, she sold them instead, costing Beerings Bank nearly $40,000. To save her job, her boss, Nick Leon, a young trader keen to make his mark, decides to hide the loss. He puts it in an obscure error account. That's account 88888. It's used by banks to solve small discrepancies in trades. It's a dangerous move and it should have been picked up by the central office immediately. But when nobody from bearings notices, he gains confidence, convinced he can win back the loss and get the team out of trouble.
>> I'm operating in the belief that I can get it back. You know, maybe it goes back to the confidence thing. I don't know. I mean, I'm confident I can get it back at that stage. But Leon's staggering overconfidence would create a debt of gargantuan proportions and lead to one of the biggest collapses in banking history. It's easy for me to make the case that overconfidence is the most dangerous of the human biases. Overconfidence gets us into all sorts of trouble. It leads us to take risks, make commitments, enter contests, try things that will ultimately fail, sometimes in costly, embarrassing, and dangerous ways. Overconfidence has been implicated in almost every big disaster, from the sinking of the Titanic to the Chernobyl nuclear disaster to the loss of the space shuttle Challenger. But overconfidence isn't reserved for just a few reckless individuals. We can all fall victim to it. For example, 93% of us think we are better drivers than the median, which is of course impossible. The scale of the problem was identified in some now classic research with a set of simple quiz questions. True or false? Australia is wider than the moon. Oh, I bet they're about the same size.
>> It's just it looks small on a map, but it's huge.
>> Are there more or less stars in the Milky Way than trees on Earth?
>> More stars. more stars.
>> One teaspoon of pure olive oil,
>> 4 1/2 g, contains more chemical potential energy than an equivalent 4 1/2 g amount of TNT.
>> I'm going to say true.
>> Oh no,
>> this feels kind of like a trick question.
>> The energy density of butter is 10 times that of lithium batteries, right? I mean, lithium batteries are rubbish. Everyone's going on about them. Just run your car on butter, I say.
>> True or false? Plants are more efficient than the average solar panel at absorbing the sun's energy.
>> Yeah, they must be.
>> Now, these aren't the exact questions from the original research. More on those later, but the specifics don't really matter. The interesting bit is what they asked next. How confident are you that you are right?
>> 100% confident.
>> 100% confident.
>> 100. Yes.
>> I think it's true. Um, so I've also got to go 90%.
>> 100%
>> 100%
>> 100%.
>> Yeah.
>> I don't think we actually had any expectations. This was very early on the re in in the research on on confidence assessment, but we didn't really know what we what what we would find.
>> The results revealed a surprising disparity between how accurate someone thinks they are and how accurate they actually are. When people are 90% certain, they are right only 75% of the time. In fact, we ran our own version of this online and found an even more extreme discrepancy. We asked the Veritassin community a bunch of science questions and then asked how confident they were in their answer. Our results showed that those who were the most confident, describing themselves as 91 to 100% sure, were only correct 51% of the time. Since the original research, these results have been replicated again and again in all areas from general knowledge to motor skills and it affects everyone even experts. I have a paper where we analyze the survey of professional forecasters. These are chief economists at various corporations and banks who are invited to forecast the state of the economy on a quarterly basis. We find that they are on average too sure that they know what's going to happen. So they on average say they're something like 53% sure they have correctly predicted what's going to happen to inflation for instance and they are right like 23% of the time. How well what you think you know matches with what you actually know is called your calibration. So if you're perfectly calibrated and say 80% confident you should be right 80% of the time. But most of us are not well calibrated
>> 100%
>> 100%.
>> Yeah. There are 200 billion stars in the Milky Way, but there are three trillion trees on Earth.
>> 100% confident.
>> 100. Yes.
>> False.
>> Most of the time, being overconfident isn't a huge issue. But for Nick Leon, the stakes soon became very high. Leon's plan to recover his team's loss was to bet that the Japanese stock market would go up. So he went long on the top 225 companies in Japan, the Nikkeay 225. Ever since the Japanese asset price bubble peaked 2 years previously, the Nikkeay had been dropping from 38,000 to 16,000. And he was confident the market would soon bottom out and start rising, but it continued to fall. Over the next few weeks, it dropped to a low of 14,000. And the whole time, Nick was betting the wrong way with ever bigger and riskier bets. He would double down, betting double his losses so the next win would bring him back above water. This strategy should work when the next win comes along, but the market collapse was unrelenting and his losses ballooned from $40,000 to around $3 million. In spite of this, Leon remained confident and eventually his luck turned around. In the spring of 1993, the market rebounded up to 20,000, and by the summer, that account was back in credit. Leon goes out to celebrate that weekend, drinking and dancing on tables, finally free of the hole he had dug himself into. But on Monday morning, he made another trading error on the futures market. A damaging loss that Leon didn't want to admit. So he put the loss back into account 88888. Confident that if he got out of the previous one, he could do it again. He began making risky trades to try to recover that initial loss. And as the losses mounted in the 58 account, it became harder and harder to make new trades to cover the last loss. By the end of 1993, his losses exceeded $30 million. Leon is obviously an extreme example, but this tendency to overestimate our abilities is something we all share. So the question is why? The obvious explanation that a lot of people default to that is we want to feel good about ourselves and pretend like we're wellinformed that we enjoy enormous satisfaction from being able to say I know or even better I told you so. And so uh we pretend to ourselves and others that we know when we don't. That is the the motivated egocentric version of an explanation for excessive faith in her own judgment.
>> Reichel had faith and the idea if nothing else.
>> But what if it's something more uncomfortable? Stupidity. France. Reichelt was a tailor with no formal scientific or engineering training. But he was obsessed with solving the problem of aviation safety. He spent months designing a parachute suit which repeatedly failed during testing. But he became convinced the issue was that he didn't have enough height for it to work. So in February 1912, he took it to the Eiffel Tower. And rather than using a dummy to test it, he jumped himself. Tragic, but also really dumb.
>> Do you recognize this graph?
>> Uh the like Dunning Krueger graph.
>> Are you confident that this is the actual Dunning Krueger graph?
>> Not at all. I in fact, I think that this is not the Dunning Krueger graph. I think that this is a bit of a communication trick. This is what people call the Mount Stupid curve, which will pop up if you search for the Dunning Krueger effect into Google images.
>> As far as I understand it, um it's a it's an effect that says that when you know very little about it, your confidence is high. And as you know more about it, your confidence sinks until you become a master at it.
>> But I think that the actual result was like a little bit more fuzzy than this. It was this graph doesn't actually show the Dunning Krueger effect. It's just a meme that resonates with a lot of people and it became conflated with the effect. In their original research, Dunning and Krueger tested people on tasks like grammar, logic, and humor and then they asked participants to estimate how well they performed. That produced this curve. You can see that those who performed worse had the largest mismatch between their confidence and performance. They were the most overconfident. Those who performed the best were actually slightly underconfident. This suggests that overconfidence may be linked to how much we know. Those who know less think that they know more than they do. But to me, this effect looks a little like a statistical artifact. Because while I was doing my PhD, I asked students some physics questions and I also asked for their confidence in their answers. And when I looked at the results, accuracy spanned the full range from nearly 0% to 100%. But confidence varied over a much narrower range. All the scores were roughly in the middle. This meant that poor performers were the most overconfident and the highest performers were actually slightly underconfident. This is exactly what Dunning and Krueger found. So maybe overconfidence isn't entirely due to how much we know, but also because most of us express at least kind of middle-of the road confidence. But there is another factor at play here, which is how much information our brains are capable of processing. Monday, the 27th of January, 1986. It's 5:45 p.m. at the Kennedy Space Center in Cape Canaveral, and the engineers from Morton Theacle, who made the Challenger Space Shuttle's rocket boosters, make an emergency conference call. They've just seen the weather forecast, predicting temperatures overnight will plummet to 25° F, far colder than any previous shuttle launch. They know the rubber O-rings that seal joints in the boosters become less flexible in the cold, but have just a few hours to gather data, create charts, and present their case. Over the next 6 hours, the engineers present 13 charts with data on O-ring temperature, hot gas erosion, joint rotation, and more. But the data is scattered, incomplete, and not synthesized into a clear narrative. They'd never tested below 53° F. So NASA managers were trying simultaneously to track historical O-ring data, erosion patterns, joint dynamics, seal resiliency, pressure differentials, and more. No single chart told the whole story. So overwhelmed by seemingly contradictory data and confident that their rocket boosters were safe, theole management overruled their own engineers and approved the launch. At 11:38 the next morning, 73 seconds after launch, all seven crew members were killed. Calibrating your certainty requires thinking of all the ways that you could be wrong. And that's hard for finite fallible agents like us. If it means considering everything that we don't know,
>> how many chunks of novel information you can hold in your head at one time is your short-term memory capacity. In 2008, Hansen, Jesus, and Winman investigated how short-term memory capacity was linked to accuracy and overconfidence. Participants were asked to give ranges for factual questions like the length of a river or the population of a city. People's ranges were consistently too narrow, which effectively meant they were being overconfident. And those who had worse short-term memory were more often wrong and more likely to be overconfident. Another study conducted by Conti in 2023 asked participants to keep sequences of letters in their mind while they judged their own performance. As the memory load increased, confidence estimates became less accurate, even for participants with higher working memory capacities. Together, these studies suggest that assessing your accuracy is a mentally taxing task. So overconfidence isn't necessarily about arrogance. It's your brain working at the limits of what it can track and hold. And because of this, your brain can start using shortcuts. Psychologist Daniel Conorman describes these mental shortcuts as heruristics that together create systemic errors called cognitive biases. One shortcut we use a lot is substituting hard questions with easier related ones. Researchers have tested this by asking students how happy they were in their life and how many dates they'd had in the last month. Unsurprisingly, these two questions did not correlate. There's a lot more to happiness than matches on Tinder, at least for most people. However, if you switch it around and ask about their dates first, suddenly the correlation jumps to 66. Working out how happy you are in your life is a difficult question. You have to consider many things and balance them all out. So, when you're primed with the information about your dating life, you're very likely to substitute that hard question like, "How happy am I in my life?" with, "How many dates have I recently had?" Overconfidence from misprocessing information like this can be disastrous. So, why are our brains wired this way? I mean, you might expect natural selection to have wiped out the confidently incorrect, but there is evidence that overconfidence can actually be advantageous. Overconfidence can massively improve your status. In a scientific version of the apprentice, scientists in 2012 compared participants own assessments of their skill with objective measures. They placed them in group tasks to see who was chosen as a leader and whose ideas influenced the group, tracking status over multiple sessions and assessing whether the desire for status led participants to exaggerate their abilities. The results were clear. Overconfident individuals were more likely to lead, assert themselves, and maintain influence even when their actual abilities were mid. And the evidence certainly shows people react better to confident individuals. Using an fMRI, researchers at the University of Sussex measured brain activity of people after hearing unconfident versus confident advice. Those who listened to the confident advice had increased activity in the ventromedial prefrontal cortex. That's a brain region associated with processing rewards and expected satisfaction. This means that human brains are biologically tuned to be influenced by confident individuals. We literally feel better when we hear confident people. But recognizing that dynamic highlights a potentially problematic incentive for anyone who's contending for positions that they want. People who express more confidence in employment interviews or political campaigns, for instance, do earn the confidence of interviewers and potential voters even if they're being overconfident. They can't actually deliver. They don't actually know the answer, but they can talk a good line to impress others even if they can't ultimately deliver on those grand assertions. They know the audience will place more faith in them if they express conf. Well, they should express maximal confidence.
>> Leon knew this and he took advantage of it. While he was secretly racking up huge losses in the infamous 58 account, he was publicly posting huge profits and everyone believed the illusion.
>> They come in and they don't test any records.
>> So, I can't be happier. They didn't test one record. As Leon's hidden losses mounted, he requested huge sums from head office to keep doubling down, up to $5 million at a time. Bearing management, barely understanding futures and believing in their star trader, they granted his requests and continued to grant future requests. Every day that I make one of these requests for additional money, I never expected to come. I expect somebody to say, "Look, what the hell's going on?"
>> By autumn 1994, the account was nearly $260 million in the red. To mask this, Leon began buying futures from himself, inflating his perceived profits further. At Syax's 10th anniversary in September, Beerings received two awards, largely credited to Leon. In December, he was flown to New York, seemingly responsible for $44 million in Bearings turnover that year. Some traders raised doubts that these kinds of profits could be made from the low-risisk trading he was supposed to be doing. But management's faith in Leon's talent was unshakable, and they dismissed these concerns. Beering's overconfidence in Leon and Leon's overconfidence in himself would be the bank's downfall. The figures are so big it seems like the ultimate confidence trick. But there's a partial explanation for the delusion on both sides. Leon's and bearings overconfidence was amplified by the complexity and unpredictability of the market and the trades he was making. It's sort of an issue of feedback. In a controlled environment where there are clear rules and guaranteed outcomes, like in a chess match, there is clear feedback on whether decisions are good or bad. With reliable feedback, professional chess players are able to learn to make better decisions with more accurate confidence. But in a noisy environment where there is rarely consistent or timely consequences for predictions, this feedback is unreliable. Whether our confidence is accurate or misplaced is increasingly hard to judge even amongst experts. It's especially problematic for political pundits.
>> This is going to be a landslide. I think Romney is going to win by quite a bit.
>> So, right now, we have Hillary's about a 75 or an 80% favorite.
>> For example, prior to 2024, political analyst Alan Lickman had accurately predicted the winner of nine of the 10 previous US presidential elections using his 13 keys to the White House method. Using the same strategy in 2024, he predicted that
>> Kla Harris will be a president-breaking president.
>> Look what happened. Is this crazy?
>> He attributed his miscalculation to the spread of disinformation that misled the electorate. This noisy environment made it difficult to discern key issues like the actual state of the economy. Similarly, the feedback Leon had received was inconsistent. He was making some bad trades, but he had also won it all back before. and this significantly clouded his judgment, amplifying his overconfidence. By 1995, Leon's losses were in the hundreds of millions, and Bearings had unwittingly sent him $1 billion. For a bank with around $700 million in capital base, they were legally only allowed to lend around a quarter of that. But no one questioned it. They were all blinded by his apparent success. At this point, his positions were so big, he estimates that he was probably half of the entire Nikay futures market. So all he could do was buy himself some time and hope that the market went his way. And for a while it worked. The economy was stable and he couldn't see anything on the horizon that would change this. But then disaster struck. Japan is tonight in a state of mourning and of shock.
>> On the 17th of January 1995, the great Henshin earthquake struck Japan. 20 km from the city of Coobe. With a magnitude of 6.9, it devastated the city which was one of Japan's key ports. This devastation spread to the stock market. The NIK index plunged 1,055 points. Leon attempting to double down again risked even more money. He bet heavily that the Nikay would make a rapid recovery, but it didn't. And in the end, in today's money, Leon had lost $2.8 billion. On the 23rd of February, Leon went on the run. And 3 days later, Bearings, one of the oldest and most trusted banks in the world, collapsed. overconfidence was at least partially to blame for its downfall. Realizing the walls were closing in, Leon fled to Malaysia and then Thailand, but his escape was short-lived. He was eventually arrested in Germany and extradited to face justice, marking the end of a spectacularly destructive gamble. He was just 28 years old. Now, we don't all bring down banks, but we are all vulnerable to overconfidence. In a complex world with unclear, noisy feedback where our brains are overwhelmed, a set of simplistic biases can take over and we all too often end up thinking we know more than we do. So, what can we actually do about this? I try to get better at calibrating my confidence judgments by keeping track and keeping score. So, uh, when a colleague asks me, "How long is it going to take you to get me comments on this paper draft we're working on?" I don't promise I'll do it by Friday. I'm much more likely to say something like, "I think there's a 60% chance I can get you comments by Friday." They'll often uh react with a quizzical look or uh a laugh. Well, practicing and being aware of our calibration is the obvious way to improve, but so is being intellectually humble.
>> I think that uh the best medicine for overconfidence is not so much information as feedback. Um and I get plenty of that though. I also I I think people are right that sometimes I do have a little bit of overconfidence.
>> If we want to become more accurate, we should capitalize on the wisdom of the crowd by listening more to others. In particular, we should listen to people who disagree with us. Understanding the best arguments of your critics, understanding what information those who disagree with you have that you lack is very helpful for making better decisions. The best calibrated people aren't those who know the most. It's those who know what they don't know. So, true wisdom lies not in being certain, but in knowing the limits of your own certainty. And that's an idea that's inspired our latest project. All those questions I asked. These are good questions. A
>> well,
>> they come from a new board game that we've made. It's called Elements of Truth. The game contains over 800 fascinating science trivia questions with a twist. The number of points you win on each question depends on how confident you are. You can bid any number from 1 to 10. If you're not sure, you can play a low number, or you can try to follow the lead of someone else who you think should know the answer. We've tested this game with scientists, teachers, and students. And what we found is that it regularly leads to discussions that go way beyond the initial questions. The core game comes with 200 questions that cover all aspects of science, and there are five additional packs on specific topics like physics, technology, engineering, and astronomy. Plus, there's a Veritassium pack on concepts covered in many of our most popular videos. We're launching the game through Kickstarter to give you the opportunity to shape it with us. Over the next month, you'll be able to submit questions for a special community pack. This is your chance to etch your name into Veritasium History with a credited question in the game. To reserve your copy and get involved, use this QR code or the link in the description to head over to Kickstarter. It is only because of you that I've been able to make this channel and this game. So, as always, I want to thank you for your support and thank you for watching.