大家好 欢迎来到我的频道 昨天呢做了那期加里马库斯的视频啊 很多人在底下留言啊 就是说呀 这个马库斯根本就不懂人工智能 现在AI已经很好用了 你就是想要去黑这个ChatGPT 我这得跟大家解释一下啊 我可是这个大语言模型的忠实用户 基本上 市面上你能想到的这些顶尖模型 我都有付费使用 我有买这个ChatGPT的 200刀一个月的会员 然后呢Gemini我也买了一个 那个Ultra应该也是200刀一个月 然后还有Claude和perplexity啊 当然perplexity是买这个Zoom会员送的啊 这个就没有付钱了 所以呢基本上 我对于这个AI技术是非常认可的 因为我觉得它确实在很多方面 能够帮你提升工作效率 但是呢我觉得呃 加里马库斯的批评也是很到位的啊 事实上我也测试了好几个 就是关于ChatGPT 它现在目前没有办法能做到的 这个功能啊 它确实存在这些问题 那我们今天呢 就想给大家解读一下啊 加里马库斯在20年前写的这本书 《代数大脑》 呃基本上在这本书中呢 其实就已经展现了 他现在对于这个神经网络技术的不足 的批评观点基本上就没变 那我们直接进入今天的主题吧 我们都听说过啊 大脑像一个复杂的神经网络 那如果这是错的呢 今天的AI巨头 啊比如说ChatGPT啊 都是基于这个神经网络 但他们为什么会犯下这些低级错误呢 20年前啊 一位认知科学家就预言了这一切 今天呢我们深入解读一下 加里马库斯的代数大脑 揭开一个颠覆你常识的真相 啊你的智能核心或许不是模式识别 而是一套强大的代数系统 准备好我们就进入这一场 大脑的底层探秘之旅 首先朋友们 你们有没有想过一个问题啊 一个7个月大的婴儿 话还不会说 路还不会走 竟然能够像一个逻辑学家一样 发现抽象的语法规则 这听起来是不是有点反常识啊 我们总被告知啊 大脑嘛就像一个巨大的神经网络 通过海量的经验学习 慢慢的识别模式 我们今天引以为傲的人工智能 比如说ChatGPT5 不就是这么工作的吗 但如果我告诉你啊 我们深信不疑的这个神经网络 可能从根本上 就解释不了 人类智能最核心的那部分能力呢 如果说啊 你的大脑深处 其实有一个更古老 更强大的代数引擎呢 我们今天就聊一聊 这本20多年前出版的 在今天却越发具有这个预言性的神作 这本书呢 将带我们潜入智能的底层 去探索一个被大家很多人忽视的 就是理解我们自己 以及真正通用人工智能AGI的关键 相信看完本期节目呢 大家对于智能的理解啊 会有更深层次的进步 要理解这本书的厉害之处呢 我们先得回到认知科学领域啊 一场持续了几十年的华山论剑 这个论剑的双方呢 就像什么剑宗和气宗 对吧在这里头呢 两大派第一派叫做符号主义 第二派叫做连接主义 这个符号主义啊 这一派的大佬认为啊 大脑就像一台经典的计算机 智能的核心是什么 就是处理符号 就像计算机处理0和1 我们大脑处理的是概念 规则这些心理符号 比如啊所有的狗都会叫 这是一条规则 遇到一条新狗 我们就能够运用这条规则 推测出它也会叫 简单清晰 有逻辑。第二派呢 就是连接派啊 他们觉得把大脑比作计算机太土了 大脑明明是由几十亿个神经元 相互连接组成的 所以呢智能不是靠什么规则 而是神经元网络在经验中学习 通过调节神经元之间的连接权重 逐渐形成一种能力 你看啊 这是不是更符合生物学的事实 也更高级了呢 时间到了上世纪80年代 随着一本叫做《并行分布式处理》 PDP的书横空出世 连接主义迎来了高光时刻 大家突然发现啊 这种受神经网络启发的模型 好像真的能够模拟很多 过去难以解释的认知现象 比如说语言学习 从那以后啊 连接主义一路高歌猛进 直到今天成为了人工智能的绝对主流 我们现在用的 所有大语言模型 本质上都是连接主义思想的产物 他们都是规模巨大 结构复杂的神经网络 这就带来一个核心问题啊 也就是 《代数大脑》这本书想要挑战的终极问题 既然连接主义这么成功 我们是不是可以彻底的 抛弃符号主义了呢 人类智能 真的就是一个超级复杂的神经网络吗 加里马库斯响亮的回答不对 为了搞清楚马库斯的论证啊 我们必须得花一分钟 首先了解连接主义的当家花旦 多层感知器MLP啊 我记得这个英文好像是呃 Multi layer perceptron啊 这个我后面查一查 我不知道说的对不对啊 到底是怎么工作的呢 你看啊你可以把它想象成 一个超级复杂的调光系统 最底下一层呢 是输入节点 就像一层开关 比如说我们要识别一张猫的图片 有可能代表胡须的开关就打开 代表有尖耳朵的开关也打开 最上面一层呢 是输出节点 就像最终亮的灯泡 可能一个灯泡代表猫 一个灯泡代表狗 最有意思的是 中间这一层 叫做隐藏层 他就像无数个错综复杂的调光器 和线路连接着输入开关和输出灯泡 每个连接线路上都有一个权重 决定了这条线路的信号到底有多强 当输入的开关打开时 信号可以通过这些带权重的线路 传到隐藏层 隐藏层再把信号传到输出层 最终亮的那个灯泡就是网络的答案 比如猫这个灯泡最亮 那么网络就判断这是一只猫 那这个神奇的系统是怎么学习的呢 那最常用的方法叫做反向传播 backpropagation 这个名字听起来很唬人啊 但是打个比方 你就秒懂了 想象一个学生正在做题啊 他刚给出一个答案 网络输出哎 老师就告诉他正确答案应该是什么 目标输出哎 学生一看 哎呀 我的答案和正确答案之间有差距啊 这个差距在网络里头就叫做误差 怎么办呢 学生就得反思啊 我到底是哪个知识点没掌握好呢 于是他就从答案开始 一层层的往回找原因 修改自己的笔记 这个修改笔记的过程呢 就是在网络调整那些连接的权重 一次次重复这个过程 网络里的权重就会被调整的越来越好 误差越来越小 他就学会了 你看这过程是不是很吸引人 他不需要你预设任何规则 只要给他足够多的数据和反馈 他就能够自己学习 感觉上 这可比硬邦邦的符号规则聪明多了吧 也更像是我们人类学习的方式 对吧 这个核心呢 其实也就是机器学习的这个原理啊 好 背景铺垫完了 现在主角要登场了 马库斯认为啊 要真正理解人类智能 我们不能只看连接主义的表面风光 必须直面符号 加工思想这三个核心支柱 这三个支柱 才代表我们智能的代数本质 第一我们的大脑 能够表示变量之间的抽象关系 简单来说 就是我们能够理解和使用规则 比如给动词加ED 变成过去 式，past verb等于verb加ED 这里的verb就是一个变量 你可以代入任何动词 比如说walk jump 这些规则都成立 第二就是 我们的大脑 拥有递归和结构化的表示系统 这什么意思呢 桌子上的书和书上的桌子 虽然用的词都一样 但我们清楚的知道 这是两个完全不同的意思 因为 我们大脑不是一个简单处理一堆词 而是在处理他们之间的连接关系 而这种结构可以无限嵌套 就像俄罗斯套娃一样 第三 我们的大脑能够明确区分个体和种类 我们知道狗是一个类别 也知道我家那条叫旺财的狗 是一个独一无二的个体 这听起来好像很简单 但对于计算系统来说 其实是一个巨大的挑战 现在最核心的问题来了 那个看起来很厉害 能够从数据中学习的多层感知器 它能实现这三个核心能力吗 马库斯的答案是不能 或者说标准的多层感知器 在这些人类智能的核心领域存在 根本性的缺陷 接下来的内容 就是这本书最精彩的部分 马库斯用一系列精巧的思想实验 和真实的认知心理学研究 像一位侦探一样层层剥茧 向我们展示 为什么那个看似万能的神经网络 其实并不能解释我们大脑里 那个真正的智能引擎 首先我们来看一个最简单的思想实验 也是梳理一个非常核心的例子 大家看屏幕上的这个表格 我给大家看几组输入和 输出输入1010输出1010输入0100输出0100 规律很简单吧 好那现在问题来了 我给你一个新的输入 1111 你觉得输出应该是什么 我猜 99%的朋友 都会毫不犹豫地回答1111 对吧因为 我们瞬间就发现了一个抽象的规则 输出等于输入 或者用数学的话说 这就是一个恒等函数F（x）= x 我们能够把这个规则 自由地泛化到所有没见过的新例子上 这种能力就叫自由泛化 好我们再把同样的问题 交给一个标准的多层感知器 你猜怎么着 经过训练后啊 你给他输入1111 他可能输出的是1110 为什么会这样呢 这就触及到 这类神经网络的一个致命弱点 马库斯称之为训练独立性 你看啊在这个网络在训练的时候 发现所有的训练样本里头 最右边那一列的输出永远是0 所以他学到的潜规则是 不管输入啥 我输出的最右边那一位大概率就是0 他根本就没有学到那个抽象的 输出等于输入的代数规则 打个比方啊 就像一个只会死记硬背的学生 你给他100道例题 他都背了下来 但考试的时候你换了个新题 只要这个题型他没见过 他就懵了 他没有掌握背后的公式 而我们人类恰恰相反 我们就天生擅长找那个公式 这个小小的例子 就暴露出了标准的神经网络和 人类智能之间的一个巨大鸿沟 你可能觉得 刚才那个0和1的例子太抽象了 别急啊更有意思的来了 我们来看看 开头提到那个7个月大的婴儿实验 科学家给一群7个月大的宝宝 听一些毫无意义的音节序列 一组宝宝听的是a b a结构的句子 比如拉踢拉 另一组听的是ABB结构 比如说拉踢踢 就这么听2分钟啊 然后神奇的事情发生了 科学家开始给宝宝播放 全新的音节组成的句子 你猜怎么着 听过ABA的宝宝 当他们听到全新的ABA句的时候 比如说噢非噢的时候 就没什么反应 但一旦听到ABB结构的奥菲菲 他们就会表现出明显的惊讶 盯着喇叭更长的时间 这意味着什么 这意味着这些话都说不明白的婴儿 竟然在短短的2分钟内 超越声音本身 提取了一个抽象的代数规则 第一项和第三项相同 并且 能够把这个规则应用到全新的声音上 这简直太惊人了 这种强大的规则提取能力 在儿童学习语言的过程中随处可见 最经典的例子就是学习英语的过去式 我们大家都知道啊 大部分动词的过去式都是加e d 比如说walk变成walked 但还有一小撮不规则的 比如说sing变成sang go变成went 有意思的是呢 小孩子在学习说话的时候 经常会犯一种聪明的错误 他们可能会先说ate 但过一段时间呢 他们反而会说eaten 为什么呢 因为大脑发现一个更通用的规则动词 加ED然后呢 试图把这个规则应用到所有动词上 哪怕那些是不规则的 而很多早期的连接主义模型 就很难解释这个现象 他们要么 很难学会这个通用的加ED规则 要么在泛化的时候 就会搞出一些很奇怪的混合词 比如说把Splin变成了一个Splind 而不是我们人类常会说的Splind 或者是Splang 你看这再次说明 我们的语言系统里头 似乎内置了一个处理抽象规则的模块 和一个负责处理记忆特殊例外的模块 这是一种双轨制 而不是一个大一统的神经网络 好的解决了规则问题 我们再来看看第二个核心支柱 结构化表示 我们前面提到了桌子上的书 和书上的桌子 在我们看来 这两个意思天差地别 但是对于一个简单的神经网络来说 可能就傻眼了 因为他看到的可能就是书桌子上 这几个概念被激活了 至于谁在谁上面 这个结构信息就丢失了 这个问题在AI领域被称为是“叠加灾难” 当你试图用同一组资源 比如说一堆神经元 去表达多个实体和他们之间的关系时 信息就会互相干扰 变成一锅粥 为了解决这个问题 马库斯在书里头 提了一个非常有趣的概念 叫做树苗 你可以把它想象成 我们大脑里头 预先装了一堆文件结构模板 每个模板都有固定的 槽位比如说施动者动作承受者 当我们理解这一句话时 就把对应的概念填到这些槽位里头 这样一来 结构信息就不会丢失了 桌子上的书 就是把书填到主体槽 把桌子填到位置槽 反之亦然 这个想法 就为大脑如何在神经层面 实现结构化表示 提供了一种可能的解释 最后我们再来看第3个 也是最容易被忽视的一点 区分个体和种类 你看啊一个标准的神经网络 它通过特征来识别物体 比如说四条腿 有胡须会喵喵叫 它就识别为猫 但问题来了 如果现在有两只长得一模一样的猫 菲利克斯和莫里斯站在你面前 神经网络怎么区分它俩 对网络来说 他们两个特征完全一样 所以他们俩就是同一个东西 网络无法理解 这是两个完全不同的个体这样的概念 而我们大脑呢 大脑有个神奇的能力 大脑有个神奇的能力 就是给每一个遇到的个体 贴上一个独一无二的心理标签 并且在时间和空间中持续追踪 这个标签 就像电影变脸里 无论是尼古拉斯凯奇 还是约翰特拉沃尔塔 还是约翰特拉沃尔塔 怎么换脸 我们始终清楚谁是好人 谁是坏人 因为我们追踪那个是持续存在的个体 而不是他表面的特征 这个能力是客体的永久性 是计数甚至是社会关系的基础 而一个无法区分个体 和种类的系统 是无法真正理解 我们 这个由无数独特个体组成的世界的 好了我们讲到这里呢 大家可能会觉得 马库斯说的这些都很有道理 但是呢这本书《代数大脑》 毕竟是20多年前的书了 今天的神经网络 特别是那些新的大语言模型啊 已经比那时候强大太多了 他们是不是已经解决了这些问题呢 有意思的事就在这里 答案是并没有完全解决 你看 今天大模型非常擅长识别和生成模式 这是联结主义的强项 但是呢他们也暴露出了很多弱点 他们会一本正经的胡说八道 幻觉，缺乏真正的逻辑推理能力 而且有时候会因为输入的一点点变化 就得出完全错误的结论 脆弱性 这不正是马库斯当年指出的 那个根本性缺陷 在今天的体现吗 他们仍然很难完美的处理抽象规则 复杂结构和个体追踪 所以呢 代数大脑的观点在今天非但没有过时 反而变得更加重要 告诉我们 通往真正通用人工智能道路 可能不是把神经网络做的更大 而需要把符号主义的代数能力 和连接主义的学习能力结合起来 这就是现在AI研究的前沿方 向之一神经符号AI 那么了解了我们大脑的代数引擎 对我们普通人有什么用呢 哎这用处可就大了 第一呢可以改善我们的学习方式 你要分清楚 你是像神经网络一样死记硬背 还是像代数大脑一样掌握公式 下次学习新知识 别光记结论 多问几个为什么 去寻找背后那可以自由泛化的规则 这才是真正的高效学习 第二是提升你解决问题的能力 遇到一个问题 先判断一下 这是一个需要模式识别的问题 还是需要逻辑推理的问题 如果是前者 你需要多找案例 凭感觉和经验 如果是后者 你就得静下心来 一步步分析结构 运用规则 把大脑两个系统都用在刀刃上 第三更清晰地看待AI 下次再看到天花乱坠的AI宣传 你就可以多一分批判性思考 问问自己 它是在做高级的模式匹配 还是 真的具备了理解结构和规则的能力 这能够帮助你更好地运用AI 而不是被它所忽悠 所以我回到我们最初的问题 我们大脑到底是什么 再说大脑给了我们一个新的启示 它既不是一台冷冰冰的逻辑计算机 也不仅仅是一台混沌的神经网络 它是一个无比精妙的混合系统 它既有连接主义系统的 强大的学习和模式识别能力 又有符号主义系统精准的规则 操作和结构表示能力 这就像一个伟大的艺术家 他既对色彩和光影有直觉连接主义 又对透视和构图有严谨知识符号主义 两者结合 才诞生了伟大的作品 理解了这一点 我们不仅距离创造真正的人工智能 又更近了一步 更重要的是 我们能够更深的体验到 我们的心智的奇迹 我们大脑里都运用着这个代数引擎 它赋予我们学习语言理解世界 进行创造的能力 这本身 就是一件值得惊叹和感恩的事情 最后呢聊一聊对这本书的批评啊 很多人认为啊 这本书出版于21世纪初 其中呢 马库斯批判的一些具体的模型和论文 啊现在已经被认为是过时了 机器学习领域已经取得了长足的进步 更新的 深度学习模型能够完成一些啊 曾经被认为是不可能的任务 一些读者也发现啊 如果没有专业背景 很难理解 书中关于反向传播模型的技术细节 尽管有这些批 评呢但是很多评论者一致认为啊 代数大脑这本书提出的理论 思考和思维方式 仍然具有很好的现实意义 好的今天的分享就到这里了 希望这本代数大脑 能为你打开一扇新的窗 让你看到智能背后呢更深邃的逻辑 如果你对这个话题感兴趣的话 强烈推荐去读一下原书 本期节目就录到这里了 非常感谢大家观看 我们下期节目再见