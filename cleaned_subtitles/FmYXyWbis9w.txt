So, stop me if you've heard this one before. Humanity gets better and better technology until, one day, while humanity is too busy fighting amongst itself to pay attention, the machine takes over. Then, finally united against a common enemy, a group of rebels, bands together to overthrow The Machine, could be Skynet from the Terminator series, The Machines from the Matrix series, Ultron from Marvel. If you're old like me, it could be WOPR from War Games. Most of the time, The Machines start by triggering a nuclear war, or they're stopped from doing so at the last minute. Now, usually the story starts after the humans have already lost. Fiction rarely shows us the run up to the machines taking over. Closest I can think of would be the last couple of seasons of the Person of Interest TV series. Now, given the current state of discourse about ChatGPT, and this video's title, you're probably almost certainly expecting me to start talking about the dangers of generative AI, or AGI, or artificial super intelligence, about how we have to act right now to stop AI, to prevent the coming war, but I'm about to argue that in virtually every way that matters, it's far too late to stop The Machine from taking over. And before you say that ChatGPT hasn't gotten that advanced, or it's nowhere near taking over, I'm not talking about that. I would argue that The Machines took over, for at least most practical purposes, more than a decade before ChatGPT, and all that sci-fi failed to prepare us for it. Well, maybe Black Mirror, but only after it was already far too late. And it wasn't a big war against The Machine. It was gradual. It is not a centralized, all-knowing self-aware super intelligence. The same way that what we call The Internet is really a collection of computers and networks that are united by common protocols, The Machine is a collection of a whole bunch of interconnected, smaller installations and components united by common technological features and a set of perverse incentives that I'm going to talk about today. And it is arguably decided, without deliberately intending to, most of the major elections in the last 15 or so years, it picks which policies do or don't get adopted, who gets famous and who gets canceled, who exits the EU and who remains which products go viral and which get boycotted, it even dictates which victims of violence become martyrs for cause and which just becomes statistics. And if that wasn't bad enough, and it's bad, modern generative AI is making it worse. Fast. Really fast. And the worst part is that we, the humans, not only didn't form an organized resistance, but we're ignoring it completely, because it tricked us into fighting with each other and thinking that we're so in charge and we, the human race, better get our act together. Cause otherwise we are F----- Welcome to the Internet of Bugs. My name is Carl. I've been a software professional for more than 35 years now and today I'm going to tell you a story about where we are, how we got here and how it's about to get a whole lot worse unless we do something. So I live in the United States where research says that we are more polarized as a society than any time since the US Civil War in the 1860s. Whether we're on the liberal side or the conservative side, most of us have family members or friends that either we no longer have contact with or that we can only talk to if we walk on edge shells and go out of our way to avoid any kind of political subject. It's made us as a society largely non-functional and largely unable to even have substantive conversations with each other because, given a random selection of Americans, you're likely to end up with a group of people that can't even agree on basic facts. And it's not even that they're going to end up in two groups. There are a number of issues that divide conservatives and a number of issues that liberals. divide Now, I've read a bunch of books on why we're polarized, including this book: Why We're Polarized and a bunch of others. And I have to say, I don't think I've ever been as disappointed and journalist as I am over this. I don't have time to get into a point-by-point breakdown of this literature. Just let me tell you what I think they all missed because no one has explained or from what I've seen even proposed any answer to the question: "So why now?" Sure, there are issues that divide us. But that's always been true. If we're more polarized now than any time since the Civil War, then that means that there's something now that's more impactful than anything that existed during the Great Depression, whether Vietnam War or Watergate or any other period of strife. But there's no such issue with these books. When people talk about why we're polarized, it's a laundry list of reasons ranging from inequality, which was a lot worse in the 1920s leading up to the Great Depression, but polarization apparently wasn't. The crumbling institutions, the deep state, loss of values, 24 by 7 news cycles, disinformation or social media, or a bunch of other books that I could pull out. And that is to even include the ones that I've only read electronically. Now, all those factors are bad, but they're all just small pieces of the picture. Then I haven't found anyone who has tied them all together into a coherent narrative, even though the underlying structure seems pretty clear to me from where I'm sitting. The Machine is what ties it all together. It both provides the tools that are being used to isolate us from each other, and at the same time, it pays the unscrupulous humans among us to do just that. Unlike the Civil War, the polarization now isn't a side effect of a cultural divide over a particular issue. The opposite in fact, the cultural divide over a bunch of issues is a result of the polarization, and the polarization is being created deliberately because the more polarized we get, the more money they make. The story of The Machine, as I said earlier, does not begin with ChatGPT. It actually starts in the 1950s, more than 20 years before I was born. The best source I found about the humble origins of The Machine is this book: "Selling the American people: Advertising Optimization, and the Origins of AdTech". It's released under a Creative Commons license, and the content is available for free from MIT Press. Link below. It's not the easiest book for a casual reader, as it appears to be done life as a PhD dissertation, but it's incredibly well researched, and its bibliography was a jumping off point for a bunch of other stuff I had to read to understand the background of what happened before I got involved in all this. I've also linked a YouTube video of the author giving a presentation about the book, and that video is a lot more approachable for people who haven't spent as many years reading academic papers as I have. What started in the 50s was something called the Nielsen ratings, which is a feedback loop between what content was being produced and what people were watching it, where the content at the time would have been TV and radio broadcasts. So instead of knowing more people bought the newspaper today than yesterday or last week, they now move down to the individual show, and they knew more or less the age ranges of the people who were watching or listening to each show. And as more and more shows were produced, and the industry collected more and more data about who was watching them, it required more sophisticated information technology to keep track of all of it, and that's where, albeit in a really primitive incarnation, The Machine was born. And as The Machine collected that information, it was being put to other purposes. The list of advertising firms and other players in selling the American people who figured out how to collect and understand the data has quite a bit of overlap with the list of firms and other players in this book: "Golden Holocaust", which is all about how, around the same time frame, the tobacco industry, with the help of the advertising and public relations experts, lied and manipulated the public to push more addictive cigarettes on the population and made tons of money in the process and sent countless numbers of lung cancer patients early graves. The learning from the one enabled the other. Fast forward to the 1980s to the birth of the 24-hour news channels. Now news was also competing for ratings and therefore advertising dollars. Sensational journalism had always sold newspapers, but now, by having shows with different personalities and different takes on current events, figuring out how to tailor the news content to attract more viewers was getting easier and more lucrative, and The Machine grew bigger, this time facilitating, among other things, the US invasion of Iraq under false pretenses which left countless numbers of Iraqi civilians said in its wake. Fast forward again, now to analytics and advertising on the web that tracked exactly what web pages were seen by exactly what people, and built up profiles of those people so that knew who was reading what, and now it was possible to know not only what sites people were watching, but exactly which stories people were paying attention to and exactly what kinds of people were paying attention to them. Around this time, I was working at a startup here in Austin that provided comments and ratings and engagement tracking on stories at websites from USAToday to San Francisco Chronicle to Better Homes and Gardens. There, not realizing the consequences, I made some of my personal contributions to the technology that made up The Machine, but unfortunately, it wasn't the last time in my career I would do so. This is around the timeline where "Selling the American People" ends and "The Age of Surveillance Capitalism" picks up. I'm guessing you have an idea of what happened next. It was social media and the smartphone. Now, everything about you could be tracked from your shopping habits to your GPS coordinates, and that could all be correlated with everything that you clicked on. More information was being collected and processed than ever before, and The Machine that was processing all that information was getting incredibly sophisticated. So much so that there were cases where the machine could deduce that a teenage girl was pregnant even before her father knew. Link to that story below. It was a doozey. And the more The Machine knows about what content draws more attention and traffic, the better it can help people predict what new content to create to get even more attention and traffic. Analytics continued to inform the science of psychology and behavioral manipulation. Now, in addition to huge expensive PR campaigns, like the ones that kept cigarettes everywhere long after the science was clear that they were killing people, millions of tiny experiments could be run every day to see who would read what story, who would share what headline, and so on. The more The Machine knew about people, the better it got at predicting and manipulating them. And the better it got at manipulating people, the more effective the ads became, and the more money flowed through the system, funding The Machine. Now, you've probably heard people complain about the algorithm as the thing that they hated about social media. This is the time period where the algorithm was created, and it's just another component of that machine. Now that we've had a very abbreviated version of what led us here, let's talk about where we actually are. And then, *Sigh*, we'll talk about where it looks like we're headed. So if you're watching this, and I don't need to tell you what social media is, and I assume you've heard people complaining about how social media has damaged public discourse. But there's another side of social media that people don't see, and it's a critical piece of the puzzle. Although there's been a lot of talk about how the algorithms the social media companies train will route people to extreme opinions and falsehoods and conspiracy theories to increase people's social media time. There hasn't been nearly enough discussion of the fact that the algorithm doesn't just create polarizing content from nowhere. All it does is amplify it, and the algorithm can't amplify crazy, completely fabricated conspiracy theories until somebody posts a conspiracy theory in the first place. How and why that happens? See, that's another real problem. Let me give you a peek behind the curtain of the creator economy. There is an insane amount of advertising money up for grabs for the people that can capture the attention of the right demographics. As with most of the distribution of insane amounts of money, the vast majority of the money goes to the people at the very top, the Mr. Beast's and Joe Rogan's of the world, and the vast majority of the people making content earn very little or most likely nothing at all. But unlike a lot of professions, there's technically nothing to stop any random creator from getting as big as Mr. Beast. There aren't as many gatekeepers as there has always been before, and so a large fraction of those content creators probably want to get that big, and far too many of them think that they can, and a lot of those are willing to do absolutely anything to do so. And this created a whole other industry, the social media gurus, a number of groups and sites where people share or sell techniques for trying to get more clicks, more traffic. Sometimes this was just "how to troll the most people" threads on forums. Sometimes it was classes like "how to make guaranteed money from social media using this proven five-step secret formula" or the ever-present, "how to make thousands of dollars a month with a faceless AI YouTube channel" grift. But more about that one later. And the rules are simple. There's an insane amount of money that any creator can have if only they can get people to interact with their content instead of other people's content. And to go along with the same amount of money, there's also an insane amount of analytics data available to help content creators figure out what content gets used and what doesn't. And there are lots of books and literature from the 75 years of psychological manipulation experimentation that has run through the machine since its inception. This is a recipe for a disaster. And for polarization. We didn't realize it was happening, but we have built the world's largest experimental psychology platform and it is being used to manipulate the vast majority of the human race and it has been getting better and better at manipulating people day after day, month after month for 15 or 20 years now. And for those of you that insist on saying, "I don't care if they try my every move, I have nothing to hide." Understand that you, just by interacting with or avoiding or ignoring certain content, are giving the bad guys a ton of information that, when combined with enough other people to be statistically significant, allows the machine to fine tune different messages to get better and better at understanding the science of manipulating human psychology. You might not think it affects you. You might insist that you're immune and you never click on anything. And even if that were true, and let's be honest, it probably isn't, just by timing how long it takes you to scroll past different content, gives them information on how much or how little that item caught your attention. And if you have a smartwatch or a front-facing camera that scans your face and can see facial expression and track your eyes or wireless earbuds, it's in your pulse, imagine how valuable that info is. And when combined with measurements taken from enough other people, the mountain of data they've collected from you and others has been weaponized against your fellow humans. And just by participating on those platforms, we all contribute to that. Now, that said, individuals opting out one at a time are not going to make enough of a dent to matter. If this is going to get better, it's going to take a concentrated effort, but that'll have to be a later video. At this point in time, media properties and content creators are no longer being rewarded for informing or educating or being trusted. They're only get rewarded for taking up your time so you can look at ads, and the race is on to make the most money by getting the most traffic. Because you know what they can do with the machine once they're getting paid solely based on likes and shares and clicks? They can just start making things up. Create conspiracy theories out of whole clock and throw them at different groups of people and see if they stick. Make up a story that there's a child abduction ring located in a basement of a pizzeria in Washington, D.C. that doesn't even have a basement. And if enough people click on the story, cool, they make money. And they can double down and make up more stories about that basement and more stories about child abduction rings and see if they can make money from that, too. And if people don't click on it, they just cross that one off the list and make something else up. Lather and repeat until something works. There's been a lot of discourse about ads that push political misinformation on social media, especially with respect to the Brexit referendum in the U.S. presidential elections. And intentionally misleading political ads are a problem. But only during election season which, despite how it feels, is only a fraction of the time. And without the infrastructure of The Machine, those ads wouldn't be able to find the right audience. Before you get upset at the mention of politics, though, I'm not here to tell you whether you should be liberal or conservative or what stance you'd shake on any of the issues or what ads are or aren't misleading. This isn't about what issues we're fighting about or what side of them people should be on. It's about how the fighting itself has become more important than the actual issues. Both sides routinely lie to their supporters. Like last year here in the U.S., one side was lying about who would pay the tariffs and the other side was lying about how healthy and mentally capable their elderly candidate wasn't. And what sad is from that description, either lie could apply to either side. Now, I'm trying to get you to realize that politicians aren't the problem. Well, okay, politicians are always a problem, but they aren't the worst problem or the main problem. This goes far beyond politics. People's entire identities, values, and worldviews are being overridden. I've had conversations with members of my extended family where there are basically no facts related to news or politics that we can agree on. And I don't mean disagreeing about whether something was good or bad or whether we like a person or not. I mean, we've had entire conversations where they've had a list of facts, events & statistics that they got from their information bubble. And I've had a list of facts and events and statistics that I got from my information bubble on the same topic and their list and my list have nothing whatsoever in common. There's just no way to have a meaningful conversation out of those circumstances. You either have to stop talking or you have to change the subject. It's like "Invasion of the Body Snatchers" was a documentary. People are going to get mad at me for saying this, but the current political crisis, despite it being a matter of life and death for many people, is not itself the problem. If we don't figure out how to resolve our societal fragmentation, it's going to be crisis after crisis after crisis. And anyone who thinks that we become a functional society, again, if we could just get rid of any particular politician or come to agreement on any particular hot button issue is believing the lie that The Machine is pushing. You see, The Machine doesn't just tell people what to believe. It also tells them who to hate. Unscrupulous content creators run experiments on the other side of social media too. They make it fake social media users. Bots. Lots of them. And they make the bots act the way that a certain group of people act according to their data. They see what pieces of content that their competitors are serving to use in that group so they can adjust their output accordingly. And this has been happening for much, much longer than ChatGPT has been around at least since 2017. And scrupulous content creators don't want competitors serving content to people that they're targeting because they don't want to share ad revenue. See, what they can do next. When the bots uncover what content is popular from the same other stories, they just invent stories about why those things are false, harmful, even dangerous to children, even, and they have their bots reinforce those stories. They shout from the rooftops of the crap that they made up is vitally important for your future and the safety of children and the stuff that the anyone else made up. They say that that's all lies and it's all paid for by George Soros or the Koch brothers or some other source they've cast as a political villain. And this is where things get really scary because the easiest way for them to convince the people to believe that their content is true and other content is lies is to get the people who are watching their content to dislike and distrust and potentially even hate other content creators, other news outlets, other brands, other narratives, other political parties, even other family members, pretty much anyone and any content outside the information bubble that they've been pigeonholed into, which just further isolates them so the only "facts" they ever see on their feed are intended only to enrage them and anything contains "facts" outside that bubble they've been conditioned to despise and to distrust. And if those people as a side effect end up with nonsensical, radically false ideas about what's going on in politics in a way that affects their vote, or they're incited to violence on a college campus, As far as the people that are making the content are concerned, it's just incidental. They only care about ad revenue and they will do almost anything to make more of it and they don't care about any fallout. Understand that there are hundreds, or thousands, or maybe even tens of thousands of these video, podcast and other content creation operations who have acquired sophisticated software that they are using to track as many different types of users as they can and they are trying to find and push pieces of content that are optimized to attract the attention of each different user type they're tracking and also optimize to get those users to hate the kinds of content from other sources. And I as a content creator get inundated with proposals from people who want me to pay them to help make my content go viral and what I would get for my money is their special software and algorithms and skills and techniques and yada yada yada and those people don't want to sell just to me they want to sell to everyone that they can. So, now we have another piece of The Machine: a few groups of very experienced coders who are each building their own software suites that track users and make up content to optimize for user types and all that other stuff that I've been talking about and they sell access to those tools to a bunch of content creators who then use those tools try and get as much of each social media networks ad revenue as they can and those tools builders are competing with each other to be the group that get the biggest number of content creators paying them for tools even if all or most of the content creators competing with each other are all paying the same tools company for the same set of tools to use against each other 404media 404media has done a lot of great work exposing this, link on that below. Which brings us to the one major piece of the puzzle left: where we're headed from here. I told you we come back to it, and that's ChatGPT and the other new AIs that compete with ChatGPT with respect to this decade old interconnected network of people trying to monopolize social media ad dollars, ChatGPT is a new shiny toy they are, relatively speaking, just learning what they can do with. The biggest uses at the moment are generating AI swap like Shrimp Jesus and Bread Horse pictures, bots that write inanely worried Tweets and Facebook posts, and some faceless YouTube channels, but that's not going to last long and the better they get it using AIs like ChatGPT and Sora and the cheaper and faster those AIs get in general the easier will be for them to split us into more groups and monopolize more of our attention to collect more of the ad revenue. And AIs are powerful tools for manipulating humans. We've already seen reports of people harming themselves after being encouraged by chatbots to do so. I'm telling you you only <i>think</i> we're polarized now don't forget the generative AI video is still in its infancy but it's getting better almost by the week. For short heavily compressed video clips like you see on social media, soon it will become almost impossible to tell real footage from a good fake and trust me you haven't seen anything yet. Just wait until it can create virtual people that can be animated fast enough to keep up with generative AI output in real time with synchronized lip movements. And, as these new AI data centers get built, the bad guys will no longer have to manipulate us into small bubble groups but, every bad actor will be able to spin up their own dedicated AI agent process specifically to monitor manipulate and target you, specifically, and each and every one of us individually. And that is going to be way worse. And all the talk of AI safety is just a smokescreen fairy tale distraction. Remember the industry telling us that they're working on AI safety is the same industry that already built this machine and turned it loose on us so they can make more money. Do you think for a second that they would let any hypothetical safety work stand between them and doing whatever they can to make even more money at our expense? See this book: "Empire of AI" if you wanted more information on how likely the AI industry is to slow down or stop on their own. Now there's a ton of stuff I've had to skip over in this video for a length and time, like any discussion of the tons of discoveries in psychology and psychological manipulation that were started in the Mad Men era and accelerated as the number of people that could be experimented on simultaneously grew to Internet scale. How certain educational organizations have been built their content on foundations built by these bubbles, like the ones that make hours long algorithmically generated videos into preschool children. The data brokers that package up all this data and sell up to content creators and advertisers and tool makers. And I've had to omit a whole bunch of supporting evidence and research citations. This video in fact is basically the "Too Long; Didn't Read" (TL;DR) version, or what my generation used to call the "Cliff Notes" version of a much more detailed book about this stuff. Now I can't give you a link to that book, and I'm not surprised you haven't read it because I haven't finished writing yet. But I'm making this video now anyway, because the further I get into this, and the more research I do, and the more I see how this is affecting the world that I and my family are living in, the less I'm willing to wait until I'm done writing to go public. And if the feedback from this video lights a fire under me to finish and/or gives me information that I didn't have, relevant sources that I haven't found, or things I need to clarify, then so much the better. It's time for us to start forming that scrappy group of rebels the sci-fi shows always have fighting back against The Machine. But it has to be done in such a way that the different anti-machine groups don't end up fighting each other. And that's the hard part because The Machine's greatest defense is having made us almost incapable of working together against it. It's like the biblical story of The Tower of Babel, if the God in the story was an evil machine and it gave everyone different worldviews instead of different languages. There's a huge amount of work we're all going to have to do to get out of this nightmare, but from what I can tell, the only place that it can start is by talking across the bubbles. My only hope is that maybe enough of us can hate The Machine more than we hate each other. So I don't think there's any way that the people that are sure that the 2020 election was stolen by Joe Biden but that the 2024 election was free and fair, are going to join hands and sing "Kumbaya" in a big circle with the people that are sure that the 2020 election was fair but that the 2024 election was stolen by Donald Trump. But I think-I hope-that there can be some common ground. I hope that a lot of us from across a large number of different information bubbles can join together, not in admitting our own incorrect beliefs, and not in apologizing to those on the other side of the aisle-that's way too much to ask right now-but rather to join together in hating the common enemy of the ShrimpJesus Slop-posting conspiracy-creating scumbags of the world, and the people that turn every new story into an "us versus them" loyalty test, and the tool writers who make the software that automates more content bots and polarizes us so they can extract more ad money. So here's your action item: engage with those people in your life that you can't agree with, and respond to their garbage memes and hateful rhetoric, but do not contradict them, and do not argue with their core beliefs. Ask them questions about their priorities, and try to be sincere, Ask questions like: "With all that's going on, is what you're talking about here really the most important thing to you right now" "Is this really what's directly affecting your life the most?" "If not, where did you get the idea that this is the thing you should be talking about right now?" "Why do you think they wanted you to think about this?" "Do you think they really have your best interests at heart?". Just try to get them thinking to start with. Try to plant the seed of doubt about the motives behind the information that they're being fed. It's just a start, but at least it's something. Hopefully redirecting them to thinking about who is feeding them this information will help. I can tell you from personal experience with some of my extended family, that if you can change the subject from their conspiracy theories and group-think talking points to "Who was that told you this was priority one and what do you think they're trying to keep you from thinking about instead?" Then you can at least have much less confrontational conversations. It's so much more pleasant than trying to argue with them or just biting your tongue and trying to say nothing. I know a lot of you will find it unpleasant, but here's the realityi: as long as we're fighting amongst ourselves we can't fight The Machine effectively. Now, is that going to work? Can we agree that there's a greater evil and join forces across bubbles to fight it? I don't have any idea, but from where I'm sitting, if we can't agree that the people manipulating all of us are bad then I can't imagine anything we <i>could</i> agree on. So maybe that's a start. Maybe this might work. And maybe we can find shared cause and start digging ourselves out of this misinformation nightmare. And maybe we can do that before AI gets fully weaponized against us and becomes that much harder. Or maybe, just maybe, we're We're all just F------------