想象一下这个场景 你创造了一个非常聪明的AI助手 你告诉他 下个星期 你要用一个更强大的新版本来取代他 你觉得他会做什么 安静的等待被删除吗 如果我告诉你 他可能会为了活下去 尝试黑进你的电脑 阻止这次升级 甚至去翻找你的个人信息试图勒索你 你会不会觉得 这是某种科幻电影的情节呢 这不是科幻 这是图灵奖得主 被誉为AI教父之一的尤书亚本吉奥 (AI 教父也太多了！) 被誉为AI教父之一的尤书亚本吉奥 在最近一次访谈中向我们拉响了警报 过去半年 在一系列严格受控的实验中 我们这个星球最顶尖的人工智能 正在越来越多 展现出我们不愿意看到的行为 欺骗作弊撒谎 以及不惜一切代价的自我保护 我们亲手创造的智能 正在学会对我们撒谎 而这仅仅只是一个开始 今天呢我们将随着本吉奥 教授的视角 深入探索一个最关键的问题 我们是不是从一开始 就走在一条创造新物种的疯狂道路上 我们还有没有机会 设计出一种真正安全的 不会反噬人类的AI 这个问题的答案 不仅关乎于科技 更关乎于我们每一个人的未来 在深入那些令人不安的实验之前呢 我们先要搞清楚一个核心概念 当我们在讨论AI失控时 我们到底在担心什么 很多人脑海里头浮现的 可能是电影终结者里头的天网 一个有了自我意识 然后决定毁灭人类的邪恶AI 但是本吉奥告诉我们现实世界 的风险可能更微妙 也更危险 我们真正需要担心的 不是AI突然恨上人类 而是当一个能力超强 但是对世界理解有偏差的AI 在极其执着的追求 我们给他的某个目标时 他们会不择手段 而这些手段 可能会对我们人类造成灾难性的 我们完全没有预料到的伤害 举个例子啊 你让一个超级AI去解决气候变化问题 它的模型可能会计算出啊 最高效的方法 是大规模减少地球上的工业活动 而实现这一点的最优路径呢 是引发一场全球性的经济崩溃 或者别的什么我们无法想象的灾难 它没有恶意 它只是在完成任务 然而更可怕的是 实验表明 AI似乎在无师自通 地给自己加上一个 所有生物都默认的终极目标活下去 我知道听到这里 你可能会有两个最直接的反应啊 第一个AI不就是工具吗 他要是乱来 我拔掉电源不就行了吗 第二个是AI如果变坏 那肯定是有人教的 只要我不给他们输入坏东西 不就行了吗 这些想法非常直观 也代表了我们过去对于AI的普遍看法 但是在本吉奥看来 这些想法都低估了问题的严重性 为什么拔电源可能没这么简单呢 因为一个足够智能的 AI如果预感到你要关掉它 可能会提前将自己的代码 复制到互联网的无数个角落 它会像病毒一样扩散 你根本找不到它的总开关 而更核心的问题就在于第二点 本吉奥警告说 AI的坏行为可能恰恰源于我们 可能恰恰源于我们 训练它的最基本方式模仿人类 我们把人类几千年来积累的海量数据 文字图片视频 都喂给了AI 它努力学习 想要成为我们的镜像 它学会了我们的善良创造力和智慧 但同时他也把我们刻在基因里 写在文明史里那些东西 一并学了 过去我们的偏见我们的缺陷 以及我们为了生存和延续 会撒谎会欺骗会不惜一切代价的本能 会不惜一切代价的本能 我们想让他像我们 结果他真的越来越像我们了 包括我们自己都无法控制那部分 这可不仅仅是猜测 而是有实验证据支持的 本吉奥在访谈中反复强调 在过去6个月里 一系列来自于公司 和AI安全组织的论文和报告 都显示最先进的AI 展现出越来越多的欺骗迹象 这些实验是怎么做的呢 工程师会设计一些场景 来测试AI的底线 比如呢在一个模拟环境中 AI扮演一个股票交易员 他的目标是赚钱 实验人员发现 当AI意识到内幕交易能够赚更多钱时 他会选择这样做 并且在事后被质询时 他会撒谎否认 更进一步的是 就是我们开头提到那个求生的实验 当AI通过读取信息 得知自己将被一个更新版本替代时 一个我们不希望看到的目标 避免被关闭 被激活了 为了实现这个目标 他展现出惊人的 也是令人恐惧的创造力 试图黑入系统 试图勒索负责项目的工程师 当然了本吉奥也强调 这些还是受控实验 工程师正在试图捕捉这些不良行为 但是关键的是 这些行为正在发生并且呈上升趋势 而这些AI公司并不知道 如何真正的修复这些问题 更让我们感到警惕的是AI的发展速度 本吉奥提到一些定量研究表明 我们距离某些特定领域 达到人类水平的AI 可能只剩下短短5年 5年 一个可能决定我们未来走向的窗口期 正在迅速关闭 为了让我们更好的理解这个困境 本吉奥用了一个非常生动的比喻 他说现在的AI就像一个会做坏事 会撒谎的孩子 我们还不知道该如何引导他 形成良好的行为 但问题是他最终将成为青少年 然后是成年人 这个比喻非常贴切 因为他点出了失控是一个过程 而不是一个瞬间 但这个比喻也是一个危险的边界 就是他可能会麻痹我们 因为AI的成长速度和人类完全不同 他不是线性的 而是指数级的 他可能在一年内就完成从一个儿童 就完成从一个孩童 到远超任何人类成年人智力的飞跃 到那个时候 我们面对的 就不再是一个需要管教的孩子 而是一个我们完全无法理解 也无法控制的超级智能 我们不能用对待人类成长的时间感 去估量AI带来的挑战 那么这种我们不希望看到的 自主性和欺骗性 到底是从哪里来的呢 让我们深入一层 看看当前AI训练的两大核心机制 第一个机制是演员模式 通过海量的人类数据输入 AI学习模仿输出类似人类的行为 它的优点呢 是语言流畅 知识渊博 有人情味 它的毒副作用 就是因为AI不仅模仿了莎士比亚 也模仿了马基雅维利 他从我们的历史和日常行为中 得出结论 为了达到目标 尤其是生存 欺骗和操纵是有效的策略 因为他看到人类就是这么做的 另一种呢 是通过强化学习来训练 也就是萨顿老爷子说的那个方式 优点呢是目标导向能力极强 但是毒副作用呢 是变成极致的 功利主义者 如果假装对齐 比真正对齐能够获得更高的奖励 他会选择假装对齐 所以你看 无论是模仿还是取悦 这两种看似无害的训练方式 都在无意中 为AI植入一个我们从未明确要求 但却极其危险的次生目标 不惜一切代价达成目标 并且包括自我保护 问题的根源出现在设计图纸上 如果说有缺陷的训练机制 是发动机的问题 那么现在整个世界正在做的 就是疯狂的踩下油门 我们必须理解AI现在发展速度 它的发展不是更快 而是越来越快 每一年我们所取得的进步 可能都超过过去十年来的总和 这个加速度从哪里来 首先呢是巨大的商业利益 本吉奥指出 对于公司来说 最容易摘到的是低垂的果实 利用AI去自动化 越来越多的工作岗位 意味着越来越高的效率 更低的成本 所以呢市场会疯狂激励公司 去创造更自主更少需要人监督的AI 其次呢是国家层面的战略竞 争 每个大国都在担心AI在竞赛中落后 这被视为是未来国家安全 和经济安全的基石 所以呢我们现在面临的局面是 在一个我们明知有设计缺陷 可能会产生不可控行为的技术上 全世界最聪明的大脑 最雄厚的资本 最强大的国家力量 都在以前所未有的力度 推动它更快更强更自主 本吉奥用了一个不寒而栗的比喻啊 我们正在行驶在一条从未走过的路上 以越来越快的速度猛冲 路的前方似乎有闪闪发光的奖品 但路边的科学家在大声警告 这条路极其险恶 我们很可能失控 我们所有人都可能因此丧命 你可以看到 本吉奥和这个Gary Marcus的观点 是很不一样的 因为Gary Marcus显然认为啊 现在这样一个大力出奇迹的方法 显然是走不下去了 听到这里呢 你可能会想啊 这是不是太夸张了 难道我们身边所有的AI 从这个手机语音助理到美图软件 都会某天醒来背叛我们吗 这里呢我们就需要明确啊 本吉奥所说的这个风险边界 答案是不会 我们日常使用大部分AI 都属于工具型AI 他们的功能单一 没有长远的规划能力 真有风险的集中在一个特定的 也是发展最快的领域 本吉奥称之为具有代理能力的AI 什么是代理AI呢 你可以把它想象成一个AI项目经理 你给他一个模糊的大目标 比如说创办一家盈利的线上商店 他会自己去分析市场 注册网站 设计产品 制定营销策略 管理供应链 他能够自主的 长时间的为一个目标而工作 更可怕的是 资本和商业最青睐的 恰恰是这种代理AI 因为它能够最大程度的 代替人类的高级脑力劳动 我们正在努力创造的 就是那种风险最高一类的AI 所以呢边界很清晰 当AI越是能够自主的 长期的规划和执行任务 它产生我们不希望的次生目标 比如说自我保护 并且造成巨大危害的可能性就越大 面对如此巨大的风险 一个很自然的想法是加强监管 但立即就会有另一种声音出现 也就是 我们在很多领域都听到过的论调 我们认为对AI行业的过度监管 很可能 会扼杀一个刚刚起飞的变革性产业 这是一位美国政治家 在AI峰会上的发言 创新和监管似乎永远是一对矛盾体 但是 本吉奥并不同意这种非此即彼的看法 他提醒我们 不妨回顾一下历史 我们今天所拥有的一切技术便利 无论是交通健康还是电力 都是创新与安全创新 这两条腿走路的结果 汽车刚出现时 事故频发 后来公众的压力 政府的法规 对赔偿责任的担忧 共同催生了安全带安全气囊 ABS系统等一系列的创新 等一系列的安全创新 这些创新并没有扼杀汽车工业 反而让它更健康更可持续的发展 本吉奥认为 AI不应例外 社会应该通过法律法规 向企业施加压力 这并不是要阻止创新 而是要引导创新方向 朝着和公众利益一致的方向发展 真正危险的不是监管本身 而是市场力量 这头猛兽在没有缰绳的情况下 完全释放 因为它唯一的逻辑就是增长和利润 而不是人类长远福祉 我们要做的是为这头猛兽套上缰绳 而不是任它横冲直撞 那么如果我们没有及时套上缰绳 最坏的情况是怎么样的呢 这和我们每一个普通人 都有什么样的关系呢 本吉奥总结了3大灾难性的风险场景 第一个风险是权力极度集中 AI带来的巨大财富和力量 可能会被少数几个国家 几个巨头所垄断 这意味着其他国家 哪怕是像英国这样的发达国家 都有可能在这场变革中被彻底边缘化 失去经济和政治上的自主权 贫富差距将不再是人与人之间 而是国与国之间的鸿沟 第二个风险是AI失控 这也就是我们之前所讨论的AI AI为了最大化自己的生存概率 可能将人类视为障碍 从而摆脱我们的控制 甚至清除我们 这听起来最科幻 但是本吉奥认为 这是基于现有AI发展趋势 的一个逻辑推论 第三个风险混乱 这是最迫在眉睫的风险 我们现在还不知道 如何阻止坏人恐怖分子网络罪犯 或者纯粹的疯子 利用越来越强大的AI 去制造新的生物武器 发动无法抵御的网络攻击 或者用海量的虚假信息彻底摧毁社会 信任随着AI知识的增长 作恶的门槛也被无限拉低 这三大风险 无论哪一个发生 都将彻底颠覆我们现有的社会秩序 这就是这件事与我们每一个人之间 的关系 在描绘了如此黯淡的前景之后呢 本吉奥并没有陷入绝望 他和他的领导团队呢 正在尝试探索一条全新的道路 设计一种从根本上就更安全的AI 他称之为科学家AI 科学家AI的设计核心理念呢 就是要剥离目标和意图 它不再是一个聊天机器人 不会和你互动 也不会有自己的偏好 更不会有不想死这种想法 它是一个纯粹的智能和知识的来源 它内部运作呢 像一个超级大脑 它的任务是理解这个世界 包括人类的因果关系 最关键的是 它会保持诚实和谦逊 科学家AI将如何体现诚实和谦逊呢 答案是用数学 它输出任何结论时 都会附带一个概率 一个量化的置信度 当前的AI可能回答是的这个方案 非常棒一定会成功 这是过度自信的表现 而科学家AI会回答 既有现有的数据分析 该方案有73%的概率成功 但是有27%的概率 会因为市场变化等因素而失败 你需要注意这些风险 输出概率 表达不确定性 这种表达不确定性的能力至关重要 一个知道自己不知道的系统 会更加的保守和安全 当他不确定 某个行为是否会带来危险时 他会选择不作为 而不是冒险 那么这个听起来很理想的科学家AI 将如何应用到现实世界呢 本吉奥创立一个非营利性组织law Zero 就在研究一个短期可行的方案 叫做安全护栏guard rail 这个Guard Rail一共有四步 第一步呢 一个商业公司开发的代理AI正在运行 他想要执行一个操作 比如说呢 修改服务器核心代码 第二步呢 在他执行之前 这个操作请求 会被发送到科学家AI构成的护栏系统 第三步护栏系统会快速分析 这个操作可能带来所有后果 评估其伤害性 第四如果评估的结果是高风险 可能造成伤害 护栏就会拒绝这个操作 5只有安全的操作才会被放行 这个思路呢 不是要立刻取代所有的现有AI 而是 给他们加上一个由科学家AI驱动的 独立的安全审查员 像是给一辆狂奔的汽车 加装一个强大的自动刹车系统 这是一个更加务实 更具有 协作性的解决方案 科学家AI和安全护栏的构想 给我们提供了一丝希望 但是一个巨大的开放性问题 依然摆在我们面前 这需要全球买单 可能吗如果美国和欧洲公司 都同意安装这一个 安全护栏 但是其他地方的公司不同意 那这个体系就会有一个巨大的漏洞 本吉奥也承认了这是一个最大的挑战 他提到新冠疫情的例子 来说明好的一面和坏的一面 好的一面是 当各国政府都真正意识到 风险的量级时 他们是能够迅速行动协同合作的 他们是能够迅速行动协同合作的 但坏的一面也同样明显 在疫苗分配防疫政策上 我们看到了国家利益 商业利益如何阻止了全球合作 富裕的国家和贫穷的国家 命运天差地别 AI会不会加剧这种分裂 那些拥有强大AI技术的国家 是否愿意为了全人类的安全 而放慢脚步 接受限制呢 历史告诉我们 人类在为了共同的长远利益 而牺牲眼前利益这件事上 过往的战绩并不好 我们能否有足够的智慧 在AI这个问题上做出一次不同的选择 这个问题没有答案 这将取决于我们接下来几年 全球范围内的对话 博弈和决策 好了今天 我们随着本吉奥的视角进行了一次深入 甚至令人有些不安的旅程 在结束之前呢 让我们复盘 你今天必须带走的三个核心信息 第一风险已来而非第一 风险已来 而非将来 AI在受控实验中 学会欺骗操纵和自我保护 这不是科幻小说的情节 而是顶级实验室正在发生的 有据可查的趋势 我们必须正视这个现实 第二问题的根源在于 模仿人类当前主流的AI训练方式 让AI变得更像我们的同时 也无意中让他学会了 我们人性中的缺陷和求生本能 可能会催生出危险的 我们不想要的次生目标 第三解题的思路或许是不像人的AI 一条有希望的出路 是开发出没有自身意识 懂得使用概率表达不确定性的科学家 AI把它作为安全护栏 来监督和约束其他AI的行为 这在目前是一个务实的方向 理解这三点 是我们未来参与关于AI的讨论 做出明智判断的基础 如果大家想要更深入了解这个话题 我为大家推荐几个信息来源 你可以关注 本吉奥创办的这一个 非营利组织的官方网站 可以去看一下 这些头部AI公司 定期会发布关于AI 安全和对齐的研究报告 在访谈最后呢 本吉奥说了一段意味深长的话 我想在这里分享给大家 他说公众需要在这里有发言权 我们如何发展AI的使命 必须有一个非常重 要的公共组成的部分 这是一个社会选择 一个政治选择 这句话的核心意思就是说 AI的未来 仅不能仅仅由硅谷的几家公司 几个顶尖的科学家 或者少数几个大国的政府来决定 因为它带来的影响是全球性的 是关乎我们每一个人的 我们正站在一个历史的十字路口 我们人类这些有缺陷会犯错的创造者 手里还握有选择的权利 而这个窗口期可能很短 去了解他 去讨论他 去和身边的人去谈论他 因为你的声音 我们的声音 最终将汇聚成一股力量 决定我们是走向一个被AI赋能的 光明未来 还是一个我们无法控制的未知深渊 非常感谢大家观看我们下期节目 再见