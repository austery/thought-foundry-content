欢迎收听《硅谷101》 我是泓君 Today we're announcing the Sora app powered by the all-new Sora 2 9月的最后一天Sora2发布 它可以把一句话 变成一段10秒的短视频 而好莱坞完全由AI创作的演员 Tilly Norwood 它诞生6个多月 就获得了6.5万的粉丝 I'm built on everything that came before me 她发自拍 代言品牌 却从来没有真实存在过 My jeans are binary 所以我们看到一个趋势 数字人它正在成为新的内容生产者 但是我们说在屏幕上 生成一段2D的视频 到一个3D的数字人 实现一个比较稳定的实时的互动 这中间其实还是 有很多的技术壁垒的 本期嘉宾柴金祥教授 他是2000年就已经进入了 卡内基梅隆大学去研究机器人 但是因为机器人 它的应用与落地都非常的困难 所以他们团队反而成为了 世界上最早用AI做3D动画的团队 在这18年的时间里 他几乎都在做同样的研究 从机器人到好莱坞的AI动画 到今天其实我们又在讨论一个 非常前沿的问题就是 3D数字人的模型 是不是又可以反过来去驱动机器人 所以这听起来 其实有一点点像一种轮回 但也是一种新的开始 这一集我们就来讨论一下 这轮的人工智能浪潮 到底是如何去改变 3D数字人这个行业与机器人领域的 而在好莱坞与游戏产业里 到底谁又是这项技术的受益者 今天跟我在一起的嘉宾 是魔珐科技的创始人与CEO 柴金祥教授 Hello 柴教授您好 Hello 大家好 我以前是在美国当教授 是2018年的时候回去 创立了魔珐科技 做了大概有7年多的时间 很高兴今天有机会 和大家分享一下 关于3D数字人 和巨神智能的一些观点 因为正好是在采访您前几天 就是硅谷大家都在关注的一个大事 就是Sora2放出来了 然后它做成了一个 类似于社交媒体的形式 就是我最近是被Sam Altman刷屏了 好像每个人都会拿它去做一段demo 包括我们前几天刚刚开了 《硅谷101》的科技大会 我们就生成了一段 让Sam Altman帮我们去宣传 我们大会的Sora2的视频 看起来它在屏幕里面的形象 这是一个比较数字人的形象 这个对你们的业务会有影响吗 我自己大概也去快速地体验一下 我觉得Sora2相比Sora1的话 进步是蛮大的 无论从画质也好 包括新的一种视频的那种形态 我觉得这里面一个核心的点 其实还是一个 文生视频的能力了 它主要的形态是以人为中心的 以前可能Sora1的时候 还是有风景 各种其他的一些 视频的内容的形态 它可以让视频里的人 做各种各样的事情 跳舞也好 坐在那跟你交流也好 吃东西也好等等等等 我也大概用了一下 第一个感觉的话 其实视频生成的 现在还是10秒钟的时间 还是没有跳出 被时间的限制文生视频 第二个点其实也特别特别重要 大家一直在说物理上的一致性 基本上大家看 刷屏的时候很多效果 其实还是蛮好的 但你真正自己做的时候 还是有很多瑕疵 太多了 他那个视频里面有皮卡丘 跟一个唐老鸭 在总统竞选的一段辩论 他可以在原视频上改 我就说把这个辩论变成一个 在《硅谷101》上关于AGI的辩论 主题是Alignment2025 是我们活动的主题 但你仔细去看的话 它后面的Alignment 那个字就是错的 就开始乱码了 是 还有一个点特别重要 对视频这样的内容创作者来说 你不仅想生成视频 它的背景里面如果有字错了 或者人物的有一致性的问题 那你最想做的 说我能不能edited一下 能把它变好 其实它现在这个能力也还没有 更重要的是 它现在是容许你用prompt 去生成这个视频 你没有能力去精细化地去控制 这个人的动作 表情等等等等 有一个点它是特别的好 它第一次让人看到了 如果有一个大模型 其实你可以让人做各种各样的动作 在视频这个层面上 那我们是在做3D数字人 这方面的研究包括产品 我们认为假如说最后我们像做人 人可以在交流 跳舞 可以在娱乐大家 最后的大模型会是什么形态 它的训练数据会是什么形态 你看到Sora2他又说 我用所有的视频作为输入 作为训练数据 我就可以做这个 最近Genie3出来了以后 其实是 它其实是3D的生成了 给你一种交互型的感觉是吧 但它不是人 它是关于这个场景相关的 到最后如果咱们做大模型 如果做人的话 我们会觉得 最后可能需要2D加3D的 所有的训练技术在一起 我们是希望你生成这个人的时候 不仅是没有这个10秒钟的限制 你还希望它没有瑕疵 物理上是准确的 你能控制它 最好它是实时的而且成本很低 因为我们自己 现在在做3D数字人的时候 除了我们3D的训练数据 其实我们也已经开始用 大量的一些视频的数据一起结合 作为训练数据来做 这个大模型的整个 3D数字人的表达力的模型 你看视频这个数据 如果你的模型做得好 其实还是有一定的生存能力的 以前我看Sora1的时候 就觉得好像不行 因为你觉得Sora1 都是场景式的生成 然后Sora2里面 它基本上因为你要让视频有生命力 就必须有一个主体 这个主体要么是人要么是动物 是的 然后它的生成看起来也比较立体 所以其实我简单总结一下 Sora2跟你们的整个的 3D数字人的生成 最大的区别是 它是文生视频 你们相当于是文生3D 然后这个3D 它可以是在VR领域里面进行展示的 比如说我戴着一个VR头盔 我可以360度地去看到这个人 同时这个3D 未来可不可以用于机器人 这个我们待会也可以去讨论一下 核心是这个区别 是 就是2D跟3D之间的区别 Sora2还是文生2D的视频 如果3D的话 你放在VR AI里面 它就跟我们现实生活中是一样的 那3D还有一个好处 它能让你控制 就像人一样 你让它怎么动就怎么动 但你2D因为在 我们叫像素这个层面 其实要对它进行精准人的 动作表情的控制 相对来说会比较难 因为我看见你们公司的数字人 其实也会用于这种屏幕的展示 有一点我可能很难区分的是 我知道很多公司的 那个展示屏的数字人 都是你们来做的 假设我进到一个展厅 看到一个屏幕上的 非常立体的数字人 它有动作声音表情 跟我看到Sam Altman 在一个视频里的数字人 就是我们说除了时长的这个区别 它在核心的技术上 它的区别是什么呢 一个区别 在屏幕上这个数字人 其实它担当的角色是 人跟机器之间交流的一个载体 那人跟机器交流的时候 其实你是实时互动的 我们是希望一般来说 端对端小于2秒钟 或1.5秒的延时才可以做 不能说像你生成一个视频 要等个10分钟 5分钟 这是不可能的 如果再往下走呢 屏幕里这个数字人 如果是在展厅里面 你希望所有的介绍 回答问题它的动作不能出错 如果有一点瑕疵 那你肯定觉得这个不行 所以这里面跟Sora2 有一个很大的区别 你不能有瑕疵 你在物理上是准确的 不能有瑕疵 物理上准确指的是 人他的表情动作 他有一致性 他不会突然出现说 我的胳膊突然衔接不上了 不能是这样子的 不能是说 大家以前可能看得比较多 当你用文生视频去做的时候 手指是个特别难的事情 经常手指会多出来一点 或者从这一帧的时候OK 可能到5秒钟的时候 忽然多了一个手指 或多出来了一截 或穿插也好 那你在实际的交互中 特别是一个人的时候 他是一个服务人员 或者他是个销售人员 跟你讲解产品的时候 你肯定是不希望这个体验很差的 他一定要准确 最后一个点 当你把这样的3D的数字人 部署在一个终端上的时候 你的成本不应该高 因为终端本来今天来说 它本身这个屏幕 可能也就一万人民币 如果你说生成这个视频 给它交互了20分钟 即使它能实时做 他说一年放在那 我也得花很多钱 那就没法做了 但今天从Sora的角度 或Sora2文生视频的角度来说 其实这个成本它是不能扩展的 它的成本是多高 用你们的这个成本是多高 为什么成本之间 会有这样的一个差距 我不一定能给一个具体的数字 但我可以告诉你一个量级 我们现在比语音合成的成本 比如说语音合成 现在大模型做的 我比它成本可能是几十分之一吧 这里面就很核心的一个点 就是2D跟3D之间的区别 其实3D对人类来说 其实我要去描述一个人 他的动作表情 其实他只要有几百个参数就行了 人的肌肉可能就是大几百块 你只要去控制一些肌肉就可以了 你下一步就是用3D的渲染 把它3D的内容变成视频 然后要3D的解算 因为不仅有人的表情动作 还有头发 衣服 我们需要有物理解算 这两个事情如果你用AI来做 其实我们最大的一个核心是说 你内容生成以后 你要用游戏的引擎 非常昂贵的GPU来做 当我们把这两个事情 用AI渲染跟解算做了 这就使得咱们的成本 主要就是生成 每一帧生成这几百个参数的成本 跟大模型生成Token 其实是一样的 所以它的成本就非常非常低 如果说你从文生视频 因为你是没有结构化信息 你全是像素 所以在这个事情上 使得你整个的推理 整个生产的过程 你的成本会非常非常高 所以我理解 现在你们之所以能把成本降下来 是因为你们有一个自己的端模型 可以这样理解吗 是 我们有一个怎么把文本 变成我们所谓的3D多模态 表达能力的一个模型 其实就是从文本生成语音 表情的参数 动作的参数 肢体比如手势的参数 我们把这些参数传到终端 终端就可以是Pad 或者是终端一个大屏上 我们用AI渲染 给AI解算把它变成视频 这个渲染其实因为我们用AI做的 所以它对于 终端算力的要求是极低的 我们现在都可以用一个 比如说国内这种几百块钱的芯片 比如说RK3566 瑞芯微的 我们在端上就可以跑了 比如说它要跟人做实时互动跟问答 这种还是在端模型上 还是说你后面 除了你自己的这个端模型 在表达的内容上 你会去接大模型 这是个很好的问题 我在跟你交流的过程中 首先我的眼睛看到你 我的耳朵听到你 这个我们叫做感知 大模型其实是有理解跟决策能力的 然后我们做那个事情 是把文本直接变成了语音跟我姿态 身体的动作 表情 手势 相当于一个人 他不仅仅只是有语音 也不仅仅只是有表情 或者表情比较木讷 他是动作 语言 手势都是一体 就是人与人之间的交互 现在你ChatGPT的话 你可以输入声音图片 它最后输出文字 我们做的是说 是文字到3D的多模态这个输出 比如说咱们俩要交流 就是人跟一个数字人 它其实需要两个模型现在 一个是就是像ChatGPT这样的 多模态到文本的模型 第二个是从文本 再到多模态的3D多模态的模型 就语音的输出 动作 表情 手势的输出 我们只有自己垂域的大模型 但我们也可以用 比如说现在国内 像千文的也好 DeepSeek的也好 或者豆包的模型也好 跟我们接在一起形成端对端的 人与数字人之间的这种 像人一样交流的一种体验 所以你们从多模态到文本是 可以用大模型来做 用大模型来做 然后从文本到多模态 就是你们自己的这个端模型 自己的我们叫做 文生3D多模态大模型 这已经是一个产品 可以发布星云平台 是的 这个产品我们会在10月份发布 现在我们是在测试testing mode 然后我们现在可能有几百个的 B端的企业客户在测试 也有付费了已经 我们预计时间会在两周后吧 发布我们的文生3D多模态这个模型 因为我们自己在做的过程 做了很长很长时间 从我回到20多年前 我读研究生开始 到今天我们花了很多的精力做 我们希望大家不要重复造轮子 能够把这个能力 提供给所有的开发者 能够把我们的能力 集成到他们的应用中去 了解 我自己觉得很有意思的一点就是 因为我知道你们公司 之前其实是在做3D数字人的 所以我理解 随着就是你们要发的这个星云平台 所以你们其实就是从一家 3D数字人的公司 到了一家3D数字人的平台公司 我这样的理解是对的吗 差不多 我觉得差不多 对 是的 之前我在NVIDIA的发布会上 Jensen Huang他会非常自豪地说 你看到的我不是真的我 然后他是一个自己的 虚拟的3D数字人跟大家介绍 比如说他后面有一个壁炉 然后他在前面介绍 渲染得非常非常的真实 他经常会用他自己的虚拟人 去讲他们的渲染能力有多强大 他们的显卡有多强大 他那个的成本大概有多少 这个成本其实蛮高的 但你问的问题特别特别好 因为他今天做的 其实还是视频的输出 通常来说造这个人 如果像老黄造成这样子的话 通常是需要研发团队 配合美术团队 一个team来做这个事情 按照业界它的成本 基本上在美国的话 找国内最顶尖的美术团队来做 基本上在10万美金左右 10万美金一个人 对 差不多 做到就是他们发布会的那个效果 逼真效果 然后再包含视频 它只包含把这个人造出来 视频如果要做 可能成本也会按秒算 这个其实在我们通常会讲 3D数字人其实还是在 专业级的内容生产 就还没有到每一个人都能生产 这样的3D数字人 能生成这样的视频 对 我记得其实每次去 那个游戏的展会 会感受非常明显 大家怎么去造那个3D数字人 以前我们是让一个演员 他会有很多的动作捕捉的团队 同时会有一个环形的摄像机 把你身体的每一个部位都拍 再来建模 再一步一步地把它还原出来 这是不是也经常是好莱坞使用 或者游戏公司使用到的一种方式 对 刚才讲到了专业级的造人 无论是3A级游戏公司 包括好莱坞的阿凡达 或者老黄这样的数字人 其实整体来说它是两部分的东西 第一部分 我要把这个人造出来 像你一般会我们叫扫描 你会有很多相机在那 你坐在那 你做各种表情 把你人的整个的几何 几何词的意思 就像雕塑雕你人的这个形象一样 然后再把人表面我们叫纹理 包括这个材质把它给重建出来 然后生成这个人 包括人本身的肌肉 我们用学术化的语言来说 叫建模跟绑定 第二步你要让它动起来 你看到就是身上穿一件动捕的衣服 上面有各种点 旁边有很大的一圈相机 能把你的动作捕捉下来 再去驱动刚才那个 照完那个人 再用渲染引擎 或者用离线的渲染的引擎输出视频 其实它整个过程 从建模绑定照这个人到动画 让这个人动起来 再到后面输出这个人的视频 整个过程都是 非常非常expensive的 这一套我理解是在 大模型之前的时代 好莱坞跟游戏公司 经常会用到的一种方式 现在有了模型 这一套在这两个行业里面 仍然是主流吗 还是说他们其实也在探索 我能不能用3D直接去生成人 其实这个问题特别特别好 这就说到这个行业的一个特性 其实3D内容本身的AI化 它取决于两个事情 一个叫高质量的数据 一个是AI的算法 是不是能对3D的内容做大模型 咱们今天看到了 所有的影视动画公司游戏公司 他们比较擅长的是做内容 把美术把3D的模型做得很好很逼真 但绝大部分这些公司 应该说AI的能力基本是缺乏的 因为它走的是跟我们现在 互联网公司跟科技公司两条线 它两条线之间的交叉是很少很少的 其实他们当然也希望拥抱AI 但是今天他们在这方面的能力 是欠缺的 AI公司当然算法能力很强 但它其实是没有数据的 但是如果说是3D的内容 首先得解决 你得有大量的3D的高质量的内容 你才能做大模型 所以这是他们的目标 但其实做起来 现在对他们来说 就是两个行业没有交叉 就是大模型公司 缺这些好莱坞制作公司的数据 然后这些好莱坞制作公司 缺AI的算法 我可以这样理解吗 是 基本上是这样 但我看也有一些公司 开始在尝试做了 你们其实我理解 在这一轮AI浪潮之前 你们做这个数字人 跟积累这样的数据时间也很久了 是的 我们是2018年成立的 当时最主要做的是 我们为B端的公司 比如说游戏公司 或者影视动画公司或者企业 像做3D的虚拟偶像的 为他们去提供3D的内容制作的 那时候其实做用AI加美术 一起来提升效率提升质量 然后在这个过程中 当然AI的能力也在提升 我觉得大家都要突破的一个点 就是3D内容的高质量数据 你没有数据 你AI算法再怎么厉害都没法干 对 从2018年到现在是2025年 你们大概积累了多少数据 可以透露吗 就像我们动画数据 我们前面是为企业服务了 后面我们就自己来做动画数据 我们现在如果像 3D高质量的动画数据 我们在1000多个小时左右 其实这个数据 可能跟视频的数据来讲 或者文本的数据来讲是小的 但是如果你考虑到它的成本 一条数据大概要多少的成本 大概比如说像我们现在要的 比如高质量的 人脸的动画 手势 表情这些 我们叫动画数据 一秒钟至少在1000人民币左右 在国内 这个一方面 当然你说成本 其实还有一个点 你得找到团队 有非常强的能力把质量做得这么高 所以整体来说 它的成本它本身的数据的量 其实是很难很难 在短时间内积累起来的 很有意思 所以数据是你能训练成这样的一个 模型的一个核心要素 我觉得数据是最最核心的 如果你没有数据 其他任何的研发都没法做 因为我们现在有的是3D的数据 刚才其实我们也讲 我们其实还有的是有视频的数据 视频的数据是哪里来 举个例子 你现在在网上看到的 有人在走路也好 有人在跟人交流也好 这个就是纯粹的视频的数据 它是没有3D信息的 但是另外3D的数据 其实我们现在开始把两者融合起来 去做模型的训练 OK 有意思 你为什么当时会选 3D数字人这个领域 我是2000年去卡梅读博士 当时在机器人研究所 我就做的是这个方向 当时我的博士论文就做的是 怎么能够创建一个 可交互的3D数字人 怎么用AI去做动画 我们那个团队 应该是世界上最早用AI做动画的 因为那时候也刚凑巧 运动捕捉刚刚在2000年的时候 你有了动画数据你就可以去做AI了 所以从那个时间点开始 我开始做3D动画3D数字人 2006年毕业去Texas A&M当教授 其实也一直在做这个方向 那时候做动画主要在 我们叫图形学 图形学专门是为影视动画公司 游戏公司这个行业服务的 所以那时候我们发了很多论文 全是关于3D数字人 跟3D动画相关的 创业其实2018年 也是做了同样的事情 所以这个事情应该说 坚持了有二十几年吧 当然在学校里做的 还是以研究为主了 然后我知道您的PHD的导师 是Jessica Hodgins 她其实主要是研究人形机器人 还有3D的数字动画的 而且她的博士生导师 是Marc Raibert 是Boston Dynamic的创始人 现在最有名的机器人公司 也是特别早的一家机器人公司 所以看起来整个的3D生成 它最开始的应用 就是在好莱坞领域的 我导师Jessica Hodgins 她CMU毕业 也是卡梅1989年博士毕业 Jessica以前是在博士的时候 她是做机器人的 那时候机器人也叫人形机器人 但只有一个脚 人形机器人只有一个脚 为什么只有一个脚 因为两个脚平衡太难了 其实你也看到过 现在人形机器人其实在几年前 两个脚的人形机器还会跌倒是吧 平衡是一个非常重要的问题 她那时候做的是 用物理运动控制的方式 动力学的方式 控制机器人走跑跳 单腿的是吧 她毕业了以后很奇怪 她进到的方向是到了图形学或动画 这两个方向大家可能觉得 好像没有联系 其实她当时想法是说 我在实际世界中能让机器人动起来 那我是不是用同样的方法 能让虚拟世界中的3D的数字人 能让它动画能够动起来 所以她是全世界第一个 用物理运动控制的方法 来做数字人的动画的 她到了 她是叫Georgia Tech做教授 她就说我们叫做 基于物理的仿真跟控制做动画 然后她是2000年的时候 又回到了卡梅当教授 但2000年动画数据慢慢有了 刚才讲的运动捕捉的出现 然后她又开始 我就是她在卡梅带的最早的博士 我们是那时候是最早用AI做动画 因为你有了数据了 然后她又做动画 做完了以后后来觉得 这个动画挺好的 用AI去做 反过来是不是还能去做Robotics 这个行业现在大家可能 知道的很多做Robotics 做很厉害的人 其实以前都是做动画的 比如说Sergey Levine 他是Pi的联合创始人 也是伯克利的教授 但你肯定都不知道 他是在斯坦福拿了博士学位 他在斯坦福读博士的时候 就是做动画的 他是用物理的方式 用运动控制动力学的方式来做动画 他毕业了以后说 我这个能做动画 我也能做机器人 他后来当教授的时候 就是开始做机器人 难怪Pi他们的核心思想是 要解决整个机器人的大脑的问题 就是软件层的问题 他就是希望通过模型层 来指挥机器人 我觉得这个跟他最开始 不是从硬件研究开始的 他是用机器人去做动画 听起来是一脉相承的 是的 的确是的 我再给你举一个例子 我还有一个很好的朋友 叫Karen Liu 她现在在斯坦福当教授 她是同时做Animation 做Robotics 她以前是在Georgia Tech 当教授 也是做Animation 做Robotics 我们还有其他那个时候 做Animation的人 后面都做Robotics 或Robotics and animation 这两个领域是非常非常相通的 因为都是3D 一个在虚拟世界一个在物理世界 你都是要驱动人 都是让机器人像现在这样的人一样 能够去驱动它 为什么那时候很多人做动画 因为动画这个事情 相对来说会比机器人会简单一些 因为机器人你是有个本体的 你搭个硬件就老半天 动画在三维的世界当中 你至少不需要搭这个硬件 第二点限之间其实受很多的限制 比如说重力或这个房间的限制 或者这个机器人硬件的限制 动画这个事情实际上没有限制 所以那时候其实就有 很多做物理的人开始做动画 做动画这方面也分成几派 一派即物理来做 那比较有名的Jessica肯定也是了 包括我们在UBC的 Michiel van de Panne 他是我博士的委员会的成员 他一直做Controller 做运动控制的 那时候做动画的中心其实也在卡梅 Karen Liu 她的导师叫Zoran Popović 她其实是从卡梅毕业的 那个时候做物理的 整个的动画这一拨人 其实人很少很少 那时候国内基本上没有人做动画 可能欧洲也没人做 其实在美国可能最主要就是 那么两三个组了 后面动画有一个大的飞跃 是从2000年开始的 那时候最主要的原因是 做动画的时候有数据了 运动捕捉把数据有了以后 这个事情其实是使得 慢慢慢慢大家说可以用AI做 那时候比较早 现在叫强化学习 我记得最早的做动画的论文 应该是2004年还是2005年 就用强化学习去做动画 其实虚拟世界跟实际世界 是差不多的 它唯一的区别就是 实际世界中有硬件的限制 但底层的方法其实很类似很类似 我们在讲小脑做的事情 动作的规划 运动的控制 这个流派到现在 动画的也有人在做 Robotics也有人在做 如果到现在最新东西出来 我们叫VLA 视觉 语言 动作模型 这是一个新的 这个讲的是大脑 但小脑这个事情 其实在动画跟机器人是蛮类似的 很有意思 我们之前聊很多好莱坞节目的时候 就有听众问我说 《硅谷101》 不应该是一档技术节目吗 然后你们在讨论AI的时候 不是应该多聊聊技术吗 我就说其实好莱坞是还蛮重要的 驱动整个的科技向前发展的一层 而且很多AI技术 它最开始用到的 就是在电影制作上 是 你们有没有想过 比如说把你们的整个的 3D数字人的产品 用到更多的好莱坞造人 比如说你们公司 只是用生成的这种方式 因为你们已经训练了自己的端模型 你是可以输出一个数字人的模型的 其实底层的技术你就有了 就可以去把一个不太动的演员 让他活动起来 我觉得这可能是对 整个好莱坞的一次降维打击 就是我们刚刚提到了很多 他们怎么去用AI技术 跟机器人的技术 去互相地促进跟发展的 现在听起来 那一套技术已经是一个 有一点点落实的技术 虽然说我们现在生成效果 还没有那么好 但是我觉得现在整个进展很惊艳了 是的 其实你刚才讲到一个 非常非常重要的点 当我们讲一项技术的时候 其实这里面有几个关键的点 一个是它的质量 好莱坞质量可能最高的 再往下是3A级游戏 再往下可能是我们在生活中有一些 如果说交互做的比较简单的 第二个就是我们在讲的成本 第三个事情其实又讲到了 它的应用场景在哪里 如果你要做好莱坞这个方向 它的高保真 它的质量 可能是特别特别重要 因为它可以等100个小时 或200个小时 或花更多的钱去等你的高质量 但是在实时交互里面 它可能是说 我今天我等不了你那么多时间 我就要马上能看到这个结果 能够给它交互 我在质量上 可能不一定要像好莱坞 那么高的质量 但是可以做好莱坞的IP的衍生 对 衍生品肯定可以 当然如果好莱坞要做 这方面也可以做 你需要更高质量的3D的数据 来做这个AI的大模型 这块东西在我们自己 在行进路径上 我们可能更先后的顺序 对于我们自己来说 可能先是到日常生活中 比如说交互 服务 陪伴 再到游戏 再到好莱坞 因为难度来说 其实好莱坞如果要做那个 那你的难度是很高很高 因为你的质量要很高 但能生产这个高质量数据的人 全世界可能就没几个 正好是在我们采访前几天 我看好莱坞他们已经造了一个 叫Tilly Norwood的女演员 这个女演员 她是完全由AI生成的 但是如果你去关注她的INS 她其实看起来跟真人就非常的像 她每天也会自己喝咖啡 也有自拍照 然后也有自己的生活 如果你只看她的社交媒体 你是很难区别 她是一个真实的演员 还是一个数字造出来的演员的 像这种技术以你们的平台 比如说开发者再接一个你们的API 可以做到吗 还是说它需要更多的 其他的方向的辅助 它现在的做法 其实还是我们PGC制作的方法 它还是2D 它其实只有文生视频 它是文生视频的方式 对 但你们如果来做降维打击 对 但是这里面有一个点是 在元宇宙比较火的过程中 其实美国有一个虚拟偶像 叫Lil Miquela 她在INS上 可能有个一两百万的粉丝 她可能比今天你刚才讲到的 Tilly Norwood的粉丝 要多很多很多 刚开始大家都不知道 她是个虚拟的偶像 所以我们今天在讲 这个方式其实在讲更多社媒运营 怎么能生产这种专业的内容 去打造一个人设 但这里面有一个 特别要注意的一个点 咱们今天这样文生视频的过程中 因为你不能保证 每次生成的视频是100%准确的 但它可以有时间 因为它如果要每天 发布一张图片的话 或一段视频的话 它每天可以我生成100段 从中挑一个就可以了 如果是在这样的情况下 如果你要去做Real-Time 是不可以的 那我们反过来再来看 我们现在这套技术 如果post到比如说 比如说她要开一个现场演唱会 当然是可以做的 文生视频有一个好处 因为它是基于视频来训练的 你觉得这个真实感好真 虽然可能有一些 物理上有的时候会不准确 我们现在采取了3D的方式 做的时候其实我们可能不是 像做的跟现实界的 那个真实感一模一样的 我们其实还是在于交互性上 了解 了解 就是它更有一个实时性 如果是要实时性 它在训练上它要最侧重的是什么呢 实时性里面 我觉得它的核心的点我们一直在讲 这个延迟 这个时间 比如说文本输入的延迟 是特别特别重要 如果你的时间要花 比如说10分钟1分钟或30秒 或者一秒钟 我们基本上我们现在做到 是500毫秒到600毫秒之间 如果说你是文生视频的 它就没有这个需求 等个5分钟可以 等个10分钟可以 还有一个你部署的时候也很重要 因为你是个实时交互的一个 用户在跟它沟通交流的时候 很有可能我同时有100个用户 或1000个用户1万个用户 给这个3D的AI数字人在做交互 如果说每一个人生成的内容 都会不一样给交互 如果你的成本很高 如果同时有1000个人 你要乘个1000倍这个成本 就是1000个用户 跟同一个数字人交互 它可能就是一个高并发的场景 高并发 是的 所以你在后面就是要去做 额外的服务器的部署的这一类 如果说你今天成本又很高 延时又很长 那根本是没有可能做了 对 问一个稍稍有一点敏感的问题 你可以选择答不答 你们现在整个的API接口放出去 我相信它肯定有一个 基础的接入成本 你觉得它是能赚钱的吗 这肯定的 因为我们在真正的 发布这个平台之前 因为我们已经有B端客户了 你国内做AI公司 你得商业上这个账得算得过来 除非你是字节 阿里 腾讯是吧 所以在这里面就很核心的一个点 也是我们在过去的半年里面 一个最大的突破吧 从我们的交互能力也好 API也好 半年前其实我们已经做好了 但是我们那时候成本很高 就是刚才讲到服务一个人的成本 当时要一张显卡 基本上是两三万 所以那时有很多很多的 B端的客户进来说 你这个东西能不能让我用一下 然后一问我们这个价格是这个 人家不用了 所以这个成本是怎么降下来的 因为我们是3D的内容 3D内容有一个特别特别重要的 所有的影视动画公司 游戏公司逃出去 一定得有渲染引擎跟解算的引擎 这个我太懂了 因为我们做视频 那个渲染真的是太耗时间了 对 如果你3D的内容 如果要支持实时 每一路一张显卡 就是为了做3D的渲染跟解算 那么我们用的 可能最好的引擎叫Unreal 但成本放在那 我们当时一直在想 如果说我没有把这个成本 这张显卡给干掉 我们再谈应用 真正地让大家都用 比如说在刚才讲的 展厅里的大屏也好 手机上也好 Pad上或电视机上根本不可能 其实我以前是觉得解决不了的 当然技术有的时候就是很奇怪 忽然想到了一个方法 我们非常幸运吧 把渲染跟解算用AI做好了 不需要渲染引擎 不需要渲染引擎所需要的显卡 我们可以在非常非常便宜的端上 可能一两百 两三百块钱的这个芯片上 我就可以做渲染跟解算 所以你用AI的方式 端到端的模型 解决了渲染的问题 渲染问题只是其中的一个 前面还有一个问题是说 从文本生成3D的动画表情 所需要的参数跟语音 其实你要通过渲染 跟解算的方式才能做的 以前需要显卡 实际上我们是两部分的 我们就要分成这个模型 第一部分解决的是文本到语音 到3D的表情动作姿态 第二部分 通过3D的动作表情 姿态的参数输入 让输出了它对应的实时的视频 这样使得我们成本 就比语音的生成的成本还低 那你觉得如果你能做到这件事情 把整个渲染的成本大幅降低 这次的整个的生成式AI技术 对Unreal这些游戏引擎公司 会是一次冲击吗 对NVIDIA它可能就是 一个左手跟右手的关系 它那一部分失去的卡 这部分补回来了 我认为对游戏公司来说 更多的是个机会 不一定对Unreal是个特别好的事情 但对游戏公司 因为每个游戏公司今天 特别你3A级游戏 你去run的时候 你一定是得云端有显卡 或者在手机上你得有算力比较强 不然手机也经常很热 你玩的时候 所以这个事情对于游戏公司来说 可能是一个好事 对于渲染跟解算 引擎所需要的 将来是不是用AI的方式 就可以把这个事情给解决掉 不需要引擎 你不需要体验卡就可以玩游戏了 那游戏肯定是到时候也开始无处不在 或者将来真的有元宇宙的时候 大家在这个虚拟世界中的时候 它的成本就会很低很低也许 那你觉得现在用AI的方式 去解决渲染的问题 它的解决质量 跟原有的游戏公司的渲染的质量 大概到了一个什么样的进度位 对于我们这个特定的应用场景 基本上是一样的 因为我们在做这个事情 你的输入的训练数据 就是用最高质量的游戏引擎渲染的 然后你只是有大量的数据 同时去逼近 跟原先用游戏引擎的效果而已 包括我们自己做了并列对比 就是左边是用游戏引擎 右边是用AI 没有一个人能看出来 左边跟右边之间的区别 那这个非常的颠覆 这个 对 这个对于我们来说 是个非常非常 特别是我们今天说 我们希望把3D数字人 放到每一个终端 每一个屏幕 它就是一个最最重要的事情 也许我们从技术上 我们说文生3D的 多模态的大模型我们能做 但是你真的要部署下去的时候 低成本这个事情 它就是一个最最重要的问题 对于游戏公司自己 他们也有很多的游戏人物 他们也需要大量的渲染 然后他们也需要很多的卡 对 它可以预渲染 其实还是需要卡 或者叫游戏引擎 就像我们生成训练数据一样 或者大家今天看到 比如说做具身智能机器人 你要采集很多数据 但采集完了训练完了以后 你就不需要 这个数据就在实时 比如说在机器人去抓东西的时候 你就只是基于模型去做而已 你就不需要这个数据了 所以他们还是模式不一样 他们对实时性的要求没有那么高 就是游戏公司的AI渲染的问题 游戏公司的AI渲染 我觉得将来也一定会走向 到最后实时玩游戏的时候 不一定要真正的游戏引擎 我认为最后可能是用大模型 这种端的能够针对某个特定游戏 某个特定应用场景的 这样的一个AI的渲染引擎 就可以做了 也许这个渲染引擎 会比咱们今天用游戏引擎 跟用解算渲染的方法可能更便宜 为什么这样我听下来觉得 Unreal跟Epic Games是 如果不赶紧更新是有点危险的 但前面训练数据 还是要从他们获得 但实时的时候就不一定需要他们 其实你看到Genie3是吧 他有很多训练数据 就是用游戏引擎生产出来的 当它生成视频的时候 它现在说我有3D的这种感觉 你可以跟它交互 这时候它其实不需要用新引擎了 你觉得现在如果 接入你们的这一部分开发者 他可以现在用这套3D数字人的平台 去做一些什么样的事情 它的场景有哪些呢 我觉得这是一个非常非常好的问题 我们真正在做这个平台的过程中 其实我们已经有很多客户合作过 或者是找过我们 那么我们自己会看到了 一个最最重要的应用 因为现在大家可能在国内 大家慢慢已经大模型了 将来有一天 可能大模型会出现在各种终端 在你的手机 平板 PC 或者在你的线下大屏 或者我们现在有很多小的全息屏 放在桌子上的陪伴的 假如说大模型再出现是终端了 你怎么跟它交互 你交互难道今天 还是在文本框里打字吗 或者用语音跟它说话 对着空气讲话一样 我现在觉得打字的效率太低了 就是很多时候 尤其是在一些突发跟实时的场景下 可能是我越来越依赖模型了 来不及 是的 是这样子 有一个非常有名的心理学家 1970年的时候有一个发现说 人与人之间的沟通交流 可能百分之五六十是视觉信号 语音信号占百分之三四十 语言这个信号可能占7%才 在交流的过程中 所以我们一个最大的应用场景 今天在后续的 就是我们想把我们的3D数字人 这个能跟用户交流的 通过语音 动作 表情姿态 就是让他到每一个屏幕上去 从非常大的这种显示屏 或展厅的屏幕 到电视机的屏幕上 再到电脑 手机 车机 到最后的迷你的全息屏 当你跟它交流的过程中 其实你就像跟人交流一样 有一个有意思的点是 大家现在看到大模型 它的交互从文本到文本的输出 文本到图片的输出 我觉得这个全部是在 ChatGPT发布的时候 我们可以说Open AI定义了 它的交互方式 但是其实我们看到 现在整个Open AI 也在升级这一套的交互方式 所以你觉得未来的交互方式 它可能就是一个数字人 对数字人的这样的一个交互 就是像人跟人之间的交互一样 而不应该是一个文本对语音 或者文本对视频的 这样的一个交互 是 我觉得将来咱们人跟机器 或人跟屏幕的交互 一定是人跟人之间的交互一样 今天ChatGPT刚才讲到了 他们其实做了多模态到文本的 也做了文本到视频 文本到图片 就差把这两个串起来了 但是它没有到文本到多模态表达 如果加上了多模态到文本 两边串起来 完全就像我们现实生活中一样 我看到你的表情 听到你的说话 我自己知道要说什么 同时我有表情动作声音 每个人都要渲染一个自己的模型吗 我觉得将来 每个人可能会有一个分身 至少我觉得企业来说 它肯定会有统一的一个形象 比如说我是做客户服务的 所有的用户 企业都知道这个是 这个企业的客户服务 或者它是一个品牌官 企业的虚拟人的一个形象 个人肯定也会有 个人我们叫个人的分身 大家跟你沟通交流 比如说泓君 你可能对某方面非常专业 你是个专家 你将来肯定会有一个 你自己的分身 你休息的时候 你同样可以跟别人去沟通交流 提供你的反馈等等等等 如果我们把你们现在的模型 放在一起综合去看这个能力的话 你觉得它最强的一点是什么 就比如说我们自己现在在看到 很多的2D的视频渲染的时候 我觉得最大的一个痛点 在前几年可能是这个口型对不上 它有一种虚假感 或者眼神它很空洞 你觉得现在你们的这个3D数字人 在应用到不同行业的时候 大家最大的痛点是什么 你们是怎么解决的 我觉得这个问题非常好 我们自己在跟客户沟通交流的时候 我们收到的反馈 永远是几个问题 第一个问题就是你提到的质量好吧 一个是它的语音 动作表情它的唇形是不是自然 是不是像真人一样 另外一个事情就是延时 我跟它聊的时候 是不是我说一句话 它等5秒钟才回来 我肯定没有这个耐心了 第三个事情 其实他们非常非常关心它的成本 如果非常非常昂贵 基本上从客户的角度 因为他是要考虑 这个投资回报率的 体验是提升了是吧 但是如果付出的成本很高 对他来说他也不一定愿意去做 所以我们从整个的核心的点来说 这三个问题是我们真正在落地 我们要规模化的过程中 我们叫三座大山吧 如果还有一个点可能是说 我们想让这个具身智能数字人 能够到多终端 无论是说大屏上 小屏上 手机 APP 支持并发 这里面可能牵涉到不同的操作系统 不同的芯片的算力 我们解决这个问题的方式 质量跟延时 最主要用的是我们的大模型 提升它的能力 质量这个事情 当然训练数据是最重要 如果你动画的训练数据 这个人3D人的质量很差 你就根本做不好 另外就是大模型本身的能力 你能不能通过文本去生成语音 表情 动作包括唇形 能不能让它匹配 同时我还能从文本里面 提取一些情绪 比如说他笑或者打个招呼 它能够自动生成这些关键的意图 包括你的TTS 语音生成是不是也是有情绪的 这个事情其实牵涉到 大模型怎么能够让它的能力 能够产生高质量的输出 对 像语音生成它也是有情绪的 这种你们怎么考虑 你们自己做这一块 还是说直接调用大模型的能力 我们这块是自己做 就是从文本生成语音 跟所有的表情动作姿态 是会自己做的 这一部分输出从文本到多模态输出 全是我们自己做的 你们之前的数据积累 我理解其实就是外形的数据 动作的数据 表情的数据可能都有 语音的数据也是有的 一样有的 对 一样有 我们自己其实是有一个工作室 里面可以采集各种的动作表情数据 同时我们就有自己的工作室 去录制这个最高质量的语音数据 因为有的时候比如说 我跟你交流的过程中 我的语音跟我的表情动作是匹配的 我同时要把这个数据同时录下来 而不是说我今天语音归语音 动作或表情 所以你录的时候 这个数据就是要语音跟唇形 是在一起的 那你怎么考虑哪些环节自己做 哪些环节接模型 因为我觉得现在整个语音的应用 包括模型在语音层的进化 已经做得非常好了 也有很多语音的开源模型 跟接口出来 是 我们现在对于文本 去生成语音 动作 表情这一部分 我们自己一定会自己做 因为我们现在这个特定的应用场景 其实在现在的 很多语音的场景是没有的 举个非常简单的例子 我们在销售陪练的时候 我需要有一个医生是某一种风格的 或者我今天在做陪伴的时候 他可能是一个某一种特定人设 我们叫小奶狗 比如说举个例子是吧 他的声音是特别了 所以你如果只是去调用别人的声音 没有去匹配他的人设 我们很多场景是做不了的 所以你们会针对一些特定的场景 去做一些特定的声音训练 比如说有哪些场景 我们现在做的分B端给C端了 B端里面可能会有不同 比如说我说客户服务的 他说话的声音 或者我们现在做教练 比如说我是一个销售的培训的教练 或者我是面试官 这些其实是B端都会有些不一样 有些可能要求专业 有些可能是稍微能够有一些严谨的 到C端可能更会多样一些 比如说今天是做陪伴的 可能会有卡通形象的陪伴 他的声音可能像小孩一样 萌萌的 对 所以我们在这一块 因为很多的现在已有的TTS 它的应用场景 没有像我们多样化 我们自己在整个做下来 一个感觉是说 如果你用通用的 其实很多时候 进到垂直场景是不行的 你一定要做自己 因为你不能等着他帮你来做 我们就像一套套模板一样 客户如果有文本大模型了以后 我们就直接调用我的整个文生的 多模态这部分就行了 或者客户说 我自己已经有语音了 我不需要你的语音也可以 你直接调用我的能力 你都可以 如果你什么都没有 那我都提供 对 我们刚刚其实聊的 很大的一部分都是在AI的技术 如何去做虚拟的世界 反过来 你们现在训练的这个模型 它可以去操控机器人 你有试过吗 我们试过 我们在做所有3D数字人 跟3D动画一个很好的点就是 它能够驱动机器人 比如说我是个3D数字人 能跟你交流 是吧 你问我的时候我能听懂你 然后我知道用什么样的语音 生成语音 动作 表情跟姿态 对一个机器人来说 我可以同样用这套东西去驱动它 机器人也可以做 实时的语音 动作 手势 只是现在机器人没有脸部 所以它表情表现不出来 它没有脸部的肌肉 对 因为现在机器人就是个蓝领 将来机器人如果做陪伴 如果是做白领的工作 比如说它是个销售它是个老师 它可能也需要表情 首先我知道这个机器人 比如说我跟你交流的时候 我的手势应该怎么动 表情应该怎么动 我的姿态应该怎么动 下一步就是说 我们叫做用模仿学习 就像NVIDIA那种方法 我能够去做仿真 直接能够拿驱动跟你做交流 太有意思了 然后你们现在在真实的应用中 就比如说 你现在用你的这个模型的数据 接到机器人上去 你觉得对他的哪一部分的提高最大 因为我们可能说 机器人是没有表情的对不对 然后他的手势是可以动的 是 你可以同时驱动手跟脚吗 还是只能驱动上半身 我们可以 你们可以同时驱动手跟脚 告诉你一个特别有意思的事情 国内现在比如说我们合作的过程中 因为我们生成的是 从脸 手包括腿部的动作其实全有 现在很多机器人公司 其实他建这个机器人的时候 其实他的平衡还没有做那么好 就使得我给了他这个动作 他可能也是用强化学习 再加simulation去做 因为我们提供了API给他们了以后 他们在这方面可能 如果做得特别好的 可能也能够驱动起来 因为上身其实有很多的动作 就是它有一定的泛化性 但其实这个事情 我觉得其实没有那么的难 就像我们爬楼梯也一样 我的动作能够通过我们的能力 能够生产出来 我就在simulation环境里面 加上强化学习 让它能够去复制这个动作 一点问题都没有 所以机器人的平衡问题 是我们收集的这些3D人的3D数据 它只是动作姿态的 但是它并没有力的反馈 然后你只要加入到力这一点 就可能会出现平衡的问题 摔跤的问题 我觉得你好专业 没有 没有 我在尝试理解 这里面是两个核心的点 就是说你要驱动一个机器人 一个叫做运动学 我们叫Kinematics 还有一个叫Dynamics 叫动力学 第一步比如说我要抓一个杯子 我首先知道我抓杯子 手应该它的pose 它的姿态应该怎么动去抓它 第二个事情 动力学其实解决的是 我要用多少的力 能够按照我想的那个路径 那个姿态去抓这个事情 所以我们先做Kinematics 大家很多时候叫做运动规划 做模型planning 也是做这个事情的 一般来说两者之间可以结合起来 所以我理解其实机器人公司 在寻求合作的时候 它两个都是需要的 第一个可能他们自己现在 如果从零起步 做一家机器人公司 它最缺的就是数据 然后你们有数据的模型 就已经训练好了 因为我们聚焦是交互 从我们平台的角度来说下一步 我们今年吧 应该会发布一个3D动作的大模型 比如说它可以爬楼梯 或者你今天直接给它说 你往前走五步 趴在地上然后再爬起来再跑 它就能自动能生产出来 3D的动作的数据 这个动作数据当然可以用来做 机器人整个的训练了 因为它今天要去捕捉 其实这个数据有的时候 如果我们有这样的 动作大模型了以后 它也不一定要捕捉 因为你捕捉 也是获取这样的数据而已 了解 因为我看波士顿动力的机器人 就是这种爬楼梯旋转搬箱子 都已经做得非常的成熟了 但是他们其实 我理解他是在大模型公司 还没有出来之前 这家公司在机器人领域 就已经研发了很多年 他用了各种的方式去做 你现在其实是用AI的模型 再去驱动的这一套 就是爬楼梯的动作 你觉得这两者之间 我们看到机器人表现的 是同样的技术爬楼梯 但是它的技术路径是完全不一样的 还是说相似的 我觉得你刚才讲到一个 很有意思的点 就是波士顿动力 它以前能做爬楼梯 但是有一个点我想指出是说 它以前爬楼梯的时候 它的泛化能力并不强 比如说你给它不同的楼梯 高度是不一样的 它不一定每种楼梯都能爬得很好 对 因为它给你秀demo的时候 永远给你秀的是 同一个楼梯 对 所以这里面有一个特别重要的 我们叫泛化性 我相信今天做人形机器人 或做机器人的大家都会讲到 我的数据生成了以后 我能不能做我数据里做不到的事情 这个里面就非常重要 就是说爬楼梯吧 每个楼梯其实有一个高度 有多少层楼梯 包括楼梯本身的摩擦力是多少 摩擦系数有多少 这个其实都是一些泛化的参数 今天你有没有能力 今天说给你任何一个楼梯 你都能爬得特别稳 另外是不是你能给我说 我能控制它 爬得快一点爬得慢一点 这个事情其实在今天来说 我觉得还是一个难的问题 其实也是来自于数据 假设说你今天所有的数据 比如爬各种楼梯的高度的 不同的快慢的 我今天去做这个事情 其实也没有那么的难 我们如果现在做了一个核心的点 我们说在虚拟世界里面 包括我们后面要发布的 3D动画的大模型 其实也是要来生产出动画的数据 让它爬楼梯 所有东西都见过了 太有意思了 所以你们其实也是在做 机器人动作的泛化性 你看一种是机器人动作的泛化性 我们也在做数字人动作的泛化性 其实这两个是一样的 你觉得用AI的方式去做机器人 就是AI跟机器人 它又经过了哪些变迁呢 就像你说的 可能最开始大家还没有想到 要用AI的方式去做机器人 后来又开始在AI中 加入了强化学习去做机器人 最早的时候 AI机器人这个方向很难很难 特别是对于人形机器人 我们叫biped 就是两只脚要 它最难的问题是平衡 另外一个问题就是抓取 那个时候做人形机器人 最主要是在日本 有一段时间很火 本田 叫ASIMO 那时候工程师要调一个 它走路的动作 你都不知道后面有多少工程师 在调这个参数 我们叫控制器 怎么用这个力去控制它 让它在不同的表面上 能够像人一样走路 这个参数而且也没那么稳定 如果你把平面稍微改一改 可能就跌倒了 Learning的东西 AI的东西其实是不多的 那时候就做控制器 所以早期机器人的发展 它其实主要是控制 就是为了让机器人不跌倒 不跌倒 平衡 如果它能走不跌倒 太了不起了那时候 然后后面大家说光这么走不行 你能不能就是有一定的泛化能力 我走路的时候能不能在不同的平面 不同的表面 或者你的走路的速度都能够不一样 这个事情如果你没有用AI的方法做 你基本上不可能做的 你觉得现在的机器人 跟你当时学机器人的时候 20年前进化有多少 我觉得进化还是蛮大的 就是以前让一个机器人 有两只脚的能够跑 走跑跳觉得这个事好难好难 但你其实看看 看到国内很多做人形机器人公司 运动会拿个遥控器控制它 还是能走的 跑也能跑 大部分的问题是能解决了 这个事情在20年前基本不可能 它的balance平衡太难了 但它是通过远程操控的方式解决的 对 即使通过远程操控的方式 它还是要解决我说的 刚才动力学控制那个问题 我觉得控制这个事情 如果你有视觉 语言 动作大模型 它就不需要拿个遥控器了 但我们小脑控制这个事情 让它走不跌倒 这个事情其实蛮难的 所以但是现在进步就是说 一方面是数据 另一方面就是强化学习 simulation这样的环境 像NVIDIA 这就是技术的进步 能力开放出来了以后 大家都在这个 simulation环境都能去做 你发觉其实也没有那么的难了 是的 那机器人走路不摔倒 这个是现在一个做机器人的公司 普遍能达到的水平 还是说只有头部几家公司能达到 对于稍微OK的团队 我觉得是没什么问题的 就已经都解决了 但是有一个点就是 你的泛化到底有多强 你指的走路不摔倒 是在他们日常的训练中 特定的场景走路不摔倒 如果新的场景 保不定你还是会摔倒 那你觉得现在这个世界上 能让机器人走路不摔倒 在部分场景中实现的公司有多少 如果说完全不摔倒 在新的应用场景其实蛮难的 我不知道现在有吗 能够做到泛化能力很强 它能很鲁棒 不跌倒 其实基于我的认知来说 可能现在还没有吧 如果有那我可能要学习一下我觉得 真的 就爬楼梯这么个事情 我今天就可以设置任何爬楼梯的 它不一定以前见过 我不相信今天世界上有任何一个 人性机器人公司能够做到 所以我们其实只是解决了 在平面走的问题 特定场景平面走的问题 应该叫特定的场景下 包括你现在看还有一个事情 是grasping 就抓东西 抓取在我们那个时候 比较早的时候用人形手去抓东西 其实不多的 包括机器人在整个的业界你去看 很多时候它是个吸盘 毕竟这个东西我吸它就行了 但你现在可能很多人可以做抓取 像人形手一样 比如说拿筷子夹东西 这个事情其实也是一个 非常非常难的问题 还是要大脑加小脑的 大脑首先得看到这个东西 我应该怎么去抓它 到后面用小脑真正去控制 你的筷子去夹它 我觉得这个事情也非常非常难 今天你现在看到的都是demo而已 我认为真正在一个 特定的应用场景下 稍微有一点点泛化性 但是如果把它再往外 外延一些泛化 今天来说还是很难 我们10月5号的这个活动您也去了 然后我们现场其实是有机器人 给大家开可乐的 头一天他们在彩排的时候 中间我就放了一瓶可乐上去 我说我也要试这个 放完以后他说 你得把可乐转一个方向 他说那个环要对着它的手指 如果你不把环对准的话 那个机器人它的手的灵活度 还很难去把它转一个方向打开 是 真的 你这个还是在一个特定的环境 它已经布置好了 你更不要说它进入家庭 那在这个家庭的环境中 更是各种各样 灯光包括受限制那就更难 所以我觉得这条路 只是说大家现在看到了 大脑我们叫VLA这个模型 有可能可以去解决这个问题 但是不是100%能解决 其实也没有人知道 如果可以解决 到底要多少的数据 才能达到一定的泛化能力 一定的鲁棒性去解决 大家只是觉得相信Scaling Laws 相信大模型将会有一天能够解决 但这里面的挑战是很大很大的 是 所以从你的角度 你觉得现在世界上 最好的机器人公司是谁 为什么 我觉得是这样 做机器人它有不同的流派 有做本体的 比如说有做硬件的 有做小脑的 也有做大脑的 我自己觉得还说不到有多好 因为多好有不同的定义 你今天在做研究 你这条路已经有一些 promising results 还是说你今天已经落地了 也许你今天这条路 感觉看上去很有希望 因为最后发觉你这条路是死的 你暂时的领先并不是最终的领先 你像现在国内其实有不同的流派 像宇树可能做的是机器人本体加小脑 他不做大脑 大脑是指什么 大脑就是说现在做VOA 叠衣服这种 小脑就是说你让爬个楼梯 跳个舞 跑个步 在这一块里面有做本体的 有做控制的 就是控制我们叫小脑 就是运动规划 运动控制 动力学整个这一套 还有做大脑的 我觉得至少我现在还没有 已经看到了曙光了 可能我比较悲观吧 它可能也会像任何其他领域 比如说无论是VR AR也好 还是AI领域也会有起起落落 因为这是Robotics第一波浪潮 无人驾驶其实也有起起落落 但从长期的角度来说 那肯定是前景光明 从短期来说可能还是有很多挑战 你觉得机器人模型 要达到GPT-3时刻需要多久 这个其实我没有 那么强的经验和认知吧 我觉得今天的数据要泛化能力 至少要很长一段时间 今天我看到的这些 还没有让我非常清晰地 能够判断两年或者三年 但我觉得10年 可能有希望 这个问题可能能解决 10年是很长的时间了 所以这也是为什么 你们公司在做的时候 其实你没有直接去选 我去切机器人这个赛道 反而是说我们把3D跟机器人的 交叉的领域 数字世界里的3D我们来做一做 如果我让3D数字人在数字世界里 在VR空间 或在屏幕上能跟人 像人与人之间交流 也是在这个数字世界里 能够抓取东西 能走路能爬楼梯 那本身在数字世界已经很有用了 它已经可以有这个 Real-world application了 也可以有商业的落地的 反过来如果这些做了以后 作为做Robotics来说 也是一个很有价值的 因为我们在讲小脑这个事情的时候 你的控制运动学 动力学 你先得知道怎么动 然后再去决定用强化学 是用怎么样的力 让它能够去做这个事情 我觉得做research它是一个 今天Robotics是一个非常好的方向 因为有太多东西可以尝试了 如果从商业化的角度来说 我自己觉得其实挑战蛮多的 如果你要商业化落地 至少从人形机器人的话 我觉得白领可能会比蓝领更快 是是 你刚刚提到在数字世界里面 它可能也会涉及到一些力的反馈 会有 比如说好莱坞动画里面 我们把一个苹果 一个南瓜甩过去 它变成一个南瓜酱 它怎么炸开 那个就是 就是物理 其实物理还有一个点比如说 你是个数字人或3D的角色 你从二层楼跳到一层楼 你跳下去的时候 你跟地面之间的整个的反馈 怎么滚动一定要满足物理 我们这个大模型的动画 如果生成了以后 它本身就可以用物理的方式 让它在虚拟世界中去仿真它 同样的方式 其实也可以在虚拟世界中 用强化学习的方式 去生成这个控制器 同样的方式 我可以在实际世界中这么做 本身的逻辑是很通的 但我有一个问题 如果我们把动画世界里的数据 收集来学习 我知道一个人 从楼梯上掉下去以后 怎么弹怎么滚的 但是我不知道为什么 我也不知道这个里面有多少力 但是就是看见了这些现象 然后用这些现象跟这些数据 去训练出一个大模型 它能反馈能模拟 我们还是不知道力是多少 就是我们说规模化法则 如果跟所有的大模型都是黑盒模型 但是我们再把这个场景 拉回到现实里面来 我们要去让一个机器人 砸到一个东西或者拿到一个东西 这个力我不知道现在在现实数据中 是不是就是要反复调控跟算出来的 所以它就必须有这个力的数据 我觉得人他真正在现实生活中 我们去举一个杯子 我们也不需要去计算它的力 这就是我们的一个经验习惯 就是我们有这样的一个感知就好了 这是我总体的意思 大概就是过去整个机器人 它的研究包括它的力学的反馈 还是在用白盒的方式去做 但是整个模型在用黑盒 跟一套更加经验主义的方式去做 就是为什么我们觉得 现在已有的方式上做的时候 到真正你要泛化到一个实际世界中 去抓取各种东西的时候 它的挑战会非常非常大 因为它的泛化里面的东西太多 就是我们今天讲整个的过程中 你在学力的控制的函数 以前的方式是要自己算的吗 或者一个一个的自己 对 现在就是用强化学习的方式 现在用强化学习 就是大家不需要知道为什么 我只要有足够多的数据跟它reward 它就慢慢慢慢就能够做 但这个问题是说 我抓杯子只是我很小的一个例子 这个世界上有多少 所以我就说这个事情就是希望 将来有一个基座的大模型 我足够多的数据了以后 大家能够去一个特定的场景 我能去调优这个模型 能够在这个环境里面把它 慢慢把它做好 但其实是很难 你像我们学会抓东西 我们学会走路跑步 我们花了多长时间 是的 我自己听下来 就是我对机器人领域 这一波最大的进展 我是觉得整个研究的方式 它从白盒模型的研究 变成了黑盒模型的研究 从我们必须知道每一个细节 它的受力点是多少 靠这种计算跟一个一个细节 调配的方式的研究 变成了我们一个端到端的模型输出 我们不知道里面是怎么运作的 但是它可以 我们在讲强化学习的时候 就在讲这个事情 这是一个最最大的点 就是以前的时候 那套东西就是更多是显示的 比如说我要去抓这个东西 我大概知道要什么力 预先算好 不是说我在这个过程中 我根据实际世界的情况 包括表面第一次抓的时候的感受 我能够持续去调整 它一定是Reward Function​​在后面 这条路来说一定是打开了 以前对机器人来说 觉得怎么做 感觉好像也没有希望那种感觉 好难 那种方法一定是 不能扩大规模的 但今天其实大家为什么觉得 虽然我作为一个外行来说 我自己会觉得很难 你说是3年还是5年 但是从长期的角度来说是有希望的 这套方法它在大语言模型也好 在其他方向上也好 其实已经展示了它的一个能力 如果在机器人这个方向上 如果你有足够多的数据 是有可能能解决这个问题的 它的天花板就是大家能看到 是有可能有一天能做到 我们真的像大家想象的一样 机器人能干各种各样的活 在各种复杂的场景里面 中间是不是在这个过程中 会遇到大家想象不到的问题 还会遇到低谷 其实我不知道 看起来现在是一个 大家刚找到一条新的路的 那个兴奋感的时候 但是它的结果是不是能收敛 是不是一直能看到效果 是 这可能就是中间起起落落的过程 是的 是的 好 谢谢柴教授 好 谢谢 好的 这就是我们今天的节目 很可惜 就今天我们在录制的时候 是播客不是视频 所以其实很难去实时地展示 跟感受一下 这个3D数字人的效果 也希望未来我们视频 可以出一个呈现的数字人 给大家看看感受一下 所以如果大家对 比如说像3D的AI数字人 到底可以用于哪些好玩的领域 去做一些哪些好玩的事情 有更多的想法 欢迎给我们写评论多多交流 我们的博客听众 可以在小宇宙 苹果博客 Spotify上来收听订阅我们 如果大家想看字幕版 也可以在YouTube 或者bilibili上来订阅我们 未来我们也会推出 我们的newsletter 在硅谷举办一些线下活动 如果大家对我们的线下活动感兴趣 可以在我们的Shownotes里面 订阅我们的newsletter 我是泓君 感谢大家的收听