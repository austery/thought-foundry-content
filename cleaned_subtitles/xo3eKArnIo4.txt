The Pandora box of technology is already open. The reality is that kids are growing up with AI and they're talking to systems that are saying yes, that are agreeing to them, that are placating them because that's what these systems are trained to do. At the same time, it's being used for really horrible things. I think there's a real there's a real worry. Everything from just spam and AI slop from that to highly targeted, highly contextual fishing campaigns to victimizing people by creating non-consensual intimate imagery. Someone needs to be able to stop those horrible things from happening so innovation can continue because if you don't what's going to end up happening is that there's going to be regulation. They're going to have to stop and fix things and before they can innovate and it slows down ability to innovate as a society. And so what I want to do is be able to we should be able to be the ones that are stopping those horrible things and innovating on that and allow everyone else to innovate incredibly quickly. I'm Glenn Wise. I'm the co-founder CEO of Cinder, a central platform for trust and safety operations. You can think of Cinder as the club bouncer for the internet. Our customers want to be able to set rules on what they allow on their platforms and what they don't allow. And so Cinder is the system that they use to enforce those rules across all of their users. We raised $14 million from investors such as Y Cominator and Excel. Our mission is to make the internet a safer place. So growing up in New Jersey, being 6 or 7 years old during 911, that was such an impactful sort of moment in my life and my community. And when you grow up with that in the backdrop, any opportunity to be part of a greater mission was really important to me. So then when I went to college and I realized that you can actually go work at the NSA or the CIA or the FBI on these exact issues of making sure that never happens again. That's the the only thing I wanted to do. And so that inevitably led me to join government being able to work on counterterrorism issues which inevitably led to me doing the same type of work at at Facebook on a threat intelligence team. Facebook started investing heavily in threat intelligence before the harm became prevalent on platform. Being on a red team, I think, is one of the most fun jobs that someone could have and someone can do because you get to, you know, try to break things. This is something that I instill on my team today. It's like, how do you have that adversarial mindset, right? There's going to be people on the other side of that trying to stop you and you have to acknowledge that and be able to think like that. At the time, I was talking to so many other companies that were really struggling with getting a grasp on the abuse occurring on their platform. And so, I thought that this would be a really interesting thing to start. I was thinking about it for a long time to the point where, you know, it's all I thought about outside of work. Part of my hesitation of founding Cinder that I just thought I wasn't ready, right? I felt I didn't have the right experience. My initial thought at the time was to go to a smaller company and help them build, you know, a platform internally. So, I ended up just reaching out to a bunch of people. And I realized that there were a lot of companies to choose from to build something internally that at that point you should just build it once centrally and then give it to all these companies. All right. It just like made so much sense as a business. That's inevitably why I made the decision to to found it. And I think that it's important. Someone needs to be able to stop those horrible things from happening so innovation can continue. And so what I want to do is be able to we should be able to be the ones that are stopping those horrible things and innovating on that allow everyone else to innovate incredibly quickly and deploying new things and building new things without worrying about this underbelly of the internet and these underbelly of of harmful people. I applied to Y Comer thinking that nothing would happen, you know, literally an hour or two before the deadline was due. Uh ended up getting a call from Michael Cyel and Michael told me that he thought the idea was great. He's really excited about it. He wants us to he wants me to do it, but I need to find a co-founder. And I told him that there were people that I worked with at Facebook that I thought were really amazing people that I really wanted to work with, but it's going to be impossible for me to get them to to leave Facebook and to actually join starting this. And fast forward 3 months later, had a really great team of people that I was really respected. Um, and it was amazing that I mean still is amazing that I get to work with them every day. Bring all these people on and and work with them was a really special moment for me. This year alone with Cinder, our customers have submitted over 100,000 reports. The National Center for Missing and Exploited Children. That alone is a pretty insane number, but it's also just like scratching the surface of all of the really bad things. We see abuse today that 4 years ago only a nation state could do. And today, a teenager with a laptop is able to do it. As a society, we need systems that can combat this abuse before it turns into a total hellscape. When we set out to build Cinder, we knew that we were going to build a platform and that is really challenging and I would encourage anyone to not build a platform from the beginning because you have to build so many things on top of it in order for it just to work, right? You have to be able to integrate all these signals. You have to be able to make it highly configurable and customizable. You have to be able for customers to represent their own unique data and their own unique workflow within it. So we did a lot of work initially to support all these different content types to support all these different types of workflows that takes a long time. We set out to build what was effectively a threat intel platform for trust and safety. And we thought this was a great idea because we saw that pain in previous jobs and we were going to go solve it and bring it to everyone else. So we spent all this time building this platform and then we went out to show people and they effectively told us that this was interesting but they did not want it and what they really needed was a way to handle their overall operations and so we invested all this time uh in me and Declan one of the co-founders spent so much time building this thread intel platform to be told that they wanted something else and that's like a huge learning for us right and that that brings us to this idea of really focusing ing on what the core customer problem is and get that problem down really tight and then go out and build. And my focus from like the beginning of my career has been on how do you stop people from taking advantage and and abusing other systems or or people. And so being able to empathize with the customer was really key, right? Even when we had nothing built, someone being able to listen to them and understand what they were going through and provide suggestions on how to fix it and then a few weeks later come with a product. It solved a real problem. So a really prominent harm facing Gai customers today is basically non-consensual intimate imagery NCI. We are seeing harms become more and more complex as time goes on. At Cinder, we have a framework called the decision spectrum. And almost every problem can be placed on the spectrum in some way where on the left side of the spectrum is a really something really simple, like a really simple decision of yeah, this image is nudity or this uh chat message is fraud, right? Like a really simple identification of a single piece of content or a single event. And on the other side, you're investigating some, you know, a really complex nation state or really complex network or an adversary that is advanced in trying to hide their behavior. There are way too many things to review and prioritizing is really difficult because everything is a heart, right? Everything is hurting someone else. And that burnout is real. and you see people burning out the industry all the time because they almost feel like there's they're facing an uphill battle of targeting this. So I think our team, you know, we we definitely see some of that, but for us, everyone at our company is deeply motivated by the mission and everyone wants to inevitably have a world where the internet and innovation is is safe and can be used by anyone. And our founding team had direct experience in building these systems at many different places. And we experienced that harm firsthand, right? We experienced that painoint firsthand. I think in this space, the only way that you're able to build an effective product is by having that experience, but also having that attraction to the mission and having that attraction to the outcome and having that purpose behind it all because the the work is so difficult. It is very complex and very nuanced that you have to have that that drive. When you hear stories from our teams of something that we took down or something that we helped stop or an abuse that we caught that allows us to go on, right, and be really motive for the next day. And so I think you can it's you you can easily get bogged down in the harm, right? You can easily look at all of the really horrible things happening across the internet and and be really dejected from it, but know that there's a path to being able to come at it. and someone needs to combat it. And if it's not us, then you know who else is that going to be?