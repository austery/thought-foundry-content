[Music] Hi everybody. I'm Nicolola Tangan, the CEO of the Norwegian Sovereign Wealth Fund. And today I'm in really good company with Sir David Spiegel. Well, I would say he's the world best statistician and for sure the best communicator of risk that I've ever seen. Written lots of fantastic books and is particularly known for making statistics, which is uh difficult uh really accessible for most people. So big thanks for joining us. So David,
>> no great great pleasure to be here.
>> Having worked with risks, what what's the main thing that you have learned about human psychology?
>> Well, first of all that I'm not a psychologist. So you know I am a statistician but I I have done my best to learn from psychologists that I have worked with and I suppose just from observing how people react to un risk and uncertainty. I tend to think of the broader idea of uncertainty rather than just risk. everything to do with not knowing about what might happen in the future or even not knowing what's going on at the moment or what's happened in the past. Um, all these things we are uncertain about. Some of them, you know, usually things do have an upside and a downside and so they could be considered risks depending on how they occur. But I think, you know, what I've learned is that uh people, you know, have to live with uncertainty. When you ask people, they say, "Oh, I don't like uncertainty." And then when you ask,
>> but some but some people like it, right?
>> Well, some people like it. Some people are a bit more bold than others. But the point is that when you actually then go a bit further and say, well, do you want to know what you're going to get for Christmas? Do you want to know how a match is going to end? You know, if you've recorded it or something, do you want to know, you know, do you jump just jump to the end of your uh, you know, series on TV to see the last episode and see what happens? Or also the thing I ask is, do you want to know when you're going to die if I could tell you? And no, they all say no. Or some would qu some would like to know when they're going to die. Some are so in a way uncertainty averse uh that they really like to have everything planned. But most people realize that you got to live with uncertainty and think of a life without uncertainty without some risk. Think how awful that would be.
>> What are the people who hate risks the most? Oh, there are some there are some people I think who are very cautious who uh would like to have everything planned out uh who want to feel that they can control all contingencies and have mapped out the possibilities and of course this is impossible. Um and this is you know when I when I talk to audiences when I say the first thing is not not only that we have to face uncertainty but we have to face actually deeper uncertainty that we can't even list the possibilities of what might happen to us in the future. we have to deal with that you know you know cloud of unknowing um and that's the part of human life and uh I'm interested in strategies that people use personally to to deal with that
>> how is it linked with the big five so my impression is that introverts like risks less uh Americans like it more uh old people perhaps less than young people just how do you how does that
>> yeah I haven't actually looked at that I mean people will have looked at that because people have studied risk and proness from risk aversion. What they found is that there's not a single characteristic. I think this is why it's not part of the big five a single risk characteristic in people's personalities. Some people I I've known people who are incredibly sort of what I would think consider reckless physically with what they did with their bodies. They were extremely cautious with money. Uh other people uh may be you know uh very bold um socially and take all sorts of uh risks uh in in changing jobs in changing friends going into new environments um but again may be very cautious about their physical health and so I I I there is not a single risk scale where you can put everybody on. It's much more multi-dimensional than that.
>> Why do people fear the unknown so much? Oh, I mean I suppose if I was an evolutionary biologist I might say
>> I mean the we we fear the unknown risks more than
>> you know more more than the known right which is why co covid was so scary because we hadn't seen it before.
>> Exactly. Exactly. And that's been known you know for ages that unknown unknown risk Ellburgg paradoxes that people invest in you know looking in the 1950s that if you couldn't actually say how big the risk was people were much more averse to being exposed to it and that's been known for ages a well known that idea of risk aversion to a well-known um to uncertainty about the risk has has been you know 70 years ago I think Daniel Ellburg did his original um you know study of that and um and I think quite reasonably because um if you don't know what the possibilities are and roughly how likely they are then all sorts of other uh perhaps rather deeper attitudes to caution and precaution come in and people might start being really hedging themselves against and quite reasonably against major losses and we can see that going on you know in all all parts of our life.
>> Um what kind of habits can help us interpret risk in a more rational way? Well, first of all, I don't like the word rational. So, I I in my book, I hardly use the word rational at all because I think this um claim that's been, oh yeah, we can look at risks rationally and deconstruct them thing. I actually in real life, I think that's pretty nonsensical because and I've taught this stuff for decades and I've taught decision theory. I know how you should be doing it and I know you can't do it in practice because it for the for the theory to work, you have to be able to list all the possibilities. You have to list all the options. you have to look at the probabilities of the of the possible outcomes and their and their value to you and then according to you know economic principles you should maximize your expected return and things like that. Well, it just doesn't work. It be it fails at the first step that you can't even list everything that's going going to happen let alone except in really simple sit cir circumstances um put um numbers on everything. So I I I I think r nobody can be rational. It it just doesn't exist. I think so I really don't like thinking in those and this is some objective. No, I think one can try to be in a sense reasonable in a much broader sense of uh you know I suppose I how I would say is think is first of all you have to use as much imagination as you can. the things might happen that you didn't think of, but really it it you're really um opening yourself up to problems if you haven't at least made a big effort to envisage the possible futures to consider quite extreme scenarios and that requires diversity of inputs. I'm hopeless at this. I have no imagination at all. Absolutely disastrous. So, but I know that if I were if I were, you know, God forbid, in an important, you know, making important decisions for society, I'd want advisers with a with a real range of different inputs. The um the example I like is is Barack Obama when he was faced with the decision about whether to send in the seals when it was suspected that Osama bin Laden was in compound in Ababad and he had a a very diverse team of advisers who didn't speak to each other and some were you know they may have been set up as kind of red teams they they were really pessimistic 30 to 40% chance he was going to be there others were real gung-ho 80 to 90% chance he's there and uh he had to put all that information together but I think that's what uh someone who actually has to take the rap the real decision maker should be open to a diversity of opinion when there is no clear correct answer. So I think the first thing is we have to acknowledge there's no correct way of doing this. We have to have a diversity of opinion and we have to work in in a a combination of an analytic approach which I love. I'm you know based in maths I I've done maths and stats. I love de trying to deconstruct uncertainty, looking at the sources, analyzing data, building statistical models, and it's great, but it's never enough. It never tells you what to do. You also have to have judgment.
>> A bit of an increasingly numbers are emotional. They're weaponized in debates and so on. Just how do you counteract that?
>> Oh, I I think it's, you know, it's well known numbers, you know, it's a it's a complete myth that they're cold hard facts. Even before they're weaponized, we know that someone has made a decision to collect that particular data. There's lots of judgments has gone into every analysis, every sort of measurement. They are there's always judgment behind every statistical analysis and it's good as that's made very explicit. Um, and so other judgments can be added to it. People may disagree about the fundamental tenants, the fundamental assumptions that are always underlying any statistical analysis. So, it's a mixture. It's not thinking fast and it's not thinking slow. It's has to be a combination of the two.
>> Now, you started out in medical statistics. just how did you how did that come about? Oh. Oh, very naturally. It's just because there's a good job going and um and and cur curiously the job my first you know a real job after um after university I taught in America for a year and then came back and it was um it was 1978 and it was working on artificial intelligence in medicine 19 late 1970s. It was a booming idea. It was then largely called computer aided diagnosis and computer aided prognosis and it was building statistical models to enable um you know diagnosis but it included computer interviewing of people with stomach complaints and things like that. It was really advanced and the tech was terrible but the ideas were absolutely modern and and you know the problems the issues about how to integrate this in with medical practice were in there. So I was working on uncertainty in AI for much of the 1980s and we thought we'd solved it. Ah, how wrong could we be? But um because it's still a massive topic. Obviously the machine learning techniques that people use now have developed, you know, beyond all imagination and they are really are incredible. However, they are really struggling with uncertainty still.
>> What were what was some of the strangest stats that you've seen in in the medical sector?
>> Oh, I don't know.
>> Some of the mind-boggling
>> the mindboggling ones. Yeah. I I suppose it's the the ones I've been involved in actually four major public inquiries into health scandals in the UK. That's kind of where um I developed quite you know a slightly higher public profile I think. So ones where you know over 30 babies died with heart surgery at a center more than you would expect to have died. And then of course the second one was Harold Shipman, the mass murderer um who murdered, you know, at least 250 and possibly 400 of his patients over a 20-y year period. And uh we were brought in, he had been caught by then, but we were brought in to say uh could he have been detected earlier or not? And uh
>> could he?
>> Yes. Yeah. We can clear he could have been he could have been um detected after a few years if somebody had been looking at the data because he had so many excess deaths, but nobody was looking at the data. So nobody could be in
>> are people now looking at data properly across across hospitals across
>> it's got it's got better but it's still it's still slow. I'm in char I'm on a a group in the NHS that's only now building a a really rigorous statistical monitoring system for adverse events in maternity units and there's been endless maternity scandals in the UK and uh finally we've got a system based on it's essentially a statistical process control system but that we applied to shipment and then people took what we' done which was adapting industrial quality control to medical outcomes and then applied it to for example intensive children's intensive care in the UK has got a monitoring system based you know almost precisely on the work we did for shipment for early detection of problems
>> now you uh you are a leading kind of public communicator of of u statistics why is it important that people have a grasp of this field
>> oh what are the big wrong decisions people are making
>> so we only have to look at some of the I without mentioning any names uh well do a few Okay, we only have to look at what's happening in America at the moment to see what happens when high level public discourse is not based on evidence. Uh it's not based on numbers. It's it's just based on on people saying what they feel like saying and regardless of of the evidence behind it.
>> Give some examples. What are what are the most horrifying ones in your mind?
>> Oh, well, I I I think the um you know what RFK is saying about vaccines at the moment, you know, because he's got a built-in bias. I mean, vaccines are not perfect. They're not perfectly safe and they're not perfectly effective. So, I'd be the first one to say the term vaccines are safe and effective is is actually misleading. However, they are of enormous value and um and he's got his particular I think biases there. And uh and of course, I'm not going to talk about Trump and his way he was setting chars and things like that. So, you know, it seemed to be, you know, how he originally did that seem to be based on what a you know, 20-year-old intern might do on a on a you know, on a in a spreadsheet. And so, I It it just upsets me when I see um you know the enormous Oh, apart from of course sacking the head of the Bureau of Labor Statistics when he doesn't like the numbers. So all these things deeply upsetting to a nerdy statistician who I don't I I don't want to tell anyone what to do. I don't want to tell anyone what the right policy is. All I want to do is say please respect the evidence that we've got. just respect it and it it doesn't tell you what to do or whatever, but just try to respect it. And and it's not just of course politicians, it's social media, it's conspiracy theories everywhere. The um lack of concern or the I think deliberate lack of understanding of what good evidence is and how a piece should be used is deeply upsetting to a to a nerd.
>> Why is it happening?
>> Oh god, this is beyond my look, I'm a statistician. I'm not a great big sociologist.
>> Okay. But give give us some more kind of examples of where you think the world is going totally bananas and and moving away from from facts.
>> Yeah. Yeah. I I I I think of obviously there's enormous blame on social media on the algorithms on the recommendation algorithms that that mean that something oh wow that's looks impressive and it's almost certainly wrong. And so often they are based on numbers. You know, people love numbers and they kind of think, as we said before, they kind of think they're cold, hard facts. But no, and often the numbers are actually not completely wrong. It's just that they're grossly misinterpreted and exaggerated and one-sided, cherrypicked. And uh you know, a a wrongly ch a wrong number that's that's blown up and people making some bold claim uh is around the world, you know, is just triggered by the algorithms everywhere. And it looks good. It looks impressive. and trying to backtrack on that is really really really is really difficult and that's why um one of the things you know I'm on the board for the UK statistics authority and one of the things I try to hammer all the time in the communication of official statistics boring old official statistics is um to try to preempt the misunderstandings that people will make you know because once everything's out there it's really difficult to counter the misinformation misclaims which might be made accidentally or deliberately Um, you can't stop every people saying everything. You can't stop misclaims. Um, but you can of if you can preempt them, if you can understand by knowing your audiences, by listening to people's concerns, even the people you don't like. Um, to to know how what might be said, you can get in there and actually say this this data means, you know, I think we can interpret it to mean at least this, but it does not mean this. And uh that I think is going to become is becoming a more common trend in the communication of official statistics to say what things don't mean.
>> What was the most important thing we learned from COVID?
>> Oh, the importance of data.
>> The importance of data in it.
>> Which data in particular?
>> Oh, everything. Good. We wrote a whole book, you know, with every chapter on a different data source. There was so much. which I mean I was working you know round the clock really analyzing data and communicating about it because I didn't have an official role which was great which meant I could get out there with the media and trying to explain things and I again I never said what should be done it was only trying to explain the numbers and you got had everything you had the vaccines you had the roll out you had um the testing you had of course the disease the infections
>> but what a what a fantastic time for a statistician I mean it must be must be paradise for you
>> it was well I don't paradise isn't quite the right word but it was it was very exciting, very challenging and incredibly rewarding.
>> Um, and
>> important. I mean, statisticians have hardly been that important before.
>> Exactly. And I've had I keep on I now even now get people coming up and say, "Oh, thank you so much for the work you're doing during COVID." And the media had to learn. I you know that it wasn't just me or other statisticians who were out there talking about the numbers and yet we always at the beginning at least asked well you know who's to blame and what's going to happen or what should be done and we'd have to say I'm not going to say no no that's not my job you'll have to ask somebody else all we're doing is explaining the numbers and after a while the media learned that their a this is what the audience actually wanted an unbiased unaggendered discussion of the numbers and they loved it and so you know as I as I was really popular to be honest.
>> Well, you you in your book you talk about the five FCON rules. You know, you tell people what you know, you tell people what you don't know. Tell tell us about these five things.
>> Oh, yeah. Well, this is from this is for communicating evidence in a crisis. This is all derived from John Krebs when he was head of the food standards agency in the UK when he faced crisis after crisis. He had foot and mouth, he had mad cow disease, he had everything one after the other, total disasters. And he developed sort of playbook that he then afterwards he wrote and he said this is what I did when I was talking five points and I you got to have everyone should have these written tattooed on them I think first what you know so you know be really clear about what we know and then you say what you don't know you say where the areas of uncertainty are you admit them straight away second not first but what second and then you say um you say what we're doing about it you know we are learning more we're doing experiments we're finding out we're collecting data we are learning we are learning then you tell people what they can do in the meantime time that you may want to be cautious. You may not want to eat beef. You may not want to do everything except you. So you give people adi advice, self-efficacy in the meantime. But the final one is the most important. You say, "We will come back to you and our advice will change as we learn more." So you emphasize the provisionality of what you're saying. Now this is this is both deeply trustworthy because it's true. Um, it's also, as far as I can see, absolutely impossible for politicians to do. They just, it's just not in their vocabulary at all. This idea of provisionality.
>> Why is it so difficult?
>> Oh, well, they think they have to be absolutely confident about it. They say, "Oh, if we're not certain about everything, nobody will believe us. They'll just listen to somebody else. We have to be absolutely certain about everything." And I think they believe it. And our research with psychologists has and and not just our work but other research we've done randomized trials for different ways of messaging strongly suggests this is a complete myth that if you actually do you're in a position of authority you do actually admit some uncertainty that there are pros and cons etc etc um that you are trusted more and what's more important you're trusted more by the people who were initially skeptical
>> absolutely
>> by the very people you're trying to reach trust you more because you're finally listening to their concerns. You're finally acknowledging that um there are issues out there that perhaps vaccines aren't completely safe and effective. So what that means is the common political way of communicating which is I think put into practice by communication departments in in in government which hammer through the message bam bam bam are actively decreasing trust in the group they're trying to reach those who are most skeptical people who believe them already there's no point. So they're making it worse by their attitude. And I I since we did these trials and actually saw data on thousands of people showing that trust was improved in the most skeptical way if you gave a balanced trustworthy message including uncertainty. I it totally changed my mind. It absolutely convinced me about this. I also believe it's correct on an ethical point of view because it is correct but it's also purely from a practical point of view. It should be more effective.
>> No, totally agree with you. We we uh I've done a podcast with Rachel Botszman who is a specialist on trust and and indeed this is very very important but it's a bit um in the public sector generally they never apologize either right it's kind of tied into the same thing I think but
>> well what did we not learn from co
>> oh um a lot of it was uh not being flexible enough um getting tied into you know we were told to you know wash our hands and wipe surfaces and things like that and within about a month we knew this was pretty useless scientifically and yet nobody ever said, "Oh, what you can this is actually this is not the point of point. It's fresh air that's more important than ventilation." Nobody said that for a year and and so I think what we didn't learn was that you need to be agile and flexible and take people with you by acknowledging the uncertainties and that you change course. So the the guy we worked with who was uh you know most impressive I thought um was Jonathan Vanam the deputy chief medical officer and we worked together when the UK you know did admit that the Astroenica vaccine was causing these very nasty um well which was actually I think pretty well first detected in Norway um causing these nasty blood clots particularly in young people and uh we worked on the communication of that and where we showed that the the benefits of the vaccine went down massive when you got younger, but the risks went up. And so there comes a point you just shouldn't give the vaccine stratified by age. And he then said to the public, he explained all this, used our graphics, went through the numbers, taking treating the audience with respect, admitting the evidence had changed, and then said, "We're changing policy." And everyone said, "Well, fine." And and he said, "Oh, we're adjusting our course. It's not a U-turn. It's adjusting our course." And um and there was no push back from the media. There's no accusations. people really accepted it because he he actually showed the evidence to the public as he was explaining it to them and he could understand it. Politician would have been hopeless at it because he wouldn't have understood what was going on. He wouldn't be able to explain it. And uh so that to me showed that um you know if you can get good scientists actually doing the communication and they're good and they're reliable and trustworthy this can have an enormous impact on the public and on um well public trust in authority I think
>> uh the world is totally overflowing with um with data. How do you um distinguish kind of the signal from the noise so to say? Well, sorry. That's my entire career. You're asking me to explain what being a statistician means. Um, that's a statistician's job, you know, trying to split the signal from the noise. And of course, you can't ever do it. And, you know, what's a signal, what's noise is never absolutely a black and white thing at all. But um it's by trying to understand and this is a standard statistical you know thing that would have been said for the last century the sources of variation just like in you know pre-war you know the 19 all the statistics developed in um in Rothamstead breeding stations for uh for for plants and uh it was understanding the sources of variation what led to the variation between the crop yields what factors led to it and of course there is in a way unavoidable variation which tends be called noise or random error. And then there's ins predictable variation which is due to factors that you might be able to control. And that's what statistics has worked on for about the last hundred years. And um and it's it's not been bad. It's got some pretty good techniques for you know largely regression methods and so on. Um when and so it's actually done quite well. But you notice that that is different really from a a strict machine learning blackbox approach which just throws the data in and tries to extract a prediction you know a classification possibly with some uncertainty or a prediction of what what's going to happen where um there's no you know real understanding there of where it came from. People again you can't people will have real difficulty for explaining why a piece of AI came up with its conclusion. again people are really working on that now just like they are with uncertainty but um you know if you have rather slightly more basic statistical methods uh that you do I which I that's why I support them uh you can uh then generate a much clearer explanation of why you came to that conclusion and what are the important factors
>> in which uh in which area are you the most impressed by the improved predictions? Oh well I I I mean AI has is in terms of what you might call rather tightly controlled um areas um has done brilli brilliantly. I mean the people at Google deep mind who started you know started on games like chess and go and things like that and then moved into um what obviously protein folding um and then and also sort of medical diagnostic from images in terms of breast cancer and eye problems. they've worked with the Morfields Hospital is is tremendously impressive in that way in that they can take a really quite a big area but these are all tightly constrained problems.
>> Yeah. you know there's a block of data you've got an image uh you've got uh you know a set of data and then you produce an outcome and it's just brilliant at that where I'm much more skeptical is about I think you know very uh unfounded claims that oh well we can just put your medical record into AI and it'll tell you x y and zed and so I'm much people make have made a jump from these kind of quite tightly constrained problems which are which are just brilliant into much more general problems. And it's hardly surprising they do that when we look at large language models, how effective they are at coming back with a what is quite often a reasonable response to very generic issues because they've been able to mine, you know, vast amounts of stuff on the web. Now, how good that would be about and and of course it can come up with medical list of medical diagnoses and things like that. Yeah, it's just it's fine. It can make suggestions and it's can be extremely effective on that. But another if you take another I mean you've been around for a while I mean just uh during during that period the accuracy of weather forecast for instance is just mindbogglingly different right? Oh, weather forecasts are fascinating what's going on because there's a real compet there's a real competition going on I think fairly friendly compet about the totally different philosophies for weather forecasting because traditionally they it's been kind of applied mathematicians and physicists you know building huge model weather models based on Navia Stokes equations and third order differential equations and they build massive models of the of the atmosphere and then make a prediction you know six 10 a week 10 days ahead um But they don't use any data apart from the initial conditions really and then they vary the initial conditions and that produces in an ensemble model and they produce a probability of what's going to happen. the the alternative approach which people like Dean Mind have taken is to throw out all our knowledge of physics, the atmosphere, everything that's been learned in the last 300 years and just get and just throw it all out and take a the massive amount of data and to do a pattern recognition essentially and make a prediction which has no ability to explain why it's come up with conclusion particularly a pure black box and they're doing really well.
>> Which one is going to win eventually? Well, I I'm I'm really pleased that the UK Met Office has got both teams working and collaborating because it it's I think it's going to be complimentary in the end, but I'm kind of because my background in statistics rather than applied maths, I'm kind of secretly on the side of the blackbox machine learning people because I just love the thought of just putting the data in and out it comes with a with a prediction uh without any ability to say why. It's saying it's just saying well in the past when this pattern was there this is what happened. Well actually maybe that's as good as you can do. So I I think um it's it's a fascinating competition going on at the moment which I'm watching with glee.
>> Would you have liked to be a weather forecaster?
>> Oh well I kind of I kind of think if I had to study something methology would have been I mean one but what I'm interested in is the I don't care about the meteorology. That's why I quite like the databased approach. What I'm interested in is the first main nature paper from deep mind on this didn't have uncertainties in it and I think it it's really important to have uncertainties when I um you know I all the time I look at probabilities of rain and things like that I you I use those uncertainties if I don't have them I I really um would feel a bit lost and so um what I'm
>> So you so when you look at the forecast you don't look at is it going to rain or be sunn you you look at what's the probability of rain
>> okay and what probability you need to bring your umbrella.
>> Well, exactly. I don't know. It depends how that's person very personal about how it depends what I want to do if I want to have a picnic or not. So, uh I know I need the probabilities and so um this is uh you know this goes back to the 1950s with Glenn Brier developing a scoring rule but for probabilistic precipitation forecasts and uh it's it's terribly exciting I think and the the skill of these probabilistic forecasts is growing all the time and it will continue to grow. Do you buy do you buy lottery tickets?
>> Uh I bought one a few years ago when the the expected return was higher than the ticket price. There had been so many rollovers. It's still almost un completely impossible to win. But I thought I've got to have a go at a gamble where the expected return is higher than the stake.
>> Where um in which cases do you look at probabilities where other people would look at yes or no? Oh, um I got prostate cancer and so uh I I really interested in in forecasting effect of people with cancer and we've been involved in algorithms for um for breast cancer and prostate cancer building software to demonstrate those to people and they're all in terms of probabilities, you know, you know, roughish but not bad in terms of 10ear survival uh and how those will change depending on the different treatments you've got. And I I think it's absolutely essential when somebody says, "Oh, my doctor told me I had 6 months to live." I think what? First, I never believe they said that anymore. Maybe there's some doctors who'd be so stupid as to say that, but I can't believe that you have to show we don't know how long anyone's going to live. We can put some broad bracket on it because we it's a survival curve.
>> First of all, I want to say I'm really sorry to hear that you've got canc but given that you are a mathematician, what are your stats?
>> Oh, mine. Oh yeah. Um is that's the problem. I've got locally advanced prostate cancer. So I I've got some minor metastasiz um olig metastatic it's called. I got a few of them and um so I I and I but the drugs now the new drugs the new hormone drugs I'm on aberatone and um they just are so effective. Uh now it's I've got my PSA is essentially non-measurable. But the problem is we try to get the use the data from survival in clinical trials. I can't that it's really depressing when I go back on the trials for apparatone. They're terrible. You get sort of immediate survival of 18 months or something. I think what? No, I'm going to live longer than that. I'm sure because you know in the trials they were trying this on on very sick people. um and things have improved so much and the actually the um I'm I'm a the pe I'm at a earlier stage than the people who got the chance. So there's no good data really on what are my survival prospects. It's very difficult. I I it's a shame and I wish there were um you know better you know databases. I really wish I could just tap in and find out well out of a hundred people who are most similar to me what happened to them. But for a start, we don't know. We don't know. It's only been given to people like me for a few years.
>> So, we got no long-term follow-up. We don't know. I mean, I my, you know, some people got it earlier. My oncologist said, "Oh, I've had someone on this for 16 years." And said, "So, that's the problem with something that's fairly rapidly changing. When you're asking for a long-term prediction, you can't you can't say." So, uh,
>> well, all I can say all I can say is, uh, fingers crossed. And, uh,
>> yeah. Yeah. I mean it's it does seem a bit you know a bit pathetic for a statistician just to say well I you know hope I'm lucky but I hope I'm lucky.
>> Why are we so bad at predicting uh elections?
>> Oh elections. Oh well for a start because when you go out and ask somebody the all the election things are just ask people what would you vote if you had to vote now? I mean that's the question. You're not even asking them what they're going to vote in the election. You're asking them what what if you had to vote today what would you vote? And um and that's a very biased measure of what you're trying to estimate of of you know what's that person will vote in 3 weeks time, two weeks time, one week or even you know 3 months time. People change, people are not necessarily honest. Um and uh so people may vote, they may not vote at all. So I I think that the basic data source is always going to be biased. Um, and so it's not like predicting weather. You know, weather changes, but in a sense it's not changing because of what people feel. Um, it's not like changing. So I think it they're never going to be great because they're trying to predict estimate something that you cannot predict. You can't observe.
>> No. You've been bringing um statistics into some new areas. So for instance um anti-doping you know you mean the world anti-doping agency what kind of things were you doing there?
>> Oh then I I'm not sure what's happened then they had the idea of an athletics passport. Um because they wanted to actually a passport which kept a complete record of their drug testing history. Um and it was to try to allow to a certain extent for the fact that um you know there is individual variation between how people do respond um to drugs. And so when you take a measurement from somebody um uh they were particularly interested in um people getting blood transfusions, you know, just before a um an athletic event. And so you would be wanting to look at someone's red cell level or something like that. Was it remarkably high? Well, you only people vary anyway. So to know whether it been pumped up high, you have to know something about their past history. So essentially you have to have a model for um you know for someone's variability and their their natural baseline level for their hemoglobin level. And so uh it was quite complex. No, it was fascinating statistically and um and I I haven't I actually I would be interested to know whether it's what what the current situation is about that but it was in a sense trying to make the drug testing regime a bit fairer in order so it could adapt to the individual biology of the athletes
>> from uh drug testing to the financial industry. Is there anything in the financial industry that puzzles you?
>> No, I've kept well away from that. I mean I for a long time
>> why why why are you keeping well away from
>> I'm not interested for a long time of course because I was um I was funded uh from the charitable arm of Winon Capital Management hedge fund David Harding supported and he was great he gave us money and let us get on with what we wanted to and he was and I think I hope he felt it was a good investment but I I I I had nothing to do with the hedge fund um business and I've I've just never had any interest in money I hope it's just it just puts me off it's I just
>> why didn't why didn't you know why didn't uh Winton uh uh you know who's established a very uh successful firm why didn't he ask you hey David come and check out all things and make sure
>> no that was not part of the deal at all no he had plenty of really good people
>> he's a mathematician right
>> yeah yeah yeah so he he had the whole place stuffed full of of of mathematicians really competent people much more competent mathematicians than me for a start and so um he for start I couldn't have contributed anyway and it would have it would have not it would have really inappropriate, I think, for for that to happen and and I just wasn't interested. I couldn't care less.
>> Do you think people are worried enough about the really really bad outcomes?
>> So, for instance, um bioteterrorism, uh you know, the comeback of smallpox, that kind of thing,
>> nuclear war, you know, climate change, you say. Um,
>> well, nuclear war is relatively uh less dangerous than bioteterrorism.
>> Yeah. Well, it could be on a larger scale, but yeah, it depends on the scale, but it's um nuclear war would not be great. And so, um I I'm that's tricky, I think, because in the end, we're all going to die, you know, and you know, within a very finite finite period. I from a personal point of view I would understand because I think I do that that people do not want to spend their time obsessing against about all the terrible things that could happen in the world. It seems to me um that this is not a um not beneficial to your mental health shall we say to be really obsessed. I I kind of hope there are people studying it, you know, more professionally and who are trying to counter it with appropriate regulation, appropriate policing and so on. Um, but I personally do not want to spend my time waking up in the morning worried about smallox and bioteterrorism. Um, if people are so in other words, I I think I can understand because I don't do it why this is not full of top of the agenda in people's concerns. Catastrophic existential risks. Um I for a start I I I but I'm hopelessly optimistic. I think actually they tend to be overrated. Um and so but that's maybe because I my particular personality is far too optimistic.
>> Was Norway lucky to find the oil.
>> Oh that's I don't know. I think Norway I I don't know about how finding it but it was extremely sensible in how it dealt with it once it had found it compared with the UK. um who so and uh you know which is why you why you've got your job at the moment to some extent and so um I think that Norway deal dealt with this in an absolutely brilliant way of seeing it as a as a a national resource to be in sense of you know um you know to be nurtured for the whole entire community rather than just in the UK to to sell off the rights uh in order to raise raise some money at the In shortterm view,
>> how do you look at climate risk?
>> It's difficult because I
>> so so you have people talking about it like u some places in America, you sit there in the middle of ash, rain, um forest fires and you're kind of in the middle of it. You're sitting in the middle of it and you're saying CL, you know, there's no problem with the climate.
>> I know. I know. No, it's you know, it's just happening and that's it. um you could just tell by the events which are just going to carry on. There'll be you know ups and downs and but there are going to be more extreme extreme events. I'm interested in uh in um attribute what what what it's brought to the four is attribution studies which is not so much about climate risk but about looking backwards and say to what extent was this caused by manmade climate change which is a really big growing area in research and it's going to be a big growing area uh financially when people start suing uh fossil fuel companies for um for events that happen and so the uh you know and but it all requires models. You have to have a model of uh what we would, you know, how the climate has developed um with man-made uh you know, man-made interventions and how we think it would have developed had we not been throwing all this muck into the air um since the 1700s. And uh and you see see how likely these events were under these two different scenarios. And the relative risk can is the our meteorological office do have got an attribution center and they just they will give you a relative risk. Technically that can be converted into a probability of causation to say the probability that this hot weather event that this tornado was caused by man-made climate change was x%. And um officially uh once that gets above 50% by the balance of probabilities on a civil court case um you could say that man-made man-made climate change was responsible. Now trying to then attribute it to particular companies I think is is rather more difficult. But it it's brought from a technical point of view it's brought this fascinating idea of attribution. And of course for that you have to have climate models and the climate models are used to make projections as to what's going to happen. a lot of uncertainty and they the models take a lot of time in of dealing with that. They also have what I think is really good independent teams coming up with different climate models which then they pull and then they make it even more uncertain. They broaden the things out and um you know we're never going to know what's going to happen and uh one one should not state too confidently about what's going to happen but we know bad things are going to happen. Um, and what's to do about it? Again, not my job. Not my job, I'm afraid.
>> Talking about big things, uh, in, uh, 2021, you said that, uh, AI poses an extreme risk, but that it perhaps is overrated. What do you think now?
>> Oh, I think it poses an extreme risk and I think it's probably overrated. [Laughter]
>> What uh, could you explain? Yeah, I mean it's amazing how how strong it is and it turns what you mean about extreme risk. It's certainly going to take some jobs and certainly we're all going to have to adapt our jobs, our work to it. It's also incredibly useful and valuable. I use of course use it every day and um that I but in terms of sort of risks well people when they talk about this they're talking about sort of existential risks about you know um the the say self-aware AI that's going to start uh having essentially a will of its own and deciding that the these people get right get in the way of what it wants to optimize and um I I think of course that is a possible scenario And and I think it's quite reasonable then that people respond by wanting additional overview of and guard rails on AI. So it's like a lot of these things people say it's a bit like COVID before um you know co the modelers in the UK said oh there could be half a million deaths and that still gets quoted oh they said there were going to be half a million deaths. No they said there would be half a million deaths if nobody did anything about it. If we all just sat there and let it wash over us, there would be half a million deaths. And there would have been. But they're now being accused of saying, "Oh, they said there would be half a million deaths." And there weren't. So the point is that one could talk about there being risk. But I think it's limited the value of that if we're all going to assume we're just going to sit here and allow ourselves to be taken over by killer robots. So I think that what it does do is of course call for far greater scrutiny of um what's being done um in the o in openness about the guardrails put in um and so on. I mean
>> but are you seeing but are you seeing the necessary guard rails and so on being put in place? I
>> I don't know enough about it. Again, it's not really my area.
>> But when you look at AI, what are the type of things you look at in order to to gauge the risk? Oh, again I don't know enough about I don't know enough about these sort of existential risks and how those could occur, the super intelligence and things like that. I really don't know enough about it and I wouldn't want to claim to.
>> And how do you use You said you use it all the time.
>> What kind of What kind of things do you use it for?
>> I use it in writing my book. I use it for researching and I use it for coding and I use it for personal things like trying to work out where I'm going to go on holiday. So, so I'll I'll use it all for all sorts of stuff.
>> Where does it where does it tell you to go on holiday then?
>> Oh well. I I I I don't just say where should I go on holiday. It's not quite that broad, but I no I use it all the time and it's and of course we we're almost forced to use it now because it comes up number one thing when we do a Google search. So um I I I I think it's incredibly valuable. It's unbelievable what it can do. But I the guardrails of course are already in there in many ways in terms of you know violent speech and racism and all sorts of stuff that it can't do that are built in. Um, and I want those the crucial thing I feel is that these should of course should be open and public and uh and they should be there should be a regulator to make sure they're being adhered to. So, but lots of people are saying this. I mean, there's a massive AI safety is such a massive because all the tech people are going on about it as well. So, so I I'll leave them to it and hope that there's some some decent people involved in it. But it is a crucial area, not my job. Uh now if you do look at your job and and kind of your legacy, what what is the one kind of idea or principle that you hope you will be remembered for?
>> Oh, I don't know. I've moved around rather a lot. Um yeah. Oh, one thing. Oh, I think I I think it's the stuff I've been doing later. I think it's on trustworthy communication of evidence. Um in a way, it's not my I've done quite a lot of technical stuff. That's where I get all my citations from, etc. and I get loads of those which is lovely. But in the end, uh what I'm just obsessed by is the need for trustworthy communication about evidence. Uh as we said, not that it tells you what to do, but unless I mean, we're s sort of doomed if we're if we don't use evidence in in an appropriate way and don't communicate it properly, we are just left up to thinking fast. In Danny Carnean's turn, we're just left up to gut reactions and emotional feelings in order to for everything. And I think, wow, that is just disastrous.
>> And where is the next step of this trustworthy communication? Where is it? Where is that kind of part of the science going?
>> Oh, uh, yeah. Well, people are concerned about it. They're obviously concerned about, you know, the quality of what's published in the scientific literature, which is a massive problem because there's so much junk out there, um, un from paper mills and so on. Um I think that's well well I can talk about in the UK with actually this is now you've got a very high level there's a new there's a code of practice of statistics in the UK which is a pretty dull document but it's incredibly important there's a new version coming out which is really putting down you know the way in which all official statistics and even non-official statistics should be communicated to the public and based on these ideas of preempting misunderstandings of not being misleading of being open about limitations and so on and that's all down there and people have to adhere government departments have to adhere to it they are actually bound by it and so it's I think quite setting quite a good because in the UK we've got an office for statistics regulation which I think is might be fairly unique around the world an actual body that is there as a as an inspector as a regulator for statistics and uh I I'm a you know huge believer in that obviously And I would love to see that model developed elsewhere that you have got a body who can really tell people off when statistics are being misused. My god, they'd have their work cut out in the US at the moment, wouldn't they?
>> Oh, that's for sure.
>> What's the big what's the big unanswered question that you still want to tackle? Oh, well, I'd like quite like to know understand consciousness and whether there is such a thing as free will, but that's again going somewhat outside my um in my my professional expertise, shall we say. Um but it is in my book. I do discuss it because I think it comes quite important when you start talking about whether to what extent is the world genuinely stochastic and random or whether in to what extent is it actually deterministic but staggeringly complex in a way that renders it unpredictable. Um I think is an interesting issue. Um, oh, oh, interesting question. I suppose, you know, broadly it comes down a bit to what we're discussing before about whether I co was actually quite encouraging because in a crisis situation, um, good communication did rise to the surface. There were obviously people on each side arguing. I was right in the middle getting attacked by everybody. So, I thought, yep, doing the right thing. And it wasn't just me, but there was an enhanced respect for the mainstream media and largely people um you know were interested and uh you know there was a a whole body everybody was discussing the data. It was very active community and I think it was it was as you as we discussed a very exciting positive time. Now once a crisis has gone everyone goes back to their normal normal stuff and loses interest in all of this and um I suppose my qu my question I'm interested is whether that kind of interest and attention and wanting trustworthy information can be retained in societies that are becoming increasingly popular. you know, follow populist politicians who object to authority, who are distrustful of what they call elites and uh experts and so on. And as that happens, well, first of all, I suppose the big thing is can that be countered by having trustworthy experts, you know, people who do know something out there?
>> Yeah, I think it's so interesting. According to Bill Gates, it would take roughly a billion dollars a year to make sure the world is really ready for the next pandemic. And we the world is not spending that money.
>> Yeah. And I the next pandemic will be different. Um I and and it's people certainly wouldn't respond. I don't think in the next pandemic people would accept lockdowns. I just don't think they'll be politically acceptable. So I think uh
>> so we all so so we'll all be Swedes in the next pandemic. I think well the as Swedes as they as they said the guy the minister said well we practice social distancing anyway in Sweden. So I thought that's great. So um yeah I think we would be I think we would be more Swedes in the future. Um and so but the crucial thing about that is that what it says is that you know you said you can spend a billion dollars but you can't change how you do what are you going to do about people. I mean how people react is absolutely crucial and you don't necessarily change the way they react by just spending money on on on things. So I I think that the the particularly in pandemics the the role of human reaction to the situation is which is the most important and the least predictable aspect um and uh and actually very quite difficult to research very difficult I think to learn from the past pandemic about exactly what worked and what didn't because things were so different across um every every bit of society with within and between societies. So, um I'm not quite convinced that just throwing money at something is going to necessarily uh you know protect us against it.
>> What do you read outside statistics?
>> Oh, I read um some crime novels, but I'm interested in I really like history and biography um especially military history. I'm obsessed with the Second World War. So, I I spend my time visiting um you know, war sites around Europe and uh and and further and and in India. So that's actually what I'm interested in.
>> Why are you why are you so interested in that?
>> I've been asking myself that why am I so interested? I think it's growing up in this generation and you know born in 1953 in the UK the war was around us all the time in the films and the culture and the experience of of the adults around us and things like that. We grew up with it as small kids absolutely obsessed with it and um and I never really have quite lost my my interest. I I think partly because every time I read anything about it, I just sort of thank uh heavens for my well what's known as constitutional luck. The fact that I was born when I was born into a society I was born into which was staggering constitutive luck. Now, if you were to apply your if you were to put on your professor in statistics hat and give advice to young people using some numerical math or whatever, what what what is your advice to young people? How should they think about their life in statistical terms?
>> Yeah. Well, I do I mean some of them even read my books, which is I don't I had a 17-year-old come I nearly burst into tears because he came up and said, "Oh, I really like your book." And I said, "Well, it's not actually aimed at teaching you. I really I was so moved that he liked it because I actually think there is some stuff in there about um you know fa we have to face up to uncertainty. We we don't know what's going to happen. I didn't know when I was 18. So I had no idea what was going to happen in my life. I was as I said I had enormous constitutive luck where I was at that time. Lots of opportunities you very secure situation everything paid healthcare university everything all paid for. Um I was in a very really privileged situation. Um and so but there's still of course massive unpredictability but I didn't mind. I took I felt that I'd got a good upbringing which gave me resilience. So the crucial thing and of course this is as relevant to corporations as it is to human beings I think is resilience. It just it's the number one priority because that's how we deal with the deep uncertainty in all situations. the fact that we don't even know we can't even list what might happen particularly some way in the future. So all what we have to do is cultivate resilience which is an ability to deal with if not and learn from
>> benefit from anything that can happen whether it's good or bad and um for some reason I think I developed quite a lot of it. I'm not quite sure maybe it's a nice secure um upbringing I had um and the the good fortune I've had but for some reason I think I got it. I don't know and I think know again I would say this for young people that you have to go out and take risks. Don't be reckless. I say this to I do I I say I give talks in schools and I say you got to take risks now. Don't be reckless. You know look cover yourself from the damn major downsides. You know just be careful but take risks. So go out you know camping on your own in the middle of a moore but don't be stupid. let people know where you're going and make sure you got the proper kit in Norway because everyone knows about that stuff, but not in the UK necessarily. So, go and take go and have those adventures, but don't be stupid. And so, and it's through having, you know, those sorts of adventures and taking some risks and being in situations where you're not quite sure what's going on that you develop resilience. So, I just say to young people, go out there and have adventures, but don't be stupid. David, I had a 90% probability on this uh podcast being very good, but it's even better than I expected. I just absolutely love talking to you. So, big thanks for everything you do to, you know, society and increasing the knowledge of stats and just for being such a wonderful communicator. Big thank you.
>> Well, thanks so much. This was somewhat outside my comfort zone, a lot of this, but so anyway, so I suppose I had to take the risks of of being there. The biggest risk I've done for quite a long time is being on this podcast, I tell you that. Great. Big thanks.
>> Thank you. Bye-bye.