---
author: Best Partners TV
date: '2025-12-27'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=k1fCwfjEz_w
speaker: Best Partners TV
tags:
  - ai-inference
  - chip-architecture
  - supply-chain-management
  - ai-economics
  - energy-policy
title: 【商业】英伟达200亿天价拿下Groq | 低延迟 LPU | AI推理算力革命 | 英伟达补短板 | 全球AI能源博弈 | 芯片行业变局 | AI 劳动力短缺 | HBM供应链护城河
summary: 本次视频深入分析了英伟达以200亿美元收购AI芯片初创公司Groq的重磅交易。交易核心在于Groq专为AI推理设计的低延迟、高能效LPU技术，旨在弥补英伟达在推理算力上的结构性短板。通过对Groq创始人Jonathan Ross的访谈回顾，文章揭示了AI算力瓶颈、速度对用户参与度的影响、HBM供应链的关键作用，以及AI对未来经济（通缩、劳动力短缺）的深远预测。此次收购标志着AI产业正从训练转向规模化推理落地。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - Nvidia
  - Groq
  - Google
  - OpenAI
  - Microsoft
  - Amazon
  - Anthropic
products_models:
  - LPU
  - GPU
  - TPU
  - Kimi
media_books:
  - Hardware Lottery
status: evergreen
---
### 英伟达200亿美元收购Groq：AI推理算力的新篇章

大家好，这里是最佳拍档。这个圣诞节，英伟达与AI芯片初创公司Groq达成了一笔高达200亿美元（约合1405亿元人民币）的重磅交易，这标志着英伟达历史上最大的一笔收购。根据Groq的官方声明，此次交易的核心是英伟达获得了Groq推理技术的授权，Groq的创始人兼CEO Jonathan Ross、总裁Sunny Madra及其他高管将加入英伟达，协助推动授权技术的落地。与此同时，Groq将继续作为独立公司运营，由现任CFO Simon Edwards接任CEO。

表面上看，这似乎是一场普通的技术合作。然而，Groq的投资方Disruptive公司的CEO Alex Davis指出，英伟达将获得Groq几乎所有的资产，仅保留初具规模的云计算业务GroqCloud。这本质上是一笔典型的**Acqui-hire**（人才收购），即不收购公司整体，而是获取其核心技术、专利和关键人才。那么，英伟达为何愿意斥巨资收购Groq呢？这需要从Groq的背景及其技术优势说起。

Groq成立于2016年，其创始人Jonathan Ross拥有传奇经历。他高中辍学、大学未毕业，却在谷歌设计出了第一代TPU芯片的核心架构。TPU是谷歌为AI计算自研的芯片，被视为英伟达GPU在AI领域最重要的竞争对手之一。1999年，Ross带领TPU团队中的7位核心成员集体出走，创立了Groq。这家公司从一开始就做出了一个极其明确、甚至有些反主流的选择：不与英伟达拼训练算力，而是专注于AI推理。Groq的名字来源于“Grain of Quantum”（量子之粒），寓意着要处理量子级别海量数据，并宣告小体量也能在芯片领域拥有大杀器。

Groq的核心杀手锏是专门为AI推理设计的ASIC芯片——**LPU**（Language Processing Unit）。与英伟达的GPU相比，LPU在处理大语言模型的推理时，能实现更低的延迟和更高的吞吐量，这对英伟达、AMD和英特尔等传统GPU制造商构成了巨大挑战。为了实现规模化推理，Groq还设计了可扩展的分布式系统，能够将数千个LPU芯片互联，让计算流持续在芯片间流动，从而避免了传统架构中因频繁访问外部内存带来的能耗与延迟。得益于架构优化，LPU的单位token能耗可降低到普通GPU的三分之一左右。

2024年，Ross曾公开表示，AI推理成本高昂，Groq为此提供了超快、更便宜的芯片选择，并预测到当年年底，Groq将成为大多数初创公司使用的基础设施，且价格非常友好。这恰恰触及了英伟达的结构性短板。根据投资方透露，在被英伟达接洽时，Groq并无出售意愿，刚于当年9月完成7.5亿美元融资，估值达69亿美元，投资方包括贝莱德、三星、思科等。Groq当年的营收目标是5亿美元，正处于高速增长期。

根据CNBC报道，黄仁勋在英伟达内部邮件中明确了此次交易的战略意图：计划将Groq的低延迟处理器整合到英伟达的AI工厂架构中，服务更广泛的AI推理和实时工作负载。通俗地说，Groq的核心技术将成为英伟达生态的一部分。至于Groq公司本身，仅保留云业务继续运营。这既不影响英伟达的战略，也避免了直接并购可能引发的反垄断风险。对英伟达而言，此次交易不仅是获得了一项关键技术，更是将一个潜在的挑战者纳入了自己的体系。截至2025年10月底，英伟达持有现金及短期投资规模已达606亿美元，相比2023年初的133亿美元翻了近5倍，为此次大手笔投资提供了充足的弹药。

### AI算力瓶颈与速度的经济学价值

巧合的是，在收购消息公布前三个月，科技播客20VC的主持人Harry Stebbings与Groq创始人Jonathan Ross进行了一场近90分钟的对话。Ross在对话中反复强调“我们不会做模型”，并坦承“可能会被客户吞并”。他详细解释了为何自建芯片几乎注定失败，为何英伟达的护城河不在CUDA而在HBM供应链，以及Groq为何能做到6个月的交付周期——这才是真正的差异化。如今三个月后的收购，让这期对话显得尤为关键，或许能一窥此次收购背后的逻辑脉络。

Ross在对话开场就抛出了一个判断：当前AI公司最大的瓶颈不是模型，而是算力。他认为，OpenAI和Anthropic最大的瓶颈其实是速率限制，导致用户拿不到足够的token。如果这些公司有更多算力，就能产出更多token，从而收更多的钱，甚至翻倍。主持人追问原因，Ross解释说，算力决定了你能服务多少用户以及服务到什么质量。例如，OpenAI的聊天服务如果跑得慢一点，用户参与度就会下降，这也是其推出限量高价产品的原因——他们想测试投入更多算力后产品能好多少。

他认为，AI与SaaS的逻辑完全不同。SaaS产品的质量由工程师决定，而AI则可以通过跑多个实例、选择更好的答案，甚至为高价值客户提供更多算力来提升结果质量。也就是说，用户能直接用钱买到更好的产品质量。许多人可能觉得AI响应速度够用就行，等几秒钟无所谓。但Ross认为这个判断完全错误。他用消费品行业类比：利润率最高的通常是作用于人体速度快的成分（如烟草、软饮料），多巴胺循环越快，品牌黏性越强。他引用数据表明，每100毫秒的加速会带来约8%的转化率提升，这是Google和Facebook早年验证过的规律。Ross反驳了“为何需要比阅读速度还快”的质疑，并反问“为何网页加载需要比阅读速度还快？”他指出，人们很不擅长判断真正影响参与度和结果的因素，而Groq从早期互联网公司建设中学习到了这一点。

### 市场真相：聪明钱的流向与芯片制造的挑战

主持人问及当前的AI是否是泡沫，Ross建议换个问题，看看“聪明钱”——Google、微软、亚马逊以及一些国家——在做什么。他们都在加倍投入AI，且投资额不断攀升。他举例说，微软曾在一个季度部署大量GPU，却宣布不将它们放到Azure出租，因为自己用比租出去更能赚钱。这表明市场里有真金白银的投入。在阿布扎比的高盛峰会上，Ross询问台下管理着百亿美元以上资产的基金经理，是否有100%确信10年后AI做不了他们的工作，无人举手。他认为，这就是超大规模厂商们的感受，他们必须像“醉酒水手一样花钱”，否则将被踢出局。这已不再是纯粹的经济框架，而是关乎领导地位的存亡。要想留在行业顶尖位置，就必须持续投入，这构成了这些公司股价高企的自我强化循环。

主持人接着问，OpenAI是否会自建芯片做垂直整合？英伟达是否担心？Ross的回答充满工程师的冷静。他表示，如果今天再创业，肯定不会做芯片，因为时机已过。从芯片设计到投产，即使执行完美，最快也需三年，英伟达通常也需要三到四年。更残酷的是，首次流片的成功率仅14%，86%的概率需要重来。他回忆自己做V2芯片时，第一次就成功了，连自己都震惊了，但这种几率太小。Ross认为，造芯片最难的不是硬件，而是软件，以及跟上市场演进方向。在位者可以提前规划，因为大家会为他们的硬件设计模型；但新进入者没人会为未发布的芯片设计模型，必须有更快的迭代循环。Groq做到了“一年一代芯片”（V2、V3、V4）。

他还提到了Sarah Hooker的论文《硬件彩票》（Hardware Lottery），核心观点是人们只为现有硬件设计模型，因此即使存在比Attention更好的架构，但因Attention在GPU上跑得好，就成了标准。Ross还讲了一个Google的故事：当时AMD还在挣扎，Google却建了10000台AMD服务器，目的是为了在Intel那里拿到更好的折扣，而非真的要用AMD芯片。

许多人以为CUDA是英伟达的护城河，但Ross认为这只对训练成立，对推理不成立。他认为真正的护城河在于供应链，具体是**HBM**（High Bandwidth Memory）。Ross解释了**买方垄断**（monopsony）的概念：你是唯一的大买家，因此能控制供给。英伟达的GPU工艺与手机芯片类似，一年可造5000万颗GPU die，但今年只造了约550万颗，原因在于HBM产能有限，导致中介层产能也受限。他举例，当超大规模云服务商向英伟达要100万颗GPU时，英伟达会说抱歉，但如果服务商说“我自己造”，英伟达就能神奇地找到货。他想表达的是，自建芯片给你的不是芯片本身，而是掌控自己命运的能力，因为英伟达无法告知配额。

虽然自建芯片可能更贵、不如英伟达的好，但Ross解释了为何这点差距在系统总成本里微不足道。如果芯片占系统总成本的20%，芯片性能提升20%能带来系统价值20%的提升，而芯片成本只增加20%的20%（即4%）。这就是为何小的性能优势能带来巨大的价值差异，以及英伟达即使只比AMD好一点点也能主导市场。当然，HBM供应商也有自己的算计：HBM利润率极高，他们不愿增加产能导致利润率下降；产能建设需提前至少两年下单付款，即使有英伟达的现金流也难押注那么远的未来。

### Groq的核心差异化：SRAM与供应链速度

接下来的部分，可能是整期访谈中最关键的——关于差异化的解释。Ross说，他曾与一家超大规模云服务商的基础设施负责人开会，谈了速度、成本等各种优势，对方都没太在意。但当他提到“自己能做到6个月的供应链”时，对方直接暂停了对话，只想深挖这一点，显然这是他唯一关心的事。

为什么会有这个差异呢？原因在于Groq的LPU架构不依赖于HBM，使用的是片上**SRAM**（Static Random-Access Memory）。这是大家最常问的问题：SRAM不是比DRAM贵吗？Ross解释说，SRAM每比特大约比DRAM贵3到4倍，因为SRAM需要6到8个晶体管，而DRAM只需1个晶体管加1个电容，且SRAM部署在更先进的制程上，每单位面积成本更高，综合下来可能贵10倍。但这只是从芯片视角。如果用系统视角来看，当Groq跑一个像Kimi这样的模型时，需要用4000颗芯片；而GPU跑同样的模型可能只需8颗。这意味着GPU那边有500份模型拷贝，用了500倍的内存容量。所以，即使SRAM每比特贵了10倍，但他们用了500倍的内存量，系统总成本算下来，Groq反而会更便宜。

Ross说，他们现在是从全球视角看问题。Groq有13个数据中心，分布在美国、加拿大、欧洲、中东，会根据不同地区需求，在不同数据中心部署不同模型的编译优化版本，从而在世界级别做负载均衡。他还讲了一个两周前的真实案例：有客户来找他们，要5倍于全部产能的算力，从任何云服务商或任何人那里都拿不到，Groq也给不了，因为“没有人能给”。这意味着市场不是有没有需求的问题，而是产能根本不够的问题。

### 全球AI发展路径、能源博弈与经济预测

在访谈中，Ross还谈到了中美AI发展路径的差异。他注意到，当DeepSeek等国产模型发布时，业界关注点多在训练成本的突破。但Ross认为，这背后是不同的优化方向选择。他的判断是，中国模型的运行成本大约是美国模型的10倍，因为中国模型优化的是训练成本，而美国模型优化的是推理成本。那为何API价格反而会更低呢？Ross认为这是定价策略差异，不能将价格与成本混为一谈。当你是某个特定模型的唯一提供者时，在封闭市场里可以灵活定价。需要注意的是，训练是一次性投入，要摊销到每次推理上。如果推理量巨大、算力充裕，降低单次推理成本收益更高；如果算力受限，则需先把训练效率做到极致、让模型跑起来更务实。所以，他的思路是，由于芯片获取受限，中国团队在有限算力下将训练效率做到极致，这是约束条件下的理性选择。Ross还提到，中国正在建设大量核电站，从能源侧为AI算力做长期准备。当能源不再是瓶颈时，算力约束的逻辑就会发生变化。

比起中国，Ross对欧洲的诊断非常直接：问题不是资源，是“恐惧”。他还说了一个让主持人惊讶的判断：美国比欧洲更厌恶风险。但他马上解释，风险有两种：一种是犯错的风险（做了某事结果是错的），另一种是错过的风险（没做某事结果错过了机会）。美国害怕的是错过的风险，在高增长经济体里，错过比犯错代价更大。而欧洲害怕的是犯错的风险。他说，欧洲试图通过立法来竞争（如数据本地化、隐私保护），但这解决的是“别人控制我的风险”，解决不了“我没有足够算力”的问题。所以，如果欧洲想竞争AI，可以直接在挪威部署大量风力发电，配合水电，仅挪威就能提供相当于整个美国的电力。他还说，欧洲还有大量潜在能源未开发。更何况，沙特阿拉伯也在建设数据中心，有吉瓦级别电力。欧洲为何不和沙特合作，利用其“数据大使馆”概念，在主权监管下使用对方能源呢？关于核能，Ross说他在欧洲基本不提，因为大家会本能抗拒，但日本正在重启核电站。他还提到在美国建核电站，许可证费用是电站本身的3倍，欧洲可能更糟。其实法国、韩国都知道怎么建核电站。Ross建议，不如来一个“能源领域的曼哈顿计划”。主持人问，如果欧洲不行动会怎样？Ross回答：欧洲经济就会变成旅游经济，人们只是来看看古老建筑，仅此而已。没有新经济所依赖的资源，就无法在新经济中竞争，而新经济就是AI，它建立在算力之上。简单来说，控制算力就能控制AI，没有能源就没有算力。

聊到对AI经济影响的判断，Ross的观点与主流叙事完全相反。主流媒体担心AI导致大规模失业，但Ross认为AI会导致大规模劳动力短缺，即没有足够的人来填补将要创造的工作岗位。他预测AI会带来三重效应：
1.  **大规模通缩压力**：咖啡、住房等一切都会更便宜，因为机器人农业更高效、供应链管理优化，甚至可以通过基因工程改造咖啡豆。
2.  **劳动力退出市场**：工作时间、每周工作天数减少，退休更早，因为维持生活水平所需工作量下降。
3.  **新工作和新产业涌现**：100年前美国98%劳动力在农业，现在仅2%，其余从事当时无法想象的工作（如软件工程师、网红）。Ross认为100年后软件工程师职业也会消失，但以不同方式消失，因为那时人人都会**vibe coding**了。

Ross还解释了AI经济学与工业革命的本质区别。工业革命时期，能源不够用，还需要机器转化；想让更多汽车上路，光挖石油不够，还得造汽车。而AI不一样，把算力翻倍，用户数就翻倍，产品质量也提升，直接加算力即可，没有中间环节。在经济中，最有价值的是劳动力，而现在可以通过生产更多算力和更好AI向经济中增加更多劳动力，这在历史上是从未发生过的。他举了一个公司内部案例：客户提出一个功能需求，Ross做了个高层级规范说明，四个小时后该功能就上线生产环境了，没有一行人类写的代码，没有人类调试，全是提示工程。他甚至通过Slack做代码提交。他设想，也许6个月后，这件事在客户会议结束前就能完成。这不只是省钱，而是质的不同，能赢得竞争对手赢不了的单子。

### Vibe Coding、利润率与未来展望

主持人问“Vibe Coding”会是持久的市场还是过渡现象？Ross用读写类比：读写曾是专业技能（抄写员），现在是基本要求。编程也正在经历同样转变，市场、客服等都要会编程。他提到一些实习生特别擅长vibe coding，还有一个开咖啡店的朋友，从未写过代码，却用vibe coding做了供应链库存管理工具，并修复了软件工程师都会发现的问题。

关于利润率（margin），Ross说了一个反直觉的观点：他希望Groq的利润率尽可能的低，只要业务保持稳定即可。他解释利润率的两个功能：一是稳定性，利润薄可能撑不住市场波动；二是竞争壁垒。但反过来说，对手的高利润率就是自己的机会，因为高利润率会吸引更多竞争者。Ross面试过一个CFO候选人，对方建议提价到需求下降为止，这从经济学合理，但Ross认为为何不将品牌价值变现，利用客户信任卖不那么好的东西？他认为品牌和客户信任有价值，信任会生出利息。但收取高利润率时，你与客户是对立的。所以Groq策略是：利润率尽可能低，通过增加销量获得充足现金流。

对于未来5年后芯片市场，Ross预测英伟达仍将占50%以上收入，但可能只占10%的芯片销量。品牌有巨大价值，可以收更多钱，但会让人不那么“饥渴”，开始收更高利润率。有些人愿为品牌付费，因为“买英伟达没人会被开除”，这生意会继续值钱。但他又说，当客户集中度高时（如35-36个客户占99%token消费），大客户会基于对自身业务有利的因素做决定，而非仅品牌，所以会有更多其他芯片被使用。主持人问英伟达5年后能否值10万亿美元？Ross回答：“如果不值，我会很惊讶。”再问Groq5年后能否值10万亿？Ross回答：“可能吧。Groq没有供应链约束，能生产比任何人多的算力。现在市场上最稀缺的是算力，而Groq能生产几乎无限量的算力。”

就在他说完这句话的三个月后，英伟达用200亿美元给出了答案。无论是从英伟达的收购，还是从Ross的对话中，我们都可以看到，全球AI产业正处在从模型训练阶段迈入规模化推理落地的关键期。低延迟、高能效的推理算力已成为AI模型的核心刚需。

大家是如何看待英伟达这次收购Groq呢？你们觉得200亿美元值吗？感谢收看本期视频，我们下期再见。