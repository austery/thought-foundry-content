---
author: 科普基地
date: '2025-11-14'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=2ZzNk9c33nI
speaker: 科普基地
tags:
  - ai-development
  - startup-strategy
  - code-editors
  - agi-debate
  - ai-efficiency
title: 挑战微软、套壳VSCode：Cursor如何逆袭？AI应用创业的深层思考
summary: 本文深入探讨了AI代码编辑器Cursor在巨头环伺下，如何通过“复刻VSCode”的激进策略求生。文章分析了AI行业的三大门派，揭示了Cursor以用户体验为核心、追求极致响应速度的独特路径。同时，文章也对AGI与工具派的哲学之争，以及AI发展面临的“样本复杂度”和“美瓦智能”两大根本性挑战进行了深刻剖析，并从生物学角度探讨了未来智能算法的可能方向。
insight: ''
draft: true
series: ''
category: technology
area: tech-insights
project:
  - ai-impact-analysis
  - entrepreneurship
  - systems-thinking
people:
  - Ben
  - Michael
  - RV
  - Swarov
  - Oscar
  - Ian LeCun
companies_orgs:
  - Microsoft
  - Cursor
  - Alibaba
  - Autodesk
  - OpenAI
  - Google
  - Nvidia
products_models:
  - VSCode
  - Copilot
  - ChatGPT
  - Custom 360
  - GPT-4
  - H100
  - B200
media_books: []
status: evergreen
---
### 巨头环伺下的激进选择

全球最大的编程编辑器**VSCode**（Visual Studio Code：微软开发的免费开源代码编辑器），再加上全球最大的代码库，以及内部正在进行的AI集成，显然都在朝着AI方向发展。所以当时科技界所有人的反应都是：你们没搞错吧？你们要直接复刻VSCode，然后做和它一样的软件规划，还想跟他抢客户？祝你们好运。除了这个终极巨头，微软周围还有一圈小巨头，它们是上亿美元投资的增强型代码魔法公司。这全是资本，是一道完整的冰墙。**Cursor**（一家AI代码编辑器公司）的初始团队简直是小打小闹。这种比例完全是小巫见大巫。这场看起来必败的比赛是如何开始的？这个故事就更有趣了。

### 早期探索与失败的教训

Cursor的团队实际上是两个早期小公司的小团队合并而成的。第一个团队想做什么呢？他们想做一款超级私密的加密聊天软件，私密到不仅你发送的内容加密，就连你发送给谁，所有信息都必须用同类型的加密方式隐藏。当时他们的朋友Ben听到这个想法，第一反应就是：你们的客户是谁？阿里巴巴吗？你看，聪明人在一开始构思时，可能不会去找另一个团队的编辑器。他们走得更远，他们看到了AI的潜力，想做一个CAD领域的Copilot，也就是帮助工程师自动生成三维模型。这个想法听起来更可靠，AI不能具体地讲好一个锤子领域的故事。但很快，他们就撞上了南墙，而且是两堵墙。第一堵墙是数据，他们发现无法获得足够的CAD模型数据来训练AI模型，导致效果很差。第二堵墙是最致命的，那就是插件的限制。他们想在**Autodesk**（一家设计软件公司）旗下的**Custom 360**（Autodesk的一款定制化软件）软件上做一个插件，结果发现这款软件的API接口连简单的键盘监听都做不到。这是什么概念？这意味着你无法像**Copilot**（GitHub Copilot：AI编程助手）那样，你敲代码时，一个键盘代码建议就“嘣”地一下自己冒出来。你只能在屏幕上放一个笨拙的按钮，让用户点击一下才能把代码放进去。这种体验根本不行啊！难道你还要去求Autodesk说：“大佬，能不能给我们开放一个API接口？”你猜人家会理你吗？

正是在CAD领域这场悲剧和痛苦的失败中，他们领悟了一个核心真理：如果你想创造一个真正有魔力的AI体验，你就不能寄人篱下，你必须拥有整个房子。这个看似疯狂的决定——直接复刻VSCode，正是他们从失败中吸取的最宝贵经验。尽管这让他们站在了巨头的对立面，但也赋予了他们修改整个“房子”的最高权限。

### 两支团队的合并与外部质疑

他们拥有了整个房子，但房子里却住着两家人。还记得我们前面提到的两个小团队吗？一支是来自CAD项目，由Michael带领的团队，他们思考问题非常直接。而另一支团队，则是想做加密聊天的RV和Swarov。他们也转向了代码领域，但想法不同，想做一种更精英、更定制化的工具，有点像程序员的“泡泡”编辑器。然后，一个更疯狂的想法出现了：这两组人一合计，说不如我们合伙吧？这次，旁边看到的朋友们都怒了，Oscar又跳出来说：“别！别！”他的理由简单粗暴，而且完全符合创业的黄金法则：第一，别去红海。他们却去合并了。第二，创始人太多，内部必斗。他们又回来了。

### AI江湖的三大门派与Cursor的独特定位

可以说，Cursor这家公司几乎是踩着所有创业避坑指南的雷区诞生的。所有人都觉得他们要完，但他们就这么干了。那他们为什么敢这么干？因为他们看到了别人没看到的东西。当时的AI江湖主要有三大门派：

第一派，我叫它“炼丹派”。代表就是像**OpenAI**（一家人工智能研究公司）的**ChatGPT**（一种大型语言模型）这些明星公司。他们的想法是：我们得训练自己的专属大模型。怎么炼？去跟大企业合作，用他们内部的代码库来投喂。听起来很高端，对吧？但问题是这太慢了。

第二派，“插件派”。代表是Copilot、**Codeium**（一家AI代码补全工具公司）这些公司。他们的逻辑是：VSCode这么普及，我们就在上面做个插件，用户装一下就能用，多方便！但这不就是Cursor团队自己在CAD上踩过的大坑吗？寄人篱下永远不可能有极致的体验。

然后就是第三派，也是最孤独的一派：“推倒重建派”。整个硅谷就他们一家Cursor。他们的赌注是：AI必须和编辑器深度融合，融为一体。想要真正的魔法，就必须重写底层的交互逻辑。

### 预测未来与短期执行的平衡

你看，真正重要的地方在哪？十年后世界会变成什么样？AI如何写代码？其实大家想法都一样。九十年代网景的创始人想做纸媒，后来把公司卖掉去做Instagram。想法并不是多么“牛逼”，但真正的决策不是预测十年后的生活，而是你对未来12个月产品路线图的判断。对于一家商业公司来说，看未来十年，也要做未来三个季度，因为你得活下去。你需要在短时间内取得成果，获得用户的认可，形成一个上升的趋势。你没有趋势，你就没有一切，人才会走，投资会跑，市场会忘记你。Cursor选择了这条最困难、最孤独，也需要最短时间见效的道路。

### Cursor如何点燃第一把火

那第一把火到底是怎么点燃的呢？你可能会觉得他们今天的大招，是一个能帮你自动写整个项目的超级AI。错了，恰恰相反，他们做的第一件事极其简单，简单到甚至有点反AI。他们发现，一家创业公司最容易踩的也是最致命的坑是：功能不是越强越好。什么是好？是让用户以最快的速度感受到价值的功能。

我们来做个对比：一边是一个超级智能的AI特工，你告诉他：“帮我把这个项目重构成React。”他能做得非常强大，但你需要花时间学习如何与他沟通，如何给他指令，万一做错了还得重来。另一方面，是一个简单的代码补全功能。你在VSCode里敲代码，你改个颜色，你刚敲了两个字母“bo”，一下，一整行代码直接帮你补齐了。哪种体验更酷？一定是后者！因为它带来的价值是“零学习成本”的“早期大脑”体验。你从VSCode切换过来，第二秒就立刻感受到了这种酷。这种酷就是他们的第一把火，是他们的“原力之火”。

### 用户至上的产品哲学与扁平化组织

这第一把火不仅能让用户觉得酷，他们自己就是自己产品的头号用户。整个公司的工程师每天都用Cursor写代码，哪里不好用，哪个功能响应慢，根本不需要产品经理提需求，他们自己就是第一批“销售员”。这种模式让整个公司变成了一个极其扁平、极其工业化的思想中心组织。新员工加入，问“我们部门是做什么的？我们的产品路线是什么？我应该做什么？”答案是：“你把自己用爽了，不就有想法了吗？如果你有想法，就去AI行业。每个人都是第一次来，路线说了半天，部门的身体是一套VSCode，大脑是那些巨头模型供应商，OpenAI和Google。”

### 程序员的真实需求：解决问题而非重复劳动

这项技术成功的关键是什么？是对程序员人心的洞察。你看，一个常见的误解是：程序员热爱写代码。程序员热爱的是解决问题的快感，是那种复杂算法作业后的复杂计算。但他们痛恨代码中的那些“垃圾”：例如，处理一个莫名其妙的React Bug，或者翻半天文档，解决一个破依赖问题。这与其他行业完全相反。你去问一个顶尖律师：“嘿，我有一个AI能帮你写法律文书，你不用再写了。”你猜他会说什么？他会觉得你在侮辱他的职业，是在夺走他工作的灵魂，因为写作本身就是他引以为傲的手艺。但你告诉程序员老哥：“我能帮你自动处理那些凡人琐事。”他会说：“快点！”这正是成功的关键。他们没有试图取代程序员，他们做的是让程序员免受痛苦的体力活、脏活。

这还不是全部。程序员这个群体还有一个独特的特点：他们天生就是病毒式传播的温床。他们坐在一起，会互相看对方屏幕用什么工具，哪个插件好，哪个主题酷。一传十，十传百。这种面对面的效应，是任何价格都无法比拟的优秀销售团队。这就是Cursor独特的产品主导增长模式的组成部分，一种几乎不可能在其他领域复制的增长。

### AGI与工具派的哲学之争

当整个行业都在为**AGI**（Artificial General Intelligence: 通用人工智能，指拥有与人类同等或超越人类智能水平的AI）而疯狂时，你甚至不能心平气和地问一个问题：“这个AGI到底有多大，影响有多深？”只要你问了，就是一种“你不懂行”的概念绑架。Cursor恰恰与这种疯狂相反。他们不关心遥远、模糊，甚至有点吓人的AGI。他们只关心一件事：AI是一个工具，一个用来解决特定问题的工具。

这不是很真实、很稀有吗？就像工具本身开始以指数级的速度进化一样。你这套实用主义哲学还能跟得上吗？问题不仅仅是说，这直接给所有AI应用公司判了“死刑”，因为AI的进化不仅仅是变聪明那么简单，它更像是一个胃口无限的巨兽，每天都在吞噬天量的文本、海量的算力和电力。这导致了一个更深刻的矛盾。

### AI发展的两大根本性挑战

一方面，Cursor这家公司拼命想让AI体验更实用、更便宜、更**样本复杂度**（Sample Complexity: 指AI模型学习一个概念或任务所需的训练数据量）低。说白了，就是笨。人类小孩看一两次猫就知道什么是猫了，现在的AI呢？你得喂给他几百万张图，他才能勉强分清。写代码也一样，人类高手看一两个例子就能举一反三，AI可能需要成千上万个范例才能学会。最新的模型像**GPT-4**（OpenAI开发的大型语言模型）在这个指标上跟人类比依然是天壤之别。

第二叫**美瓦智能**（Intelligence per Watt: 指每单位能耗产生的智能量，衡量AI的能源效率）。简单说就是耗电能耗。一个功耗大概是20瓦的小灯泡，AI呢？一次复杂的查询据说要消耗掉几升水来冷却。效率的差距是几十万倍。所以你看，当前的AI是强大，但他是一个“大黑胖子”式的强大，依靠海量的能源、海量的智能，全力以赴地输出。这带来了巨大的鸿沟。

乐观派说：“别慌，技术问题交给技术解决。你看，**Nvidia**（一家图形处理器和AI芯片公司）不是会不断推出更好的芯片来降低成本吗？”悲观派或者说现实派直接泼冷水，打破梦想：“硬件的物理极限很快就要来了。你看，Nvidia最新的**B200**（Nvidia的AI芯片）芯片，拆开来看不就是把两块上一代的**H100**（Nvidia的AI芯片）芯片放在一起吗？为了省电，我们已经把计算速度从32位降到了4位。你再降下去也没用了，就像最后一点的‘吹干’快要被吹干了。更重要的是，电力根本不够。你看数据中心建得跟大屏幕一样快，但你看核电站要建好几年。欧美几十年都没有认真搞能源基建，这个短板卡在所有人的脖子上。”

这个论点对于Cursor这样的公司来说是最能接受的。他们是悬挂在顶端的大型驾驶员。他们在AI工具化的道路上拥有所有的宝藏。但是，如果驱动工具的燃料，也就是大模型的成本不降低，甚至因为能源危机而上升，那么他们的整个商业模式就不会破产。所以，真正的破局点可能根本不在硬件上，而是在一个更根本的地方：我们能不能创造出一种更聪明的算法？一种不需要靠蛮力，而是更接近人脑工作方式的AI？一种每单位算力能产生更多智能的AI？这才是真正的胜者。当所有人都还在为电力和芯片吵得不可开交时，一些更聪明的脑袋已经开始在这条心路上狂奔了。而这条路又会把Cursor带向何方？

### 人脑的启示：更聪明的算法

那这个更聪明的算法在哪？到底长啥样？别急，答案还是要回到我们上面说的人脑上。咱们来做个算术题：人脑到底等于多少算力？有人估算过，大概在1-10个**Petaflops**（PFLOPS: 每秒千万亿次浮点运算，衡量计算速度的单位）之间。这个数字其实跟Nvidia最新的B200芯片在同一个数量级上。听起来，好像我们已经被追上了，对吧？但别忘了最要命的一点：功耗。咱们的大脑功耗多少？20瓦，一个昏暗的小灯泡。B200呢？1000瓦，不是一个热敏空调。这差了50倍还不止。为什么？人脑的神经元到底用了什么魔法？

首先，它使用了低电压策略。我们都知道，方波的频率和电压也更多地使用了一种叫做“习惯”的技巧。这意味着我们的大脑不是每时每刻都在全力运行，它大部分的神经元都在休息，只有在需要时才精确激活。这就像一个超高效的压缩算法，用最少的能量传递最多的信息。

你看，这把AI面临的两座大山清清楚楚地摆在了我们面前。第一座山叫**美瓦智能**，也就是能效比。对，看起来像个工程问题，也许我们能解决。怎么解决？换材料，不用硅了，用新的晶体管。现在已经有公司在朝这个方向猛攻了。虽然很难，但至少我们能看到一条模糊的路。

但第二座山才是真正的绝望之山，它叫**样本复杂度**，也就是我们前面说的AI太笨了，学东西太慢了。这个问题，它不是一个工程问题，它是一个纯粹的算法黑箱。我们的大脑到底隐藏着一种什么样的惊人自然学习算法？没有人知道。那是35亿年随机搜索和进化的结果，你不能指望工程师去计算、去重演它。你甚至连问题是什么都不清楚。就像一个游戏，你被扔了进去，但没有人告诉你规则是什么，目标是什么，你在玩什么。你甚至连第一步都迈不出去。

### AI的本质之争：工具、伙伴还是新物种？

这又回到了最根本的分析。当所有人都认为AI是一个可以不断优化的工具时，他们承认我们是那个拿着斧头的人，只要我们能把斧头磨得更锋利，我们就没问题。但样本复杂度告诉你这个问题：我们可能连数字是什么都不知道。我们甚至不知道我们手里拿的是不是一把斧头。这种底层奥秘也让AI圈开始了一场更深刻的灵魂之争：AI到底是什么？它是一个工具、一个伙伴，还是一个全新的物种？

这将彻底把AI圈一分为二。一边是仰望星空的AGI派。他们认为代码是第一张多米诺骨牌，一旦推倒，AI就会自我演化，一路狂奔，直到成为无敌的新物种。而另一边，则是脚踏实地的工具派。他们认为别想那么远，AI就是一把更好的锤子。既然是锤子，就得考虑怎么卖出去，怎么赚钱。

当AGI派还在纠结AI会不会产生自我意识时，工具派正在思考：在你的编辑器里，用什么疯狂的商业模式来定价？排名数据库公司直接在你的代码工具里，成为你的默认选项，打得头破血流，脑洞大开。但你仔细想想，这不就是谷歌广告的反向操作吗？一种无形的税收。你花在谷歌上的每一分钱，都有一部分悄无声息地流向了谷歌广告系统，但你却感受不到。这是最强大的地方：把成本分摊给所有人，让每个人都感受不到痛苦，但加起来却是一个商业帝国。这种极致的商业思维与那种无限智能的哲学，简直是冰与火的碰撞。

### Cursor的“快”哲学与产品演进

Cursor属于哪一边？他们也做了自己的模型，但目的不是为了冲向AGI，恰恰相反，是为了一个非常简单的原因：快。他们发现，当时市面上所有的AI助手都太慢了。问一个问题，它“吭哧吭哧”想半天，那个等待过程足以摧毁一个程序员最宝贵的专注力。所以他们绞尽脑汁去优化，让AI的响应速度足够快，快到你感受不到它的存在，就像空气一样，你需要时它就在。

这就是典型的工具型思维：“我不管AI未来有多智能，我只关心它现在好不好用。”这种务实甚至到了“无信仰”的地步。他们根本不信有什么终极的产品形态。今天用户觉得A好用，那他们就把IDE做到极致；明天要是用户觉得在命令行里敲自然语言更爽，那就去把命令行做到极致。做产品的人就应该随时准备革自己的命。这种灵活，这种对用户体验的偏执，才能让我们避开了那个关于AGI的宏大陷阱——那个听起来最性感的陷阱：AI写代码，AI自己测试，AI自己改进，无限循环，最终演化出通用人工智能。听起来是不是很完美？但现实是，这个所谓的自我进化循环根本跑不起来。

### 强化学习的争议与真实智能的缺失

因为在很多情况下，AI连它自己生成的代码的第一步都迈不出去，连最基本的测试都通不过。在一个没有奖励的环境中，你考40分，你如何让他像学生一样学习和改进？每次考试都交白卷，你指望他自己总结出危机点？你必须先手把手教他，给他一点小照片，让他至少及格。现在很多大公司都在这么做，用**强化学习**（Reinforcement Learning, RL: 一种机器学习方法，通过与环境互动，根据奖励信号学习最优策略）来“作弊”。这不是自我改进，这是作弊。

真正的智能，不是在一个封闭的工厂里，靠着刷题，而是对我们这个真实、复杂、混沌的世界，有深刻的理解和标准。而这，恰恰是AI最缺乏的。但AI真的理解这个世界吗？这个问题的答案，可能就藏在我们的DNA里。我们所有人类的DNA都压缩在几十万个字节里。一只猫跟我们92%的DNA相同，一只黑猩猩比我们高98%。就是那决定我们成为万物之灵的核心代码，那点死也只有几万几十万行的原始代码，创造了一个能学习微积分、能造火箭的大脑。而我们现在的大模型，它动辄几百G的训练数据砸进去，结果它还得依靠强化学习这个“拐杖”才能勉强走得更稳一点。

这是AI圈最激烈的争论：强化学习（RL）是神药还是毒药？反对派的观点简单粗暴：RL就是垃圾！它是一群走投无路的人才会用的烂技术。为什么？因为它自己根本不知道这个世界长什么样，它必须踩在已经通过**无监督学习**（Unsupervised Learning: 一种机器学习方法，在没有标签数据的情况下发现数据中的模式）构建起来的巨大坚实模型上才能发挥作用。说白了，就是用大模型的“学霸”来掩盖强化学习的“学渣”本质。图灵奖得主**Ian LeCun**（Yann LeCun：法国计算机科学家，图灵奖得主，Facebook AI首席科学家）有一个特别形象的比喻：AI这个蛋糕，无监督学习是蛋糕，是主体；**有监督学习**（Supervised Learning: 一种机器学习方法，通过带有标签的训练数据来学习）是奶油，在上面；而强化学习是蛋糕上的樱桃，作为点缀。它的作用是做最后的微调，告诉模型：“嘿，人类喜欢这样，不喜欢那样。”它很重要，但它绝不是蛋糕本身。

但支持派立刻跳出来：“你们都搞错了！问题根本不在RL，问题是我们太烂了，我们玩不转它！”我们现在所有的算法都继承自一种叫做“老思想”的旧范式，它只擅长解决那些平滑连续的问题。但真实世界不是，真实世界是零和一的残酷战场：要么你被狮子吃了，要么你活下来；要么你双赢成功，要么你失败。这里没有中间地带。我们的算法，遇到这种连续的、断崖式的难题，立刻就卡壳了。所以RL不是问题，它恰恰是把真实世界的残酷带给了我们，逼迫我们承认我们现有的数学工具已经走到了尽头。

### AI革命的哲学馈赠

那真正的智能如何解决这个问题？答案又回到了生物学。一只小鹿生下来就会跑，一只松鼠离开妈妈就知道埋坚果。这是自给自足系统的体现，是写在基因里的本能。这部分就是那个“蛋糕”，那个巨大的、不需要学习的、快速学习的知识。所以，真正的突破点不是回答“AI如何学习”这个真实问题，而是回答一个更根本的问题：当大脑这个算法运行时，一个婴儿是如何开始解决那些复杂问题的？

你看，我们兜了一个圈，从复杂的软件代码一路走到旁边，最终发现我们面对的不再是一个工程问题，甚至不是一个科学问题，它变成了一个哲学问题。我们建造了一个人脑，但最终，我们却不得不转过身，去面对我们自己大脑中最神秘的黑箱。这也许就是AI革命带给我们最意想不到的礼物。