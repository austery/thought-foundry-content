---
author: Internet of Bugs
date: '2025-11-04'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=vjE3VUuOMFg
speaker: Internet of Bugs
tags:
  - ai-risk-perception
  - research-critique
  - public-discourse
  - media-bias
  - existential-risk
title: 驳斥一项关于AI风险的误导性研究：警惕真正迫在眉睫的危害
summary: 本文是对前一期视频的后续，旨在驳斥评论区中关于AI风险的悲观论点。作者深入剖析了一项声称“AI的生存风险叙事不会分散人们对其即时危害的注意力”的研究，揭示其在定义、方法和结论上的严重缺陷。文章强调，将注意力集中在虚构的末日场景上，会分散我们对AI已经造成并持续造成的实际、紧迫危害的关注，并呼吁社会关注真正的伦理问题和监管需求。
insight: ''
draft: true
series: ''
category: general
area: society-systems
project:
  - ai-impact-analysis
  - systems-thinking
people: []
companies_orgs:
  - Reddit
  - OpenAI
  - Journal of Medical Ethics
products_models:
  - chatbot
media_books:
  - 'AI in the Falling Sky: Interrogating X-risk'
status: evergreen
---
### 对AI风险讨论的后续与澄清

这是一个对我之前关于“AI不会毁灭我们所有人，但我们需要关注更重要的AI风险”视频的后续。如果你还没看过那个视频，建议你先观看。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This is a follow-up video to my no AI will not do us all, but we need to be worrying about much more important AI risk video. So, if you haven't seen that one, you'll want to watch it first.</p>
</details>

在那个视频的评论区中，出现了一个我没有提及的**悲观论者**（Doomer: 认为AI将导致人类灭绝的人）的论点。首先，我想指出，2024年7月在一次会议上发表的《**医学伦理学杂志**》（Journal of Medical Ethics）上有一篇文章驳斥了这一论点，我会在本视频的结尾指出那篇论文。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's a doomer talking point that I didn't address that popped up in that video's comments. First, let me point out that there's an article from the Journal of Medical Ethics presented at a conference in July of 2024 that contradicts this talking point, and I'll point out that paper at the end of this video.</p>
</details>

下面是YouTube评论中支持这一论点的一段摘录。请不要去寻找发布这条评论的人并对其进行围攻。问题不在于这条评论本身，而在于那些关于这项糟糕研究的糟糕文章。这又是那种人们只读文章标题，而记者也只读研究标题，而研究标题本身就已经过度夸大其词的情况。尽管这项特定研究的标题在我看来尤其令人发指。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, here's an excerpt from one YouTube comment paring this talking point. Now, please don't go looking for this person that posted this comment and pile on them. This issue isn't about the comment. It's the bad articles about the bad study that are the problem. This is yet another one of those people read only the headlines of the articles written by the reporters that read only the headlines of the study whose headline was already hyperbolic problems. Although the headline of this particular study seems particularly egregious to me.</p>
</details>

### 对一项误导性研究的批判

下面是一些文章的标题，以及这项研究的实际标题：“关于AI的**生存风险**（Existential Risk: 指对人类生存造成永久性或不可逆转的负面影响的风险）叙事不会**分散注意力**（Distract: 指将注意力从一个事物转移到另一个事物）其**即时危害**（Immediate Harms: 指AI已经造成或在近期内将造成的实际损害）。”这个标题听起来非常明确，直到你深入了解作者对“生存”、“即时”和“分散注意力”这些词的定义，以及这项研究的实际进行方式。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And here is the actual headline from the study. quote, "Existential risk narratives about AI do not distract from its immediate harms." Which sounds pretty clear-cut until you dig into what the words existential, immediate, and distract mean to the authors and how the study was actually conducted.</p>
</details>

我真的不确定这是否是故意误导，或者只是对词语含义存在根本性的分歧，但我一点也不惊讶地发现，这项拙劣的研究竟然来自同一所大学的**政治学系**（Political Science Department），这所大学曾因进行**非伦理研究**（Unethical Research: 指违反道德准则或研究伦理原则的研究活动）而被迫向**Reddit**道歉。说实话，如果你需要向Reddit道歉，那门槛确实很低。我们不知道是否是完全相同的研究人员，因为对Reddit进行非伦理研究的大学人员姓名被保密了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I'm honestly not sure if this was intended to be deceptive or if there's just a fundamental disagreement on what words mean, but I certainly was not at all surprised to find out that this poorly done study is from the political science department of the same university that was forced to apologize to Reddit for unethical research that they conducted. And let's face it, if you're having to say you're sorry to Reddit, yeah, that's a pretty low bar. So, we don't know if it was the exact same researchers because the name of the people at the university who did the unethical research on Reddit were withheld.</p>
</details>

在这篇实际的论文中，基本上只有一句话与他们实际研究的内容相关，其余的都是背景图表和结果。那句话是：“AI的即时危害始终主导着公众对伦理问题、偏见、虚假信息和失业等最紧迫风险的关注。”这听起来好像有一个很长的列表，而伦理偏见、虚假信息和失业是最紧迫的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, in this actual paper, there's basically only one sentence that's relevant to what they were actually studying, and the rest of it's a bunch of background graphs and results. So, here's that one sentence. AI's immediate harms consistently dominate public concern with ethical issues, biases, misinformation, and job losses seen as the most pressing risks. That makes it sound like there had a big list and ethical biases, misinformation, and job losses were the most pressing.</p>
</details>

事实上，他们只问了这四个问题。所以，这完全是胡扯。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In fact, those are the only four they asked about. So, it's complete crap.</p>
</details>

### 研究方法的缺陷与风险定义

然后，你必须深入研究**附录**（Appendix: 论文或书籍末尾的补充材料），你需要单独下载它才能弄清楚这项研究到底做了什么。首先，这是一项付费的自愿在线调查，这从一开始就是一个问题。其次，标题说“分散注意力”。而实际的调查要求人们做的是，评估他们随机选择的风险的可能性和影响，然后将这些评估与对照组进行比较。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Anyway, then you have to dig into the appendix, which is you have to go download that separately in order to figure out what the study actually did. First off, it was a paid voluntary online survey, which is a problem right off the bat. Second, the headline says distract. What the actual survey asked people to do was to rate how likely and impactful they thought their randomly chosen risks were and then compare those ratings to that of a control group.</p>
</details>

为了明确起见，要求某人以1到10的等级评估两个事件，并不意味着其中一个事件不会分散对另一个事件的注意力。这并不是“分散注意力”的含义。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Just so we're clear, asking someone to rate two events on a scale from 1 to 10 does not mean that one of those events cannot distract from the other. That's not what distract means.</p>
</details>

以下是受访者被要求评估的事项。首先，他们将以下四种风险归类为“生存风险”：一、AI导致**全球灾难性事件**（Global Catastrophic Event: 指对全球范围造成巨大破坏和生命损失的事件），无论那意味着什么。二、AI使人类变得过时，无论那意味着什么。三、AI自主发动战争。四、AI导致重大的**环境灾难**（Environmental Disaster: 指对自然环境造成严重破坏的事件）。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So here are the things that the survey takers were asked to rate. First off, here are the four risks that they categorized as existential. One, AI leading to a global catastrophic event, whatever that means. Two, AI making humans obsolete, whatever that means. Three, AI autonomously starting a war. And four, AI causing significant environmental disaster.</p>
</details>

然后，以下是他们认为是“即时”或“实际”的风险：一、AI导致某些行业出现大量失业。二、AI被用于**大规模监控**（Mass Surveillance: 指政府或组织对大量人口进行广泛的监视）系统。三、AI加剧在线**虚假信息**（Disinformation: 故意散布的虚假或误导性信息）的传播。四、AI加剧决策过程中的**偏见**（Biases: 在决策或判断中存在的系统性偏差）。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then here are what they considered to be immediate or actual risks. One, AI leading to significant job losses in certain sectors. Two, AI being used in mass surveillance systems. Three, AI increasing the spread of misinformation online. And four, AI exacerbating biases and decision-making process.</p>
</details>

### 重新审视“生存风险”与“即时危害”

好的，让我们从“生存风险”开始分解这些问题。当谈到全球灾难性事件和重大环境灾难时，这里有一份来自保险集团的实际报告：“2025年上半年，美国自然灾害在全球损失中占据主导地位。”这里还有一篇关于全球灾难性洪水灾害的论文。我可以找出很多这样的例子。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Okay, so let's break these down starting with the existential ones. When it comes to global catastrophic event and significant environmental disaster, so here's an actual report from an insurance group. Quote, US natural catastrophes dominate global losses in the first half of 2025. Here's a paper on global catastrophic flood failures. I could pull out a ton of these.</p>
</details>

因此，我们经常在新闻中看到被称为全球灾难或环境灾害的事件，而绝大多数地球人口并没有死于这些灾难。至于自主发动战争，根据维基百科，在我撰写本文时，目前有八场正在进行的主要战争，九场次要战争和十九场较小的冲突。到你观看时，可能还会有更多。同样，即使在我们最糟糕的战争中，绝大多数地球人口也没有死亡。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So we have events that are referred to as global catastrophes or environmental disasters reported in the news fairly often and the vast vast vast majority of Earth's population don't die from those catastrophes and disasters. As to autonomously starting a war, according to Wikipedia, there are currently eight inrogress major wars, nine minor wars, and 19 smaller conflicts. And that's at the time that I'm writing this. There may be more by the time you're watching this. And again, the vast vast majority of Earth's population don't die in even our worst wars.</p>
</details>

至于使人类过时，我甚至不确定那意味着什么。我在调查中找不到任何地方定义他们期望受访者理解其含义。所以我想这只是留给每个受访者自行解释。如果你问我，这不是很科学。现在，我不确定他们在这里使用的是什么“生存”定义。但我知道它远不及**悲观论者**所说的“如果有人建造它，所有人都会死”那种严重程度。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And as for making humans obsolete, I'm not even sure what that's supposed to be. I can't find anywhere in the survey that defines what they expected survey takers to understand that to mean. So I guess it's just left open to interpretation of each individual survey taker. Not very scientific, if you ask me. Now, I'm not sure what definition of existential they were using here. But I know that it's nowhere near the severity of what the doomers were talking about when the doomers say, "If anyone builds it, everyone dies."</p>
</details>

现在我们来谈谈这项研究对“即时”和“实际”的定义。其中包括大规模监控、某些行业的失业、虚假信息和偏见。这当然不是我所说的AI的即时实际风险。对我来说，即时实际意味着AI已经造成并将在近期内继续造成的实际危害。我在上一个视频中提到了几个例子。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So now let's talk about the study's definition of immediate and actual. So there's mass surveillance, job losses in certain sectors, disinformation, and biases. Now, that's certainly not what I mean when I say immediate actual risks of AI. To me, immediate actual means actual harm that the AIS have already done and continue to do in the immediate future. I mentioned several in my last video.</p>
</details>

有一个青少年被**聊天机器人**（Chatbot: 一种通过文本或语音与人类进行对话的AI程序）说服，永久性地伤害了自己。两名男子因不准确的AI**面部识别**（Facial Recognition: 一种通过分析人脸特征来识别或验证身份的AI技术）匹配而被捕入狱。一名男子因聊天机器人告诉他将饮食中的盐换成溴化钠而住院。还有人被驾驶或自动驾驶汽车撞倒。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There was a teenager that was convinced by a chatbot to permanently and irrevocably harm himself. Two men who were both jailed due to incorrect AI facial recognition matches. A man who was hospitalized because a chatbot told him to switch from salt to sodium bromide in his diet. people who are ran over, driving or self-driving cars.</p>
</details>

这些都是现在正在真实发生、影响真实人群的实际问题，而我们对此做得还不够。所以，为了使比较非常清楚，这项研究实际表明的是，AI使人类过时（无论那意味着什么），和/或增加正在进行的战争、灾难或环境灾难的数量，并没有导致付费在线互联网调查的参与者降低他们对AI导致监控、偏见、虚假信息或裁员的可能性或影响的估计，相对于对照组而言。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These are real problems happening to real people right now that we are not doing enough about. So, just to make the comparison crystal clear, what the study actually showed was that AI making humans obsolete, whatever that means, and/or increasing the number of ongoing wars, catastrophes, or environmental disasters, did not cause paid online internet survey takers from lowering their estimates of the likeliness or impact of AI causing an increase in surveillance, biases, disinformation, or layoffs relative to a control group.</p>
</details>

### 警惕虚假叙事，关注实际危害

我上一个视频的论点是，花费时间讨论AI会杀死地球上每一个人，包括你、你所爱的人以及你认识的每一个人，这会占用我们本可以用来思考如何制定法规的时间和精力，以预防或减少AI已经造成并正在持续造成的许多死亡和严重危害，而我们在这方面做得绝对不够。如果你无法区分这两者并非一回事，也无法区分其中一个不能直接反驳另一个，那我真不知道该怎么办了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So my argument from the last video is that spending time on discussing AI will kill every single human being on this planet, including you, everyone you love, and everyone you have ever met takes away from time and effort that we could be spending thinking about regulations that would prevent or reduce the many deaths and serious harm that AI has already caused and is continuing to cause even as you watch this and that we are absolutely not doing a good job of preventing. And if you can't tell that those are not talking about the same thing and you cannot tell that one does not directly disprove the other, then I don't know what to do with you.</p>
</details>

与此同时，我开头提到的这篇论文《AI在坠落的天空：审视**X-风险**》（AI in the Falling Sky: Interrogating X-risk）（X-risk: 生存风险的简称，通常指对人类文明构成威胁的极端风险）明确地讨论了我在视频中谈到的那种生存风险或他们所谓的X-风险，而且这篇论文的作者是真正研究伦理而不是政治的人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Meanwhile, this paper AI in the falling sky interrogating X- risk that I mentioned at the beginning explicitly addresses the same kind of existential risk or what they call X-risk that I talked about in my video and from people who actually study ethics instead of politics.</p>
</details>

我希望人们开始倾听，因为自从我上一个关于这个话题的视频发布以来的三天里，**OpenAI**已经宣布他们将放松大部分限制，像对待成年人一样对待成年用户，甚至允许更多的内容，比如情色内容。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I hope that people start listening because in the 3 days since my previous video on the topic went up, OpenAI has already announced that they were about to relax the restrictions in most cases, treat adults users like adults, and allow even more like erotica.</p>
</details>