---
area: "society-thinking"
category: technology
companies:
- immediate-harm
companies_orgs:
- OpenAI
- Reddit
date: '2025-11-05'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- Journal of Medical Ethics
- AI in the Falling Sky
project: []
series: ''
source: https://www.youtube.com/watch?v=vjE3VUuOMFg
speaker: Internet of Bugs
status: evergreen
summary: 本文是对“AI不会毁灭我们所有人”视频的后续，旨在驳斥一项关于AI风险的“糟糕研究”。该研究声称AI的“生存风险叙事”不会分散人们对“即时危害”的注意力，但作者通过深入分析其方法论，揭示了该研究的诸多缺陷，包括定义模糊、问题设置片面以及调查方式不严谨。文章强调，过度关注遥远的“AI末日论”反而会分散我们对AI已造成和正在造成的实际、即时危害（如误导性信息、偏见、失业、甚至人身伤害）的关注，并呼吁将精力投入到制定有效的AI监管措施上。
tags:
- existential-risk
- public
- research
- risk
title: 驳斥AI末日论：警惕被误导的研究与被忽视的即时危害
---
### 引言：对AI风险研究的后续讨论

这是一个对我之前“AI不会毁灭我们所有人，但我们需要关注更重要的AI风险”视频的后续。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This is a follow-up video to my no AI will not do us all, but we need to be worrying about much more important AI risk video.</p>
</details>
所以，如果你还没看过那个视频，你会想先看它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, if you haven't seen that one, you'll want to watch it first.</p>
</details>
有一个我没有提及的**末日论者**（Doomer: 认为AI将导致人类灭绝的人）的论点，出现在那个视频的评论中。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's a doomer talking point that I didn't address that popped up in that video's comments.</p>
</details>
首先，我想指出，《**医学伦理学杂志**》（Journal of Medical Ethics）上有一篇文章，在2024年7月的一次会议上发表，它与这个论点相悖，我会在本视频的最后指出那篇论文。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">First, let me point out that there's an article from the Journal of Medical Ethics presented at a conference in July of 2024 that contradicts this talking point, and I'll point out that paper at the end of this video.</p>
</details>
所以，这里是YouTube评论中支持这个论点的一段摘录。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, here's an excerpt from one YouTube comment paring this talking point.</p>
</details>
现在，请不要去寻找发布这条评论的人并攻击他们。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now, please don't go looking for this person that posted this comment and pile on them.</p>
</details>
这个问题不是关于评论本身。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This issue isn't about the comment.</p>
</details>
问题在于那些关于这项“糟糕研究”的“糟糕文章”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's the bad articles about the bad study that are the problem.</p>
</details>
这又是那种人们只读记者撰写的文章标题，而记者又只读研究标题的情况，而研究标题本身就已经存在夸大其词的问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This is yet another one of those people read only the headlines of the articles written by the reporters that read only the headlines of the study whose headline was already hyperbolic problems.</p>
</details>
尽管这项特定研究的标题在我看来尤其令人震惊。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Although the headline of this particular study seems particularly egregious to me.</p>
</details>
所以，这里是一些文章的标题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, here are some of the article headlines.</p>
</details>

### 对“生存风险叙事”研究的批判

而这是这项研究的实际标题，引用：“关于AI的**生存风险**（Existential Risk: 指可能导致人类文明永久性或彻底崩溃的风险）叙事不会分散人们对其**即时危害**（Immediate Harms: 指AI目前已造成或在短期内可能造成的实际损害）的注意力。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And here is the actual headline from the study. quote, "Existential risk narratives about AI do not distract from its immediate harms."</p>
</details>
这听起来非常明确，直到你深入了解“生存”、“即时”和“分散注意力”这些词对作者来说意味着什么，以及这项研究是如何实际进行的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Which sounds pretty clear-cut until you dig into what the words existential, immediate, and distract mean to the authors and how the study was actually conducted.</p>
</details>
我真的不确定这是否是故意欺骗，或者只是对词义存在根本性的分歧，但我一点也不惊讶地发现，这项做得如此糟糕的研究来自同一所大学的政治学系，该大学曾因进行不道德的研究而被迫向**Reddit**道歉。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I'm honestly not sure if this was intended to be deceptive or if there's just a fundamental disagreement on what words mean, but I certainly was not at all surprised to find out that this poorly done study is from the political science department of the same university that was forced to apologize to Reddit for unethical research that they conducted.</p>
</details>
说实话，如果你不得不向Reddit道歉，那门槛确实很低。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And let's face it, if you're having to say you're sorry to Reddit, yeah, that's a pretty low bar.</p>
</details>
所以，我们不知道是否是完全相同研究人员，因为对Reddit进行不道德研究的大学人员姓名被隐瞒了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, we don't know if it was the exact same researchers because the name of the people at the university who did the unethical research on Reddit were withheld.</p>
</details>
所以，在这篇实际的论文中，基本上只有一句话与他们实际研究的内容相关，其余的都是一堆背景图表和结果。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, in this actual paper, there's basically only one sentence that's relevant to what they were actually studying, and the rest of it's a bunch of background graphs and results.</p>
</details>
所以，这是那句话：“AI的即时危害持续主导公众关注，其中伦理问题、偏见、**虚假信息**（Disinformation: 指故意传播的错误信息，旨在欺骗或误导）和失业被视为最紧迫的风险。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, here's that one sentence. AI's immediate harms consistently dominate public concern with ethical issues, biases, misinformation, and job losses seen as the most pressing risks.</p>
</details>
这听起来好像有一个很长的列表，而伦理偏见、虚假信息和失业是最紧迫的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That makes it sound like there was a big list and ethical biases, misinformation, and job losses were the most pressing.</p>
</details>
事实上，他们只问了这四项。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In fact, those are the only four they asked about.</p>
</details>
所以，这完全是胡扯。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, it's complete crap.</p>
</details>
无论如何，你还得深入研究附录，你必须单独下载它才能弄清楚这项研究到底做了什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Anyway, then you have to dig into the appendix, which is you have to go download that separately in order to figure out what the study actually did.</p>
</details>
首先，它是一项付费的自愿在线调查，这从一开始就是一个问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">First off, it was a paid voluntary online survey, which is a problem right off the bat.</p>
</details>
其次，标题说“分散注意力”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Second, the headline says distract.</p>
</details>
实际调查要求人们做的是评估他们随机选择的风险的可能性和影响，然后将这些评估与对照组进行比较。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What the actual survey asked people to do was to rate how likely and impactful they thought their randomly chosen risks were and then compare those ratings to that of a control group.</p>
</details>
为了说清楚，要求某人以1到10的等级评估两个事件，并不意味着其中一个事件不能分散对另一个的注意力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Just so we're clear, asking someone to rate two events on a scale from 1 to 10 does not mean that one of those events cannot distract from the other.</p>
</details>
那不是“分散注意力”的意思。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That's not what distract means.</p>
</details>

### 研究中对风险的定义与质疑

所以，这里是调查参与者被要求评估的事项。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So here are the things that the survey takers were asked to rate.</p>
</details>
首先，这里是他们归类为**生存风险**的四种风险。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">First off, here are the four risks that they categorized as existential.</p>
</details>
一、AI导致全球灾难性事件，无论那意味着什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One, AI leading to a global catastrophic event, whatever that means.</p>
</details>
二、AI使人类过时，无论那意味着什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Two, AI making humans obsolete, whatever that means.</p>
</details>
三、AI自主发动战争。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Three, AI autonomously starting a war.</p>
</details>
四、AI造成重大环境灾难。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And four, AI causing significant environmental disaster.</p>
</details>
然后，这里是他们认为是**即时或实际风险**的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then here are what they considered to be immediate or actual risks.</p>
</details>
一、AI导致某些行业出现大量失业。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One, AI leading to significant job losses in certain sectors.</p>
</details>
二、AI被用于**大规模监控**（Mass Surveillance: 指政府或组织对大量人口进行系统性、广泛的监视活动）系统。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Two, AI being used in mass surveillance systems.</p>
</details>
三、AI增加在线**虚假信息**的传播。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Three, AI increasing the spread of misinformation online.</p>
</details>
四、AI加剧决策过程中的**偏见**（Biases: 指在AI决策过程中因训练数据或算法设计缺陷导致的系统性不公平或歧视）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And four, AI exacerbating biases and decision-making process.</p>
</details>
好的，让我们从生存风险开始分析这些。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Okay, so let's break these down starting with the existential ones.</p>
</details>
当谈到全球灾难性事件和重大环境灾难时，这里有一份来自保险集团的实际报告，引用：“2025年上半年，美国自然灾害在全球损失中占据主导地位。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When it comes to global catastrophic event and significant environmental disaster, so here's an actual report from an insurance group. Quote, US natural catastrophes dominate global losses in the first half of 2025.</p>
</details>
这里有一篇关于全球灾难性洪水灾害的论文。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Here's a paper on global catastrophic flood failures.</p>
</details>
我能找出很多这样的例子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I could pull out a ton of these.</p>
</details>
所以，我们有新闻中经常报道的被称为全球灾难或环境灾害的事件，而地球上绝大多数人口并没有死于这些灾难。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So we have events that are referred to as global catastrophes or environmental disasters reported in the news fairly often and the vast vast vast majority of Earth's population don't die from those catastrophes and disasters.</p>
</details>
至于自主发动战争，根据维基百科，目前有八场正在进行的主要战争，九场次要战争，以及19场较小的冲突。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">As to autonomously starting a war, according to Wikipedia, there are currently eight inrogress major wars, nine minor wars, and 19 smaller conflicts.</p>
</details>
这还是在我撰写此文时的数据。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's at the time that I'm writing this.</p>
</details>
当你观看时可能更多。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There may be more by the time you're watching this.</p>
</details>
再次强调，即使在我们最糟糕的战争中，地球上绝大多数人口也没有死亡。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And again, the vast vast majority of Earth's population don't die in even our worst wars.</p>
</details>
至于使人类过时，我甚至不确定那应该是什么意思。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And as for making humans obsolete, I'm not even sure what that's supposed to be.</p>
</details>
我在调查中找不到任何地方定义了他们期望调查参与者理解其含义。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I can't find anywhere in the survey that defines what they expected survey takers to understand that to mean.</p>
</details>
所以我想，这只是留给每个调查参与者自行解释。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So I guess it's just left open to interpretation of each individual survey taker.</p>
</details>
如果你问我，这很不科学。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Not very scientific, if you ask me.</p>
</details>
现在，我不确定他们在这里使用的是什么“生存”定义。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now, I'm not sure what definition of existential they were using here.</p>
</details>
但我知道它远不及那些**末日论者**所说的“如果有人建造它，所有人都会死”的严重程度。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But I know that it's nowhere near the severity of what the doomers were talking about when the doomers say, "If anyone builds it, everyone dies."</p>
</details>

### 真正的即时危害与被误导的关注点

所以现在我们来谈谈这项研究对“即时”和“实际”的定义。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So now let's talk about the study's definition of immediate and actual.</p>
</details>
有**大规模监控**、某些行业的失业、**虚假信息**和**偏见**。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So there's mass surveillance, job losses in certain sectors, disinformation, and biases.</p>
</details>
这当然不是我所说的AI的“即时实际风险”的意思。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now, that's certainly not what I mean when I say immediate actual risks of AI.</p>
</details>
对我来说，“即时实际”意味着AI已经造成并将在近期继续造成的实际伤害。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">To me, immediate actual means actual harm that the AIS have already done and continue to do in the immediate future.</p>
</details>
我在上一个视频中提到了几个例子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I mentioned several in my last video.</p>
</details>
有一个青少年被**聊天机器人**（chatbot: 一种通过文本或语音与用户进行对话的AI程序）说服，永久性地伤害了自己。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There was a teenager that was convinced by a chatbot to permanently and irrevocably harm himself.</p>
</details>
两名男子因不正确的AI**面部识别**（Facial Recognition: 一种通过分析人脸特征来识别或验证个体身份的技术）匹配而被监禁。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Two men who were both jailed due to incorrect AI facial recognition matches.</p>
</details>
一名男子因**聊天机器人**告诉他将饮食中的盐换成溴化钠而住院。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A man who was hospitalized because a chatbot told him to switch from salt to sodium bromide in his diet.</p>
</details>
还有人被驾驶或自动驾驶汽车撞倒。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">people who are ran over, driving or self-driving cars.</p>
</details>
这些都是真实的问题，正在真实的人身上发生，而我们对此做得还不够。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These are real problems happening to real people right now that we are not doing enough about.</p>
</details>
所以，为了让比较清晰明了，这项研究实际表明的是：AI使人类过时（无论那意味着什么），和/或增加正在发生的战争、灾难或环境灾害的数量，并没有导致付费在线互联网调查参与者降低他们对AI导致**大规模监控**、**偏见**、**虚假信息**或裁员的可能性或影响的估计，相对于对照组而言。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, just to make the comparison crystal clear, what the study actually showed was that AI making humans obsolete, whatever that means, and/or increasing the number of ongoing wars, catastrophes, or environmental disasters, did not cause paid online internet survey takers from lowering their estimates of the likeliness or impact of AI causing an increase in surveillance, biases, disinformation, or layoffs relative to a control group.</p>
</details>
所以，我上一个视频的论点是，花时间讨论AI会杀死地球上每一个人，包括你、你所爱的人以及你遇到过的每一个人，这会占用我们本可以用来思考如何制定法规以防止或减少AI已经造成并正在持续造成的许多死亡和严重伤害的时间和精力，而我们在这方面做得绝对不够好。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So my argument from the last video is that spending time on discussing AI will kill every single human being on this planet, including you, everyone you love, and everyone you have ever met takes away from time and effort that we could be spending thinking about regulations that would prevent or reduce the many deaths and serious harm that AI has already caused and is continuing to cause even as you watch this and that we are absolutely not doing a good job of preventing.</p>
</details>
如果你无法分辨这些不是在谈论同一件事，并且你无法分辨一个不能直接反驳另一个，那我不知道该拿你怎么办。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if you can't tell that those are not talking about the same thing and you cannot tell that one does not directly disprove the other, then I don't know what to do with you.</p>
</details>

### 伦理学视角与AI发展现状

与此同时，我开头提到的那篇论文《**AI在坠落的天空：审视X风险**》（AI in the Falling Sky: Interrogating X-risk），明确地讨论了我在视频中谈到的那种**生存风险**，或者他们称之为**X风险**（X-risk: 存在风险的缩写，通常指对人类生存构成威胁的风险），而且这些是来自真正研究伦理学而不是政治学的人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Meanwhile, this paper AI in the falling sky interrogating X- risk that I mentioned at the beginning explicitly addresses the same kind of existential risk or what they call X-risk that I talked about in my video and from people who actually study ethics instead of politics.</p>
</details>
我希望人们开始倾听，因为自从我上一个关于这个话题的视频发布以来的三天里，**OpenAI**已经宣布他们将放松大部分限制，像对待成年用户一样对待成年人，甚至允许更多的色情内容。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I hope that people start listening because in the 3 days since my previous video on the topic went up, OpenAI has already announced that they were about to relax the restrictions in most cases, treat adults users like adults, and allow even more like erotica.</p>
</details>