---
author: TED
date: '2026-01-20'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=81slns4Dte8
speaker: TED
tags:
  - generative-film
  - storytelling
  - film-technology
  - digital-art
title: 颠覆叙事：生成式电影的无限可能
summary: 独立电影制作人 Gary Hustwit 探讨了传统电影的局限性，并介绍了其开创性的生成式电影项目《Eno》。该项目通过算法动态生成影片内容，使每次放映都呈现独一无二的故事版本，颠覆了固定观影体验，并预示着电影叙事和观众互动的新纪元。
insight: ''
draft: true
series: ''
category: ai-application
area: tech-engineering
project: []
people:
  - Brian Eno
companies_orgs: []
products_models:
  - Eno
media_books: []
status: evergreen
---
### 传统电影的局限与生成式叙事的曙光

作为一名拥有二十年经验的独立电影制作人，我长期以来专注于创作关于设计、艺术和音乐的纪录片，但其核心始终是人。然而，随着时间的推移，我开始审视纪录片创作的固有局限性。人类本身是多维度的，关于任何一个人的故事，绝非单一版本。纪录片，其本质上是一种“还原”的艺术，无论多么精良，呈现的都只是真实故事的冰山一角。这促使我思考：一部电影能否讲述不止一个故事？甚至，能否讲述成千上万个关于其主体故事？我们如何才能重新构想纪录片，使其像人类一样，拥有丰富的多面性？

这正是我团队和我一直在探索的方向。去年，我们发布了一部名为《Eno》的电影。它是一部关于音乐家兼艺术家**布莱恩·伊诺（Brian Eno）**的纪录片，但其最独特之处在于——它每次放映时都会发生变化。这是世界上第一部**生成式（generative）**长片，拥有数十亿种可能的变体。它始终是关于布莱恩·伊诺的故事，但每一次观看，都是一个全新的叙事。

这自然会引发一系列问题：“电影是如何变化的？”“它为何要变化？”“如果我的朋友看到一个截然不同的版本，我该如何与他讨论这部电影？”又或者，“加里，你为什么要这么做？我们喜欢电影原本的样子。”

我们都热爱电影，一生中观看过数百甚至数千部影片，并拥有自己的最爱。但所有这些电影都有一个共同点：它们都是**线性、固定**的体验。它们有始有终，且每次观看的内容都完全一致。但我们是否曾想过，为何会如此？为何电影必须每次都一样？

究其原因，这实际上源于130年前电影诞生之初的一个技术限制。那时，电影是一种物理媒介——一卷赛璐珞胶片，必须通过摄影机和放映机滚动播放。制作方需要复制这些胶片卷，然后将其发送到各个影院。然而，在25到30年前，随着电影制作全面转向数字化，这种物理媒介的限制已不复存在。但我们却依然沿袭着旧有的制作模式，仿佛还在遵循一本早已失效的规则手册。

因此，在2019年，我联系了居住在英国的数字艺术家**布兰登·道斯（Brendan Dawes）**，我们开始进行实验。我们希望探索是否能用软件动态生成一部电影，利用真实素材，使其每次都能讲述一个不同的故事。我们构建了一个完全由人工编写代码的生成式视频平台，它并非基于AI模型或他人作品的训练。在实验过程中，我们开始思考，谁将是第一部生成式电影的理想主角。然后，我们联系了这个人。

<details>
<summary>Original English</summary>

As an independent filmmaker with 20 years of experience, I've been making documentaries about design, art, and music, but they're really about people. Over the years, I started to question the limitations of documentary filmmaking. Human beings are multidimensional; there's never just one story about any of us. A documentary film is, by its nature, reductive. Any documentary you've ever seen is just a tiny sliver of the actual story. But what if a film could tell more than one story? Or what if one film could tell thousands of stories about its subject? How could we reenvision documentaries so that they were as multifaceted as human beings are?

Well, that’s what my team and I have been working on. And last year, we released a film called "Eno." It's a documentary about the musician and artist **Brian Eno** that changes every time it's shown. It's the world's first **generative feature film**, and there are billions of possible variations of it. It's always a story about Brian Eno, it's just a different story every time you watch it.

So you probably have some questions, like, "How does the film change?" "Why does the film change?" "How do I talk to my friend about a movie if they've seen a totally different version of it?" Or, "Why are you doing this to us, Gary? We like our movies the way they are."

Yes, we all love movies. We've watched hundreds of them in our lifetime, thousands, probably. And we have our favorites. But there's one thing that all of these movies have in common: They are all linear, fixed experiences. There's a beginning and an end, and they're the same every time we watch them. But have you ever wondered why? Like, why do films have to be the same every time?

The reason is actually a technical constraint from 130 years ago, when cinema was born and film was a physical medium, a reel of celluloid images that had to scroll through cameras and projectors, and they had to make duplicate copies of those reels and send them out to theaters. But 25 or 30 years ago, when filmmaking all went digital, suddenly, this constraint of physicality is gone, but we've continued to make movies kind of in the same way we always have. It's like we're playing by a rule book that doesn't exist anymore.

So in 2019, I reached out to **Brendan Dawes**, who is a digital artist in England, and we started experimenting. We wanted to see if we could make a cinematic documentary that was created dynamically in software, with real footage, that could tell a different story each time. We built a generative video platform that was entirely human-coded. It wasn't an AI model based or trained on other people's work. And as we were experimenting, we realized, like, who the ideal subject would be for the first generative film. And then, we reached out to this guy.
</details>

### 《Eno》项目的诞生：合作与布莱恩·伊诺的独特角色

（视频片段：询问全名）
视频：Can you tell us your full name?
视频：Brian Peter George St John the Baptist de la Salle Eno.

我们将在本次演讲中采用他名字的简称。布莱恩·伊诺在过去50年里，一直是创造力与技术边界的探索者。从他在**Roxy Music**乐队的电子音乐实验，到与**大卫·鲍伊（David Bowie）**合作录制《Heroes》等专辑，再到担任**Talking Heads**、**U2**、**Laurie Anderson**、**Grace Jones**等众多艺术家的制作人，他发行了超过40张个人及合作专辑。早在生成式AI出现之前的1990年代，布莱恩就已经在创作软件以生成音乐。他将此比作播下一段音乐的种子，然后让这段音乐在漫长的时间里，以数千种不同的方式绽放，仿佛音乐是一种生命体。

事实上，我早在几年前就曾就制作一部普通纪录片与布莱恩接触过，但他拒绝了，他也拒绝了许多其他电影制作人。但他拒绝的理由非常引人入胜。他说他憎恶传记式纪录片，因为那总是某一个人的视角来讲述另一个人的故事，而一个人身上从来就不止一个故事。但布兰登和我认为我们找到了解决方案，并向他展示了我们生成式电影软件的早期演示版本。他对此感到非常兴奋。我仍然不认为他真的想拍一部关于自己的电影，但他渴望参与到这个生成式电影的实验中来，而这便是他必须付出的代价。（笑声）

布莱恩为我们提供了数以百计小时的**档案影像资料**，涵盖了你能想象到的所有过时录像带格式。仅仅是数字化和编目这些素材，我们就花了两年时间。但要讲述这个故事，我们需要的不仅仅是档案影像。于是，我又花了50个小时与布莱恩一同拍摄，让他谈论他的创作过程。最终，我们为这个生成式软件平台积累了超过500小时的素材。

<details>
<summary>Original English</summary>

(Music)
Video: Can you tell us your full name?
Video: Brian Peter George St John the Baptist de la Salle Eno.
(Electronic sound)
GH: We'll just use his shortened form of his name for this talk.
So, Brian, for the past 50 years, has been pushing the boundaries of creativity and technology, from his electronic music experiments in **Roxy Music** to his collaborations with **David Bowie** on records like "Heroes," to producing **Talking Heads**, **U2**, **Laurie Anderson**, **Grace Jones**, so many others. And he's released over 40 solo and collaboration records. And in the 1990s, long before generative AI, Brian was making software to create generative music. He likened it to planting the seeds for a piece of music, and then letting that piece of music flower in thousands of different ways over the course of time. It was like the music was a living thing.

Now I’d actually approached Brian several years before this about doing a normal documentary, and he turned me down, and he turned down a lot of filmmakers. But his reason was really fascinating. He said he hated biographical documentaries because it was always one person's version of another person's story, and there was never just one story about anyone. But Brendan and I thought we had a solution to this, and we showed him an early demo of our generative film software, and he was really excited. I still don't think he wanted to have a movie made about him, but he wanted to be part of this generative film experiment, and that was the price that he had to pay. (Laughs)
Brian gave us access to hundreds of hours of archival footage on every obsolete videotape format imaginable. It took us two years just to digitize and catalog all this stuff, but we needed more than just archival footage to tell this story. So I filmed another 50 hours with Brian talking about his creative process. In the end, we had over 500 hours of material for this generative software platform.
</details>

### 生成式电影的工作机制：从数据到动态叙事

接下来，我将展示它是如何运作的。我们从一个包含编辑过的场景、原始素材和音乐的数据集中开始。系统会从中选取片段，并将它们构建成一部时长约85到90分钟的电影。系统了解所有这些片段的内容，并知道如何将它们组织成一个流畅的故事。它还能实时动态地创建场景之间的过渡。

对我们而言，最大的挑战在于如何确保影片的每一个版本都能拥有一个引人入胜的故事弧线，无论其中包含哪些独立的片段。电影制作人以控制欲强著称，但我仍然拥有控制权，只是这种控制体现在一个更高的层面。我负责策划所有可能被纳入系统的零散片段，并设计它们之间无限的互动方式。因此，我无法控制每一部独立电影的具体内容，但这并不重要，因为系统始终能正常运作——这是我们设计使然。而且，每次观看自己的电影时，我都能获得惊喜，这既疯狂又极其解放。

如果你有500小时的素材需要压缩成一部90分钟的电影，这便是你最终留下的东西——所谓的“剪辑室地板”（cutting-room floor）上的残余。通常在电影制作中，你必须抛弃所有其他素材，将其缩减到规定时长，这便是所谓的“杀死你的宠儿”（killing your darlings）。但在我们这种方法中，根本不存在“剪辑室地板”。我可以放入任意多的素材，它们会在不同版本的电影中以各种方式呈现出来。

所以，这不像是一个“选择你自己的冒险”故事。更确切地说，更像是“冒险在选择你”。但我们还内置了另一项非常酷的功能：在影片的任何一个迭代版本中，**Laurie Anderson**或**David Byrne**都会出现，并选择一张布莱恩的“**Oblique Strategies**”（间接策略）卡片。这些卡片就像是随机的提示，当你陷入创作困境时可以阅读它们。卡片有几十种，根据影片中出现哪一张，它会引导电影走向不同的方向或做出某种反应。下面我将展示它是如何工作的。

（展示卡片示例）
Laurie Anderson: Retrace your steps.
(Music)
David Byrne: Turn it upside down.
(Music)
LA: Gardening. Not architecture.
BE: So this is Cotinus. That's a family of plants that I like a lot. In fact, in this garden, we have a lot of Cotinus, a lot of dogwood.

屏幕上显示的这些代码，是我们系统在解析数据集、遍历所有文件名，并决定下一步选择什么。

<details>
<summary>Original English</summary>

And I'll show you how that works. We start off with a data set of edited scenes, raw footage and music, and the system selects pieces from that material and builds them into a film that's probably 85 to 90 minutes long. Now the system knows what all the contents of these pieces are, and it knows how to arrange them into a good story flow. It also creates transitions between the scenes dynamically, in real time. The biggest challenge for us was how to make it so that every version of the film had an engaging story arc, regardless of what individual pieces were in it. Filmmakers are notoriously control freaks, but I still have control. But it's on this higher level. Like I’m curating all the different little pieces that could go into this system, and I'm also designing the limitless ways that they can interact. So I don't have control over the contents of each individual film, but it doesn't matter, because it always works. We've designed it that way. And I get to be surprised by my own film every time I watch it, which is crazy and so liberating.

If you have 500 hours of footage you got to get down to a 90-minute film, this is what you're left with. It's the cutting-room floor thing. Normally in a film, you'd have to get rid of all that other footage and get it down to that time thing. "Killing your darlings" is what they say. But in this approach, there is no cutting-room floor. I can put as much material in, and it will come up in different versions of the film in different ways. So it's not like a "choose your own adventure." Well actually, it’s more like the adventure choosing you.

But another thing that we built in that's really cool is that, in any iteration of the film, in every one, either **Laurie Anderson** or **David Byrne** will appear and choose one of Brian's "**Oblique Strategies**" cards. These are, like, random prompts. If you're in a creative bind, you can read them. So there's dozens of them, and depending on which one comes up in the film, it will divert the movie or react in some way. So I'll show you how that works.
[Oblique Strategies]
Laurie Anderson: Retrace your steps.
(Music)
David Byrne: Turn it upside down.
(Music)
LA: Gardening. Not architecture.
BE: So this is Cotinus. That's a family of plants that I like a lot. In fact, in this garden, we have a lot of Cotinus, a lot of dogwood.

GH: There are many more cards and many more directions that they can push the film. The code that we've been seeing on screen is our system parsing the data set and going through all the file names, and deciding what it's going to choose next.
</details>

### 重新定义电影：反响、行业影响与未来展望

我们首次公映这部电影是在**圣丹斯电影节（Sundance Film Festival）**，此后在全球数百家影院放映，而每一次放映，都是一个不同的版本。每一位观众看到的，都是为他们量身定制的电影，是世界上其他任何观众都无法看到的。人们会回来观看三、四次，甚至十次、二十次，只为看不同的版本，每一次都能从中发现布莱恩故事的另一层含义。然后他们会和朋友讨论，比较各自看到的版本：“你看到大卫·鲍伊的那个场景了吗？”“没有，我没看到。”这是一种全新的观影方式。

（笑声）我竟然把最重要的消息放在了后面。（欢呼与掌声）哦天哪，我把最重要的消息放在了后面。（欢呼与掌声）

但问题在于，究竟是什么被提名了？是那数十亿个不同版本中的哪一个？还是全部？没人真正知道。但这些都是**电影行业**和**好莱坞**即将必须回答的问题。

现在，我们正在开发流媒体软件，以便能够在线播放这类生成式电影。我们也在与其他电影制作人合作，将这项技术融入他们的作品中。随着我们扩展这一理念，其创意可能性是无穷无尽的。比如，一部**漫威（Marvel）**电影，在每个影院的版本都不同，粉丝们可以观看多个版本，拼凑出故事的谜题。我们还可以利用该软件重新混剪现有的电影。在过去的几个月里，我们一直在尝试制作**大卫·林奇（David Lynch）**的《穆赫兰道》（Mulholland Drive）的生成式版本，它会疯狂地反复自我编辑，或者它可以永远播放而不重复。

需要明确的是，我并非认为这种方法会取代传统的电影，但它开辟了一条不同的道路。我认为，我们必须不断质疑这些**遗留模型（legacy models）**至关重要。仅仅因为某事物存在了很长时间，并不意味着它是唯一的方式或最好的方式。作为电影制作人，我们从未不得不问自己：“如果我的电影可以改变，它会如何改变？”因为我们根本不具备实现它的技术能力。

所以，现在我们拥有了这种能力……最有趣的部分在于思考所有新的叙事可能性，以及它能够解锁的所有电影语言。

（电子音效）
BE: When you create something, you're doing this thing that humans are very good at, which is imagining.
(Music)
We really need to be able to harness the intelligence and creativity of everybody, actually. Art is a way we do that. I think that's a real hope for the future.
LA: Is it finished?
(Laughter)
GH: We'll never be finished reinventing the way we tell stories as human beings, but this talk is finished. Thank you so much, everyone.
(Cheers and applause)
Thank you.
(Cheers and applause)

<details>
<summary>Original English</summary>

We premiered the film at the **Sundance Film Festival**, and we've shown it in hundreds of cinemas around the world since then, and every time, it’s been a different version. And each audience that’s seen it was seeing a film that was made for them, that no other audience in the world will ever see. People have come back three, four, 10, 20 times or more to see different versions, and every time, they're getting another layer of Brian's story. Then they talk to their friends and they're, like, comparing versions. "Did you see the David Bowie scene?" "No, I didn't see it." So it's a totally new way to watch movies.

Oh, the film was shortlisted for the Academy Award for Best Documentary. (Laughter) I buried the lede. (Cheers and applause) (Laughs) (Cheers and applause) Oh my God, I buried the lede. But the question was what was actually being nominated. Like which version of the billions of different versions of the film? And all of them? Like nobody really knew. But these are questions that the **film industry** in **Hollywood** will have to answer soon.

Now we’re developing streaming software so we can stream generative films like this. And we're also collaborating with other filmmakers to bring this technology into their films. And there are so many creative possibilities as we scale this idea up. Like what about a **Marvel** film where it’s different in every theater, and fans can go see multiple versions and piece together the story puzzle. We can also remix existing films with the software. For the past few months, we've been playing with a generative version of **David Lynch's** "Mulholland Drive," which is crazy, just re-edits itself over and over again. Or it could just play forever and never repeat.

Just to be clear, this approach, I'm not saying it's a replacement for, you know, normal movies, but it's a different path. And I think it's so important for us to keep questioning these **legacy models**. Just because something is one way for a long time doesn't mean it's the only way or the best way. As filmmakers, we've never had to ask the question of, like, "How would my film change if it could change," because we didn't have the technical capability to even do it. So now that we have that... the fun part is thinking about all the new storytelling possibilities and all the cinematic languages that this can unlock.

(Electronic sound)
BE: When you create something, you're doing this thing that humans are very good at, which is imagining.
(Music)
We really need to be able to harness the intelligence and creativity of everybody, actually. Art is a way we do that. I think that's a real hope for the future.
LA: Is it finished?
(Laughter)
GH: We'll never be finished reinventing the way we tell stories as human beings, but this talk is finished. Thank you so much, everyone.
(Cheers and applause)
Thank you.
(Cheers and applause)
</details>