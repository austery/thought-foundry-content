---
author: 硅谷101
date: '2026-01-13'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=g5hw1HZfwTc
speaker: 硅谷101
tags:
  - robotics
  - foundation-model
  - vla-model
  - embodied-ai
  - scaling-law
title: 机器人“大脑”60年进化史：从编程式逻辑到VLA基础模型的范式革命
summary: 本文深度解析了机器人基础模型的发展历程，从1961年的工业编程范式演进至2025年的VLA大模型时代。通过拆解特斯拉、Figure AI与Dyna Robotics等顶尖公司的技术路径，揭示了全栈整合、垂直突破与生态平台三大流派在实现“通用机器人”目标上的核心博弈与商业逻辑。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people:
  - Elon Musk
  - Brett Adcock
  - Jason Ma
companies_orgs:
  - Tesla
  - Figure AI
  - Dyna Robotics
  - OpenAI
  - NVIDIA
  - Google
  - Amazon
products_models:
  - Optimus
  - Helix
  - DYNA-1
  - GR00T
media_books: []
status: evergreen
---
### 2025：机器人基础模型的“魔幻”元年

2025年，机器人公司发布的 Demo 都有点魔幻。首先是 **Figure AI** 在10月发布了第三代机器人，能够做各种家务，Demo 很酷炫，但任务成功率在业界仍存质疑，且其脸部设计引发了明显的**恐怖谷效应**（Psychological response to humanoid objects that look almost, but not exactly, like humans）。相比之下，10月底发布 Demo 的明星公司 **1X** 就聪明得多，其机器人 **Neo** 的脸部设计更具亲和力，尽管它因依赖远程操控被批评为“假智能”，并引发了隐私担忧。

与此同时，**特斯拉**（Tesla）的机器人 **Optimus** 虽然发布了顺滑的跑步 Demo，但量产计划在2025年遇到了极大挑战，公司不得不暂停生产以重新设计硬件。最近的一次亮相中，Optimus 在分发瓶装水时甚至遭遇了“翻车”，动作极像人类操作员摘下头戴设备，引发了远程操控的质疑。这些现象引出了一个核心问题：为什么 2025 年突然变成了**机器人基础模型**（Robot Foundation Model）的元年？我们将系统拆解主流机器人的“大脑”是如何训练出来、如何接入真实世界，以及不同路线背后的技术与商业逻辑。

### 跨越六十年：从“编程式”逻辑到“会动手”的大脑

要理解现在的突破，必须搞清楚什么是机器人基础模型。简单类比：如果说 **GPT** 是“会说话的大脑”，那么机器人基础模型就是“会动手的大脑”。这个大脑人类研究了整整60年，经历了四个主要范式。1961年，世界上第一台工业机器人 **Unimate** 在通用汽车上班，它完全靠**硬编码**（Hard-coding: 将固定指令直接写入程序），零容错、零灵活性，零件偏离一厘米就彻底“掉链子”。

到了90年代，机器人开始具备感知能力，出现了 **SLAM**（Simultaneous Localization and Mapping: 即时定位与地图构建）技术。这在扫地机器人（如 **Roomba**）的导航任务上很成功，但在复杂的“操作”任务上却屡屡碰壁。例如叠毛巾，传统方法需要视觉识别、3D坐标计算、路径规划等繁琐步骤，2010年伯克利团队的实验显示，叠一条毛巾竟要花24分钟。随后出现的**行为克隆**（Behavior Cloning: 模仿学习的一种，通过记录人类演示的视觉与动作映射进行训练）虽然减少了手工规则，但数据效率极低且泛化性差。2016年，**强化学习**（Reinforcement Learning: 通过试错与奖励机制获取最优策略）因 **AlphaGo** 而声名大噪，但在物理世界中，真机试错太慢、太贵且太危险，且机器人缺乏“常识”，学习效率难以满足通用需求。

### VLA 范式革命：具身智能的底层逻辑重构

2025年，**大语言模型**（Large Language Model）的成熟改变了一切。**VLA模型**（Vision-Language-Action: 将视觉感知、语言理解与动作控制统一在单个神经网络中的模型）应运而生。它的革命性在于将视觉、语言常识与动作指令端到端地结合。当你对机器人说“帮我准备早餐”，它不需要你一行行编程，而是利用大模型中蕴含的常识，知道要从冰箱拿鸡蛋且不能摔碎。

2025年成为元年的关键在于三个因素的同步成熟：第一，大模型能力趋于稳定，足以提供逻辑规划基础；第二，算力价格大幅下降，初创公司也租得起数千张 **H100** 显卡；第三，硬件供应链（如电机、减速器）因人形机器人热潮而成熟，成本显著降低。然而，VLA 模型的核心挑战在于数据——互联网上有文本和视频，但缺乏机器人本体的传感器数据。这场军备竞赛的核心，在于谁能以最低成本采集最高质量的**真机数据**。

### 全栈整合派：追求软硬深度耦合的“一步到位”

在闭源系统领域，目前存在三大流派。第一派是以 **Tesla Optimus** 和 **Figure AI** 为代表的“全栈整合派”。他们坚信基础模型不能与硬件分离，必须深度耦合。马斯克认为特斯拉八成的价值将来自 Optimus，其底气源于 **FSD**（Full Self-Driving: 全自动驾驶）十年的积累。然而，这一派面临**具身鸿沟**（Embodiment Gap: 人类动作数据与机器人硬件结构之间的物理差异）的挑战。即便有海量人类视频，人手与机器手的差异仍导致迁移效率低下。

**Figure AI** 则走得更激进，在与 **OpenAI** 经历了一段“热恋”后，于2025年2月宣布“分手”，独立推出 **Helix** 模型。Helix 采用了 **System 1 & System 2** 双系统架构：System 2 负责逻辑思考，System 1 负责小脑般的实时动作控制。这种架构解决了视觉-语言模型反应慢的问题，实现了上半身35个自由度的精确控制。Figure AI 凭借这一自研模型，在C轮融资中估值飙升至390亿美元，成为具身智能领域的领头羊。

### 垂直突破派：从深度专精到元学习能力的涌现

第二派是以 **Dyna Robotics** 为代表的“垂直突破派”。他们的核心理念是：与其训练一个什么都会但什么都做不好的泛化模型，不如先在垂直场景（如洗衣房、餐厅）做到极致。Dyna 的机器人通过在24小时内自主折叠700多张餐巾（成功率99.4%）证明了其路径的可行性。

这一派认为机器人基础模型的 **Scaling Law**（缩放定律: 模型性能随规模增加而提升的规律）与语言模型不同。语言模型可以容忍低质量数据，但机器人模型对**物理一致性**要求极高，低质量数据会放大错误的物理直觉。Dyna 创始人认为，在深度专精某个任务的过程中，模型学到的不仅是技能，更是“如何学习”的**元学习**（Meta-learning）能力。当模型掌握了复杂的物理交互逻辑，迁移到新任务的成本会从数月缩短至一两天。这种“小而精”的路线，试图通过高质量数据和实际部署中的强化学习，实现从专精到通用的跨越。

### 生态平台派：技术路线背后的标准之争与商业版图

第三派则是追求制定行业标准的“生态平台派”。**NVIDIA** 通过发布并开源 **GR00T N1**，试图打造机器人界的 Android 生态，其护城河在于全套工具链的生态锁定。**Google** 则通过 **RT系列** 模型和开放数据集，在学术界建立影响力，并挖角波士顿动力前 CTO 推动 **Gemini AI** 成为通用控制平台。

此外，**亚马逊**（Amazon）虽然已部署100万台专用机器人，但其 **Agentic AI** 团队正秘密研发通用模型，策略与垂直突破派类似——先在物流场景积累全球最强的数据，再向通用人形机器人泛化。**OpenAI** 和 **Meta** 也在通过投资（如 Physical Intelligence）或组建新部门（如 Reality Labs 旗下的机器人团队）积极占坑。2025年的竞赛尚未分出胜负，但可以确定的是，无论是全栈整合、垂直突破还是生态平台，这场关于“大脑”如何长成的战争，正将我们带向机器人真正走进家庭的临界点。