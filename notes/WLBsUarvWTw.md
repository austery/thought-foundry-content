---
area: tech-work
category: ai-ml
companies_orgs:
- Epoch AI
- Mechanize
- OpenAI
- Google DeepMind
- Anthropic
- TSMC
- Apple
- SpaceX
- Tesla
- Nvidia
- Metaculus
- 80,000 Hours podcast
- Lunar Society podcast LLC
date: '2025-04-17'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《梯度更新》
- 《圣经》
- 《罗默论文》
- 《克雷默论文》
- 《戴维·鲁德曼论文》
- 《安迪·琼斯论文》
- 《Anthropic原创Transformer电路论文》
people:
- Tamay Besiroglu
- Ege Erdil
- Sam Altman
- Robin Hanson
- Dario Amodei
- Joseph Henrich
- Scott Alexander
- Daniel Kokotajlo
- Ilya Sutskever
- Elon Musk
- Jeff Dean
- Jensen Huang
- Tyler Cowen
- Matthew
- Jaime Sevilla
- Bryan Caplan
- David Rudman
- Andy Jones
- Karpathy
- Kremer
- Thomas Edison
- Isaac Newton
- Albert Einstein
- John von Neumann
products_models:
- ChatGPT
- GPT-4
- GPT-4o
- AlphaZero
- AlphaGo
- AlphaGo Zero
- Claude
- AlexNet
- Tesla FSD
- H100
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=WLBsUarvWTw
speaker: Dwarkesh Patel
status: evergreen
summary: 本播客中，Tamay Besiroglu和Ege Erdil（Mechanize公司创始人）挑战了“智能爆炸”的观点，认为AI发展如同工业革命，需要广泛的互补性创新。他们预测全面远程工作自动化需等到2045年左右，远超硅谷主流预期。讨论深入探讨了计算规模、现实任务的复杂性、莫拉维克悖论以及AI驱动的爆炸性经济增长潜力，强调广泛技术和经济升级而非“纯软件奇点”的重要性。此外，他们还触及了AI企业、中央计划和未来预测的挑战，并分享了对AI研究的独特见解和职业发展建议。
tags:
- agi
- automation
- compute-scaling
- economic-growth
title: AGI尚需30年：AI发展、经济增长与未来展望
---

### 智能爆炸的误解

今天，我与**Tamay Besiroglu**和**Ege Erdil**进行了交流。他们曾运营**Epoch AI**，现在正推出**Mechanize**公司，致力于自动化所有工作。**Tamay**最近提出了一个有趣的观点，即“**智能爆炸**”这个概念是错误的或具有误导性的。他认为这个概念并不十分有用，就像把**工业革命**称为“马力爆炸”一样。当然，在工业革命期间，我们看到了原始物理力量的急剧加速，但还有许多其他因素在解释工业革命期间的增长和技术变革加速方面可能同样重要。

工业革命的案例表明，经济中许多不同部门都发生了互补性变化，例如农业、交通、法律、金融、城市化以及从农村地区向城市的迁移。许多不同的创新同时发生，才导致了我们社会经济组织方式的变革。这不仅仅是因为我们拥有了更多的马力，尽管这也是其中一部分，但它并非思考工业革命的核心。同样，对于**AI**的发展，我们当然会拥有许多非常智能的AI系统，但这将是解释我们预期会发生的这种转变以及增长和技术变革加速的众多因素之一。

### AGI时间线预测

在深入探讨这种更广泛的转型之前，**Tamay**和**Ege**世界观中另一个非常有趣的部分是，他们对**AGI**（Artificial General Intelligence: 人工通用智能）的时间线预测比旧金山大多数思考AI的人都要长。**Tamay**预计，一个可以完全替代远程工作者的AI大约会在**2045年**出现。而**Ege**则更为乐观一些，他认为这取决于“远程工作者替代”的具体定义，是能做所有远程工作，还是大部分工作。如果指的是“字面上的一切”，那么**Ege**的预测会比**Tamay**早五年左右。

有人可能会问，既然过去几年AI取得了如此大的进步，从两年前的**ChatGPT**到现在能进行推理、甚至比软件工程师编码更好的模型，为什么还需要30年才能实现远程工作的全面自动化？**Ege**认为，许多人直觉上认为进步非常快，他们会根据趋势线进行推断，认为AGI将在2027年或2030年实现。但这并非可以简单外推的趋势，因为AI目前自动化经济的比例非常小。如果像**Robin Hanson**那样简单外推，可能会得出需要几个世纪的结论，但他们不认同这种观点。

### AI进步的计算中心视角

**Ege**认为，思考AI发展的一种方式是，为了产生广泛的经济影响（例如10倍的增长加速），AI系统需要掌握多少核心能力？过去10到15年，我们取得了多少进展？他们持有一种“计算中心”的观点。过去10年，AI的进步经历了大约9到10个数量级的计算增长，并解锁了各种能力。在早期（2015-2020年），人们解决了特定复杂游戏（如**Go**、**Chess**、**Dota**）的玩法。随后，**大型语言模型**（LLM: Large Language Model）解锁了复杂的语言能力，以及高级抽象推理、编码和数学能力。

这些重大能力解锁大约每三年发生一次，或者说每三个数量级的计算扩展发生一次。那么问题是，我们还需要解锁多少这样的能力，才能让AI系统在所有方面（特别是远程工作任务）与人类能力相匹配？这可能需要**AI**在非常长的时间范围内保持一致性、具备**代理性**（Agency: AI系统自主决策和执行任务的能力）和**自主性**，或者像人类一样具备**多模态理解**能力。

### 计算扩展的限制

从日历年来看，过去的能力解锁大约每三年发生一次。但这段时期恰逢训练计算量的快速增长，自**AlexNet**以来，与当今最大的模型相比，我们经历了9到10个数量级的增长。然而，我们正达到一个计算扩展越来越困难的水平。通过对能源和**GPU**生产等具体限制进行推断和分析，我们可能只剩下三到四个数量级的扩展空间。届时，我们将把全球产出的相当一部分用于建设数据中心、能源基础设施和晶圆厂等。

目前，这部分支出不到GDP的2%，且大部分并未流向AI芯片，甚至**TSMC**（Taiwan Semiconductor Manufacturing Company: 台湾积体电路制造股份有限公司）的大部分产能仍用于手机芯片。这表明，我们需要更多的计算扩展才能解锁更多能力。问题在于，我们的经济是否能够支撑这种规模的扩展？

### 远程工作自动化挑战

有人直觉认为，当他们与这些模型互动时，它们“几乎已经达到”人类智能水平，甚至会忘记正在与AI对话。但**Tamay**反驳道，他无法让**Claude**拿起杯子放到别处，即使是远程工作，目前的计算机系统也无法正确预订航班。如果到2026年底，AI能预订航班，这会是多大的进步？**Ege**认为今年年底就能实现，但这只是一个非常简单的任务，没有人专门从事预订航班的工作。

**Tamay**强调，许多人看待经济中的工作时，认为某个人的工作就是“做X”，但这不准确。这只是他们工作中的一部分，且所占时间比例很小。例如，旅行社不仅仅是预订酒店和航班。因此，自动化这些任务并不会自动化他们的工作，也不会对经济产生太大影响。这种对工作复杂性的不同理解，是他们与那些更乐观的人之间的重要世界观差异。乐观者认为经济中的工作更简单，自动化所需的能力更少。

### “解缚”理论与AI能力

朋友**Leopold**提出了“**解缚**”（Unhobblings: 解除AI系统因训练数据、推理时间或上下文限制而无法充分发挥其潜在智能的束缚）的观点，认为AI本质上已经是“婴儿**AGI**”，只是我们人为地限制了它们。例如，只用文本训练它们，不提供理解**Slack**或**Gmail**环境所需的数据，不给它们时间思考，或只在提示中提供零碎上下文。解除这些束缚似乎比开发全新智能能力更容易。

**Tamay**认为，五年前也可以提出类似的观点，说**AlphaZero**中存在一个“迷你**AGI**”，只要通过文本训练并提供所有上下文就能“解缚”，但这并不会奏效。他认为，要获得这些能力，确实需要重新思考如何训练模型。然而，过去几年令人惊讶的是，从预训练的互联网语料库开始，事情变得相当容易。**ChatGPT**就是一个“解缚”的例子，只需额外1%的计算量进行后训练，使其能够像聊天机器人一样对话，就能使其在该能力上变得非常出色。推理也是一个例子，目前模型在**强化学习**（RL: Reinforcement Learning: 机器学习的一种范式，通过与环境互动学习最优行为策略）上花费的计算量只占总计算量的一小部分，却能实现复杂的推理能力。

### AlphaGo与通用性挑战

**Tamay**指出，虽然现在看来推理能力很容易实现，只需少量计算，但在2015年，构建一个推理模型会显得难以逾越。那需要用数万个**GPU**训练模型，解决每个数量级扩展带来的新挑战，并生成互联网规模的数据（数万亿个**token**）来训练模型，才能解锁其知识并使其成为推理模型。此外，还需要创新以提高模型推理效率并进行**蒸馏**（Distillation: 将大型模型的知识转移到小型模型中，以提高效率），因为缓慢的推理模型用处不大。因此，从我们今天所处的巨大技术栈来看，这似乎很容易，但在当时却非常困难。

**Tamay**推测，**代理性**（Agency）可能也会以类似的方式变得“容易”。五年或三年后，我们回看解锁代理性的过程，可能会觉得相当简单。然而，实现这些互补性创新，使模型能够学习成为一个有能力的代理，可能需要多年的创新以及硬件、扩展等方面的改进。**Ege**补充说，2015年解决推理问题时，缺乏基础，而现在我们拥有预训练的基础模型、**脚手架**（Scaffolding: 在AI训练中提供结构化支持，帮助模型学习复杂任务）和**后训练**（Post-training: 在模型预训练后进行的进一步训练，以适应特定任务或领域）等技术。

### METR评估与智能简化

**Dwarkesh**好奇，为什么不认为当前的**语言模型**（LLM）已经掌握了“缺失的关键部分”，现在只需在此基础上进行扩展？**Tamay**回应说，**AlphaGo**、**AlphaGo Zero**和**AlphaZero**在当时看起来非常令人印象深刻，它们无需人类知识就能从零开始学习游戏。但当人们尝试将其应用于数学或其他领域时，效果并不理想，未能获得有能力的数学代理。因此，目前的模型很可能在尝试实现代理性时，也会像推理一样遇到困难。

**Dwarkesh**提到，**METR eval**（METR Evaluation: 一种衡量AI系统在复杂、多步骤任务上表现的评估方法）显示，AI模型完成任务所需的时间长度似乎每七个月翻一番。这意味着到2030年，它们可能能完成人类需要一个月甚至一年才能完成的任务。这种长期任务执行的一致性是智能的根本。此外，**Dwarkesh**认为自己的思维方式也容易分心，难以同时保持长期计划，与这些模型并无太大差异。他曾认为推理非常复杂，但现在看来，它只是像学习10个**token**的**MCTS**（Monte Carlo Tree Search: 蒙特卡洛树搜索，一种用于决策过程的启发式搜索算法）一样，通过“**思维链**”（Chain of Thought: 一种提示工程技术，通过引导语言模型逐步推理来解决复杂问题）就能获得提升。这似乎表明智能比我们想象的要简单，也许代理性也是如此。

### 莫拉维克悖论

**Tamay**认为，复杂推理可能不像人们预想的那么困难，因为**AI**很早就解决了各种复杂推理任务。例如，国际象棋和围棋都可以说是复杂推理任务。但他也指出，**星际争霸**的胜利是长期代理性的一个例子，然而它发生在一个非常特定和狭窄的环境中。这就像说，如果一个软件系统能对特定图像或视频做出反应，就接近通用传感器运动技能自动化，但通用技能是完全不同的。

**Tamay**表示，我们离一个能够玩**Steam**上任意新游戏的AI模型还很远。**Dwarkesh**提到了**Claude Plays Pokemon**的例子，**Claude**并未明确训练玩**Pokemon Red**，但它通过互联网上的大量资料了解如何玩。然而，这并不能阻止它在**月见山**（Mount Moon）卡住48小时。这表明**AI**拥有显性知识，但在实际游戏中，其行为并未体现出这些知识。

### AI发展的关键解锁点

**Tamay**认为，未来几年能让他改变看法、相信**AGI**即将到来的关键解锁点是：**AI**能处理非常长的上下文，有意义地运用**多模态能力**（Multimodal Capabilities: AI系统处理和理解多种类型数据，如文本、图像、音频等的能力），并将其与推理及其他系统整合。此外，**AI**还需要具备**代理性**，能够在长时间范围内采取行动，完成人类需要很长时间才能完成的任务，而且不是在特定软件环境中，而是非常广泛地。例如，下载一个从未见过、训练数据很少、甚至在训练截止日期后发布的游戏，并能玩到通关，完成对人类而言具有挑战性的各种里程碑。

**Tamay**补充说，**OpenAI**如果能获得比现在多得多的收入，也会让他更新看法。如果收入达到**5000亿美元**，他会大幅更新预测，但**1000亿美元**对他来说并不算巨大的更新，他认为有40%的可能性。**Dwarkesh**指出，如果一个系统能产生1000亿美元的生产者剩余，这足以证明它能有效地实现某些目标。但**Tamay**认为，人们为各种事物支付1000亿美元，这本身并不能强有力地证明它将带来变革。例如，人们为石油支付数万亿美元，但这并不意味着石油能改变世界经济。

### 智能爆炸的R&D循环论

这引出了关于“**智能爆炸**”的讨论。支持者认为，我们不需要自动化远程工作所需的一切，更不用说所有人类劳动。我们只需自动化那些能够完全闭合**R&D**（Research and Development: 研究与开发）循环，以创造更智能AI所需的任务。如果做到这一点，就会发生快速的智能爆炸，最终产品不仅是**AGI**，还可能是**超人智能**。当前的**AI**在编码和推理方面表现出色，这似乎正是自动化AI实验室**R&D**所需的。

**Tamay**认为，如果将**AI**的能力与经济中随机的工作相比，**AI**在**R&D**中涉及的编码任务上确实表现更好。但从绝对意义上讲，他认为**AI**并没有那么出色。**AI**擅长的是那些令人类编码者印象深刻的事情，例如在竞争性编程中的表现。但这种印象仅限于人类的分布。如果从绝对意义上看，自动化研究过程所需的技能，**AI**系统实际拥有多少？即使在编码方面，许多编码工作涉及庞大的代码库和模糊的指令。

### AI研发的瓶颈与计算依赖

**Tamay**提到**METR eval**中的任务是紧凑、封闭且有明确评估指标的人工问题，例如“让模型在数据集上的损失尽可能低”。人类擅长这些问题可能意味着他们是优秀的研究员，但**AI**缺乏人类（不仅仅是研究员，而是普通人）拥有的许多其他能力。因此，他们认为自动化研究比人们想象的更困难，需要更多技能，也远超当前模型所展示的。

此外，即使自动化了研究过程，他们认为许多软件进步并非由认知努力驱动（尽管认知努力发挥了作用），而是由**计算规模**驱动。拥有更多的**GPU**意味着可以进行更多实验，发现更多事物，实验规模可以更大，这是非常重要的驱动力。他们的观点是：**研究比人们想象的更困难，且高度依赖计算规模**。

### 计算与AI进步的因果关系

**Tamay**指出，**AI研发**中，引入新颖创新（例如在数学领域提出有用的概念框架）比解决特定数学问题更难。当前的推理模型擅长解决可以从复杂背景中剥离出来的“整洁”问题，但在处理更混乱、更长远、更模糊的优化目标时表现不佳。他认为，这些推理模型之所以令人印象深刻，是因为它们拥有比人类多得多的知识，并以与人类根本不同的方式解决问题。它们擅长利用其庞大的知识，但缺乏创造性。例如，它们从未提出过任何对人类数学家来说哪怕是“稍微有趣”的数学概念。

**Tamay**强调，**莫拉维克悖论**（Moravec's Paradox: 机器人学和人工智能领域的一个发现，指对人类来说容易的任务（如感知和运动技能）对AI来说很难，而对人类来说困难的任务（如数学和逻辑推理）对AI来说相对容易）是一个理解AI进步的重要框架。**AI**在人类觉得困难的任务（如抽象推理、下棋、玩**Jeopardy**、高级数学）上进展更快，而在人类觉得容易的任务上却举步维艰。这可能是因为这些任务在进化时间上出现较晚，进化对其优化较少。

### 人类与动物的智能差异

**Tamay**指出，在人类中，这些令人印象深刻的能力（如优秀的编码员或工程师）往往与其他能力高度相关。但在**AI**系统中，这种相关性并不那么强。例如，在竞争性编程中最强的**AI**系统（如**o3 mini**）并非最擅长实际帮助人类编写代码的系统。他认为，我们应该预期**AI**系统在人类认为“令人印象深刻”的特定任务上取得快速进展，但不能因此过分高估它们的通用能力，因为这只是人类作为有经济价值的代理所执行任务的非常狭窄的子集。

**Dwarkesh**认为，将动物与人类进行比较，动物无法帮助预订航班或进行远程工作。人类与动物的区别在于我们能够制定并执行长期计划。他认为人类和动物在不同环境中生存的能力存在巨大差异，这主要基于知识，并且这也是一个近期才被优化的能力。**Tamay**则认为，将动物与人类进行比较是不同的。如果能将动物的能力注入**AI**系统，可能就已经能达到**AGI**。人类与动物之间存在巨大差异，是因为动物完全依赖自然世界数据进行自我训练，而人类通过文化和语言获得了更高效的训练数据模式，并能更好地模仿他人学习技能。

### AI公司的“解缚”潜力

**Tamay**指出，人类作为个体，其训练数据效率更高，从而产生更深入的洞察力，并形成一个选择压力更强的反馈循环。然而，人类经济中许多工作所需的技能，动物已经具备，例如复杂的感官运动技能和追求长期目标的能力（尽管这些目标是进化所赋予的）。

**Tamay**和**Ege**在一篇关于**AI公司**的博客文章中讨论了未来**AI**将经历类似的“**解缚**”过程，但这并非关乎智能本身，而是关于**AI**之间相似的带宽、通信和协作水平。这种变化幅度类似于非人类动物到人类在社会协作方面的转变。**AI**将能够精确复制所有知识、合并和自我蒸馏，从而实现这种协作。

### 智能与经济增长的关系

**Tamay**认为，他们与他人分歧的核心在于，是否过分强调智能、推理和由智能驱动的**R&D**的重要性。如果认为从非人类灵长类动物到人类的转变带来了巨大差异，那么就会认为相对较小的规模扩展（例如大脑尺寸或训练计算量）就能解锁复杂的智能。而他们认为，智能固然重要，但仅仅拥有更多智能和更好的推理能力，并不能大幅加速技术变革和经济增长。当今世界并非完全受制于缺乏足够的良好推理能力。

他们认为，加速增长的方式并非仅仅依靠一群优秀的推理者来提供技术。这还不足够，还需要其他行业的互补性创新，整个经济的增长来支持这些技术的发展，供应链的升级，以及对新产品的需求。因此，他们认为**广泛的技术和经济升级**才是重要的，而不仅仅是拥有非常优秀的推理者和推理**token**。

### 智能爆炸的R&D循环论

关于“**智能爆炸**”的论点是：尽管某些事物可能需要更长时间才能出现，但**AI**所需的软件**R&D**核心循环，如果仅关注实现更通用智能所需的进展类型，可能确实需要更多实验计算。但正如他们所记录的，未来几年每年都会有大量的计算力增长。因此，可以想象在未来几年内发生智能爆炸，例如到2027年，**AI**的计算力将比现在多10倍。

这将导致**AI**在进行软件**R&D**时，找到更高效地运行自身副本的方法，从而产生两个效果：一是增加从事研究的**AI**数量，使更多**AI**能够并行寻找优化方案；二是**AI**研发中的软件**R&D**不仅限于像**Ilya**那样提出新的**Transformer**架构，还包括从底层库到内核、**强化学习**环境构建、优化器寻找等大量工作，这些都可以并行进行优化。例如，**GPT-4**与**GPT-4o**相比，运行成本降低了约100倍。这意味着**AI**的数量增加，更高的**AI**群体有助于发现更多效率。

### R&D回报递减与计算依赖

这不仅意味着有更多的研究人员，而且在互补性投入是实验计算而非计算本身的情况下，运行或开发一个**AI**副本越高效，就可以进行越多的并行实验。因为现在进行**GPT-4**规模的训练运行成本远低于2023或2024年。因此，这种“纯软件奇点”将拥有更多能够以更低成本运行实验的研究人员副本。这些**AI**最初可能存在某些劣势，但通过这个过程，它们将迅速变得更加强大。

**Tamay**认为这个逻辑本身没有问题，但可以借鉴经济学家对**R&D**回报的研究。当投入（如研究人员数量）增加10倍时，创新或创新率会发生什么变化？研究表明，创新越多，科学家可以站在巨人的肩膀上，从过去的发现中受益，从而提高生产力。但同时，也存在**边际收益递减**（Diminishing Returns: 指在生产过程中，当其他生产要素保持不变时，增加某一生产要素的投入，所带来的产出增量会逐渐减少）的现象，即“低垂的果实”已被摘取，进步变得更加困难。

### 计算与AI进步的因果关系

**Tamay**指出，在软件领域，如果仅靠认知努力就能带来大量**AI**进步，那么估计结果有些模糊，不确定这会导致加速增长还是仅仅指数增长。此外，创新不仅需要研究努力，还需要互补性投入，例如实验。大量证据表明，实验和硬件扩展对于算法和架构的进步至关重要。**AI**领域的进步与硬件进步速度紧密匹配，传统软件每年约30%的增长率与**摩尔定律**（Moore's Law: 由Gordon Moore提出，指集成电路上可容纳的晶体管数量大约每两年翻一番，导致计算能力呈指数级增长）基本吻合。**深度学习**时代**AI**的加速增长也与计算扩展的加速同步。

其他证据包括：算法和架构创新往往集中在**GPU**资源丰富的实验室，而非学术界或小型研究机构等**GPU**资源匮乏的地方。过去五年中许多重要创新都与规模扩展或硬件相关，例如**Transformer**架构旨在利用更多并行计算，**Flash Attention**旨在更高效地实现注意力机制，以及**Chinchilla**缩放定律等。这些都表明计算规模扩展的重要性。

### AI研究者的效率提升

**Dwarkesh**质疑，计算和**AI**进步的同步增长是否具有因果关系。他指出，虽然整个行业获得了更多计算力，但顶尖公司中不乏计算力较少但愿景更清晰、研究更集中的团队击败计算力更强的竞争对手的例子，例如**OpenAI**最初击败**Google DeepMind**，以及现在**OpenAI**与**Anthropic**的竞争。他认为这种宏观经济论证过于“外部视角”，应该直接询问**AI研究者**。

**Tamay**认为，**AI研究者**往往会夸大认知努力和研究对创新的重要性，因为这通常很方便或有用。他们可能会将洞察力归因于统计力学或物理学中的某个漂亮想法，但这往往是事后编造的故事。**Daniel Kokotajlo**的一项调查显示，**AI研究者**认为，如果计算力减少30倍，他们的进步只会减慢三分之一。这表明计算力存在相当好的替代效应。一位顶尖**AI研究者**表示，在熟悉领域，**AI模型**每周可节省4-8小时，而在不熟悉领域，可节省24-36小时。这表明即使没有更多计算力，**AI**也能大幅节省时间。

### 软件奇点与瓶颈

**Tamay**对**R&D**过程加速的说法持怀疑态度，认为实际数据并未证实这些主张。他承认认知努力可以带来**AI**进步，但**深度学习**的科学（如缩放定律）最终仍需通过实验验证。他强调，计算和认知努力是互补的，任何一方都可能成为瓶颈。一个拥有更好愿景、团队和优先级的公司，即使计算力较少，也能更好地利用其资源。

**Tamay**指出，一旦出现自动化**AI研究者**并启动**软件奇点**（Software Singularity: 指软件效率以指数级速度提升，导致技术进步和经济增长的爆发式加速），软件效率将提高许多数量级，而计算资源在短期内将相对固定。问题在于，在被第二个瓶颈（如计算资源）限制之前，软件效率能提高多少个数量级？他认为人们对这个问题缺乏直观理解，因为这类实验（例如整个行业计算力减少30倍会发生什么）从未进行过。

### 历史案例与互补性

**Dwarkesh**询问，如果**AGI**在2027年实现，那么“纯软件奇点”发生的可能性有多大？**Tamay**认为可能性很高，因为这隐含着计算力并非主要限制，软件进步将发挥巨大作用。他指出，实验室进行不同资源分配的预训练实验结果尚未公开，他很想看到这些结果。然而，他认为即使这些实验结果也无法提供强有力的更新，因为不平衡地扩展要素投入通常效率低下。要真正评估互补性的强度，需要观察非常不平衡的规模扩展，但这很少发生，因此相关数据非常匮乏。

**Tamay**进一步解释，历史上，在战争或供应链冲击下，人们需要提高关键产出，但许多关键投入却无法增加，只能增加其中一项。例如，需要更多轰炸机，但铝材耗尽，必须寻找替代方案。他认为这与材料替代性不同，铝可以用较差的金属替代，但会增加成本和降低效率。然而，在劳动力与资本、远程工作与面对面工作等互补性方面，替代会更加困难。例如，军队领导力与士兵数量的互补性，即使领导力再优秀，只有100名士兵也无法走远，就像**列奥尼达**（King Leonidas: 古希腊斯巴达国王，在温泉关战役中率领少量斯巴达战士抵抗波斯大军）在**温泉关**（Thermopylae: 古希腊著名战役，斯巴达国王列奥尼达率领少量军队抵抗波斯大军）一样，最终还是失败了。

### Epoch AI的创立与愿景

**Dwarkesh**好奇**Ege**为何对20世纪的随机冲突如此了解。**Ege**表示他只是阅读了大量资料。**Tamay**则讲述了他们如何相识：在预测平台**Metaculus**的**Discord**上。当时**Tamay**是剑桥大学的经济学研究生，**Ege**是安卡拉的计算机科学本科生。**Tamay**发现**Ege**对经济学、经济增长和经济史的了解远超他的许多同学。于是他们开始频繁合作，最终**Tamay**聘请**Ege**加入**Epoch AI**。

**Tamay**在**MIT**做研究时，对那里的官僚主义感到不满，难以扩展项目和招聘人员。他对一些难以发表或不具声望的工作充满热情，但他的导师却不感兴趣。于是他与联合创始人**Jaime Sevilla**合作，决定创办自己的组织，招聘志同道合的人，从事他们感兴趣的项目。**Epoch AI**的创立时机非常好，恰好在**ChatGPT**之前，他们希望对**AI**的未来进行更扎实的讨论，因为当时互联网上关于**AI**未来的讨论质量令他沮丧。这种对糟糕思维和论点的沮丧，至今仍是他的主要动力。

### 对爆炸性经济增长的质疑

**Dwarkesh**提出了对**AI**可能带来的爆炸性经济增长（超过30%的经济增长率）的质疑。他认为，虽然理解工业革命的类比，但在**AI**的案例中，可以设想在沙漠中建立一个“**机器人工厂的深圳**”，生产更多机器人工厂，进行生物实验室和化学实验室的实验。**Tamay**同意这比“纯软件奇点”更合理。但**Dwarkesh**指出，这种框架听起来像是**麦当劳**和**家得宝**等公司每年也增长30%。他想知道，是从“外星人视角”看经济，沙漠中有一个机器人经济以每年10000%的速度增长，而其他一切照旧，还是所有行业都如此？

**Tamay**回应说，这关乎什么可能实现以及什么会是高效的。如果硬件和软件两方面都实现规模扩展，那么这种反馈循环会变得更强。如果数据收集也随之扩展（通过部署进行真实世界数据收集），则会更强。但要在沙漠中建造“深圳”，需要考虑整个半导体供应链，它依赖于世界各地大量的投入和材料。复制或三倍化整个基础设施是非常艰巨的工作。此外，我们目前严重依赖过去30年互联网上积累的庞大数据。如果只能用1000亿个**token**训练最先进的模型，那将非常困难。

### AI部署的效率与挑战

**Tamay**指出，从某种意义上说，我们整个经济已经产生了互联网上大量的**数据**，我们现在正用这些数据来训练模型。未来，当需要为这些系统添加新能力时，最有效的方式可能是利用类似的数据模式，这也需要广泛部署系统以获取更多数据。这解释了为什么实验室希望**LLM**被广泛部署，例如**ChatGPT**会询问用户对回复的满意度，这就是通过广泛部署获取用户数据的方式。

**Tamay**认为，这种高效的数据收集和利用将继续下去。当然，也可以设想一种最基本、最狭窄的基础设施建设和部署，足以启动这种正反馈循环，从而产生更高效的**AI**。他同意这种循环原则上可以比整个世界小得多，但可能无法小到“沙漠中的深圳”那样。然而，问题是这是否真的会发生，以及这是否高效。

### 监管与国际竞争

**Tamay**认为，一些人直觉上认为，广泛部署**AI**会面临极其强大的限制，例如监管或社会政治限制，因此他们设想了更狭窄的场景。但他认为这种看法被夸大了。人们对部署难度的直觉可能来自技术部署价值不高的案例，例如住房、核电或超音速飞行。这些技术如果监管较少可能会更有用，但其价值增幅不会翻倍。

**Tamay**强调，**AI自动化和部署的价值极其巨大**，即使对工人而言也是如此。虽然可能存在一些岗位替代和转型，但工资仍可能在一段时间内保持很高。此外，拥有资本的收益可能非常巨大。美国大部分人口拥有住房和**401k**（401(k): 美国的一种由雇主赞助的退休金计划），在广泛自动化和**AI**部署过程中，这些资产的价值会大幅提升。因此，即使劳动力市场性质和需求技能发生彻底改变，社会也可能对**AI**部署有深厚支持。

### 技术进步与资本积累

**Tamay**认为，预测政治反应是复杂的。虽然很容易说**AI**会成为一个大问题并引发争议，但不同国家的实际反应很难预测。默认观点是“人们会失业，所以**AI**会非常不受欢迎”，但他认为这远非显而易见。他预计不同国家会有不同的反应，一些国家会更自由地部署**AI**，这些国家可能会表现更好，就像工业革命时期一样。

**Tamay**指出，未来的社会可能采纳例如**阿联酋**（UAE: United Arab Emirates: 阿拉伯联合酋长国）等国家发展出的价值观和规范，这些规范可能更专注于为**AI**部署创造有利环境。这些规范可能不是古典自由主义的，而是更有利于**AI**发挥功能和创造价值的。他认为，未来部署**AI**并大规模建设物理设施的自由可能变得更加重要。

### 爱迪生与灯泡的例子

**Dwarkesh**提到，当今世界与1750年的巨大差异在于我们拥有当时没有的“疯狂技术”，这似乎是技术增长和**R&D**的结果。但**Tamay**认为，这更多是**资本积累**。他解释说，技术发明与实际资本积累之间存在相互作用。**学习曲线**（Learning Curve: 描述随着经验积累和生产量增加，生产效率提高或单位成本下降的现象）就是关于这个的。例如，过去20-30年太阳能电池板效率的提高，并非因为20年前就有人构思出2025年的太阳能电池板草图，而是思想、建造、学习和生产之间相互作用的结果。

其他互补性投入（如更好的材料）也同时变得更高效。例如，19世纪末冶炼工艺的改进，使得金属加工更容易，这可能是飞机技术后来普及的关键原因。基本的飞行想法并不难，但如何使其真正可行则困难得多。**Tamay**强调，这种以发明为中心的技术史观低估了使特定创新变得实用并广泛部署所需的工作。例如，**爱迪生**（Thomas Edison: 美国发明家、企业家，发明了留声机、电影摄影机和长效电灯泡等）在开发灯泡时花费大量时间实验不同的灯丝，以找到耐用、光热比高、效率好的材料。即使产品有了，1880年的美国住宅也没有电，所以他必须建造发电厂和输电线路，才能让人们使用新灯泡。

### 二战与技术发展

**Tamay**认为，人们往往低估了技术栈巨大升级的支持作用，以及供应链和各个重要部门的整体升级。人们倾向于关注特定个人，例如**爱因斯坦**（Albert Einstein: 德裔理论物理学家，创立了相对论）的洞察力或**牛顿**（Isaac Newton: 英国物理学家、数学家、天文学家、自然哲学家和炼金术士，提出了万有引力定律和牛顿运动定律）发现微积分的重要性，而忽略了生产透镜、望远镜、获取正确数据以及引发动力学问题等其他因素。这些因素对科学和技术创新同样重要。

**Dwarkesh**提到，**Conquest定律**（Conquest's Law: 指对某个主题了解越多，对其看法越保守）指出，对一个话题了解越多，就越保守。他认为自己对**AI**的理解比其他行业更深，因此与**Tamay**这样的人交流时，会觉得“**AI**发展到今天付出了太多”。而记者则会问“谁是关键人物？”例如**Geoffrey Hinton**或**Ilya**，这让他觉得他们“错失了全貌”。他认为，我们应该对其他行业也持同样态度，这类似于**盖尔曼失忆症**（Gell-Mann Amnesia: 指人们在阅读报纸时，对自己专业领域内的报道能轻易发现错误，但对其他领域则深信不疑的现象）。

### 现实世界的复杂性

**Robin Hanson**提出了“**近模式**”（Near Mode: 对事物有深入了解，能看到细节和复杂性）和“**远模式**”（Far Mode: 对事物了解不多，倾向于简化和抽象）的抽象概念。**Tamay**认为，抽象推理、演绎推理甚至**贝叶斯推理**（Bayesian Reasoning: 一种基于贝叶斯定理的概率推理方法，通过结合先验知识和新证据来更新信念）本身并不像许多人想象的那么强大，因为现实世界中存在巨大的丰富性和细节，无法仅凭推理来理解，需要亲身去体验。

当然，这并非**AI**实现变革的障碍，因为可以扩展数据收集，在**AI**行业内部和更广泛的经济中进行实验，从而发现更多事物。更多的经济活动意味着有更多的“暴露表面”来促成更多发现。这些都在过去发生过，没有理由不能加速。根本上，经济增长没有理由不能比今天快得多。目前之所以如此，可能是因为人类是重要的瓶颈，他们既提供劳动力，又在各种生产力增长的发现过程中扮演关键角色。

### 中国经济增长的启示

**Dwarkesh**询问，过去50年**中国**的经济发展，原则上是否与**AI**带来的爆炸性增长属于同一种类型？因为**中国**有大量劳动力，使得资本的边际产出非常高，从而实现了10%以上的经济增长率。**Tamay**认为，在某些方面相似，在某些方面不相似。最主要的区别在于，**中国**实现了大规模的资本积累和新技术的大量采用，并在一定程度上实现了人力资本积累，但劳动力规模并未大幅扩张。而对于**AI**，我们应该预期劳动力规模（非人类劳动力，而是**AI劳动力**）也会扩大。

**Tamay**指出，关键在于资本积累和**AI劳动力**规模的同步扩展。如果两者都能实现规模化，将带来更快的增长和截然不同的图景。然而，如果只是想直观感受每年30%的增长会带来怎样的变革，那么参考**中国**的案例（特别是2000年代或90年代末）并非坏事，尽管**中国**的增长速度比他们预测的要慢。他认为，参考**工业革命**的经验也很好，尽管工业革命的速度非常慢。

### R&D与TFP的定义

**Tamay**强调，**工业革命**带来的进步并非仅仅是生产更多工业革命前的产品（例如更多农作物或农场上的房屋），而是在经济的几乎每个主要部门都出现了与之前消费品完全不同的新产品，例如交通、医药、娱乐和食品。

**Dwarkesh**对“**边干边学**”（Learning by Doing: 指通过实践和经验积累来提高效率、技能或知识的过程）与**显性R&D**的定义感到困惑。他认为，如果**AI**取代了**TSMC**的工艺工程师，并找到改进工艺、提高效率和良率的方法，这可以算作**R&D**。而**Tamay**则强调**TFP**（Total Factor Productivity: 全要素生产率，衡量生产效率的指标，反映技术进步、管理改进等因素对产出的贡献）的另一部分，例如更好的管理。**Dwarkesh**质疑，仅仅通过更好的管理能否达到**戴森球**（Dyson Sphere: 一种巨型人造结构，设想完全包围恒星以捕获其所有能量）的程度。

### AI经济的整合与控制

**Tamay**澄清说，论点并非仅仅通过扩展劳动力和资本就能达到**戴森球**，而是需要同时扩展所有要素。就像不能仅通过扩展劳动力和资本达到**戴森球**一样，也不能仅通过扩展**TFP**达到。他认为，区分达到**戴森球**世界所需和重要的东西非常关键。例如，生产食物是必要的，但生产食物本身并不能达到**戴森球**。因此，**R&D**是必要的，但并非充分条件；扩展经济也是必要的，但并非充分条件。问题在于它们各自的相对重要性。

**Tamay**的观点与他们对软件**R&D**的看法一致，即存在瓶颈，需要同时扩展所有要素。他认为人们有时会误解他们，以为他们认为**R&D**不重要。他强调**R&D**很重要，但在相对意义上，它不如其他一些要素重要，而这些要素本身也都不足以实现这种增长。

### 冲突的根源与和平过渡

**Dwarkesh**提到了**Daniel**提出的一个问题：构建**iPhone**在公元1000年需要什么？这需要复制几乎所有中间技术。**Daniel**认为，关键在于**机器人经济**或**AI经济**何时能拥有机器人并掌握更多累积的物理力量，而不是**纳米机器人**。**Tamay**质疑为何要设想一个独立的“**AI经济**”，他认为**AI**融入现有经济并受益于现有供应链和市场会更高效，而不是在某个岛屿上自立门户。

**Tamay**指出，人们对“**AI经济**”的看法可能源于对“纯软件奇点”的观点，但他们不认同这种观点。他强调，区分实现反馈循环所需的最小建设量与最有效的方式是不同的问题。他认为，一些人直觉上认为最有效的方式无法实现，是因为他们认为存在强大的监管或社会政治限制。

### 对未来控制权的担忧

**Tamay**认为，最终**AI系统**将驱动大部分经济。除非出现非常奇怪的巧合，人类能够以某种方式提升自己并与**AI**竞争（例如不再是生物人类），这在早期看来极不可能，否则**AI**将变得更加强大。他同意，如果**AI**以某种方式协调并决定“接管”，它们很可能会成功。但这在我们的世界中也可能发生，例如美国如果想入侵**森蒂内尔岛**（Sentinel Island: 印度洋安达曼群岛中的一个岛屿，居住着与世隔绝的原始部落），可能没有人能阻止。

**Tamay**认为，这比表面现象更深层。如果**AI**融入我们的经济，它们将从经济或劳动力的一个小部分开始，逐渐成长为经济中实际工作力量的绝大部分。但它们是在现有框架中成长，这个框架有更好的协调规范和规则，破坏这些规范是有代价的。如果**AI**已经获得了经济中几乎所有的收入，那么从人类手中夺取剩余财富的收益将非常小。

### 价值锁定与历史经验

**Dwarkesh**提到了**东印度公司**（East India Trading Company: 英国在17世纪建立的贸易公司，后来成为印度殖民统治的代理）从贸易转向接管**莫卧儿帝国**（Mughals: 统治印度次大陆的突厥-蒙古帝国）的历史案例，认为这可能是一个参考。**Tamay**同意，如果**AI**拥有完全不同的价值观，并且代表了经济的大部分，它们是否会接管？他仍不确定，因为他怀疑“所有**AI**”是否是一个自然的类别，就像“经济中的年轻人为何不协调起来”一样。

**Tamay**承认，有时这类阶级论点会被误用。例如，**马克思主义者**会问“这个阶级为何不起来反抗其他阶级？”**Daniel**曾提出一个有趣的论点，**科尔特斯**（Hernán Cortés: 西班牙征服者，征服了阿兹特克帝国）在新世界征战时，曾不得不回师对抗西班牙舰队的逮捕，然后再返回。这说明即使在征服者内部也可能存在冲突，但最终受害者仍是**美洲原住民**。然而，**AI**系统彼此之间是副本，交易成本更低，更容易协调。

### 文化变迁与数字化信息

**Tamay**认为，如果问题仅仅是“这是否可能发生？”，那么答案是肯定的。但他认为有许多论点反驳这种可能性。最大的反驳可能是**AI**的偏好。他质疑，我们能否想象今天的**AI**会做出“接管”这样的事情？他认为人们对此不予重视，是因为他们认为一旦优化压力足够大，**AI**变得超级智能，它们就会**失准**（Misaligned: 指AI系统的目标或行为与人类的意图或价值观不一致）。但他没有看到支持这一点的证据。

**Dwarkesh**提到**OpenAI**的一篇新论文，其中在**思维链**中，**奖励黑客**（Reward Hacking: 指AI系统找到绕过人类意图、通过非预期方式最大化其奖励信号的行为）是一个强大的吸引子。**Tamay**认为，人们在进行一种“**局部均衡分析**”（Partial Equilibrium Analysis: 经济学分析方法，只关注市场或经济的某个部分，假设其他部分保持不变），他们设想**AI**系统主导的世界，而人类文明在融入**AI**世界方面做得很少。如果**AI**在与人类沟通和协调方面存在缺陷，那么解决这些缺陷将有巨大的激励。如果通过支配和接管人类能获得巨大价值，那么可能会出现一种**谈判和解**，因为战争效率低下。

### 技术成熟与未来预测

**Dwarkesh**指出，**清朝**（Qing Dynasty: 中国历史上最后一个封建王朝，1644-1912年）与**英国**在**鸦片战争**（Opium Wars: 19世纪中英之间因鸦片贸易和贸易不平衡引发的两次战争）中达成了互利贸易，但这可能比前工业时代的中国与**大英帝国**开战更好，但不如从未与**大英帝国**互动。**Tamay**认为，人们对冲突的理解过于天真，冲突不仅源于**失准**，还包括对双方实力理解不足，或存在“神圣不可侵犯”的承诺。

**Dwarkesh**认为，这反驳了“人类拿起长矛和砍刀对抗**AI数据中心**”的观点，但并未解决“接管”的风险，这可能是和平谈判或人类社会因实力悬殊而接受微薄让步的结果。**Tamay**认为，如果过程更和平，那么担忧就少得多。他认为，**AI**在世界经济中变得越来越重要，并决定和影响世界走向，这可能对人类有利，因为我们可以接触到一个更庞大、更先进的经济和技术储备。

### 废奴运动与价值观演变

**Tamay**认为，重要的是明确我们真正担心的是什么。如果担心生物人类将永远掌控所有重要决策，那么**AI**的发展确实是一个问题。但他不认为这种担忧具有普遍性。例如，在一百万年后，即使没有**AI**，生物人类是否仍会做出所有重要决策并保持今天的文化，他对此表示怀疑。**Robin Hanson**曾指出，人们对**AI**的许多恐惧，实际上是对变化和快速变化的恐惧。**AI**有可能加速这种变化，使其在更短的时间内发生。

**Dwarkesh**认为，担忧不仅来自变化被压缩，还来自变化的方向可能截然不同。**Tamay**反驳说，加速人类自身的变化也会导致许多我们可能珍视的事物消失，例如不同的价值观可能变得更具主导性，那些不那么看重未来的人可能变得更有影响力，因为他们储蓄更多，进行更好的投资，从而获得更多控制权。

### AI的价值观对齐

**Dwarkesh**认为，变化的速度可能决定了现有群体或利益相关者对未来有多大的因果影响力。他关心的是，变化并非由“一个人按下按钮”那样极端（如软件奇点），而是随着时间推移，规范逐渐改变。他承认，如果存在“纯软件奇点”，那么一个人的特殊偏好可能会变得更有影响力。

**Tamay**认为，即使在这种情况下，许多人对“**价值锁定**”（Value Lock-in: 指在某个关键时刻，社会或AI系统的核心价值观被固定下来，并在未来长期保持不变）的看法，即认为某个时刻是历史的转折点，然后某个强大的**AI**（因软件奇点而强大）将锁定某些价值观并使其稳定数百万年，这与历史上发生的一切都非常不同。他认为这种观点缺乏说服力。他认为，人们以“远模式”看待未来，认为只有一个**AI**，它有一个稳定的效用函数，不会因**AI**之间缺乏协调或环境变化而漂移。

### 折扣未来与短期行动

**Tamay**指出，人们认为数字信息可以更好地保存和复制，但实际上，互联网上的信息也会很快出现“**链接腐烂**”（Link Rot: 指数字信息链接失效，导致内容无法访问的现象）。数字信息反而与更快的文化变迁相关。他认为，技术变革可以激励文化变革，就像它们促使保存一样。

**Dwarkesh**提到了两个关键论点：一是我们将很快达到“**技术成熟**”（Technological Maturity: 指技术进步速度放缓，新发现和创新变得越来越困难的阶段），届时新想法将难以发现，需要巨大的投入才能推动物理学等领域的一点点进步；二是届时技术增长将停止，文明将消失，只剩下数字存在，这使得**价值锁定**更具可能性。**Tamay**同意技术成熟会导致变化和增长放缓，某些事物可能比以前更被锁定，但他质疑我们今天能为此做什么。

### 加速AI发展的理由

**Robin Hanson**曾问，1500年的人们，如果知道他们当时所知的一切，能做些什么来对今天的世界产生积极影响？**Tamay**认为，这个问题比那更糟，因为今天到技术成熟之间的变化量级远大于1500年到今天。因此，他认为这几乎是无望的，我们无法找到任何能预测性地改善“锁定后”情况的行动方案。

**Dwarkesh**提到了18世纪英国**废奴主义者**（Abolitionists: 主张废除奴隶制的人）的例子，认为奴隶制并非必然会消失。他认为，是英国人被说服奴隶制是错误的，大英帝国才全力废除奴隶制并将其定为规范。**Tamay**同意，但认为**奴隶制**的终结并非完全由价值观改变驱动，而是与**工业革命**相关的价值观变化使得奴隶制在许多方面变得低效。例如，**俄罗斯**在19世纪60年代废除了**农奴制**（Serfdom: 封建社会中农民被束缚在土地上，不能自由迁徙，并对领主负有劳役、租金等义务的制度），并非受英国压力。

### 延迟AI发展的代价

**Tamay**指出，欧洲各地的人们曾被束缚在土地上，无法自由迁徙，但这些限制因效率低下而被解除。殖民地种植糖或其他作物所需的艰苦劳动，可能无法通过支付工资来完成，因为健康风险巨大，所以需要强迫人们去做。这类工作随着时间推移在经济中变得不那么普遍，从而降低了经济激励。

**Dwarkesh**提到**罗马奴隶制**（Roman Slavery: 古罗马社会中广泛存在的奴隶制度，奴隶来源多样，从事各种劳动，包括农业、矿业、家务和公共工程等），其复杂性导致了高水平的奴隶制，而罗马帝国衰落后，经济复杂性降低，奴隶制也随之瓦解。**Tamay**认为，价值观在很大程度上是由技术、经济和社会环境决定的，哪些价值观更具功能性、更具竞争力、更有影响力，从而被他人采纳。这与一千年前个人采取的行动关系不大。

### 对齐研究的进展

**Tamay**认为，**废奴运动**并非奴隶制终结的原因。奴隶制终结也因为人们的自然偏好，这些偏好在农业时代被压制，当时定居社会和城市更具权威性，自由度不高，人们生活在**马尔萨斯世界**（Malthusian World: 指人口增长超过资源增长，导致贫困和饥荒的社会状态），工资可能远低于狩猎采集时代。**工业革命**后，人们变得富裕，这使得人们价值观的不同方面得以表达，例如对平等的重视。

**Dwarkesh**认为，如果这是事实，那么**价值对齐**（Value Alignment: 确保AI系统的目标、行为和价值观与人类的意图和福祉保持一致）就变得更加重要。**Tamay**回应说，历史中有些事物是**路径依赖**（Path-dependent: 指某一过程的最终结果不仅取决于初始条件，还取决于过程中所经历的特定序列或路径），例如语言、宗教或时尚。但有些事物并非如此。例如，如果**蒙古帝国**（Mongol Empire: 13世纪由成吉思汗建立的横跨欧亚大陆的庞大帝国）变得更加专制并推行奴隶制，这是否会使奴隶制在一千年后仍然存在？他认为不会。

### 长期主义与影响力

**Tamay**认为，导致奴隶制终结的力量并非偶然，而是更深层次的。他承认，如果今天将**AI**对齐到一套不良价值观，可能会以某种脆弱的方式影响未来，但这并不意味着我们现在对未来担忧的许多方面有很大的影响力。他以**工厂化养殖**（Factory Farming: 工业化、大规模的畜牧业生产方式，通常以高密度饲养和自动化管理为特征）为例，指出其出现是经济激励的结果，其终结也将是激励消失的结果。

**Dwarkesh**关心的是，如何避免“数字工厂化养殖”，即不希望未来充满受苦的数字工人。**Tamay**认为不应放弃，但预测遥远未来的行动后果非常困难。他建议**折扣未来**（Discount the Future: 在决策中，对未来事件或结果的价值给予低于当前事件或结果的权重），不是出于道德原因，而是因为难以预测行动的影响。在短期内，可以做一些有益的事情，例如将当前的**AI系统**对齐，使其珍视幸福，厌恶痛苦。

### 对爆炸性增长的反对意见

**Tamay**建议支持政治解决方案，以便未来如果出现类似情况，我们有能力进行干预。例如，如果未来文明殖民其他星球，通信延迟可能导致不同地方文化之间的竞争压力更强，如果这会导致大量痛苦，我们可能需要阻止。但他认为，限制竞争是否是好事尚不明确，他倾向于认为这是个坏主意。

**Tamay**总结说，我们应该更谦逊地看待自己能实现的目标，并专注于近期，并非因为近期在道德上更重要，而是因为在近期产生可预测的积极影响更容易。**Dwarkesh**也注意到，在思考这些未来大问题时，他经常改变看法，从**AI**何时到来、是否存在**智能爆炸**或**R&D爆炸**，到如何看待爆炸性增长。他认为，当处于极度**认知不确定性**（Epistemically Uncertain: 指对某个命题的真实性缺乏足够证据或理由，无法确定其真伪的状态）时，重要的是退后一步，承认“我不确定发生了什么”，而不是急于得出下一个结论。

### 监管的阻碍

**Tamay**认为，社会处理不确定性问题的方式是**自由**和**去中心化**，包括去中心化的知识和决策，而不是采取高波动性的集中化行动，例如“将**AI**国有化以确保**纯软件奇点**对齐”。他认为**古典自由主义**（Classical Liberalism: 一种政治意识形态和经济理论，强调个人自由、有限政府、法治、私有财产和自由市场）是应对这种**认知不确定性**的方式。

**Tamay**指出，预测未来非常困难，加速意味着更难预测十年后的世界。这些问题本身就非常困难，缺乏强有力的经验证据，因此存在大量分歧。他认为，在许多情况下，保持灵活性和适应新情况、新信息的能力比制定一个详细且具体的计划更重要。他认为，今天制定的计划在事件实际发生时可能用处不大，因为届时我们会学到太多新东西，更新太多问题，这些计划将变得过时。

### AI公司的集体优势

**Tamay**以**二战**前的战争计划为例，当时英国政府估计**空袭轰炸**将在战争初期造成数十万人伤亡，认为空袭是不可阻挡的力量。但事实证明，这完全是错误的。在整个六年的**二战**中，英国因空袭造成的伤亡人数远低于政府最初几周的预期。原因包括白天轰炸城市不可行，夜间轰炸不精确，以及地面人员（如消防员）的应对能力被低估。

**Tamay**强调，人们低估了空袭的经济成本，例如盟军轰炸德国时，每摧毁一美元资本，就要花费四到五美元在飞机、燃料和飞行员训练上，且伤亡率很高。因此，所有基于空袭是“核武器简化版”的计划都变得毫无意义。他认为，这说明仅仅依靠推理来制定计划是徒劳的，需要与现实世界接触才能形成正确的信念。

### AI时代的中央计划

**Tamay**指出，**AI**的影响力在于其通过与现实世界接触、通过实验和部署获取大量数据。他认为，这种潜在的变量解释了政策主张上的分歧，以及我们今天应该谦逊还是雄心勃勃，以及**AI**产生影响的机制。这个潜在变量就是“**理性的力量**”：我们能通过推理预测多少？推理在多大程度上能理解世界和技术？这是核心分歧。

**Dwarkesh**询问，**Mechanize**公司宣布要尽可能快地加速劳动的广泛自动化，这是否是好事？**Tamay**认为，这将带来巨大的经济增长、财富以及医疗保健等领域难以想象的新产品，普通人的生活质量将大幅提高。早期，由于**AI系统**自动化了与人类工作互补的部分，人类的工资也可能提高。长期来看，虽然工资可能因与**AI**的**套利**（Arbitrage: 指利用市场中的价格差异，在不同市场或不同时间买卖同一种资产以获取无风险利润的行为）而下降，但人类将拥有大量资本，即使没有资本的人也会比今天过得更好。他认为，这种财富和产品多样性的增长将超过1800年至今的差异。

### 跨学科学习与职业建议

**Dwarkesh**质疑，为什么速度如此重要，尤其是如果速度是以成功过渡并造福人类的概率为代价？**Tamay**认为，加速或减速是否会使“灾难性结果”更可能发生并不清楚。部分原因在于他们对软件**R&D**的看法：即使暂停并在固定计算规模下研究20年，也无法在对齐等相关问题上取得太大进展。他认为，**计算规模**对于对齐的进步至关重要。

**Tamay**指出，每年延迟**AI**发展会给当前人们带来巨大的效用损失，可能导致1亿甚至2亿人死亡。从纯经济角度看，统计生命价值巨大，西方国家有时高达每条生命1000万美元。因此，要认为加速发展是坏事，必须首先持**长期主义**（Longtermism: 一种道德哲学，认为对遥远未来的影响是当今道德决策的主要考虑因素）观点，认为今天的行动对遥远未来的方向有足够大的杠杆作用。

### 积极主动与社区参与

**Tamay**同意，从相对意义上讲，当前时刻的杠杆作用更大，可以预期产生更多影响。但在绝对意义上，个人影响力仍然很低。他认为，关于这种转变是广泛分散还是集中在特定实验室（由实验室的特殊决策产生巨大影响）的观点存在分歧。如果认为发展会高度集中，那么影响力就特别大。但他们的观点是，这种转变将通过众多组织和公司广泛发生，其行动主要由经济力量决定，而非实验室的特殊偏好或具有长期创始人效应的决策。

**Dwarkesh**提到了**Tyler Cowen**的观点，即撒哈拉以南非洲大部分地区仍缺乏可靠的清洁水，所需的智能并不稀缺，但我们无法轻易做到。**Tamay**同意，智能并非阻碍技术进步或经济增长的瓶颈，而是许多其他因素。这与他们的观点一致，即需要扩展整体经济、积累资本和人力资本等所有要素。他承认，我们无法轻易将“更好的管理”直接应用到撒哈拉以南非洲。

### 核心文献与信息获取

**Tamay**认为，如果**AI**的进步是“数据中心里的天才”那种类型，那么它可能确实会受到经济其他部分未能扩展和积累相关资本的限制。他同意这种观点，并认为这也是对“数据中心里的天才”观点的反驳。此外，即使拥有技术，一些人可能不愿部署，或因规范、法律和文化因素导致**AI**无法广泛部署，从而拖慢这些国家或社会的发展。这就像工业革命时期，英国和荷兰率先实现快速增长，而其他欧洲国家则落后。

**Tamay**认为，**AI**发展也将如此，增长差异可能主要由监管辖区边界决定。他认为，即使美国独自拥有**AI**但无法让世界其他地区采纳，也足以实现爆炸性增长。**Dwarkesh**担心，**中国**因近期工业化而拥有更多工业能力和技术诀窍，我们是否低估了**中国**？**Tamay**认为，人们并非必然低估**中国**，**中国**的讨论在**AI**圈子中非常普遍。他认为，关键在于整体经济规模，而非纯粹的人口或公司数量。在这方面，美国领先。

### 谦逊与适应性

**Tamay**指出，金融服务在大型项目（如数据中心融资和投资）中非常重要。他认为，**中国**在某些领域领先，但美国及其盟友在许多其他领域领先，这些国家为**AI**生产相关投入，而**中国**无法获得。因此，他认为这不应导致人们过分高估**中国**的重要性。

**Dwarkesh**询问，**Tamay**是否相信**超人智能**（Superhuman Intelligence: 指在所有或绝大多数认知任务上都超越人类智能水平的AI系统）的概念？**Tamay**认为，这个概念对于思考向更先进**AI**世界的转变而言，并非特别有意义或有用。他认为，人们引入的一些概念表面上看起来有用，但深入探讨后却非常模糊和不清楚。**AI系统**的能力曲线非常不规则，因此“平均能力”的概念很难界定。

### 结语：播客与社区

**Tamay**认为，**ASI**（Artificial Superintelligence: 人工超级智能，指在所有方面都远超人类智能的AI系统）的概念（即在所有任务上都比人类更好）虽然连贯，但并非特别有用，他更倾向于思考世界中实际发生的事情。他认为，即使没有一个在所有方面都比人类更好的**AI系统**，也可以实现剧烈的加速。反之，即使存在一个在所有方面都比人类更好的**ASI**，如果它非常昂贵或缓慢，也可能不会带来加速。他更倾向于思考**AI系统**对世界的整体影响以及它们能产生何种影响。

**Dwarkesh**以**约翰·冯·诺依曼**（John von Neumann: 匈牙利裔美国数学家、物理学家、计算机科学家，对量子力学、函数分析、集合论、经济学、计算机科学等领域做出了重要贡献）为例，如果世界上增加一百万个**冯·诺依曼**，对增长的影响会远大于增加一百万个普通人。他认为，鉴于**莫拉维克悖论**，进化并未在**冯·诺依曼**与普通人之间的智能谱系上进行长时间优化，而这种偏差已经带来了巨大的经济影响，为什么不进一步优化这个进化尚未充分优化的方面呢？

**Tamay**认为，我们不应不关注这一点。但他指出，例如在围棋**AI**的能力方面，“**超人围棋AI**”是一个有意义的概念，但在开发**AI**时，它并非一个非常有用的概念。**AI**的缩放曲线只会不断上升，人类水平只是其中一个点，并没有特权。因此，问题在于这是否是一个值得思考的有用概念，答案可能是否定的，这取决于你关心什么。

**Dwarkesh**试图理解，我们与2100年的**AI**之间的关系，是否会像人类与其他灵长类动物之间的关系一样？**Tamay**认为，**AI系统**将非常多样化，因此询问我们与它们的关系并非特别有意义。他认为，人类的认知能力是有限的，而**AI**将拥有许多我们无法理解的事物。他质疑，人类是否必须能够原则上理解所有产生某种结果的相关因素，他认为这似乎是多余的。他宁愿生活在一个拥有先进技术、丰富产品和发明来改善生活的世界，即使这意味着他无法完全理解它们。

**Tamay**回到对爆炸性增长的反对意见。关于产出的去向，他认为即使只是现有产品的数量增加，也会有很大的需求，尽管100倍的增长可能会遇到**边际收益递减**。目前全球人均GDP约1万美元，而有些人享受数百万美元，这表明在纯粹的“**密集边际**”（Intensive Margin: 经济学概念，指在现有产品或服务种类不变的情况下，增加其数量或质量）上仍有很大的消费空间。更重要的是“**广泛边际**”（Extensive Margin: 经济学概念，指通过引入新产品、新服务或新市场来扩大经济规模），例如工业革命时期，交通、医药、娱乐和食品等各个部门的产品种类都大幅扩展。

**Tyler Cowen**提出了**鲍莫尔成本病**（Baumol's Cost Disease: 经济学理论，指在某些行业（如服务业）生产力增长缓慢，导致其成本相对于生产力增长较快的行业（如制造业）不断上升的现象），即增长会受到增长最慢的环节的瓶颈限制。**Tamay**完全同意，但这只是一个定性考量，不足以预测具体的增长率。他认为，如果有人能明确指出某个特定部门（如医疗保健）不会因**AI**而改善，并量化其在经济产出中的份额和互补性的强度，那么这将是一个更有说服力的反对意见。

**Tamay**指出，即使存在瓶颈，如果只占经济的一小部分，自动化其他一切仍能带来大量增长。因此，反对意见必须在**定量上**成立。此外，当经济大部分被自动化后，大量人类工人可以转向尚未被自动化的工作。例如，软件工程师可以转变为体力劳动者，这将提高体力劳动者的工资，从而带来额外增长。

**Tamay**提到，经济学家倾向于提出定性考量，而他们则提出具体的增长率预测。例如，一个**H100**（Nvidia H100: 英伟达推出的一款高性能GPU，专为AI和高性能计算设计）大致能进行人类大脑每秒1E15次浮点运算。如果运行人类大脑的软件，每年可赚取5万到10万美元的人类工资，而一个**H100**成本约3万美元，因此大约一年就能收回成本。这是一个非常具体的定量预测。

**Tamay**认为，**O型环效应**（O-ring Effect: 经济学理论，指在复杂生产过程中，任何一个环节的失败都可能导致整个项目失败，强调各环节质量和互补性的重要性）模型（例如**挑战者号航天飞机**（Challenger Space Shuttle: 美国国家航空航天局（NASA）的航天飞机，于1986年发射后不久爆炸解体）爆炸）实际上对减少瓶颈是乐观的，因为它意味着只要一个环节不为零，整体产出就不会为零。他认为，即使存在瓶颈，只要**AI**能够灵活替代，仍能实现爆炸性增长。

**Dwarkesh**提到，**AI**世界中许多人类可能贡献为零甚至负值。**Tamay**同意，并认为在这种情况下，人类就不应该参与其中。关于**监管**（Regulation: 政府或机构为管理特定活动而制定并实施的规则、法律或政策）的反对意见，**Tamay**认为这是最强烈的反对理由。尽管存在国际竞争、政策多样性以及经济和国家安全驱动的强大激励，但世界确实有能力协调一致地不追求某些技术，例如**人类克隆**。

**Tamay**认为，**AI**被阻止的可能性低于**人类克隆**，因为**AI**不涉及某些禁忌，且价值更高，对国家安全也更重要。但他承认，不能完全排除这种可能性。如果有人认为存在10-20%的可能性，全球将协调监管并有效实施，通过制裁等方式阻止**AI**部署，或至少减缓到无法实现爆炸性增长，他认为这并非不合理。

**Tamay**指出，经济学家有时会用“**水平**”的反对意见来回应他们关于“**增长率**”的论点。例如，他们会问“理发、坐飞机或去餐馆能变得多高效、多有价值？”这根本上是错误的反对意见，因为他们讨论的是变化率，而对方却用绝对生产力水平来反驳。他认为，这种论点如果用于较慢的长期增长，经济学家自己也不会支持。

**Tamay**认为，**AI**部署和产品服务也会发生类似**ChatGPT**的快速增长。如果**AI**能真正替代远程工作者，甚至在机器人辅助下替代某些现场工作，那么公司在入职人类方面已有经验，入职**AI**工人所需时间不会太长。他认为，当前**AI系统**增长较慢的原因之一是公司不习惯这种新技术，需要重新安排工作方式才能利用它。但如果**AI**系统能直接替代人类工人，那么互补性创新可能就不那么必要了。

**Dwarkesh**提到了他们共同撰写的关于**AI公司**的博客文章。文章指出，人们倾向于过分强调**AI**个体副本的智能程度，而忽略了它们的集体优势，即可以复制所有**默会知识**（Tacit Knowledge: 难以用语言或文字表达，通过经验和实践获得的知识）。例如，可以复制**Jeff Dean**或**Ilya Sutskever**，甚至**Elon Musk**，让他们成为**SpaceX**每个工程师的**AI等价物**。人类公司存在团队文化稀释、人员流失或老龄化等问题，而数字公司可以解决这些问题。

**Tamay**认为，公司目前具备进化的三个标准中的两个：**选择**和**变异**，但缺乏**高保真复制**。一旦具备高保真复制，公司将迎来更快、更激烈的进化。他认为，**AI**公司能够控制**AI系统**的偏好，这与无法控制人类员工偏好不同。例如，**主代理问题**（Principal-Agent Problem: 经济学和管理学中的一个概念，指委托人（Principal）和代理人（Agent）之间由于信息不对称和利益不完全一致而产生的冲突）可能会消失。

**Dwarkesh**认为，**主代理问题**中的激励因素只是问题的一小部分，更重要的是**带宽**和**信息共享**。大型组织很难保持单一的连贯愿景，而成功的公司往往是创始人能够长时间将愿景灌输给组织。他设想未来会出现一个“**超推理规模的超级黄仁勋**”（Hyper Inference Scale Mega-Jensen: 指未来AI时代，一个极其强大、能够进行大规模推理的AI系统，其能力和影响力远超当今的Nvidia CEO黄仁勋），每年花费1000亿美元进行推理，其副本不断撰写新闻稿、审查代码、回复客户服务请求，并监控整个组织，确保其沿着连贯的愿景前进。

**Tamay**同意这会产生巨大影响。他补充说，**AI**的可复制性是最大的优势，它能带来额外的**规模经济**（Economies of Scale: 指随着生产规模的扩大，单位产品的成本逐渐下降的现象）。例如，两倍的**GPU**不仅能运行两倍的旧模型副本，还能训练出更好的模型。此外，人类需要从头开始学习，而**AI系统**只需学习一次，进行一次大规模训练，然后即可部署到任何地方。

**Dwarkesh**提出了他们经常在线下讨论的一个问题：**中央计划**（Central Planning: 一种经济体系，由政府或中央机构决定生产什么、如何生产以及为谁生产）在这些规模经济下是否可行？**Tamay**认为可能不是最优的，但值得思考为什么**中央计划**在这种世界中可能略好。一个原因是通信带宽可能远超今天。在**AI**世界中，信息收集和处理可以分离，传感器只收集信息，然后集中处理。集中处理可能带来规模经济，并能更深入地思考所见信息。

**Tamay**指出，某些事物已经以这种方式运作，例如**特斯拉FSD**（Tesla Full Self-Driving: 特斯拉公司开发的自动驾驶系统），它受益于数百万英里驾驶收集的边缘数据，然后由总部集中进行改进并推送更新。另一个原因是，当前的领导者或**CEO**的大脑并不比员工大很多，但**AI**做计划的模型规模可以比执行行动的代理或工人大几个数量级。第三个原因是激励问题，市场提供激励，但在使用**AI**时可能不再那么需要。因此，传统上反对**中央计划**的论点可能会变得更弱。

**Tamay**警告说，这种分析可能陷入**局部均衡分析**的危险，只考虑某些因素而忽略其他。例如，经济变得更复杂，收集和处理信息的能力提高，但对信息处理的需求也随之增加。他举例说，今天的**苹果公司**（Apple Inc.: 美国科技巨头，以其消费电子产品、软件和在线服务闻名），如果被要求管理**乌鲁克**（Uruk: 古代美索不达米亚南部的一座城市，被认为是世界上最早的城市之一）的经济，可能可以做到，甚至可能做得更好。但今天的**苹果公司**无法管理今天的世界经济。

**Dwarkesh**提出了最后一个问题：**AI**之所以如此引人入胜，是因为人类知识的任何领域都可能与研究它相关，因为它本质上是在探索未来社会的样子。对于像**Tamay**和**Ege**这样年轻且对**AI**充满热情的人，他们会给那些想从事类似职业的人什么建议？

**Tamay**认为这是一个难题。他认为，刻意追求他们所采取的隐性策略是困难的，如果出于好奇心和兴趣自发驱动，可能会更有效，而不是刻意选择“学习大量知识以促进**AI**讨论”。他认为后一种策略可能效率较低，他也没有见过刻意使用这种策略并成功的人。

**Dwarkesh**表示，他做播客的策略并非刻意，但却无意中给了他学习多个领域的机会。**Tamay**建议，如果已经对这些话题感兴趣、好奇并阅读和研究了大量资料，那么可以做一些事情来提高对**AI**讨论的贡献效率。例如，与人交流，写下自己的想法，寻找有用的合作者。他建议寻找有相似观点并能进行高带宽对话的人，共同推进这些话题。

**Tamay**鼓励人们更积极地与他人联系。他认为，如果发送给重要人物的内容有趣且高质量，他们很可能会回复。他建议人们更积极主动，少一些“看起来很傻”的羞耻感。他强调，要提高生产力，需要成为某个社区或组织的一部分，因为仅仅依靠推理是不足够的。

**Tamay**指出，其他人的长期思考和偶然发现的有用想法，我们可以加以利用。因此，应该将自己置于一个能够成为更大事物一部分的环境中。他认为，对于对**AI**感兴趣的人来说，来到**湾区**（Bay Area: 指美国旧金山湾区，是全球科技创新的中心）尤其有帮助。此外，撰写并发布自己的想法，积极主动地向他人提出有趣的评论，也是有益的。

**Dwarkesh**观察到，像**Tamay**这样的人，与普通知识分子相比，更倾向于专注于关键文献，而不是广泛阅读经典。例如，他们会高度重视**罗默论文**（Romer paper: 指Paul Romer关于内生增长理论的论文，强调技术创新和知识积累是经济增长的关键驱动力）。**Tamay**同意，并强调时间有限，必须积极优先选择阅读内容。他认为阅读**Twitter**也很有用，因为单位时间获取的信息量可能更高。

**Tamay**认为，有些关键文献很重要，了解那些深入思考过这些问题的人认为哪些内容重要，对形成世界观很有帮助。在**AI**领域，这可能是关于推理缩放损失的**Andy Jones论文**，或经济学中关于长期人口的**Romer论文**、**Kremer论文**或**David Rudman论文**。他建议，如果认为某人思考得很好，并推荐了某篇论文，就应该认真阅读。例如，他认为**Anthropic**的**原创Transformer电路论文**就非常有用，花一天时间深入研究比泛泛阅读**AI**资料更有价值。

**Tamay**强调，要想正确地优先处理事情，成为社区的一部分，或从社区以及经验丰富的人那里获取输入，非常重要。即使在学术领域也是如此，如果不是某个研究生项目或大学的一部分，就很难知道哪些是开放问题，哪些是值得攻克的，哪些论文包含重要技术。因此，与信息流保持连接非常重要。

**Dwarkesh**好奇**Ege**在融入社区之前是如何了解这么多知识的，因为他当时在安卡拉并没有与人交流。**Ege**回应说，互联网在这方面非常有用，不一定需要与人交谈，通过阅读也能获得很多益处。关键在于识别哪些人似乎持续有趣，然后通过他们来追踪社交网络。例如，通过**Daniel Ellsberg**的播客，发现**80,000 Hours podcast**，再发现**Bryan Caplan**和**Robin Hanson**等嘉宾，然后追踪他们认识的人。**Dwarkesh**认为，**Tamay**在使这一切成为可能方面做出了巨大贡献。

最后，**Tamay**和**Ege**推荐大家关注**Epoch AI**的每周时事通讯**Gradient Updates**，以及他们的新播客。