---
area: market-analysis
category: finance
companies_orgs:
- OpenAI
- xAI
- Meta
- NASA
- Oracle
- Amazon
- Nvidia
- AMD
- Dell
- HP
- Arista
- Cisco
- Huawei
- Samsung
- SK Hynix
- Micron
- Seagate
- Vertiv
- Caterpillar
- Rolls-Royce
- Google
- GE Aerospace
- Microsoft
- SpaceX
- Bank of America
- Bernstein
- Morgan Stanley
date: '2025-12-01'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《硅谷101》
people:
- Jensen Huang
products_models:
- InfiniBand
- Stargate
project:
- ai-impact-analysis
- investment-strategy
- market-cycles
series: ''
source: https://www.youtube.com/watch?v=reCHpD4yDfQ
speaker: 硅谷101
status: evergreen
summary: 本视频深入剖析了AI数据中心建设的巨大资本支出，从IT设备、供电、冷却到工程建设，详细拆解了每GW的成本构成。探讨了不同机构估算差异的原因，以及电力短缺如何成为关键瓶颈。最后，分析了科技巨头在此领域疯狂投入的深层逻辑：投资不足的风险远大于过度投资，且算力总能被消耗。
tags:
- ai-data-center
- capital-expenditure
- crisis
- investment
- market-dynamic
title: AI数据中心：万亿级基建狂潮背后的真实成本与投资逻辑
---

### 引言：AI基建的万亿级投入

NASA预估5000亿美元能让人类完成火星登陆，这笔钱能买下1.36个阿里巴巴、3.5个NBA联盟，建设100座Apple Park，或购买1400亿杯咖啡。然而，这笔巨款却只够OpenAI建设一座名为Stargate的数据中心，而其野心可能是这个规模的十倍甚至更多。除了OpenAI之外，xAI、Meta等科技巨头也开始疯狂地在AI数据中心领域砸钱，全球因此开启了一波基建狂潮，押注新一轮的万亿级市场。但在狂潮背后，我们不禁想问，这么多钱都花到哪里去了？本期《硅谷101》将深入探讨AI数据中心背后的资本支出，分析数据中心由哪些部分构成，上下游主要公司和玩家有哪些，以及资金究竟如何分配。

### AI数据中心成本拆解：四大类支出

有意思的是，我们翻遍了各大报告后发现，大家给出的预算都各不相同。究竟谁才是对的？更有数据中心被“逼”上了太空，这背后的原因又是什么？在AI被质疑存在泡沫的情况下，为什么资本依然在疯狂地涌入呢？

我们首先来看看今年10月15日美国银行对于下一代AI数据中心的成本分析。数据中心的支出主要分为四大类：IT类设备、供电设备、冷却设备和工程建设。为了便于对比，我们将计算单位统一到每**GW**（Gigawatt: 吉瓦，衡量功率的单位）的支出。

### IT类设备：核心算力引擎

首先是与计算直接相关的IT类设备，分为服务器、网络、存储三块。其中的大头是服务器，每GW大概需要375亿美元。服务器包含了CPU、GPU、内存、主板这些重要的元件，通常直接由**ODM**（Original Design Manufacturer: 原始设计制造商，负责产品设计与制造）供货，例如鸿海。它们会从英伟达和AMD这些芯片设计公司拿到服务器的设计标准，并制造成整机，直接向Oracle、Meta、亚马逊这类超大规模的客户供货。ODM占据了服务器市场46%的份额。而其他中小企业要购买服务器，则需要找戴尔、超微、惠普这类**OEM**（Original Equipment Manufacturer: 原始设备制造商，负责生产贴牌产品）厂商购买。

在网络方面，每GW需要37.5亿美元的网络设备，其中主要的玩家分别是Arista、Cisco、华为、英伟达等。值得一提的是，虽然英伟达在其中的市场占比只有5%，但业界有观点认为，尽管英伟达的**InfiniBand**（一种高速低延迟的网络通信技术标准）网络通信标准更贵，但凭借其低延迟、无丢包风险的优势，更适用于AI数据中心。

最后是存储，也就是硬盘，每GW需要19亿美元的存储设备。主要玩家包括三星、SK Hynix、美光、希捷等。我们将以上三项相加，最终得出IT类设备每GW支出为431.5亿美元，这是数据中心支出的大头。

### 冷却系统：保障算力稳定运行

IT类设备是核心，但整个数据中心的支持系统也同样关键。接下来我们来看一下冷却系统。

2018年，亚特兰大的一个数据中心遭受了网络攻击，导致法院、警察局、机场等多个城市服务机构被迫关闭。攻击者除了用勒索软件锁住数据之外，还侵入了冷却系统。冷却系统被入侵后，环境温度骤升到100华氏度以上，不少芯片受到损坏。黑客甚至将服务器和冷却系统的控制权作为“人质”，要求支付51000美元的比特币。后来，攻击冷却系统的方式变得越来越常见，花样也越来越多。这个故事告诉我们，冷却系统对于一个数据中心的重要性。

虽然冷却系统建造预算只占总成本的3%，但随着全球AI算力需求的指数级升级，传统的风冷技术已经很难满足高密度算力设备的散热需求。同时，对于英伟达的GPU来说，散热能力也在一定程度上成为制约算力的核心瓶颈。因此，对于数据中心来说，液冷已经从散热备选方案变为必需品。

对于配备液冷系统的数据中心来说，冷却设备主要包含冷却塔、冷水机组、**CDU**（Cooling Distribution Unit: 冷却分配单元）和**CRAH**（Computer Room Air Handler: 机房空气处理机组）。如果要承担1GW的散热，它们分别需要支出0.9亿、3.6亿、4.5亿、5.75亿美元，总计14.75亿美元。主要供应商由于分散在各个环节，数量众多，但维谛、江森、世图兹和施耐德等都是这个领域的大玩家。

### 供电设备：数据中心的生命线

说完了制冷，电力也是核心基建。我们再来看看供电设备的情况。供电设备主要分为应急供电的备用柴油发电机、负责配电总控的开关设备、保障不断电的**UPS**（Uninterruptible Power Supply: 不间断电源，提供短期电力保障）、给各机组配电的母线槽以及其他配电设备。

美国银行认为，典型的柴油发电机每**MW**（Megawatt: 兆瓦，衡量功率的单位）的成本在40万至55万美元，燃料箱、燃料泵和安装费用加起来大约是35万至50万美元。因此，每MW的发电机成本大约是80万美元。要提供1GW的电力，则需要8亿美元的应急发电机。

但在我们的嘉宾看来，真实成本远不止这些，原因是冗余性。如果IT设备的容量（功耗）达到1GW，往往需要配置不止1GW的柴油发电机，最重要的原因就是保证冗余性。像一些可靠性要求特别高的数据中心，其柴油发电机的量可能是数据中心算力需求的两倍，例如数据中心如果是1GW的量，可能要配备2GW的柴油发电机。在柴油发电机的市场中，最大的玩家是卡特彼勒，康明斯和罗尔斯·罗伊斯旗鼓相当。

除此之外，1GW数据中心还需要6.15亿美元的开关设备、9.85亿美元的UPS和3亿美元的配电设备。这些电气设备的三大玩家分别是施耐德、维谛和伊顿。所以，整个供电设施的花费算下来是每GW 27亿美元，只有IT设备的1/13。

### 工程建设：数据中心的基础架构

最后一项支出是工程建设费用，包含了建筑成本、安装成本、总承包商费用等。每GW的工程预计花费大约是42.8亿美元。

### 总支出与机构估算差异

我们合计了一下，要建成1GW的数据中心，最终的总支出大约是516亿美元，其中IT设备占比最高，成本达到了84%。这么算下来，OpenAI 10GW的Stargate项目就得要5160亿美元，与官方宣称的5000亿美元投资非常接近。

但与此同时，我们在翻阅各种研报时发现一个很有意思的事情，就是不同机构给出来的数据差距非常大。例如就拿Stargate为例，不同机构估算出来的总预算甚至差出了2000亿美元。这是为什么？大家应该如何看待这样的计算分歧？

我们首先来看看几个不同机构的预测：Bernstein在11月1日发布的报告称，每GW的AI数据中心成本大约为350亿美元，而且各项目的支出占比也与美国银行的预测不同，例如IT设备相关的GPU、网络、CPU、存储总占比为56%，远低于美国银行计算的84%。Barclays Bank在10月底给出的报告中表示，AI数据中心每GW对应支出为500亿至600亿美元，其中65%至70%都用在计算与网络当中。而在今年8月的Morgan Stanley研究模型中，1GW对应的成本是335亿美元，其中计算设备占比为41%，而剩下的59%用于电力、冷却等基础设施的建设中。

为什么各家的预测数据相差会如此大呢？主要有两个原因。

第一是假设使用的芯片不同。美国银行的计算对象为英伟达在今年9月初发布的**Rubin架构**（英伟达下一代GPU架构）芯片，将于2026年年底上市。而Bernstein和Morgan Stanley的计算对象则是2024年3月发布的**Blackwell架构**（英伟达当前一代GPU架构）。光是GPU的成本，美国银行的未来数据中心成本是375亿美元，而Bernstein的GPU成本是136.5亿美元，两者就差了200多亿美元。所以，各家计算金额最大的差别就在于芯片价格不同，每GW相差了200亿美元。而像供电、冷却等其他设施的成本相差其实并不大。不过这也侧面说明了，英伟达下一代芯片又要涨价了。新的“**Jensen’s Math**”（黄氏数学: 英伟达CEO黄仁勋提出的关于AI数据中心成本和GPU价值的计算方式）认为一座1GW的AI数据中心总成本在600亿至800亿美元，甚至还高于其他机构给出的预测。其中的“计算成本”，也就是英伟达的潜在收入，大约是400亿至500亿美元。黄仁勋自己知道他想定什么价，也算过能耗和自己能赚多少，所以他的预测可能更准确。

第二个原因就是计算范围的不同。美国银行相当于计算的是数据中心建筑内部的成本，而Bernstein计算的则包括了建筑成本以及整个数据中心园区的成本，因为它把园区内的配电系统和涡轮发电机全部都包括进去了。美国银行的发电机更多是备用电源的柴油发电机，而Bernstein的发电机是燃气涡轮发电机，相当于是一个自发电的发电机。

综合来看，我们的嘉宾认为，对于巨头们未来建设的数据中心，美国银行给出的预算会更接近真实情况，因此我们这期的预估也是根据美国银行的报告来整理的。

### 电力瓶颈与创新解决方案

我们前面提到，电力会成为数据中心的瓶颈。这就是为什么大家会看到，动画中数据中心里面和外面其实都有发电机。在电力这一块，会有不小的一项隐形支出——电力投资。

我们之前做过一期视频和播客，分别讲述了AI带来的用电荒以及为什么美国如此缺电。在一年半后的今天，情况依然没有好转。如今，巨头们为了获取电力，不得不自己投资建厂。OpenAI或其合作伙伴如Oracle，需要想办法在电网上创造新的容量。现在的很多科技公司，得自己去建发电机、建发电站、变电站和一些配电网设施，甚至建一些稍微短一点的电力传输线，以满足自身需求。如果要给一个10GW的数据中心配上一个发电厂，其成本可能会达到120亿至200亿美元。

因此，我们还看到，由于AI数据中心的大基建，带火了被认为是“夕阳产业”的电力股GE Aerospace（GEV），其燃气轮机订单甚至都排到了三年之后。谷歌曾经斥资30亿美元改造宾夕法尼亚州的两座水力发电厂，为的就是换取3000MW的电力，这相当于获取1GW得花10亿美元，这还仅仅是改造的费用。马斯克为了Colossus2项目也收购了一家发电厂。数据中心抢电抢得很厉害，也有一些分析师觉得像GE这样的公司会有溢价能力。购买1GW的发电机可能就是相当于25亿美元，20亿美元可能是一个比较合适的**CapEx**（Capital Expenditure: 资本支出，指用于购买固定资产的投资）估算。

到这里就有一个问题了，数据中心不是本来就有应急发电机了吗？为什么不直接去用这些发电机来供电呢？应急的柴油发电机和大型的天然气涡轮发电机还是有本质区别的。柴油发电机更多是作为备用电源使用，其所有组件都是为了高功率、短时爆发而优化，所以它并不能承载7x24小时随时随地都在运行的状态。而天然气涡轮发电机在设计时就考虑到了像一年365天几乎每一个小时都在运行的场景。还有一些其他原因，柴油实际上是一种比较贵的燃料，相对于天然气发电机使用天然气，可以通过管道输送，发同一度电的成本，柴油发电机的成本很可能是天然气发电机成本的3至8倍。

所以现在数据中心的建设就卡在了获取电力上，美国电网又无法提供足够的功率，想买天然气涡轮发电机又买不到。由此也催生了一些其他方式，例如燃料电池开始变得越来越受欢迎。甚至巨头们都被“逼”上了太空。谷歌的最新消息说，计划在2027年将数据中心送上太空，主要原因在于在太空中利用太阳能板来发电，效率可以达到地球上的8倍，还能够解决晚上没有太阳能的困扰，可以说是免费且无限的能源供应。除此之外，在太空中还能够利用真空和辐射散热的方式，降低冷却系统的需求。除了谷歌、微软、亚马逊，还有马斯克的SpaceX都开启了这方面的探索。

那么建设太空数据中心又得花多少钱呢？在LinkedIn上面，我们看到有相关人士预测，目前建设一座1MW的太空数据中心，算上发射费之后，成本大约为3550万美元。如果是1GW，那将是355亿美元。不过这好像也没有比地球上贵多少。关于太空数据中心是否可行，背后的挑战与机遇，我们之后也会计划单开一期视频来好好聊聊。

### AI基建狂潮的深层逻辑

既然建设AI数据中心耗费如此之大，而且在市场纷纷怀疑充满泡沫的情况下，为什么这股基建热潮只增不减呢？在我们采访的嘉宾看来，主要原因有两点。

第一是投资不足比投资过度的风险更大。大部分公司现在都意识到一点，就是“Under investment is riskier than over investment”，所谓的投资不够给你带来的风险，要远远大于你过度投资带给你的风险。为什么会这样呢？很有可能谁最先获得最好的AI模型，或者所谓的**AGI**（Artificial General Intelligence: 通用人工智能，指能够理解或学习人类能做的任何智力任务的AI），这家公司就会占据比较大的市场份额，其他公司的生存空间就会很快地缩小。过度投资会有什么样的风险呢？无非就是买了更多的地、更多的电、更多的房子来建数据中心，最后发现可能买多了。无非就是可以把它用作自己公司内部的一些使用，提升效率，或者可以把它租给其他人，或者把这些地、电卖给其他公司。总体来说，过度投资的风险实际上是有一个封顶的。

第二个原因在于，只要有算力，科技公司们总会有办法去用掉。在硅谷有一句话，就是“Bill will always eat Andy”，你只要有**Infra**（Infrastructure: 基础设施）、只要有**Hardware**（硬件），**Server**（服务器）总有办法可以想办法把你运用掉的。这周早些时候，Open Compute Project（OCP）Meta的人就在里面说，他们目前的GPU光用来做他们内部的一些AI，比如Instagram或者Facebook，去筛除一些不合适的内容，其实也已经需要很多算力了。就算有多余闲置的算力，它用来做内部的降本（cost reduction），其实也是完全可以用的。所以，现在主流的这些公司都不会担心会过度投资。

### 资金来源与未来展望

所以我们看到，哪怕现在市场纷纷质疑AI存在过度投资的情况，巨头们依然在疯狂地投入。那么最后一个问题是，上万亿美元的需求，钱从哪里来呢？

其实就是这些**hyper scaler**（超大规模云服务商: 指拥有庞大云计算基础设施的公司）的自有资金，自己赚的钱再投回去，自己借的钱再投回去。后面其实就是要靠这些**public market**（公开市场: 指股票、债券等公开交易的市场），就是这个债券市场，美国的**investment grade**（投资级: 指信用评级较高的债券）或者**high yield grade**（高收益级: 指信用评级较低但收益较高的债券，也称垃圾债），还要说最近新起来的“影子银行”，就是所谓这些**private credit**（私募信贷: 指非银行机构向企业提供的直接贷款）。你把它拆分，基本上就是这些大的融资渠道来撑起整个的**AI build out**（AI基建热潮: 指大规模建设AI相关基础设施的趋势）。这在美国历史上也不是没有见过。AI更像全球基建的一个大周期，只要AI能挣到钱，它是全球增长的**driver**（驱动者: 指推动增长或发展的因素），真的不用特别担心钱这个事情。

这场看似疯狂的投入，本质上是一场关于“谁先抵达未来”的博弈。或许这条路充满风险，但是对于科技巨头们来说，“缺席”的代价比“投资错误”的代价要更高。