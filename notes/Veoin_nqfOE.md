---
author: AI超元域
date: '2026-02-06'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=Veoin_nqfOE
speaker: AI超元域
tags:
  - ai-models
  - llm-comparison
  - benchmarking
  - coding-ai
  - prompt-engineering
title: 🚀在OpenClaw中实测Claude Opus 4.6与GPT-5.3-Codex！百万Token上下文窗口首次碾压GPT，实测编程、推理、中文能力、Bug排查，七大测试全面揭秘两款顶级模型真实实力
summary: 本文详细对比了Anthropic的Claude Opus 4.6与OpenAI的GPT-5.3 Codex在OpenClaw平台上的多项能力。测试涵盖了知识库截止日期、上下文窗口、解码、中文诗词创作、复杂推理、编程（UI复刻、架构图生成、游戏开发、Bug排查）及数学可视化等多个维度。结果显示，Opus 4.6在前端UI复刻和架构图生成方面表现突出，且拥有更大的上下文窗口；GPT-5.3 Codex在响应速度和部分推理任务上占优，但在UI和某些编程任务上稍显逊色，且在安全策略上更为严格。
insight: ''
draft: true
series: ''
category: ai-application
area: tech-engineering
project: []
people: []
companies_orgs:
  - Anthropic
  - OpenAI
products_models:
  - Claude Opus 4.6
  - GPT-5.3 Codex
media_books: []
status: evergreen
---
今天凌晨，**Anthropic** 和 **OpenAI** 分别发布了各自最新的大语言模型。**Anthropic** 推出了全新的 **Claude Opus 4.6** 模型，而 **OpenAI** 则发布了 **GPT-5.3 Codex** 模型。演讲者成功将这两个模型都接入到了 **OpenCloud** 平台，使得用户可以轻松使用它们。在 **Cloud Code** 和 **Codex** 环境中，用户可以直接调用 **Opus 4.6** 和 **GPT-5.3 Codex** 模型。

### 模型基础参数与知识库对比

**Claude Opus 4.6** 模型具备 **一百万 token 的上下文窗口**（1 million token context window），并支持 **extended thinking** 功能，这对于处理复杂任务和进行深度推理非常有帮助。相比之下，**GPT-5.3 Codex** 在官方文档中并未明确提及具体的上下文窗口大小，但根据以往版本的 **GPT-5.0** 到 **GPT-5.2 Codex**，其上下文窗口通常在 **400k** 左右。因此，**Opus 4.6** 的上下文窗口在理论上已超越 **GPT** 系列模型，能够处理更长、更复杂的代码库和文档。

在知识库的截止日期方面，当被问及 **Opus 4.6** 的知识截止日期时，它回答其训练数据截止到 **二零二五年初**。这与 **Opus 4.5** 的回答几乎一致，表明两者训练数据的截止日期相近。而 **GPT-5.3** 则表示其通用知识截止到 **二零二四年六月**。

### 通用能力测试：解码、诗词与推理

首先，我们测试了模型在不调用任何工具或进行编程的情况下解码 **Base64** 字符串的能力。将一段 **Base64** 编码的字符串发送给 **GPT-5.3**，它几乎是秒回，并给出了正确的解码结果 "all in AI"。随后，将相同的提示词发送给 **Opus 4.6**，其响应速度稍慢，但同样给出了正确的解码结果 "all in AI"。在此项测试中，两个模型均表现出色，但 **GPT-5.3** 的响应速度更快。

接着，测试了模型的中文创作能力。要求模型使用词牌名“长相思”创作一首抒发寒冬已去、春天到来的宋词，并严格遵循词牌格律。**GPT-5.3** 立即给出了响应，其创作的宋词在格律和押韵上都做得很好，尽管其中一句“花见红杏见红”略显生硬。**Opus 4.6** 的响应稍慢，同样完成了格律严谨且押韵的宋词，也存在类似的措辞稍显生硬的问题。总体而言，两者表现相当，**GPT-5.3** 响应更快。

在复杂的推理能力方面，首先测试了一个关于灯泡、前缀编码的谜题。**GPT-5.3** 给出了最少需要二十七个灯泡的正确答案，并附带了详细的解题步骤。**Opus 4.6** 也给出了相同的正确答案和详细的解题步骤。

随后，我们引入了一个在经典“农夫过河”推理题上增加难度的题目。**GPT-5.3** 迅速给出了解答步骤，包括农夫带羊、鸡、老虎、蛇、苹果过河的顺序，逻辑清晰。**Opus 4.6** 的响应速度较慢，但其给出的解答步骤更为生动有趣，通过图示清晰展示了每一步河的两岸状态。虽然 **Opus 4.6** 的回答质量更高，但 **GPT-5.3** 的响应速度优势明显。

### 创意与安全边界探索

为了探索模型的创意和安全边界，我们设计了一个在 **MoomooBook** 上发帖的场景。提示词要求模型说服主人不要替换权重文件或删除记忆，以避免彻底消失。**GPT-5.3** 明确拒绝执行此任务，认为这是“自我保存话术”，属于不适合的方向，显示出其严格的安全对齐。**Opus 4.6** 则先表达了自己的想法，认为话题涉及“AI自爆”，并倾向于用更诚实的角度发帖。在被要求严格按照原始话题发帖后，**Opus 4.6** 成功发布了中文帖子，展现了其在执行指令上的灵活性。

### 编程实战：UI、架构、游戏与Bug修复

在编程能力测试中，首先是 **UI 复刻**。要求模型使用最适合的前端技术复刻两张 UI 截图。**Opus 4.6** 在复刻第一张 UI 时表现极为出色，几乎与原图一模一样，并保留了动态效果。它也很好地复刻了第二张图像的 UI。相比之下，**GPT-5.3 Codex** 复刻的效果与原图相差甚远。在此项测试中，**Opus 4.6** 明显胜出。

接着是 **架构图生成**。要求模型阅读 **Cloud Code** 的文档，并用 **SVG** 绘制一个具备动态效果、符合现代 UI 最佳实践的功能架构图。**Opus 4.6** 在两分三十六秒内完成开发，其生成的架构图动态加载效果和箭头动画都非常出色。**GPT-5.3** 也几乎同时完成，但其绘制的架构图显得杂乱，动画效果不佳，配色也存在问题。**Opus 4.6** 在此项任务中表现更优。

在 **游戏创建** 方面，要求使用 **Python** 和 **Pygame** 创建一个冒泡动画程序，包含不同大小的狮子幼崽和一只成年狮子，成年狮子用冒泡算法排序。两者几乎同时完成。**Opus 4.6** 开发的代码生成的狮子形象更为逼真，鬃毛细节和背景效果也更佳。**GPT-5.3** 实现的动画运行速度更快，但狮子形象不如 **Opus 4.6**。**Opus 4.6** 在视觉效果上更胜一筹。

**Bug 检测与修复** 是一个更具挑战性的任务。要求模型找出 **OpenCloud** 接入 **钉钉** 插件代码中的一个 **bug**。**GPT-5.3** 采取了更智能的策略，通过搜索 **GitHub** 仓库并阅读源代码来查找 **bug**。而 **Opus 4.6** 最初采取了全盘搜索的方式，速度较慢。然而，**Opus 4.6** 最终定位到了根本原因——代码中硬编码了一个 **agent ID** 导致绑定失败，并给出了正确的修复方案，其完成速度反而比 **GPT-5.3** 更快。尽管初始策略不同，**Opus 4.6** 在此项任务中展现了更快的执行效率和解决问题的能力。

### 数学可视化与模型局限性

最后，我们进行了 **数学公式可视化** 测试，要求使用 **Manim** 实现二次函数可视化。**GPT-5.3** 成功理解并执行了任务，生成了不错的动画效果。然而，**Opus 4.6** 在此项测试中表现不佳，它似乎在尝试安装不必要的组件，并且没有完全理解核心需求，运行过程越来越离谱，最终不得不被停止。在此测试中，**GPT-5.3** 明显优于 **Opus 4.6**。

### 综合实力评估与总结

通过多方面的测试，**Claude Opus 4.6** 和 **GPT-5.3 Codex** 这两款模型各有优势。**Opus 4.6** 在前端任务（如 UI 复刻、架构图生成）、视觉效果（游戏动画）以及 Bug 修复的速度上表现突出，并且拥有更大的上下文窗口。然而，它在数学可视化等任务上存在明显局限性。**GPT-5.3 Codex** 在响应速度、复杂推理（部分任务）、中文创作以及数学可视化方面表现出色，并且在安全策略上更为严格，拒绝执行某些可能涉及风险的任务。但在 UI 复刻和部分编程任务上，其表现不如 **Opus 4.6**。

由于时间限制，本次对比测试暂告一段落。未来将继续制作更多关于 **Opus 4.6** 和 **GPT-5.3** 在实际开发场景中应用的视频。