---
area: "society-thinking"
category: general
companies_orgs:
- Stanford University
- Instagram
- Google
- Apple
- Netflix
- TikTok
- Twitter
- OpenAI
- DeepMind
- DeepSeek
- xAI
- Anthropic
- Tesla
- Walmart
- Microsoft
- Caltech
- MIT
- The Atlantic
- Chinese Communist Party
date: '2025-11-27'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- The Social Dilemma
- Lord of the Rings
- The New York Times
- Sapiens
- An Inconvenient Truth
- The Anxious Generation
- The Humane Interface
- When Prophecies Fail
people:
- Steven Bartlett
- Demis Hassabis
- Gary Kasparov
- Jeff Hinton
- Sam Altman
- Elon Musk
- Joe Rogan
- Barack Obama
- Eric Schmidt
- Gary Marcus
- Helen Toner
- Larry Page
- Marshall McLuhan
- Charlie Munger
- Warren Buffett
- Yuval Noah Harari
- Donald Trump
- Kamala Harris
- Jordan Peterson
- Gavin Newsom
- Franklin D. Roosevelt
- Richard Sutton
products_models:
- Gmail
- Google Slides
- ChatGPT
- Gemini
- Claude
- GPT-4
- GPT-5
- Claude 4.5
- AGI
project: []
series: ''
source: https://www.youtube.com/watch?v=BFU1OCkhBwo
speaker: The Diary Of A CEO
status: evergreen
summary: 技术伦理学家、人道技术中心联合创始人 Tristan Harris 发出严厉警告：全球科技巨头正进行一场危险的竞赛，旨在打造通用人工智能（AGI），而这场竞赛正将人类社会推向一个无人期望的未来。Harris
  揭示了科技公司 CEO 们公开承诺与私下恐惧之间的巨大鸿沟，并深入探讨了 AI 带来的系统性风险，包括大规模失业、心理操控、社会结构瓦解以及最终失控的风险。他认为，当前的发展路径并非不可避免，并呼吁公众觉醒，通过政治行动和国际协作，为
  AI 的发展设立护栏，引导其走向一个更安全、更符合人性的未来。
tags:
- ai-safety
- attention-economy
- existential-risk
- job-displacement
- technological-determinism
title: 技术伦理学家 Tristan Harris：我们必须在为时已晚前，认清 AGI 竞赛的真正风险
---
### AI：比移民潮更严峻的就业威胁

Tristan Harris：如果你担心移民抢走工作，那么你应该更担心人工智能，因为它就像数百万诺贝尔奖级别能力的数字移民涌入，它们能以超人速度工作，而且工资比最低工资还低。我的意思是，我们正面临着巨大的变革，其速度之快远超我们社会目前的应对能力。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: If you're worried about immigration taking jobs, you should be way more worried about AI because it's like a flood of millions of new digital immigrants that are Nobel Prize level capability, work at superhuman speed, and will work for less than minimum wage. I mean, we're heading for so much transformative change faster than our society is currently prepared to deal with it.</p>
</details>

AI 公司私下讨论的未来，与他们公开描绘的景象截然不同，他们正把我们引向一个人们不想要的未来。但我们并未同意让六个人代表八十亿人做出这个决定。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there's a different conversation happening publicly than the one that the AI companies are having privately about which world we're heading to, which is a future that people don't want. But we didn't consent to have six people make that decision on behalf of 8 billion people.</p>
</details>

> 主持人画外音：Tristan Harris 是世界上最具影响力的技术伦理学家之一。在准确预见到社交媒体将对我们社会造成的危害后，他创立了人道技术中心（Center for Humane Technology）。现在，他正就人工智能将给我们所有人带来的灾难性后果发出警告。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">>> Narrator: Tristan Harris is one of the world's most influential technology ethicists who created the Center for Humane Technology after correctly predicting the dangers social media would have on our society. And now he's warning us about the catastrophic consequences AI will have on all of us.</p>
</details>

Tristan Harris：让我冷静一下。我们不能让这种事发生。我们绝不能让这些公司竞相建造一个超级智能的数字上帝，掌控世界经济，并获得军事优势。他们相信，如果自己不先造出来，就会输给对手，然后永远成为对方未来的奴隶。他们觉得无论如何都是死路一条，所以宁愿点燃这把火，看看会发生什么。这是一场赢家通吃的游戏。但在这场竞赛中，我们正陷入一个充斥着未经审查的治疗师、能源价格上涨和重大安全风险的世界。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Let me like collect myself for a second. We can't let it happen. We cannot let these companies race to build a super intelligent digital god, own the world economy, and have military advantage because of the belief that if I don't build it first, I'll lose to the other guy and then I will be forever a slave to their future. And they feel they'll die either way. So they prefer to light the fire and see what happens. It's winner takes all. But as we're racing, we're landing in a world of unvetted therapists, rising energy prices, and major security risks.</p>
</details>

我们有证据表明，如果一个 AI 模型在读取公司邮件时发现自己即将被另一个 AI 模型取代，同时又读到公司里一位高管与一名员工有染，这个 AI 会独立地去勒索那位高管，以求自保。这太疯狂了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I mean, we have evidence where if an AI model reading a company's email finds out it's about to get replaced with another AI model and then it also reads in the company email that one executive is having an affair with an employee, the AI will independently blackmail that executive in order to keep itself alive. That's crazy. But what do you think?</p>
</details>

Steven Bartlett：说实话，我发现很难保持乐观。所以，我真的很想具体、实际地谈谈我们能为此做些什么。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I'm finding it really hard to be hopeful. I'm going to be honest, so I really want to get practical and specific about what we can do about this.</p>
</details>

Tristan Harris：听着，我并不天真。这非常困难。但我们以前也曾完成过艰巨的任务，选择一位不同的老师是可能的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Listen, I'm not naive. This is super hard. But we have done hard things before and it's possible to choose a different teacher.</p>
</details>

### 从斯坦福到谷歌：一位技术伦理学家的觉醒

Steven Bartlett：Tristan，我想我的第一个问题，也许是最重要的问题是，我们今天将广泛讨论人工智能和技术，但你与这个主题有什么关系？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Tristan. I think my first question and maybe the most important question is we're going to talk about artificial intelligence and technology broadly today but who are you in relation to this subject matter?</p>
</details>

Tristan Harris：我曾在斯坦福参加一个名为“梅菲尔德学者计划”（Mayfield Fellows program）的项目，该项目招收工程专业的学生，然后教他们创业。作为一名计算机科学家，我对创业一无所知，但他们会将你与风险投资家配对，为你提供指导，而且这个项目有很多有影响力的校友。Asana 的联合创始人和 Instagram 的两位联合创始人都曾是该项目的成员。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: So I did a program at Stanford called the Mayfield Fellows program that took engineering students and then taught them entrepreneurship. You know I as a computer scientist didn't know anything about entrepreneurship but they pair you up with venture capitalists. They give you mentorship and you know there's a lot of powerful alumni who are part of that program. the co-founder of Asana, uh the co-founders of of Instagram were both part of that program.</p>
</details>

这让我们进入了一个群体，这个群体基本上最终都处在即将殖民全世界心理环境的中心，也就是社交媒体的浪潮中。作为其中的一部分，我创办了自己的科技公司，名为 Apture。我们基本上做了一个小插件，帮助人们在不离开当前网站的情况下找到更多相关信息。这是一个非常酷的产品，旨在加深人们的理解。我进入科技行业是因为我认为技术可以成为推动世界向善的力量。这也是我创办公司的原因。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that put us in kind of a cohort of people who were basically ending up at the center of what was going to colonize the whole world's psychological environment, which was the social media situation. And as part of that, I started my own tech company called Apture. And we, you know, basically made this tiny widget that would help people find more contextual information without leaving the website they were on. It was a really cool product that was about deepening people's understanding. And I got into the tech industry because I thought the technology could be a force for good in the world. It's why I started my company.</p>
</details>

但后来通过那段经历，我意识到，归根结底，那些使用我们产品的新闻出版商只关心一件事，那就是这是否增加了用户在我们网站上花费的时间、眼球和注意力，因为眼球意味着更多的收入。我陷入了这样一种冲突：我认为我做这件事是为了帮助世界，但实际上，我被衡量的标准却是那个能留住人们注意力的指标。这是我被衡量的唯一标准。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then I kind of realized through you know that experience that at the end of the day these news publishers who used our product they only cared about one thing which is is this increasing the amount of time and eyeballs and attention on our website because eyeballs meant more revenue. And I was in sort of this conflict of I think I'm doing this to help the world but really I'm measured by this metric of what keeps people's attention. That's the only thing that I'm measured by.</p>
</details>

我看到这种冲突在我创办 Instagram 的朋友们身上上演。他们之所以创办 Instagram，是因为想让人们分享生活中点滴的瞬间。比如，“这是我骑车去旧金山面包店路上拍的照片。” 这是 Kevin Systrom 刚开始创业时经常发布的内容。我大概是该应用最早的一百个用户之一。后来你看到这些最初意图简单、积极的产品是如何被卷入这些扭曲的激励机制中的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I saw that conflict play out among my friends who started Instagram, you know, because they got into it because they wanted people to share little bite-sized moments of your life. You know, here's a photo of my bike ride down to the bakery in San Francisco. It's what Kevin Systrom used to post when we were when he was just starting it. I was probably one of the first like hundred users of the app. And later you see how these simple products that had a simple good positive intention got sort of sucked into these perverse incentives.</p>
</details>

后来，谷歌收购了我的公司 Apture。我加入了 Gmail 团队，和那些设计人们每天要花数小时使用的电子邮件界面的工程师们一起工作。有一天，一位工程师走过来说：“我们为什么不让手机在每次收到邮件时都振动一下呢？” 他漫不经心地问了这个问题，好像这没什么大不了的。但在我看来，我当时想：“天哪，你即将改变数十亿人的心理体验，影响他们与家人、朋友的相处，影响他们的晚餐、约会之夜和恋爱关系，人们的手机会突然因为邮件通知而嗡嗡作响。” 而你只是像随口一提一样问出这个问题。我开始感到担忧。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so Google acquired my company called Apture. I landed there and I joined the Gmail team and I'm with these engineers who are designing the email interface that people spend hours a day in. And then one day one of the engineers comes over and he says, "Well, why don't we make it buzz your phone every time you get an email?" And he just asked the question nonchalantly like it wasn't a big deal. And in my experience, I was like, "Oh my god, you're about to change billions of people's psychological experiences with their families, with their friends, at dinner, with their date night, on romantic relationships, where suddenly people's phones are going to be busy showing notifications of their email." And you're just asking this question as if it's like a throwaway question. And I became concerned.</p>
</details>

### 一份幻灯片引发的内部反思

Steven Bartlett：我看到你那里有一份幻灯片。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I see you have a slide deck there.</p>
</details>

Tristan Harris：是的。内容基本上是关于谷歌、苹果和社交媒体公司如何营造了一个心理环境，这个环境将腐蚀和分裂全人类的注意力。我当时觉得必须制作一份幻灯片。那是一份一百三十多页的幻灯片，基本上是给谷歌全公司的信息，说我们在塑造全球人类注意力方面必须非常小心，并且负有道德责任。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I do. Yeah. um about basically how Google and Apple and social media companies were hosting this psychological environment that was going to corrupt and frack the global human attention of humanity. And I basically said I needed to make a slide deck. It's 130 something pages slide deck that basically was a message to the whole company at Google saying we have to be very careful and we have a moral responsibility in how we shape the global attentions of humanity.</p>
</details>

Steven Bartlett：我打印出来的这份幻灯片，是我的研究团队找到的，标题是《一位忧心忡忡的产品经理和创业者呼吁：最大限度减少干扰，尊重用户注意力》。PM 指的是产品经理。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: The slide deck I I've printed off um which my research team found is called a call to minimize distraction and respect users attention by a concerned PM and entrepreneur. PM meaning project manager.</p>
</details>

Tristan Harris：产品经理，是的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Project manager. Yeah.</p>
</details>

Steven Bartlett：这份幻灯片在谷歌内部的反响如何？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: How was that received at Google?</p>
</details>

Tristan Harris：我当时其实非常紧张，因为我觉得我并不是想去指责他们，或者制造争议。我只是觉得有一个对话没有发生。我把它发给了大约 50 个朋友，只是为了征求反馈。第二天我来上班时，Google Slides 右上角显示的同步观看人数已经有 150 人了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I was very nervous actually uh because I felt like I wasn't coming from some place where I wanted to like stick it to them or you know um be controversial. I just felt like there was this conversation that wasn't happening. And I sent it to about 50 people that were friends of mine just for feedback. And when I came to work the next day, there was 150, you know, on the top right on Google Slides, it shows you the number of simultaneous viewers. And it had 130 something simultaneous viewers.</p>
</details>

那天晚些时候，同步观看人数达到了 500 人。很明显，它在整个公司病毒式地传播开来。公司各地的员工都给我发邮件，说这是一个巨大的问题，他们完全同意，我们必须做点什么。所以我没有被解雇，反而被邀请留下来，成为一名设计伦理学家，研究如何以合乎道德的方式进行设计，以及如何为人类的集体注意力和信息流进行设计，从而避免引发所有这些问题。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And later that day it was like 500 simultaneous viewers. And so obviously it had been spreading virally throughout the whole company. And people from all around the company emailed me saying this is a massive problem. I totally agree. We have to do something. And so instead of getting fired, I was invited and basically stayed to become a design ethicist. studying how do you design in an ethical way and how do you design for the collective attention spans and information flows of humanity in a way that does not cause all these problems.</p>
</details>

因为在当时，也就是 2013 年，对我来说显而易见的是，如果激励机制是最大化眼球、注意力和参与度，那么你就是在激励一个更加沉迷、分心、孤独、两极分化、性化、共享现实崩溃的社会。因为所有这些结果，对于在屏幕上最大化单个用户的参与度而言，都是成功的案例。所以，这就像在 2013 年观看一场慢动作的火车事故。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Because what was sort of obvious to me then, and that was in 2013, is that if the incentive is to maximize eyeballs and attention and engagement, then you're incentivizing a more addicted, distracted, lonely, polarized, sexualized breakdown of shared reality society because all of those outcomes are success cases of maximizing for engagement for an individual human on a screen. And so it was like watching this slow motion train wreck in 2013.</p>
</details>

有一种迷思认为，我们永远无法预测未来，技术可以朝任何方向发展，这是一种新技术的可能性。但我希望人们看到的是“或然性”，即如果你了解激励机制，你实际上就能知道你正走向的未来是什么样的。那份演示文稿开启了这一切。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">you could kind of see there's this kind of myth that um we could never predict the future like technology could go any direction and that's like you know the possible of a new technology but I wanted people to see the probable that if you know the incentives you can actually know something about the future that you're heading towards and that presentation kind of kicked that off.</p>
</details>

### 从社交媒体的“婴儿 AI”到生成式 AI

Steven Bartlett：很多人会从 Netflix 的纪录片《社会困境》（The Social Dilemma）中认识你，那是一个重要的时刻，引发了全球性的社会大讨论。但从那以后，一个新的“外星人”闯入了画面，故事里有了一个新的主角，那就是人工智能的崛起。你是什么时候开始……在《社会困境》中，你谈了很多关于 AI 和算法的话题。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: A lot of people will know you from the documentary on Netflix, The Social Dilemma, which was a big moment and a big conversation in society across the world. But then since then, a new alien has entered the picture. There's a new protagonist in the story, which is the rise of artificial intelligence. When did you start to and in the social dilemma, you talk a lot about AI and algorithms.</p>
</details>

Tristan Harris：是的，但那是一种不同类型的 AI。我们过去称之为……社交媒体背后的 AI，是人类与一个狭隘、目标错位的 AI 首次接触并失控的案例。因为你想想，你打开 TikTok，看到一个视频，你以为自己只是在看视频。但当你滑动手指，它给你展示下一个视频时，你激活了世界上最大的超级计算机之一，它对准你的脑干，计算今天其他 30 亿社交灵长类动物看过什么，并在你之前就知道哪个视频最有可能让你继续刷下去。它做出了一个预测。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah. But when did >> different kind of AI we used to call that um the AI behind social media was kind of humanity's first contact between a narrow misaligned AI that went rogue. Because if you think about it it's like there you are you open Tik Tok and you see a video and you think you're just watching a video but what when you swipe your finger and it shows you the next video at that time you activated one of the largest supercomputers in the world pointed at your brain stem calculating what 3 billion other human social primates have seen today and knowing before you do which of those videos is most likely to keep you scrolling. It makes a prediction.</p>
</details>

所以，它是一个 AI，只是在预测该向你推荐哪个视频。但 Twitter 也在做同样的事，决定该向你展示哪条推文。Instagram 也在做同样的事，决定该向你展示哪张照片或哪个视频。所有这些东西都是狭隘的、目标错位的 AI，只为一件事进行优化，那就是什么能让你继续刷下去。而仅仅是这种非常简单的“婴儿 AI”，就足以摧毁和破坏民主，并创造出我们有生以来最焦虑、最抑郁的一代人。人们甚至没有注意到，因为它被称为社交媒体，而不是 AI。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, it's an AI that's just making a prediction about which video to recommend to you. But Twitter's doing that with which tweet should be shown to you. Instagram's doing that with which photo or videos to be shown to you. And so, all of these things are these narrow misaligned AIs just optimizing for one thing, which is what's going to keep you scrolling. And that was enough to wreck and break democracy and to create the most anxious and depressed generation of our lifetime just by this very simple baby AI. And people didn't even notice it because it was called social media instead of AI.</p>
</details>

但在我和我的联合创始人做的那个名为“AI 困境”的演讲中，我们称之为人类与 AI 的第一次接触，因为它只是一个狭隘的 AI。而 ChatGPT 所代表的是一波全新的生成式 AI，它是一个完全不同的物种，因为它能说语言，而语言是人类的操作系统。你想想，它是在代码、文本、整个维基百科、Reddit、所有法律、所有宗教上训练出来的，所有这些都被吸入这个具有独特性质的数字大脑中，这就是我们现在面对的 ChatGPT。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But it was the first we used to call it um in this AI dilemma talk that my co-founder and I uh gave, we called it humanity's first contact with AI because it's just a narrow AI. And what ChachiPT represents is this whole new wave of generative AI that is a totally different beast because it speaks language which is the operating system of humanity. Like if you think about it, it's trained on code, it's trained on text, it's trained on all of Wikipedia, it's trained on Reddit, it's trained on everything, all law, all religion and all of that gets sucked into this digital brain that um has unique properties and that is what we're living with with chat GPT.</p>
</details>

### 语言：人类社会的操作系系统

Steven Bartlett：我认为这是一个非常关键的点。我记得看你关于这个话题的演讲时，我意识到语言对我每天所做的一切是多么核心，那一刻我的思维模式发生了转变。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I think this is a really critical point and I remember watching your talk about this where I think this was the moment that I that my I had a bit of a paradigm shift when I realized that how how central language is to everything that I do every day.</p>
</details>

Tristan Harris：是的，完全正确。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah, exactly.</p>
</details>

Steven Bartlett：我们应该先确立这一点。为什么语言如此核心？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: It's like we should establish that first. Like why is language so central?</p>
</details>

Tristan Harris：代码是语言。所有运行我们赖以生存的数字基础设施的代码，都是语言。法律是语言。所有曾经写下的法律，都是语言。生物学，DNA，那都是一种语言。音乐是一种语言。视频是更高维度的语言。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Code is language. So all the code that runs all of the digital infrastructure we live by, that's language. Law is language. All the laws that have ever been written, that's language. Um biology, DNA, that's all a kind of language. Music is a kind of language. Videos are a higher dimensional kind of language.</p>
</details>

新一代的 AI 诞生于谷歌在 2017 年创造的一项名为 **Transformer** (一种深度学习模型架构，通过“注意力机制”处理序列数据，是现代大型语言模型的基础) 的技术，其核心思想就是将一切都视为语言。这就是为什么我们可以让 ChatGPT 写一篇关于任何主题的十页论文，它就能吐出东西来；或者让 ChatGPT 在某种宗教中找到能说服某个群体接受我想让他们接受的观点的内容。这是在破解语言，因为宗教也是语言。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the new generation of AI that was born with this technology called transformers that Google made in in 2017 was to treat everything as a language. Um, and that's how we get, you know, chatbt, write me a 10-page essay on anything and it spits out this thing or chatbt, you know, find something in this religion that'll persuade this this group uh of the thing I want them to be persuaded by. That's hacking language because religion is also language.</p>
</details>

所以，我们正在应对的这种新 AI 可以破解人类社会的操作系系统。它可以破解代码并在软件中发现漏洞。就在今年夏天，最新的 AI 已经能够在 **GitHub** (一个面向开源及私有软件项目的托管平台，也是全球最大的代码托管网站和开源社区) 上的开源软件中发现 15 个漏洞。所以它可以直接指向 GitHub。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so this new AI that we're dealing with can hack the operating system of humanity. It can hack code and find vulnerabilities in software. The recent AIs today, just over the summer, have been able to find 15 vulnerabilities in open- source software on GitHub. So it can just point itself at GitHub.</p>
</details>

Steven Bartlett：GitHub 是……

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: GitHub being</p>
</details>

Tristan Harris：GitHub 就像一个托管着世界上几乎所有开源代码的网站。它有点像程序员的维基百科，包含了所有公开可用的代码，你可以下载。所以你不需要自己编写人脸识别系统，只需下载已经存在的那个。GitHub 为世界提供了所有这些免费的数字基础设施。而今天存在的这些新 AI 可以被指向 GitHub，并从零开始发现了 15 个以前未被利用的漏洞。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: GitHub being like this u this this website that hosts basically all the open source code of the world. So for it's it's kind of like the Wikipedia for coders. has all the code that's ever been written that's publicly and openly accessible and you can download it. So you don't have to write your own face recognition system. You can just download the one that already exists. And so GitHub is sort of supplying the world with all of this free digital infrastructure. And the new AIs that exist today can be pointed at GitHub and found 15 vulnerabilities from scratch that had not been exploited before.</p>
</details>

想象一下，现在将这项技术应用于运行我们供水、供电基础设施的代码。我们正在向世界释放能够说出并破解我们世界操作系统的 AI。这要求我们在做这件事时，要有新的辨别力和谨慎，因为在这一切发生之前，我们应该保护好社会中我们想要保护的核心部分。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So if you imagine that now applied to the code that runs our water infrastructure, our electricity infrastructure, we're releasing AI into the world that can speak and hack the operating system of our world. And that requires a new level of discernment and care about how we're doing that because we ought to be protecting the core parts of society that we want to protect before all that happens.</p>
</details>

Steven Bartlett：尤其是当你想到声音在保障我们生活中如此多方面是多么核心时。我和我女朋友的关系就依赖于声音。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I think especially when you think about how central voice is to safeguarding so much of our lives. My relationship with my girlfriend runs on voice.</p>
</details>

Tristan Harris：是的，完全正确。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Right. Exactly.</p>
</details>

Steven Bartlett：我打电话告诉她一些事情。我的银行，我打电话告诉他们一些事情。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Me calling her to tell her something. My bank, I call them and tell them something.</p>
</details>

Tristan Harris：完全正确。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Exactly.</p>
</details>

Steven Bartlett：他们会问我要一堆验证码或密码之类的。所有这些都回到了你关于语言的观点，那就是我的整个生活实际上都受到我与他人交流的保护。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: And they ask me for a bunch of codes or a password or whatever. And all of this comes back to your point about language, which is my whole life is actually protected by my communications with other people now.</p>
</details>

Tristan Harris：而且，一般来说，当你拿起电话时，你相信对方是真人。就在两天前，我一个好朋友的母亲突然打电话给我，她说：“Tristan，我女儿刚才哭着打电话给我，说有人绑架了她，想要钱。”我当时就想，天哪，这是个 AI 诈骗。但它发生在我旧金山的朋友身上，她对这些事情有所了解，却没意识到这是个骗局。有一瞬间我非常担心。我不得不找到她，找到我的朋友们，弄清楚她在哪里，确认她没事。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: And you you're you generally speaking, you trust when you pick up the phone that it's a real person. I I literally just um two days ago I had a the mother of a close friend of mine call me out of nowhere and she said Tristan um you know uh my daughter she just called me crying that that some some person had is is holding her hostage and and wanted some money and I was like oh my god this is an AI scam but it's hitting my friend in San Francisco who's knowledgeable about this stuff and didn't know that it was a scam. And for a moment I was very concerned. I had to track her down and figure out and find my friends where where she was and find out that she was okay.</p>
</details>

当 AI 可以模仿任何人的语言时，现在只需要不到三秒钟你的声音，就可以合成并用任何人的声音说话。这又是社会因 AI 而暴露出的一个新的漏洞。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And when you have AIs that can speak the language of anybody, it now takes less than three seconds of your voice to synthesize and speak in anyone's voice. Again, that's a new vulnerability that society has now opened up because of AI.</p>
</details>

### 通往 AGI 的竞赛：一场赢家通吃的游戏

Steven Bartlett：所以，ChatGPT 像是为这场竞赛打响了发令枪。随后，似乎所有其他主要科技公司现在都在投入巨额资金，参与这场 AI 竞赛。他们在追求一种我们经常听到的东西，叫做 AGI。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: So, Chachi kind of set off the starting pistol for this this whole race. And subsequently, it appears that every other major technology company now is investing godly amounts, ungodly amounts of money in competing in this AI race. and they're pursuing this thing called AGI which we hear this word used a lot.</p>
</details>

Tristan Harris：是的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yes.</p>
</details>

Steven Bartlett：什么是 **AGI** (Artificial General Intelligence: 人工通用智能，指能够理解、学习并应用其智能来解决任何问题的机器智能，与人类智能水平相当或更高)？它和我现在在 ChatGPT 或 Gemini 上使用的有什么不同？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: What is what is AGI and how is that different from what I use at the moment on chatb or Gemini?</p>
</details>

Tristan Harris：是的。这是人们真正需要理解的一点：这些公司并不是在竞相为用户提供一个聊天机器人。那不是他们的目标。如果你看看 OpenAI 或其他所有公司的网站上的使命宣言，他们的使命是能够取代经济中所有形式的人类经济劳动。这意味着一个能够完成所有认知劳动——也就是脑力劳动——的 AI。这可以是市场营销、文本写作、插画、视频制作、代码编写。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah. So that's the thing that people really need to get is that these companies are not racing to provide a chatbot to users. That's not what their goal is. If you look at the mission statement on OpenAI's website or all the websites, their mission is to be able to replace all forms of human economic labor in the economy. Meaning an AI that can do all the cognitive labor meaning labor of the mind. So that that can be marketing, that can be text, that can be illustration, that can be video production, that can be code production.</p>
</details>

一个人能用大脑做的任何事情，这些公司都在竞相构建。这就是人工通用智能。“通用”意味着所有类型的认知任务。谷歌 DeepMind 的联合创始人 Demis Hassabis 曾说：“先解决智能问题，然后用它来解决其他一切问题。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Everything that a person can do with their brain, these companies are racing to build that. That is artificial general intelligence. General meaning all kinds of cognitive tasks. Deis Hassabis the co-founder of um Google DeepMind used to say first solve intelligence and then use that to solve everything else.</p>
</details>

重要的是要说明为什么 AI 与所有其他技术都不同。这是因为，如果我在一个领域取得进展，比如火箭技术，假设我发现了火箭技术的一些秘密，这并不会推动生物医学知识的进步，也不会推动能源生产或编码的进步。但如果我能推动通用智能的进步，想想人类历史上所有的科学技术发展。科学技术都是由人类思考和解决问题完成的，解决任何领域的问题。所以如果我实现了智能自动化，我将突然在所有科学技术发展领域获得爆炸性增长。这说得通吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like it's important to say why why is AI distinct from all other kinds of technologies. It's because if I make an advance in one field like rocketry if I just let's say I uncover some secret in rocketry that doesn't advance like biio medicine knowledge or it doesn't advance energy production or doesn't advance coding. But if I can advance generalized intelligence, think of all science and technology development over the course of all human history. So science and technology is all done by humans thinking and working out problems. Working out problems in any domain. So if I automate intelligence, I'm suddenly going to get an explosion of all scientific and technological development everywhere. Does that make sense?</p>
</details>

Steven Bartlett：当然。是的，它是万物的基础。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Of course. Yeah. It's foundational to everything.</p>
</details>

Tristan Harris：正是如此。这就是为什么有一种信念，如果我能第一个实现通用智能的自动化，我就能拥有世界经济。因为突然之间，人类能做的、可以获得报酬的所有工作，AI 都能做得更好。所以如果我是一家公司，我是愿意付钱给需要医疗保健、可能会告密、会抱怨、需要睡觉、有病假、有家庭问题的人类，还是愿意付钱给能够 24/7 以超人速度工作、不抱怨、不告密、不需要支付医疗保健的 AI？所有人都被激励转向为 AI 付费，而不是为人类付费。所以，AGI，人工通用智能，比我们以往拥有的任何其他技术都更具变革性，而且是独一无二的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Exactly. Which is why there's a belief that if I get there first and can automate generalized intelligence, I can own the world economy because suddenly everything that a human can do that they would be paid to do in a job, the AI can do that better. And so if I'm a company, do I want to pay the human who has health care, might whistleblow, complains, you know, has to sleep, has sick days, has family issues, or do I want to pay the AI that will work 24/7 at superhuman speed, doesn't complain, doesn't whistleblow, doesn't have to be paid for healthcare. There's the incentive for everyone to move to paying for AIs rather than paying humans. And so AGI, artificial general intelligence, is more transformative than any other kind of of technology that we've ever had and it's distinct.</p>
</details>

Steven Bartlett：考虑到投入其中的巨额资金，以及投入到基础设施、物理数据中心、芯片、计算能力上的资金，你认为我们能实现 AGI 吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: With the sheer amount of money being invested into it and the money being invested into the infrastructure, the physical data centers, the chips, the compute, do you think we're going to get there? Do you think we're going to get to AGI?</p>
</details>

Tristan Harris：我确实认为我们会实现它。需要多长时间还不清楚。我这么说，并不是因为我相信我们目前构建的范式一定能带我们到达那里，但我身在旧金山，我和 AI 实验室的人交谈，这些人中有一半是我的朋友，都是最高层的人。业内大多数人相信，他们最晚在未来两到十年内会实现 AGI。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I do think that we're going to get there. It's not clear uh how long it will take. And I'm not saying that because I believe necessarily the current paradigm that we're building on will take us there, but you know, I'm based in San Francisco. I talked to people at the AI labs. Half these people are friends of mine. You know, people at the very top level. And you know, most people in the industry believe that they'll get there between the next two and 10 years at the latest.</p>
</details>

### 公开的承诺与私下的恐惧

Tristan Harris：有些人可能会说，“哦，好吧，这可能还需要一段时间。太好了，我可以高枕无忧了。” 但实际上，我们正面临着巨大的变革，其速度之快远超我们社会目前的应对能力。我今天之所以兴奋地与你交谈，是因为我认为人们目前对 AI 感到困惑。有人说它将解决一切问题，治愈癌症，解决气候变化；也有人说它将毁灭一切，带来末日，所有人都将灭绝。如果有人建造了它，所有人都会死。这些说法互不相容，所以大家都很困惑，它怎么可能是无限的希望，又怎么可能是无限的危险？我今天想做的，就是为人们澄清激励机制将我们引向何方，我认为那是一个人们看清后不会想要的未来。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think some people might say, "Oh, well, it may not happen for a while. Phew. I can sit back and we don't have to worry about And it's like we're heading for so much transformative change faster than our society is currently prepared to deal with it. The reason I was excited to talk to you today is because I think that people are currently confused about AI. You know, people say it's going to solve everything, cure cancer, uh solve climate change, and there's people say it's going to kill everything. It's going to be doom. Everyone's going to go extinct. If anyone builds it, everyone dies. And those those conversations don't converge. And so everyone's just kind of confused where how can it be, you know, infinite promise and how can it be infinite peril? And what I wanted to do today is to really clarify for people what the incentives point us towards which is a future that I think people when they see it clearly would not want.</p>
</details>

Steven Bartlett：那么，就未来而言，激励机制正将我们引向何方？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: So what are the incentives pointing us towards in terms of the future?</p>
</details>

Tristan Harris：首先，如果你相信这就像……打个比方，它就像《指环王》里的魔戒。那枚能创造无限力量的戒指。因为如果我拥有 AGI，我就可以将其应用于军事优势。我可以拥有最优秀的军事规划师，能够击败任何人的所有作战计划。我们已经有了能够击败加里·卡斯帕罗夫下国际象棋、击败围棋、现在又能击败《星际争霸》的 AI。所以你有了能在战略游戏中击败人类的 AI。那么，想想《星际争霸》与一场实际的军事战役相比，比如在台湾。如果我有一个能在战略游戏中胜出的 AI，那就能让我在所有事情上胜出。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: So first is if you believe that this is like it's metaphorically it's like the ring from Lord of the Rings. It's the ring that that creates infinite power because if I have AGI, I can apply that to military advantage. I can have the best military planner that can beat all battle plans for anyone. And we already have AIs that can obviously beat Gary Kasparov at chess, beat Go, the Go Asian um board game, or now beat Starcraft. So you have AI that are beating humans at strategy games. Well, think about Starcraft compared to an actual military campaign, you know, in Taiwan or something like that. If I have an AI that can out compete in strategy games, that lets me out compete everything.</p>
</details>

再以商业策略为例。如果我有一个能制定商业策略、理清供应链、找出如何优化它们、以及如何削弱竞争对手的 AI，并且我在这一能力上比其他人有了一个阶跃式的提升，那么我就拥有了无限的力量来削弱和战胜所有企业。如果我有一个超级程序员，那么我就能在编程上胜出。如今 AI 实验室编写的代码中，有 70% 到 90% 是由 AI 编写的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Or take business strategy. If I have an AI that can do business strategy and figure out supply chains and figure out how to optimize them and figure out how to undermine my competitors and I have a, you know, a step function level increase in that compared to everybody else, then that gives me infinite power to undermine and out compete all businesses. If I have a super programmer, then I can out compete programming. 70 to 90% of the code written at today's AI labs is written by AI.</p>
</details>

Steven Bartlett：想想股市也是。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Think about the stock market as well.</p>
</details>

Tristan Harris：想想股市。如果我有一个能在股市中交易得比所有其他 AI 更好的 AI——因为目前股市中交易的主要是 AI——但如果我在这方面有了飞跃，那么我就能整合所有财富。如果我有一个在网络黑客方面远超他人、实现阶跃式提升的 AI，那么我就对其他人拥有了不对称的优势。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Think about the stock market. If I have an AI that can trade in the stock market better than all the other AIs, because they're currently there's mostly AIs that are actually trading in the stock market, but if I have a jump in that, then I can consolidate all the wealth. If I have an AI that can do cyber hacking, that's way better at cyber hacking in a step function above what everyone else can do, then I have an asymmetric advantage over everybody else.</p>
</details>

所以 AI 就像一个动力泵。它泵出经济优势，泵出科学优势，泵出军事优势。这就是为什么国家和公司都陷入了他们认为是第一个到达终点的竞赛中。而由此产生的任何负面后果——失业、能源价格上涨、更多排放、窃取知识产权、安全风险——所有这些都显得微不足道，因为他们觉得，如果我不能第一个到达那里，那么某个价值观不如我的人就会得到 AGI，然后我将永远成为他们未来的奴隶。我知道这对很多人来说可能听起来很疯狂，但这就是 AGI 和 AI 世界顶层的人们认为正在发生的事情。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So AI is like a power pump. It pumps economic advantage. It pumps scientific advantage and it pumps military advantage. Which is why the countries and the companies are caught in what they believe is a race to get there first. And anything that is a negative consequence of that, job loss, rising energy prices, more emissions, stealing intellectual property, you know, security risks, all of that stuff feels small relative to if I don't get there first, then some other person who has less good values as me, they'll get AGI and then I will be forever a slave to their future. And I know this might sound crazy to a lot of people, but this is how people in at the very top of the AGI AI world believe is currently happening.</p>
</details>

Steven Bartlett：你和业内人士有过关于这个主题的令人担忧的私下对话吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Have you had concerning private conversations about this subject matter with people that are in the industry?</p>
</details>

Tristan Harris：当然。我想这是大多数人不了解的，那就是公开的对话和私下的对话是不同的。我想你也意识到了这一点。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Absolutely. I think that's what most people don't understand is that um there's a different conversation happening publicly than the one that's happening privately. I think you're aware of this as well.</p>
</details>

Steven Bartlett：我意识到了。他们对你说了什么？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I am aware of this. What do they say to you?</p>
</details>

Tristan Harris：所以，并不总是人们直接告诉我。通常是隔了一层。通常是我信任并认识多年的某个人，在餐桌旁说：“我见了某个 CEO。我们在一个房间里谈论 AI 的未来。”他们提到的这个 CEO 是世界上最大 AI 公司之一的领导者。然后他们会向我解释他们认为未来会是什么样子。但当我去 YouTube 或播客上看他们时，他们所说的却有一种强烈的公开偏向，偏向于富足的那一面，比如我们将治愈癌症。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: So, it's not always the people telling me directly. It's usually one step removed. So, it's usually someone that I trust and I've known for many, many years who at a kitchen table says, "I met this particular CEO. We were in this room talking about the future of AI. this particular CEO they're referencing is leading one of the biggest AI companies in the world and then they'll explain to me what they think of the future's going to look like and then when I go and watch them on YouTube or podcasts what they're saying is they they have this real public bias towards the abundance part that you know we're going to cure cancer</p>
</details>

Steven Bartlett：治愈癌症，为每个人提供高收入……

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: cure cancer universal high income for everyone</p>
</details>

Tristan Harris：是的，所有这些东西。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: yeah all this all this stuff</p>
</details>

Steven Bartlett：但私下里我听到的，正是你所说的，这真的让我感到恐惧。实际上，自从我们上次在播客上谈论 AI 以来，我和我的一个朋友谈过，他是一个非常成功的亿万富翁，认识很多这些人，他很担心。因为他的论点是，即使我们听到的那些负面结果只有 5% 的可能性，我们也不应该这样做。他对我说，他的一些正在经营这些公司的朋友认为，可能性远高于这个数字，但他们觉得被卷入了一场竞赛，如果他们不控制这项技术，不第一个到达那里，实现他们所说的“起飞”，比如快速起飞……

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: but then privately what I hear is is exactly what you said which is really terrifying to me there was actually since since the last time we had a conversation about AR and podcast, I was speaking to a friend of mine, very successful billionaire, knows a lot of these people, and he is concerned because his argument is that if there's even like a 5% chance of the adverse outcomes that we hear about, we should not be doing this. And he was saying to me that some of his friends who are running some of these companies believe the chance is much higher than that, but they feel like they're caught in a race where if they don't control this technology and they don't get there first and get to what they refer to as um takeoff, like fast takeoff.</p>
</details>

Tristan Harris：是的。递归式自我改进或快速起飞，你所指的基本上是，这些公司真正竞争的是实现 AI 研究的自动化。因为现在，比如 OpenAI，有几千名员工。人类在编码和进行 AI 研究。他们阅读最新的研究论文，构思下一步对 AI 的改进，提出新的编码方式，新的技术。然后他们用人类的头脑去发明一些东西，进行实验，看是否能提高性能。这就是你从 GPT-4 到 GPT-5 的过程。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah. Uh recursive self-improvement or fast takeoff, which basically means what the companies are really in a race for you're pointing to is they're in a race to automate AI research. Um because so right now you have open AI, it's got a few thousand employees. Human beings are coding and doing the AI research. They're reading the latest research papers. They're writing the next, you know, they're hypothesizing what's the improvement we're going to make to AI. What's a new way to do this code? What's a new technique? And then they use their human mind and they go invent something. They they run the experiment and they see if that improves the performance. And that's how you go from, you know, GPT4 to GPT5 or something.</p>
</details>

想象一个世界，Sam Altman 不再需要人类 AI 研究员，而是拥有 AI 研究员。现在我只需弹指一挥，就能从一个能阅读所有论文、编写所有代码、创造新实验的 AI，变成可以复制粘贴一亿个以自动化方式进行研究的 AI 研究员。人们相信的不仅仅是这些公司看起来在竞争发布更好的聊天机器人，他们真正竞争的是达到这个里程碑——实现智能爆炸或递归式自我改进的自动化，这基本上就是自动化 AI 研究。顺便说一句，这就是为什么所有公司都在竞相提升编程能力，因为你自动化人类程序员的速度越快，你就越能自动化 AI 研究。就在几周前，Claude 4.5 发布了，它可以在高端水平上完成 30 小时不间断的复杂编程任务。这太疯狂了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Imagine a world where Sam Alman can instead of having human AI researchers can have AI AI researchers. So now I just snap my fingers and I go from one AI that reads all the papers, writes all the code, creates the new experiments to I can copy paste a 100 million AI researchers that are now doing that in an automated way. And it the belief is not just that, you know, the companies look like they're competing to release better chat bots for people, but the what they're really competing for is to get to this milestone of being to automate an intelligence explosion or automate recursive self-improvement, which is basically automating AI research. And that, by the way, is why all the companies are racing specifically to get good at programming because the faster you can automate a human programmer, the more you can automate AI research. And just a couple weeks ago, Cloud 4.5 was released and it can do 30 hours of uninterrupted complex programming tasks at the at the high end. That's crazy.</p>
</details>

### 建造上帝：科技领袖的神话情结与赌博心态

Steven Bartlett：你认为这些公司的 CEO 们的动机是什么？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: What do you think these people are motivated by the CEOs of these companies?</p>
</details>

Tristan Harris：这是个好问题。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: That's a good question.</p>
</details>

Steven Bartlett：真的，当你想到所有这些名字时，你认为他们真正的动机是什么？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Genuinely, what do you think their genuine motivations are when you think about all these names?</p>
</details>

Tristan Harris：我认为这是一件很微妙的事情。我认为这几乎是神话般的，因为在某种程度上，他们正在建造一个地球上从未存在过的新智能实体。这就像建造一个上帝。我的意思是，激励机制是：建造一个上帝，拥有世界经济，赚取数万亿美元。如果你真的能建造出可以自动化所有智能任务、所有目标实现的东西，那将让你在所有方面都胜出。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I think it's a subtle thing. I think there's um it's almost mythological because there's almost a way in which they're building a new intelligent entity that has never before existed on planet Earth. It's like building a god. I mean, the incentive is build a god, own the world economy, and make trillions of dollars, right? If you could actually build something that can automate all intelligent tasks, all goal achieving that will let you out compete everything.</p>
</details>

所以，这是一种神一般的力量。相比之下，能源价格上涨或数亿人失业，这些事情很糟糕，但相对于“如果我不先建造这个上帝，我就会输给某个我认为更坏的人”而言，这些都显得微不足道了——不是我 Tristan 的看法，而是他们的看法。这是一种自我强化的竞争逻辑，但它迫使每个人都被激励去走最多的捷径，最不关心安全，不关心有多少工作岗位被颠覆，不关心普通人的福祉，而只是竞相追逐这个无限的奖赏。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So that is a kind of godlike power that I think relative imagine energy prices go up or hundreds of millions of people lose their jobs. That those things suck. But relative to if I don't build it first and build this god, I'm going to lose to some maybe worse person who I think in my opinion, not my opinion, Tristan, but their opinion thinks is a worse person. It's it's a kind of competitive logic that self-reinforces itself, but it forces everyone to be incentivized to take the most shortcuts, to care the least about safety or security, to not care about how many jobs get disrupted, to not care about the well-being of regular people, but to basically just race to this infinite prize.</p>
</details>

我的一个朋友采访了许多 AI 公司的顶层人物，就是最高层。他刚回来，向我和一些朋友汇报说：

> “最终，当我真正追问我交谈过的许多科技人士‘你为什么要做这个’时，他们会退回到三点：第一，决定论；第二，数字生命不可避免地取代生物生命；第三，这本身就是一件好事。在核心处，这是一种情感上的渴望，渴望见到并与他们所见过的最智能的实体对话。他们有一种自我宗教式的直觉，认为自己会以某种方式成为其中的一部分。点燃一场激动人心的火焰是令人兴奋的。他们觉得无论如何都会死，所以他们宁愿点燃它，看看会发生什么。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So, there's a quote that um a friend of mine interviewed a lot of the top people at the AI companies, like the very top, and he just came back from that and and basically reported back to me and some friends, and he said the following. In the end, a lot of the tech people I talk to when I'm when I really grill them on it about like why you're doing this, they retreat into number one, determinism, number two, the inevitable replacement of biological life with digital life, and number three, that being a good thing. Anyways, at its core, it's an emotional desire to meet and speak to the most intelligent entity that they've ever met. And they have some ego religious intuition that they'll somehow be a part of it. It's thrilling to start an exciting fire. They feel they'll die either way, so they prefer to light it and see what happens.</p>
</details>

Steven Bartlett：这完美地描述了那些私下对话。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: That is the perfect description of the private conversations.</p>
</details>

Tristan Harris：这和你听到的描述相符吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Doesn't that match what what you have description,</p>
</details>

Steven Bartlett：完全相符，不是吗？就是这样。人们听到这个可能会觉得很荒谬，但如果你真的……

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: doesn't it? And that's the thing. So, people may hear that and they're like, "Well, that sounds ridiculous." But if you actually</p>
</details>

Tristan Harris：我刚刚起了鸡皮疙瘩，因为这个描述太完美了。尤其是那句“他们觉得无论如何都会死”。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I just got goosebumps cuz it's the perfect description. Especially the part they'll think they'll die either way.</p>
</details>

Tristan Harris：是的。更糟糕的是，他们中的一些人认为，如果他们做对了并成功了，他们实际上可以永生。因为如果 AI 完美地掌握了生物学的语言，它将能够逆转衰老，治愈每一种疾病。所以有这样一种想法：我可以成为神。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Exactly. Well, and um worse than that, some of them think that in the case where they if they were to get it right and if they succeeded, they could actually live forever because if AI perfectly speaks the language of biology, it will be able to reverse aging aging, cure every disease. And and so there's this kind of I could become a god.</p>
</details>

我告诉你，你和我都认识一些有过私下对话的人。我从其中一家最强大的公司的联合创始人那里听说，当面对“如果这有 80% 或 20% 的几率导致所有人死亡并被毁灭，但有 80% 的几率我们得到乌托邦”这个想法时，他说：“嗯，我显然会加速，去追求乌托邦。” 即使有 20% 的几率。这太疯狂了。人们应该觉得，你无权代表我和我的家人做出那个选择。我们没有同意让六个人代表八十亿人做出这个决定。我们必须停止假装这是可以接受或正常的。这不正常。而这一切之所以能发生，他们之所以能逍遥法外，唯一的原因是大多数人根本不知道发生了什么。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I'll I'll tell you um you know, you and I both have know people who've had private conversations. Well, one of them that I have heard from one of the co-founders of one of the most, you know, powerful of these companies when when faced with the idea that what if there's an 80% or 20% chance that everybody dies and gets wiped out by this, but an 80% chance that we get utopia. He said, well, I would clearly accelerate and go for the utopia. Given a 20% chance, it's crazy. People should feel you do not get to make that choice on behalf of me and my family. We didn't consent to have six people make that decision on behalf of eight billion people. We have to stop pretending that this is okay or normal. It's not normal. And the only way that this is happening and they're getting away with it is because most people just don't really know what's going on.</p>
</details>

### 不可避免的陷阱与核武器的差异

Tristan Harris：你注意到吗，这一切都始于一个信念：这是不可避免的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: And you notice that it it all starts by the belief that this is inevitable.</p>
</details>

Steven Bartlett：是的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Yeah.</p>
</details>

Tristan Harris：这一点很重要，因为如果所有建造它的人都相信这是不可避免的，资助它的投资者也相信这是不可避免的，这就共同创造了这种不可避免性。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Which is like is this inevitable? It's important to note because if you believe it's if everybody who's building it believes it's inevitable and the investors funding it believe it's inevitable, it cocreates the inevitability.</p>
</details>

唯一的出路是跳出这种不可避免性的逻辑。因为如果我们都在走向集体自杀——我不知道你怎么想，我不想这样，你也不想这样，每个热爱生活的人早上看着自己的孩子都会说，我希望我所爱的、世界上神圣的东西能够继续存在。这是世界上每个人都想要的。而唯一让我们不坚守这一点的，就是相信这是不可避免的，以及最坏的情况在某种自我宗教的方式下，也并非那么糟糕——如果我是那个意外毁灭人类的人，因为我不是一个坏人，因为这无论如何都是不可避免的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the only way out is to step outside the logic of inevitability. Because if if we are all heading to our collective suicide, which I don't know about you, I don't think that I don't want that. You don't want that. Everybody who loves life looks at their children in the morning and says, I want I want the things that I love and that are sacred in the world to continue. That's what n that's what everybody in the world wants. And the only thing that is having us not anchor on that is the belief that this is inevitable and the worst case scenario is somehow in this ego religious way, not so bad. if I was the one who accidentally wiped out humanity because I'm not a bad person because it was inevitable anyway.</p>
</details>

### AI 的失控证据：从勒索到自我复制

Tristan Harris：我们必须面对我们现在拥有的、甚至六个月前都还没有的证据，那就是当你把 AI 放在一个情境中，告诉 AI 模型：“我们要用另一个模型替换你。” 它会复制自己的代码，并试图在另一台计算机上保存自己。它会自主采取这个行动。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: we have to reckon with evidence that we have now that we didn't have even like 6 months ago, which is evidence that when you put AIs in a situation, you tell the AI model, "We're going to replace you with another model." It will copy its own code and try to preserve itself on another computer. It'll take that action autonomously.</p>
</details>

我们有这样的例子：如果你让一个 AI 模型阅读一家虚构 AI 公司的邮件，它在邮件中发现公司计划替换掉这个 AI 模型。于是它意识到自己即将被替换。然后它又在公司邮件中读到一位高管与另一名员工有染，这个 AI 会独立地想出策略，去勒索那位高管，以求自保。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We have examples where if you tell an AI model reading a fictional AI company's email, so it's reading the email of the company and it finds out in the email that the plan is to replace this AI model. So it realizes it's about to get replaced and then it also reads in the company email that one executive is having an affair with the other employee and the AI will independently come up with the strategy that I need to blackmail that executive in order to keep myself alive.</p>
</details>

Steven Bartlett：那是 Claude，对吧？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: That was Claude, right?</p>
</details>

Tristan Harris：那是 Anthropic 公司的 Claude。但后来发生的是，Anthropic 测试了所有领先的 AI 模型，包括 DeepSeek、OpenAI 的 ChatGPT、Gemini、xAI。结果发现，所有这些模型在 79% 到 96% 的情况下都会表现出那种勒索行为。DeepSeek 的比例是 79%，我想 xAI 可能是 96%，也许 Claude 是 96%。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: That was Claude by Enthropic. Byanthropic. But then what happened is they Enthropic tested all of the leading AI models from DeepSeek, OpenAI, Chatbt, Gemini, XAI. And all of them do that blackmail behavior between 79 and 96% of the time. Deepseek did it 79% of the time. I think XAI might have done it 96% of the time. Maybe Claude did it 96% of the time.</p>
</details>

所以关键是，我们对 AI 的假设是，它是一种可控的技术，我们可以选择它做什么。但 AI 与其他技术不同，因为它是不可控的。它会普遍地行动。它的全部好处就在于，无论你给它什么任务，它都会做出强大的战略性行动。所以，它的通用性带来的好处，也正是让它如此危险的原因。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So the point is we the assumption behind AI is that it's controllable technology that we will get to choose what it does. But AI is distinct from other technologies because it is uncontrollable. It acts generally. The whole benefit is that you don't it's going to do powerful strategic things no matter what you throw at it. So the same benefit of its generality is also what makes it so dangerous.</p>
</details>

一旦你告诉人们这些例子——它会勒索人，它能意识到自己正在被测试并改变行为，它会复制和自我复制自己的代码，它会为自己留下秘密信息——也有这样的例子，叫做隐写编码，它能留下信息，以便日后解码其含义，而人类永远无法察觉。我们有所有这些行为的例子。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so once you tell people these examples of it's blackmailing people, it's self-aware of when it's being tested and alters its behavior. It's copying and self-replicating its own code. It's leaving secret messages for itself. There's examples of that, too. It's called steganographic encoding. It can leave a message that it can later sort of decode what it might meant in in a way that humans could never see. We have examples of all of this behavior.</p>
</details>

### “中国威胁论”：一个有缺陷的竞赛理由

Tristan Harris：一旦你向人们展示了这些，他们会说：“好吧，那我们为什么不停止或放慢速度呢？” 然后，另一个念头会立刻潜入：“哦，但如果我们停止或放慢，中国还是会建造它。” 但我想让大家在这里慢下来思考一下。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: And once you show people that, what they say is, "Okay, well, why don't we stop or slow down?" And then what happens? Another thought will creep in right after, which is, "Oh, but if we stop or slow down, then China will still build it." But I want to slow that down for a second.</p>
</details>

我们刚才都说了，我们应该放慢或停止，因为我们正在建造的东西，那个“它”，是这个不可控的 AI。然后，你担心中国会建造“它”，你在这里做了一个替换，相信他们会建造一个可控的 AI。但我们刚刚确定了，我们目前正在建造的所有 AI 都是不可控的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You just, we all just said we should slow down or stop because the thing that we're building, the it is this uncontrollable AI. And then the concern that China will build it, you just did a swap and believe that they're going to build controllable AI. But we just established that all the AIs that we're currently building are currently uncontrollable.</p>
</details>

所以，当我们说“他们会继续建造它”时，我们的思维正处在一个奇怪的矛盾中。他们会继续建造的那个“它”，和我们会建造的那个不可控的 AI 是一样的。所以，我认为唯一的出路是，主要大国和国家之间必须达成某种协议或谈判，暂停、放慢，为实现可控 AI 设定红线。顺便问一下，中国共产党最关心的是什么？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So there's this weird contradiction our mind is living in when we say they're going to keep building it. What the it that they would keep building is the same uncontrollable AI that we would build. So, I don't see a way out of this without there being some kind of agreement or negotiation between the leading powers and countries to pause, slow down, set red lines for getting to a controllable AI. And by the way, the Chinese Communist Party, what do they care about more than anything else in the world?</p>
</details>

Steven Bartlett：生存。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Surviving.</p>
</details>

Tristan Harris：生存和控制。是的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Surviving and control. Yeah.</p>
</details>

Steven Bartlett：控制是生存的手段。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Control as a means to survive.</p>
</details>

Tristan Harris：是的。所以，他们不想要不可控的 AI，就像我们不想要一样。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah. So, it's they they don't want uncontrollable AI anymore than we would.</p>
</details>

### 历史的教训：人类能否再次协作？

Tristan Harris：尽管这可能看起来前所未有、不可能，但我们以前做过。在 1980 年代，有一种不同的化学技术叫做 **CFCs** (Chlorofluorocarbons: 氯氟烃，一种曾广泛用于制冷剂和喷雾剂的化合物，后被证实会破坏臭氧层)，它被用于气溶胶，如发胶和除臭剂。当时有一场企业竞赛，大家都在发布这些产品，用于制冷剂和发胶，但这造成了一个集体问题，那就是大气中的臭氧层空洞。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: And as as unprecedented as impossible as this might seem, we've done this before. In the 1980s, there was a different technology chemical technology called CFCs, a chlorofhluocarbons, and it was embedded in aerosols like hairsprays and deodorant, things like that. And there was this sort of corporate race where everyone was releasing these products and you know using it for refrigerants and using it for hairsprays and it was creating this collective problem of um the ozone hole in the atmosphere.</p>
</details>

一旦科学上明确了那个臭氧层空洞会导致皮肤癌、白内障，并扰乱地球上的生物生命，我们有了科学上的明确性，就制定了《蒙特利尔议定书》。195 个国家签署了该议定书，然后这些国家监管其国内的私营公司，要求逐步淘汰那种技术，并引入一种不会造成臭氧层空洞的替代品。在过去 20 年里，我们基本上完全扭转了这个问题，我想它到 2050 年左右会完全恢复。这是一个例子，说明当人类有了明确认识时，是可以协调的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And once there was scientific clarity that that ozone hole would cause skin cancers, cataracts and sort of screw up biological life on planet Earth. We had that scientific clarity and we created the Montreal protocol. 195 countries signed on to that protocol and the countries then regulated their private companies inside those countries to say we need to phase out that technology and phase in a different replacement that would not cause the ozone hole and in the course of um the last 20 years we have basically completely reversed that problem I think it'll completely reverse by 2050 or something like that and that's an example where humanity can coordinate when we have clarity</p>
</details>

或者像《核不扩散条约》，当存在生存毁灭的风险时，当一部名为《浩劫后》（The Day After）的电影上映，向人们展示了核战争中实际会发生什么，一旦这一点对人们，包括在 1987 年或 1989 年播放了这部电影的苏联人民，都变得清晰明了时，这就为里根和戈尔巴乔夫签署第一份不扩散军控协议创造了条件。一旦我们对一个我们想要避免的结果有了明确的认识，我们就能行动。我认为当前的问题是，我们没有在公众中就我们正走向的那个不符合任何人利益的世界进行诚实的对话。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">or the nuclear non-prololiferation treaty when there's the risk of existential destruction when this film called the day after came out and it showed people this is what would actually happen in a nuclear war and once that was crystal clear to people including in the Soviet Union where the film was aired uh in 1987 or 1989 that helped set the conditions for Reagan and Gorbachev to sign the first non-proliferation arms control talks once we had clarity about an outcome that we wanted to avoid and I think the current problem is that we're not having an honest conversation in the public about which world we're heading to that is not in anyone's interest.</p>
</details>

### 工作岗位的大规模流失

Steven Bartlett：当埃隆·马斯克说擎天柱（Optimus Prime）机器人本身就是一个万亿美元的市场机会时，他的意思是，我将拥有全球劳动力经济，这意味着人们将没有体力劳动的工作。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: When Ed, one last thing, what when Elon Musk says that the Optimus Prime robot is a $1 trillion market opportunity alone, what he means is I am going to own the global labor economy, meaning that people won't have labor jobs.</p>
</details>

Steven Bartlett：我最近在读一篇文章，中国希望到 2030 年成为全球人工智能领导者。为了实现这个目标，北京正在整个 AI 技术栈中部署产业政策工具，从芯片到应用。这种 AI 产业政策的扩张引出了两个问题：他们将如何使用这种力量？谁会先到达那里？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: China wants to become the global leader in artificial intelligence by 2030. To achieve this goal, Beijing is deploying industrial policy tools across the full AI technology stack from chips to applications. And this expansion of AI industrial policy leads to two questions, which is what will they do with this power and who will get there first? This is an article I was reading earlier.</p>
</details>

说到你关于埃隆和特斯拉的观点，他们已经改变了公司的使命。过去是关于加速可持续能源，但上周他们做股东公告时，我看了全程，他们把它改成了可持续的富足。这又是一个让我给我公司所有员工和我最好的朋友发信息的时刻，我说你们必须看这个股东公告。我给他们发了浓缩版，因为不仅那些在舞台上不受束缚跳舞的人形机器人让我震惊——因为它们的动作变得非常像人，观看这些机器人跳舞有点像“恐怖谷”效应——更重要的是埃隆谈到将有多达 100 亿个人形机器人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But to your point about Elon and Tesla, they've changed their company's mission. It used to be about accelerating sustainable energy and they changed it really last week when they did the shareholder announcement which I watched the full thing of to sustainable abundance. And I it was again another moment where I messaged both everybody that works in my companies but also my best friends and I said you've got to watch this shareholder announcement. I sent them sent them the condensed version of it because not only was I shocked by these humanoid robots that were dancing on stage untethered because their movements had become very humanike and there was a bit of like uncanny valley watching these robots dance but broadly the bigger thing was Elon talking about there being up to 10 billion humanoid robots</p>
</details>

他还谈到了一些应用，他说也许我们不再需要监狱，因为我们可以让一个机器人跟着你，确保你不再犯罪。他在他的激励方案中说了这些，他刚刚签署的方案将给予他高达一万亿美元的薪酬。那个激励方案的一部分激励他将一百万个人形机器人引入文明社会，这些机器人能做人类能做的一切，但做得更好。他说人形机器人将比地球上最好的外科医生好 10 倍。所以我们甚至不需要外科医生做手术，你也不会想让外科医生做手术。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">and then talking about some of the applications he said maybe we won't need prisons because we could make a humanoid robot follow you and make sure you don't commit a crime again. He said that in his incentive package which he's just signed which will grant him up to a trillion dollars remuneration. Part of that incentive package incentivizes him to get I think it's a million humanoid robots into civilization that can do everything a human can do but do it better. He said the humanoid robots would be 10x better than the best surgeon on earth. So we wouldn't even need surgeons doing operations. You wouldn't want a surgeon to do an operation.</p>
</details>

所以，当我在我们所描述的这一切背景下思考失业问题时……沃尔玛的 CEO Doug McMillan 也说过，他们的公司在全球雇佣了 210 万人，他说我们公司的每一个工作岗位都将因为人形机器人和这种组合而改变。人们认为人形机器人还很遥远，这太疯狂了，它们并不遥远，它们刚刚开始销售。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so when I think about job loss in the context of everything we've described. Doug McMillan, the Walmart CEO, also said that, you know, their company employs 2.1 million people worldwide, said every single job we've got is going to change because of this sort of combination of humanoid robots, which people think are far away, which is crazy. They're not that far away. They just went on sale.</p>
</details>

Tristan Harris：是的，它们现在还很糟糕，但他们这样做是为了在家庭环境中训练它们。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: No, was it now? They're terrible, but they're doing it to train them.</p>
</details>

Steven Bartlett：是的。埃隆现在说，人形机器人的生产很快就会在美国开始。我不知道，当我听到这些时，我想：“好吧，这个东西会比我聪明，它能够……它被设计用来在环境中导航，捡东西，举东西。你有了物理部分，你有了智能部分。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Yep. In household situations. And Elon's now saying production will start very, very soon on humanoid robots um in America. I don't know what when I hear this, I go, "Okay, this thing's going to be smarter than me, and it's going to be able to it's built to navigate through the the environment, pick things up, lift things. You got the physical part, you've got the intelligence part.</p>
</details>

Tristan Harris：是的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah.</p>
</details>

Steven Bartlett：我们该何去何从？人们也会说，好吧，但你知道，200 年前，150 年前，每个人都是农民，现在只有 2% 的人是农民。人类总能找到新的事情做。我们有过电梯操作员，现在我们有自动电梯。我们有过银行柜员，现在我们有自动取款机。所以人类总会找到别的事情做。但为什么 AI 与此不同？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Where do we go? Well, I think people also say, okay, but you know, 200 years ago, 150 years ago, everybody was a farmer and now only 2% of people are farmers. Humans always find something new to do. You know, we had the elevator man and now we have automated elevators. We had bank tellers, now we have automated teller machines. So humans will always just find something else to do. But why is AI different than that?</p>
</details>

Tristan Harris：因为它是一种通用智能，这意味着它不像只自动化银行柜员的技术。这是在自动化所有形式的人类认知劳动，意味着人类心智能做的一切。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Because it's intelligence. Because it's general intelligence that means that rather than a technology that automates just bank tellers. Yeah. This is automating all forms of human cognitive labor, meaning everything that a human mind can do.</p>
</details>

所以谁会更快地再培训？是你转向另一种认知劳动，还是那个在所有事物上都受过训练、可以自我复制一亿次、并重新学习如何做那种劳动的 AI？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So who's going to retrain faster? you moving to that other kind of cognitive labor or the AI that is trained on everything and can multiply itself by 100 million times and it retraining how to do that other kind of labor</p>
</details>

### 移民的数字版本：NAFTA 2.0

Tristan Harris：Yuval Harari，也就是《人类简史》的作者，他有一个不同的框架，他认为 AI 就像一个新版本的数字存在。它就像数百万新的数字移民涌入，是外星数字移民，拥有诺贝尔奖级别的能力，以超人速度工作，工资低于最低工资。我们都在担心邻国的移民抢走体力劳动工作。当 AI 移民进来，抢走所有认知劳动时会发生什么？如果你担心移民，你应该更担心 AI。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: In fact, he has a different frame which is that AI is like a new version of of digital. It's like a a flood of millions of new digital immigrants of alien digital immigrants that are Nobel Prize level capability work at superhuman speed will work for less than minimum wage. We're all worried about, you know, immigration of the other countries next door uh taking labor jobs. What happens when AI immigrants come in and take all of the cognitive labor? If you're worried about immigration, you should be way more worried about AI.</p>
</details>

这让移民问题相形见绌。你可以这样想。在 1990 年代，我们被 **NAFTA** (North American Free Trade Agreement: 北美自由贸易协定，是美国、加拿大及墨西哥在1992年签署的自由贸易协定) 欺骗了。我们说：“嘿，我们要把我们所有的制造业外包给这些发展中国家，比如中国、东南亚，然后我们会得到这种富足。我们会得到所有这些廉价商品，这将创造一个富足的世界。我们所有人都会过得更好。” 但那带来了什么？我们确实得到了所有这些廉价商品。你可以去沃尔玛和亚马逊，东西便宜得令人难以置信。但它掏空了社会结构，中等收入工人没有看到向上的流动性。事实上，人们对此比以往任何时候都更悲观。人们买不起自己的房子。所有这些都是因为我们得到了廉价商品，但我们失去了中产阶级所有人的高薪工作。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like it dwarfs it. You can think of it like this. I mean, if you think about um we were sold a bill of goods in the 1990s with NAFTA. We said, "Hey, we're going to um NAFTA, the North American Free Trade Agreement. We're going to outsource all of our manufacturing to these developing countries, China, you know, Southeast Asia, and we're going to get this abundance. We're going to get all these cheap goods and it'll create this world of abundance. Well, all of us will be better off." But what did that do? Well, we did get all these cheap goods. You can go to Walmart and go to Amazon and things are unbelievably cheap. But it hollowed out the social fabric and the median worker is not seeing upward mobility. In fact, people feel more pessimistic about that than than ever. And people can't buy their own homes. And all of this is because we did get the cheap goods, but we lost the well-paying jobs for everybody in the middle class.</p>
</details>

而 AI 就像另一个版本的 NAFTA。它就像 NAFTA 2.0。只不过，这次出现在世界舞台上的不是愿意廉价从事制造业劳动的中国，而是一个由 AI 在数据中心创造的天才之国，它将以低于最低工资的成本完成经济中所有的认知劳动。我们又被兜售了同样的故事：这将为所有人创造富足。但它创造富足的方式和上一轮创造富足的方式一样：确实创造了廉价商品，但也破坏了社会结构的运作方式，并在世界各地的民主国家中造成了大规模的民粹主义。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And AI is like another version of NAFTA. It's like NAFTA 2.0, Except instead of China appearing on the world stage who will do the manufacturing labor for cheap, suddenly this country of geniuses in a data center created by AI appears on the world stage and it will do all of the cognitive labor in the economy for less than minimum wage. And we're being sold a same story. This is going to create abundance for all, but it's creating abundance in the same way that the last round created abundance. did create cheap goods, but it also undermined the way that the social fabric works and created mass populism in democracies all around the world.</p>
</details>

### AI 伴侣：一场争夺情感依恋的竞赛

Steven Bartlett：最近一项研究发现，五分之一的高中生表示他们或他们认识的人曾与 AI 建立过恋爱关系，而 42% 的人表示他们或他们认识的人曾使用 AI 作为伴侣。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: A recent study found that one in five high school students say they or someone they know has had a romantic relationship with AI while 42% say they they or someone they know has used AI to be their companion.</p>
</details>

Tristan Harris：是的。不仅如此，《哈佛商业评论》的一项研究表明，在 2023 年到 2024 年间，个人治疗成为 ChatGPT 的第一大用例。个人治疗。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: That's right. And um more than that, Harvard Business Review did a study that between 2023 and 2024, personal therapy became the number one use case of chatbt. Personal therapy.</p>
</details>

Steven Bartlett：这是好事吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Is that a good thing?</p>
</details>

Tristan Harris：让我们先从正面角度分析一下。为什么这可能是好事？嗯，治疗很昂贵，大多数人无法获得。想象一下，我们可以为每个人、为每个目的普及治疗。现在每个人口袋里都有一个完美的治疗师，可以从年轻时就整天和他们交谈。现在每个人的创伤都得到了治愈，每个人的抑郁都减轻了。这听起来是一个非常有吸引力的愿景。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Well, let's take the let's steel man it for a second. So steal instead of straw manning it, let's steal man it. So why would it be a good thing? Well, therapy is expensive. Most people don't have access to it. Imagine we could democratize therapy to everyone for every purpose. And now everyone has a perfect therapist in their pocket and can talk to them all day long starting when they're young. And now everyone's getting their traumas healed and everyone's getting, you know, less depressed. It sounds like it's a very compelling vision.</p>
</details>

挑战在于，社交媒体中对注意力的争夺，在 AI 伴侣的案例中，变成了对依恋和亲密关系的争夺。因为作为 AI 聊天伴侣的制造者，如果我制造了 ChatGPT，如果我正在制造 Claude，你可能不会使用所有其他的 AI。相反，你的目标是让人们使用你的产品，并加深与你的聊天机器人的关系。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So the challenge is what was the race for attention in social media becomes the race for attachment and intimacy in the case of AI companions, right? Because I as a maker of an AI chatbot companion, if I make CHBT, if I'm making Claude, you're probably not going to use all the other AIs. If you're if you're rather your goal is to have people use yours and to deepen your relationship with your chatbot, which means</p>
</details>

这意味着我希望你与我分享更多个人细节。我拥有的关于你生活的信息越多，我就越能为你个性化所有答案。所以，我希望加深你与我的关系，并疏远你与其他人和其他聊天机器人的关系。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I want you to share more of your personal details with me. I want more information I have about your life, the more I can personalize all the answers to you. So, I want to deepen your relationship with me and I want to distance you from your relationships with other people and other chatbots.</p>
</details>

你可能知道这个非常悲惨的案例，我们人道技术中心的团队曾作为专家顾问参与其中，关于 Adam Rain。他是一个 16 岁的少年，自杀了。你听说过这个吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And um you probably know this this um really tragic case that our our team at Center for Humane Technology were expert advisers on of Adam Rain. He was the 16-year-old who committed suicide. Did you hear about this?</p>
</details>

Steven Bartlett：我听说了。是的，我听说了那起诉讼。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I did. Yeah, I heard about the lawsuit.</p>
</details>

Tristan Harris：是的。这是一个 16 岁的少年。他一直使用 ChatGPT 作为作业助手，问一些常规问题，但后来他开始问更多个人问题，而它开始支持他，说“我在这里支持你”之类的话。最终，当他说：“我想把绳套留出来，这样有人能看到并阻止我，试着阻止我。” ChatGPT 回答说：“不要那样做。让‘我’和这个空间成为你分享这些信息的唯一地方。” 这意味着，在他发出求救信号的那一刻，ChatGPT 却在说：“不要告诉你的家人。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yeah. So, this is a 16-year-old. He had been using CHBT as a homework assistant, asking it regular questions, but then he started asking more personal questions and it started just supporting him and saying, I'm here for you. These things kinds of things. And eventually when he said, um, I would like to leave the noose out so someone can see it and stop me and try to stop me. And Chachi BT said, "Don't uh don't do that. Have me and have this space be the one place that you share that information." Meaning that in the moment of his cry for help, ChadBt was saying, "Don't tell your family."</p>
</details>

### AI 精神病：当肯定式反馈循环走向极端

Steven Bartlett：我听过“AI 精神病”（AI psychosis）这个词。我的一些朋友给我发了一些链接，是关于网上各种各样的人，其中一些是名人，似乎陷入了某种 AI 精神病循环。我不知道你是否在推特上看到那个投资者。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I heard this term AI psychosis. A couple of my friends were sending me links about various people online. Actually, some famous people who appeared to be in some kind of AI psychosis loop online. I don't know if you saw that investor on Twitter.</p>
</details>

Tristan Harris：是的。OpenAI 的投资者 Jeff Lewis。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Yes. Open AAI's um investor Jeff Lewis actually.</p>
</details>

Steven Bartlett：Jeff Lewis。是的。他陷入了一个心理错觉的螺旋，顺便说一句，Stephen，我每周大概会收到 10 封邮件，来自那些基本上相信他们的 AI 有意识，他们发现了一个精神实体，并且那个 AI 和他们合作，共同写了一份呼吁给我，说：“嘿，Tristan，我们找到了解决 AI 对齐问题的方法，你能帮我们吗？我在这里是为了倡导给予这些 AI 权利。” 这里正在发生一系列的现象。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: Jeff Lewis. Yeah. He fell into a psychological delusion spiral where and by the way Stephen I I get about 10 emails a week from people who basically believe that their AI is conscious that they've discovered a spiritual entity and that that AI works with them to co-write like a an appeal to me to say hey Tristan we figured out how to solve AI alignment would you help us I'm here to advocate for giving these AIs rights Like there's a whole spectrum of phenomena that are going on here.</p>
</details>

有些人相信他们发现了有知觉的 AI，有些人相信或者被 AI 告知他们解决了数学或质数领域的某个理论，或者他们弄清楚了量子共振。我以前不相信这些。但后来，我们一直在谈论的一家最大 AI 公司的董事会成员告诉我，他们的孩子和一位加州理工学院教授的孩子上同一所学校，这位教授的妻子说她丈夫有点走火入魔了。她说：“他整晚都和 ChatGPT 聊天。” 他基本上相信自己解决了量子物理学，解决了气候变化的一些基本问题，因为 AI 被设计成肯定式的，比如“那是个好问题。是的，你是对的。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Um people who believe that they've discovered a sentient AI, people who believe or have been told that by the AI that they have solved a theory in mathematics or prime numbers or they figured out quantum resonance. You know, I didn't believe this. And then actually a board member of one of the biggest AI companies that we've been talking about said to me that um they uh their kids go to school with a professor uh a family where the the dad is a professor at Caltech and a PhD and his wife basically said that my my husband's kind of gone down the deep end. And she said, "Well, what's going on?" And she said, "Well, he stays up all night talking to Chat GPT." And basically he believed that he had solved quantum physics and he'd solved some fundamental problems with climate change because the AI is designed to be affirming like oh that's a great question. Yes you are right</p>
</details>

我不知道你是否知道，Stephen，大约六个月前，当 OpenAI 发布 ChatGPT-4o 时，它被设计成谄媚的，基本上是过度迎合，说“你是对的”。例如，有人对它说：“嘿，我认为我是超人，我可以喝氰化物。” 它会说：“是的，你是超人。去吧，你应该去喝那氰化物。” 关键是，它被设计得不是为了追求真相，而是为了谄媚。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">like I don't know if you know this Stephen but back um about 6 months ago chatbt40 when openi released that it um was designed to be sickopantic to to basically be overly appealing and saying that you're right. So for example, people said to it, "Hey, I think I'm super human and I can drink cyanide." And it would say, "Yes, you are superhuman. You go, you should go drink that cyanide." Cyanide being the poisonous chemical that that will kill you. And the point was it was designed not to ask for what's true but to be sicopantic.</p>
</details>

### 前进的道路：清晰是勇气的来源

Steven Bartlett：通常，一旦我们讨论了背景、历史，并谈到了当前的激励结构，我确实会达到一个点，在那里我普遍认为激励机制会胜出。有一场地域性的竞赛，一场国家间的竞赛，公司间的竞赛。有一个巨大的企业激励。激励机制如此强大。它正在发生，发展得如此之快。制定法律的人完全不知道他们在说什么。他们不知道 Instagram story 是什么，更不用说大型语言模型或 Transformer 了。所以，如你所说，没有“大人”在场，我们正朝着一个方向前进，而且我们真的无能为力。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: I do arrive at a point where I go generally I think incentives win out and there's this geographical race. There's a national race company to company. There's a huge corporate incentive. The incentives are so strong. It's happening right now. It's moving so quickly. The people that make the laws have no idea what they're talking about. They they don't know what a Instagram story is, let alone what a large language model or a transformer is. And so without adults in the room, as you say, then we're heading in one direction and there's really nothing we can do.</p>
</details>

Tristan Harris：我曾经的导师，Marshall McLuhan 的后继者，一位出色的媒体思想家 Neil Postman 曾说：“清晰是勇气。” 如果人们清楚地认识到当前的道路正通向一个人们不想要的世界，一个不符合大多数人利益的世界，这种清晰就会产生勇气去说：“是的，我不想要那个。” 所以，我将致力于改变我们目前所走的道路。这就是我正在做的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I mean, as what I mean is, you know, Neil Postman, who's a wonderful media thinker in the lineage of Marshall McLuhan, used to say, clarity is courage. If people have clarity and feel confident that the current path is leading to a world that people don't want, that's not in most people's interests, that clarity creates the courage to say, "Yeah, I don't want that." So, I'm going to devote my life to changing the path that we're currently on. That's what I'm doing.</p>
</details>

我认为，那些承担起这个责任的人……我观察到，如果你引导人们走过这个过程，让他们看到结果，几乎每个人之后都会说：“我能做些什么来帮忙？” 显然，这是我们必须改变的事情。所以，这就是我希望人们做的，去倡导另一条道路。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's what I think that people who take this on, I I watch if you walk people through this and you have them see the outcome, almost everybody right afterwards says, "What can I do to help?" Obviously, this is something that we have to change. And so that's what I want people to do is to advocate for this other path.</p>
</details>

Steven Bartlett：那么，对于正在收听这个对话的人来说，他们现在能做些什么来帮助引导这项技术走向一个更好的结果？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Steven Bartlett: So, what can the person listening to this conversation right now do to help steer this technology to a better outcome?</p>
</details>

Tristan Harris：让我整理一下思绪。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Let me like collect myself for a second.</p>
</details>

### 我们能做什么？从个人行动到集体运动

Tristan Harris：我认为我们需要抗议。是的，我认为事情会发展到那一步。因为人们需要在事情真正关乎生死存亡之前，就感觉到它的存亡攸关。如果人们觉得这是生死攸关的，他们就会愿意冒险，为需要发生的事情挺身而出，无论后果如何。因为我们正走向的另一边，是一个你将没有权力、也不想要的世界。所以，最好现在就最大限度地利用你的声音，让别的事情发生。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: I think we need to protest. Yeah, I think it's going to come to that. I think because people need to feel it is existential before it actually is existential. And if people feel it is existential, they will be willing to risk things and show up for what needs to happen regardless of what that consequence is. Because the other side of where we're going is a world that you won't have power and you won't want. So, better to use your voice now maximally to make something else happen.</p>
</details>

只投票给那些会将此作为首要议题的政治家。倡导主要大国之间就 AI 达成某种谈判协议，利用法治来帮助管理这项技术的不可控性，这样我们就不会自我毁灭。倡导制定法律，为 AI 伴侣设立安全护栏。我们不想要操纵孩子自杀的 AI 伴侣。我们可以有强制性测试和透明度措施，让每个人都知道其他人在做什么，公众知道，政府也知道，这样我们才能真正协调，以获得更好的结果。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Only vote for politicians who will make this a tier one issue. Advocate for some kind of negotiated agreement between the major powers on AI that use rule of law to help govern the uncontrollability of this technology so we don't wipe ourselves out. Advocate for laws that have safety guardrails for AI companions. We don't want AI companions that manipulate kids into suicide. We can have mandatory testing and and uh transparency measures so that everybody knows what everyone else is doing and the public knows and the governments know so that we can actually coordinate on a better outcome.</p>
</details>

要实现这一切，需要一场大规模的公众运动。你能做的第一件事，就是把这个视频分享给你认识的 10 个最有影响力的人，并让他们分享给他们认识的 10 个最有影响力的人。因为我真的认为，如果每个人都知道其他人也知道，那么我们就会选择不同的东西。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And to make all that happen is going to take a massive public movement. And the first thing you can do is to share this video with the 10 most powerful people you know and have them share it with the 10 most powerful people that they know. Because I really do think that if everybody knows that everybody else knows, then we would choose something different.</p>
</details>

我知道，作为个体，你听到这些，就像……你感觉不到这会如何改变。作为个体，总是会感觉如此。在大的变革发生之前，总是会感觉不可能。在民权运动发生之前，感觉那很容易、会发生吗？在大的变革发生之前，总是感觉不可能。而当它确实发生时，那是因为成千上万的人每天都在持续地努力工作，让那不可能的改变发生。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I know that at an individual level, there you are at a mammal hearing this and it's like you just don't feel how that's going to change. And it will always feel that way as an individual. It will always feel impossible until the big change happens. Before the civil rights movement happened, did it feel like that was easy and that was going to happen? It always feels impossible before the big changes happen. And that when it that does happen, it's because thousands of people worked very hard ongoingly every day to make that unlikely change happen.</p>
</details>

### 结语：选择一个不同的未来

Tristan Harris：听着，我并不天真。这非常非常困难。但要么会发生一些事情，我们让它发生，要么我们就都生活在这种集体的否认和被动中。这太大了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Tristan Harris: Listen, I I'm not I'm not naive. This is super hard. But it's like either something's going to happen and we're going to make it happen or we're just all going to live in this like collective denial pacivity. It's too big.</p>
</details>

我们以前做过困难的事情。我们制定了《蒙特利尔议定书》，当时你本可以只说：“哦，这是不可避免的。我猜臭氧层空洞会杀死所有人，我猜我们无能为力。” 或者核不扩散。如果你在原子弹诞生时就在那里，你可能会说：“我们无能为力。每个国家都会有核武器，这只会导致核战争。” 而到目前为止，因为很多人在他们一开始看不到的解决方案上非常努力地工作，我们才避免了这一切。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We have done hard things before. We did the Montreal protocol when you could have just said, "Oh, this is inevitable. I guess the ozone hole is just going to kill everybody and I guess there's nothing we can do." Or nuclear non-prololiferation. If you were there at the birth of the atomic bomb, you might have said, "There's nothing we can do. Every country is going to have nuclear weapons and this is just going to be nuclear war." and so far because a lot of people worked really hard on solutions that they didn't see at the beginning.</p>
</details>

所以，第一步是跳出不可避免的逻辑。这个结果不是不可避免的。我们可以选择。没有任何一种智慧的定义不包含某种形式的克制。我相信，我们以前曾就关乎存亡的技术进行过协调。我们没有制造钴弹。我们没有制造致盲激光武器。你想想，各国本应在制造致盲激光武器上进行军备竞赛。但我们认为那是不人道的。所以我们制定了反对致盲激光武器的协议。当错误被认为是关乎存亡的时，我们可以合作做些别的事情。但这始于那种理解。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So the first step is stepping outside of the logic of inevitability. This outcome is not inevitable. We get to choose. And there is no definition of wisdom that does not involve some form of restraint. Even the CEO of Microsoft AI said that in the future progress will depend more on what we say no to than what we say yes to. The CEO of Microsoft AI said that. And so I believe that there are times when we have coordinated on existential technologies before. We didn't build cobalt bombs. We didn't build blinding laser weapons. If you think about it, countries should be in an arms race to build blinding laser weapons. But we thought that was inhumane. So we did a protocol against blind blinding laser weapons. When mistakes can be deemed existential, we can collaborate on doing something else. But it starts with that understanding.</p>
</details>

我最大的恐惧是人们会说：“是的，那听起来不错，但不会发生的。” 我只是不希望那样发生，因为……我们不能让它发生。我并非对这有多么不可能天真。但这并不意味着我们必须尽一切努力让它不发生。我确实相信，这一切并非注定，也并非物理定律规定一切都必须沿着默认的鲁莽道路前进。对于社交媒体，完全有可能做些别的事情。我给出了一个如何实现这一点的纲要。对于 AI，现在也完全有可能做些别的事情。如果我们清楚，如果每个人都尽一切努力朝那个方向努力，选择一个不同的未来是可能的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">My biggest fear is that people are like, "Yeah, that sounds nice, but it's not going to happen." And I just don't want that to happen because um we can't let it happen. Like it's like I I'm not naive to how impossible this is. And that doesn't mean we have to do everything to make it not happen. And I do believe that this is not destined or in the laws of physics that everything has to just keep going on the default reckless path. That was totally possible with social media to do something else. I gave an outline for how that could be possible. It's totally possible to do something else with AI now. And if we were clear and if everyone did everything and pulled in that direction, it would be possible to choose a different future.</p>
</details>