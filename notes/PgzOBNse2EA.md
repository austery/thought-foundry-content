---
area: tech-engineering
category: ai-ml
companies_orgs: []
date: '2025-10-13'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- how-i-ai
products_models: []
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=PgzOBNse2EA
speaker: How I AI
status: evergreen
summary: 本文深入探讨了提升AI产品质量的系统性方法，包括通过数据分析识别用户输入中的模糊性、实施错误分析以发现上游问题、利用二元输出的LLM判官进行评估，以及通过提示工程和微调来改进AI系统。文章强调了人工洞察和结构化流程在AI产品开发中的核心作用。
tags:
- analysis
- data
- product
title: AI产品质量提升：评估、错误分析与优化提示的系统性方法
---

### 提升AI产品质量的核心概念

Claire Vo: 要想打造更高质量的AI产品，人们需要了解哪些基本概念？

Hamill: 最重要的是审视数据。早在AI出现之前，审视数据就一直很重要。对于AI来说，只是在原有基础上稍作调整，但本质上是一样的。当你看到像这样真实的**用户输入**（user input: 用户提供给AI系统的原始文本或指令）时，你会发现用户给AI的提示语非常模糊。

Claire Vo: 没错，这正是有趣之处。一旦你发现人们是以那种方式交流的，你可能就会想模拟那种输入，因为那才是数据的真实分布，或者说，那才是真实世界的面貌。

Claire Vo: 我相信我们的听众期待某种能自动完成这一切的神奇系统，但你却说：“不，伙计。你只需花三个小时的下午时间，亲自阅读一些聊天记录，用你的肉眼审视它们，为每条记录写下一句笔记，然后进行一次快速的分类练习，就可以开始工作了。”你会发现这能真正地影响产品质量并减少错误。

Hamill: 是的，它对质量有巨大的影响。它如此强大，以至于我的一些客户仅仅通过这个过程就非常满意，他们会说：“太棒了，Hamill，我们搞定了！”而我则会说：“不，等等，我们还能做得更多。”

### 如何AI：AI产品构建与调试

Claire Vo: 欢迎回到《How I AI》。我是Claire Vo，一位产品负责人和AI狂热者，致力于帮助大家利用这些新工具更好地构建产品。今天我为大家带来了一集非常有教育意义的节目，特别适合像我这样正在构建AI产品的人。我们邀请了Hamill Hussein，他将为我们揭秘如何调试AI产品中的错误、编写优秀的**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的），并展示他如何使用**Claude**（Claude: Anthropic公司开发的一系列大型语言模型）和一个GitHub仓库来运营他的整个业务。让我们开始吧！本期节目由GoFundMe Giving Funds赞助，这是一个零费用的**DAFF**（Donor-Advised Fund: 捐赠者建议基金：一种慈善捐赠账户，允许捐赠者获得即时税收减免，然后建议如何将资金捐赠给符合条件的慈善机构）。我想告诉大家GoFundMe推出的新产品，叫做Giving Funds。这是一种更智能、更简单的捐赠方式，尤其是在报税季，它基本上已经到来。GoFundMe Giving Funds是全球排名第一的捐赠平台提供的DAFF，受到2亿人的信任。它基本上就是你自己的迷你基金会，无需律师或管理费用。你捐赠资金或增值资产，立即获得税收减免，可能减少资本利得，然后稍后决定从140万个非营利组织中选择捐赠对象。它没有管理费或资产费，当资金存放在那里时，你可以进行投资并免税增长，这样你以后就有更多的钱可以捐赠。所有这些都来自一个简单的中心，只有一个干净的税单。现在锁定你的减免，稍后决定捐赠地点。非常适合报税季。加入GoFundMe的2亿人社区，开始节省你的税单。同时帮助你最关心的事业。立即在gofundme.com/howi启动你的Giving Fund。如果你将现有的DAFF转过来，我们甚至会承担DAFF支付费用。访问gofundme.com/howiai开始你的Giving Fund。Hamill，我真的对这集节目很兴奋，因为我从事产品构建已经很长时间了，这是我职业生涯中少数几次，我正在构建的产品在“如何做”和“是什么”方面与我过去构建的产品如此不同。它们在技术上是不同的，从用户体验的角度来看也是不同的，而且它们在后端拥有这些**非确定性模型**（non-deterministic models: 指在相同输入下可能产生不同输出的模型，例如大型语言模型），而我作为产品负责人，某种程度上要负责让它们输出高质量、一致、可靠、有趣的用户体验，这是一个极具挑战性的问题。我喜欢你今天将要展示给我们的，是如何系统性地处理AI世界中的产品构建质量问题，以及你如何使用不同的技术将对我们所有人来说都是新事物的AI产品从“好”提升到“卓越”。

Hamill: 是的，我很高兴来到这里。很高兴能谈论这个话题。

Claire Vo: 对于产品经理来说，这确实是一个全新的领域。我很想知道你是否可以从基础开始讲起。你认为构建AI产品的人真正需要了解哪些基本概念或事项，才能打造出更高质量的产品？我知道你还会向我们展示一些如何做到这一点的例子。

### 数据分析：AI产品质量提升的基石

Hamill: 基础确实归结为最重要的一点：审视数据。我相信，通过与许多产品经理的合作经验，审视数据一直都是重要的，甚至在AI出现之前也是如此。你知道，我敢肯定，那些能够编写一点**SQL**（Structured Query Language: 结构化查询语言：用于管理关系数据库的计算机语言）或熟悉电子表格的产品经理，他们会查看数字、查看指标，这在如今看来，似乎是成为一名优秀产品经理的基本要求。因此，对于AI而言，这只是有一点点不同，但本质上是一样的。

Hamill: 而且它就像是，好吧，你如何为AI做到这一点？这就是我们所教的，也是我今天将向你展示的。

Claire Vo: 太棒了，我完全同意。我认为我作为一名年轻的“菜鸟”产品经理学到的最具变革性的技能之一，就是能够编写SQL并实际进行自己的数据分析和探索。但我认为现在AI的**表面积**（surface area: 指一个系统或产品与外部世界互动的所有方式和接口，在这里指AI系统需要考虑和处理的各种输入和输出情况）如此之广，而且数据也不同了。那么，你为什么不向我们展示一下，在构建这些AI产品时，我们应该关注什么呢？

### 案例研究：Nurture Boss的AI助理失败案例

Hamill: 好的。我来分享一下我的屏幕。我先给大家介绍一些背景信息。这是我的一位客户，公司名叫Nurture Boss。正如你所看到的，它是一款面向公寓经理或物业经理的AI助理。

Hamill: 基本上，你可以从我正在展示的网站上了解一些情况。它是一个虚拟租赁助理。它会帮助处理整个**漏斗顶部**（top of funnel: 营销或销售漏斗的第一阶段，旨在吸引尽可能多的潜在客户并激发他们的兴趣），比如帮助安排预约、帮助潜在居民找到公寓、设置预约、回答租金问题等等。它试图减少物业经理的繁重工作，但仍然保留人工参与。所以当他们找到我时，他们已经制作出了一个原型，就像每个人都会做的那样，进行了一番**初步测试**（vibe checking: 非正式地评估某物或某人的感受、氛围或潜在反应），并将所有东西整合在一起。但他们想知道，如何才能真正让它运行良好？因为AI会以奇怪的方式失败，它并不总是做正确的事情，但感觉就像，好吧，每次我们修复一个**提示**（prompt: 给AI模型的指令或问题），我们都不确定，也许我们正在破坏其他东西，或者它真的整体上改善了吗？我们真的不知道。我们只是在猜测。我们只是看着它，凭感觉判断。而这种感觉对于尝试扩展产品来说是非常不舒服的。

### 理解AI交互中的“追踪链”

Hamill: 好的，我要直接切入的第一个概念是**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）。追踪链是工程学中的一个概念，但它不必令人望而生畏。基本上，它对于AI来说非常**应景**（topical: 与当前主题或情况高度相关），因为AI通常有许多不同的事件，尤其是对于聊天机器人，你会有多轮对话，你和AI之间来回交流。可能涉及信息**检索**（retrieval: 在AI系统中，指从知识库或数据库中获取相关信息以辅助生成响应的过程，常用于检索增强生成（RAG）系统），可能涉及调用一些工具——外部工具、内部工具等等。所以你需要记录这些追踪链。有很多不同的方法可以做到这一点，但为了向你展示Nurture Boss究竟发生了什么，我们来看看它长什么样。这是一个名为Brain Trust的平台。还有很多其他平台，比如Phoenix，它也有完全相同的数据。这其实不重要。你可以看到它们都是一样的，对吧？所以我们这里有的，我来进入一个单一的追踪链。这就是我所说的追踪链。我可以把它放大，这样你就可以全屏看到它，你可以看到这个产品中的AI交互是什么样的。所以你有**系统提示**（system prompt: 预设给AI模型的一系列指令或角色定义，用于指导其行为和生成内容）：你是一个AI助理，在一个公寓担任租赁团队成员。这些都是虚构的，因为这些都经过了**个人身份信息**（PII: Personally Identifiable Information: 任何可用于识别、联系或定位个人身份的信息）的**清洗**（scrubbed: 清除或移除敏感信息）。你知道你的主要职责是回复短信。所以这是接收短信。好的。你有一整套规则，比如回复，提供准确信息，回答居民的任何问题，做以下事情，比如如果他们询问租房申请，提供这个网站等等，所有这些规则，对吧？这是一个真实的用户说“你好，四个月的租金怎么回事？”我甚至不知道那是什么意思。

Hamill: 我明白了，我明白了，我来读一下：“你好，四个月的租金怎么回事？”我以为我理解了。我以为我理解了。

Claire Vo: 是的，不清楚，但没关系。我是说，这没问题。这是真实的。这是真实世界。这些是真实的追踪链。所以，然后这里有一个**工具调用**（tool call: AI系统调用外部或内部功能/API以执行特定任务），叫做“获取社区信息”。它正在调用这个工具，这个内部工具。然后工具调用的结果。

Hamill: 返回了这些信息，这些都对用户隐藏。用户看不到这个工具调用结果。它就像是，好吧，这是你可以使用的关于社区的信息，等等。它甚至不确定这是否是正确的工具调用。我们稍后会讲到这一点。然后助理回复：“你好，我们目前提供长达八周的免租金作为特别促销。”所以这是回到用户。这是AI回复给用户的内容。“你好，我们目前提供长达八周的免租金作为特别促销。请注意，适用的租赁特惠和优惠可能有所不同，等等。”

Hamill: 好的，那么这是否……我有一个自己的备忘单，上面写着什么是对的，什么是错的。好的。所以这里的评论是，用户可能在询问租期之类的事情，而不是特惠。所以，这并不清楚这是否正确，这不是我们想要的。这太现实了，对吧？每个人都经历过这样的AI，它有点帮助，但并没有真正按照你想要的方式去做，而且这实际上相当具有挑战性，因为它并不清楚用户想要什么，你可能会往很多不同的方向发展。

Claire Vo: 当我测试我自己的AI时，这是一个非常令人大开眼界的例子。因为当我测试我自己的AI时，我会问它好的问题，我拼写正确，我表达得很清楚。但当你看到像这样真实的**用户输入**（user input: 用户提供给AI系统的原始文本或指令）时，你真正审视用户给你的AI发出的提示语，你会意识到它非常模糊。他们会说“怎么了？”这个问题没有明确的问题。所以，我真的认为查看真实的用户数据可以帮助开发者或产品经理摆脱他们自己认为用户将如何与系统交互的思维定式。

Hamill: 绝对如此。这样做非常关键。所以现在你可能没有这些数据，我只是直接跳到一个真实的例子来开启话题，我们可以深入探讨所有这些不同的**兔子洞**（rabbit holes: 指深入探究一个复杂或耗时的问题，往往偏离了主要目标），比如如果你没有数据怎么办等等，但我只是想把它建立在基础上，设定好舞台，比如：

Hamill: 这就是一种基础：你必须拥有数据。

Hamill: 获取数据有不同的方法。一种是你可以在真实系统中记录它，然后你就可以查看这些东西。另一种方法是，你可以拥有**合成数据**（synthetic data: 通过算法或模拟生成的数据，而非真实世界收集的数据），你可以通过**大型语言模型**（LLM: Large Language Model: 指拥有大量参数、在海量文本数据上训练而成的深度学习模型，能够理解、生成和处理人类语言）生成这样的问题，你知道，比如“你好，什么……”生成像那样的问题可能很难，因为我甚至不知道，我们不知道它是什么意思，而且LLM可能不会生成那样的问题，但这正是整个有趣之处：一旦你看到人们那样说话，你可能就会想模拟那样的数据，因为如果那是数据的真实分布，或者那是真实世界的面貌，那么你可能就需要适当地挑战你的LLM或你的AI系统。好的，我们回到这里。所以你有这个系统，它正在做一些事情。正在发生这样的事情。如果你想，我们可以看看另一个追踪链，只是为了了解一下。

Hamill: 而且，你知道，这不是预先设定好的。我没有记住这些追踪链中发生了什么。我们只是自然地查看它们。

Hamill: 所以，这是另一个公寓综合体，Metobrook Apartments。同样的概念。所以，我们不会再读整个系统提示了。好的。所以我们会向下滚动。我们来看看用户在问什么。“Walk in T。”所以这一定是另一个短信情境。助理说：“我们的团队会尽力满足不预约的访客。我帮你找人。”这太搞笑了。我不知道，为什么LM会这样？这很令人惊讶。为什么它会对一个可以提供帮助的人说“我帮你找人”？也许它试图模仿用户？

Hamill: 然后它确实做了，是的，然后，好的，太好了。所以这个似乎可以。我们看看我们最终标注了什么。是的，我们说这个没问题。这里有一些关于我们标签的**元数据**（metadata: 描述数据的数据，例如数据的创建时间、作者、类型等），我们接下来会讨论。但是，是的，你可以看到这是一个真实的系统。这里可能会发生很多不同的事情。

### 错误分析：从无法处理到可操作的洞察

Hamill: 所以问题就来了，好吧，我们谈论了编写SQL和数据，但是你如何将同样的思维方式应用于此呢？你甚至如何处理这个呢？你如何分析这个而不陷入困境？因为这看起来像是。

Claire Vo: 一开始似乎是无法处理的。不，我只是在想，我应该编写什么样的SQL查询来获取第一个提示？你如何查询所有包含拼写错误的第一个提示？如何查询所有模糊问题的第一个提示？这感觉几乎是难以克服的。然后你知道，你向我们展示了两个例子，这只是成千上万个例子中的两个。所以手动检查可能不是非常可扩展的。所以我想知道，这里的系统性解决方案是什么？

Hamill: 好的，系统性解决方案叫做**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进）。

Hamill: **错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进）意味着它是一种反直觉但极其有效的方法，它很简单，但对每个人都适用，而且它确实有效，这不是我凭空捏造的。它在机器学习领域已经存在很长时间了，因为实际上机器学习也有同样的问题，比如在**生成式AI**（Generative AI: 指能够生成全新内容（如文本、图像、音频、视频等）的人工智能系统）之前，我们有这些**随机系统**（stochastic systems: 指其行为或输出包含随机或不确定元素的系统），它们可以做很多事情，那么你如何实际分析它并找出哪里出了问题并加以改进呢？所以错误分析有两个步骤。第一步是写笔记，这叫做**开放式编码**（open coding: 在质性研究中，指对原始数据进行初步分析，通过逐行阅读并标注相关概念和主题，以发现潜在模式的过程），它基本上就是记录哪里出了问题。所以如果我们回到我们看到的那个追踪链。我来回到它。就像我们看到的第一个追踪链，我们会进入这个追踪链，然后我们会说，好吧，每个**可观察性工具**（observability tool: 帮助用户监控、理解和调试复杂系统内部状态的工具）都有自己不同的记录笔记的方式。你已经在这里有一条笔记了：助理应该就“四个月的租金怎么回事”这个问题提出后续问题，因为它用户意图不明确。这就是写下正在发生的事情的笔记。

Hamill: 好的。

Hamill: 你会随机抽取100个追踪链，然后对它们进行这样的操作。

Hamill: 你会停止在发现的最**上游错误**（upstream error: 在一系列因果事件中，指最先发生的导致后续问题的错误）。所以你阅读这些，看看发生了什么，然后你会想，嗯，好吧，用户意图似乎我们没有很好地澄清他们到底需要什么。

Claire Vo: 是的。

Hamill: 所以我认为这是事件序列中最上游的问题。所以我要把它写下来作为笔记。

Claire Vo: 是的，你强调要关注最上游的问题，因为你认为如果能及早明确意图、及早纠正错误，那么系统后续部分就更有可能正确运行。

Hamill: 是的，因为它是因果关系。所以当事件序列发生时，无论是用户提示、**工具调用**（tool calls: AI系统调用外部或内部功能/API以执行特定任务）、**RAG**（Retrieval-Augmented Generation: 检索增强生成：一种结合了信息检索和文本生成的技术，使大型语言模型能够访问外部知识库以生成更准确和最新的响应）的检索，无论是什么，链条上的任何一点的任何错误都会导致下游问题。因此，为了简化我们进行**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进）的目的，这是一个**启发式方法**（heuristic: 一种经验法则或解决问题的方法，不保证找到最优解，但通常能提供一个足够好的解决方案）。你知道，最终你确实会关心不同的错误和不同的下游问题，但当你刚开始时，只关注上游错误，因为我们正在努力使其变得可处理，这是你快速获得结果的方法。所以基本上，你所做的就是，你进行并收集一堆笔记。

Hamill: 然后你所做的就是，你可以下载这些笔记或做其他事情，你可以对这些笔记进行分类，你甚至可以将这些笔记放入像ChatGPT这样的工具中。你可以说：“嘿，这是我所有的笔记，你能把它们归类吗？”然后你可能需要来回调整一下，比如“嘿，这些是我的笔记，这些是类别。嗯，我认为你缺少一个类别”，等等。

### 自定义标注工具与分类统计

Hamill: 对于Nurture Boss，我们最终做的是，我们实际上制作了一个我们强烈推荐很多人考虑的东西：制作你自己的**自定义标注工具**（custom annotation tool: 用户根据特定需求定制的软件或平台，用于对数据进行标记或添加元数据，常用于训练AI模型或进行数据分析）。就像你看到的，这里在Brain Trust中有，在Arise Phoenix中也有。它们非常相似。你可以看到这是一个看起来非常相似的用户界面，他们甚至在这里称之为错误分析，你可以添加你的笔记，你知道，无论是什么，你可以保存这些笔记。同样，如果你要查看大量数据，你不想拖慢自己的速度。

Hamill: 而且你希望能够有非常易读的输出。有时，像这种Markdown格式的东西并不是那么易读，你希望确保它对你有意义，并且你可以尽可能快地浏览它。所以，你知道，给这些东西进行**凭感觉编码**（vibe code: 非正式地、快速地对数据进行分类或标记，通常基于直觉或大致的印象）真的很容易。

Hamill: 因为最终你所做的就是展示数据。所以在Nurture Boss的情况下。

Hamill: 正如你可能已经了解到的，他们有多个渠道供客户联系他们。他们有我们看到的短信。他们有电子邮件。他们的网站上有一个聊天机器人等等。所以他们只是想要一个可以更快导航的东西，就像我的代码一样。我的意思是，他们有那个权限，我们是开发者，但我们正在我们的流程中使用AI来非常快速地完成这个任务，那就是：这个追踪链来自哪个渠道？然后还有一些其他过滤器，比如我们是否已经标注了它，或者没有。然后顶部有一些统计数据。你知道，这就是标注的样子，它有点相似，但只是根据我们想要的进行了调整。你知道，我们只是做了笔记。

Hamill: 然后，对于Nurture Boss，我们所做的是，我们有一个自动化流程，可以总结并分类这些笔记，找出最大的问题，然后我们就会做一些非常简单的事情，比如计数。计数总是强大的。作为产品经理，你知道，你可以在系统中进行体验，比如编写SQL查询，你知道计数有多强大。计数依然强大。所以你可以统计这些问题，对吧？所以，对于Nurture Boss，我不知道你是否能看到我的屏幕，或者它是否太小了，我可以试着放大一些。

Claire Vo: 是的，是的，太棒了。

Hamill: 好的，在进行了只花了几个小时的**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进）练习后，最大的问题是什么？

Claire Vo: 是的。

Hamill: 比如，我们有很多**转移和交接问题**（transfer and handoff issues: AI系统在将用户请求转移给人类代理或在不同AI模块之间传递信息时出现的问题）。我们试图将客户转移给人工。

Hamill: 我们有很多**行程安排问题**（tour scheduling issues: AI系统在安排或重新安排用户请求的参观或行程时出现的问题）。比如，他们试图安排行程，但像重新安排行程。在这种情况下，我们发现有人要求重新安排，但实际上没有重新安排的行程，而AI不知道这一点。它只是继续安排更多的行程，这很糟糕。你知道，**跟进**（follow-up: 指AI系统在用户提出问题后未能提供进一步的回复或相关信息）。所以AI在用户有问题时没有跟进。有时提供了不正确的信息。好的，所以你可以看到这些是统计结果，现在我们不再迷茫了。现在我们知道我们应该做什么了。我们知道，好吧，我们应该修复这个转移和交接问题以及这个行程安排问题。我们有信心，你知道，我们不再**瘫痪**（paralyzed: 形容由于不确定或恐惧而无法行动或做决定）了。我们知道，好吧，这是我们需要专注于修复的AI问题。

### 赞助商：Persona - AI时代下的身份验证

Claire Vo: 本期节目由Persona赞助，Persona是一个**B2B身份平台**（B2B identity platform: 为企业提供身份验证和管理服务的平台），帮助产品、欺诈以及信任与安全团队在AI优先的世界中保护他们正在构建的产品。2024年，**机器人流量**（bot traffic: 由自动化程序而非人类用户产生的网络流量）正式超越了人类在线活动。随着AI代理预计在未来十年末驱动近90%的所有流量，很明显，互联网的大部分将不再是人类。这就是为什么信任和安全比以往任何时候都更加重要。无论你是在构建下一代AI产品还是推出新的数字平台，Persona都能帮助确保是真实的人类，而不是机器人或恶意行为者，在访问你的工具。通过Persona的构建模块，你可以验证用户、打击欺诈并满足合规要求。所有这些都通过根据你的产品和风险需求量身定制的身份流程来实现。如果你验证过你的LinkedIn个人资料或注册过Etsy账户，你可能已经见过Persona在行动。它为互联网上最受信任的平台提供身份验证，现在它也可以为你的平台提供支持。访问withpersona.com/howiAI了解更多。

### 错误分析的实践与价值

Claire Vo: 我喜欢这个。总结一下，你正在获取这些真实对话的**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）。而且，你知道，你甚至不必阅读所有内容。你只需阅读直到遇到一个**障碍**（snag: 意外的困难或问题），对吧？遇到一个明显的错误或体验中高摩擦的部分。你已经**凭感觉编码**（vibe coded: 非正式地、快速地对数据进行分类或标记，通常基于直觉或大致的印象）了一个应用程序，使团队能够非常容易地进入，标注这些内容，对它们进行好坏质量的评级，自动对它们进行分类，统计它们，然后你就会得到一个优先列表，你就会知道：“这些是我需要解决的问题。”我喜欢这一点，你知道，我敢肯定我们的听众期待某种能自动完成这一切的神奇系统，但你却说：“不，伙计。你只需花三个小时的下午时间，亲自阅读一些聊天记录，用你的肉眼审视它们，为每条记录写下一句笔记，然后进行一次快速的分类练习，就可以开始工作了。”你会发现这能真正地影响产品质量并减少错误。

Hamill: 是的，它对质量有巨大的影响。它如此强大，以至于我的一些客户仅仅通过这个过程就非常满意，他们会说：“太棒了，Hamill，我们搞定了！”而我则会说：“不，等等，我们还能做得更多。”你知道，你付了更多的钱，之类的。他们会说：“不，这太棒了！我只是觉得我知道该怎么做。”所以他们在这个过程中找到了巨大的价值，而且这非常重要。这是没有人谈论的事情。人们在谈论**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的）时，会说：“你如何编写评估？你做什么评估？你应该使用什么工具？”在你进入所有这些之前，你需要对你应该编写什么样的评估有一些基础，因为评估是无限的。所以，在这种情况下，我们编写了一个关于行程安排问题的评估，我们编写了一个关于转移和交接问题的评估，我们对此感觉非常好，因为我们知道那是一个真正的问题，我们知道如何编写评估，因为我们看到了那个错误。而且我们知道如何找到数据来测试那个评估，因为我们已经标记了它，我们看到了那个错误，这正是你想要做的方式。

Claire Vo: 是的，我喜欢这种方法的一点是，它减轻了用户的负担。我的意思是，很多人试图通过放置一个“竖起大拇指”和“竖起大拇指朝下”的按钮，或者一些小评论来收集这些数据，我甚至在我的产品的一些部分也有这些功能，是的，它确实有用，但它只提供了应用程序中自我识别错误的很小一部分，而且用户对系统有很高的容忍度，所以有时这些错误根本不会被用户升级。他们要么放弃，要么只是通过太多步骤才能达到他们想要的结果。他们会有一个高质量的体验。所以，我认为，承担起这个责任，说你负责查看数据，你可以创建简单的方法来分类它。然后你就有了一个优先列表。现在，如果你的客户愿意更进一步，并对此做些什么，并编写**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的）并修复**提示**（prompts: 给AI模型的指令或问题），那么你的下一步是什么？我们接下来会看到什么例子呢？我想花一分钟谈谈，好吧，这种特定的技术非常强大，但知道它的人并不多。你知道，我最近实际上与OpenAI进行了一次培训，向OpenAI的人展示了这种方法如何适用于**特定领域评估**（domain-specific evals: 针对特定应用场景或行业定制的AI模型评估）。如果你想了解更多，我们请Nurture Boss的创始人Jacob用两分钟的时间讲解了整个过程。你可以在这个页面上找到它。

### 编写有效的评估（Evals）

Hamill: 好的，回到你的问题，现在该怎么做？好的，你已经完成了**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进），并且你已经对这些问题进行了优先级排序，那么现在该怎么做呢？现在你就要开始。

Hamill: 编写**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的）。所以现在你必须决定你想要什么样的评估？有不同类型的评估。有**基于参考的评估**（reference-based evals: 一种评估方法，通过将AI系统的输出与预设的“正确答案”或参考文本进行比较来判断其质量），比如你知道正确答案是什么，也许你可以编写一些代码，你不需要LLM为你做评估，或者如果它本质上更具主观性。

Hamill: 那么，你知道，也许像这个转移交接问题，它本质上更具主观性，那么你就需要一个**LLM判官**（LLM judge: 使用大型语言模型来自动评估另一个AI模型输出质量的方法，通常通过提供评分或二元判断）。所以，你可以开始编写这些评估。我这里有一篇关于评估的博客文章。所以有这张图。老实说，很难把这整个事情都放到一张图里，因为它你知道，它有点非线性。但是你真正想做的是，我们已经讲过了记录**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录），而且有两种不同类型的评估器或评估。有一种是**单元测试**（unit tests: 软件开发中用于测试程序中最小可测试单元的代码），我称之为**基于代码的评估**（code-based evals: 通过编写代码来自动检查AI系统输出是否符合特定规则或条件，通常用于客观、可量化的评估），然后是模型，比如LLM。你知道，基于代码的评估，比如，什么样的事情适合基于代码的评估？比如，如果用户ID出现在响应中，或者类似的情况，你可以在代码中测试它。

Hamill: 对于。

Claire Vo: 我不得不说你在这里救了我的命，因为我一直在想我需要写一个什么样的单元测试，而这正是其中之一，那就是我的**工具调用**（tool calls: AI系统调用外部或内部功能/API以执行特定任务）需要**UU ID**（Universally Unique Identifier: 全局唯一标识符：一种用于在计算系统中唯一标识信息或实体的数字或字符串），而用户绝对不需要。所以，这是一个很好的例子，适用于任何编写大量工具调用的聊天机器人的人。

Hamill: 是的，因为它们可能会意外出现，比如你可能在系统提示中包含了**UID**（User ID: 用户ID），然后它不知不觉地出现在输出中，由于某种原因，你不想那样。好的。你想编写这些测试，无论你编写哪种测试，你都想创建**测试用例**（test cases: 用于验证软件或系统功能是否按预期执行的特定输入、执行条件和预期结果的集合），有时你可以从你的**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）中收集这些测试用例。有时你可能想生成**合成数据**（synthetic data: 通过算法或模拟生成的数据，而非真实世界收集的数据）。

Hamill: 所以，这是一个针对不同房地产经纪人助理“Reachout”的**提示**（prompt: 给AI模型的指令或问题），它面向住宅房地产。这是一个简化版的提示，对吧？房地产经纪人可以给助理的50条不同指令。它可以在他们的**客户关系管理系统**（CRM: Customer Relationship Management system: 用于管理和分析客户互动与数据的软件系统，旨在改善客户服务关系并辅助销售增长）中创建联系人。联系人详细信息可以包括姓名、电话、电子邮件等等。基本上，它可以生成系统的**合成输入**（synthetic inputs: 模拟用户输入的虚构数据），然后你可以从中记录**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）。

Hamill: 我会跳过一些内容，所以我们稍后会回到那个话题。好的，我们已经讨论了记录**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）。你知道，这又是另一个自定义日志标注工具，因为我们确实强调了这一点，即消除所有摩擦非常重要。所以，我不会在这上面停留太久。基本上，你知道，你想做的一件事是，如果你正在使用LLM作为判官或任何其他东西，你想做的是。

Hamill: 当我们讨论LLM作为判官时，通常会跳过的一点是，人们只是直接使用现成的LLM作为判官，他们会编写一个**提示**（prompt: 给AI模型的指令或问题），然后说：“好的，判断它”，然后报告结果。我来转到一个不同的博客文章，它对LLM判官的解释更好，就是这篇。好的，所以LLM作为判官。你经常会在LLM评估领域看到一个像这样的仪表盘：有用性、真实性、简洁性、分数、语气等等。这到底是什么意思？有人知道那是什么意思吗？没有人知道。没有人具体理解。比如，如果有用性分数是4.2分，然后变成4.7分。

Hamill: 你真的知道哪里出了问题，或者哪里发生了变化吗？不知道。所以，关于如何创建**LLM判官**（LLM judge: 使用大型语言模型来自动评估另一个AI模型输出质量的方法，通常通过提供评分或二元判断），有很多指导。对于这个播客来说，要告诉你所有的事情可能太多了。而且这篇博客文章相当长，它详细列举了如何正确地做到这一点。但你需要记住的主要事情是：第一，你需要有**二元输出**（binary outputs: 指评估结果只有两种可能的情况，例如“是/否”、“通过/失败”、“好/坏”），比如对于一个特定问题，它是好还是坏。所以对于Nurture Boss的交接问题，比如，是否有问题？你想要针对特定问题的特定评估器。第二，你需要**标注一些数据**（label some data: 为原始数据添加有意义的标签或分类信息，以便AI模型学习和理解），你已经通过**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进）做到了这一点，并且你想将判官与**人工标注数据**（hand-labeled data: 经过人工审查和标记的数据，通常用作训练或验证AI模型的“黄金标准”）进行比较，这样你就可以信任判官。你最不想做的事情是像这样在仪表盘上扔出一个判官，然后。

Hamill: 人们不知道他们是否可以信任它。作为产品经理，你做的最糟糕的事情是开始向人们展示**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的），然后在某个时候，人们对产品的感觉或他们的产品体验与评估不符。他们会说：“嘿，它坏了，但评估显示它很好。”那就是人们对你失去信任的时刻，然后你将很难重新获得这种信任。所以，确保你可以信任这些自动化LLM评估的方法是。

Hamill: 你知道，衡量与这些**人工标注**（hand labels: 指由人类专家对数据进行分类、标记或评级的过程）的一致性。

Claire Vo: 是的。

Claire Vo: 所以我从你那里听到的关于**LLM判官**（LLM judge: 使用大型语言模型来自动评估另一个AI模型输出质量的方法，通常通过提供评分或二元判断）的观点是，这些带有任意评分的通用类别是无用的，并且往往会适得其反。你希望为特定任务编写具体的**二元结果评估**（binary outcome evals: 指评估结果只有两种可能的情况，例如“是/否”、“通过/失败”、“好/坏”）。所以你想要一系列评估，比如“这个是否正确安排了？”“是”或“否”。所以你正在列出LLM作为判官正在评估的评估列表，这些评估会给你一个通过/失败或是/否、真/假、二元结果。非常简单。然后你正在做额外的工作，通过实际查看结果并说：“我真的同意这个LLM判官对这个输出质量的评估吗？”来验证评估是否有效。这些步骤加在一起将给你一个更全面的视角，了解你的产品表现如何。然后，第二层人工评估将给你更多的信心，要么你的LLM判官是好的，并且正在正确评估你的输出，要么你实际上需要调整判官本身以获得更高质量的评估。这也是你总结的吗？

Hamill: 是的。最重要的是，如果你不这样做，就很难编写任何LLM判官的**提示**（prompt: 给AI模型的指令或问题），因为研究表明，我正在教授的课程的共同讲师有一些研究，有一篇论文叫做“谁验证了验证者”，研究表明，人们在编写规范或要求方面真的很糟糕，直到他们需要对LLM正在做的事情做出反应，以澄清并帮助他们将他们想要的东西**外化**（externalize: 将内在的想法、感受或需求表达出来或转化为外部形式）。只有通过这个过程，通过编写详细的笔记和批评，你才能开始完善LLM判官。

### 优化系统指令与提示工程

Claire Vo: 太棒了。所以我们已经涵盖了**追踪链**（traces: 在AI系统中，指从用户输入到系统输出过程中，所有内部事件、工具调用、信息检索等步骤的记录）和**错误标注**（errors annotation: 对AI系统产生的错误进行识别和标记的过程）。你已经知道如何构建**自动化单元测试**（automated unit tests: 自动执行的最小化代码测试，用于验证特定功能是否按预期工作）。当然，你也在手动查看它。你正在以正确的方式使用LLM判官。现在告诉我，我已经识别了所有这些问题。我有了这些提供数据的评估。我如何编写一个好的**提示**（prompt: 给AI模型的指令或问题）？有没有什么技巧或者我该怎么做？你是否发现，在改进系统指令、改进工具的下一步中，你必须去解决这些问题，有哪些是有效的？

Hamill: 是的。所以，当你遇到你所发现的错误时，你知道，你将使用这些**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的），并将其大规模部署。好吧，你并没有查看所有数据，你正在查看一个数据样本。

Hamill: 你将根据**标注数据**（label data: 经过人工审查和标记的数据，通常用作训练或验证AI模型的“黄金标准”）样本来评估你的LLM判官，并将其大规模部署，然后你将查看哪里存在错误。

Hamill: 而且它非常，你知道，你需要根据你发现的错误来判断如何改进你的系统。它是一个**检索问题**（retrieval problem: 在AI系统中，指从知识库或数据库中获取相关信息以辅助生成响应时出现的问题）吗？它是一个**提示问题**（prompting issue: 指AI模型由于提示语设计不当而未能生成所需输出的问题）吗？你是否应该在提示中放入更多示例？你知道，我敢说，这里并没有**万能药**（silver bullet: 指一种能解决所有问题的简单而有效的解决方案）。你知道，**检索**（retrieval: 在AI系统中，指从知识库或数据库中获取相关信息以辅助生成响应的过程，常用于检索增强生成（RAG）系统）有其自身的复杂性。它往往是许多AI产品的**阿喀琉斯之踵**（Achilles heel: 指一个系统或计划中最脆弱、最容易失败的部分）。

Hamill: 你知道，事情往往会出错。但有时，是的，就像尤其在开始阶段，你会发现很多**低垂的果实**（low-hanging fruits: 指那些容易实现且能带来显著效益的改进点）。比如，在Nurture Boss中，**系统提示**（system prompt: 预设给AI模型的一系列指令或角色定义，用于指导其行为和生成内容）中没有包含今天的日期。

Hamill: 所以当有人说：“嘿，你能安排明天的日程吗？”AI完全不知道明天是什么意思，但它没有告诉用户，对吧？我们只是猜测。所以，你知道，那是非常明显的。所以会有一些你可以修复的明显问题，然后有一些不太明显的问题你可以修复。你可以尝试**提示工程**（prompt engineering: 设计和优化输入给大型语言模型（LLM）的提示语（prompt），以使其生成更准确、相关或所需输出的过程）。所以有一个范围，从**提示工程**（prompt engineering: 设计和优化输入给大型语言模型（LLM）的提示语（prompt），以使其生成更准确、相关或所需输出的过程）一直到**微调**（fine-tuning: 在预训练模型的基础上，使用特定任务的数据集进一步训练模型，以提高其在该任务上的性能）。

Hamill: 大多数人不应该进行**微调**（fine-tuning: 在预训练模型的基础上，使用特定任务的数据集进一步训练模型，以提高其在该任务上的性能）。我要说的是，如果你做了所有这些**评估**（evals: 对AI模型或系统性能进行衡量和判断的过程，可以是自动化的，也可以是人工的）工作，那么微调基本上是免费的，因为你已经搭建好了所有这些基础设施来做这些测量，并**整理**（curate: 精心选择、组织和呈现信息或数据）数据，比如那些高质量的**高信号数据**（high signal data: 包含丰富有用信息且噪声较少的数据），这些数据很难获取，而且那些困难的数据，那些你的AI没有做对的困难示例，正是你想要用来微调的东西。那是对微调非常有价值的东西。

Hamill: 而且，是的，**微调**（fine-tuning: 在预训练模型的基础上，使用特定任务的数据集进一步训练模型，以提高其在该任务上的性能）并不难。在Reach案例中，我们不得不进行微调才能达到额外的效果。但在大多数情况下，都是**提示工程**（prompt engineering: 设计和优化输入给大型语言模型（LLM）的提示语（prompt），以使其生成更准确、相关或所需输出的过程）。并没有什么神奇的提示工程技巧。我真的会说，有很多实验。

Hamill: 你应该参与其中。嗯，我发现作为一名具有软件工程背景的AI构建者，最有趣的事情之一是，现在我的系统指令和提示语在自然语言层面上也存在**bug**（缺陷/错误）。我最近在ChatGPT上遇到了这样的经历，我们当时在**工具调用**（tool calling: AI系统调用外部或内部功能/API以执行特定任务）方面遇到了很大的困难。无论用户说什么，我们的一个工具都会间歇性地不被调用。这真的很难确定，而且我们有一个庞大的**系统提示**（system prompt: 预设给AI模型的一系列指令或角色定义，用于指导其行为和生成内容）。我检查了一下，发现提示语中有两个词是错误的。它们是关于UU ID的，但却是错误的。我一删除那两个词，那些词只是被人输入并推送到仓库中，等等，我们的工具调用质量就立刻飙升了。所以，我不得不说，作为产品人员，作为工程师，我们必须开始思考我们产品的整个**表面积**（surface area: 指一个系统或产品与外部世界互动的所有方式和接口，在这里指AI系统需要考虑和处理的各种输入和输出情况）。它不仅仅是代理或聊天机器人本身的构建。它确实深入到进出你系统的单词。这是一个复杂的调试和跟踪的表面区域，因为它是非结构化的，但根据我的经验，它的影响非常大。

### 评估智能体系统与产品发现

Hamill: 是的，当然。你知道，当谈到**工具调用**（tool calls: AI系统调用外部或内部功能/API以执行特定任务）时。实际上，我来给你展示一个经常出现的问题：人们想知道如何评估**智能体**（agents: 具有自主决策、规划和执行能力，能够与环境互动并完成复杂任务的AI系统），因为，你知道，有那么多不同的。

Hamill: **交接**（handoffs: 指在AI系统中，任务或信息从一个模块、工具或人类代理传递到另一个的过程），你如何在现实生活中做到这一点？我来看看我是否可以分享。好的，我正在分享我们给学生上课用的书。但让我看看目录。所以有所有这些不同的领域。我们会大致浏览一下关于智能体的部分。

Hamill: 所以，有你可以用于所有事情的分析工具。你知道，对于**智能体**（agents: 具有自主决策、规划和执行能力，能够与环境互动并完成复杂任务的AI系统），你可以构建这些**转移矩阵**（transition matrices: 一种数学工具，用于表示系统从一个状态转移到另一个状态的概率，在这里指AI智能体在不同步骤或工具之间交接的流程图）。

Hamill: 从一个步骤到另一个步骤，错误位于哪里？比如在哪个智能体交接点，或者哪个步骤正在交接给哪个其他步骤。所以，在这种情况下，我们有这个“生成SQL到执行SQL”的过程，很多错误都发生在这里，然后你就可以缩小范围。所以，当你深入到评估这个主题时，有很多分析工具你可以用来处理问题。

Claire Vo: 这非常有趣，作为产品经理，你可以通过**AI辅助笔记本**（AI-assisted notebooks: 结合了AI能力（如代码补全、错误检测、数据洞察）的交互式编程环境）走得很远。

Claire Vo: 是的。从产品经理的角度来看，我想说的是，这确实是从错误和评估的角度来阐述的，但即使是针对**智能体系统**（agentic systems: 具有自主决策、规划和执行能力，能够与环境互动并完成复杂任务的AI系统）的分析，弄清楚你的用户试图做什么。我以前没有想过这种实际绘制不同对话到工具或工具到工具交接的想法。即使所有这些都有效，产品经理能够从工具到工具交接的角度查看其智能体行为的数据，并真正识别用户试图从系统中获取价值的地方，也可以做一些事情，比如推动**路线图**（roadmap: 指产品或项目未来发展计划的视觉化呈现，包括目标、里程碑和时间表）的想法，对吧？如果你看到，好吧，人们只是在编写SQL，执行SQL，那么我们需要深入研究围绕这些，我们还可以为用户构建哪些有趣的东西。所以我喜欢它从错误的角度来看，我也喜欢它从产品发现的角度来看。

Hamill: 是的，当然。那非常正确。嗯，是的，我喜欢那个视角。

### 务实的AI产品改进方法

Claire Vo: 好的，你已经向我们展示了。我喜欢的另一点是你向我们展示了，除了亲自动手，别无他法。人们想要这些技巧。他们想要一些**窍门**（hack: 指一种巧妙但不一定常规的解决方案或方法）。他们想要一些**现成的解决方案**（off-the-shelf solution: 指可以直接购买和使用的标准化产品或服务，无需定制）。而你却说，老实说，看看数据。如果需要，自己构建一个解决方案。自己验证它。做这些辛苦的工作。如果你做了这些辛苦的工作，你就能在产品质量和体验上实现飞跃。但现在，你只是需要查看数据，然后做出一些决定，让事情变得更好。所以，我认为这对于帮助像我这样正在构建AI产品的人提高产品质量非常有启发性。

### Hamill的AI工具栈与工作流

Claire Vo: 让我们花几分钟时间讨论一个完全不同的话题，那就是你正在经营这个企业。你正在开设课程。你显然是AI领域的专家。你日常工作或至少是商业生活中使用的工具栈中有哪些工具？

Hamill: 是的。我做了很多写作工作，也做了很多与客户的沟通，而且，你知道，我也想减少自己的**繁重工作**（toil: 指重复性、可自动化且没有内在价值的工作）。所以，我再分享一下我的屏幕。

Claire Vo: 是的。

Hamill: 展示**Claude项目**（Claude project: 指在Anthropic的Claude AI平台上创建和管理的工作空间，用于特定任务或客户项目）可能最容易。我有所有这些Claude项目。

Hamill: 所以，好的，我有一个用于文案写作的，我有一个法律助理，我还有咨询提案。咨询提案非常有趣。所以它基本上是咨询提案的一个例子。它，你知道，我，这有点好笑。我有一个技能水平：合伙人、志愿者、专家级生成式AI等等。你知道，我给它一些关于其他提案的指令。你知道，我有一个这样的提示，无论是什么，直奔主题，用短句子写作，等等。基本上，我有很多例子，基本上，每当我与想要提案的客户进行**初步沟通**（intake call: 与潜在客户进行的首次电话或会议，旨在了解其需求并评估合作可能性）时，我都会把**逐字稿**（transcript: 音频或视频内容的文字记录）给它，然后它就完成了。它基本上已经准备好了。我只需花大约一分钟来编辑它，然后就可以使用了。所以这就是提案，你知道。我有一个用于课程的，它包含了很多关于我课程的背景信息，比如整本书。我有一个非常广泛的已发布的**常见问题解答**（FAQ: Frequently Asked Questions）。

Hamill: 还有所有的**逐字稿**（transcripts: 音频或视频内容的文字记录）、所有的**Discord**（Discord: 一个为社群设计的即时通讯和语音聊天平台）消息、**办公时间**（office hours: 指教授或导师在特定时间段内与学生一对一交流、答疑解惑的时间），你知道，我的提示语是：“嘿，你的工作是帮助课程讲师创建独立的、有趣的常见问题解答。”这是我到处都有的写作提示。

Hamill: 不要添加单词。

Hamill: 不要重复你自己。直奔主题。

Claire Vo: 是的。是的。是的。这非常，你必须非常，你知道，嗯，所以，好的，就像。是的，就是这里的东西。你知道，所以有一个用于课程的。嗯，你知道，有一个帮助我创建这些叫做“闪电课程”的东西，它基本上就像这个**潜在客户磁铁**（lead magnet: 营销中用于吸引潜在客户并获取其联系方式的免费有价值内容或服务）。

Hamill: 所以有各种各样的东西。

Claire Vo: 我看到你和我共享了一个**总法律顾问**（general counsel: 公司内部的首席律师或法律顾问）在这里。

Hamill: 哦，好的。

Claire Vo: 用**Claude AI**（Claude AI: 指Anthropic公司开发的一系列大型语言模型）？

Hamill: 哦，是的，没错，就是那个。嗯，所以有那个，我也有我自己的软件。是的。嗯，所以我有，我看看我能不能找到它。

Hamill: 我的意思是，我并不是真的在宣传它，但我有一个YouTube章节创建工具，然后我基本上有一个东西，可以从YouTube视频中创建博客文章。所以，我来给你展示一个例子。所以，这个，我基本上所做的是，我拿一个YouTube视频。

Hamill: 它就变成了一个带注释的演示文稿。所以你不必看视频。

Claire Vo: 是的。

Hamill: 你可以直接，尤其是如果视频有幻灯片，它会截取所有幻灯片，然后在每张幻灯片下有一个总结，说明说了什么。所以你可以在，你知道，五分钟内看完一个一小时的演示文稿。嗯，这非常好，因为，你知道，我教了很多课，我有很多内容，所以我分发笔记，所有这些。所以，很多教育性的东西都是我工作流程的一部分。嗯，这个使用了**Gemini**（Gemini: 谷歌开发的一系列多模态大型语言模型）。它基本上所做的是，它提取**逐字稿**（transcript: 音频或视频内容的文字记录），提取视频，我可以一次性放入幻灯片，有很多例子，我把它给它，然后它就生成了这个。

Claire Vo: 是的，我最近在几个播客中都听说了，人们真的喜欢**Gemini**（Gemini: 谷歌开发的一系列多模态大型语言模型）用于视频信息。**摄取**（Ingest: 指将数据从源系统导入到目标系统或应用程序的过程）似乎是粉丝最喜欢的功能，用于将YouTube视频或其他视频内容转换为文本或其他可以从中提取的应用程序。所以，如果你想这样做，可以尝试**Gemini模型**（Gemini models: 谷歌开发的一系列多模态大型语言模型）。

Hamill: 是的，它绝对是辉煌的。太棒了。

### GitHub仓库作为“第二大脑”

Claire Vo: 酷。好的，所以你的业务的每个小部分都有**Claude项目**（Claude project: 指在Anthropic的Claude AI平台上创建和管理的工作空间，用于特定任务或客户项目）。我喜欢**提案工作流**（proposal workflow: 指从客户需求收集到最终提案提交的整个过程，包括起草、审查和批准等步骤）。对于我们这些从事**企业销售**（enterprise sales: 指向大型企业客户销售产品或服务的销售模式）的人来说，这可能很有用。我正要开始为所有《How I AI》播客写博客文章。所以也许我会下载你的仓库，试用一下。然后你正在使用**Gemini模型**（Gemini models: 谷歌开发的一系列多模态大型语言模型）来提取内容并将其作为模板共享。然后你有，哦，看看这些提示。有一个带有提示的GitHub仓库。

Hamill: 是的。所以我有带有提示的GitHub。这个是私有的，但只是为了给你一个概念上的想法，它基本上是一个包含所有东西的**单体仓库**（monorepo: 一种软件开发策略，将多个项目或模块的代码存储在同一个版本控制仓库中）。这样做的原因是，我喜欢拥有Claude代码、OpenHands，随便你叫什么。基本上，我之所以这么说，是因为所有这些东西都是相互关联的，对吧？就像很多这些项目。所以，你知道，这是我的博客在这里。例如，这是我的博客。这是我刚才给你看的YouTube的东西。这个Hamill项目。这是另一个获取Discord消息的东西。这是关于文案写作提案，等等。我只是把AI指向这个仓库，你知道，这里有一些**Claude规则**（Claude rules: 指在Anthropic的Claude AI平台上设置的、用于指导AI行为和输出的特定指令或配置），它会说：“好的，这个仓库是关于什么的？你可以在哪里找到东西？比如，你知道，如果你需要写作，你应该看这里”，等等。

Claire Vo: 我的朋友，你在这里**藏着大秘密**（buried the lead: 指在文章或对话中没有把最重要的信息放在开头，而是放在了后面），因为我们本可以专门用一整集来讨论这个仓库。这让我想起了，你知道，五年前曾有一个关于笔记、**第二大脑**（second brain: 指一种个人知识管理系统，旨在收集、组织和连接个人信息，以便长期存储和检索），你把所有信息放在哪里才能永远访问它？我看到这个，我的小工程师大脑就想，显然它应该放在一个仓库里，它应该是一个数据源、笔记、文章、我写过的东西、我喜欢的东西以及提示和工具的组合，以便真正用它做点什么。所以你给了我一个个人项目，我将在接下来的几天里去完成，因为我认为这就是我作为一个与Cursor或Claude Code作为一切的**副驾驶**（co-pilots: 指协助人类完成任务的AI工具或系统）一起生活的人，我希望如何组织我的数据和提示，以便能够用它做点什么。

Hamill: 是的。我不想被锁定，对吧？被任何一个提供商锁定。所以这就是我这样做的方式。

Hamill: 本质上。

Claire Vo: 太棒了。好吧。我们可能得请你回来详细讲解这个东西。这太棒了。嗯，我有两个**闪电式问答**（lightning round questions: 指快速回答的一系列问题），然后我就让你离开这里。我知道你是个忙碌的人。我的第一个问题是，你知道，你给我们展示的很多东西都需要一个人，一个人用他们的肉眼去阅读东西，并进行评估。我很想知道，你认为这是谁的职责？这是产品经理的职责吗？是工程师的职责吗？是**领域专家**（subject matter expert: 对特定领域拥有深入知识和经验的人）的职责吗？谁来做这个？我认为领域专家非常核心。很多时候，产品经理在很多组织中就是某个主题的领域专家，他们是每个人都指望的那个人，负责判断“嘿，用户应该发生什么？”所以我会说，很多时候，这确实是产品经理的职责，他们应该做那个**标注**（annotation: 对数据进行标记或添加元数据的行为）。

### 谁来负责AI产品的评估与质量？

Hamill: 现在当涉及到分析时，这真的很有趣。如果产品经理能做到这一点会很好。

Hamill: 你能做的越多越好，就像你了解的SQL和那些东西一样。

Hamill: 在某个时候，当它变得高级时，你可能确实需要一个**数据科学家**（data scientist: 运用统计学、计算机科学和领域知识从数据中提取洞察和知识的专业人员）。但是，你知道，你学得越多越好，反之亦然，数据科学家学得越多产品技能，你知道，就会越好。很难预测。

Hamill: 你知道，总是有这种张力或者这种，好吧，我们能否合并角色？我们能否合并产品角色和这种数据科学家类型的AI角色？我不确定。嗯，还有待观察，我认为不会。嗯，实际上有很多**表面积**（surface area: 指一个系统或产品与外部世界互动的所有方式和接口，在这里指AI系统需要考虑和处理的各种输入和输出情况）。比如有**AI工程师**（AI engineer: 专注于设计、开发、部署和维护AI系统和应用的技术人员），有**AI产品经理**（AI product manager: 负责AI产品从概念到发布的整个生命周期，结合产品管理和AI专业知识），而且还有这个**数据科学家**（data scientist: 运用统计学、计算机科学和领域知识从数据中提取洞察和知识的专业人员）方面，所以这三个角色仍然在处理这个问题。嗯，而且它们都有很大的**表面积**（surface area: 指一个系统或产品与外部世界互动的所有方式和接口，在这里指AI系统需要考虑和处理的各种输入和输出情况），尤其是在你扩展规模时。

Claire Vo: 我想指出的另一件事，或者我的希望是，除了技术构建团队之外，他们在我看来是**领域专家**（subject matter experts: 对特定领域拥有深入知识和经验的人）的**代理**（proxies: 指代表或替代另一个实体行事的个体或系统）。所以，很多时候，产品经理是租赁代理的代理，在这个例子中。他们了解那个用户，他们了解什么是高质量。但是，你知道，我真的很想看到那些从事运营或更职能性角色的人进来，并真正为产品的质量做出贡献，因为他们知道什么能带来好的用户体验。他们知道什么能带来好的租赁代理。他们知道他们应该如何说话以及他们应该做什么。我认为对于人们来说，这是一个机会，可以投入进来，以一种在整个公司范围内扩展的方式发挥他们的专业知识。嗯，如果你愿意并且勇敢地去做，我认为产品团队会欢迎非技术同事参与到这个过程中，以增加更多的用户**同理心**（empathy: 理解和分享他人感受的能力）和**领域专业知识**（subject matter expertise: 对特定领域拥有深入知识和经验）。

Hamill: 是的，当然。是的，你越能将产品意义上实际所需的**品味**（taste: 在产品或设计领域，指对美学、用户体验和质量的判断力或偏好）带入这个过程，就越能，是的，因为那本质上就是你正在做**标注**（annotating: 对数据进行标记或添加元数据的行为）时所做的事情。

Claire Vo: 是的。

Hamill: 进行**错误分析**（error analysis: 一种系统性方法，通过检查AI系统的失败案例来识别和分类错误模式，从而指导改进），而错误分析是所有一切的基础。

Claire Vo: 是的。好的。然后我的最后一个问题，我问每个人。我知道你非常有条理，你会告诉我你会看数据，然后弄清楚该说什么，但你必须承认，有时AI非常令人沮丧，它不会做你想要它做的事情。你有什么**秘密武器**（back pocket: 形容随时可用、预先准备好的）的**提示技巧**（prompting techniques: 设计和优化输入给大型语言模型（LLM）的提示语（prompt），以使其生成更准确、相关或所需输出的过程）吗？你会大喊大叫吗？你会全大写吗？你的策略是什么？

### 应对AI写作的挑战：分步编辑与迭代

Hamill: AI最让我沮丧的是写作。

Claire Vo: 嗯哼。

Hamill: 因为写作，我不想让它听起来像AI写的。

Claire Vo: 是的。而且很难，你知道，在某些情况下，你最不想让你的写作听起来像AI。并不是说AI是错误的，只是，是的，你想确保你的**风格**（flavor: 指独特的风格、特点或个性）能够体现出来。所以，嗯，所以有一件事，有一件事是。

Hamill: 我给你看了一点我的写作**提示**（prompt: 给AI模型的指令或问题）。我也可以单独分享给你。

Hamill: 那就是提供大量的例子，但也要**一步一步来**（take it step by step: 逐步进行，不急于求成）。所以对于写作，我所做的是让它先写一个**大纲**（outline: 文本或演讲的结构化概要），然后让它写第一或第二部分，然后非常仔细地编辑。现在有一个技巧是使用像**AI Studio**（AI Studio: 指提供AI模型开发、训练和部署功能的集成开发环境或平台）这样的工具，它允许你编辑LLM给你的输出。这非常重要，因为这样做最终会为LLM创建**内联示例**（in-line examples: 在文本或代码中直接提供的示例，通常用于即时说明或演示）。

Claire Vo: 是的。**内联**（In line: 指在同一行或紧接着出现，不另起一行）。是的。

Hamill: 是的。所以，嗯，是的，你想要编辑输出，而且，你知道，是的，像笔记本或AI Studio这样的东西，没有太多能让你编辑输出的工具。

Hamill: 但是一旦你这样做了，一旦你做了那些辛苦的工作，比如那些例子，尤其是你现在正在尝试写的东西。

Hamill: 那么它就开始运行得非常好了。

Claire Vo: 是的，这是我构建到我的AI产品中最重要的东西之一，就是每个生成的资产都有一个实时编辑器供用户更新，然后这些更新会反馈到模型中，因为我只是觉得，如果你的产品的核心价值主张是写作（我的产品就是），那么它是我见过AI最难应对的**风格挑战**（stylistic challenges: 写作或艺术创作中与表达方式、语气、修辞等相关的困难）。它听起来都像**敷衍了事**（slop: 形容质量低劣、粗制滥造）。我能一眼就认出AI的写作。所以，是的，我发现这种**增量优化**（incremental optimization: 逐步改进和完善的过程）——先大纲，然后草稿，然后编辑，然后精炼的过程需要一些时间。嗯，体验中存在一些**延迟**（latency: 指系统响应用户请求所需的时间），但最终会带来更高的质量。然后就像把它当作草稿，编辑它，让系统猜测，让系统变得更好。所以这是一个非常非常棒的反馈。

Claire Vo: 这是给**Chat PRD**（Chat PRD: 可能指一个基于聊天的产品需求文档工具或AI产品）的吗？

Claire Vo: 这是给Chat PRD的。是的。

Hamill: 是的。

Claire Vo: 非常酷。

Claire Vo: 是的，你知道，我对写作也有很高的标准。所以这对我来说很重要。嗯，这太棒了。我们可以在哪里找到你，我们如何提供帮助？

Hamill: 是的，haml.dev是我的网站。你也可以在Twitter上找到我Hamill Hussein，是的，我正在Maven上教一门关于**评估主题**（eval subjects: 指AI模型评估中涉及的具体内容、指标或方面）的课程，非常深入。

Hamill: 嗯，但是的，你可以在那里找到我。

Claire Vo: 太棒了。是的，对于我们的听众来说，如果你不知道，Lenny's list在Maven上，包括一个How I AI专区，我想里面有你的课程。所以，你可以在那里查看。非常感谢你的时间。这非常有教育意义，非常实用。我将立即采纳这些建议，去改进我自己的产品。祝你有个美好的一天。

Hamill: 是的，谢谢你的邀请。

Claire Vo: 非常感谢观看。如果你喜欢这个节目，请在YouTube上点赞并订阅，或者更好的是，留下你的评论。你也可以在Apple Podcasts、Spotify或你喜欢的播客应用程序上找到这个播客。请考虑给我们评分和评论，这将帮助其他人找到这个节目。你可以在howiipod.com查看我们所有的剧集并了解更多关于节目的信息。

Claire Vo: 下次见。