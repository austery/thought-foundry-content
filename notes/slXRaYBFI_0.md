---
area: tech-insights
category: technology
companies_orgs:
- Google
- OpenAI
- DeepMind
- Nvidia
- Microsoft
- Anthropic
- Meta
- Apple
- 华为
- Polymarket
- Windsurf
date: '2025-11-20'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《The New York Times》
people:
- Demis Hassabis
- Sam Altman
- Satya Nadella
- Sundar Pichai
- Greg Brockman
- Jose
- 巴菲特
products_models:
- Gemini
- GPT-5
- GPT-4
- AlphaGo
- AlphaFold
- Codex
- Sora
- NotebookLM
- DeepSeek R
- Cloud 4
- GLM
- MiniMax
- Kimi
- Cursor
- Devlin
- GPT OSS
- Mac OS
- Windows 98
- Chrome
- VS Code
- CUDA
project:
- ai-impact-analysis
- us-analysis
series: ''
source: https://www.youtube.com/watch?v=slXRaYBFI_0
speaker: 人民公園說AI
status: evergreen
summary: 本次讨论深入分析了Google Gemini 3的发布及其对AI领域的影响。与OpenAI的GPT-5相比，Gemini 3被认为是实现了GPT-5的理想状态，尤其在底层架构、TPU应用、多模态训练及“DeepThink”模式上展现出显著优势。文章探讨了Google在基础模型上的坚定投入、组织整合能力（如DeepMind和Windsurf的融合），以及其ToB战略的清晰性。同时，也对比了Google与OpenAI在产品化和市场策略上的差异，并强调了Demis
  Hassabis作为Google AI掌门人的关键作用，展望了“一次性软件”的未来潜力。
tags:
- ai-competition
- development
- future
- google-ai-strategy
- llm
- model
- organizational
title: Gemini 3：Google如何跑出GPT-5的理想状态，及其对AI格局的影响
---

### Gemini 3：跑出GPT-5的理想状态

**老兄:** Gemini这一次给人的感觉是从容不迫、游刃有余，仿佛将大家对GPT-5的理想状态都实现了，明显比它更好。Google吸纳了Windsurf最核心的员工，带着他们的**Know-How**（专有技术: 实践知识和技能），用着Google的**TPU**（Tensor Processing Unit: 谷歌为机器学习工作负载设计的专用集成电路），吹着Google的空调，将这些Know-How融入到产品中，然后发布出来，这简直是活久见。

**小苏:** 我觉得这几乎就是原班人马，可能就差代码直接拷贝了。

**老兄:** 我的惊艳点在于，同样是半年时间，OpenAI更多地将手伸向了产品端，它手握很多好牌，但并未快速打出。而Google是所有做AI大模型的公司中，真正愿意将能力开放给用户的那一家。我预祝Google好人一生平安。以前是我们吹捧Gemini，现在是人民群众都在吹捧Gemini了。这次的Gemini 3，让我想起闲哥之前的一个比喻，就像段誉的六脉神剑，以前是控制不好内力，指哪不打哪，但这一次，六脉神剑已经收放自如了。相对来说，我觉得整个内力，包括模型和产品，应该是相对比较成熟的一次发布。

### Gemini 3的架构重构与能力融合

**老兄:** 我一开始就想问，据说Gemini 3是一次彻底的重构，对吗？

**小苏:** 号称是这样，但其实“彻底的重构”有点误读。更合适的说法是，它将Gemini 1和Gemini 2进行了融合。Gemini 1专注于长上下文窗口，例如支持100万个**Token**（词元: 文本或代码的基本处理单元）。而Gemini 2则侧重于**Tool**（工具: 指模型能够调用的外部功能或API）的使用能力和多模态功能。这两个版本最初是基于两条不同的地基构建的，而Gemini 3则是将这两条地基融合到一起，并融入到训练中。这确实是一个非常大的构建，一个独立的构建，但称之为“彻底重构”可能不严谨。因为从技术上讲，彻底重构意味着完全放弃前两代，重新开始。而Gemini 3是在现有基础上进行融合和创新。

**老兄:** 也就是说，之前的长上下文、多模态仍然是最基础的，而Tool和**Agent**（代理: 在人工智能领域，指能够自主感知环境、进行决策并执行行动的智能实体）的使用能力，在2.5 Pro版本时就已经有所体现，并且获得了用户的好评。

**小苏:** 是的，2.5版本已经融合了之前的功能，并对Agent和多模态的融合做了铺垫。现在Gemini 3是从底层重新融合这两样东西，并重新训练。这个训练肯定是重新进行的，而不是简单的微调。

### 推理时扩展与稀疏混合专家架构

**老兄:** 很多人会拿Gemini 3来比较，说它长成了GPT-5应该有的样子。但GPT-5更像是GPT-4的一个微调版本。从诚意上讲，大家肯定觉得Google更有诚意，Gemini 3与2.5相比，是一个比较大的蜕变，至少底层架构进行了一些重组，并使用了更多的合成数据，以及多模态数据进行训练。

**小苏:** 是的，从它的模型卡片就能看得很清楚，它并没有外挂**OCR**（Optical Character Recognition: 光学字符识别，将图像中的文本转换为可编辑文本的技术）或语音读取等功能，而是完全原生的多模态内容进行训练的。

**老兄:** 我看它这次有一些创新，特别是在推理时的**Scale**（规模扩展: 指系统在处理更多任务、数据或用户时保持性能的能力）方面。它现在不叫Flash或Pro，而是“DeepThink”模式。这块是不是有一个比较大的创新？

**小苏:** 是的，这里可以对照GPT来看。GPT以前的Scale方式是所谓的“预训练扩展”，通过模式匹配来寻找。而Gemini 3的“推理时扩展”则会进行搜索和自我验证（Search and Verification）。这其实是DeepMind的一套做法，现在在大模型端实现了。以前DeepMind的研究（Deep Research）就是搜索和验证一体的，但那时主要由多个Agent完成。现在大模型本身就能承担更多，分工更加顺畅。理论上，Agent要做的事情会减少，或者成功率会更高，因为大模型已经预先处理了一些工作，避开了一些坑。

**老兄:** 所以，像**稀疏混合型专家MoE架构**（Mixture of Experts Architecture: 一种神经网络架构，通过组合多个“专家”网络来处理不同任务）这样的架构，他们也做了更多优化，使其在推理Scale的拓展状态下，效率更高，成本更低。

### 用户体验与市场策略差异

**老兄:** 我们昨天没有第一时间录节目，给了我24小时体验时间，但我个人感受是，它没有2.5 Pro那么惊艳。你们两位感觉如何？有没有特别深度的体会，3.0到底强在哪？我个人感觉它继承了之前的优良传统，能处理更复杂的问题。但这种推理型的专家模式或DeepThink模式，需要合适的场景去测试。我看到很多都是刷榜，国内外都在提它的分数、榜单排名，说它夺回了AI王座，超越了GPT和OpenAI。但作为普通AI用户，它到底强在哪？这24小时内，我看到很多报告都在引用同样的案例，如UI、写作、推理等，甚至提到了小苏说的重构。但我个人感觉，它真的没有惊艳到我，这是我的第一直观感受。小苏和老徐，有没有什么东西特别惊艳到你们，让你们觉得3.0是不可或缺的，2.5 Pro完全无法企及？甚至Banana（一个AI产品）都给过我这种感受，IO大会上提到的很多产品场景也给我这种感觉，但这次3.0出来后，我期待的惊喜没有出现，这让我有点困惑。

**小苏:** 24小时的体验，可能大家惊艳的都是官方引导的方向，很多前端案例非常酷炫，比如模拟Windows 98或Mac OS操作系统，或是一些可以操控电扇的演示。很多博主放出的案例也很帅，但实际上很多人发现，这些还是用很多已有元素组合的，并非模型一次性就能做成那样，也不是提示词有什么不一样。也就是说，实际使用中，惊艳的部分比例不会那么大，普通人可能只有5%到10%能感受到。模型真正厉害的部分，大部分人第一时间并不能感受到。

**老兄:** 我觉得这是一个比较彻底的问题。但从我的角度，我的惊艳点在于，同样是半年时间，OpenAI在做什么，Google和Gemini在做什么。把这半年他们做的事情列出来，你就会发现Google已经是业内良心了。六个月前是2.5 Pro，一次很大的跃升；六个月后，半年就发布了Gemini 3.0，基本上是一个重构的大版本。而OpenAI从GPT-4到GPT-5，更像是一个增量更新或原有模型的微调。从架构上看，刚才小苏讲的DeepThink，而OpenAI推出的是模型路由，说白了就是把用户当“傻X”，根据情况给你用贵一点的或降级。再看具体的变现动作，Google一直坚持全家桶加云服务。OpenAI则做了很多，融资、浏览器、短视频、设计、电商支付等什么都搞。所以你会发现，这两家公司在模型上的诚意，Google还是比较有业内良心的。坦白说，Google内部应该也比较“卷”，就像闲哥说的“大象他妈的会跳舞”。

**老徐:** 是的，2.5 Pro的时候，我真的感觉到“哇，大象要表演一段舞蹈，而且是飘逸的，真厉害！”

**老兄:** 感觉它身体更轻盈了，脚步更美妙了，也就这样而已。

### TPU与英伟达：竞争与协同

**老兄:** 反倒有两件其他事情让我印象深刻。一个是它提到了**TPU**，说这次的训练和之前的能力都是100%基于自己的TPU来完成的。这件事出来后，Google股价马上就上涨了，盘中一度涨到接近7%，收盘也涨了3%。这说明市场对它的信心增强了很多，不光是对模型能力的肯定，肯定也有TPU的因素存在。紧接着，英伟达发布了第三季度财报，这份财报万众瞩目。现在美股，包括全球很多股市都跟美股联动，所有东西都万丈高楼平地起，最底下只有一块英伟达的小小芯片撑着，这块芯片倒了，上面市值要倒一大半。但你看这两件事：Google不再完全依赖英伟达的**GPU**（Graphics Processing Unit: 图形处理器，一种专门在个人电脑、工作站、游戏机和一些移动设备上图像渲染的微处理器），它自己有TPU了；同时英伟达财报出来后股价也在上涨。你们二位觉得，这两者在长中期是竞争关系，还是互相抬轿子，能彼此促进？

**小苏:** 从技术上来讲，肯定还是互相抬轿子。因为TPU从Google内部人员的分享来看，很早，可能2016年左右就开始用于机器学习训练了。到后来有大模型时，他们又针对大模型做了改变，现在TPU已经迭代到好几代了，专门为大模型服务。但他们仍然大量使用GPU。为什么？因为他们卖云服务，有很多场景需要用。不光卖云，从正常使用上来讲，开发环境和生产环境都需要大量资源。开发环境有时用得更暴力，很多情况下还是要用英伟达的GPU。而在准备正式环境和正式环境上跑训练和推理时，他们会更多地用TPU。至少在训练环节，从Gemini 2开始就已经是100%使用TPU了。但在正式环境之前的一些环节，他们还是会用GPU。再加上云端会有混合情况，所以这种情况还会持续很长时间。我相信他们都是各自都要用的，因为TPU本身就是为专业领域设计的，不像GPU那么通用，很多问题不能直接用GPU跑。

**老徐:** 其实你到DeepMind官网翻模型卡片，从1.0开始，硬件描述就是Gemini的训练和推理都使用自己的TPU。只是前几代大家没有很强的体感，到第三代突然有人捡起了这句话。从2.0开始，应该是100%的训练和推理工作是用TPU完成的，这应该是没错的。

**小苏:** 是的，但这应该仅限于Google内部，也就是模型内部的训练和推理工作。但实际上卖出去的时候，包括你的环境，包括你适配英伟达的环境，这些都要考虑。

**老兄:** 这其实是个文字游戏，你绕不开英伟达。规模化生产与英伟达是绕不开的。至于对英伟达能否构成竞争，我觉得是另一回事。这就好比英伟达是开店卖早餐的，你是做油条的厂家，你自己去开了早餐店，那肯定是不一样的。所有开早餐店的人可能就会提防你，或者你供给市面上早餐店的油条，品质可能就比你自己开的早餐店差一点。你可能会用上一代或稍微落后一点的TPU去供给Anthropic或OpenAI，肯定优先保证自己用最好的。我觉得是这样一个逻辑。所以它更多是一个内部成本的优化。当满足内部需求后，它可以对外提供一些服务，但实际上它很难与英伟达直接竞争，因为本质上是两种生意模式：一个是要回本的，一个是疯狂捞钱的。

**老兄:** 这给我一个感觉，既然TPU既能训练模型又能推理模型，说明它在训练和使用环节都可以实现。这说明对于**CUDA**（Compute Unified Device Architecture: 英伟达开发的并行计算平台和编程模型），也就是英伟达构建的护城河，其实已经有漏洞，或者说已经突破了。这对中国企业，尤其像华为以及正在做芯片的企业来讲，证明了一种可能性。我觉得只要能证明这种可能性，就是一件很好的事情。这是一个比特的路线，告诉你这条路是通的就够了。而且资本市场也认可。据说最近要发布的DeepSeek R，到底是不是在全华为生态上训练的，我们还不知道，可能要结合这个事情才能看得更清楚，得出一些结论。但至少从美国的情况来看，不管Google是主动还是被动，Anthropic和OpenAI都已经事实上部分使用了TPU生态来做模型的训练或推理。因为这其实是一个“备胎计划”，是必须要有的。

**小苏:** 是的，厂商之间互相合纵连横、竞争都有。最近微软又出来给Anthropic站台，因为它可能又迁移了一部分到微软的云上面。我觉得这是一个互相影响的过程。就像老徐之前讲过一个例子，黄仁勋（英伟达CEO）说“整天有人想干掉我，我的竞争对手天天晚上做梦都想干掉我，但我还是能领先他们一步到半步”。这其实就是护城河。他总会算好账，即使你的卡不要钱，他也能比你先算好，你的总运营成本还是买他的最便宜。

**老兄:** 所以多啰嗦一句，这跟护城河相关。你看巴菲特现在也建仓了Google，据说还不少。这说明他可能大概看懂了Google的护城河。强如Google，与英伟达的护城河相比，老黄还是战战兢兢的。讲真话，真正的护城河跟技术和硬实力真的没有关系，很多时候它就是一个用户心智，用脚投票，并不是100%由技术构建的护城河。你强如英伟达，天天都有人想干掉他，他也只能领先别人半步到一步。

### Google AI战略与Demis Hassabis的领导力

**小苏:** 而且这里面有一个点，就是它的技术其实可以不用一直保持最顶尖，TOP3就可以了。因为它其实就是我们刚才提到的云服务。我觉得Google的战略非常清晰，**ToB**（To Business: 面向企业，指产品或服务主要针对企业客户）战略是基础，顺便把**ToC**（To Consumer: 面向消费者，指产品或服务主要针对个人用户）的一些东西也做了。它的ToB战略非常明确，就是我把ToB的东西做好，能够通过Google Cloud出去。Google Cloud这几年增长特别稳健，超出预期。所以这次可以理解为厚积薄发。前面Gemini 1和2还无法与OpenAI抗衡，但直到Gemini 3，你感觉它跑出了GPT-5的理想状态，明显比它好。但它实际上是一步一步在走。这次Gemini 3的发布也非常老练，学习了OpenAI的方式，提前让Sundar Pichai、Demis Hassabis等大佬和各种媒体在社交媒体上预热，猜测发布时间。我记得Pichai还回复了某个博彩网站关于发布日期的预测，回了两个惊讶和思考的表情，大家都在猜他是不是自己也买了一点。所以他们这次搞得很轻松、很老练。

**老兄:** 而且哈萨比斯和Jose（Gemini团队负责人）在发布前一天还接受了《The New York Times》的采访，这很正式。他们甚至在采访前声明，纽约时报正在与OpenAI打内容侵权官司，我觉得这个设计非常老练，是一个很经典的公关**PR**（Public Relations: 公共关系），只是方式比较诙谐。

**小徐:** 哈萨比斯和Jose讲了很多东西，综合起来就是“一切尽在掌握，Gemini 3跟我预期的一样好”。他也没有说这个东西出来加速了**AGI**（Artificial General Intelligence: 通用人工智能，指能够理解或学习人类所能完成的任何智力任务的人工智能）。他五个月前接受某个博客采访时说是5到10年，现在他说Gemini 3与预测一致，很好，但还有好几个重大突破需要完成。现在的时间与他预测的没变，他仍认为是5到10年AGI会实现，中间还有几次大的突破需要攻克。也就是说，Gemini 3并非在这些重大攻克点上。所以你看，这次发布也没有专门的发布会，只是造势一下，然后权限就都上了，包括Google搜索的AI模型都直接全平台上线了。以前这种全量发布是蛮激进的。

**小苏:** 是的，这种是全量的。这说明这次的发布，就像我们前两个月听到一些风声时估计的，我们以前在外企工作，所谓的**GA**（General Availability: 普遍可用，指产品或服务正式向所有用户发布的状态）状态，通常要提前两三个月版本就很稳定了，只是先找一小撮人测试两三个月再上线。所以我觉得两三个月前，Gemini 3应该已经在各种地方灰度测试了，而且测得还不错，所以到这个时候就很稳，直接上线就是了。所有地方都可以上。无非是Pro之外的一些模型，可能稍晚一点，两三个星期，我觉得年底之前，像Flash模型、Light模型应该也都会出来，只是先把Pro推到面前先用起来。所以整个节奏，对于他们而言，就是尽在掌握，按照自己的节奏走，确保能力在B端企业端使用都很稳定，包括云端。这是他们路线图中的一次迭代。

**老兄:** 从技术的架构牵引上讲，这一步可能在一年前组织调整之前就已经做好了。这次我看采访，之前我不确定Jose是不是汇报给哈萨比斯，看这个采访挺像，应该是的。Gemini APP应该直接由哈萨比斯管理了，这样事情就会比较稳。因为之前可能有一段时间的过渡，Gemini APP的负责人被换掉了。我们早晚报还报道过这条新闻，Gemini APP负责人离职，这可能是比较早之前的一个组织架构调整。但这件事非常重要，应该大半年前Jose接手的时候。Jose上来后做了很多大刀阔斧的改革，但他之前是负责Google AI Studio的。所以我觉得他更多代表的是用户的意见，改革更多是在产品层面。而模型层面，还是跟着哈萨比斯和DeepMind这条路线稳步前进的，他能做的不多。

**小苏:** 是的，他的结合我们可以参照OpenAI来看。OpenAI的组织架构有点特别，它能把研究员和工程师融合得非常好。以前以伊利亚为代表的研究员和以格雷格为代表的工程团队，能够融合得特别好，将一线的理论和实验转化为实际能跑的工程产品，这非常难，因为两个团队方向完全不同，很难交流。而哈萨比斯就是这样一个人，他能搞定科研，也就是研究员这一块，加上工程，他两个都能搞定。他以前在DeepMind，我们稍微扒一下他历史会知道，他最早就是剑桥毕业的博士，也是一个天才少年，很早就因围棋成名，是世界冠军级的。后来又因AlphaFold获得了诺贝尔化学奖，对化学领域的贡献很大。之前还有更震惊的AlphaGo，击败了世界冠军李世石和柯洁。也就是说，他在从科研找方向、做实验，到转化成一个工程产品，可以直接与人打交道，这方面的经验非常多。他本身也有足够的判断力来做这件事。所以现在这个东西，我也看到有人评论说，这次Gemini 3又引出了另外一个竞争，就是每家大厂的AI掌门人到底是谁。Google这边，哈萨比斯这一次很明显地成为了AI掌舵人。

**老兄:** 对，之前可能大家在组织架构调整过程中看不清楚到底是谁，现在看得很明显，关键的大模型部分就是哈萨比斯。我后面也做了一些功课，看到很多Google内部的人或离职的人都会说，哈萨比斯在确认OpenAI很强的时候，也就是Bard（Gemini 1）那个时候，他其实就已经强制要求，除了一些关键部门，比如像AlphaFold这样明确已经成果很好的，都要强制转向大语言模型。如果不行的话，就离职。就这样子，很多人，很多很优秀的人，也在那个时候真的就走了。但是他这个时候坚定的转换是非常坚决的。然后也确实，后来很多关键人才在其中起到了关键作用。这个人是被低估的，我一直感觉哈萨比斯这个人是被低估的，严重被低估的。因为你刚才讲的，整个Google的AI转向大语言模型，包括DeepMind和Google大脑的合并，等等这些动作，这个人完全是被低估了。包括我觉得说，他在做技术选型的时候，包括最后整合Gemini团队的时候，用的人我觉得都是用得非常对的。最后你看Gemini口碑做得这么好，而且他是非常坚定，说我基础模型一定要足够牛逼，足够强，我才能溢出来，把产品顺便做好。我觉得他是非常坚定这条路。所以你看Google整个路线都是在基础模型上努力，一直在基础模型上努力，而产品上的努力其实不算多，更多是基础模型溢出一点，产品接一点。

**小苏:** 相对而言，虽然我们不在里面，但感受就是这样，可以感受到里面的工程团队与产品团队在聊的时候，肯定工程团队更强势一点。很多产品是基于基础模型能力溢出的包装，比如多模态、Storybook这些东西。基本上是工程团队过来跟你汇报一下，我这周有哪些重大突破，产品团队就想，我怎么把这些包装成一个功能给你。他不像OpenAI，直接去做出一个产品给你，直接做一个Agent模式，直接做一个Codex，直接做一个Sora给你。他不是这样的，OpenAI是直接干出一个产品，从UI到细节到交互，直接给你定义完了。但我觉得Google的产品比较弱势的是，它只能去包装这些基础模型做好的东西。

**老兄:** 是的，很多基础设施上，我还是会觉得可能历史包袱比较重。你看这么长时间，哪怕是我们觉得经常讲的NotebookLM这么惊艳的一个产品，其实也经历了好多波折才生出来。但是，然后他们在那边，其实应该还是，我们怎么讲，就是说，在这个产品这一块就是会滞后一点。只要能把工程这块搞定，我是觉得它的，我们还是回到那个B端的这个交付盈利这些部分就是有谱吧。就是它因为它还是会更多去兼容它已有的这些产品，而不是直接做个新产品。还是这样子的。或者换个角度想，你看，你确实啊，我首先我承认，就是Gemini 3.0让我觉得它还是现在现存的完整性、平衡性最好的一个模型。我觉得这个确实比我用OpenAI的GPT 5.1感觉要舒服，可能也加上用惯了。但是呢，就是从产品端来讲的话，确实是我们感觉它没有像OpenAI包装那么好。那会不会有一种可能性，就是在Google内部他们也评估了，就是现在来讲，应该把力量花在基础模型上？就是基础模型的这个前进速度，或者说所需要消耗的能量，还远远不够，还远远大于说现在要花时间去做产品。这种也可能是他们内部的一种判断，所以说在战略上必须做一种选择吧。就好像我遇到一些人确实很聪明，他们聪明到什么地步你知道，就说话会结巴。就是他大脑思考能力远超于自己的表达，太快了，嘴巴的带宽太低了。所以他表达的时候，就会让人觉得词不达意，或者说结巴。这并不是因为语言的障碍，而是因为表达能力跟不上他思考速度。所以他在这个阶段时候，他会表现出这种情况。当然了，也可能永远改变不了，也可能就是听过一些训练之后，他表达能力也上来了，思维更敏捷了。然后当然有些人就是能说会道，口若悬河，但脑子里没什么东西，永远都是那几套方法论，永远都是在聊那些东西。你现在Google和其他的AI公司来讲的话，会不会Google内部也在基础模型上有巨大的一个战略安排？然后他不断不断投入自己的资源，然后在这个过程中还不够，所以说根本没有把精力放在产品上？或者说像之前咱们也讨论过，他主要是做ToB，再加上他本身也还有搜索的包袱。

**小苏:** 你其实提出了这个问题的本质。作为Google来讲，你看OpenAI跟Google，我们还是拿两家来比。OpenAI跟Google差了一个搜索跟云服务。我觉得这是最明显的一个差异。我们上次也讲过，只要Google云每年佛系增长10%，就能长出一个OpenAI一年的营业额。所以我觉得他们想的事情是完全不一样的，焦虑程度也不同，屁股决定脑袋。Google作为云服务第三名，如果还要增长，那必须是靠基础模型。而且你仔细去看，它的整个Gemini的**API**（Application Programming Interface: 应用程序编程接口，允许不同软件之间进行通信和交互的规范）能力的提升，其实导致了它云和AI这块客户的增长非常明显。所以我觉得这是它最稳妥的一个选择，也是它能力范围内最稳妥的选择。如果你说Google今天就跟OpenAI一样，我拉团队去做应用，我可能未必会做得比别人好。我觉得这是很有可能的一件事。我未必会做得比OpenAI好，未必会做得比Anthropic好，甚至未必做得比国内的这些厂商好。但是我把API放出来，你们一堆人去套壳拿了Banana，你们一堆人去套壳Deep Research，你们做出好的应用，然后也买我的API。你看，像NotebookLM那个语音的API，它就一直不开放。老师就抱怨好多次，我们早晚都想用那个。而Gemini里面有开放类似的，质量差很多的**TTS**（Text-to-Speech: 文本转语音技术），那个就很烂。它故意就气死你。实际上你想，如果NotebookLM把这个语音博客API开放了，那这个市场其实可能就更繁荣了，它的云服务生意也会更好。那是它要不开放的问题，我觉得选择权在他手上。我觉得它其实是从从容容、游刃有余的。

**老兄:** 不，这只能说是到了2.5 Pro之后，它才开始变得从从容容、游刃有余。前面都是跌跌撞撞，真的是翻车几次了。2.5之前调整组织那段时间，看得真的是很惊心动魄。但实际上你今天回过头来看，我觉得2.5之前他们还是从从容容、游刃有余的。就是我，我是觉得，就是他们还是在自己的掌控范围内。

### Windsurf收购与Gravity产品

**老兄:** 这引发出来的事情就会好玩。我看到有人去对标，说到了这个时候，看到了哈萨比斯这么厉害，搞出的东西又稳又强，而且后面看起来5到10年的规划都很清楚。那这样对标起来，其他几个大厂的AI掌门人，比如OpenAI的Sam Altman，营销奇才，但好像对工程技术差那么点劲，不太懂。包括安全部分也不太行吧，不然当时伊利亚不会走，伊利亚就说它的安全实在不重视就走了。微软的Satya Nadella，老板冲在前面，后面最担心的就是财务。Meta的杨立坤本来一号位挺强的，但最近也走了。而且杨立坤在的时候天天都说大模型不行，所以他这个方向也是个谜，也不是说他不对，但至少他跟Meta的整个发展路线确实有点冲突。Meta以后行不行，又得看那个小年轻了。这也是搞笑，食君之禄忠君之事，你拿人钱财不替人消灾，整天在外面骂大语言模型不行，天天骂自己公司的产品路线不对，这也是一个很神奇的事情。而且也能忍他10年，也算很强了，我觉得扎克伯格还是很包容的。

**小苏:** 是的，已经很包容了。

**老兄:** 然后苹果的AI没有一号位，我们也不想多说苹果了，说得也挺惨。微软其实也没有明确的AI一号位是谁。

**小苏:** 微软的AI应该在云服务之下，云肯定有一号位，就是纳德拉本人，他自己其实就是强人。但是就是拿不出来，你说像哈萨比斯这种又工程又学术，有研究员这种背景的负责人，好像是找不到。

**老兄:** 是的。这也挺有意思的，稍微沿着这个组织问题延伸一下。你注意到这次发布的一个**IDE**（Integrated Development Environment: 集成开发环境，提供程序开发所需工具的软件应用程序）产品吗？就是Google干掉Cursor的那个产品，Gravity，反重力。上次我们聊过，是被神奇72小时的Windsurf的CEO搞的，他们的团队做的这个产品。你们用过没有？

**小苏:** 我还没开始用，因为我看了一下他的东西，应该是把精华的东西都学到了。而且很重要的一点是，他到了Google，很多调试可以直接调Google浏览器了。我觉得太牛逼了。有很多东西可以直接调Google浏览器，以后是完全不一样的状态。很多人都说他是套壳VS Code，但肯定要套的，套是正常的，因为全世界都套它。因为那边已经有了程序员习惯的交互和丰富的插件，他套是正常的，不套才不正常。

**老徐:** 我其实用了，我发现它跟Chrome的集成非常丝滑，可以直接通过Chrome去跑你现在写出来的这些东西了。

**小苏:** 不光是跑，你还有很多，比如说我们刚才说UI，他可以直接你现在Chrome在看哪个UI，让他去把看的UI抄过来就完了。他这个东西就不，你以前是肯定不行的。你以前得自己去，比如说我是其他的，是用GREP还是或者别的IDE，我肯定得自己想办法跑到Chrome里面去，把那个源代码抠出来。但是其实前端代码，很多东西已经是前后端分离了，没有那么好抠的。你看到的东西，它后面的代码你都不知道藏在哪，然后其实很难抠的。但你现在因为是背后一条线通了，Chrome的本身背后底层通了，那你可以想要做调试要干嘛，想要抄人家哪个站点哪个功能，其实至少就是这个效率肯定是比以前能提升很多的。这个是这个是有利有弊嘛，有的人也会觉得说唉，那为什么绑Chrome，能不能搞一个单独的，那以后看他会不会出呗。那有Chrome，至少在你大部分的东西都已经很顺了。就大概是这样。

**老兄:** 是的，而且我觉得它是比Gemini CI更进一步了，已经到IDE级别的开发环境里面去。我真的就觉得说，它的组织整合做得非常好，这么快地吸纳了Windsurf最核心的员工，带着他们的Know-How，用着Google的TPU，开着Google的服务器，吹着Google的空调，把他们的Know-How写到这个产品里面去。然后放出来，气死你们全部人，气死Cursor，气死OpenAI。这才四五个月吧，就非常快了。这只有原班人马来造，才有这么快。

**小苏:** 我觉得Google在组织整合现在也进入了一个游刃有余的地步了，真的是很厉害。一个团队进来，然后开始就干了，这个东西出来的完成度其实也是蛮高的。虽然产品做得还不好，很多人说登录也没做好，付费也没地方付，但实际上你发现这个产品已经放出来第一天，我觉得这还是可以的，挺好用的。

**老徐:** 至少对我来讲，多了一个Gemini Agent的客户端。因为你其实它有一个叫做HMOD，你进去的时候，你就是把它当做一个Gemini客户端去用。然后你叫他帮你查商品、比价什么东西的，就直接在后台浏览器自动化帮你完成了。过程当中，你也可以看到他是怎么做Planning的，怎么做计划，怎么做执行，怎么做比价的。那很多自动化东西在上面都，它的整个就是叫做AGMOD的那个整合模式，其实我觉得是比OpenAI或者是比Gemini自己的APP好得多的。

**老兄:** 但其实那个用量很快就用完了。我用它上面那个Gemini 3的那个High的模型，应该是比较高端的那个模型，没用几次就用完了。想找地方付钱没地方付。就先吊你一下，饥饿营销一下。

**小苏:** 是的，而且还可以用Anthropic Cloud，还有一个模型是GPT OSS。

**老徐:** 而且不光可以用Anthropic Cloud，而且用Anthropic Cloud那边还免费的。就是Cloud 4好像在那边是可以免费用，就是GPT也是免费的，GPT在里面也是可以免费用的，那个OSS。

**老兄:** 是的，我觉得这个还是挺魔幻的。我第一次看到Google出了一个Mac的APP。我觉得这活久见了。我觉得原班人马，可能就差代码直接拷贝了。

**小苏:** 我觉得原班人马应该都很熟了，因为他们最早做的都是为Mac做的那个IDE。

**老兄:** 是的。所以我说，哈萨比斯现在的整个组织整合能力，包括自己在Google内部的威望，包括他的权力，其实已经到了一定的地步了。所以我觉得，你要说什么护城河，我觉得人是最重要的。人和，我们讲人和，这非常非常重要。

### 一次性软件的未来展望

**小苏:** 所以Gemini 3的突出，我觉得在我心中就是四个字：水到渠成。到了这个地步之后，把所有的这些能力，包括你说的组织架构的这种隐性的实力展现出来，然后在年底之前先推出一波。我现在更期待是3.5，就是看3.5 Pro版本，能不能带给我像2.5一样的，或者像Banana这种产品，它真的是在模型基础能力溢出的时候，然后释放一个产品。我觉得未来可以期待的是什么？这一次，可能大家有没有注意到一个“一次性软件”的概念？就是我当我在AI模式下，选择一个思考模式的时候，比如说我要去查图文并茂地了解梵高的一生，或者了解某个科学研究的时候，它其实已经可以一次性编码来帮你解析蛋白质结构，梵高的一生，等等这些科学、艺术的东西了。这本质上也是一种成本的下降，带来的就是你可以浪费算力了，可以浪费模型的这个能力了。我觉得我看到一个点，就是或许可能真的到成本降到一定程度的时候，“一次性的软件”就会变得随手可得。你每一次搜索，可能调用的都是一个即时的编码，帮你解决了一个即时的问题，而不是用一个现有的程序了。我觉得未来是蛮有想象空间的一件事情。可能今天想起来是有点铺张浪费的，但是可能未来也许这个事情在3.5，在4到5的时候，有可能就是一个非常随手可得的东西。这是我个人觉得，比起那些前端酷炫展示之外，我个人觉得最期待的一个事情，就是一次性的软件，可能一次性的Demo，一次性的代码，可能未来就是随手可得了。老兄，对未来Gemini有什么期待？

**老兄:** 我还是希望它继续走现在的路线就很好，就是原生多模态、长上下文，这个事情你能把它继续做下去。昨天好像咱没提，确实是。然后还有它的世界模型，就是Gemini那一个，我们之前也聊过一些。那现在Gemini应该还在实验室，没有太多的出来，怎么跟整个世界去融合，或者说跟我们产品怎么融合，现在还不知道。那我会真的期待它的就是全方位的多模态，多模态到了真实世界，物理模型这些东西，这方面的东西，它还可以继续地走。因为我觉得它是所有在做AI大模型里面，它会真的把能力开放给你的那一家。如果OpenAI的话，我们其实感觉得到，它更多已经手伸向产品端了。我感觉它的基础相对的东西慢了一些，ToC的比较快，但是它的基础模型我感觉慢一点。它有点像是可能有实力，但是有点像是我手上有好多好牌，但是我不那么快地打下来的那种感觉。就是比如说，预祝Google好人一生平安。我是希望它真的是更好的，没有敌人，没有永远朋友。真的是希望Google好人一生平安，它走走远一点，把更好的，像DeepMind那边也科研出来的东西，尽早地能够在产品化这边开放给我们这些小B端或者是广大的B端，反正大家都能采用起来，或者个人创作者大家能用起来。就是这个，可能是大厂中间，我们觉得直接能用得上，而且你不担心它会瞎搞的那种，就是有成熟可靠的那一份东西的。

**小苏:** 是的。然后我借用，最后我就借用Pichai的一句话吧。他说这种Gemini 1.0的时候，通过原生多模态加超长上下文，奠定了一个很好的基础。到2.0的时候，其实是在Agent跟编码上面取得了非常大的一个进步。那我们在展望Gemini 3.0，我个人觉得说，我看到了不只是说很多前端的创新，也不只是说它的整个重构，更多的是我觉得说，可能它让我们真的能看到一个一次性软件的未来。然后它真的让我们能看到说，我们可以在不久的将来，就可以抛弃卷的UI，真的把AI变成一个劳动力来用了。所以这个是，我觉得说，Gemini 3.0应该会是一个承前启后，非常重要的一代。所以呢，最后我们就祝Google好人一生平安。