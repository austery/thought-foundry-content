---
area: "work-career"
category: ai-ml
companies_orgs:
- OpenAI
- DeepMind
- Google
date: '2024-06-08'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《古拉格群岛》
- 《水族馆内幕》
people:
- Leopold Aschenbrenner
products_models:
- iPhone
- GPT-4
project: []
series: ''
source: https://www.youtube.com/watch?v=667IffkMDmU
speaker: Dwarkesh Patel
status: evergreen
summary: 本次内容探讨了国家级间谍活动对 AI 实验室构成的严重威胁，包括零日漏洞利用、技术窃取以及对模型权重和算法秘密的潜在攻击。演讲者强调了加强 AI
  安全和国家安全的重要性，指出当前防护措施远不足以应对高级威胁。
tags:
- history
- llm
- model
- national-security
- security
- state
- zero-day
title: AI 实验室面临严峻的间谍活动威胁
---
人们确实低估了**间谍活动**。我认为安全问题的一部分在于，人们没有意识到**国家级间谍活动**可能有多么激烈。例如，一家**以色列**公司拥有可以“零点击”（zero-click）破解任何**iPhone**的软件。只需输入你的号码，就可以直接下载所有内容。美国也曾渗透过一个**原子武器项目**。这真是太疯狂了。

情报机构拥有大量的**零日漏洞**（Zero-day exploit: 指尚未被软件开发者发现或修复的安全漏洞，可被攻击者利用进行攻击）。当情况变得非常棘手时，他们可能会派遣**特种部队**前往数据中心。或者，**中国**会威胁人们的家人，说：“看，如果你不合作，不给我们**情报**（Intel），后果自负。”

有一本很好的书，可以参考**《古拉格群岛》**（The Gulag Archipelago: 亚历山大·索尔仁尼琴创作的关于苏联劳改营体系的纪实文学作品），以及**GRU**（格鲁乌: 俄罗斯联邦武装力量总参谋部情报总局，是俄罗斯的主要军事情报机构）前情报官员写的**《水族馆内幕》**（Inside the Aquarium）。GRU就是军事情报机构。我读了那本书，感觉非常震惊，它详细描述了他们如何前往欧洲各国，试图获取技术并招募人员。

这位未来的**叛逃者**在**GRU间谍学院**接受训练。为了毕业，在被派往国外之前，必须通过一项测试，证明自己能够胜任。测试内容是在**莫斯科**招募一名**苏联科学家**，并让他们提供信息，就像在外国会做的那样。然而，对于被招募者来说，泄露秘密信息的惩罚是**死刑**。因此，要从GRU间谍学院毕业，就必须亲手将一名同胞推向死亡。

各国都在进行这类活动。你需要有**俄罗斯**无法窃取的安全措施。你不能让**俄罗斯**轻易窃取所有东西。也许他们的计算集群规模不会那么大，但他们仍然能够制造出**疯狂的生物武器**和先进的武器系统。

我认为安全组件是这个项目的一个相当大的组成部分。目前，我看不出有其他方法可以避免这种技术的**即时扩散**。例如，现在要让一个**敌对行为者**窃取那些关于**斯嘉丽·约翰逊**声音（此处可能指AI语音生成技术）的东西有多容易？或者关于**RL**（强化学习）和**UN**（联合国）的讨论？这都极其容易。

**DeepMind**声称他们的安全级别从0到4，其中4级是最高级别，能抵抗**国家行为者**。但他们自己承认目前处于**0级**。最近，有一份起诉书提到，有人窃取了大量非常重要的**AI代码**并带到了**中国**。他所做的只是复制代码，将其粘贴到**Apple Notes**中，然后导出为PDF，就这样绕过了他们的监控。

**Google**拥有可能是所有**AI实验室**中最好的安全措施，因为他们有**Google的基础设施**。但如果将一家初创公司的安全措施与一个靠近**三峡大坝**的**吉瓦级数据中心**相比，初创公司的安全措施就不那么好了，很容易被窃取。

一个威胁模型就是直接**窃取模型权重**。这尤其危险，因为这相当于复制了**炸弹**，直接制造了一个**最终产品**的复制品。这在**AGI**（通用人工智能: 指具备与人类同等或超越人类的认知能力的人工智能）和**超级智能**出现时尤为重要。**中国**可以建立庞大的计算集群，但我们拥有更优秀的科学家。如果我们创造了**超级智能**，他们可以直接窃取。

目前，**GPT-4**（GPT-4: OpenAI开发的大型语言模型）的权重可能不那么重要了，但我们必须现在就开始关注**权重安全**。因为如果**AGI**在2027年出现，这些工作需要时间。这不仅仅是简单的访问控制，如果想真正抵抗**中国**的**间谍活动**，安全措施必须更加严密。

但人们可能没有足够重视的是**秘密**本身。计算能力是“性感”的，我们经常谈论它。但**秘密**被低估了。每年**算法进步**带来的**半个数量级**的提升是巨大的。如果我们领先几年，就相当于拥有了**10到100倍**的计算集群优势。

我不知道是否有人真正站出来告诉他们：“你们正在构建的东西对**美国的国家安全**至关重要，对**自由世界**能否继续存在一个世纪至关重要。”你们所做的事情对你们的国家、对**民主**都非常重要。但人们却不谈论这些**秘密**，这不仅仅关乎**DeepMind**或任何其他公司，而是关乎这些真正重要的事情。