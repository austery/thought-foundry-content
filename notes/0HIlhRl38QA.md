---
author: Peter Pang
date: '2026-01-22'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=0HIlhRl38QA
speaker: Peter Pang
tags:
  - agent-skill
  - prompt-engineering
  - token-optimization
  - dependency-management
  - software-engineering
title: Agent Skill：AI工程化的新范式与Token效率革命
summary: 本文深入探讨了Anthropic提出的Agent Skill新概念，将其类比为软件开发的依赖管理，强调其通过提示词拆解、按需导入实现Token效率最大化。文章指出，Skill的本地化运行模式解决了安全与集成难题，使Prompt Engineering真正走向工程化。演讲者分享了收集和构建Skill的实践经验，并预测Skill将催生分级服务，为用户带来更经济高效的AI应用体验。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - Anthropic
  - OpenAI
  - Google
products_models: []
media_books: []
status: evergreen
---
好了，不玩梗了，我认真锐评一下 **skill** 这个东西。我们都知道，作为业界三巨头，**OpenAI** 最擅长炒作，**Google** 最擅长算法，而 **Anthropic** 最擅长开发。自从 24 年年底发布了 **MCP**（一种AI标准）之后，25 年的年底，Anthropic 又给我们带来了 **agent skill**（一种将AI能力模块化、可按需调用的新概念）这个新概念。skill 一发布，圈子里的大家就都知道，又一波 AI 开发的升级即将到来。

### Agent Skill：AI工程化的基石

其实 skill 这个概念并没有什么很重大的突破，你甚至可以说它有点返璞归真了。它解决的是一个非常现实的问题：如何用最少的 **token**（AI模型处理和生成文本的基本单位）办最多的事儿？答案就是把提示词拆解，按照能力范围打包，互相保留指针，然后再实时按需导入，实现动态的提示词构建。这其实也是为什么我觉得 skill 是目前众多 AI 应用概念里最有机会成功的那个。因为它让我想起了 **maven**、**npm**、**crate**、**pip**，也就是大家熟悉的依赖管理。你可以骂现在的一些技术框架过于依赖依赖，一个 hello world 就要安装上千个依赖，但不可否认的是，正是因为这种积木结构，才可以带来无穷的可能性。

### 本地化与工程范式的革新

从技术层面上看，比起大模型、MCP 这些，skill 被整合进到工作流的难度更低、可接受度也更高。咱们就说大模型，天天更新的 **VSCode**（集成开发环境）到现在还得靠第三方插件来支持其他的模型。而 MCP 的整合则是更折腾，尤其是去年一连串的 MCP 安全漏洞事故之后，现在稍微专业一点的平台，对于 MCP 的接入都加上了很多层的验证机制。我之前试过把 AWS 上的一个 AI 服务接上 GitHub 的 MCP，从查资料到生成各种密钥，搞了接近一个小时才搞好。

而 skill 则是用一种最简单的方法解决了这些问题，那就是完全本地运行。所有代码都在本地储存，所有指令都在本地运行，一切都是公开透明的。没有跨网络通讯，自然也不会存在 **RPC**（远程过程调用）之类的安全问题。我认为 skill 的出现是第一次让 **prompt engineering**（设计和优化输入给AI模型的指令以获得期望输出的学科）这个概念真正像一个“工程”。而在此之前，我们对提示词的使用更像是在做实验，因为还没有摸清楚大模型这个生物的特征，我们就在这儿给它一点酸，在那儿给它一点碱，然后再观察它有什么反应。而现在大模型对 **function call**（AI模型调用外部函数或工具的能力）之类的基本机制都已经稳定下来后，skill 这种有结构、有规模的软件工程范式才可以真正的普及开来。

对我这种软件工程师，它的出现是一种契机。因为在大模型迭代的上半场，主角是那些算法科学家；上半场的那些概念，我们看都看不懂，只能乖乖地当个用户。而现在进入了应用落地的下半场，软件工程的理念会更加发挥作用，我们就变成了懂行的那个了。

### 构建与应用：Skill的生态实践

为了搞清楚现在的 skill 生态，我找遍了互联网，搜集了大约 300 个开源 skill，覆盖了文件处理、数据分析、网页生成、安全检测、项目管理等各个领域，全部都安装到了 IDE 里。因为现在还没有 npm 这种包管理框架，所以这些 skill 还得一个个导入，略显繁琐。之所以要一股脑地把所有的 skill 都安装进去，而不是用什么装什么，是因为我们永远都不会知道在什么时候需要用上什么 skill。

比如说我们这里让 AI 去做一个完整的数据可视化项目，它经过对需求的拆解、分析之后，得出的设计方案里面就包括了需要处理 **CSV** 这个数据源，需要用 **D3.js**（一个用于数据可视化的JavaScript库）这个可视化框架，需要用 **Playwright**（一个用于Web浏览器自动化的Node.js库）做前端测试。正因为我把什么都装进去了，这些我都有对应的 skill，所以 AI 就会在系统提示词里面发现它们之后，直接去到对应的那个 skill 里，导入相关的提示词和参考代码。那么假如下次 AI 出的方案里面，还包括了要用 **Excel** 作为数据源，又或者它把可视化框架换成了 **ECharts**（一个由百度开发的，基于JavaScript的数据可视化图表库），又或者它要用 **property based testing**（一种软件测试方法，通过生成大量随机输入来验证代码属性）做测试，我也不需要着急，因为这些 skill 也都被安装好了。

这种按需导入的机制，就决定了我们在安装 skill 的时候，要遵守“宁滥勿缺”的原则。能找到多少就安装多少，找不到的就自己造，因为造这个东西比想象中的更容易。就像那些只有一行代码的 Node.js 工具包，你的 skill 也可以是只有一句话的一个 markdown 文档。然后在此之上，你再去逐步的拓展你的 skill 内容，增加步骤、增加可执行的脚本、补充更多的案例。比如我前些天做了这个用来分析 **CVE**（Common Vulnerabilities and Exposures，通用漏洞披露，一个公开的漏洞数据库列表）漏洞和各种漏洞事故的 skill，在一开始就是很简单的：找到官方报告，提取里面出漏洞的代码和官方解释，最后生成总结。后面我陆续地补充了更详细的拆解要求，而在让它做分析的时候，也专门指出那些要关注的点，并且引导 AI 去做更有针对的解读。再后来，我还给一些步骤加上了执行脚本，比如在收集官方报告的时候，我指定它用什么脚本去爬取网页，可以保证这个数据获取的准确性。后面有了这个漏洞分析的 skill，在平时问 AI 一些技术问题的时候，它就能给我更专业的回答。因为没有这个 skill 的时候，它就只会像播报新闻那样，给我一个很笼统的漏洞分析。

### Token可控性与未来展望

作为一个实用主义者，在我看来，skill 最大的价值是对输入的 token 数量有了可控度。因为在没有 skill 的情况下，你完全无法控制 AI 要花多少 token、爬取多少外部网页、导入多少参考代码，才会完成一个小动作。而在 skill 的基础上，你能够精确地控制每一个输入的字符。你如果想要更细致的操作，那你就多一点提示；你要想要它的输出更稳定，那你就多一些参考案例。反之亦然，你也可以在不影响输出效果的前提下，适当地削减一些提示词，减轻 token 的负担。

最近我在粉丝群里面听到最多的抱怨，就是“token 额度又没了”、“基础套餐完全不够用”。我自己还好，因为我连基础套餐都不买的，专门挑那些免费来薅，要不然实在是耗不起。你就说 GPT、Gemini、Claude 这些国外大模型，每一个烧的都是美元，而且一个个都是 token 吞噬者，我都怀疑他们是不是故意的。所以我大胆地推测，以后 skill 的发展会有点像大模型那样，开始出现不同等级的分类，比如更节省 token 的 Lite Skill、提示词更详细的 Pro Skill、完全不差钱的 Max Skill 之类的。而像我这种羊毛党，就会用着免费的 IDE，跑着最省钱的 Lite Skill，做个勤俭持家的好男人~