---
author: 硅谷101
date: '2026-02-07'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=VJgIENvy14k
speaker: 硅谷101
tags:
  - space-data-center
  - compute-bottleneck
  - orbital-computing
  - edge-ai
  - sustainable-compute
title: AI算力新纪元：太空数据中心的崛起与挑战
summary: 随着地面AI数据中心面临电力、散热等物理瓶颈，将算力搬至太空成为科技巨头的新战略。本文深入探讨了太空数据中心在能源、散热、低延迟方面的独特优势，并详细分析了在轨边缘计算、轨道云数据中心等主流建设路径。同时，也剖析了其在工程实现、高昂成本及轨道监管方面面临的严峻挑战，指出太空算力将作为地面算力的补充，共同拓展人类计算的边界。
insight: ''
draft: true
series: ''
category: tech-trends
area: tech-engineering
project: []
people: []
companies_orgs:
  - SpaceX
  - Google
  - Nvidia
  - Starcloud
  - Blue Origin
  - xAI
products_models:
  - Starship
  - H100 GPU
  - Nano-GPT
  - Suncatcher Project
  - Starlink
  - Google TPU
  - Trillium TPU
media_books: []
status: evergreen
---
你有没有想过，下一代的“算力工厂”可能根本不在地球上？过去几年，**人工智能**（AI: Artificial Intelligence）把**数据中心**（Data Center: 存储、处理和分发数据的物理设施）变成了新的“能源怪兽”。电力、散热、用水、选址，这些都成为了制约AI进化的关键瓶颈。于是，一个听起来似乎很科幻的想法，突然被拎到了台面上，那就是把数据中心搬到太空去。

在太空建造数据中心，听起来有点像是个骗投资人的PPT，但实际上，一场关于“轨道算力”的圈地运动已经拉开了帷幕。在刚刚闭幕的达沃斯论坛上，**马斯克**就宣称，在未来的两到三年内，太空就将成为部署AI数据中心成本最低的地方。而**SpaceX**今年的核心目标，就是去验证**星舰**（Starship: SpaceX研发的巨型可重复使用火箭）完全可复用性，接着在未来几年发射由太阳能供电的AI卫星，最终可能扩展至数百太瓦的规模。紧接着，马斯克又放出重磅炸弹：在当地时间2月2号，SpaceX宣布已经收购人工智能公司**xAI**，推动其总估值达到1.25万亿美元。马斯克透露，二者完成合并后，SpaceX最重要的事情之一就是将推动部署太空数据中心。文件显示，SpaceX已经向美国联邦通信委员会提交了高达100万颗卫星的发射计划，最终结果是太空将成为部署人工智能成本最低的地方，而且这将在两年内成为现实，最迟三年。

与此同时，**亚马逊**创始人**贝佐斯**旗下的**蓝色起源**（Blue Origin: 贝佐斯创立的私人航天公司），在一年多以前也已经秘密组建了开发团队，用来打造轨道AI数据中心的专用卫星。他们计划开始在太空建造这些巨型千兆瓦级数据中心。**谷歌**也在最近发布了一项名为**Suncatcher**（捕光者）的太空数据中心计划，预计将在2027年把第一批“机架级算力”送入轨道。谷歌表示，大约十年后，这种方式将被视为构建数据中心的一种更正常的途径。大佬们不只是停留在研究阶段，有些已经真正开始行动起来了。就在不久之前，**英伟达**（NVIDIA: 全球领先的GPU制造商）刚刚通过初创公司**Starcloud**，将一颗搭载了**H100 GPU**（H100 GPU: 英伟达推出的高性能AI加速芯片）的卫星送入了轨道，并且首次在太空中完成了**Nano-GPT**（Nano-GPT: 一种轻量级GPT模型）模型的训练，标志着太空算力建设已经进入到了实践验证阶段。此刻，或许预示着一个全新产业的诞生——太空数据中心。

所以，今天的太空数据中心似乎已经不再是“要不要做”的问题了，而是谁能先把它做成。那么，为什么科技公司宁愿忍受极高的发射成本，也要把服务器送上天？在万米高空的真空中，数据中心究竟应该怎么建？当算力离开地球表面，真的能跑出更便宜、更高效的AI吗？

### 地面算力瓶颈：电力与散热的极限挑战

要理解为什么数据中心要上天，我们得先看看现在地面的日子有多难过。如果现在你问硅谷大佬们，AI进化的终极瓶颈是什么，他们大概率不会说是算法，也不是人才，甚至也不是芯片，而就是两个最基础的物理限制：**电力**和**散热**。

在我们之前的一期关于“数据中心的真实账单”的视频当中，就曾经细致地拆解过，虽然供电和冷却设备加起来不足整个数据中心建设成本的10%，但却是数据中心现在真正被“卡脖子”的地方。现在的地面数据中心本质上就是一个吞电巨兽。当前一个超大规模AI数据中心的持续用电规模，已经从过去的几十兆瓦（MW）跃升到了数百兆瓦，甚至逼近了1吉瓦（GW）。1吉瓦是什么概念呢？如果一个系统以1吉瓦的功率24小时、全年无休运行，一年产生的电量大约是8.8太瓦时，差不多相当于一座中等规模城市一整年的用电量。

AI带来的问题还不止是“吃电”，而是几乎所有电最后都会变成热。以H100这类高端GPU为例，单卡功耗已经接近700瓦，一个训练集群动辄成千上万张卡，带来的直接结果是散热正在成为比算力更昂贵的系统工程。随着全球AI算力需求的指数级提升，传统的风冷技术已经很难满足高密度算力设备的散热需求，于是**液冷**（Liquid Cooling: 使用液体而非空气进行散热的技术）变为了必需品。数据显示，一个大型数据中心每消耗1千瓦时的电力，往往就需要1–2升淡水用于冷却。这意味着一个百兆瓦级AI数据中心每天就可能消耗上百万升水。更麻烦的是，随着GPU功耗继续上升，冷却系统的效率提升正在明显放缓。但是AI想要继续向前发展，仍然必须依赖大规模的能源消耗。

AI巨头们为了获取电力，可以说是绞尽脑汁：收购改造发电厂、自建电网、抢购燃气轮机、研究核能。地面已经卷入了一场AI能源战争。于是在这样的背景下，一个问题也就自然地浮现出来了：有没有一个地方，能源更充足、更加稳定，散热也能够更加地直接高效？答案就是太空。

### 太空算力的三大馈赠：能源、散热与低延迟

大气层以外的太空，给人类准备了三份厚礼，那是地面永远无法提供的“算力天堂”。

第一份厚礼是**能源**。在地面，能源是一个复杂的系统问题，涉及到发电、输电、储能、调峰、碳排、土地等环节。哪怕是最理想的新能源体系，也绕不开天气变化和季节波动。但在太空的近地轨道上，太阳能的逻辑则彻底不同。没有大气层的折射，没有云层的遮挡，更没有昼夜交替，只要电池板够大，理论上你就能获得24小时不断电的、几乎零成本的清洁能源。计算数据就显示，在地球轨道上，太阳能的利用效率是地面的8到10倍。这意味着能源第一次变成了“连续变量”，而不是“间歇资源”。而对于AI的发展来说，这一点极其关键，因为AI的训练和推理最关键的不是“便宜的电”，而是需要长期稳定、不中断的功率输入。

如果把视角再拉远一点，你会发现“太阳能”还只是太空能源金矿的冰山一角。我们今天在太空里用的“太阳能”，本质上只是太阳聚变反应的副产品。太阳本身是一个已经稳定运行了45亿年的天然核聚变反应堆，它每一秒释放的能量都远远地超过了整个人类社会所需要的总和。如今为了获取能源，很多投资者们扎堆去研究制造小型聚变反应，而马斯克对此表示这完全是多此一举，因为我们头顶上早就挂着一个免费的、不会熄火的终极能量源。这就好比在南极装个迷你制冰机，然后说“快看，我们制出冰啦”，只能说“恭喜！”，毕竟你旁边就是三千米高的冰川。

第二份礼物是**散热**。在地面我们要用巨大的风扇和昂贵的液冷系统，但太空的散热是完全不同的一套物理法则。AI运行会产生巨热，而太空背景温度仅为3开尔文（约-270℃）。只需要将散热器背对太阳，就能够获得高效的自然冷却。在真空环境中，热量不需要被“搬走”，而是可以以辐射的方式向深空释放。我们可以通过巨大的辐射散热板直接把废热丢进宇宙。前微软能源战略经理**Ethan Xu**告诉我们，这意味着**PUE**（Power Usage Effectiveness: 能源使用效率，衡量数据中心能源效率的指标）可以无限地逼近于1。他解释说，太空中的温度非常低，而传统数据中心可能有接近4%的电力是用来制冷而非算力供电。在太空中，如果能很好地利用接近绝对零度的环境，数据中心产生的废热就可以通过辐射散热的方式直接排到深空，这样数据中心的电力使用效率在理论上就可以接近于1，几乎所有电力都用于算力。

第三份礼物是**极低延迟**。光在真空中的传播速度比在光纤里快30%。通过**激光链路**（Laser Link: 使用激光进行数据传输的通信方式），太空数据中心可以绕过复杂的陆地网络和海底电缆，实现真正意义上的“全球算力秒达”。当算力节点开始出现在轨道上，它们不是“远离地球”，而是有可能在特定网络拓扑中变成更接近用户、更快的中继节点。所以说，太空同时满足了持续能源、极端散热、接近物理极限的通信条件，而这三件事正好也是AI算力当下最稀缺的三样东西。

### 轨道算力路径：边缘计算与云中心

这个听起来完美的方案，在现实中却面临着一个巨大的入场券问题：我们怎么才能够把那些比钢琴还重、比瓷器还脆弱的服务器塞进火箭，再精准地部署到轨道上呢？太空数据中心究竟该怎么建？目前来看，全球的探索已经逐渐收敛为两条主流路径：一条是**在轨边缘计算**（In-orbit Edge Computing: 将计算能力部署在卫星等轨道设备上，靠近数据源进行处理），另外一条是**轨道云数据中心**（Orbital Cloud Data Center: 在太空中构建分布式、可调度的云计算基础设施）。这两种探索一个解决“现在的问题”，一个押注“未来的规模”，解决的是不同层级的问题，也代表着不同阶段的野心。

关于这两种路径，最近**浙江大学**和**新加坡南洋理工大学**也在《**自然**》（Nature: 国际顶级科学期刊）上联合发布了最新的研究，首次系统性地提出了完整的技术框架。我们此次也采访到了该论文的第一作者**Ablimit Aili博士**，来帮助我们理解一下两种路线究竟有什么区别、都怎么建。

首先来看**在轨边缘计算**模式。边缘数据中心它并不是一个完整的“云”，它的核心逻辑相对简单，就是不再把卫星采集到的所有数据都传回地面，而是把AI加速器直接送上已经在运行的卫星，让数据在太空中就被分析、筛选和压缩，适用于一些规模较小、更加专用的场景。Aili博士解释说，边缘数据中心主要考虑单个卫星或者较小的一个卫星群，例如提供遥感或成像服务。为了对它们进行升级，加上更好的算力，比如AI加速器，可以提升这些卫星特殊的计算能力，例如图片处理，从而大大降低卫星需要传输给地面站的数据量，这会显著降低服务延迟时间，并间接减少地面数据中心需要处理的数据量。

目前，在轨边缘计算的一个代表性成功案例是**Starcloud**与**英伟达**的合作。去年11月，Starcloud成功将英伟达**H100 GPU**送入轨道。他们发射的**Starcloud-1**卫星搭载了一颗H100级别的GPU，整套算力系统只有60公斤重，大小相当于一台小型冰箱。这颗卫星的任务并不是“展示算力”，而是直接接收来自**合成孔径雷达**（SAR: Synthetic Aperture Radar，一种高分辨率雷达系统）卫星群的数据，在轨道上完成实时处理，再把结果传回地球。截至目前，它在太空中完成了几个重要的任务：
*   成功调用了谷歌的开源模型**Gemma**，并向地球发出了“Hi 地球人 你们好”的亲切问候，仿佛是一个地外智慧生命。
*   使用了**莎士比亚全集**训练由**OpenAI**创始成员**Andrej Karpathy**打造的**NanoGPT**，让模型能够以莎士比亚式的英语进行表达。
*   实时读取传感器数据，做出实时情报分析，比如瞬间识别野火热信号，并及时通知地面人员。

Starcloud-1的成功，也意味着太空中的算力第一次不再只是“辅助系统”，而开始直接参与计算本身。“在轨边缘计算”之所以成为太空数据中心建设第一条被跑通的路线，背后有着非常清晰的技术和商业逻辑。首先，在轨边缘计算的技术难度相对可控。所谓可控并不是因为“把GPU送上天”这件事很容易，而是因为它在做的，是对既有技术的延伸，而不是一次系统级的重构。

在硬件层面，这条路线并没有发明新的计算架构，使用的依然是成熟的数据中心级的AI加速器，只是把它们重新封装、适配太空环境。其次，在系统层面，在轨边缘计算不追求复杂的算力调度和多节点协同，而是一颗卫星对应一类特定任务，比如说遥感图像处理、气象灾害监测、军事侦察等等。因此它更像是一台“任务专用的算力设备”，而不是一个分布式云系统。由于这些任务本身就是高度确定，也意味着算法、算力规模、功耗、散热都可以在发射前被充分设计和验证，而不是到了轨道上才“临场发挥”。而且即便某一颗算力卫星出现问题，它的影响也是局部的、可隔离的，不会像云数据中心那样牵一发而动全身。此外，在应用层面，它的商业模式非常清晰，通过在轨计算，能够显著减少下行带宽压力，降低通信能耗和显著缩短决策延迟，为各类任务进行服务。因此这不是“未来算力”的故事，而是立刻可量化的效率和收益。

Aili博士还表示，“在轨边缘计算”更重要的意义在于，这条路线正在帮助完成一件关键的事情，那就是验证算力在太空能否长期、稳定、可靠地运行，从而为未来真正建设轨道云数据中心打下基础。这是非常重要的第一步，因为要验证几个东西，其中最重要的是GPU在太空中的算力。太空中的环境和地面上的环境很不一样，最大的不一样就是太空中有很多高能粒子，它对计算设备的影响大很多。首先他们要知道GPU能不能提供他们想看到的一个算力，然后他们也想看到这个GPU能不能承受这些粒子，能不能提供几年或者十年以上的服务。

不过，因为“在轨边缘计算”主要服务于特定任务，所以它也有非常清晰的天花板。它更适合图像识别、目标检测、事件筛选，而不是通用的大规模计算。而且从物理角度来说，因为受制于卫星体积、供电和散热，它也不可能无限堆叠GPU，更谈不上训练超大的模型。所以，“在轨边缘计算”更多的是一种对太空数据中心的验证和尝试。

而**轨道云数据中心**的目标则是更为直接、更为大胆，那就是在太空中去构建一个真正意义上的云计算基础设施。这条路线不再围绕某一类的特定任务，而是试图在轨道上形成多算力节点、高速星间通信，并受到统一调度与编排的系统，最终让太空中的算力能够像地面云一样被调用、被分配、被扩展。

目前最成体系的轨道云设想之一，就是来自于谷歌内部的**Suncatcher Project**（捕光者计划）。它的核心思路是，在轨道上部署相对固定位置的算力平台，通过持续稳定的太阳能供电，为地面的数据中心提供算力补充。在这个设想中，太空算力并不是独立运行的“外星系统”，而是被纳入现有云计算体系当中，成为地面云的一部分。它不追求全球移动覆盖，不承担用户直连通信，主要任务是为地面数据中心分担算力压力。简单来说，你可以把它理解为悬挂在太空中的超大规模算力机架。Aili博士提到，谷歌论文中几十个卫星形成一个群，不是覆盖整个地区的，而是一个群体，一直保证大概这样一个形状，其考虑是为了保证它们在太空中的某个位置能够跟地面上的数据中心实现数据通信。

在谷歌发布的该计划论文中，已经非常详细地阐述了Suncatcher系统的设定、建设方案以及进行了成本测算。从模式上来说，Suncatcher计划几乎是把地面数据中心拆成很多小单元，再将它们逐一“太空化”。它的设想是在日照更稳定的晨昏轨道里，铺开一批带太阳能阵列的卫星，每颗卫星上放上**Google TPU**（Tensor Processing Unit: 谷歌为机器学习定制的专用芯片）加速器。卫星之间用**自由空间光通信**（FSO: Free-Space Optical Communication，利用激光在自由空间中传输数据）互联，再用一套更“智能”的控制系统，让这些卫星可以在太空里“贴身飞行”，靠得很近、但不撞车。论文中还举出了一个非常具体的结构，那就是用81颗卫星形成半径1公里的集群。

在硬件方面，谷歌专门为太空数据中心研制了特别版本的TPU。通过对**Trillium TPU**做的辐射测试，实验结果显示，在等效约5年轨道任务寿命的辐射剂量下，TPU没有出现致命性失效。而在成本方面，谷歌基于**SpaceX**的发射数据做了详细的学习曲线分析，推测到2030年代中期，**LEO**（Low Earth Orbit: 低地球轨道）发射成本可能可以降至小于200美元/公斤的量级。而如果**星舰**实现了重复使用，发射成本甚至有望降至每公斤60美元，甚至15美元。那么按照谷歌的计划，两颗原型卫星预计在2027年年初发射，届时将会测试TPU在太空中的实际运行情况，同时对光通信链路进行验证。

如果说谷歌是“从数据中心出发，把它拆成卫星编队再搬上天”，那SpaceX的路线则是刚好相反，它是“从卫星星座出发，让星座进化成算力云”。SpaceX手里有一个现实存在的规模最大的低轨星座就是**Starlink**（星链: SpaceX运营的卫星互联网星座）。截至目前，Starlink大约有9300颗活跃卫星，占所有在轨可运行卫星的大约65%。卫星之间通过激光链路高速互联，这意味着如果想要在太空里做“分布式系统”，那么SpaceX是少数真的拥有“分布式硬件底座”的公司。

SpaceX的设想是，让部分Starlink卫星逐步从“纯通信节点”演进为同时具备通信与算力能力的节点。那么这样一来，算力不再集中在少数固定平台，而是分布在整张轨道网络当中。具体该怎么去实现呢？实际上现在已经在天上的Starlink卫星不会直接变成数据中心，必须通过“改造后的新一代卫星”才能够真正承载计算任务。今天已经在轨运行的Starlink卫星核心任务只有通信，它们负责用户接入、数据中继和星间激光链路转发。这些卫星虽然具备一些算力，但是并不是为了高密度计算而设计，所以把它们直接“升级为数据中心”在工程上并不现实。

所以接下来SpaceX更可能要做的，是在后续的发射中引入一类全新的、被改造过后的“算力增强型卫星”。这些卫星在设计上会发生明显变化，包括更高的供电能力、专门为算力设计的散热结构、更强的星间通信接口等等。这些卫星的核心身份是网络中的计算节点，而不是纯通信节点。当新卫星被发射上天之后，它们会与原来的Starlink通过星间激光链路连接在一起，共同组成一个在轨的、分层式云系统。Aili博士在采访中就表示，SpaceX的这种方案跟他们的研究团队从多年前所开始思考的轨道云数据中心建设方式是不谋而合。他们提出的云数据中心框架，就是基于现有的通信卫星，例如Starlink，在此基础上加上通用服务器等设备，加大太阳能板和冷却板，并增强宽带能力，这与SpaceX的思路非常相似。

这种模式的核心特点是，它并不追求一次性就建成超大规模算力中心，而是依托现有Starlink星座，不断叠加节点能力，让轨道网络本身慢慢具备计算属性，进而形成一个覆盖全球、动态调度的分布式网络。它的优势在于演进成本更低，并且风险可控。就算某个算力节点出现问题，也不会拖垮整张通信网络。

除了在轨边缘计算和基于星座的轨道云，还有一种更加直接，也更“地面思维”的探索方向，那就是在太空中建设**集中式数据中心**。它的核心思路很简单，不把算力分散在大量卫星上，而是在太空站或者大型在轨平台当中，集中部署机柜级算力系统，就像把一座小型地面数据中心给整体搬到轨道上。目前这条路线更多停留在研究与早期工程验证的阶段，但是有一些机构和创业公司已经在布局了。在航天机构层面，包括**NASA**（美国国家航空航天局）和**欧洲航天体系**，都曾经在**国际太空站**（ISS: International Space Station）的环境当中进行过在轨计算、数据处理和边缘算力相关的实验。此外，一些探索太空商业公司也在研究在空间站嵌入数据中心的可行性，包括**Axiom Space**、**Voyager Space**等等。

这种模式的优势在于，它的结构集中、维护逻辑清晰，最接近地面数据中心的工程思维。但是代价同样明显：极高的发射和在轨建设成本、扩展性有限，以及强烈依赖在轨维护能力。Aili博士指出，集中式数据中心算力集中，机柜或芯片之间通信速度更快、延迟更低。但从运维角度看，可靠性可能较难保证。如果是分布式数据中心，一个小的卫星算力节点出现问题，还有几十个、几百个其他节点在运行；但如果是集中式大型数据中心，一旦遭受较大问题，有可能会同时影响到很多数据中心的算力。

### 工程实践的复杂度与成本挑战

到这里，我们其实已经看到了一幅相当完整的太空数据中心建设图景了。有的选择从最务实的在轨边缘计算入手，有的试图直接去构建真正的轨道云计算体系。虽然它们的路径不同、节奏不同，但是它们指向的都是同一个方向，那就是算力正在被认真地推向轨道。不过，当这些路线开始从计划图纸走向工程和现实世界，真正的考验才刚刚开始。

太空有太阳、有真空环境，似乎好像天生就适合算力，但当进入工程层面，却并没有那么简单。这是目前的一颗普通的通信卫星，你看到它左右展开的两个“大翅膀”就是太阳能板，负责为整颗卫星提供电力，是它最主要、几乎也是唯一的能源来源。在卫星的中间，是一个相对紧凑的“盒子”，这就是卫星平台，这里面包含了姿态控制、推进系统、电源管理、热控和计算控制单元，负责让卫星在轨道上稳定运行，精确指向地面。而卫星前方或者下方这些突出的结构是通信载荷，它们负责接收来自地面的信号，进行简单处理和放大，然后再转发回地球。

传统通信卫星的设计目标非常明确：尽量少算、少热、少功耗，把复杂计算留在地面，自己只做“信号中继”。而要把算力真正地搬到卫星上，改变的就不只是“多加一块芯片”，而是会从能源、散热到结构设计，把整颗卫星的工程逻辑全部推翻重来。

首先发生变化的就是**能量系统**。为了支撑持续运行的计算单元，平均到单个卫星的太阳能板需要更大面积，电源管理系统也就必须更复杂，因为算力要的不是“平均电力”，而是稳定、持续、不掉线的功率输入。Aili博士举例说，100兆瓦的太阳能发电站在地表可能相当于200个足球场那么大，放到太空也需要几十个足球场面积。这意味着需要用更轻质、更高效的材料去折叠太阳能板，发射到太空后展开，并在运营维护时依赖自动化方式，如机器人，这与地面维护方式完全不同。

接着变化的就是卫星的“中枢”。在传统通信卫星中，中间的这个盒子主要负责控制和调度。而在算力卫星里，这里会多出真正的计算载荷，也就是AI加速器、存储模块、数据处理单元，它们将成为新的“核心器官”。随之而来的，是**散热结构**的变化。通信载荷产生的热量有限，但是算力载荷会持续发热，这意味着卫星外部必须增加专门的辐射散热板，把热量稳定地送向深空。而这些变化会让卫星重量和结构重心发生改变，进而也对发射能力和星座部署节奏提出了全新的要求。

即便技术上可行，太空数据中心依然要面对一个更加现实的问题，那就是工程实现的复杂度以及建设成本是否可以承受。在地面，数据中心的建设流程高度成熟，设计、施工、通电，每一步都有标准化路径。但在太空，工程流程被迫拉长成一条复杂的链条，从系统级设计到模块化制造，然后进行多次发射、在轨展开、联调运行，接着还有运行维护、退役处置。任何一个环节，都可能决定前面所有投入是否“作废”，这就让工程本身就必须极度保守。

我们在上一期数据中心建设成本的视频中就分析过，目前要建设1GW的地面数据中心大约需要516亿美元。但要建设太空数据中心呢？目前太空数据中心的成本结构主要包括了：
*   **能源系统**：空间太阳能阵列。
*   **散热系统**：超大面积辐射散热器。
*   **算力与航天级系统封装**。
*   **发射和在轨组装**。

其中，光发射和在轨组装成本这一项，就几乎要追上地面数据中心了。因为为了“能被送上去”，算力、能源、散热系统都必须被拆分、减重、重新封装，这不仅会提高单瓦算力的制造成本，一旦规模上升到百兆瓦、吉瓦级，发射次数就会变成一个不可忽视的成本乘数。根据**NASA**和**JPL**（美国国家航空航天局喷气推进实验室）等机构的测算，要在太空中实现1GW级持续功率的在轨能源系统，大约需要数百万平方米级的太阳能阵列，这就意味着系统总质量甚至会达到上万吨级。而即便是按照**SpaceX Falcon 9**（猎鹰9号: SpaceX研发的可重复使用运载火箭）最低的内部发射成本，大约1500万–2800万美元/公斤来计算，这一部分的整体投入就已经达到了200-300亿美元。

此外，地面数据中心可以容忍一定比例的故障，因为硬件可以随时更换。但是太空数据中心就不行，算力系统必须在多年无人维护的条件下稳定运行。这也意味着更高规模的元器件、更严格的测试周期和更慢的技术迭代节奏。最终的结果是每一瓦算力都要承担更高的“生存成本”。所以当把所有环节纳入，哪怕是非常保守的估算，现在1GW的太空数据中心的建设成本都可能上探到千亿美元。

不过，Ethan Xu也表示，虽然现在去建太空数据中心还非常贵，但是，在发射成本大幅度下降的前提下，由于能源方面的成本几乎为零，未来太空数据中心也可能在整体的生命周期成本上要优于地面系统。他认为，太空数据中心从经济上来讲，基本上是想用未来可能几十年的特别低的运行成本上的优势，去弥补自己前期投入成本上的劣势。如果前期投入成本还能不断地降低，同时未来长期的几十年运行成本还能不断地降低，那么这样总体算起来，太空数据中心很有可能在未来几年会实现成本上的接近，甚至比地面的数据中心的成本还要低。

### 轨道治理与算力边界的拓展

即便技术和成本上可行，太空数据中心还面对着一个非常重要的挑战，那就是**监管**。无论我们采用哪种形态来建设太空数据中心，本质上都会带来数量级增加的在轨设备。也就是说，为了实现数据中心级的算力，卫星群甚至会把地球给包围起来。而在近地轨道已经日益拥挤的情况下，这也带来了整个轨道的系统性问题。

首先是**轨道拥挤**。算力卫星往往更重、寿命更长、运行状态更复杂。当不同国家、不同公司、不同类型的卫星同时在同一轨道层运行，协调难度会被成倍放大。另外是**碰撞风险与太空垃圾问题**。一旦高功耗算力卫星发生失效，如果不能被及时、可控地离轨，就可能成为长期存在的碎片源。而碎片一旦产生，就会在轨道上以极高速度传播风险，影响的不只是单个的项目，而是整个轨道环境的长期安全。这也意味着，太空数据中心的推进不仅需要技术和资本，还需要一套新的**轨道治理**方式、更严格的离轨和退役标准，以及跨国、跨运营方的长期协作。

那么我们了解了太空数据中心所面临的一系列技术、成本，还有监管挑战之后，有一个判断就变得更加清晰了，那就是太空数据中心从一开始就不是一条会“短期见效”的路线。从整个算力体系的角度来看，未来太空数据中心更可能扮演的角色并不是地面数据中心的替代者，而是一个补充性的存在。至少在可预见的未来，地面数据中心依然具备无可替代的优势：成本更低、部署更快、维护更灵活、生态也更成熟。对绝大多数通用计算任务来说，把算力放在地面依然是最经济、最高效的选择。

而太空数据中心的建设意义，不在于“今天更便宜”，而在于它提供了一条不再完全受地面物理条件约束的算力增长路径。当算力规模持续膨胀，地面数据中心开始越来越多地受到能源供给、散热能力、用水压力、土地资源等约束的时候，太空所提供的是一种长期可行的备选方案。因此，即便太空数据中心真正开始建设，更现实、也更可能出现的形态并不是“算力整体上天”，而是地面与太空并存的**混合算力体系**。地面数据中心继续承担主体算力、核心存储和高频交互任务，而太空数据中心则在特定场景中发挥作用。

Ethan Xu表示，太空数据中心在某些场景下应该是非常可行的。例如，AI训练过程需要大量能量，但其客户主要是公司内部科研人员而非普通消费者。因此，可以将AI训练这样能量消耗特别大、对延迟要求不高、同时对可靠性要求也不是那么高的算力需求放到太空当中去进行。此外，随着太空科技的发展，很多在太空中采集的数据也需要在太空中计算，所以太空数据中心可以作为一种边缘数据中心的方式去存在。

如果说地面数据中心定义了过去二十年算力增长的方式，那么太空数据中心更像是在为下一个算力时代提前去铺设一条尚未启动的基础设施。今天的它仍然昂贵、复杂、充满争议，距离规模化还有很长的路要走。但是它所回应的，是一个越来越现实的问题：当算力需求继续膨胀，地面世界是否还能够无限承载呢？也许在短期内，太空数据中心不会成为主角，但是它正在提醒着我们，当人类开始认真讨论把“云”送上轨道，那么这意味着算力已经被当成一种需要跨越行星尺度来思考的基础资源了。太空数据中心的意义，或许不只是它什么时候能够落地，而是在于它也让我们意识到，人类计算的边界如今已经不再止于地球了。