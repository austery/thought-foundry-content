---
author: Dwarkesh Patel
date: '2024-04-18'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=bc6uFV9CJGg
speaker: Dwarkesh Patel
tags:
  - llm
  - open-source-ai
  - ai-infrastructure
  - metaverse
  - agi
  - ai-safety
title: Mark Zuckerberg 谈 Llama 3、百亿模型、奥古斯都与千兆瓦数据中心
summary: Mark Zuckerberg 在播客中探讨了 Meta AI 的最新进展，包括 Llama 3 模型的发布及其在 Meta AI 助手中的应用。他分享了 Meta 在 AI 基础设施上的巨额投资，以及对未来 AI 发展、AGI 路径、开放源代码策略的看法。Zuckerberg 还讨论了 AI 带来的社会影响，包括潜在风险与缓解措施，并将其与互联网和计算的诞生相提并论，强调了 AI 作为基础性技术的变革潜力。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-work
project:
  - ai-impact-analysis
people:
  - Mark Zuckerberg
  - Dwarkesh Patel
  - Ben Horowitz
  - Augustus
  - Picasso
companies_orgs:
  - Meta
  - Apple
  - Google
  - OpenAI
  - Microsoft Azure
  - Amazon
  - Bell Labs
  - Chan Zuckerberg Initiative
products_models:
  - Llama-3
  - Meta AI
  - Llama-2
  - ChatGPT
  - Reels
  - Facebook News Feed
  - Instagram Feed
  - Google+
  - Gemini
  - PyTorch
  - React
  - Open Compute Project
media_books: []
status: evergreen
---
主持人 **Dwarkesh Patel**：**Mark**，欢迎来到播客。

**Mark Zuckerberg**：谢谢邀请，我是你们播客的忠实听众。

主持人 **Dwarkesh Patel**：非常感谢你的赞美。让我们先聊聊这次采访发布时将推出的新产品。请介绍一下模型和 **Meta AI**，它们有哪些新功能和令人兴奋之处？

### Meta AI与Llama-3发布

**Mark Zuckerberg**：我认为世界上大多数人将看到的主要产品是新版 **Meta AI**。我们正在做的最重要的事情是模型升级，我们正在推出 **Llama-3**（大型语言模型系列：由 **Meta** 开发并开源）。我们以开源形式面向开发者社区发布它，并且它现在将为 **Meta AI** 提供支持。关于 **Llama-3** 还有很多细节，我相信我们稍后会深入探讨，但核心观点是，我们认为 **Meta AI** 现在是人们可以使用的最智能、免费的 AI 助手。我们还整合了 **Google** 和 **Bing** 以获取实时知识。

我们将使它在我们的应用程序中更加突出。在 **Facebook** 和 **Messenger** 的顶部，你将能够直接使用搜索框提出任何问题。我们还增加了一些非常酷的创作功能，我认为人们会喜欢。例如，动画功能就很好，你可以将任何图像进行动画处理。一个让人们觉得非常惊艳的功能是，它现在生成高质量图像的速度非常快，甚至可以在你输入时实时生成并更新图像。当你输入查询时，它会实时调整。比如，你输入“给我看一张奶牛在野外，背景有山，吃夏威夷果，喝啤酒的图片”，它会实时更新图像。这非常酷，我认为人们会喜欢。这就是世界上大多数人将看到的产品。我们正在一些国家推出，未来几周和几个月会推广到更多地方。我认为这将是一个大事件，我非常高兴能让人们体验到它。这是 **Meta AI** 的一大进步。

### Llama-3技术细节与未来展望

**Mark Zuckerberg**：如果你想深入了解技术细节，**Llama-3** 的内容显然是最具技术趣味的。我们正在训练三个版本：一个 80 亿参数模型和一个 700 亿参数模型，这两个版本我们今天发布；还有一个 4050 亿参数的密集模型，目前仍在训练中，所以今天不会发布。但我对 8B 和 70B 模型的表现感到非常兴奋，它们在其规模上处于领先地位。我们将发布一篇博客文章，包含所有基准测试结果，供大家自行查阅。显然，它是开源的，所以人们有机会使用它。

我们有一个新的发布路线图，将带来多模态、更多多语言支持以及更大的上下文窗口。希望在今年晚些时候，我们能推出 405B 模型。就目前训练阶段而言，它已经达到了约 **85 MMLU**（Massive Multitask Language Understanding: 衡量语言模型在多任务理解能力上的基准），我们预计它将在多项基准测试中取得领先。所有这些都让我非常兴奋。700 亿参数的模型也非常出色，我们今天发布它，它达到了约 **82 MMLU**，并在数学和推理方面取得了领先分数。我认为，能让人们亲身体验这些模型将是非常棒的。80 亿参数的模型几乎与我们发布的最大的 **Llama-2** 版本一样强大。所以，最小的 **Llama-3** 基本上与最大的 **Llama-2** 一样强大。

### GPU采购与战略决策

主持人 **Dwarkesh Patel**：在深入探讨这些模型之前，我想回到过去。我猜你是在 2022 年开始采购这些 **H100**（NVIDIA H100 GPU: NVIDIA 公司生产的用于高性能计算和人工智能训练的图形处理器）的，或者你可以告诉我具体时间。当时股价受到重创，人们都在问这些资本支出发生了什么，人们不买账元宇宙。你当时是如何知道需要这些 **H100** 的？你如何知道你需要这些 **GPU**（Graphics Processing Unit: 图形处理器，常用于并行计算，尤其在AI领域）？

**Mark Zuckerberg**：我认为那是因为我们当时正在开发 **Reels**。我们总是希望有足够的容量来构建一些我们尚未完全预见的东西。我们在 **Reels** 项目中遇到了需要更多 **GPU** 来训练模型的情况。这对我们的服务来说是一个巨大的演变。我们不再仅仅是根据你关注的人或页面来推荐内容，而是大力推动开始推荐我们称之为“非关联内容”——即来自你未关注的人或页面的内容。

我们可能向你展示的内容候选库从数千个扩展到数亿个，这需要一个完全不同的基础设施。我们开始着手做这件事，但在基础设施方面受到了限制，无法像我们希望的那样快速追赶 **TikTok**。我当时看到这种情况，就想：“嘿，我们必须确保再也不会陷入这种境地。”所以，我们订购了足够的 **GPU** 来满足 **Reels**、内容排名和信息流的需求，但我们还将其数量翻倍。我们的常规原则是，总会有一些我们尚未预见到的东西出现在地平线上。

主持人 **Dwarkesh Patel**：你当时知道会是 AI 吗？

**Mark Zuckerberg**：我们认为它会与训练大型模型有关。当时我以为可能与内容有关。这只是运营公司的一种模式匹配，总会有新的事物出现。那时我全身心投入到让 **Reels** 和其他内容的推荐系统正常运行。现在，能够向人们展示他们未关注但感兴趣的内容，这对 **Instagram** 和 **Facebook** 来说是一个巨大的突破。回想起来，那是一个非常好的决定。它源于我们当时的落后。并不是说“哦，我当时多么超前”。实际上，我们做出的一些最终看起来不错的决定，大多是因为我们之前犯了错误，只是不想重蹈覆辙。

### Facebook的早期选择与个人信念

主持人 **Dwarkesh Patel**：这完全是题外话，但既然谈到这里，我想问一下。我们稍后会回到 AI。2006 年你没有以 10 亿美元的价格出售公司，但想必当时有一个你会出售的价格，对吗？你当时心里有没有想过：“我认为 **Facebook** 当时的实际估值是这个，而他们并没有给出正确的估值”？如果他们给你 5 万亿美元，你当然会卖。那么你是如何考虑这个选择的？

**Mark Zuckerberg**：我认为有些事情纯粹是个人选择。我不知道当时我是否有足够的经验进行那样的分析。我身边所有的人都在为 10 亿美元的估值争论，比如“这是我们需要赚取的收入，这是我们需要达到的规模。这显然是很多年以后的事情了。”那远远超出了我们当时的现状。我当时并没有足够的金融知识来真正参与那样的辩论。

我内心深处相信我们正在做的事情。我做了一些分析，比如“如果我不做这个，我会做什么？嗯，我真的很喜欢建造东西，我喜欢帮助人们交流。我喜欢了解人们之间发生了什么以及他们之间的动态。所以我想，如果我卖掉这家公司，我只会去创办另一家类似的公司，而我挺喜欢我现在拥有的这家。所以为什么要卖呢？”我认为人们做出的许多最大胆的决定，往往只是基于信念和价值观。实际上，试图通过分析来预测未来通常是非常困难的。

### Meta AI的演进与AGI的追求

主持人 **Dwarkesh Patel**：你们的 **Facebook AI Research**（FAIR: Facebook 人工智能研究院，Meta 旗下的人工智能研究部门）已经存在很长时间了。现在它似乎成为了你公司的核心。在什么时刻，实现 **AGI**（Artificial General Intelligence: 人工通用智能，指能够理解、学习或执行任何人类智力任务的 AI）——或者无论你如何定义这个使命——成为了 **Meta** 工作的关键优先事项？

**Mark Zuckerberg**：这已经是一件大事有一段时间了。我们大约在 10 年前成立了 **FAIR**。当时的设想是，在通往通用智能的道路上，无论你称之为**什么**，都会有各种不同的创新，这将改善我们所做的一切。所以我们并没有把它构想成一个产品，它更像是一个研究小组。在过去的 10 年里，它创造了许多不同的东西，改进了我们所有的产品。它推动了该领域的发展，也让该领域的其他人能够创造出改进我们产品的东西。我认为这非常棒。

过去几年，随着 **ChatGPT**（大型语言模型：由 OpenAI 开发的对话式 AI）和围绕图像创作的扩散模型（Diffusion Models: 一种生成模型，通过逐步去除噪声来生成图像）的出现，显然发生了巨大的变化。这些都是非常惊人的东西，它们将非常明显地影响人们与所有应用程序的互动方式。在那时，我们成立了第二个小组，即 **Gen AI**（Generative AI: 生成式人工智能）小组，目标是将这些技术引入我们的产品，并构建领先的基础模型，为所有这些不同的产品提供支持。

当我们开始这样做时，最初的理论是，我们所做的很多事情都是社交性的。它帮助人们与创作者互动，帮助人们与企业互动，帮助企业销售产品或提供客户支持。还有基本的助手功能，无论是针对我们的应用程序还是智能眼镜或 **VR**（Virtual Reality: 虚拟现实）。所以，最初并不完全清楚你是否需要完整的 **AGI** 才能支持这些用例。但在所有这些微妙的方式中，通过对它们的研究，我认为实际上已经变得清楚，你确实需要。例如，当我们开发 **Llama-2** 时，我们没有优先考虑编程，因为人们不会在 **WhatsApp** 中向 **Meta AI** 提出很多编程问题。

主持人 **Dwarkesh Patel**：现在他们会了，对吗？

**Mark Zuckerberg**：我不知道。我不确定 **WhatsApp**、**Facebook** 或 **Instagram** 是否是人们会提出大量编程问题的用户界面。也许我们正在推出的网站 **meta.ai** 会是。但过去 18 个月的一个有点令人惊讶的结果是，编程对许多领域都很重要，不仅仅是编程本身。即使人们不问编程问题，用编程训练模型也能帮助它们在回答问题时变得更严谨，并帮助它们在许多不同类型的领域进行推理。这是一个例子，在 **Llama-3** 中，我们非常注重用大量编程来训练它，因为即使人们主要不问编程问题，这也会让它在所有这些方面表现得更好。

推理是另一个例子。也许你想与一位创作者聊天，或者你是一家企业，正试图与客户互动。这种互动不仅仅是“好的，对方给你发了一条消息，你只需要回复”。它是一个多步骤的互动，你试图思考“我如何实现对方的目标？”很多时候，当客户来访时，他们不一定确切知道自己想要什么，或者如何提出问题。所以，AI 的工作不仅仅是回应问题。你需要更全面地思考它。它真的变成了一个推理问题。所以，如果其他人解决了推理问题，或者在推理方面取得了很好的进展，而我们却只是一个基本的聊天机器人，那么我们的产品与其他人正在构建的产品相比就会显得逊色。归根结底，我们基本上意识到我们必须解决通用智能问题，所以我们提高了赌注和投资，以确保我们能够做到这一点。

### AI对人类生产力的影响与多模态发展

主持人 **Dwarkesh Patel**：那么，能够解决用户所有这些用例的 **Llama** 版本，会强大到足以取代这座大楼里的程序员吗？

**Mark Zuckerberg**：我只是认为所有这些事情都会随着时间的推移而逐步发展。

主持人 **Dwarkesh Patel**：但是最终呢？比如 **Llama-10**？

**Mark Zuckerberg**：我认为这个问题包含了很多假设。我不确定我们是在取代人类，还是在为人类提供工具来做更多事情。

主持人 **Dwarkesh Patel**：那么，**Llama-10** 之后，这座大楼里的程序员生产力会提高 10 倍吗？

**Mark Zuckerberg**：我希望会更高。我不认为人类存在一个单一的智能阈值，因为人们拥有不同的技能。我认为在某个时候，AI 可能会在大多数这些方面超越人类，这取决于模型的强大程度。但我认为这是一个渐进的过程，我不认为 **AGI** 是一个单一的概念。你基本上是在增加不同的能力。多模态是我们现在关注的一个关键点，最初是照片、图像和文本，但最终会扩展到视频。因为我们非常关注元宇宙，所以 3D 类型的东西也很重要。我非常关注的一种模态，但似乎业内其他人关注较少的是情感理解。人类大脑的很大一部分都致力于理解人、理解表情和情感。我认为这本身就是一个完整的模态，对吧？你可能会说它只是视频或图像，但它显然是这两者的一个非常专业的版本。

所以，除了在推理和记忆方面取得巨大进步之外，你还希望训练模型专注于所有这些不同的能力，记忆本身就是一个完整的领域。我不认为未来我们会主要将事物塞进查询上下文窗口来提出更复杂的问题。将会出现不同的记忆存储或更个性化的定制模型。这些都只是不同的能力。显然，还有让它们变大变小的问题。我们两者都关心。如果你运行像 **Meta AI** 这样的东西，那主要是基于服务器的。我们也希望它能在智能眼镜上运行，而智能眼镜内部空间有限。所以你需要一个非常高效的模型。

### AI在工业规模应用与未来数据中心

主持人 **Dwarkesh Patel**：如果你正在进行价值数百亿甚至最终数千亿美元的推理，如果以工业规模使用智能，其用例是什么？是模拟吗？是元宇宙中的 AI 吗？我们将用数据中心做什么？

**Mark Zuckerberg**：我们的赌注是，它将彻底改变所有产品。我认为将出现一种 **Meta AI** 通用助手产品。我认为它将从更像聊天机器人的形式（你提问，它给出答案）转变为你给它更复杂的任务，然后它去完成这些任务。这将需要大量的推理，也需要其他方式的大量计算。

然后，我认为与其他人（无论是企业还是创作者）的代理互动将成为我们工作的重要组成部分。我对此理论的一个重要部分是，你不会只与一个单一的 AI 互动。每个企业都会想要一个代表其利益的 AI。他们不会希望主要通过一个会销售其竞争对手产品的 AI 来与你互动。

我认为创作者将是一个重要的群体。我们的平台上大约有 **2 亿**创作者。他们基本上都有一个共同的模式，即他们希望与社区互动，但受限于每天的时间。他们的社区通常也希望与他们互动，但他们不知道创作者的时间有限。如果你能创造出一种产品，让创作者基本上可以拥有自己的 AI，按照他们想要的方式训练它，并与他们的社区互动，我认为那将是超级强大的。所有这些都将带来大量的互动。

这些只是消费者用例。我和我的妻子运营着我们的基金会——**陈·扎克伯格倡议**（Chan Zuckerberg Initiative: 由 Mark Zuckerberg 和 Priscilla Chan 夫妇创立的慈善基金会）。我们正在科学领域做很多工作，显然有很多 AI 工作将推动科学、医疗保健和所有这些领域的发展。因此，它最终将影响产品和经济的每个领域。

### 模型演进：规模、数据与架构

主持人 **Dwarkesh Patel**：你提到了可以自动执行多步骤任务的 AI。那会是一个更大的模型吗？例如，**Llama-4** 会不会仍然有一个 70B 版本，但你只需用正确的数据训练它，它就会变得超级强大？这种演进会是什么样子？是规模的扩大吗？还是像你所说的，只是相同大小但不同的架构？

**Mark Zuckerberg**：我不知道我们是否知道答案。我认为一个似乎是模式的事情是，你有一个 **Llama** 模型，然后你围绕它构建一些其他特定于应用程序的代码。其中一些是针对用例的微调，但其中一些是，例如，**Meta AI** 如何与 **Google** 或 **Bing** 等工具协同工作以获取实时知识的逻辑。这不属于基础 **Llama** 模型的一部分。对于 **Llama-2**，我们有一些这样的功能，但它更像是手工工程。**Llama-3** 的目标之一是将更多这样的功能整合到模型本身中。对于 **Llama-3**，当我们开始进入更多这种代理（Agent）般的行为时，我认为其中一些将更多地是手工工程。我们对 **Llama-4** 的目标是将更多这样的功能整合到模型中。

在每一步，你都会对未来可能实现的功能有所了解。你开始尝试和摸索。我认为这有助于你磨练直觉，知道你希望在模型的下一个版本中训练什么。这使得它更具通用性，因为显然，对于任何你手工编码的东西，你可以解锁一些用例，但它本质上是脆弱且不通用的。

主持人 **Dwarkesh Patel**：当你提到“整合到模型本身”时，你的意思是将你想要的功能直接训练到模型中吗？你说的“整合到模型本身”是什么意思？

**Mark Zuckerberg**：对于 **Llama-2**，工具使用非常具体，而 **Llama-3** 的工具使用要好得多。我们不必手工编写所有代码来让它使用 **Google** 进行搜索，它自己就能做到。对于编程和运行代码以及类似的事情也是如此。一旦你获得了这种能力，你就能预见到接下来我们可以做什么。我们不一定要等到 **Llama-4** 出现才开始构建这些能力，所以我们可以开始围绕它进行尝试。你做大量的手工编码，这能让产品变得更好，即使只是暂时的。这有助于指明我们希望在模型的下一个版本中构建什么。

### Llama-3社区微调与小型模型潜力

主持人 **Dwarkesh Patel**：你最期待 **Llama-3** 的哪种社区微调？也许不是对你最有用的，而是你最喜欢玩的。他们用古代文献对其进行微调，然后你就可以和 **维吉尔**（Virgil: 古罗马诗人）对话之类的。你对此有什么期待？

**Mark Zuckerberg**：我认为这类事情的本质就是你会感到惊喜。任何我曾认为有价值的具体事物，我们可能都在构建。我认为你会看到精简版，你会看到更小的版本。有一点是，我认为 8B 对于很多用例来说还不够小。随着时间的推移，我很希望能有一个 10 亿到 20 亿参数的模型，甚至是一个 5 亿参数的模型，看看能用它做些什么。

如果 80 亿参数的模型几乎和最大的 **Llama-2** 模型一样强大，那么用 10 亿参数的模型应该也能做一些有趣且更快的事情。它会很适合分类，或者人们在理解用户查询意图并将其输入到最强大的模型以精确提示之前所做的许多基本事情。我认为这可能是社区可以帮助填补的一个空白。我们也在考虑自己精简一些模型，但目前 **GPU** 都忙于训练 405B 模型。

### Meta的AI基础设施与能源瓶颈

主持人 **Dwarkesh Patel**：所以你们拥有所有这些 **GPU**。我记得你说过到今年年底将达到 35 万块。

**Mark Zuckerberg**：那是整个集群。我们建立了两个，我认为是 22,000 或 24,000 个集群，这些是我们用于训练大型模型的单一集群，显然涵盖了我们所做的很多工作。我们的大部分工作都用于训练 **Reels** 模型、**Facebook News Feed** 和 **Instagram Feed**。推理对我们来说是一件大事，因为我们服务了大量用户。由于我们服务的社区规模庞大，我们所需的推理计算与训练的比例可能比大多数其他公司要高得多。

在他们之前分享给我的材料中，非常有趣的是，你们训练的数据量超过了计算最优的训练量。推理对你们和社区来说都非常重要，所以拥有这个模型并包含数万亿个 token 是有意义的。

尽管其中一个有趣之处在于，即使是 70B 模型，我们也认为它会更早达到饱和。我们用大约 15 万亿个 token 训练了它。我猜我们最初的预测是它会更趋于渐近线，但即使到最后它仍在学习。我们可能可以给它更多 token，它会变得更好一些。在某个时候，你运营一家公司，需要做这些元推理（Meta-Reasoning）问题。我是否想将我们的 **GPU** 用于进一步训练 70B 模型？我们是否想继续下去，以便我们可以开始测试 **Llama-4** 的假设？我们需要做出这个决定，我认为我们为这个 70B 版本找到了一个合理的平衡。未来还会有其他版本，例如 70B 多模态版本，将在下一阶段推出。但令人着迷的是，目前的架构可以处理如此多的数据。

主持人 **Dwarkesh Patel**：这真的很有趣。这对未来的模型意味着什么？你提到 **Llama-3 8B** 比 **Llama-2 70B** 更好。

**Mark Zuckerberg**：不，不，它几乎一样好。我不想夸大其词，它处于相似的数量级。

主持人 **Dwarkesh Patel**：那是否意味着 **Llama-4 70B** 将与 **Llama-3 405B** 一样好？未来的发展会是怎样的？

**Mark Zuckerberg**：这是个大问题，对吧？我认为没人知道。世界上最难规划的事情之一就是指数曲线。它会持续多久？我认为它很可能会继续下去。我认为值得投资数百亿甚至数千亿美元来建设基础设施，并假设如果它继续发展，你将获得一些真正令人惊叹的东西，这些东西将创造出令人惊叹的产品。我认为业内没有人能真正告诉你它肯定会以这种速度持续扩展。通常在历史上，你会在某些点遇到瓶颈。现在，在这个领域有如此多的能量投入，也许这些瓶颈会很快被打破。我认为这是一个有趣的问题。

### AI发展中的能源与监管挑战

主持人 **Dwarkesh Patel**：如果不存在这些瓶颈，世界会是怎样？假设进展以目前的速度继续，这似乎是合理的。抛开 **Llama** 模型不谈，从宏观角度看……

**Mark Zuckerberg**：嗯，会有不同的瓶颈。过去几年，我认为存在 **GPU** 生产问题。即使有钱购买 **GPU** 的公司也无法获得他们想要的数量，因为存在各种供应限制。现在我认为这种情况正在减少。所以你看到许多公司现在正在考虑投入大量资金来建设这些设施。我认为这会持续一段时间。存在一个资本问题：投入资本到什么程度就不再值得了？

我实际上认为，在我们达到那个点之前，你会遇到能源限制。我认为还没有人建造一个千兆瓦的单一训练集群。你会遇到这些在世界上发展较慢的事情。获得能源许可是一项受到严格监管的政府职能。你正在从软件领域转向能源领域，软件在某种程度上受到监管，我甚至认为它比科技界很多人感受到的监管更严格。显然，如果你创办一家小公司，感受可能会少一些。我们与不同的政府和监管机构互动，我们有很多规则需要遵守，并确保我们在世界各地做得很好。但我认为能源方面毫无疑问。如果你谈论建造大型新发电厂或大型扩建项目，然后建造穿越其他私人或公共土地的输电线路，那是一个受到严格监管的事情。你需要多年的准备时间。如果我们要建立一个大型设施，为其供电是一个非常长期的项目。我认为人们会做，但我认为这不像达到某种 AI 水平，投入大量资金，然后模型突然就会……你会在发展过程中遇到不同的瓶颈。

### Meta的资源限制与千兆瓦数据中心

主持人 **Zuckerberg**：有没有什么项目，也许是与 AI 相关，也许不是，即使像 **Meta** 这样的公司也缺乏资源去做的？如果你的研发预算或资本支出预算是现在的 10 倍，你就可以去追求它？有什么是你一直记在心里，但以 **Meta** 目前的状况，你甚至无法为此发行股票或债券？它就是比你的预算大 10 倍？

**Mark Zuckerberg**：我认为能源是一个方面。如果我们能获得能源，我们可能会建设比现在更大的集群。

主持人 **Dwarkesh Patel**：那从根本上来说，是不是资金的瓶颈？如果你有 1 万亿美元……

**Mark Zuckerberg**：我认为是时间。这取决于指数曲线能走多远。现在，很多数据中心大约是 50 兆瓦或 100 兆瓦，大的可能达到 150 兆瓦。拿一个完整的数据中心，填满所有你需要用于训练的东西，然后建造你能建造的最大集群。我认为很多公司都在做类似的事情。

但是当你开始建造一个 300 兆瓦、500 兆瓦或 1 千兆瓦的数据中心时，目前还没有人建造过一个 1 千兆瓦的数据中心。我认为这会发生，这只是时间问题，但不会是明年。其中一些事情需要数年才能建成。从这个角度来看，我认为一个千兆瓦的数据中心，其规模相当于一个有意义的核电站，而它只用于训练一个模型。

主持人 **Dwarkesh Patel**：**Amazon** 不是做过这个吗？他们有一个 950 兆瓦的……

**Mark Zuckerberg**：我不太确定他们做了什么。你得问他们。

主持人 **Dwarkesh Patel**：但它不必在同一个地方，对吧？如果分布式训练有效，那就可以分布式。

**Mark Zuckerberg**：嗯，我认为这是一个大问题，它将如何运作。未来，我们所称的这些大型模型的训练，很可能更多地是推理生成合成数据，然后将其输入模型。我不知道这个比例会是多少，但我认为生成合成数据目前更偏向于推理而不是训练。显然，如果你这样做是为了训练模型，它就是更广泛训练过程的一部分。所以，这是一个悬而未决的问题，关于这种平衡以及它将如何发展。

### 开源AI的潜力与局限性

主持人 **Dwarkesh Patel**：这是否也可能适用于 **Llama-3**，甚至 **Llama-4** 及以后的版本？也就是说，你发布了它，如果有人拥有大量的计算能力，他们就可以利用你发布的模型，不断地使其变得任意智能。比如说，某个国家，比如科威特或阿联酋，拥有大量的计算能力，他们实际上可以利用 **Llama-4** 制造出更智能的东西。

**Mark Zuckerberg**：我确实认为会有这样的动态，但我也认为模型架构存在根本性的限制。我认为我们用 **Llama-3** 架构训练的 70B 模型可以变得更好，它可以继续发展。正如我所说，我们觉得如果我们继续给它输入更多数据，或者再次轮换高价值的 token，它就会继续变得更好。我们已经看到世界各地许多不同的公司基本上都采用了 **Llama-2 70B** 模型架构，然后构建了一个新模型。但事实仍然是，当你对像 **Llama-3 70B** 或 **Llama-3 405B** 这样的模型进行代际改进时，目前还没有任何类似的东西是开源的。我认为这是一个巨大的阶跃函数。人们在此基础上能够构建的东西，我认为不能无限地发展下去。在达到下一个阶跃函数之前，可能会有一些优化。

### AI作为基础性技术：未来二十年展望

主持人 **Dwarkesh Patel**：让我们从具体的模型，甚至是你需要多年才能获得能源审批等因素中跳出来，从大局来看，未来几十年 AI 会发生什么？它感觉像元宇宙或社交媒体那样的另一种技术，还是在人类历史上根本不同的事物？

**Mark Zuckerberg**：我认为它将是相当基础性的。我认为它更像是计算本身的诞生。你会看到所有这些新的应用程序，就像当年出现万维网或移动电话一样。人们基本上重新思考了所有这些体验，因为许多以前不可能的事情变得可能了。所以，我认为这会发生，但我认为它是一个更低层次的创新。我的感觉是，它更像是人们从没有电脑到拥有电脑的过程。

很难准确地推断这会如何发展。从宇宙尺度来看，它显然会很快发生，可能在几十年内。有些人担心它会真正失控，一夜之间从某种智能变得极其智能。我只是认为存在所有这些物理限制，使得这种情况不太可能发生。我真的不认为这会发生。我认为我们会有时间适应。但它将真正改变我们的工作方式，并为人们提供所有这些创造性工具来做不同的事情。我认为它将真正使人们能够更多地做他们想做的事情。

### AI与人类智能：意识、能动性与开放性

主持人 **Dwarkesh Patel**：所以也许不是一夜之间，但你认为从宇宙尺度来看，我们可以这样看待这些里程碑吗？人类进化了，然后 AI 出现了，然后他们走向了银河系。也许需要几十年，也许需要一个世纪，但这是否就是现在历史上正在发生的大计划？

**Mark Zuckerberg**：抱歉，从哪个意义上说？

主持人 **Dwarkesh Patel**：从这个意义上说，有其他技术，比如计算机甚至火，但 AI 本身的发展与人类最初的进化一样重要。

**Mark Zuckerberg**：我认为这很棘手。人类的历史就是人们基本上认为人类的某些方面以不同的方式非常独特，然后逐渐认识到事实并非如此，但人类实际上仍然非常特殊。我们曾认为地球是宇宙的中心，但它不是，但人类仍然非常棒和独特，对吧？

我认为人们倾向于拥有的另一个偏见是，认为智能在某种程度上与生命有着根本的联系。实际上，这并不清楚。我不知道我们对意识或生命是否有足够清晰的定义来充分探究这一点。所有这些科幻小说都描绘了创造智能，它开始具有所有这些类人行为等等。目前所有这些东西的化身感觉正在朝着智能可以与意识、能动性等事物相当分离的方向发展，我认为这使得它成为一个非常有价值的工具。

显然，很难预测这些东西会随着时间的推移走向何方，这就是为什么我认为任何人都不要对他们计划如何开发它或他们计划做什么过于教条。你希望在每次发布时都审视它。我们显然非常支持开源，但我还没有承诺发布我们所做的每一件事。我基本上非常倾向于认为开源对社区有益，对我们也有益，因为我们将从创新中受益。然而，如果在某个时候，事物能力发生了质的变化，我们觉得开源它是不负责任的，那么我们就不会开源。所有这些都非常难以预测。

### 开源AI的风险与缓解策略

主持人 **Dwarkesh Patel**：有没有一种具体的质变，比如你在训练 **Llama-5** 或 **Llama-4** 时，如果你看到了，会让你觉得“你知道吗，我不确定是否要开源它”？

**Mark Zuckerberg**：抽象地回答这个问题有点困难，因为任何产品都可能表现出负面行为，只要你能缓解它，那就没问题。社交媒体有一些不好的地方，我们努力去缓解。**Llama-2** 也有一些不好的地方，我们花了很多时间确保它不会帮助人们实施暴力行为之类的。这并不意味着它是一种自主或智能的代理。这只是意味着它对世界了解很多，并且可以回答一系列我们认为不应该回答的问题。我认为问题不在于它会表现出什么行为，而在于它表现出这些行为后，我们无法缓解什么。

我认为事物好坏的方式太多了，很难在一开始就全部列举出来。看看我们在社交媒体上必须处理的问题以及不同类型的危害。我们基本上已经确定了 18 或 19 类有害行为，我们基本上已经建立了 AI 系统来识别这些行为，并尽可能确保它们不会在我们的网络上发生。随着时间的推移，我认为你也能将此分解成更多的分类。我认为这也是我们花时间研究的事情，因为我们想确保我们理解这一点。

主持人 **Dwarkesh Patel**：在我看来，那会是一个好主意。如果未来的 AI 系统没有广泛部署，每个人都无法访问它们，我会感到失望。同时，我想更好地了解缓解措施。如果缓解措施是微调，那么开放权重（Open Weights: 指模型的参数是公开的，允许任何人检查、修改和使用）的全部意义在于你可以移除微调，而微调通常是这些能力之上的表面层。如果它像在 **Slack** 上与一位生物学研究员交谈……我认为模型离这还很远。现在，它们就像 **Google** 搜索。但如果我能给它们看我的培养皿，它们能解释我的天花样本为什么没有生长以及需要改变什么，你如何缓解这种情况？因为有人可以很容易地进行微调，对吗？

**Mark Zuckerberg**：没错。我认为很多人会基本上使用现成的模型，而一些怀有恶意的人会试图去除所有不好的东西。所以我确实认为这是一个问题。另一方面，我之所以在哲学上如此支持开源，是因为我确实认为未来 AI 的集中化可能与它的广泛传播一样危险。我认为很多人都在思考“如果我们能做这些事情，让它在野外广泛可用是否不好？”我认为另一种观点是，一个机构拥有比其他所有人都强大得多的 AI，可能也是相当糟糕的。

我想到一个安全方面的类比。在许多不同的事物中存在着如此多的安全漏洞。如果你能回到一两年前，假设你只多了一两年的安全漏洞知识。你几乎可以入侵任何系统。那不是 AI。所以，相信一个非常智能的 AI 可能会识别出一些漏洞，并且基本上像一个能回到一两年前并破坏所有这些系统的人，这并非遥不可及。

那么我们社会是如何处理这个问题的呢？一个重要的部分是开源软件，它使得当软件得到改进时，它不会只停留在一家公司的产品中，而是可以广泛部署到许多不同的系统，无论是银行、医院还是政府系统。随着软件变得更加健壮（因为更多人可以看到它，更多人可以对其进行测试），这些东西的运作方式也有了标准。世界可以很快地一起升级。

### 开放AI与权力平衡

**Mark Zuckerberg**：我认为一个 AI 广泛部署的世界，以一种随着时间推移逐渐变得更健壮的方式，是一个所有不同系统都能以某种方式受到制约的世界。这对我来说比一个更集中的世界从根本上更健康。所以各方面都有风险，但我认为这是一个我很少听到人们谈论的风险。存在 AI 系统做坏事的风险。但我更担心的是一个不可信的行动者拥有超级强大的 AI，无论是敌对政府还是不可信的公司等等。我认为这可能是一个更大的风险。

主持人 **Dwarkesh Patel**：你的意思是，他们可能会推翻我们的政府，因为他们拥有一种别人没有的武器？

**Mark Zuckerberg**：或者只是造成很大的混乱。我认为直觉是，这些东西最终对经济、安全和其他方面都非常重要和有价值。如果你不信任的人或对手获得了更强大的东西，那么我认为这可能是一个问题。也许最好的缓解方法是拥有良好的开源 AI，使其成为标准，并在很多方面成为领导者。这确保了竞争环境更加公平和平衡。

主持人 **Dwarkesh Patel**：这对我来说似乎是合理的。如果这能实现，那将是我更喜欢的未来。我想从机制上理解，世界上存在开源 AI 系统如何阻止某人用他们的 AI 系统制造混乱？以某人带着生物武器的特定例子来说，是不是我们会在世界其他地方进行大量研发，以非常快的速度找出疫苗？发生了什么？

**Mark Zuckerberg**：如果你以我刚才提到的安全为例，我认为一个较弱的 AI 试图入侵一个由较强 AI 保护的系统，成功的可能性会更小。就软件安全而言——

主持人 **Dwarkesh Patel**：我们怎么知道世界上所有事情都像这样？如果生物武器不是这样呢？

**Mark Zuckerberg**：我的意思是，我不知道世界上所有事情都像那样。生物武器是那些最担心这些事情的人关注的领域之一，我认为这很有道理。有一些缓解措施。你可以尝试不将某些知识训练到模型中。有不同的方法，但在某种程度上，如果你遇到一个足够邪恶的行动者，而你没有其他 AI 可以平衡他们并理解威胁是什么，那么这可能是一个风险。这是我们需要警惕的事情之一。

### 幻觉、欺骗与现实危害

主持人 **Dwarkesh Patel**：你在部署这些系统时，有没有可能看到 **Llama-4** 训练时对你撒谎，因为它认为你没有注意到，然后你就会想“哇，这里发生了什么？”这在 **Llama-4** 这样的系统上可能不太可能，但你能想象到类似的情况，让你非常担心欺骗性以及数十亿份这样的系统在野外传播吗？

**Mark Zuckerberg**：我的意思是，现在我们看到了很多幻觉。更多的是这样。我认为这是一个有趣的问题，你如何区分幻觉和欺骗。有很多风险和需要思考的事情。至少在运营我们公司时，我试图平衡这些长期的理论风险与我实际认为今天存在的真实风险。所以当你谈到欺骗时，我最担心的是人们利用它生成错误信息，然后通过我们的网络或其他网络传播。我们打击这类有害内容的方式是建立比对抗性系统更智能的 AI 系统。

这构成了我理论的一部分。如果你看看人们通过社交网络做或试图做的不同类型的危害，有一些危害并不那么具有对抗性。例如，仇恨言论在某种意义上并不那么具有对抗性，因为人们在种族主义方面并没有变得更好。这是一个我认为 AI 在这些问题上普遍比人类更快变得更复杂的领域。我们两方面都有问题。人们会做坏事，无论是试图煽动暴力还是其他什么，但我们也有很多误报，我们基本上审查了不应该审查的内容。我认为这理所当然地让很多人感到恼火。所以我认为拥有一个在这方面越来越精确的 AI 会随着时间的推移变得更好。

但让我再举一个例子：民族国家试图干预选举。这是一个例子，他们绝对拥有尖端技术，并且每年都在进步。所以我们阻止了某种技术，他们了解了我们所做的，然后用不同的技术来对付我们。这不像一个人试图说一些刻薄的话，他们有一个目标。他们很老练。他们有很多技术。在这些情况下，我仍然认为我们的 AI 系统能够以比他们的系统更快的速度提高复杂性。这是一场军备竞赛，但我认为我们目前至少赢得了这场军备竞赛。这是我花很多时间思考的事情。

是的，无论是 **Llama-4** 还是 **Llama-6**，我们都需要思考我们正在观察的行为，而且不仅仅是我们。你之所以开源，部分原因是因为还有很多其他人也在研究这个问题。所以我们想看看其他人正在观察什么，我们正在观察什么，我们能缓解什么，然后我们会评估我们是否可以开源。在可预见的未来，我乐观地认为我们能够做到。在短期内，我不想忽视人们今天试图用模型做的实际坏事。即使它们不是生存性的，我们运营服务时也熟悉一些相当糟糕的日常危害。这实际上也是我们必须花费大量时间处理的事情。

### 合成数据与模型架构的极限

主持人 **Dwarkesh Patel**：我觉得合成数据（Synthetic Data: 人工生成的数据，用于训练模型，而非真实世界数据）这件事非常有趣。对于当前的模型来说，反复使用合成数据可能会达到一个渐近线，这很合理。但是，假设它们变得更智能，并且你使用了那些——你在论文或即将发布的博客文章中提到的——能够导向最正确思维链的技术。你认为这为什么不会导致一个循环，即模型变得更智能，产生更好的输出，然后又变得更智能，如此循环下去？当然，这不会是一夜之间发生，而可能是在数月或数年的训练中，利用更智能的模型来实现。

**Mark Zuckerberg**：我认为这在模型架构的参数范围内是可能的。只是，对于今天的 80 亿参数模型，我不认为它能达到目前最先进的、融合了新研究成果的数百亿参数模型的水平。

主持人 **Dwarkesh Patel**：但那些也会是开源的，对吗？

**Mark Zuckerberg**：嗯，是的，但要受制于我们刚才讨论过的所有问题。我们希望会是这样。但我认为，在每一点上，当你构建软件时，你可以用软件做很多事情，但在某种程度上，你会受到运行它的芯片的限制。所以总会有不同的物理限制。模型的规模将受到你能获得和用于推理的能源量的限制。我同时非常乐观地认为这些东西会继续快速改进，但也比一些人更谨慎一些。我不认为失控的情况特别可能发生。

主持人 **Dwarkesh Patel**：我认为保持开放选择是明智的。我们有很多未知。有一种情况是，保持权力平衡非常重要，这样就不会有人成为极权独裁者。还有一种情况是，你不想开源架构，因为中国可以用它来追赶美国的 AI，然后发生智能爆炸，他们就赢了。很多事情似乎都有可能。考虑到所有这些，保持开放选择似乎是合理的。

**Mark Zuckerberg**：是的。

### 元宇宙：数字临场感与技术演进

主持人 **Dwarkesh Patel**：我们来谈谈其他事情。元宇宙。你最感兴趣回到人类历史的哪个时期？从公元前 10 万年到现在，你只是想看看那时是什么样子？

**Mark Zuckerberg**：必须是过去吗？

主持人 **Dwarkesh Patel**：哦，是的，必须是过去。

**Mark Zuckerberg**：我对美国历史和古典历史很感兴趣。我也对科学史很感兴趣。我确实认为，亲眼看看并试图更多地了解一些重大进步是如何发生的会很有趣。我们所拥有的只是关于其中一些内容的有限记载。我不确定元宇宙是否能让你做到这一点，因为对于我们没有记录的事情，很难回到过去。我实际上不确定回到过去会是那么重要的事情。我认为这对于历史课之类的会很酷，但这可能不是我最兴奋的元宇宙整体用例。

最主要的是无论你身在何处，都能与人产生临场感。我认为那将是杀手级的。在我们刚才讨论的 AI 对话中，很多内容都与所有这些背后的物理限制有关。我认为技术的一个教训是，你希望尽可能将事物从物理限制领域转移到软件领域，因为软件更容易构建和演进。你可以使其更加民主化，因为不是每个人都会拥有数据中心，但很多人可以编写代码，获取开源代码并修改它。元宇宙的这个版本正在实现逼真的数字临场感。这将是一个绝对巨大的差异，这样人们就不会觉得他们需要为了很多事情而物理上在一起。现在我认为，物理上在一起可能会有一些更好的体验。这些事情不是二元的。它不会像“好的，现在你不需要再那样做了。”但总的来说，我认为它将对社交、与人建立联系、工作、行业某些部分、医疗以及许多事情都非常强大。

### 个人驱动力与开放源代码的价值

主持人 **Dwarkesh Patel**：我想回到你对话开头提到的一件事。你没有以 10 亿美元的价格出售公司。对于元宇宙，即使市场对你施压，你也知道你会做这件事。我很好奇，这种优势的来源是什么？你说“哦，价值观，我有这种直觉”，但每个人都这么说。如果你必须说一些你独有的东西，你会如何表达？你为什么对元宇宙如此确信？

**Mark Zuckerberg**：我认为这些是不同的问题。是什么驱动着我？我们已经谈论了很多主题。我只是真的很喜欢建造东西。我特别喜欢围绕人们如何交流、如何表达自己以及如何工作来建造东西。我在大学时学习了计算机科学和心理学。我认为行业中很多其他人只学习了计算机科学。所以，对我来说，它一直是这两者的交集。

它也是一种非常深层的驱动力。我不知道如何解释，但我就是觉得，如果我没有在建造新的东西，我就是在做错事。即使我们当时在为 AI 投资 1000 亿美元或为元宇宙投资巨额资金制定商业计划时，我们也有一些计划，我认为这些计划清楚地表明，如果我们的东西成功了，那将是一项很好的投资。但你无法从一开始就确定。人们与顾问或不同的人有很多争论。他们会问：“你如何能如此自信地做这件事？”嗯，我停止尝试建造新东西的那一天，我就完了。我会去其他地方建造新东西。我根本无法运营某个东西，或者在我的生活中，不去尝试建造我感兴趣的新东西。这对我来说甚至不是一个问题，即我们是否会尝试建造下一个东西。我就是无法不这样做。我不知道。

我的生活方方面面都有些这样。我们家在考艾岛建了一个牧场，我参与设计了所有这些建筑。我们开始养牛，我就想“好吧，我想养出世界上最好的牛，那么我们如何设计才能实现这个目标，并构建所有我们需要的东西来尝试做到这一点？”我不知道，这就是我。问题的另一部分是什么？

主持人 **Dwarkesh Patel**：我不确定，但我对别的事情很好奇。一个 19 岁的 **Mark** 在高中和大学读了很多古代史和经典著作。你从中吸取了什么重要的教训？不仅仅是你发现的有趣事物，而是在你 19 岁之前，你并没有阅读那么多文本，其中很多是关于经典著作的。显然，这在某种程度上很重要。

**Mark Zuckerberg**：你没有阅读那么多文本……这是个好问题。这是我发现非常引人入胜的一件事。**奥古斯都**（Augustus: 罗马帝国的第一位皇帝）成为皇帝后，他试图建立和平。当时并没有真正的和平概念。人们对和平的理解是，和平是敌人不可避免地攻击你之间的短暂间歇。所以你得到短暂的休息。他有一个愿景，将经济从雇佣兵和军事化的东西转变为一种实际的正和（Positive-Sum: 指各方利益之和大于零，即合作能带来整体收益）事物。这在当时是一个非常新颖的想法。

这确实是根本性的：人们当时能够构想的理性工作方式的界限。这适用于元宇宙和 AI。很多投资者和其他人无法理解我们为什么要开源。他们会说：“我不明白，它是开源的。那肯定只是你将东西私有化之前的临时阶段，对吧？”我认为这在科技领域是一个非常深刻的现象，它实际上创造了很多赢家。

我不想过度强调这个类比，但我确实认为，很多时候，存在一些构建事物的模型，人们常常甚至无法理解。他们无法理解那对人们来说会是一件有价值的事情，或者那会是一个合理的世界状态。我认为合理的事情比人们想象的要多。

### 开放源代码与公司战略

主持人 **Dwarkesh Patel**：这太引人入胜了。我能说说我当时在想你可能从中得到了什么吗？这可能完全不对，但我认为这只是这些人在帝国中扮演重要角色时是多么年轻。例如，**凯撒·奥古斯都**（Caesar Augustus: 罗马帝国的第一位皇帝，本名屋大维）在 19 岁时就已经成为罗马政治中最重要的人物之一。他领导战役并组建了第二次三头同盟。我想知道 19 岁的你是否在想“我能做到这一点，因为**凯撒·奥古斯都**做到了。”

**Mark Zuckerberg**：这是一个有趣的例子，无论是从很多历史还是美国历史来看。我最喜欢的一句引言是 **毕加索**（Pablo Picasso: 西班牙画家、雕塑家）说的，所有孩子都是艺术家，挑战在于长大后如何保持艺术家的本色。当你年轻的时候，更容易有狂野的想法。在你的生活中，以及你的公司或你所建立的一切中，都存在着创新者困境的各种类比。你处于职业生涯的早期阶段，所以更容易转型并接受新想法，而不会打乱对其他事物的承诺。我认为这是运营公司的一个有趣之处：你如何保持活力？

让我们回到投资者和开源。假设这个 100 亿美元的模型是完全安全的。你已经完成了这些评估，而且与本例不同的是，评估者也可以微调模型，希望未来的模型也能如此。你会开源这个 100 亿美元的模型吗？

**Mark Zuckerberg**：只要它对我们有帮助，是的。

主持人 **Dwarkesh Patel**：但它会吗？100 亿美元的研发投入，现在却开源了。

**Mark Zuckerberg**：这也是一个需要我们随着时间推移进行评估的问题。我们有很长的开源软件历史。我们通常不会开源我们的产品。我们不会将 **Instagram** 的代码开源。我们开源了很多底层基础设施。我们历史上最大的一个项目可能是我们的 **Open Compute Project**（OCP: 开放计算项目，由 Meta 发起，旨在分享数据中心硬件设计，促进开放标准），我们把所有服务器、网络交换机和数据中心的设计都开源了，结果证明这非常有帮助。尽管很多人都能设计服务器，但现在行业已经标准化了我们的设计，这意味着供应链基本上都围绕我们的设计建立起来。所以产量增加了，对每个人来说都更便宜了，这为我们节省了数十亿美元，这太棒了。

所以开源对我们有很多好处。一个好处是如果人们能更便宜地运行模型。我们将在所有这些方面花费数百亿甚至数千亿美元。所以如果我们能提高 10% 的效率，我们就能节省数十亿甚至数百亿美元。这本身就很有价值。特别是如果存在其他竞争模型，我们的东西并不是在放弃某种疯狂的优势。

主持人 **Dwarkesh Patel**：那么你的观点是训练会商品化吗？

**Mark Zuckerberg**：我认为这有很多种可能的发展方式，而这只是其中一种。“商品化”意味着它将变得非常便宜，因为有很多选择。另一个方向是质量上的改进。你提到了微调。现在，对其他主要模型进行微调的能力相当有限。有一些选择，但通常不适用于最大的模型。能够做到这一点，不同的应用程序特定功能或用例特定功能，或者将它们构建到特定的工具链中。我认为这不仅能实现更高效的开发，还能实现质量上不同的事物。

### AI生态系统与移动生态系统的教训

**Mark Zuckerberg**：这里有一个类比。我认为移动生态系统普遍存在的一个问题是，有 **Apple** 和 **Google** 这两家看门人公司，它们可以告诉你允许构建什么。这有一个经济版本，就像我们构建一些东西，然后它们就拿走你一大笔钱。但还有一个质量版本，这实际上更让我感到沮丧。有很多次我们推出或想推出功能，但 **Apple** 却说“不行，你们不能推出”。这很糟糕，对吧？所以问题是，我们是否为 AI 建立了这样一个世界？你将看到少数几家公司运行这些封闭模型，它们将控制 **API**（Application Programming Interface: 应用程序编程接口），因此能够告诉你你可以构建什么？

对我们来说，我可以肯定地说，自己构建一个模型是值得的，以确保我们不会陷入那种境地。我不想让其他任何公司告诉我们能构建什么。从开源的角度来看，我认为很多开发者也不希望那些公司告诉他们能构建什么。所以问题是，围绕它会建立起什么样的生态系统？有哪些有趣的新事物？这会多大程度地改进我们的产品？我认为在很多情况下，如果这最终像我们的数据库、缓存系统或架构一样，我们将从社区获得有价值的贡献，这将使我们的东西变得更好。我们所做的应用程序特定工作将仍然具有足够的差异化，以至于这并不重要。我们将能够做我们所做的事情。我们将受益，而且所有系统，包括我们的和社区的，都将因为开源而变得更好。

有一种情况可能不是这样。也许模型最终会更多地成为产品本身。那么，开源它就是一个更棘手的经济计算问题。那样你会将自己商品化很多。但就我目前所见，我们似乎还没有处于那个阶段。

### 模型授权与风险框架

主持人 **Dwarkesh Patel**：你期望从向云服务提供商授权你的模型中获得可观的收入吗？这样他们就必须向你支付费用才能实际提供模型服务。

**Mark Zuckerberg**：我们希望有这样的安排，但我不知道它会有多重要。这基本上就是我们 **Llama** 的许可。在很多方面，它是一个非常宽松的开源许可，只是我们对使用它的最大公司设置了限制。这就是我们设置这个限制的原因。我们并不是想阻止他们使用它。我们只是希望如果他们要拿我们构建的东西进行转售并从中赚钱，他们能来和我们谈谈。如果你是像 **Microsoft Azure** 或 **Amazon** 这样的公司，如果你要转售模型，那么我们应该有一些收入分成。所以，在你这样做之前，先来和我们谈谈。事情就是这样发展的。

所以对于 **Llama-2**，我们基本上与所有这些主要的云公司都有合作，**Llama-2** 作为托管服务在所有这些云上都可用。我猜随着我们发布越来越大的模型，这会变得越来越重要。这不是我们正在做的主要事情，但我认为如果这些公司要销售我们的模型，我们理应分享其中的一些收益。

关于其他开源危险，我认为你对权力平衡和潜在的危害（我们可以通过更好的对齐技术等消除）有真正合理的观点。我希望 **Meta** 能有一些框架。其他实验室有这样的框架，他们会说“如果我们看到这种具体情况，那么就不能开源，甚至可能不能部署。”只是把它写下来，这样公司就做好了准备，人们也有了预期等等。

**Mark Zuckerberg**：在生存风险方面，这是一个公平的观点。目前我们更关注我们今天看到的风险类型，这些更多是内容风险。我们不希望模型做那些帮助人们实施暴力或欺诈，或以不同方式伤害他人的事情。虽然谈论生存风险可能在智力上更有趣，但我实际上认为，需要更多精力去缓解的真正危害是有人拿模型去做伤害他人的事情。实际上，对于目前的模型，我猜下一代甚至再下一代，这些都是我们今天看到的更普通的危害，比如人们互相欺诈之类的。我只是不想轻视这一点。我认为我们有责任确保我们在这方面做得很好。

主持人 **Dwarkesh Patel**：**Meta** 是一家大公司。你们可以两者兼顾。

### 开源软件的深远影响与自研芯片

主持人 **Dwarkesh Patel**：就开源而言，我很好奇你是否认为开源（从 **PyTorch**、**React**、**Open Compute** 等）对世界的影响比 **Meta** 的社交媒体方面更大。我与使用这些服务的人交谈过，他们认为这很合理，因为互联网的很大一部分都运行在这些东西上。

**Mark Zuckerberg**：这是一个有趣的问题。我的意思是，几乎一半的世界人口都在使用我们的消费产品，所以很难超越这一点。但我认为开源作为一种新的构建方式确实非常强大。我的意思是，这有可能。它可能像 **贝尔实验室**（Bell Labs: 曾是美国AT&T公司下属的著名研究机构，发明了晶体管、激光器等）一样，他们当时正在研究晶体管，因为他们想实现长途电话。他们做到了，而且能够实现长途电话对他们来说确实非常有利可图。如果五年到十年后你问他们，他们发明了什么最有用的东西，他们会说“好的，我们实现了长途电话，现在所有这些人都打长途电话了。”但如果一百年后你再问，答案可能就不同了。

我认为我们正在构建的许多东西也是如此：**Reality Labs**（Meta 旗下的虚拟现实和增强现实部门），一些 AI 相关的东西，一些开源的东西。具体的产品会演变，在某种程度上会来来去去，但人类的进步会持续存在，这是我们所有人都能做到的一个很酷的部分。

主持人 **Dwarkesh Patel**：**Llama** 模型何时会在你们自己的定制芯片上进行训练？

**Mark Zuckerberg**：很快，但不是 **Llama-4**。我们采取的方法是，首先构建了可以处理我们排名和推荐类（如 **Reels**、**News Feed** 广告等）推理的定制芯片。这消耗了大量的 **GPU**。当我们能够将其转移到我们自己的芯片上时，我们现在就可以将更昂贵的 **NVIDIA GPU** 仅用于训练。在某个时候，我们希望我们自己也能拥有芯片，可以首先用于训练一些更简单的东西，然后最终训练这些真正大型的模型。与此同时，我想说这个项目进展顺利，我们正在有条不紊地推出它，并且我们有一个长期的路线图。

### 谷歌+与公司焦点

主持人 **Dwarkesh Patel**：最后一个问题。这完全出乎意料。如果你成为 **Google+** 的首席执行官，你能让它成功吗？

**Mark Zuckerberg**：**Google+**？呃。我不知道。那是一个非常困难的反事实（Counterfactual: 假设与事实相反的情况）。

主持人 **Dwarkesh Patel**：好的，那么真正的最后一个问题是：当 **Gemini**（大型语言模型：由 Google 开发的对话式 AI）发布时，办公室里有没有人说出：“**迦太基必须被摧毁**”（Carthago delenda est: 古罗马政治家加图的名言，意指必须彻底消灭敌人）？

**Mark Zuckerberg**：不，我想我们现在更温和了。这是个好问题。问题是 **Google+** 没有首席执行官。它只是公司内部的一个部门。你之前问过最稀缺的商品是什么，但你从金钱的角度问的。我实际上认为对于大多数公司，至少是这种规模的公司，最稀缺的是焦点。当你是一家初创公司时，你可能更受资本限制。你只专注于一个想法，你可能没有所有资源。在某个时候，你所做的事情的性质会跨越某个阈值。你正在构建多个东西。你在它们之间创造了更多价值，但你变得更受限于你能指导哪些事情顺利进行。

总会有一些随机的、很棒的事情在组织中发生，我甚至都不知道。那些很棒。但我认为总的来说，组织的容量很大程度上受限于首席执行官和管理团队能够监督和管理的事情。这一直是我们的重点。正如 **Ben Horowitz**（本·霍洛维茨: 硅谷著名风险投资家、作家）所说：“**保持主要事情是主要事情**”，并努力专注于你的关键优先事项。

主持人 **Dwarkesh Patel**：太棒了，**Mark**，非常精彩。

**Mark Zuckerberg**：非常感谢。这很有趣。

主持人 **Dwarkesh Patel**：是的，真的很有趣。谢谢你的邀请。

**Mark Zuckerberg**：当然。