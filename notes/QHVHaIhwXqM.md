---
author: 北美王路飞
date: '2025-12-12'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=QHVHaIhwXqM
speaker: 北美王路飞
tags:
  - linear-models
  - cognitive-bias
  - correlation-causation
  - luck-vs-skill
  - model-limitations
title: 告别线性思维的幻觉：决策者如何识别数据陷阱与认知偏差
summary: 本视频深入剖析了线性模型的局限性，揭示了混淆相关性与因果性、过度依赖“大系数”思维以及外推风险等常见认知陷阱。通过生动案例，讲解了运气与技能的辩证关系，并强调了理解模型边界、拥抱非线性思维对于做出更优决策和实现颠覆性创新的重要性。
insight: ''
draft: true
series: ''
category: psychology
area: society-systems
project:
  - systems-thinking
people:
  - Bobby
  - Mike Phelps
  - Milorad Cavic
  - Chad le Clos
  - Scott Page
  - Elena Ferrante
companies_orgs:
  - 香料运输公司
products_models:
  - linear-models
  - neural-networks
  - decision-trees
  - random-forests
media_books: []
status: evergreen
---
### 直线的诱惑与模型的开端

埃莱娜·费兰特说过一句非常有意思的话：“是的，我在撒谎，但你为什么总要逼我给出一个线性的解释呢？线性的解释几乎都是谎言。”这句话听起来像是在说文学，但如果你问一个数据科学家，他可能会告诉你，这其实在说数学。我们来聊聊直线，我们大脑是极其迷恋直线的。想象一下，你种了一棵树，如果树的生长是线性的，那么它每年都会长高一点：今年长一米，明年长一米。或者你想扩建房子，比如说你加盖100平米，房价翻了一倍，那你直接告诉你，加盖200平米，房价应该翻两倍。这种思维方式太舒服了，太符合直觉了。这是我们今天要讲的主角：**线性模型**（Linear Models）。它是所有模型中最简单、最常用，也最容易把我们骗得团团转的工具。今天呢，我们来拆解模型思维中关于线性思维这一章。这不仅是关于y等于mx加b的数学课，更是一次关于认知陷阱的探险。我想带大家看懂数据背后的3个真相：第一，为什么大数据的规律常常是错觉？第二，为什么迈克·菲尔普斯这种顶级高手的输赢，有时候真的是运气？第三，为什么那个让你看起来最聪明的优化方案，反而可能是扼杀创新的凶手？准备好了吗？我们先从这个看起来人畜无害的线开始。

### 线性模型的运作机制

让我们回到中学数学课。线性模型的核心就是一个公式：y等于mx加b。在这里呢，y是我们要预测的结果，x是影响它的变量，**斜率**（m）是变化率，**截距**（b）是基准值。书里给了一个非常接地气的例子：假设我们找来一群成年人，年龄从20岁到60岁，统计他们每周步行的距离。把这些数据扔进计算机，跑一个**线性回归**（Linear Regression），我们得到这样一个方程：“每人每周的英里数等于-0.1乘以年龄加上12”。看这个-0.1，在模型思维里，我们关注三个东西：符号、量级和显著性。这个符号显然是负的，意味着年龄越大，走的越少。量级是0.1，意味着你每老一岁，每周就会少走0.1英里。根据这个公式，如果一个人40岁，我们预测他每周走了8英里；如果是50岁，就只剩7英里了。这看起来天衣无缝，对吧？我们可以用它来预测犯罪率、预测洗衣机销量，甚至预测葡萄酒的价格。但是现实世界总会给你一记耳光。在书中举了一个例子，叫做Bobby，他今年40岁，按照我们的模型，他应该走8英里，但数据显示，他实际上走了10英里。他“背叛”了我们的模型。为什么呢？是因为模型算错了吗？不是，是因为现实太复杂了。为让等式成立，我们必须在公式里加一个尾巴：**误差项**（Error Term）。Bob为什么走得多？也许因为他是一位植物学教授，也许他经常带学生们去野外徒步。我们的模型里只有年龄这一个变量，我们漏掉了职业这个变量。这是线性模型的第一个教训：现实世界充满了被你忽略的变量。数据永远不会完美的落在直线上。那些偏离直线的距离，可能来自于测量误差（比如说没带手机），可能来自于环境噪音，也可能来自于我们未知的世界。

### 模型的力量与潜在的陷阱

既然模型有误差，那它还有用吗？当然了，模型的真正威力不在于画图，而是在于指导行动。书里提到了一个香料运输公司，这家公司有上百种香料，员工们负责把它们打包发货。老板想知道员工的熟练度，也就是工作年限，到底对效率有多大影响。于是他跑了一个回归分析，结果出来了：“订单数等于200加上20乘以一个工作年限”。注意这里的系数啊，20，它背后带了两个星号，在统计学中呢，这叫做**显著性**（Significance）。这个星号就像一个可信度置疑，它对应的**p值**（p-value）如果小于1%，通常写作p<0.01。意思就是说啊，如果这两个变量之间没有关系，纯属巧合，导致这种数据的概率呢，还不到1%。换句话说啊，我们非常有把握地说，这个系数是正的。有了这个模型呢，老板就不只是在看报表了，他可以预测明年的产能，可以制定KPI。这就是模型的力量，它把模糊的经验变成了可执行的数字。但是这里有一个巨大的缺陷：当你手里拿着一把锤子（线性回归），你看什么都像钉子。这就引出了今天一个危险的概念：**数据挖掘**（Data Mining）。如果我告诉你，数据分析发现维生素D水平越高的人，身体越健康。作为一个线性思维者，你第一反应是什么呢？赶紧去吃维生素D片啊！这就是把**相关性**（Correlation）当成**因果性**（Causation）。事实是什么呢？人们可能通过晒太阳吸收维生素D，而那些维生素D高的人，往往是经常在户外活动的人，他们生活方式更健康，所以身体更好。户外活动，才是那个藏在背后的真凶——**隐变量**（Latent Variable / Confounding Variable）。维生素D只是一个伴随现象。书里头还有一个更离谱的例子：如果有研究发现，一所学校的马术队的规模越大，学生的学术成绩也就越好。你会建议校长赶紧去买马吗？当然不是了。马术队反映的是家庭收入和学校资金，这才是成绩好的原因。这叫做**伪相关**（Spurious Correlation）。如果你测试变量足够多，比如你在公司数据库里随便抓100个变量来测试，按照5%的显著性门槛，哪怕只是随机的数据，你也能大概率找到5个看似显著的相关性。你会发现，公司的名字越长，利润越高；或者是住披萨店附近的人，更容易得流感。这都是巧合，都是数据挖掘挖出来的垃圾。所以呢，Scott Page给我们的建议是：“先有逻辑，再跑回归。不要拿数据去碰运气，先建立一个合理的模型，再用数据去验证它。”

### 运气、技能与行业属性

说到运气，我们来聊聊这个世界上最迷人的线性方程。我们总被教导说啊，成功源于努力。但在模型思维中，成功有一个非常冷酷的公式，叫做成功方程：“成功 = a * 技能 + (1-a) * 运气”。这里的a呢，是一个0-1的权重。理解这个方程呢，就能解释很多让你困惑的现象。比如说迈克·菲尔普斯，历史上最伟大的游泳运动员，他的技能值绝对是满分。但在2008年奥运会100米蝶泳决赛，他其实全程落后于米卢拉德·卡维奇，在最后触壁的一瞬间，可能是因为一次划水的时机，或者水流的微小波动——也就是运气——他赢了。到2012年，同样的场景面对查德·勒克罗斯，他输了。这叫做技能的悖论，它的逻辑非常反直觉：正是因为在奥运会这种顶级赛场，大家技能差异微乎其微，大家都接近于满分，所以呢，最后决定金牌归属的，反而成了那一点点微不足道的运气。这个方程还能够救你的钱包。假设你是一个老板，你发现员工小王这个月的业绩报表拿了第一。你的线性直觉告诉你，小王很强，下个月他还会强，所以呢，你想用重金留住他。且慢，你需要先判断你的行业属性。如果你的行业是运气主导的，比如说石油开采，利润很大程度上看国际油价，而油价是公司控制不了的。那么小王这个月的好成绩，很可能只是他刚好碰上了好运气。到了下个月，运气不再爆棚，他业绩就会回归均值。所以呢，聪明董事会怎么发奖金呢？如果是在运气重的行业（比如说石油），不要因为一年的业绩好，就给CEO发巨额奖金，那可能只是他命好。相反，如果在技能重的行业（比如说广告创意或者是网球比赛），业绩好大概率是真本事，必须中奖，防止被挖墙脚。简单总结就是：为技能买单，别为运气买单。

### 超越直线：多变量与非线性模型

当然了，现实社会很少是单变量的。人的幸福感呢，取决于健康、婚姻和财富；房价取决于面积、学区和卧室数量。这就需要升级我们的武器了：使用**多变量线性回归**（Multivariate Linear Regression）。再来看一个教育学的经典案例。如果我们想预测学生的数学成绩，我们可能会使用这样一个模型：“数学成绩 = 21.2 + 9.2 * 学习时长 + 0.8 * 家庭地位 + 6.9 * 加速课程”。这个公式信息量巨大，我们来逐个拆解。第一，看学习时长系数9.2，带两个星号，意味着每多写一小时，分数预计涨9.2分，而且非常显著。第二，看加速课程，系数6.9，带上一个星号，上一门加速课，多考7分左右，也非常显著。第三，看家庭社会的经济地位，系数只有0.8，而且没有信号。这是否意味着家庭背景对于数学成绩没有影响呢？只要死读书就能够逆袭？这也要非常小心了，因为这里可能存在**选择性偏差**（Selection Bias）。也许是因为那些数学本来就很好的孩子，天赋高，才愿意花时间学习，才去报了加速班。回归模型虽然能够帮助我们理清变量之间的关系，甚至帮我们排除一些解释（比如说这里排除了家庭地位的直接线性影响），但它依旧不能够证明因果。现在，我们进入本视频最核心、也最具哲学意味的部分。当我们手握着线性模型，看到那个带着星号是最大的系数（比如说上面的学习时长），我们本能反应是什么呢？当然是加大力度了！既然学习时间系数最大，那就让学生学的更久；既然路宽和车速成正比，那就把路修得更宽。这种思维，Scott Page称之为**大系数思维**（Big Coefficient Thinking）。这听起来很理性，数据驱动决策嘛，但这也是一种诅咒。因为你过于关注那个现有的大系数，你就会陷入一种保守的、修修补补。而且呢，大数据往往会骗人，随着你不断的增加投入，效果是会递减的。路宽到一定程度，再宽也没有用了。这时候就需要另一种思维了，这种新的思维叫做**新现实思维**（New Reality Thinking）。大系数思维是在优化现状，而新现实思维是在创造未来。让我们来看几个精彩的对比：交通问题，大系数思维是看路宽的系数大，就去拓宽道路、建高承载车道；新现实思维就是引入火车、地铁或者公交系统，彻底改变出行方式。航空体验，大系数思维是调整飞机座椅的宽度；新现实思维是设计一种模块化的飞机机舱，可以随时更换的吊舱。这些都是脑洞大开的想法啊！看到区别了吧？使用线性模型、大系数，你可以获得稳健的**边际收益**（Marginal Returns），但如果你想获得颠覆性的改变，你必须跳出那条线，去寻找还没有被数据记录下来的新现实。说到这里呢，我们一直在说连续的数字，但是在大数据时代，很多时候我们要处理的是分类：谁会投票？谁会买产品？比如我们想预测谁会投票，受教育数据显示受教育程度越高、年龄越大，就越可能投票。在这种情况下，一条简单直线就能够把投票者和不投票者分的清清楚楚，这时候线性模型是完美的。但是当你作为一家航空公司，你想要找出这些常旅客，你会发现这些常旅客经常集中在中间：中年人、高收入。如果你想用一把尺子（也就是线性模型）去把这两拨人分开来，你会发现怎么切都是错的。这时候你可能需要一条曲面，一个**非线性模型**（Non-linear Models）。这也是为什么现在流行**深度学习**（Deep Learning）和**神经网络**（Neural Networks），因为它能够画出各种弯弯曲曲的线，去适应这个复杂的世界。面对这种非线性，还有一种强大的武器，叫做**决策树**（Decision Trees）。比如说预测谁会去参加科幻大会，线性模型可能会说啊，越年轻越喜欢。但决策树会设定一系列条件：条件一：年龄小于30岁，而且每周上网15-25个小时；条件二：年龄20-45岁，而且每周上网大于30小时。也去。你把成千上万棵这样的树结合在一起，就变成了**随机森林**（Random Forests）。它不再是一条简单的线，而是一个复杂的逻辑迷宫，能够补充到数据中最细微的非线性关系。当你在使用线性模型时，还告诉你一个保命的忠告：不要**过度外推**（Extrapolation）。如果，你生活在1880年到1960年的加利福尼亚，你会发现人口增长率大约是45%。但如果你在1960年做了一个线性模型，并且把它延伸到2018年，你的模型会告诉你，2018年加州会有1亿人口。但实际上2018年加州只有4,000万人口。为什么呢？因为人口增长不是线性的，它会受到资源环境的限制。同理，虽然研究说适量的喝咖啡或者红酒可能有益于心脏，但这绝不意味着你每天可以喝30杯咖啡、6杯红酒。这是一个好主意。线性模型只是在数据已知的范围内有效，一旦跨出了边界，就是未知数。

### 总结：拥抱边界与非线性思维

好，总结一下今天的内容。线性模型是我们理解这个世界的起点，它告诉我们三个关键信息：符号（正负）、量级（大小）和显著性（是否巧合）。但请记住这三个反模型的智慧：第一呢，要分清运气。在技能顶尖的领域，胜负往往看运气，别因为运气好就乱发奖金。第二，是要警惕大系数，不要为了优化眼前的大系数，而错过了创造新现实的机会。第三，是要尊敬边界，所有模型都有适用范围，不要把直线划到天边去。作者在这一章结尾说：“这只是个开始，因为现实世界中大部分有趣的现象，从传染病的爆发，到财富的复利，再到技术的基点，它都不是线性的，它们是凸的或者凹的。如果线性模型是走路，那么非线性模型就是坐火箭。”下一集，我们将进入更疯狂的非线性事件，去看看当边际效益不再递减而递增时，会发生什么恐怖或者美妙的事情。