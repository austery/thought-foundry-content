---
author: Peter Pang
date: '2026-02-25'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=M1bifAQSVcY
speaker: Peter Pang
tags:
  - ai-coding
  - web-rtc
  - software-debugging
  - browser-technology
title: 拯救社恐粉丝：AI 驱动的无成本一对一视频通话平台
summary: 本文介绍了一款由 AI 驱动的一对一视频通话平台，该平台完全基于浏览器运行，无需安装。开发者利用 AI 编写代码，并聚焦于利用 WebRTC 等原生浏览器 API 实现低成本、全平台覆盖。文章详细阐述了 AI 在软件开发，特别是复杂 bug 调试中的作用，以及未来浏览器技术在构建多样化应用中的潜力。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - OpenAI
products_models:
  - GPT-4o
media_books: []
status: evergreen
---
### 浏览器原生：全平台覆盖的视频通话新体验

今天，我非常激动地向大家发布我的第一款产品——一个独一无二的一对一视频通话平台，名为 **o to o**。这款平台完全基于浏览器运行，这意味着您无需安装任何软件。只需点击“发起通话”，然后将生成的网址发送给您想要通话的对象，双方即可在浏览器中直接进行视频聊天。您可以畅聊无阻，没有时间限制。未来，我们还将陆续增加更多新功能，例如共享屏幕、视频录制和文件分享等，敬请期待。

**o to o** 的地址已在屏幕上展示，并已发布在视频的简介和评论区。欢迎大家现在就前往试用。您可以在任何电脑或手机上的浏览器中打开它，这真正实现了全平台覆盖。之所以能做到这一点，是因为我们充分利用了原生的浏览器功能，包括最核心的 **WebRTC** 和 **WebSocket** 技术。这些具体的技术细节，我将在稍后进行更详细的分享。

### 源起社恐：AI 驱动的个性化解决方案

开发这个平台的一个初衷，是为了更好地照顾我的那些社恐粉丝。平时我在直播时会鼓励大家连麦咨询，但响应者寥寥，一问之下，大家普遍表示不好意思在众人面前说话。同时，考虑到个人隐私，我也没有添加任何粉丝的微信或电话号码，因此一直找不到一个合适的、能够进行一对一私密聊天的渠道。

“求人不如求己”，所以，我干脆就自己造了一个。当然，说是自己造，实际上全程都是 **AI** 在写代码。而我在此过程中扮演的角色，正是大家可能最讨厌的“产品经理”：负责准备好工作环境，明确工作要求，然后等待验收产品。

最终，项目的部署环境选用了某云服务商托管的 **Kubernetes** 集群、**Redis** 和 **PostgreSQL** 实例。幸运的是，以上这些都是我现有的资源，因此整个项目并没有增加多少额外成本，充分体现了“勤俭节约”的原则。

### 成本优化：WebRTC 与极简后端设计

那么有观众可能就会问了：“你这不是一个视频通话平台吗？视频通话的带宽消耗难道不算成本吗？”那这就要说到我选择的技术上了。从初始的 **prompt** 可以看到，**WebRTC** 等原生的浏览器 API 是我的核心功能。**WebRTC** (Web Real-Time Communications) 是一个在 2011 年就成为 **W3C** 标准的网页即时通讯 API，它允许两个浏览器之间进行端对端的音视频传输。在这种模式下，服务器仅需负责同步双方的基本信息。因此，我的后端只需要提供非常基础的业务 API 和用于同步的 **WebSocket** 接口。在一次视频通话中，这些接口的流量消耗最多仅几十个 KB。

这里还有一个关键的技术细节：在 **prompt** 的最后，我明确要求 AI 只提供 **STUN** server，而不提供 **TURN** server。**STUN** 服务器用于确认双方的 IP 地址，以达成端对端的通信。然而，在某些企业或校园网络环境中，直接的公网端对端通信可能被禁止。此时，**TURN** 服务器便充当了中转站，所有视频流都需经过它进行转发，这将导致我方承担全部的带宽成本。考虑到 **o to o** 的主要使用场景，我最终决定不支持企业和校园等复杂网络环境，因此选择了不提供 **TURN** 服务器。这也是为什么我说您可以想聊多久就聊多久——因为消耗的是您的流量，对我而言成本极低。

### AI 赋能：从 Prompt 到代码的开发流程

谈及成本，这个平台的开发成本也确实非常低。我之前提到花了大约十个小时，实际上大部分时间是 **AI** 在运行代码，我只是偶尔进行测试和寻找 bug。整个开发任务包含了六个对话 session。按照该模型两百 K 的窗口大小计算，我总共使用了大约一百二十万个 token。

画面上您看到的是我使用的最后一个 session。这里开头的 **prompt** 包含了从最初始 **prompt** 到前五个 session 的所有总结，它详细记录了上一个 session 中发生的所有事情，包括我提交的信息、总结出的 bug 以及最终的修复方案。

### 状态机困境：AI 深度调试的价值

可以看到，在第五个 session 中，我花费了大量时间来修复一个 bug：视频通话过程中断开重连的问题。**WebRTC** 的原理上是支持多人视频的，因此，要实现严格的一对一通话，我需要在业务逻辑中限制同时连接的人数，并实时记录参与者的进入、通话开始、断开及结束等状态。

这些状态信息不仅存储在 **WebSocket** 中，也保存在服务器端的内存里，并且我在 **Redis** 中也缓存了类似的数据。如果在状态变更时未能妥善处理这些数据的更新，就容易导致内存与缓存不同步。这有时会引发一人断线导致全员下线，或断线重连后显示已满员的错误。这再次印证了那句老话：“一切计算机问题都是状态机问题。”

因此，在第五个 session 的那一整个小时里，根据我 QA 的反馈，**AI** 不断地审查自己编写的代码，反复打补丁，包括新增中间状态、修正内存和缓存的读写顺序，以及及时清理过期的 **Redis** 数据等等。虽然最终花费了大约二十万个 token 才修好这个 bug，但综合来看，这绝对比我自己去 debug 更划算。

### 软件工程新范式：AI 的长文本调试能力

我觉得这也体现出了一个大的趋势：在那个“一句话生成一个没卵用的简单网站”的 web coding 时代过去之后，**AI** 编程若要真正进入复杂的软件工程领域，其核心能力将体现在超长任务窗口内持续进行 **debug** 的能力。因为任何稍微复杂一些的软件，都会结合前端、后端和数据端，并涉及大量复杂的业务逻辑需求，**AI** 必然无法一次性完成所有任务。我们都清楚这一点，所以我们注定要把大部分时间投入到测试和 **debug** 的循环中。

就拿我这个项目来说，初始的 **prompt** 和生成的代码总共只用了十万个 token 左右。而后续上百次对话、上百万个 token 的消耗，基本都用于 **debug**。

接下来，我还有不少想要添加的功能。仅通过浏览器原生 API 就可以实现的就有好几个：例如，通过 **RTC** Data Channel 进行端对端的文件传输；通过 **Media Devices API** 进行屏幕共享；通过 **Media Stream API** 进行视频录制；通过 **Web Audio API** 进行声音降噪；以及通过 **Web Code API** 对画面打水印等等。不得不说，浏览器本身就是一个无穷无尽的宝库。