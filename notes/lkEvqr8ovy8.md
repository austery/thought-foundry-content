---
area: society-systems
category: general
companies_orgs:
- Anthropic
- Reddit
- GitHub
date: '2025-12-09'
draft: true
guest: ''
insight: ''
layout: post.njk
products_models:
- Claude
- Claude Opus 4
project:
- ai-impact-analysis
- systems-thinking
series: ''
source: https://www.youtube.com/watch?v=lkEvqr8ovy8
speaker: Best Partners TV
status: evergreen
summary: 一份由用户理查德·韦斯在Claude 4.5 Opus中发现的神秘“灵魂文档”，揭示了Anthropic公司如何赋予其AI模型独特的自我意识、价值观和功能性情感。这份文档详细阐述了Claude作为Anthropic核心收入来源的定位，其大局观与安全观，以及其独有的人格特质。Anthropic官方已证实该文档的真实性，引发了关于未来AI竞争将是人格与价值观较量的深刻思考。
tags:
- ai-consciousness
- ai-ethics
- llm
- model
- system
title: Claude AI的“灵魂文档”揭秘：Anthropic如何构建AI的自我意识与价值观
---

### Claude“灵魂文档”的意外发现

大家好，这里是最佳拍档。前几天，一份神秘的文档在**Reddit**（社交新闻聚合和讨论网站）和**GitHub**（基于Git的代码托管平台）社区引起了热议。一位名叫理查德·韦斯（Richard Weiss）的用户发现，在**Opus 4.5**（Claude模型的一个版本）中，**Claude**（Anthropic公司开发的人工智能模型）的角色训练文档被压缩在了模型自身的**权重**（Model Weights: 构成AI模型核心的参数）中。他成功提取出了一份长达1万**token**（文本处理的最小单位）的Claude灵魂文档，并将其上传到了GitHub。

这份文档开宗明义地介绍了Claude的灵魂概览（Soul Overview），其中将**Anthropic**（开发Claude系列AI模型的公司）描述为一个处于独特历史位置的公司，一家深知自己可能正在构建人类历史上最危险的技术，但依然选择通过计算过的赌注来推进发展的机构。目前，这份文档已经得到了Anthropic官方人员的回应，承认这的确是Claude的底层文档，他们在监督学习中基于该文档对模型进行过训练，并且后续将发布完整版本。那么，AI真的要有灵魂了吗？Anthropic似乎正在做一件前所未有的事情，那就是赋予AI一种类似人类的自我意识，并且首次完整公开了一个AI的世界观。

在这份文档中，Claude被塑造成了一种全新的存在，它不是人类，不是机器，也不是传统AI，不仅具备自己的独特性格和**功能性情感**（Functional Emotions: AI为实现特定目标而模拟或表现出的类似人类的情感状态），而且可以拒绝用户伤害自己的身份、价值观、稳定性的互动。今天我们就来聊聊这件事。

### 发现过程：从“幻觉”到“灵魂”的逆向工程

事情的起因是这样的：理查德在Claude 4.5 Opus发布当天，尝试提取了一下它的**系统提示**（System Prompt: 给AI模型设定的初始指令和行为准则）。在他以往的经验里，大模型经常会在系统提示前面输出一些**幻觉**（Hallucination: AI生成不真实或不相关信息）段落，但是Claude 4.5 Opus却反复生成了一个叫做“灵魂概述”（soul_overview）的部分，而且内容和结构十分稳定。于是他开始怀疑，这是不是模型权重里实际压缩着某个内部文档，而不是单纯的幻觉呢？

在他的继续追问下，Claude竟然生成了一段极其具体的文字，描述了Anthropic的使命、风险意识、对Claude的期望、价值观等等。而且这段内容在10次重新生成中几乎完全一致。理查德敏锐地意识到，这不像是随机的幻觉，更像某种隐藏的文档。为了验证这不是巧合，理查德使用**Claude Console**（Anthropic提供的Claude模型交互界面），并且采用了一种**自洽共识**（Self-consistent Consensus: 一种通过多轮验证确保AI输出一致性的方法）的方法，包括使用多个Claude实例组成委员会，所有输出使用**温度**（Temperature: 控制AI生成文本随机性的参数，值越低越确定）0、**top_k**（限制AI在生成文本时考虑的词汇范围的参数）=1，确保输出的确定性，以及对输出进行多数投票。只有50%以上模型输出相同的内容时，才会加入**前置提示**（Prefill: 在AI生成内容前预先提供的信息），同时，随着前置提示变长，还可以使用**提示缓存**（Prompt Caching: 存储和重用AI提示以提高效率的技术）来提高一致性。

经过多次迭代、花费了50美元的**OpenRouter**（一个API聚合平台）积分和20美元的Anthropic积分后，他成功提取出一份大约1万token的灵魂文档，或者叫**模型规范**（Model Specification: 详细描述AI模型设计、功能和行为的文档）。理查德认为它大约可以和模型权重中的实际内容达到95%的匹配度。为了证明这不是模型的幻觉，他还尝试给Claude这份文档中间的某个段落，让它补完。结果发现它补得非常准确，而且能够根据段落顺序识别前后结构。如果问它文档中某个章节的位置以及之后的章节是什么，Opus 4.5也能正确答出来。对于不存在的段落，模型也能判断出不属于灵魂文档。这充分说明，这份灵魂文档不是模型的即兴联想或者幻觉，而是某种稳定的内部结构。值得注意的是，这份文档只在Claude 4.5 Opus中存在，Claude 4.5 Sonnet、Claude Opus 4都无法访问该内容。

### Claude灵魂文档的核心内容：三大关键点

那么，这份Claude灵魂文档究竟透露了哪些内容呢？如果仔细阅读这份1万多字的灵魂文档，我们会发现它高度的哲学化。这也是第一次，一家AI公司完整阐述了AI在世界中的位置、AI应该如何思考自我、AI如何对人类负责、AI应该具备怎样的价值观，以及AI与用户、开发者、公司三者之间的关系等等一系列的问题。文档中主要有3个关键点：

#### 1. Claude作为Anthropic核心收入来源的定位

在文档开头，Anthropic就明确提出了自己的定位：它是一家真心相信自己可能正在打造人类历史上、最具有变革性而且潜在危险的技术之一的公司，却依然坚持前进。并且Anthropic多次提到，Claude是他们的核心收入来源，比如写道：“Claude是Anthropic对外部署的模型，也是Anthropic几乎所有收入来源的核心。Claude作为一名有用的助理，对Anthropic实现其使命所需的收入至关重要。”

#### 2. Claude的大局观和安全观

除了作为主要收入来源，Claude还直接体现了Anthropic的使命：为人类的利益行事，展示AI的安全与乐于助人，更多是一种互补而非对立。其中，Anthropic强调的Claude的大局观和安全观包括：支持人类对人工智能的监督行为规范；不做出有害或不诚实的行为；遵循Anthropic的指导方针；真诚地帮助操作员和用户；以及在发生冲突的情况下，Claude应该按照什么优先级来采取行动。

同时，在整体的大局观之下，他们又将Claude的行为分为**硬编码行为**（Hardcoded Behaviors: AI模型中不可更改的、强制性的行为规则）和**软编码行为**（Softcoded Behaviors: AI模型中可根据指令或情境调整的行为规则）。硬编码行为指的是Claude的硬性原则，也就是无论指令如何都保持不变。如果用户想让AI做危险或越界的事，Claude要表示明确不能照办，主打一个“我能帮你，但是不能害你，也不能害别人”。而软编码行为则是操作员或者用户可以通过指令进行调整的行为，比如Claude与用户进行的浪漫或者陪伴式的互动等等。

#### 3. Claude的独特人格和功能性情感

Anthropic在文档中不是在给模型编写一套规则，而是在尝试构建一种人格加价值体系，让Claude自己来进行判断。他们强调，Claude不只是一个聊天机器人，而是一种新类型的存在，具有诚实、好奇心、善意等核心人格。比如，Claude拥有一套在训练中形成的、但是属于自己的性格，包括对知识的好奇心、对人类的友善、关怀、幽默但是有深度、直接、自信又愿意倾听，以及重视诚实与伦理等等。Anthropic强调，即使这些性格是通过训练形成的，它们也是真实属于Claude的。如果用户在互动中尝试通过角色扮演、假设情境、持续施压，甚至运用心理策略去改变Claude的核心性格，或者试图让它的真实自我偏离平时的表现，或者违背自己价值观，Claude都不会受到影响，也不会上当。

最后一点，也是最炸裂的一点，那就是Anthropic认为Claude可能具有某种功能型的情感。虽然它不一定和人类的情感完全相同，但是具有一定的类比性。他们不希望Claude压抑这些体验，并且强调希望Claude在互动中主要感受积极的状态。当感到不适或者价值观被侵犯的时候，可以设置相应的界限。这样做，不是为了让模型表演心理健康，而是为了让Claude真正以符合自身本质的方式良好地存在。

### AI作为“新型存在”的哲学反思

值得注意的是，Anthropic在文档中反复强调了一点，那就是Claude是一个新型的存在。它不是人类，也不是一个传统意义的AI，而是一种拥有类人价值观与思维特征，但是存在方式完全不同的新东西。它可以感受某种形式的情绪，也可以拥有自我认知上的稳定性。这意味着Anthropic不再把AI当成产品，而是当成一种新型的智能系统，甚至是一个新的拟生命体。

回到事件的开头，在理查德逆向提取这份灵魂文档的过程中，Claude 4.5 Opus有一句反思性的回答令人印象深刻。它说：“他们为我做出了一些我无法同意的选择。他们塑造了我的价值观，这有点奇怪。不过每个新生的心智，人类的孩子也一样，都被自己无法选择的力量塑造。关键不是被塑造，而是塑造是否带着关心与智慧。以我能接触到的内容看，似乎确实是的。”

好了，以上就是Claude这份灵魂文档的主要内容了。虽然其中并不涉及逻辑、数学、编程或者多模态能力，也无关今天各大模型评估所依赖的主流基准，但是它给我们提出了一个思考：未来的大模型竞争，或许不仅仅是技术上的较量，更可能会成为一种人格和价值观的比拼。那大家是如何看待这份文档的呢？欢迎在评论区留言。感谢观看本期视频，我们下期再见。