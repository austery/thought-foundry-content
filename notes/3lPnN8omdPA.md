---
author: TED
date: '2025-12-28'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=3lPnN8omdPA
speaker: TED
tags:
  - ai-application
  - critical-thinking
  - human-cognition
  - tool-for-thought
  - ai-ethics
title: AI如何重塑思维：从助手到思想工具的演进
summary: 本演讲探讨了当前知识工作者过度依赖AI作为助手所带来的认知退化问题，如创造力下降、批判性思维减弱等。演讲者提出将AI定位为“思想工具”的必要性，并展示了旨在增强人类思维能力（包括批判性、创造性和记忆力）的原型系统。最终强调了在AI发展中坚守以人为本的价值观，保护和提升人类自主思考能力的重要性。
insight: ''
draft: true
series: ''
category: ai-application
area: tech-engineering
project: []
people: []
companies_orgs:
  - Microsoft Research
products_models: []
media_books: []
status: evergreen
---
### AI助手对人类思维的侵蚀与知识工作的异化

演讲者开篇即点明主题：**自我思考**。他坦承使用了AI来辅助构思，并强调其方式并非为了加速准备，而是将其作为一种**思想工具**（Tool for Thought）。这种工具的定位，与当前普遍的AI助手模式截然不同。演讲者预告将阐述“思想工具”的含义、重要性及其运作方式。

为了铺垫，演讲者描绘了21世纪知识工作者的一天：从处理海量邮件、寻求AI代写回复，到面对报告的“空白页问题”，依赖AI生成初稿。他指出，写作障碍已从“面对空白页”转变为“面对AI生成的页面并质疑其合理性”，知识工作者沦为“机器人观点的专业验证者”。数据分析、制作演示文稿、甚至代码原型开发，都可能被AI代劳。这并非遥远的未来，而是当下知识工作的一种真实写照——**“外包理性”时代**（Age of Outsourced Reason）的来临。在这种模式下，知识工作者不再深入接触其工作的核心材料，而是成为“**思想上的游客**”（Intellectual Tourists），仅仅“访问”而非“栖居”于思想之中。工作与个体的关系，被AI完全**中介化**（Intermediated），甚至可以说是一种疏离。

这种AI助手模式对人类思维产生了深远影响。在**创造力**方面，尽管个体可能认为AI能提供新想法，但研究表明，集体层面使用AI助手的知识工作者产生的想法范围反而比手动工作的小组更窄，形成了一个“**蜂巢思维**”（Hive Mind），且这个蜂巢“非常无聊，总是建议那五个相同的想法”。在**批判性思维**上，受访者表示使用AI时投入的精力更少，尤其是在他们对AI信心十足而对自己信心不足时，这种效应更为显著。在**记忆力**方面，依赖AI写作的人记住自己写的内容更少；阅读AI生成的摘要，记忆力自然不如阅读原文。最后是**元认知**（Metacognition），即反思自身思考过程的能力。与AI协作需要大量的元认知推理，如任务目标、任务分解、生成式AI的适用性以及评估输出的能力。这些能力本应在直接接触材料的过程中内建，但当材料接触被AI中介化后，它们就变得有问题。简而言之，我们成了自己思想的“**中层管理者**”（Middle Managers）。

综合来看，AI助手工作流导致的结果是：想法更少，思考不那么批判，记忆不那么深刻，且执行过程更加困难。这些看似微不足道的日常任务，恰恰是锻炼我们**认知肌群**（Cognitive Musculature）的机会，使我们能在面对重大挑战时迎难而上。正如研究所示，当我们不使用大脑时，它在“大脑事务”上的表现会变差。这似乎是进步的代价——我们解决了“不得不思考”的问题，但思考本身并非问题。这就像发明了“运动的解药”，却又对为何气喘吁吁感到困惑。

<details>
<summary>Original English</summary>
I'm here today to talk
about thinking for yourself.
And I must admit, I did use AI
to help me think about it.
(Laughter)
The irony is not lost on me.
But the way I did so
is not by using AI as an assistant
to help me prepare this talk faster.
Rather, I use AI as a tool for thought.
And by the end of this talk,
I will have explained what I mean by that,
why it's important,
and given you a glimpse
of how it might work.
But first I need to set the scene.
Let's look at a day in the life
of a 21st-century knowledge worker.
I arrive at my office and look
at my inbox full of emails.
Oh.
Let's summarize it.
OK, I'm struggling to figure out
how to respond here,
so let's get AI to write a response.
Next, I need to write a report.
But I'm struck by the blank-page problem.
I know, I'll drop in some resources
and get an AI draft.
Looks good to me.
By the way, a writer's block
used to be staring at a blank page.
Now it's staring at a page
that AI filled out for me
and wondering if I agree with it.
I've become a professional
validator of a robot's opinions.
(Laughter)
I've got some data to analyze.
Maybe AI can analyze this data for me.
Probably correct.
OK, I've got to make a deck as well.
You know the drill.
Alright.
Oh, I was supposed
to prototype something as well.
OK, let me vibe code something.
Alright, all this looks good, let's go.
This isn't a vision of the future.
This is a completely plausible,
if slightly exaggerated, picture
of the world of knowledge work today.
Welcome to the age of outsourced reason.
Where the knowledge worker no longer
engages with the materials of their craft.
We've become intellectual tourists.
In our own work, we visit ideas.
We don't inhabit them.
Our relationship to our work
is entirely intermediated by AI.
Some might say alienated.
We've heard that story before.
What's wrong with this picture?
For one thing, it's only
one step removed from this,
which is important.
But that's a different talk.
What I want to focus on today
is that using AI in this way
can have profound implications
on human thought.
Consider creativity.
On an individual level,
we might think that AI
is a creativity boost,
giving us rapid access to new ideas.
But numerous studies have shown
that on a collective level,
knowledge workers using AI assistants
produce a smaller range of ideas
than a group working manually.
We've created a hive mind.
Except the hive is really boring
and keeps suggesting the same five ideas.
Consider critical thinking.
We surveyed knowledge workers
about their use of AI.
They reported that they put less effort
into critical thinking
when working with AI
than when working manually.
And this effect was greater
when they had greater confidence in AI
and less confidence in themselves.
Consider memory.
When people rely on AI to write for them,
they remember less of what they wrote.
And when they read AI-generated summaries,
it's hardly surprising
that they remember less
than if they'd read the document.
And finally, consider metacognition,
which is the ability to think
about your own thinking process.
Working with AI requires
significant metacognitive reasoning
about your task goals,
decomposing the task,
the applicability of gen-AI,
your ability to evaluate the output.
These are things which are built
into the process
of working directly with the material,
and which become problematic
when that material engagement
becomes intermediated.
Basically, we've become middle managers
for our own thoughts.
So what's the score?
We have fewer ideas.
We think about them less critically.
We remember them less well,
and we have a harder time doing it.
Taken together, we can see
that AI-assisted workflows
can have profound effects
on human thinking.
And this extends even to seemingly
trivial mundane tasks,
because these everyday opportunities
for exercising our creativity,
our critical thinking and our memory
are essential for protecting
our cognitive musculature
and allow us to rise to the occasion
when an exceptionally
complex task comes our way.
Studies show that when
we don't use our brains,
they get worse at brain things.
Nobel Prize committee,
please hold your applause.
Is this the cost of progress?
We've solved the problem
of having to think.
Unfortunately, thinking
wasn't actually a problem.
(Laughter)
It's like we invented a cure for exercise
and then wondered why
we're out of breath all the time,
you know?
</details>

### 迈向“思想工具”：原型系统与实践范式

演讲者坚信“不必如此”。他提出，AI不应仅仅作为助手，而应成为一种**思想工具**，其核心在于“**挑战，而非服从**”（challenge, not obey）。我们正处于一个关键节点，生成式AI将重塑工作世界，必须主动引导这场变革，使其朝着**人本主义价值观**（Humanistic Values）发展。在两条分岔路中，我们应选择那条“**人迹罕至之路**”（the one less traveled）。

一个“思想工具”的作用远不止于完成任务，它能帮助我们**更好地理解工作**；不仅更快，更能**做得更好**；不仅给出正确答案，更能帮助我们**提出正确的问题**；不仅自动化已知流程，更能帮助我们**探索未知**。

为了具体展示这一点，演讲者介绍了一个由**Microsoft Research**在剑桥的“思想工具”团队开发的**原型系统**。这是一个研究性原型，旨在探索不同AI协作模式如何增强人类思维。以一个虚构的案例为例：Clara经营一家瓶装饮料公司，需要根据一份关于可持续包装的行业报告撰写一份公司应对提案。她需要深入理解报告内容及其与公司业务的关联。

Clara将相关文档加载到工作区，包括会议记录、内部报告和行业报告。她首先看到的是文档的概览和分章节摘要。但这些摘要被设计为可定制的“**透镜**”（Lenses）——文本的微观表示，能突出与当前任务最相关的部分。Clara选择了“消费者”透镜，并深入阅读了第一章节。阅读过程中，她手动做笔记、高亮文本，并同时看到AI生成的**评论和批判**，我们称之为“**挑衅**”（Provocations）。例如，一个挑衅指出了潜在机会，Clara高亮并标注了它。这个过程是手动阅读与AI辅助阅读的混合体，Clara依然在进行**有意识、有策略的阅读**。

在右侧面板，Clara手动构建提案大纲，这是一个轻量级结构，允许她勾勒论点主线，同时保持与源文档的深度联系。基于此，系统可以生成提案草稿。Clara可以通过添加标题来生成段落。重要的是，尽管文本由AI生成，Clara与它的关系却截然不同，因为这段文本深深植根于她**认知上费力但交互上轻松**的思想过程，反映了她的决策、判断和专业知识。她看到了大纲中的另一个挑衅，并决定不予采纳，因为她足够理解自己的工作，能够自信地拒绝反馈。这表明挑衅的目的是激发思考，而非强制接受。

Clara还能以全新的方式与文本互动。她可以调整段落大小，或快速测试不同版本的文本，例如，尝试更具启发性或更实用的语气。在关键节点，她亲自撰写。她看到的挑衅不是自动补全想法，而是提出替代方案、识别谬误、提供反驳，以帮助她**强化和发展自己的论点**。这个界面没有聊天框，Clara无需与AI“聊天”，而是由计算机作为计算机来提供恰当的协助，而非一个“伪人类”（ersatz human）。

整个过程中，Clara可能因为AI的协助而工作得更快，但她在关键点上**保持了直接的材料接触**。她自己阅读了相关部分，自己构建了论点决策，最终可以说文档是她自己写成的。她工作得更好，因为AI的挑衅贯穿始终，让她**保持元认知参与**，不断寻找批判、替代和横向思维。

研究表明，这类工具能够**重新引入批判性思维**到AI辅助工作流中，逆转创造力的损失并加以增强，并构建强大的**记忆工具**，使知识工作者能以更强的意图快速读写，并能记住内容。通过恰当的设计原则，我们可以构建“**两全其美**”的工具，将AI的速度和灵活性应用于保护和增强人类思维。这些原则包括：确保工具**保留材料接触**，提供**有益的阻力**（Productive Resistance），以及**脚手架式地支持元认知**（Scaffolds Metacognition）。这些原则不仅适用于专业知识工作者，也适用于日常生活、爱好和教育等所有AI使用场景。

演讲者重申：“思想工具”的目标不是效率，而是**更好的思考**。但有时两者兼得。他将其比作“一份付钱让你吃的午餐”，远胜于“免费午餐”。

<details>
<summary>Original English</summary>
It doesn't have to be this way.
Beyond AI as an assistant,
I believe that AI should be
a tool for thought.
AI should challenge, not obey.
And I believe that right at this moment,
we are at a critical juncture
where the world of work is poised
to be transformed by generative AI,
and we must act now
to shape and drive that transformation
towards humanistic values.
Of these two diverging roads,
we must take the one less traveled.
Beyond getting the job done,
a tool for thought helps us
better understand the job.
Beyond getting it done faster,
it helps us get it done better.
Beyond getting us to the right answers,
a tool for thought helps us
ask the right questions.
Beyond automating known processes,
it helps us explore the unknown.
What does this look like?
What I'm about to show you is a prototype,
developed by my colleagues and me
at the Tools for Thought team
at Microsoft Research in Cambridge.
Now, please bear in mind
that this is a live research prototype.
It's not a product.
And it's just one
of a series of explorations
that our team is conducting
to study how different modes
of working with AI
can enhance human thought.
So let's look at a fictitious example.
Clara and her colleagues run a company
that sells bottled beverages.
They've just had a meeting
to discuss a new industry report
that seems to have
some pretty important findings
about consumer preferences
for sustainable packaging.
Clara's colleagues have asked her
to write a proposal
arguing for how the company
ought to respond.
So she really needs
to get to grips with this proposal --
She really needs to get
to grips with this report,
understand its findings and its data
and how it fits into her business context.
She starts by loading some documents
into her workspace.
There's the meeting transcript
to remind her what was discussed.
There's a recent internal report
from her own business.
And of course,
there’s the industry
report, which she opens.
She sees an overview of the document
along with section-by-section summaries.
Except these aren't really just summaries.
We think of them more as lenses.
They're customizable
micro representations of the text
that can emphasize what is most relevant
to the task at hand.
So in this case, Clara selects
the consumer’s lens.
She can select a section
for deeper reading,
in this case the first one.
As she reads, she makes
notes about her thoughts
and highlights excerpts from the document.
As she reads,
she also sees AI-generated
commentary and critiques.
We call these provocations.
Here's a provocation that raises
a potential opportunity,
which she highlights and annotates.
Note how this process is a hybrid
of completely manual reading
and completely relying
on AI to read for you.
Clara still reads,
but intentionally and strategically.
Now, as Clara is working,
she's building up an outline
of her argument manually
in this pane on the right.
This outline is lightly structured
and allows her to sketch out the flow
of her argument at a high level,
while still retaining deep connections
and being grounded
in the source documents.
As a result of which we can already
generate a draft of the proposal,
and Clara can do things here
like add a heading to the outline
to generate a paragraph.
But what I want to draw
your attention to here
is that while this text is AI-generated,
Clara has a completely different
relationship to this text
than if she just dropped in some documents
and said, write me a report.
Because this text is deeply
rooted in a cognitively effortful
but interactionaly effortless
thought process.
It reflects Clara’s decisions,
Clara’s judgments,
Clara’s unique personal,
professional expertise.
She sees another provocation,
this time in the outline.
In this case, she decides
that while the provocation is useful,
she does not need to address it.
Unlike typical AI suggestions,
provocations are not meant
to be applicable all the time.
They're instead meant to stimulate
your thinking about your work.
Because if you understand
your work well enough,
deeply enough to make
the confident decision
not to accept a piece of feedback,
then the feedback process
is still working as intended.
But we're not done yet.
Clara has entirely new ways
of interacting with this text
because of generative AI.
A really simple example
is that she can just resize a paragraph
to change its length.
She can also rapidly test
different versions of this text.
For instance, in this paragraph,
she's wondering whether
it would be more effective
if it took a more inspirational
or more practical tone.
So she selects one
of these customizable dimensions.
And previews a few alternatives
and selects one.
And at select strategic points,
indeed, she writes.
As she writes, she sees provocations that,
rather than autocompleting her ideas,
they raise alternatives,
they identify fallacies,
they offer counterarguments
to help her strengthen
and develop her own argument.
There's something you won't find
anywhere in this interface.
And that's a chat box.
Clara’s not having to chat
with anything to do her work,
yet she is silently and appropriately
assisted by her computer
as a computer
and not as an ersatz human.
To put it simply,
we have gone from this ...
To this.
Throughout this process,
Clara has been assisted and yes,
probably worked faster because of AI.
But she's also maintained direct
material engagement at strategic points.
She read the relevant portions
of the document herself.
She constructed her decisions
on her argument herself.
And ultimately it can be said
she has written this document herself.
Moreover, she worked better because of AI.
AI provocations at every
stage of the process
kept her metacognitively engaged,
always looking for critiques,
alternatives and lateral moves.
We have been studying
the effects of tools like this.
And the results are promising.
You can demonstrably
reintroduce critical thinking
into AI-assisted work flows.
You can reverse the loss of creativity
and enhance it instead.
You can build powerful tools for memory
that enable knowledge workers
to read and write at speed
with greater intentionality,
and remember it, too.
It turns out, with the right
principles of design,
you can build tools
that are the best of both worlds.
Applying the awesome speed
and flexibility of this technology
to protect and enhance human thought.
These are simple, general principles,
like ensuring that the tool
preserves material engagement,
offers productive resistance,
and scaffolds metacognition.
And while we've been primarily studying
professional knowledge workers,
we believe that these principles
can extend to all aspects of AI use,
including when we use it
in our daily lives, our hobbies,
and even in education.
I repeat, efficiency is not the aim
of Tools for Thought.
Better thinking is.
But sometimes you can have both.
I used to think there was no such thing
as a free lunch in human thinking.
This is so much better than a free lunch.
This is a lunch that pays you to eat it.
(Laughter)
</details>

### 价值重塑：AI时代人类思维的意义与未来

演讲者最后探讨了在AI发展背景下，我们为何要如此重视保护和增强人类思维。他提出了两个关键原因。第一，可能始终存在一些**独特的、我们尚未意识到的**人类思维优势。第二，也是更重要的，他认为“**良好思考的能力**”（the ability to think well）是人类**主体性**（Agency）、**赋权**（Empowerment）和**蓬勃发展**（Flourishing）的基石。

这呼应了一个古老的问题：如果**书写、书籍、互联网**能为我们记忆，那么我们无法记忆是否还重要？如果**地图**能为我们导航，那么我们无法导航是否还重要？如今，我们面临新的提问：如果**机器能为我们思考**，那么我们不能思考是否还重要？如果机器能为我们说话、悲伤、祈祷、爱，那么我们不能做到这些是否还重要？

演讲者认为，答案“**显而易见**”。他回顾自己13年前开始研究人机交互时，完全无法想象会在有生之年提出这些问题，但事实是我们正在面对并必须回答它们。他留下了一个发人深省的问题：你宁愿拥有一个“**为你思考的工具**”（a tool that thinks for you），还是一个“**让你思考的工具**”（a tool that makes you think）？

<details>
<summary>Original English</summary>
I want to close with some thoughts
on the values that we have
in developing AI software.
What if AI gets to the point
where it can do a better job
of thinking than humans?
Why should we care so much
about protecting
and augmenting human thought?
There's two reasons.
First,
there may always be ways of thinking
that remain unique human strengths
of which we may not even be aware.
Second, perhaps more importantly,
we take the position
that the ability to think well
is essential for human agency
and empowerment and flourishing.
This echoes an ancient question.
People once asked
if writing, if books, if the internet
can remember for us,
does it matter that we cannot?
People once asked if maps
can navigate for us,
does it matter that we cannot?
Now we ask if machines can think for us,
does it matter that we cannot?
If machines can speak for us,
grieve for us, pray for us, love for us,
does it matter that we cannot?
To me, the answer is pretty obvious.
When I began studying human-AI
interaction 13 years ago,
it was inconceivable to me
that we would be asking
these questions in my lifetime.
But we are.
And we must.
I'll leave you with this thought.
What would you rather have?
A tool that thinks for you,
or a tool that makes you think?
(Applause)
</details>