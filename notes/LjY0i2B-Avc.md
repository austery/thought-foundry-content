---
area: tech-work
category: ai-ml
companies_orgs:
- OpenAI
- Stanford
date: '2025-01-01'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- General Relativity
- Newtonian Physics
people:
- Adam Brown
- Albert Einstein
- Scott Aaronson
- Roger Penrose
products_models:
- GPT-4
- LLM
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=LjY0i2B-Avc
speaker: Dwarkesh Patel
status: evergreen
summary: 本文探讨了大型语言模型（LLM）在理解和创造科学理论（如广义相对论）方面的潜力，并将其与人类智能进行比较。文章指出AI在快速学习和处理信息方面的优势，但同时也讨论了其在概念飞跃和科学发现方面的局限性。随着AI能力的提升，评估其性能的难度也在增加。
tags:
- general-relativity
- human
- intelligence
- scientific-discovery
title: AI的未来：通往爱因斯坦之路的探索
---

也许，这些系统，包括我们所说的大型语言模型（LLM: Large Language Model，大型语言模型），最终能够做到的最后一件事，是在我们理解的上一世纪末的物理定律基础上，发明出**广义相对论**（General Relativity: 爱因斯坦提出的描述引力的理论）。我认为这可能是其能力的终点。一旦它能做到这一点，那么就人类而言，将没有太多其他事情可做了。

这非常非凡，尤其对于一个来自物理学背景的人来说，物理学领域的进步相当缓慢。但来到人工智能领域，却看到日复一日、周复一周、年复一年的惊人快速进展。从表面上看，这些大型语言模型（LLM）和人工智能系统在某种意义上只是插值器（interpolators: 在已知数据点之间估计未知值的过程）。但它们进行插值的抽象层级却不断提升。我们不断沿着这个抽象链向上攀升，从一个足够高的视角来看，**牛顿物理学**（Newtonian Physics: 描述宏观物体运动规律的经典物理学理论）的创造，可能也只是在某个宏大抽象层级上的插值。这或许能揭示**人类智能**的本质，以及大型语言模型的本质。

### AI与科学突破

如果问我还需要多少年才能做到这一点，那并不完全清楚。但某种意义上，**广义相对论**是人类有史以来最伟大的飞跃。一旦我们能做到这一点，也许在 10 年内，我们将完全理解人类智能。它会与爱因斯坦所做的一样吗？显然，人类智能与这些大型语言模型之间存在许多类比上的差异。但我认为，在正确的抽象层面上，它们可能是相同的。

你认为 AI 数学家、物理学家是否会比人类拥有优势，仅仅因为它们可以默认地以人类不擅长的方式思考“奇异的维度”（higher dimensions: 指超过三维空间或一维时间的数学概念）和流形（manifolds: 在拓扑学和几何学中，局部看起来像欧几里得空间的数学空间）？嗯，我想我们可能需要回顾一下，人类在多大程度上“原生”地思考高维空间。显然，这并非我们的自然空间。曾有一种技术被发明出来用于思考这些问题，那就是**记号**（notation: 用于表示数学概念或运算的符号系统），例如**张量记号**（tensor notation: 用于表示多线性映射的数学记号）。即使是像**爱因斯坦**（Albert Einstein: 20世纪最伟大的物理学家之一） 100 年前那样写作，这些工具也能让你自然地在不同维度之间切换。然后，你更多地是在思考如何操作这些数学对象，而不是直接在高维空间中思考。

我不认为大型语言模型在思考高维空间方面比人类更“自然”。你可以说，大型语言模型拥有数十亿个参数，这就像一个数十亿维度的空间。但你也可以对人脑说同样的话，它拥有数十亿个参数，因此也是数十亿维度的。然而，这个事实是否能转化为在高维空间中的思考，我并不认为在人类身上能看到这一点，而且我认为这也不适用于大型语言模型。

### 表征与创造力

是的，你可以想象，如果你看到了数百万个需要进行这种“奇异张量数学”（weird tensor math）的问题，那么就像人类通过训练建立更好的直觉一样，人工智能也会发生同样的事情。它会看到更多问题，并对这些“奇异几何”（weird geometries）形成更好的表征。我认为这肯定是真的，它确实看到了比我们任何人一生中能看到的更多的例子，并且可能会构建出比我们更复杂的表征。

在物理学史中，突破往往在于我们如何思考它，以及采用何种表征。有时人们开玩笑说，爱因斯坦对物理学最大的贡献是他发明的一种记号，称为**爱因斯坦求和约定**（Einstein summation convention: 一种简化张量表达式中重复指标求和的记号）。它能让你更轻松、更紧凑地表达和思考这些问题。**彭罗斯**（Roger Penrose: 英国数学家、物理学家、哲学家）的一项伟大贡献也是发明了一种新的记号，用于思考**时空**（spacetime: 物理学中将三维空间和一维时间统一起来的概念）及其运作方式，这使得某些问题变得清晰。因此，创造出正确的表征一直是物理学史上极其强大的工具，带来了许多巨大的发展，这在某种程度上类似于在更应用的科学领域中开发出新的实验技术。我们有理由希望，随着大型语言模型的进步，它们也能创造出更好的表征，至少是它们自己的更好表征，但这可能与对我们而言的“好”表征不同。

### AI的局限性与评估

这里有一个有趣的问题。显然，这些模型知道很多信息，即使是专业物理学家也能从中学习到他们不熟悉的知识。但这是否引发了一个问题：我们认为它们很聪明并且越来越聪明。如果一个相当聪明的人记住了几乎所有领域的知识，了解未解决的问题，了解其他领域的未解决问题及其潜在联系，了解潜在的差异和关联，那么你可能会期望他们能够做到——虽然不是爱因斯坦级别的概念飞跃——但至少能发现很多基本联系。例如，“镁（magnesium）与大脑中的某种现象相关，这种现象与头痛相关，因此也许镁补充剂可以治疗头痛”。这类基本联系是人类可以做到的。这是否表明，就智能而言，大型语言模型比我们预期的还要弱？考虑到它们在知识方面拥有压倒性优势，却似乎还无法将其转化为新的发现。

是的，它们肯定有人类所没有的优势和劣势。其中一个优势显而易见，那就是它们阅读的内容远超任何人类一生所能阅读的量。我认为，象棋程序的类比在这里是恰当的。它们会考虑比任何人类棋手都多的可能局面（这是一种蒙特卡洛搜索）。即使在人类水平的强度下，它们仍然进行了更多的搜索，这可能意味着它们的评估能力不如人类那样“自然”。我认为物理学也是如此。如果有一个人阅读了同样多的内容并记住了同样多的信息，你可能会期望他变得更强。

**斯科特·阿伦森**（Scott Aaronson: 美国计算机科学家）最近，或者说一两年前，曾发文提到 **GPT-4**（Generative Pre-trained Transformer 4: OpenAI开发的大型语言模型）在他教授的“计算理论”（Computing Theory）课程考试中获得了 B 或 A- 的成绩。这肯定比我当年考得好，我当时已经不及格了。嗯，你在**斯坦福大学**（Stanford University）教授包括广义相对论在内的许多课程。我猜你肯定用这些考试题来测试过这些模型，它们的表现随时间是如何变化的？是的，我拿了我在斯坦福大学研究生“生成性”（generativity）课程中几年前的考题，然后让这些模型来做。这非常惊人。三年前，它们几乎得零分。一年前，它们表现不错，可能算个“弱学生”，但在整体分布中。而现在，它们基本上能轻松通过考试。事实上，我正在退休，这只是我个人的私下评估，并未公开发表，但我只是用这个来跟踪它们的表现，而它们做得非常出色。虽然按照研究生课程的标准，它们可能显得“容易”，但在一门关于**广义相对论**的研究生课程中，它们在最近几个月内的期末考试中几乎所有题目都做对了。

要通过考试需要什么？显然，它们可能已经阅读了所有关于广义相对论的教科书。但我认为要通过考试，还需要一些更深层次的东西。你是否认为物理问题与数学问题相比，通常有两个组成部分？一是将文字问题转化为数学问题，这需要运用物理知识。二是解决数学问题。这通常是这类问题的典型结构。所以你需要能够同时做好这两点。第一步，也就是将文字问题转化为数学问题，这可能是只有大型语言模型才能做到的，并且对其他事物来说并不容易。

我认为，如果你给它们出困难的研究性问题，你肯定能找到它们无法解决的问题，这一点毋庸置疑。但值得注意的是，在我们尝试开发模型评估方法时发现，就在几年前，甚至三年前，你随便从网上找一些标准的、完全标准的**高中数学**（High School Math: 指中学阶段的数学课程）问题，它们都无法解决。而现在，我们需要聘请各领域的博士来设计问题，他们可能一天也只能想出一个好问题。随着这些大型语言模型的不断增强，评估它们性能的难度也在随之增加。