---
author: Best Partners TV
date: '2025-12-26'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=kjVE_cMaQNo
speaker: Best Partners TV
tags:
  - llm
  - reinforcement-learning
  - prompt-engineering
  - ai-agents
  - future-of-ai
title: 【人工智能】卡帕西2025AI回顾 | 六大范式革新 | RLVR推理革命 | 锯齿智能真相 | 本地Agent崛起 | 氛围编程降临 | 告别文本交互 | AI应用层重构 | 未来十年已来
summary: 本文基于安德烈·卡帕西的《2025大语言模型年度回顾》，深入解析了2025年AI领域的六大范式革新。重点包括RLVR技术如何突破模型推理瓶颈，‘锯齿状智能’揭示AI与人类智能的本质差异及对基准测试的挑战，应用层重构以Cursor为代表，本地Agent如Claude Code的崛起，以及‘氛围编程’（Vibe Coding）带来的全民编程时代和效率革命，最后预示了Nano Banana等模型引领的GUI交互新纪元。这些变化共同塑造了AI快速、矛盾而真实的成长态势，预示着一个充满颠覆性突破的未来。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project:
  - ai-impact-analysis
people:
  - Andrej Karpathy
companies_orgs:
  - OpenAI
  - DeepSeek
  - Anthropic
  - Google
  - Y Combinator
products_models:
  - GPT-4
  - o1
  - o3
  - Claude Code
  - Cursor
  - Nano Banana
  - ChatGPT
media_books:
  - 《2025大语言模型年度回顾》
status: evergreen
---
大家好，这里是最佳拍档。对于AI领域来说，**2025年绝对是值得被铭记的一年**。这一年里，大语言模型不再是一个简单的文本生成工具，而是在技术架构、应用形态、交互方式甚至智能本质上都完成了一系列的突破。12月19日，前特斯拉AI总监、**OpenAI**的早期核心成员**安德烈·卡帕西**发表了一篇名为《2025大语言模型年度回顾》的文章，以其独特的技术洞察力，总结了**六大重塑大语言模型领域的范式变化**。接下来，大飞就来为大家拆解一下这六大范式革新，看看2025年的大语言模型行业到底发生了哪些足以影响未来十年的关键转变。

在2025年之前，整个行业生产级的大语言模型训练流程已经形成了一套稳定且经过验证的标准配方。这套配方从2020年左右的预训练开始，后续叠加了2022年的**SFT**（Supervised Fine-Tuning: 通过监督学习进行微调，使用标注数据训练模型）和**RLHF**（Reinforcement Learning from Human Feedback: 从人类反馈中强化学习，通过人类评价来优化模型）两个关键阶段。在很长一段时间里，这套组合都是所有实验室训练生产级大语言模型的核心框架。但是这套框架存在着一个难以突破的瓶颈，那就是模型的推理能力始终停留在模仿人类反馈的层面，无法真正形成自主的问题拆解和逻辑推导。

因为无论是SFT还是RLHF，本质上都依赖于人类提供的标注数据或反馈信号，而人类很难清晰地定义什么是最优的推理路径，比如解一道复杂的数学题时，中间哪一步该拆分、哪一步该验证。这种隐性的推理逻辑既难以用文本标注传递给模型，也无法通过简单的点赞或者差评反馈让模型学会。

而2025年，**RLVR**（Reinforcement Learning from Verifiable Rewards: 从可验证奖励中强化学习，通过自动验证结果来优化模型）的出现，彻底打破了这个瓶颈，成为了大语言模型训练流程中不可或缺的新的核心阶段。RLVR的核心逻辑，简单来说，就是为模型构建一系列可自动验证结果的训练环境。在这些环境中，模型的每一个输出都能被系统自动判断正确与否，并且获得对应的奖励信号。这样一来，无需人类参与反馈，模型通过持续优化获取奖励的目标，就能自发形成一套解决问题的策略。这些策略在人类看来，就是推理能力的体现。

卡帕西特别提到，**DeepSeek**团队的R1论文中，就有大量的这类案例。经过RLVR训练的模型，在解高等数学题的时候，会像人类学生一样，先写出已知条件、拆分问题模块、进行中间计算验证，最后得出结论。在调试代码的时候，会逐行排查语法错误、逻辑漏洞，甚至主动添加测试用例，验证修复效果。

这些行为，都是之前的SFT或RLHF阶段无法实现的，因为之前的训练模式中，模型只能看到人类的最终答案或反馈，却看不到人类如何一步步想到答案。而RLVR通过可验证奖励，让模型自己摸索出了这套推理方法论。更重要的是，RLVR与SFT、RLHF存在着本质上的区别。后两者在计算规模上属于轻量级微调，训练周期短、参数更新幅度小。而RLVR面对的是客观且无法作弊的奖励函数，这使得模型可以进行更长周期的优化。

相当于之前的训练是给模型讲题，而RLVR是让模型自己刷题，并且即时批改。这种高强度的自主训练，带来了能力上的质变。这种质变最直观的体现，来自**OpenAI**的产品迭代。2024年底发布的**o1**，是行业内首个展示RLVR潜力的模型，但是当时的能力提升还相对有限。而2025年初推出的**o3**，成为了RLVR技术成熟的拐点。

很多用户在使用o3时都能直观感受到，模型不再是快速给出答案，而是先思考再回答，甚至会在输出中明确标注“我需要先验证这个前提”、“这里可能存在逻辑漏洞”、“我再检查一遍”等等。这种思考过程的可视化，正是RLVR训练的直接成果。

而RLVR还带来了一个行业性的连锁反应，那就是计算资源的重新分配。原本各大实验室计划用于更大规模预训练的算力，大部分都被投入到了RLVR的训练中。因为实践证明，RLVR每单位算力带来的能力提升，远高于单纯扩大模型的参数规模。这也导致2025年大语言模型行业的一个显著特征：主流模型的参数规模并没有明显的增长，但是训练周期大幅延长，尤其是RLVR阶段的运行时间，成为了决定模型能力的核心指标。

除此之外，RLVR还为行业带来了一个全新的能力调节旋钮，通过控制模型的思考时间，来调节模型在特定任务上的表现。这种按照任务需求，调节推理深度的模式，让大语言模型的实用性大幅提升，也为后续的应用开发提供了更灵活的技术基础。

### 智能本质与基准测试

如果说RLVR和锯齿状智能是大语言模型底层技术的范式变化，那么2025年另一大值得关注的趋势是应用层的重构，而这一重构的标志性产品就是**Cursor**。卡帕西认为，Cursor的迅速崛起，最核心的价值不在于它是一个好用的AI编程工具，而在于它首次清晰地揭示了大语言模型应用的新层级形态。在2025年，Cursor for X已经成为行业热议的话题，这里的X可以是编程、设计、法律、医疗、教育等任何的垂直领域。

那么，这个新应用层到底有什么不同？卡帕西在2025年的**Y Combinator**演讲中详细拆解了Cursor这类大语言模型应用的核心特征，总结起来有四个关键维度。第一个是**上下文工程**（Context Engineering）。与通用大语言模型不同，Cursor这类垂直应用会针对特定领域预先构建最优的上下文框架。这种构建解决了通用模型需要用户花费大量时间描述背景信息的痛点，让用户无需额外解释，模型就能快速切入核心任务。

第二个维度是复杂有向无环图，也就是**DAG**（Directed Acyclic Graph: 有向无环图，一种表示任务依赖关系的数据结构）的大语言模型调用编排。在通用大语言模型的交互中，用户与模型的沟通通常是单轮或多轮对话。而Cursor这类应用的底层，是将多个大语言模型调用串联成复杂的DAG结构，每个步骤的输出作为下一个步骤的输入，同时系统会实时平衡性能和成本。这种编排式调用，让大语言模型的能力从单次响应升级为了流程化的解决复杂任务。

第三个维度是应用的专用**GUI**（Graphical User Interface: 图形用户界面）。通用大语言模型的交互界面大多是聊天框，而Cursor为编程场景设计了专用的GUI。这种领域专用GUI的核心价值，是让人类和大语言模型之间的协作更加符合特定场景的工作流。

第四个维度是**自主度滑块**（Autonomy Slider）。这是Cursor最具创新性的设计之一，用户可以根据自己的需求调节AI的自主参与程度。这种可调节的自主度，解决了通用大语言模型的一个关键问题：AI的参与要么过度，要么不足。而自主度滑块让AI成为了可定制的协作伙伴，从而适配不同用户、不同场景的需求。

卡帕西对这个应用层趋势的判断是，大语言模型实验室与应用开发者的分工将会越来越清晰。大语言模型实验室的核心任务是培养出具备通用能力的大学生，也就是提供基础模型，具备语言理解、知识储备、推理等核心能力。而应用开发者的核心任务是将这些大学生培养成垂直领域的专业人才，让通用模型在特定领域形成专业能力，最终落地为可部署的产品。

这种分工模式也让行业看到了应用层创新的巨大潜力。大语言模型实验室无需包揽所有场景落地，可专注于基础模型优化；应用开发者则可基于成熟模型，聚焦垂直领域需求挖掘和体验优化。在2025年，已出现大量Cursor for X创业项目，如医疗、法律、教育等。这些垂直应用的爆发，让大语言模型从通用工具渗透到各行各业工作流，成为提升生产力的核心工具。

### 本地Agent与氛围编程

在2025年的大语言模型领域，另一个极具创新性的范式变化来自于**Anthropic** 推出的**Claude Code**。卡帕西认为，Claude Code的核心突破有两个：一是它首次让大语言模型**Agent**（大语言模型Agent: 能够自主使用工具并进行推理以完成复杂任务的AI）的概念从理论走向了实用；二是它选择了本地运行的部署模式，与**OpenAI**的云端Agent策略形成了鲜明对比。而在卡帕西看来，Claude Code的选择更符合当前的技术阶段。

首先，Agent的核心能力就是循环式的工具使用与推理。与传统大语言模型单次响应用户需求不同，Claude Code这类Agent能像人类一样，根据任务目标，自主决定需要使用什么工具、如何使用工具、如何根据工具反馈调整策略，并且持续循环这一过程，直到完成复杂任务。

而Claude Code的另一个核心特征——本地运行，则是其区别于其他大语言模型Agent的关键。卡帕西认为，OpenAI在Agent方向上的策略走偏了，OpenAI将其这部分能力集中在云端容器部署，通过**ChatGPT**进行调度。优势是算力强、模型规模大，但是缺点也同样明显：一是隐私安全风险，二是环境适配性差，三是有交互延迟。而Claude Code选择在本地运行，恰好解决了这些痛点。

它直接安装在用户的电脑上，所有数据处理、工具调用、推理计算都在本地完成，无需上传云端，从根本上保障了隐私安全。同时，它能够深度适配用户的本地环境，无论是Windows、macOS还是Linux系统，无论是Python、Java还是Rust等开发语言，无论是本地数据库还是私有软件工具，Claude Code都能直接调用和交互。

此外，本地运行带来的零延迟，让AI Agent与用户的协作更流畅，这种实时反馈的体验是云端Agent所无法比拟的。卡帕西强调，Claude Code的成功还在于它的形态设计，它采用了简洁而强大的命令行界面（**CLI**）（Command Line Interface: 命令行界面），而不是复杂的图形界面。这种设计看似复古，实则精准适配了开发者的工作习惯。对于程序员、数据分析师等专业用户来说，CLI界面操作高效、可自动化、可批量处理，比图形界面更能提升工作效率。

这种本地运行+CLI界面的组合，也让AI形象转变：不再是网页服务，而是居住在电脑里的小幽灵、小助手，随时响应指令，协同工作。这标志着大语言模型从远程服务走向本地伙伴，从被动响应走向主动协作。2025年，用户将习惯电脑里有AI Agent，普及率大幅提升，从专业领域走向更广泛的个人场景。

2025年，大语言模型还带来了一个足以改变软件行业生态的范式变化，卡帕西称之为**氛围编程**（Vibe Coding）。这个听起来有点随性的术语，其实是卡帕西在一条突发奇想的推文中偶然创造的，没成想却意外成为了2025年行业最热门的概念之一。因为它精准捕捉了AI赋能编程的核心形态：你可以用自然语言描述想要的效果，然后让AI自动生成代码，而用户无需关注代码的具体实现细节。简单来说，就是忘记代码，只谈需求。

氛围编程的核心突破，是大语言模型跨越了自然语言到代码的能力阈值。在2025年之前，AI生成的代码往往需要大量人工修改才能使用。而到了2025年，经过RLVR训练和垂直优化的大语言模型，已经能够精准理解自然语言中的隐性需求，并且生成高质量、可直接运行的代码。这种能力的突破，带来了两个层面的颠覆性影响。

第一个层面是全民编程时代的到来。传统编程门槛高，需掌握语言、语法、算法。普通人开发工具需数月甚至数年学习。氛围编程彻底打破此门槛。学生、教师、设计师、白领、自由职业者，只需用自然语言描述需求，AI即可生成对应软件工具。编程不再是开发者专属，而是全民可及的基础技能，如同使用Word、Excel般简单。

第二个层面是专业开发者的效率革命。对于专业程序员来说，氛围编程不是替代他们，而是解放他们。开发者可以将大量时间从编写重复代码、实现基础功能中解放出来，专注于核心逻辑设计、架构优化、创新功能的研发等更高价值的工作。

卡帕西分享了自己2025年的亲身实践。他在开发**nanochat**项目时，需要一个高效的BPE分词器，但是他并不熟悉**Rust**语言。按照以往的做法，他要么学习Rust语言，要么采用现有的开源库。而通过氛围编程，他直接用自然语言描述了分词器的需求，AI自动生成了对应的Rust代码，不仅性能达标，还完美适配了nanochat的架构。

此外，他还通过氛围编程快速开发了多个演示项目，比如menugen、reader3等等，甚至为了查找一个bug专门生成了一个临时应用。因为在氛围编程的模式下，代码变得免费、短暂、可塑造，甚至单次使用后可以丢弃，开发成本几乎为零。

卡帕西曾提出观点：大语言模型技术扩散，普通人受益远超专业人士、企业或政府。氛围编程是最佳佐证。以往技术革新（计算机、互联网、手机）先惠及企业专业人士，普通人需长时间后享红利。而氛围编程让普通人即时平等地获得开发软件的能力。

而这种全民编程的趋势，也将深刻改变软件行业的生态。未来的软件市场，也许将不再是少数大公司主导，而是海量个人开发者和小团队百花齐放。每个人都可以根据自己的需求开发工具，然后分享给有同样需求的人。软件的形态也将从通用大产品走向垂直小工具，更精准地满足用户的个性化需求。

同时，未来的程序员，不再是代码的编写者，而是需求的定义者、逻辑架构师、AI协作管理者等等。核心能力将从代码熟练度，转向需求拆解能力、系统设计能力，以及AI协同能力。

### GUI时代的到来

如果说氛围编程改变了大语言模型的输入方式，那么2025年另一大交互形态的革新来自大语言模型的输出方式。这个革新的标志性产品，正是**Google**的**Nano Banana**。卡帕西认为，Nano Banana是2025年最具颠覆性的模型之一，因为它首次预示了大语言模型的**GUI**（Graphical User Interface: 图形用户界面）时代的到来。而这个时代的核心逻辑，就是让大语言模型用人类喜欢的方式沟通。

回顾交互现状：2025年前，LLM主要靠文本聊天，用户输入指令，模型输出结果。优点是直接高效，因文本是LLM擅长的数据形态。缺点是：不符人类接收习惯。卡帕西指出，人类不喜欢读大量文本，因其信息密度低、速度慢、需高注意力。人类天生喜视觉化、空间化信息，故GUI取代CLI成主流。

而Nano Banana的核心创新，不在于它能够生成图像，而在于它实现了文本生成、图像生成、世界知识的深度融合。模型的权重中同时包含了语言理解、视觉生成、世界知识三大能力，能够根据用户的需求，自动选择最优的信息呈现方式。

卡帕西认为，LLM作为下一代计算范式，其发展路径与70、80年代计算机相似：从大型主机到PC，从命令行到GUI。如今LLM正从通用文本工具走向专用视觉化工具。当前文本聊天交互相当于命令行时代，高效但门槛高。未来LLM GUI将如**Windows**或**Mac OS**，直观易用，让更多人轻松使用。

LLM GUI并非取代文本交互，而是互补。简单查询、快速指令场景下文本仍高效。复杂信息、知识传递、决策支持场景则视觉化交互为主流。2025年行业实践已现早期案例，预示交互方式正从单一文本走向文本+视觉+动效多模态融合。此融合将降门槛，推LLM从专业工具走向全民普及基础设施。

### 总结与展望

回顾2025年大语言模型领域的六大范式变化，我们能够清晰地看到一个核心特征：那就是大语言模型正在以一种**矛盾而真实的姿态**，快速成长。它既比我们预期的更聪明，又比我们预期的更笨拙；它既具备了颠覆行业的潜力，又面临着诸多待解的挑战。

卡帕西曾经在Dwarkesh的播客中，表达过一个看似矛盾但是又极具洞察力的观点：他同时相信大语言模型领域会持续快速进步，但是也认为还有大量工作要做。未来的大语言模型，无论是底层技术的优化、应用层的创新，抑或是行业规范的建立，都还有巨大的探索空间。

虽然2025年即将过去，但是大语言模型的革命，也许才刚刚开始。正如卡帕西在文章结尾所说的：“Strap in”。系好安全带，未来几年，我们恐怕还将见证更多颠覆认知的技术突破，更多改变生活的应用落地。而作为这场革命的见证者和参与者，我们既要保持对技术的敬畏之心，也要怀揣对未来的期待。感谢收看本期视频，我们下期再见。