---
area: society-systems
category: business
companies_orgs:
- Meta
- Google
- OpenAI
- Anthropic
- DeepSeek
- Microsoft
- Scale AI
- Apple
- IBM
- AWS
- Cohere
- GitHub
date: '2025-11-09'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- Wired
people:
- Yann LeCun
- Mark Zuckerberg
- 田渊栋
- Alexander Wang
- Nat Friedman
- Elon Musk
- Geoffrey Hinton
products_models:
- Llama
- Llama 2
- Llama 3
- Llama 4
- Maverick
- GPT-3
- Gemini 2.5 Pro
- o1系列
project:
- ai-impact-analysis
- systems-thinking
- entrepreneurship
series: ''
source: https://www.youtube.com/watch?v=0mrko3cYqBs
speaker: 硅谷101
status: evergreen
summary: 2025年Meta AI部门经历大规模裁员和高管离职，引发外界对Llama开源路线的质疑。本文深入剖析Meta AI的组织架构、FAIR与GenAI的理想与失衡，以及Llama
  1到Llama 4的发展历程。Llama 4的失败揭示了产品驱动研发与前沿技术探索之间的冲突，最终导致扎克伯格引入Alex Wang进行大刀阔斧的重组，试图挽救Meta在AI竞赛中的地位。
tags:
- ai-strategy
- leadership-challenge
- open-source-ai
- organizational
- research
title: 失衡的乌托邦：Meta开源AI路线的滑铁卢与组织重构
---

### Meta AI裁员与Llama 4滑铁卢的背景

2025年10月底，Meta AI部门宣布裁员600个职位，甚至核心部门的研究总监、掌管AI业务的高管纷纷离职或被边缘化。就连**图灵奖**（Turing Award: 计算机科学领域的最高荣誉）得主Yann LeCun也被认为自身难保。在看到新闻时，我们感到震惊，一方面马克·扎克伯格（Mark Zuckerberg）正用上亿美元的年薪去挖AI人才，但同时又如此决绝地裁员。这种割裂行为背后的原因是什么？

为了还原Meta的Llama开源路线究竟发生了什么，以及为何Llama 3还让众人惊艳而仅一年后的Llama 4就如此“拉胯”，我们采访了Meta的前**FAIR**（Fundamental AI Research: Meta旗下专注于人工智能前沿研究的实验室）研究总监、AI科学家田渊栋，参与了Llama 3后训练的前Meta员工Gavin Wang，硅谷资深HR专家以及一些匿名人士。Meta的开源路线从一开始就注定是个错误吗？在AI大模型激烈对战的当下，一个乌托邦式的AI研究实验室还能存在吗？不能让不懂的人来做整个领导者或规划者。Llama 4规划时，其实就能感觉到领导层的方向可能出现了一些变化。Meta拥有资金、算力、人才和数据，几乎什么都有，那它为什么现在做得不够好？接下来，我们将深入探讨Meta的开源AI路线是如何碰壁的。

### Meta AI的架构与开源初心

首先，我们要了解Meta对AI布局的整个公司架构。2013年年底，扎克伯格开始搭建Meta的AI团队。当时谷歌收购了Geoffrey Hinton的**DNN**（Deep Neural Network: 深度神经网络）团队，将Hinton招入麾下。同一时间，Meta将**Yann LeCun**（图灵奖得主，深度学习三巨头之一）请来坐镇AI的发展。至此，图灵奖三巨头的两位开始步入商业科技领域，主导AI研发。

扎克伯格邀请Yann LeCun加入Meta时，后者提出了三个条件：第一是不从纽约搬走；第二不会辞去在纽约大学的工作；第三必须开展开放研究，公开发布所有工作，并将代码开源。因此，我们看到Meta的AI路线从一开始就是开源的。Yann LeCun进入Meta之后，开始着手前沿的AI研发，组建了**FAIR**实验室，主导人工智能的前沿研究。

FAIR是负责前沿研究的，即探索那些目前看似没有重大应用，但可能带来新想法、新思路、新算法、新框架和新模型架构的领域。这样的探索之后，可能会带来一些大的突破，这大概是其运作的逻辑。

### FAIR与GenAI：理想与现实的天平

然而，对于Meta来说，最终还是要看到AI在自身产品上的进展。于是，与FAIR组平行设置了一个组，叫“**Generative AI**”（简称**GenAI**）组。这个组里面分别有不同的功能团队，包括了Llama开源模型的研发，将AI能力运用在产品上的Meta AI团队，以及AI算力基建的数据中心团队。此外，还有一些小部门，例如Search（搜索）、Enterprise（企业服务）、Video-gen（文生视频）模型等等。

GenAI和FAIR是平行关系，就像一个天平，一边是前沿科研，一边是产品化。理想情况下，前沿研究能够带来更好的产品力，而产品赚钱了就能够让管理层有更大的动力去拨款给FAIR做研发。FAIR提供一些好的想法和工作，然后这些想法和工作会给GenAI去使用，让GenAI将其投入生产，并在下一代模型中使用。

很多人的初心是想做一些不一样的东西，与众不同的方向和工作，并希望能真正实现**AGI**（Artificial General Intelligence: 通用人工智能）。所以，FAIR的目的是AGI，而GenAI的目的是如何将AI放在Meta现有的产品中，让AI发挥效应，主要包括Llama大模型以及如何将AI应用于具体场景。

然而，让这样的天平始终保持平衡，是一个很理想化的乌托邦状态。这个乌托邦状态的前提是Meta的AI模型水平一直保持最领先，或者至少在开源赛道最领先，并且不落后闭源模型太多。

在FAIR，最快乐的一段时光是从我入职之后到2022年。这段时间大家都很开心，因为大语言模型出现后，整个生态和研究者之间的关系发生了一些变化。大语言模型出现后，算力成为一个很重要的因素，而算力是有限的，因此产生了各种问题和矛盾。大家都想训练一个很大的模型，如果这样，相互之间就会产生问题，例如我卡多了，你卡就少了。但卡不多就没办法训练出好的模型。正因为这个原因，2023年之后，FAIR的状态肯定不如以前那么好。

### Llama系列：从开源奠基到辉煌顶点

Meta的AI天平是如何失衡的呢？我们可以从Llama的四代发布中看到一些端倪和痕迹。顺便说一句，Meta给自家大语言模型取名“Llama”，据说是因为考虑到Large Language Model的缩写“LLM”不太好发音，所以补上了元音字母，让“Llama”念起来朗朗上口，也便于记忆传播。自此，大语言模型命名才和“羊驼”扯上了关系。

我们先来看一下Llama 1，它为Meta的大模型“开源”路线奠定了基础。2023年2月24日，Meta发布了Llama模型，主打“更小参数更好效果”，发布了7B/13B/33B/65B的多规模版本，强调当时的13B模型可以在多项基准上超过175B参数的GPT-3。Llama在官宣之后的一周，权重在4chan上以种子形式被“泄露”，引发了AI社区对开源模型的广泛讨论，甚至还引发国会参议员致信质询Meta。虽然有不少质疑的声音，但业界对Llama的“意外泄露”出人意料地支持，这也被视为“大模型开源”格局的重塑，并很快催生出诸多的民间微调项目。

我们在这里稍微解释一下大模型的“开源”定义。其实Meta也不是完全的开源，Meta称之为“**开放权重**”（Open weights）。那么这个**权重**（weights）是什么东西呢？在机器学习中，有三个部分：**结构**（architecture）、**权重**（weights）和**代码**（code）。所谓“权重”就是模型学习到的所有参数数值。模型训练完成之后，所有的参数会存在几个巨大的二进制文件，每个文件里面保存着每一层神经网络的矩阵数值。在推理时，模型代码会加载这些权重文件，用**GPU**（Graphics Processing Unit: 图形处理器）进行矩阵运算生成文本。所以，“开放权重”就意味着向公众提供训练好的参数文件，外界可以本地加载、部署和微调。但这还不是完全的“开源”，因为真正的开源意味着公开训练数据、代码和许可等等。但Meta并没有公开这些信息，甚至之后的Llama 2、3、4代都仅仅是开放权重，只是在许可证的政策上有些许松动。

结论是，虽然Llama属于“半开源”，但比起OpenAI、Anthropic和谷歌完全闭源，只通过**API**（Application Programming Interface: 应用程序接口）接口来提供模型能力服务的公司来说，Llama已经算是给开源社区带来了非常旺盛的生命力了。

2023年7月28日，Meta联合微软发布了**大模型**（Large Language Model, LLM）Llama 2，包含7B、13B和70B参数的三种参数变体。新一代模型的“开源”虽然也是“开放权重”，但对比Llama 1的不可商用、只能申请研究用途而言，Llama 2是一个免费可商用的版本，更放宽了许可证的权限。Wired等杂志指出，Llama 2让“开放路线”对抗封闭模型巨头成为现实。Llama 2很快在开发者社区风靡起来，它的可得性显著放大了生态和AI开发，成为大家今后首选的模型。开发者不用再被OpenAI API的限流约束，也不用再跟客户解释为何还得按用量额外多付几美元。关键差别就在这里，Meta和Microsoft这一大胆之举彻底改变了行业格局，他们逼得其他公司不得不更开放，因为他们为优秀模型应该是什么样、开源许可该怎么做树立了新的行业标准。

随后就到了2024年的Llama 3，这也是Llama系列最为风光和辉煌的时候。步入Llama 3的时代，Meta已经成为AI开源社区的顶流存在。2024年4月到9月，Meta连发三个版本的模型迭代。2024年4月18日，Meta发布了8B、70B的两个规格的Llama 3版本，称同等规模“显著超越Llama 2”，并将其作为Meta AI助手的底座之一。之后的7月23日，Meta推出了405B、70B、8B三档Llama 3.1模型，并宣称405B是“全球最强的开放可得**基础模型**（Foundation Model: 经过大量数据预训练，可适应多种下游任务的通用模型）”之一，同时登陆AWS Bedrock、IBM watsonx等平台。仅两个月之后的2024年9月25日，Meta推出了Llama 3.2，主打小而全的**多模态**（Multi-model: 能够处理和理解多种类型数据，如文本、图像、音频等）能力，增加1B与3B轻量文本模型，与11B与90B的视觉多模态模型，面向终端和边缘场景。AWS等平台同步接入，开源框架平台Ollama亦可本地运行。

我们采访到了Llama 3团队的Gavin Wang，他负责Llama 3的后训练工作，表示当时整个Meta当中，GenAI团队真的是在以“光速”前进，真的有一种“AI一天，人间一年”的感觉。他提到当时Llama 3.1/3.2确实有很多很好的进展，例如多模态是在这个阶段发布的，包括后面他们做的**轻量化模型**（Lightweight model: 参数量小、计算资源需求低的模型）1B/3B的，这些都是为了产品化生态做出了很多进展。许多开源社区也提供了支持，包括有朋友在Llama Stack团队，他们专门支持整个Llama生态在企业级或小企业级的落地。

Llama 3的强势出击，特别是450B版本，被认为在模型能力上逼近闭源阵营，也快速推动了AI应用的落地。对于Meta内部员工，特别是在Llama组的AI工程师们来说，这是一个让他们非常值得骄傲的项目。当时的**叙事**（narrative: 故事、论述）是Meta是大厂里面唯一一个剩下开源模型的公司，而且对整个开源生态很有贡献。很多人觉得不仅仅是在做一份工作，而是真正在支持整个AI前沿的发展，做的每一件事情都感觉非常有意义。当时感到非常自豪，出去跟别人说在做Llama，连一些创业公司创始人都会表示感谢，感觉整个技术圈，尤其是AI创业圈，都在指望Llama。

### Llama 4的灾难性滑铁卢

Meta乘着东风，期望Llama 4的发布能够进一步扩大自身在AI开发社区的影响力，保持“顶尖大模型中唯一开源存在”的地位。扎克伯格在2025年1月底的财报会议之后发帖说：“我们对Llama 3的目标是使开源与闭源模型具有竞争力，而我们对Llama 4的目标是领先。”

然而，三个月之后的Llama 4发布，却是一场彻底的灾难和滑铁卢。2025年4月5日，Meta推出了Llama 4的两个版本Scout与Maverick，宣称多模态与长上下文能力大幅跃进，并在宣传中高调引用LMArena排行榜上的领先成绩，Maverick版本仅次于Gemini 2.5 Pro，与ChatGPT 4o和Grok 3 Pro并列第二。然而很快，开发者社区的反馈并不正面，认为Llama 4的效果不及预期。市面上开始有流言质疑Meta在LMArena上面冲到第二名的版本有作弊嫌疑，怀疑Llama 4给LMArena排名的版本是经过了优化的变体，经过了对话强化训练，存在误导LMArena、导致过拟合的现象。

虽然Meta高层迅速否认了作弊，但影响迅速发酵。一方面，媒体纷纷将此视为“用特调版本刷榜”的“**诱饵调包**”（bait-and-switch: 营销中先以低价或优质产品吸引顾客，再推销高价或劣质产品的行为），行业对基准公信力和可复现性的讨论迅速升温。另一方面，Meta更高端的Behemoth版本推迟发布，公关与节奏严重受挫。在我写稿时，Behemoth还没有发布，Meta应该是放弃了。

接下来就是大家所知道的，扎克伯格开始孤注一掷地大手笔收购Scale AI，把Alexander Wang挖来领导新的AI架构，之后用上亿美元的支票开始挖人，疯狂搅局硅谷AI人才市场。再之后就是最近的新闻，Alex开始重组整个Meta的AI架构，裁掉600人。但大家看看这个时间线，是不是还是觉得很割裂？那么在Llama 3和Llama 4的这一年当中，发生了什么？怎么Llama 4一下子就不行了？这是不是也太快了？通过复盘，我们也许找到了一些答案。

### 天平失衡：Llama 3到Llama 4的转折

还记得我们前面说的Meta内部的AI架构是一架天平吗？那么Llama 4失败的原因，很可能就是这架天平失衡了。我们再回到Meta的AI架构上，FAIR和GenAI是并行的两个组。Yann LeCun管理FAIR，但他很多时候都沉浸在自己的研发当中，有时候还在网上跟人，例如埃隆·马斯克（Elon Musk）对战，还经常说不看好LLM路线，让Meta很头疼。

于是2023年2月，Meta高层就把Meta AI的研究负责人Joelle Pineau调到FAIR，担任FAIR的全球负责人，与Yann LeCun两个人一起领导FAIR。而GenAI部门的负责人是Ahmad Al-Dahle，他之前在苹果工作了快17年。扎克伯格把他挖过来的原因，就是想把AI和Meta的各种产品结合起来，包括元宇宙、智能眼镜的AI整合以及聊天工具meta.ai等等。

就在经历了Llama 2的成功，公司开始研发Llama 3的过程中，Meta高层越来越强调“要将AI用于自家产品”的属性。于是我们看到2024年1月份，Meta的AI团队进行了一次重组，FAIR的两名负责人开始直接汇报给Meta的**CPO**（Chief Product Officer: 首席产品官）Chris Cox。

### 领导层变动与产品驱动的弊端

Llama 1到3算是一个时代，大家很疯狂地在卷**规模化法则**（Scaling Law: 指模型性能随模型规模、数据量和计算量增加而提升的规律）。当时整个行业都在提升**基础模型**（Foundation Model）的能力，探索大语言模型本身的能力边界。但Meta的领导层，像扎克伯格和CPO Chris Cox，他们很早就意识到LLM的能力要能够落地，真正为社会产生价值，肯定是从产品力出发的。所以Llama 2和Llama 3阶段，整个GenAI的核心目标是让研究成果真正产品化、工程化。

也因此，在最高管理层层面，副总裁、高级总监这个层面，公司的中高层，基本上是高层，有一些之前更多是产品背景和工程背景的人来领导。在Llama 3成功推出，Meta高层开始制定Llama 4路线之际，所有的注意力都放在了与产品结合上，也就是多模态的能力，因此忽视了对模型推理能力上的重视。

### DeepSeek与O1系列带来的冲击

就在Llama 3到Llama 4这一年研发过程中，2024年9月12日，OpenAI推出了基于**思维链**（Chain-of-Thought, CoT: 一种提示技术，通过中间推理步骤引导大模型解决复杂问题）的o1系列模型。之后的2024年12月，中国的DeepSeek开源模型横空出世，用**混合专家架构**（Mixture-of-Experts, MoE: 一种神经网络架构，通过多个“专家”网络处理不同输入，提高效率和性能）在保证推理能力的情况下，大幅度降低了模型成本。

在被拉去救火Llama 4之前，我们团队正在做一些关于推理过程的研究，主要是关于思维链的形态和训练方式。其实我们在o1系列出来之前（o1是去年9月份出来的），就已经注意到非常长的思维链会对整个模型的规模化法则产生影响。

其实FAIR组当中，田渊栋等研究员已经在着手思维链的研究了，但这样对推理能力的前沿探索并没有及时地传达到Llama模型的工程上。Llama 4规划的时候，其实就能感觉到领导层的方向有一些变化。我认为总体来说，他们还是想要支持Meta本身重点去推的一些产品，就是Llama本身的生态，多模态肯定是其中的一个重点。

但是DeepSeek因为是1月份的时候横空出世，他们的推理能力非常强。推理能力当时也是讨论的其中一个方向，但是因为Meta本身的生态，他们更看重多模态，没有重点去做推理能力。但是当DeepSeek出现以后，当时据说有在讨论，因为那个时候我实际上已经离开了Llama的团队，他们有在讨论说是不是要重新把推理的地方捡起来。这个地方可能在优先级安排上有一些冲突，时间也非常有限，就导致大家加班加点地做了很多的尝试，非常忙。DeepSeek的出现肯定造成了公司里面资源和优先级管理上的一些混乱。

还有一点是，Llama 1到3的话，整个模型的架构和组织的架构其实延续了一开始的设计。但是Llama 4的话，因为Llama 3的成功本身，大家希望它能够更进一步，能够做一些更大的工程，这个时候可能出现了一些问题。我的观察是公司比较高层的，像**副总裁**（VP: Vice President）、高级总监这个层面，他们很多人是**基础设施**（Infra: Infrastructure，指计算机硬件、网络、数据中心等基础架构）背景，比较传统的，或者说他们可能有一些比较传统的计算机视觉方向，自然语言处理的背景都比较少。就是技术方面对于AI原生技术或者说是大语言模型这些东西，就没有一个深度的理解和认识。

真正懂行的，可能是下面具体做事的一些学术研究型博士，尤其是我们非常骄傲的华人学术研究型博士，他们技术非常扎实。但是他们获得的话语权或者说在公司内部的资源没有那么多，所以说可能不知什么缘故就造成一种外行管理内行的一些局面出现。

### 外行领导内行与救火团队的困境

因为OpenAI的o1系列和DeepSeek的出现，让Meta在2025年年初乱了阵脚。于是高层临时让FAIR的研究团队去支援Llama 4的研发，或者可以直接说是去“救火”。而这个“救火团队”就是由田渊栋带队的。

我觉得现在很大的一个教训是，做这样的项目，不能让不懂的人来做整个领导者或者说规划者。如果有些东西出了问题，应该是大家说好我们不能在这个时候发布，我们再往后拖，应该是采用一种拖到什么时候能够正常运作才发布这样的几个阶段，而不能说把最后期限先定好。最后期限先定好的话，其实有很多事情是做不好的。我们组里面当时很多人非常累，例如我是在加州，我有几个团队成员在东部时区，他们晚上12点给我打电话，他们那边已经3点钟了，还在干活，所以非常辛苦。这样的话，我觉得这是一个很大的问题。

他们为什么那么辛苦呢？是因为最后期限压得很紧，就是说我们要在某一天必须按计划发布版本。一般做项目管理的话，要从后面开始往前倒推，看2月底或者3月初一定要做什么事情，3月底要做什么事情。但如果在做这些事情的时候，发现模型这方面不行，或者说数据有什么问题，在这种情况下，就有一个很大的问题是，你怎么样能够让大家因为你这句话停下来？比如说我说这个数据有问题，不行，这个数据不能用，我们得换一个数据。那这样的话就多出事了，我们得把整个事情往后延一个星期、两个星期。但这个事情能不能做到是一个很大的问题。如果在很强的最后期限压力之下，最后结果就是这事情做不了，或者说大家没有办法提出异议，那这样的话，最后质量就会变得很差，这是一个比较大的问题。

为什么Meta会有那么强的压力在最后期限上面呢？因为开源模型其实它已经是第一了。当然DeepSeek在年初的时候出来，大家都没有意料得到。但是为什么它有那么强的硬性期限说我一定要在这个时候把这个东西推出来？应该说有个上面高层拍板定下的最后期限，但这个我就不方便说了，可能要去问一下相关的人，懂的都懂。

我们在这里基本上能够有一些答案了。从Llama 3开始，“将AI产品化”这样的路线就已经制定，整个模型注重多模态和应用，忙于整合应用和业务，但是却忽略了推理能力和更加前沿的技术研发。这让天平另一边的FAIR团队不得不跨组来“救火”。就这样，天平失衡了。但实际情况其实是因为前沿模型的竞争太激烈了，所以基本上很难真的去，比如说用FAIR这边的一些文章。其实有些文章是被用到了，但是我们在交流的过程中，其实还是会存在一些问题。

我当时在FAIR的时候，有时候给GenAI的人发信息，他们都不理我。但真的我去了GenAI之后，我会觉得确实我也没法理他们（FAIR研究员们）。为什么？因为太忙了。你想，比如说我半小时不看手机，可能就有20条消息、30条消息在那里，然后你要去看。所以有很多的人要找，有很多的事情要决定。所以这个我也能理解了，GenAI这样的一个环境下，很难有比较长远的长期思考过程。

### 扎克伯格的修复之道：Alex Wang的特种部队

扎克伯格是如何修复这个失衡的天平呢？他直接空降了一个特种部队，由Alex Wang带队的**TBD**（To Be Determined: 待定，此处指Meta内部一个拥有特权和优先级的特别小组）团队。我们再回到Meta的AI业务架构上，如今再一次重组之后，高层也经历了一系列的动荡。

Alex Wang带领几十位高薪聘请来的顶级研究员，单独成立了这个在Meta内部拥有无限特权和优先级别的特别小组TBD。TBD、FAIR和GenAI一起组成了**Meta Superintelligence Labs**（MSL）部门，直接汇报给Alex，而Alex直接汇报给扎克伯格。这也就意味着，FAIR的Yann LeCun如今也要汇报给Alex。而Joelle Pineau此前被要求汇报给GenAI组的负责人Ahmad，我们看到Joelle已经在今年5月离职，去了Cohere做首席AI官。而Ahmad也说实话很久没有什么声音了，也没有被任命负责如今任何重要的项目。CPO Chris Cox也被Alex抢了风头，排除在了AI团队的直接领导者之外。所以现在的架构就是28岁的Alex一人独大的局面。

反正我已经听到Meta内部各种对Alex和他领导的这支极度有特权小组的不满了，包括TBD团队里的人可以三年不用做绩效考评，可以不理不回其它任何VP的信息。Meta AI里面的所有论文都要给TBD里面的人去审核才能够发表。要知道TBD里面的不少人还比较年轻，这让很多资深的研究员非常不满。反正就是各种内部政治斗争感觉又要起来一波。

但是不可否认的是，这个特权的等号后面是成绩。那么这个成绩对于扎克伯格来说，不仅仅是要让Llama重新伟大，而是“Meta必须赢”。在这场AI竞赛当中，目前的这场重组，也许对于扎克伯格来说是最后的一次，也是最重要的机会。

Alex在团队内部邮件中写到，他将做出的三个改变：第一，集中TBD和FAIR团队的核心基础研究力量；第二，提升产品和应用研发的融合，并且继续以产品为模型聚焦点；第三，成立一个核心基建团队来支持研究押注。

你看，第一条就是把基础研究，TBD Lab和FAIR更集中化，让它两个更紧密地去结合。所以这回裁掉的一些研究人员，邮件上也说，他们可能项目没有那么多高影响力的，就是你再做一些前沿的研究，但和我们现在没有关系。因为很多前沿研究是高度抽象的，是从数学的角度，从很多理论的角度，它其实和工程离得比较远。所以你看第一条就是集中化。

然后第二个，就是把产品和模型更紧密地结合。和Alex Wang一起进来的人，有一个就是GitHub的原来CEO Nat Friedman。他们两个，等于Facebook扎克伯格同时引进了两个高端人才，一个是Alex Wang管模型的，统一来说来管模型的；一个就是叫Nat Friedman，是原来GitHub CEO，他是偏产品。因为产品才能给这个模型更好的反馈，在用的过程中进行**飞轮效应**（Flywheel Effect: 指企业通过一系列相互关联的行动，形成正向循环，从而加速增长）。

第三条你看，组建一个统一的核心基础设施团队，就把管这个卡、数据中心这个团队更集中化。过去很可能是很散的，好几个领导都在，你要卡你得来申请。现在卡这个事也是统一管理，GPU被统一管理。所以这个邮件写得还是挺清楚的。

Alex能否撑得起扎克伯格的押注呢？也许很快我们就会有答案。

### Meta AI的未来与历史的警示

总结一下，Meta在Llama的前三代都还是领先的开源模型，引领着开源派去对抗OpenAI和谷歌Gemini这样的闭源派。然而，在Llama 3大获成功之后，公司高层急于将AI结合产品化，在规划路线的时候，用“产品驱动研发”的思维，将Llama 4的升级聚焦在多模态等工程性能上，但却错失了思维链等推理方向上的前沿技术时间优势。虽然当时田渊栋等FAIR的AI科学家们已经在研究思维链了，但等DeepSeek引发轰动之后，又将FAIR的田渊栋团队临时救火，去优化Llama 4上的混合专家架构，反而又中断了思维链和推理能力上面的研发，导致AI前沿技术研究和产品工程这架天平彻底失衡。

在采访过程中，我脑中不止一次闪现过历史上那些闪耀一时的前沿实验室，如贝尔实验室、IBM Watson Research、HP实验室等等。但基本上都因为无法平衡前沿科研和商业化而日益衰落。十多年历史的FAIR，曾经是一群理想化AI科学家的乌托邦之地，而如今又成了另一个商业化的牺牲品。

我们与田渊栋的采访其实还有更多精彩的部分，我们放在了下一个视频，以对话的形式上线。他跟我聊了很多与Meta无关，但是与一个资深AI研究员的信仰、兴趣以及对AI发展的前沿思考有关的内容。我觉得很有价值，也希望能够对大家来说有所收获。所以大家不要忘记订阅我们的频道，不要错过更新。我是硅谷101的联合创始人陈茜，你的留言、点赞和转发是支持我们做好深度科技和商业内容的最佳动力。那我们就下期视频再见了。