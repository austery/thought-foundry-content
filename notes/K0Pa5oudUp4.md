---
author: Dwarkesh Patel
date: '2024-06-05'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=K0Pa5oudUp4
speaker: Dwarkesh Patel
tags:
  - agi
  - asi
  - national-security
  - government-control
  - geopolitics
title: AI的未来：国家安全与政府主导的必然性
summary: 演讲者 Leopold Aschenbrenner 预测，随着人工智能（AI）技术的飞速发展，特别是通用人工智能（AGI）和人工智能超级智能（ASI）的出现，其最终将不可避免地被国家安全部门掌控，而非仅仅由私营企业主导。他认为，ASI的巨大力量将重塑世界秩序，引发地缘政治竞争，并可能威胁到自由民主。因此，政府的介入和控制将是稳定局势、应对潜在风险的关键，这与核武器的管控历史类似。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-work
project:
  - ai-impact-analysis
people:
  - Leopold Aschenbrenner
  - Dwarkesh Patel
  - Sam Altman
  - Donald Trump
companies_orgs:
  - OpenAI
  - CCP
products_models:
  - ASI
  - AGI
media_books: []
status: evergreen
---
### AI的终局预测

我希望我们使用**人工智能超级智能**（ASI: Artificial Super Intelligence，指在几乎所有领域都远超最聪明人类的AI）是为了治愈疾病，是为了造福世界。但我的预测是，在终局阶段，我们所面临的将不仅仅是酷炫的产品，而是**自由民主是否能够存续**，**中国共产党**（CCP）是否能够存续，以及**未来一个世纪的世界秩序**将是怎样的。当这些成为赌注时，将被激活的力量将远远超出我们目前的讨论范畴。

### 国家安全介入

在最终的疯狂竞赛中，**国家安全**的考量将变得最为重要。回溯第二次世界大战，核能技术是如何被管控的？在技术刚被发现的初期，你需要稳定局势，你需要拥有核武器，必须这样做。随后，**民用**应用才有了发展的空间。我认为，人们谈论**通用人工智能**（AGI: Artificial General Intelligence，指在广泛的任务上表现出与人类相当或超越人类的智能水平的AI）时，总是只关注私营AI实验室。我想挑战这种假设，因为正如我们所讨论的，**国家安全部门**很可能会介入其中。

### 政府主导模式

这可能以多种形式出现：是国家化？是公私合营？是国防合同或合作关系？还是一个吸纳了所有人才的政府项目？尽管存在这些可能性，但我认为人们严重低估了这种情况最终更像是一个**政府项目**的可能性。想象一下，当拥有字面意义上的超级智能集群时，拥有数十亿超级智能科学家，他们可以破解一切，可以**扰乱中国的数据中心**，可以开始组建机器人军队。你真的认为这会是一家私营公司，而政府会对此束手无策吗？

### 地缘政治考量

甚至退一步看，我们为什么要赢得与中国的竞争？因为我们不希望一个自上而下的威权体系获胜。但如果击败它的方式是，人类最重要的技术必须由一个自上而下的政府来控制，那意义何在？为什么？也许我们可以尝试私有化，这是我们希望为ASI实现经典自由市场体系的途径。好了，关于这一点有很多讨论。我认为，或许我应该先谈谈**私有化**的世界会是什么样子，这或许是“别无选择”论的来源。然后，我们再看看**政府项目**会是什么样子，以及**制衡**机制会如何运作。

### 私有化模式的局限

好的，关于私有化世界。首先，很多人现在谈论开源。我认为有一种误解，认为AGI的发展将是某种美好的、去中心化的事物，是一群快乐的程序员在那里协作。事实并非如此。你所说的百亿、万亿级别的计算集群，不会有那么多人拥有它。算法也是如此。现在，开源之所以有价值，是因为人们可以利用已发布的东西。算法被公开，或者像**深度思维**（DeepMind）那样，研究人员离开公司时带走所有秘密，然后进行复制。但这种情况不会持续下去。因此，开源的模式将会改变。

### 巨头垄断与信任

此外，人们还说“1026 PFLOPS（每秒百亿亿次浮点运算）的算力将在我的手机里”。这不可能。摩尔定律已经很慢了。AI芯片确实在进步，但你一生中可能都无法以1000美元的价格拥有价值千亿美元的计算机。因此，私有化领域将只有**两到三个巨头**。那么，我们来看看一些事情。你谈到了超级智能将拥有的巨大力量，政府也将拥有这种力量。我认为，另一种可能性是一家**AI公司**拥有这种力量是相当可信的。特别是如果我们谈论的是领先优势，比如**OpenAI**领先六个月。那么，你谈论的将是**有史以来最强大的武器**，而你却在押注一位私营公司CEO是仁慈的独裁者。并非如此。就像其他私有化事物一样，我们不能指望它们是仁慈的。

### 历史经验与核武器

我们不能指望私营公司是仁慈的。例如，一个生产工业肥料的人，如果回到古代文明，他可以炸毁罗马，甚至可能炸毁**华盛顿特区**。我认为人们低估了这一点：有许多私营行为者拥有这种能力。有很多人控制着供水系统。我们可以依靠合作和基于市场的激励来维持力量平衡。我明白事情进展很快，但我们有大量的历史证据表明，某些东西是行之有效的。我们如何处理核武器？我们如何控制核武器？不是通过某个加强版的**第二修正案**，让每个州都有自己的核武库，让达里奥和萨姆拥有自己的核武库。不，是通过**机构、宪法、法律和法院**。因此，我并不确定力量平衡的类比是否适用。事实上，政府拥有最强大的武器是一种巨大的文明成就。就像在**神圣罗马帝国**时期，如果邻镇的人犯了罪，你不会发动两镇之间的战争，而是将其诉诸神圣罗马帝国的法庭来裁决。这是一个巨大的成就。

### 速度、风险与失衡

现在，关于工业肥料，我认为关键区别在于**速度和攻防平衡**问题。这意味着20世纪的技术在十年内，甚至几年内就会出现。这是一个极其可怕的时期。可怕之处在于，你将面对海量的毁灭性技术和巨大的军事进步。你可能在几年内就从马刀和战马发展到坦克大军和战斗机，然后从那里发展到核武器和洲际弹道导弹。正是这种**速度**造成了最初极其不稳定、极其危险的时期。我们必须设法度过这个难关，这将极具挑战性。这时就需要**政府项目**。如果能度过这一关，局势就会稳定下来，不再面临迫在眉睫的国家安全威胁。即使出现了大规模杀伤性武器（WMDs: Weapons of Mass Destruction，指能够造成大规模伤亡或破坏的武器，如核武器、生物武器、化学武器等），我们可能已经实现了稳定的攻防平衡。例如，生物武器最初是一个巨大问题，攻击者可以制造数千种合成病毒并传播，而你很难防御每一种。但也许最终你会找到一种**普遍防御**所有可能病毒的方法，局势就会再次稳定。或者，就像飞机一样，某些能力**私营部门**不允许拥有，你限制这些能力，然后允许**民用**用途。我对此持怀疑态度，因为……

### 国家与私营的权衡

……还有另一个重要问题。我谈到了一个公司拥有所有权力。我认为这是前所未有的，因为一个生产工业肥料的人无法推翻美国政府。但我认为，一个拥有超级智能的AI公司**很有可能推翻政府**。可能会有多家AI公司，我承认其中一家可能是AI公司。所以不一定是一家。如果领先优势只有六个月，可能就会有两三家。但如果只有两三家，那么你将面临这几家公司之间疯狂的竞争。就像**德米斯**（Demis Hassabis）和**萨姆**（Sam Altman）一样，他们不想让对方获胜，并且都在发展自己的核武库。政府怎么可能允许这些人……达里奥会负责开发超级黑客技术并攻击中国数据中心吗？另一个问题是，如果只有两三家，那将不仅仅是两三家，还会有中国、俄罗斯和朝鲜。因为在私营实验室的世界里，**安全根本不够**。好吧，我承认如果萨姆和达里奥在ASI上领先一年，我确实担心这会被私有化。但在那种情况下，我也非常担心**唐纳德·特朗普**拥有这种能力。尤其是在我们生活在一个总统就职年龄可能低于预期的世界里。在这种情况下，我更倾向于私营公司。所以，在这个矩阵的任何部分，都不能明显地说政府项目优于私营项目。

### 政府项目的现实

让我们来谈谈政府项目和制衡。在某种程度上，我认为我的论点是一种“布莱恩论”，即美国的制衡机制已经**运行了200多年**，并且经受住了疯狂的技术革命。美国军方可以杀死美国所有平民。私营与公共的权力平衡已经维持了数百年。但为什么能维持？因为政府拥有最强大的武器。从未有过一个CEO或一个随机的非营利董事会能够发射核武器。**美国国家安全部门**将深度介入其中。我认为，政府项目看起来更像是**云服务提供商、部分实验室和政府之间的合资企业**。因此，我认为不存在政府不深度介入这个疯狂时期的世界。至少，情报机构需要为这些实验室提供安全保障。他们已经在控制一切，控制着一切的访问权限。然后，如果我们在一个非常不稳定的国际局势中，很多**最初的应用将会很糟糕**。这不是我希望用ASI做的事情。我们将试图以某种方式稳定这个疯狂的局面，设法阻止某些疯狂的新大规模杀伤性武器的扩散，以及破坏**相互确保摧毁**（Mutually Assured Destruction，一种军事理论，认为大规模使用核武器会导致攻击者和防御者双方都被彻底摧毁）的平衡，以应对朝鲜、俄罗斯和中国。

### 政府介入的形态

我认为你的观点承认的**光谱**比实际情况要宽得多。我认为，私营实验室的世界实际上是**政府深度介入**的。我们争论的是政府项目的具体形式，但它看起来会更像**国家安全状态**，而不是像现在这样的初创公司。我认为类似的东西是有道理的。如果这是**曼哈顿计划**，我非常担心，因为那是美国军方的一部分。如果更像是……听着，你得先和某人谈谈。洛克希德·马丁的臭鼬工厂是美国军方的一部分，他们说了算。是的，我认为那不怎么好，我认为那很糟糕。我认为如果ASI也这样，那将是糟糕的。

### 部署与监管的挑战

那么替代方案是什么？好吧，它更接近我所说的光谱的另一端：是的，你必须在启动下一个训练集群之前与某人（比如Jan）沟通。但仍有许多公司在推进。政府将深度介入安全保障，但AI仍将**广泛部署**。并且**对齐**（Alignment，指确保AI的目标与人类价值观一致）能够奏效，这意味着你可以确保系统级提示不会帮助人们制造生物武器之类的东西。我预计AI将广泛部署。首先，如果这是一个政府项目，那么像**“草甸”**（Meadows，可能指代某个组织或概念）那样的人会开源他们两年前的AI模型，这仍然具有巨大的价值。然后会有一个问题：要么攻防平衡没问题，即使他们开源两年前的AI也没关系；要么对最极端的双重用途能力有所限制，比如不允许私营公司销售危险武器。这很好，这将有助于扩散。我认为在智能爆炸期间，对齐问题不是一个多年的官僚流程，然后你才能制定标准。这看起来更像是一场**战争**，你处于**战争迷雾**之中。你是否安全地进行下一次迭代？我们已经经历了智能爆炸的三个阶段，我们不再真正理解发生了什么。我们的一些泛化和缩放曲线看起来不太好。我们的一些自动化AI研究人员在做对齐工作，他们说没问题，但我们不太信任他们。在这个测试中，AI开始做一些不好的事情，但我们把它锤炼出来了，它就好了。我们应该继续吗？再花六个月？顺便说一句，中国刚刚窃取了模型权重，或者他们即将部署机器人军队。我们该怎么办？我认为这是……我认为是这种疯狂的局面。你更多地依赖于**健全的指挥链**，而不是某种深思熟虑的监管体系。我希望我们能做到深思熟虑的监管。这也是私营公司的问题：他们都声称会做安全工作，但当你在商业竞赛中时，情况会很艰难。有初创公司，而初创公司就是初创公司。我认为它们**不适合处理大规模杀伤性武器**。