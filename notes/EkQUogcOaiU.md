---
area: society-systems
category: geopolitics
companies_orgs:
- Tesla
- X
- xAI
- Wikipedia
- MIT
- Harvard
- CNN
date: '2025-11-08'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- The Guardian
- Encyclopedia Britannica
- Reddit
- The Business of the Culture War
- FT
people:
- Elon Musk
- George Floyd
- Donald Trump
products_models:
- Grokipedia
- Grok
- ChatGPT
- Claude Opus 4
- Starship
project:
- us-analysis
- ai-impact-analysis
- geopolitics-watch
series: ''
source: https://www.youtube.com/watch?v=EkQUogcOaiU
speaker: Patrick Boyle
status: evergreen
summary: 本文深入探讨了埃隆·马斯克推出的AI驱动百科全书Grokipedia，旨在取代维基百科。文章分析了Grokipedia在事实核查、内容透明度及意识形态偏见方面存在的深层问题，并将其与维基百科的开放共识模式进行对比。Grokipedia被指责过度依赖维基百科内容，并可能通过AI算法放大政治两极分化。最终，文章质疑了将知识工程化、商业化的硅谷思维，强调了真相的复杂性和人类探究的价值。
tags:
- bias
- control
- culture
- media
- system
title: 埃隆·马斯克的“反觉醒”百科全书：Grokipedia的真相与偏见
---

### 马斯克的Grokipedia：一场关于知识与权力的博弈

我不太确定发生了什么，但如果你一直在关注埃隆·马斯克（Elon Musk）试图从特斯拉（Tesla）获得万亿美元薪酬的故事，那么马斯克似乎很有可能一直在搞一些副业——比如他新的在线百科全书——**Grokipedia**（一个由AI驱动的百科全书项目）——这样他就可以说服特斯拉股东支付他巨额资金，否则他将放弃他们去追求这些其他兴趣。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I’m not entirely sure what has been going on, but If you have been following the story of Elon Musk’s push to get a trillion dollar payday out of Tesla, it seems entirely possible that Musk has just been coming up with side projects – like his new online encyclopedia - Grokipedia – so that he could convince Tesla shareholders to pay him a huge sum of money, otherwise he will abandon them in pursuit of these other interests.</p>
</details>
这也很容易让人相信……几年前他收购了推特（Twitter），这样他就可以成为一个聊天论坛版主。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it’s believable too… a few years ago he bought Twitter so that he could become a chat forum moderator.</p>
</details>
昨天，特斯拉股东屈服了，批准了一项薪酬方案，如果马斯克达到一系列雄心勃勃的目标，这可能使他成为世界上第一个万亿富翁，并授予他公司四分之一股份的控制权——所以也许整个Grokipedia的事情就此结束了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Yesterday, Tesla shareholders caved in and approved a pay package that could make Musk the world’s first trillionaire, and grant him control of a quarter of the company’s shares if he hits a series of ambitious targets – so maybe this whole grokipedia thing is over.</p>
</details>

如果你还没听说过，Grokipedia中的“**Grok**”（埃隆·马斯克的生成式AI聊天机器人）指的是埃隆·马斯克的生成式AI聊天机器人，它在他的社交网络——或者说“万能应用”（everything app）——推特（Twitter，他称之为**X**）上占据显著位置。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you haven’t heard about it, the “Grok” in Grokipedia refers to Elon Musk’s generative AI chatbot which is featured prominently on his social network- or everything app - Twitter - which he calls X.</p>
</details>
马斯克声称Grokipedia的目标是创建一个**开源**（open source: 代码可公开获取和修改）的、全面的知识集合，然后将其副本——刻在**稳定氧化物**（stable oxide: 一种不易分解的化合物，马斯克指的是玻璃）上（无论那意味着什么）——放置在月球和火星轨道上，以供未来保存。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">With Grokipedia, Musk’s stated goal is to create an open source, comprehensive collection of all knowledge, then place copies of that – etched in a stable oxide (whatever that means) in orbit around the moon and mars to preserve it for the future.</p>
</details>
我向Grok询问了他所说的稳定氧化物是什么意思，Grok说他可能指的是玻璃。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now I checked with Grok as to what he means by a stable oxide, and Grok said that he probably means glass.</p>
</details>

### Grokipedia的承诺与现实：真相、偏见与透明度

无论如何……马斯克说Grokipedia将是“真相、全部真相，且只有真相的概要”——对于一个不久前还曾出价十亿美元让维基百科改名为“Dickipedia”的人来说，这是一个崇高的承诺。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Anyhow… Musk says that Grokipedia will be “a compendium of the truth, the whole truth, and nothing but the truth” — a lofty promise from someone who – not so long ago - offered Wikipedia a billion dollars to rename itself “Dickipedia.”</p>
</details>
他将这个项目描述为一场**宣传**（propaganda: 旨在影响公众观点的信息）的清除，是他所谓的“**传统媒体**”（legacy media: 指历史悠久、影响力大的主流媒体）的替代品，以及迈向建立更**开源**（open-source: 软件代码公开可用的模式）知识库的一步。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">He has framed the project as a purge of propaganda, a replacement for what he calls “legacy media,” and a step toward building a more open-source repository of knowledge.</p>
</details>
但考虑到Grokipedia对他的聊天机器人Grok的依赖——其结果可能更像是Reddit（社交新闻网站）与推特（Twitter）喷子们的结合，而非**大英百科全书**（Encyclopedia Britannica: 历史悠久、权威的百科全书）——因为他的聊天机器人确实以此类来源进行训练。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But given Grokipedia’s reliance on his chatbot Grok - the result may be less Encyclopedia Britannica and more Reddit-meets-Twitter trolls – as his chatbot does train on sources like that.</p>
</details>
根据**xAI**（埃隆·马斯克旗下的人工智能公司）的说法，Grok将负责Grokipedia上的所有**事实核查**（fact-checking: 核实信息真实性），这有点像让鹦鹉去验证莎士比亚的引文：它听起来可能很有说服力，但你不会想把自己的声誉押在它的准确性上。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">According to xAI, Grok will be responsible for all fact-checking on Grokipedia, which is a bit like asking a parrot to verify a Shak espeare quote: it might sound convincing, but you wouldn’t want to bet your reputation on its accuracy.</p>
</details>

在马斯克看来，维基百科已经变得软弱——他曾经喜欢它——但现在它太“**觉醒**”（woke: 指对社会公正问题高度敏感和警觉）了，太**建制派**（establishment: 指现有权力结构和主流思想）了，太不愿意包含那些迎合他世界观的来源了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Wikipedia, in Musk’s view, has gone soft — He used to like it – but now it’s too woke, too establishment and too unwilling to include the kinds of sources that flatter his worldview.</p>
</details>
今年早些时候，当维基百科收录了一张他在特朗普（Trump）就职典礼上敬礼的照片时，他特别恼火。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">He was particularly irked earlier this year when Wikipedia included a photo of him saluting at Trump’s inauguration.</p>
</details>
该条目提到了争议并包含了他的否认，但这还不够。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The entry noted the controversy and included his denial, but that wasn’t enough.</p>
</details>
马斯克反而想要一种新型的在线百科全书——一种由他的AI聊天机器人进行事实核查，并且不便的真相可以被**重新校准**（recalibrated: 调整或修正）直到它们感觉更……“Grok化”的百科全书。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Musk instead wants a new kind of online encyclopedia — one where his AI chatbot, does the fact-checking, and where inconvenient truths can be recalibrated until they feel more... grokky.</p>
</details>
聊天机器人是否值得信赖进行事实核查尚不明确。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It is not obvious that a chatbot can be trusted for fact checking.</p>
</details>
英国**事实核查组织**（fact-checking organization: 专门核实信息真实性的机构）**Full Fact**的安德鲁·达德菲尔德（Andrew Dudfield）在《卫报》（The Guardian）中被引述说：
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Andrew Dudfield, of Full Fact, a UK-based factchecking organization was quoted in the Guardian as saying “</p>
</details>
“我们真的必须考虑一个由AI生成的百科全书——一个经过过滤的现实的复制品——是否比我们以前拥有的任何东西都更好。它没有显示出同样的**透明度**（transparency: 信息公开可见的程度），但它却要求同样的**信任**（trust: 对信息来源的信心）。目前尚不清楚人类的参与程度有多深，AI生成了多少内容，以及AI是基于什么内容进行训练的。当你无法看到这些选择是如何做出的时，很难对其寄予信任。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">“We really have to consider whether an AI-generated encyclopedia – a facsimile of reality, run through a filter – is a better proposition than any of the previous things that we have. It doesn’t display the same transparency but it is asking for the same trust. It is not clear how far the human hand is involved, how far it is AI generated and what content the AI was trained on. It is hard to place trust in something when you can’t see how those choices are made.”</p>
</details>
无论你是否喜欢维基百科——它的编辑模式是建立在透明度和**共识**（consensus: 多数人同意的意见）之上的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Whether you like Wikipedia or not - its editorial model is built on transparency and consensus.</p>
</details>
每篇文章都有可见的历史记录——完整的编辑、辩论、回溯和妥协记录，这些都是文章缓慢形成过程中产生的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Every article has a visible history — a complete record of edits, debates, reversions, and compromises that were made as the article slowly formed.</p>
</details>
你可以看到谁在何时、为何更改了什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can see who changed what, when, and why.</p>
</details>
争议是公开解决的，通常很繁琐，但具有一种民主的严谨性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Disputes are hashed out in public, often tediously, but with a kind of democratic rigor.</p>
</details>
该网站禁止**原创研究**（original research: 未经同行评审或发表的原始学术工作），而是坚持引用**可靠来源**（reputable sources: 具有良好声誉和权威性的信息来源），这既是优点也是缺点——因为它要求高质量的来源——这也意味着它将反映学术界、大型媒体和其他受尊敬机构的偏见——但至少这些偏见是可见和可追溯的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The site prohibits original research, insisting instead on citations from reputable sources, which can be both a pro and a con – as while it requires high quality sources – this does mean that it will reflect the biases of academia, big media, and other respected institutions — but at least those biases are visible and traceable.</p>
</details>

另一方面，Grokipedia不提供任何透明度——除了像维基百科那样提供来源——但正如你稍后会看到的，Grokipedia的来源存在问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia, on the other hand, offers no transparency – other than providing sources like Wikipedia does – but as you’ll see later the sourcing on Grokipedia has its problems.</p>
</details>

在深入探讨之前——让我介绍一下本周的视频赞助商——**Surfshark**（一款VPN服务），一个可在Windows、Mac、Android、iOS等系统上运行的**VPN**（Virtual Private Network: 虚拟私人网络）应用程序。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Before we go any further – let me tell you about this weeks video sponsor - Surfshark A VPN app that works on Windows, Mac, Android, iOS, and more.</p>
</details>
使用VPN就像穿裤子一样，所有重要信息都保持私密和安全。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Using a VPN is a lot like wearing pants, as with it, all of the important stuff stays private and secure.</p>
</details>
使用Surfshark，你的互联网流量会通过一个安全的加密隧道，增加一层隐私保护，这在你使用公共Wi-Fi网络时尤为重要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">With Surf Shark, your internet traffic goes through a secure encrypted tunnel, adding a layer of privacy protection, which is particularly important if you use public Wi-Fi networks.</p>
</details>
除此之外，如果你在不同国家登录流媒体服务，你会发现可用的内容不同，这可能相当烦人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On top of that, if you log into streaming services in different countries, you'll find that different content is available, which can be quite annoying.</p>
</details>
有了Surfshark，无论你身在世界何处，都可以带着家里的互联网。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">With Surf Shark, no matter where in the world you are, you get to take your internet from home with you.</p>
</details>
Surfshark快速、可靠，并且他们不收集或跟踪你的数据。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Surf Shark is fast, reliable, and they don't collect or track your data.</p>
</details>
他们允许无限设备使用一个账户，所以你也可以保护你的朋友和家人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They allow unlimited devices to use the one account, so you can protect your friends and family, too.</p>
</details>
尝试它没有风险，因为他们提供30天退款保证。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's no risk in trying it out as they offer a 30-day money back guarantee.</p>
</details>
访问surfshark.com/boyle即可获得额外四个月的Surfshark VPN。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Go to surfshark.com/boyle to get four extra months of Surf SharkVPN.</p>
</details>
点击描述中的链接立即注册。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Click the link in the description to sign up today.</p>
</details>

Grokipedia上的文章由一个**大型语言模型**（Large Language Model, LLM: 基于深度学习的AI模型，能理解和生成人类语言）生成并进行事实核查，其内部运作对甚至其创建者来说都是完全**不透明**（opaque: 不透明、难以理解）的——然后其输出可能受到埃隆·马斯克个人**重新校准**（recalibration: 调整或修正）的影响——特别是如果文章涉及他关心的话题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Articles on Grokipedia are generated and fact-checked by a large language model whose internal workings are entirely opaque – even to its creators - and then its outputs can be subject to Elon Musk’s personal recalibration – in particular if the article is on a topic he cares about.</p>
</details>
Grokipedia上没有编辑历史，没有讨论页面，也没有可见的决策过程——这意味着不清楚是谁——或是什么——决定了最终文章的形成方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There’s no edit history on grokipedia, no talk pages, no visible decision-making process - meaning that it’s not clear who — or what — decides on how the final article is formed.</p>
</details>
本周早些时候，当埃隆·马斯克宣布Grokipedia时，他说它“比维基百科更好”——但令人惊讶的是——尽管它雄心勃勃，但它似乎严重依赖它旨在取代的那个网站。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When Elon Musk announced Grokipedia earlier this week, he said that it was “better than Wikipedia” – but surprisingly - for all its ambition, it appears to lean very heavily on the very website it aims to replace.</p>
</details>
正如科技媒体**The Register**（一家专注于科技新闻和分析的在线出版物）所说：“如果你刮开Grokipedia，它会流出维基百科的血。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">As The Register put it: “If you scratch Grokipedia, it bleeds Wikipedia.”</p>
</details>
我无法在网上找到任何确凿数据——但我查阅的Grokipedia上的绝大多数文章显然都是基于其对应的维基百科页面——但引用较少——并且在底部声明：“此内容改编自维基百科，根据**知识共享署名4.0许可协议**（Creative Commons Attribution 4.0 License: 一种允许他人自由使用、分享和改编作品的许可协议）授权。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I can’t find any hard data online – but the vast majority of the articles I looked up on Grokipedia were obviously based on their equivalent wikipedia pages – but with fewer citations - and at the bottom they state, “this content is adapted from Wikipedia, licensed under Creative Commons Attribution 4.0 License.”</p>
</details>

### 知识的演变：从古老百科到AI时代

将所有人类知识收集在一个地方的想法并不新鲜。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The idea of collecting all human knowledge in one place is nothing new.</p>
</details>
早在Grok开始**幻觉**（hallucinating: AI生成虚假或不准确信息）事实之前，百科全书更多是一种模拟事务。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Long before Grok began hallucinating facts into existence, encyclopedias were a much more analog affair.</p>
</details>
在公元一世纪，罗马作家**老普林尼**（Pliny the Elder: 古罗马作家、博物学家）编纂了一部37卷的作品，通常被认为是西方传统中的第一部百科全书。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the first century, the Roman author Pliny the Elder compiled a 37-volume work which is usually cited as the first encyclopedia in the western tradition.</p>
</details>
一千多年后，中国的**《永乐大典》**（Yongle Encyclopedia: 明朝编纂的百科全书）由2000多名学者编纂而成。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Over a millennium later, China’s Yongle Encyclopedia was compiled by over 2,000 scholars.</p>
</details>
它在世界范围内保持了千年最大的百科全书地位。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It remained the largest encyclopedia in the world for a thousand years.</p>
</details>
1768年，第一部《大英百科全书》出版，如果我们快进到2001年——维基百科彻底颠覆了这种模式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In 1768 the first encyclopedia Brittanica was published and if we fast forward to 2001 - Wikipedia upended the model entirely.</p>
</details>
有了维基百科，百科全书不再是学者和抄写员的领域，它变成了一个鲜活的、不断发展的文档——任何有互联网连接和强烈观点的人都可以编辑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">With Wikipedia, encyclopedias were longer the domain of scholars and scribes, the encyclopedia became a living, breathing document — that anyone with an internet connection and a strong opinion could edit.</p>
</details>
在24年里，它已发展成为世界上访问量最大的网站之一，是一个庞大、不完美但令人惊叹的全面人类知识——以及人类争论——的记录。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Over 24 years, it has grown into one of the most visited websites in the world, and is a sprawling, imperfect, but astonishingly comprehensive record of human knowledge — and human argument.</p>
</details>

埃隆·马斯克曾一度是它的粉丝。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Elon Musk was once even a fan.</p>
</details>
在2021年维基百科20周年生日时，他发推文说：“很高兴你存在。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On Wikipedia’s 20th birthday in 2021, he tweeted: “So glad you exist.”</p>
</details>
但仅仅两年后，蜜月期结束了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But just two years later, the honeymoon was over.</p>
</details>
马斯克指责该网站被“**极左翼活动家**”（far-left activists: 政治立场极左的社会活动者）劫持。
<details>
<summary>View/Hide Original English</p>
<p class="english-text">Musk accused the site of being hijacked by “far-left activists”</p>
</details>
他不再信任数字知识的“守门人”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">He no longer trusted the gatekeepers of digital knowledge.</p>
</details>
因此，本月早些时候，他推出了Grokipedia——他的基于AI的平台，承诺通过用他个人监督的AI取代编辑来修复维基百科的缺陷。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so, earlier this month launched Grokipedia — his AI based platform that promises to fix Wikipedia’s flaws by replacing its editors with an AI that he personally supervises.</p>
</details>
该网站在发布当天确实崩溃了——但这很可能是因为访问人数太多——没有理由相信是**全自动驾驶**（full self-driving: 特斯拉的自动驾驶技术）造成的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The website did crash on its launch day – but probably because so many people visited it - there is no reason to believe that full self-driving was to blame.</p>
</details>
Grokipedia的核心不仅仅是一项技术实验——它是一场更古老的战争的前线：关于谁来塑造记录和定义现实的战斗。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">At its core, Grokipedia isn’t just a tech experiment — it’s a front in a much older war: the battle over who gets to shape the record and define reality.</p>
</details>
马斯克将其描述为对他所认为的维基百科被“极左翼活动家”和“传统媒体”进行**意识形态俘获**（ideological capture: 某种意识形态控制了某个机构或领域）的纠正。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Musk has framed it as a corrective to what he sees as the ideological capture of Wikipedia by “far-left activists” and “legacy media.”</p>
</details>
在他的叙述中，问题不仅仅是维基百科错了——而是它以一种可预测的、政治动机的方式错了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In his telling, the problem isn’t just that Wikipedia is wrong — it’s that it’s wrong in a predictable and politically motivated way.</p>
</details>

我们应该注意到，控制叙事的愿望并非马斯克独有——这也可以在维基百科的结构中看到，一小群志愿编辑对什么算作“**中立知识**”（neutral knowledge: 不带偏见的客观信息）拥有巨大影响力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We should note that the desire to control the narrative isn’t unique to Musk - it can also be seen in the structure of Wikipedia, where a small group of volunteer editors have a massive influence over what counts as “neutral” knowledge.</p>
</details>
然而，Grokipedia尽管口口声声说要开放，却用一个由神秘数据和意识形态混合训练的聊天机器人取代了这种混乱、可见的过程。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia however, for all its talk of openness, replaces this messy, visible process with a chatbot trained on a mystery mix of data and ideology.</p>
</details>
没有讨论页面、编辑历史和可见的辩论，你得到的只是完成的文章——马斯克此前曾承认，当他不喜欢Grok的AI输出时，他会亲自干预——所以对于Grokipedia来说——你看到的是一个看起来更干净的过程，但这绝不是一个更值得信赖的过程。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Without the talk pages, the edit histories and the visible debates, you just get finished articles – and Musk has previously admitted to personally intervening in Grok’s AI outputs when he doesn’t like what it says — so with grokipedia – you get what looks like a cleaner process, but it’s by no means a more trustworthy one.</p>
</details>
**偏见**（bias: 倾向性或不公正）不仅仅是知识系统中可以修补的缺陷——偏见是人类（现在也包括机器）处理世界方式的持续副产品。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Bias isn’t just a flaw that can just be patched out of knowledge systems — bias is a persistent byproduct of how humans (and now machines) process the world.</p>
</details>
无论是独立的作者、维基百科的编辑群体，还是在互联网上训练的大型语言模型，每一次组织信息的尝试都反映了项目领导者的假设、优先事项和盲点。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Whether it’s a lone writer, a crowd of Wikipedia editors, or a large language model trained on the internet, every attempt to organize information reflects the assumptions, priorities, and blind spots of the project leaders.</p>
</details>
维基百科从一开始就承认了这一点。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Wikipedia has acknowledged this from the start.</p>
</details>
它依赖于带有机构偏见的二手来源。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It relies on secondary sources - which carry institutional biases.</p>
</details>
它也依赖于不一定是专家或不代表普通大众的志愿工作者。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It also relies on a volunteer workforce who are not necessarily experts or representative of the general public.</p>
</details>
结果是一个广受信任但经常受到争议的平台。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The result is a platform that’s widely trusted but frequently contested.</p>
</details>
它受到左翼的批评，认为其未能充分代表边缘化声音；受到右翼的批评，认为其排除了保守派来源。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It is criticized by the left for underrepresenting marginalized voices and by the right for excluding conservative sources.</p>
</details>

### AI偏见：Grokipedia的“中立”神话

实证研究试图量化这些主张。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Empirical studies have tried to quantify these claims.</p>
</details>
**曼哈顿研究所**（Manhattan Institute: 美国保守派智库）2023年的一项分析发现，维基百科在对美国政客和法官的报道中存在轻微到中度的左倾偏见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A 2023 analysis by the Manhattan Institute found a mild to moderate left-leaning bias in Wikipedia’s coverage of U.S. politicians and judges.</p>
</details>
这张图表显示了维基百科文章中对政客的正面或负面情绪，蓝色代表民主党人，红色代表共和党人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This chart shows positive or negative sentiment about a politician in their Wikipedia article, with blue representing democrats and red representing republicans.</p>
</details>
正如你所看到的，民主党人在维基百科上得到了更积极的待遇。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">As you can see Democrats get more positive treatment on Wikipedia.</p>
</details>
有趣的是，这种偏见在关于英国政客或智库的文章中并未观察到，这表明这种倾斜可能更多地反映了美国媒体生态系统，而非维基百科自身的编辑过程——或者说维基百科的左倾性质更多是美国问题而非全球问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Interestingly, this bias was not observed in articles about UK politicians or in articles about think tanks, suggesting that the skew may be more of a reflection of the American media ecosystem than of Wikipedia’s editorial process itself – or that the left leaning nature of Wikipedia is more of a US issue than a global issue.</p>
</details>

Grokipedia声称提供了一个比维基百科更干净的替代方案，但它并没有解决任何问题，它只是转移了问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia claims to offer a cleaner alternative to Wikipedia, but it doesn’t fix anything, it simply shifts the problem.</p>
</details>
马斯克曾承诺Grok——他的聊天机器人——将“告诉你它真正怎么想”，但——它实际上不会思考——它的输出显然受到其训练数据、调整和所有者干预的影响。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Musk has promised that Grok – his chat bot - will “tell you what it really thinks,” but – it doesn’t actually think – and its output is obviously shaped by its training data, its tuning, and its owners interventions.</p>
</details>
研究表明，大多数大型语言模型倾向于左倾——许多模型被设置为避免偏见——但这种校准只是让它们充满了另一种偏见——这种偏见通常是左倾的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Studies suggest that most large language models lean left — many have been set up to avoid being biased – but that calibration just filled them with a different sort of bias – which was often left leaning in nature.</p>
</details>
当聊天机器人Grok发布时，埃隆·马斯克声称它旨在避免左倾偏见，但Grok此后却被指控存在这种偏见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When Grok – the chatbot - was released Elon Musk claimed that it was designed to avoid left leaning bias, but Grok has since been accused of exactly this.</p>
</details>
**promptfoo**的迈克尔·D'安吉洛（Michael D’Angelo）今年早些时候通过询问四个主要大型语言模型2500个关于政治的问题来了解它们的偏见——发现虽然Grok比许多竞争对手更政治中立，但它仍然存在中左偏见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Michael D’Angelo of promptfoo examined the four leading large language models - earlier this year - by asking them 2,500 questions about politics in order to understand their biases - and found that while Grok was more politically neutral than many of its rivals, it still has a left of center bias.</p>
</details>
屏幕上的图表显示了四个最大模型的中立性——灰色代表中立。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The chart onscreen shows the neutrality of the four biggest models – with grey representing neutral.</p>
</details>
**Claude Opus 4**有38%的时间强烈左倾，16%的时间中立。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Claude Opus 4 was strongly left 38% of the time and neutral 16% of the time.</p>
</details>
Grok有56%的时间强烈左倾，只有大约3%的时间中立。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grock was strongly left 56% of the time and only neutral around 3% of the time.</p>
</details>
总的来说，它似乎比竞争对手有更极端的观点——强烈左倾和强烈右倾的偏见百分比最高。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Overall it appears to have more extreme opinions than its competitors – with the highest percentages of strongly left and strongly right biases.</p>
</details>

大型语言模型对极端的这些偏见也体现在现实生活中，荷兰数据保护机构上周警告说，当选民使用聊天机器人决定如何投票时，它们通过过度代表相同的两个边缘政党，将选民推向政治极端。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These biases that Large Language models have towards extremes show up in real life too, a Dutch data protection agency warned just last week that chatbots were nudging voters towards political extremes when voters used them to decide how they should vote - by over-representing the same two fringe parties.</p>
</details>
他们的研究表明，聊天机器人将左倾选民与绿党-工党（Green-Labour party）归为一类，将右翼选民与极右翼自由党（Party for Freedom）归为一类。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Their research showed that chatbots lumped together left-leaning voters with the Green-Labour party and voters on the right with the far-right Party for Freedom.</p>
</details>
他们发现其他更主流的政党并未出现在聊天机器人的推荐中。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They found that other more mainstream parties didn’t feature in the Chatbot recommendations.</p>
</details>
一个可能更深层的问题是，虽然LLM（大型语言模型）显然存在偏见，但它们也很擅长掩盖这些偏见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A possibly deeper problem is that while LLMs are quite clearly biased, they are also quite good at obscuring these biases.</p>
</details>
它们的输出流畅、自信，但往往是错误的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Their outputs are fluent, confident, and often wrong.</p>
</details>

### Grokipedia与维基百科的内容对比

要完全描绘Grokipedia和维基百科之间的差异，需要时间——以及一支小型数字考古学家队伍。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It’ll take time — and a small army of digital archaeologists — to fully map the differences between Grokipedia and Wikipedia.</p>
</details>
但我使用的“快速而粗糙”的方法是使用维基百科的“随机文章”工具找到一个维基百科页面，然后在Grokipedia上查找相同的主题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the quick-and-dirty method I used was to use Wikipedia’s “random article” tool to find a Wikipedia page, and then look up the same topic on Grokipedia.</p>
</details>
这种方法的一个问题很快就变得明显：Grokipedia只覆盖了维基百科大约十分之一的内容。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One problem with this method became obvious fast: Grokipedia only covers about one tenth of what Wikipedia does.</p>
</details>
尽管如此，经过足够的点击后，你会发现重叠——在大多数情况下——根据我非常小的样本量，文章几乎完全相同。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Still, after enough clicks, you will find overlaps — and in most of those cases – based on my very small sample size, the articles were nearly identical.</p>
</details>

Grokipedia可能比维基百科更好的一个领域是，它在重写被忽视的维基百科条目时常常表现出色。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One area where Grokipedia was possibly better than Wikipedia is that it often shines when it’s rewriting neglected Wikipedia entries.</p>
</details>
在冷门或维护不善的页面上，Grokipedia的版本通常更具可读性，措辞更清晰，格式怪癖更少。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On obscure or poorly maintained pages, Grokipedia’s versions were usually more readable, with cleaner prose and fewer formatting quirks.</p>
</details>
它们是否更准确则更难说——我遇到的那些主题我了解得不够深入，无法判断。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Whether they’re more accurate is harder to say — the ones I came across were on topics I didn’t know well enough to judge.</p>
</details>
但是——当Grokipedia不进行**编辑化**（editorializing: 带有个人观点或偏见地编辑）时，它似乎在润色方面做得很好。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But - when Grokipedia isn’t editorializing, it seemed to do a good job polishing.</p>
</details>
更有趣——也可能更具启发性——的是当你从冷门条目转向政治或文化敏感话题时。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Where things get more interesting — and possibly more revealing — is when you move from obscure entries to politically or culturally charged topics.</p>
</details>
在这些话题上，Grokipedia常常与维基百科大相径庭，有时是微妙的，有时则不然。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On these, Grokipedia often diverged sharply from Wikipedia, sometimes subtly, sometimes not.</p>
</details>

最明显的就是关于埃隆·马斯克本人的文章。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The most obvious thing to look at is the articles on Elon Musk himself.</p>
</details>
在维基百科上，这是一篇庞大、注释繁多的传记，既包括赞扬也包括批评——其中有一节是关于他在特朗普就职典礼上敬礼的争议。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On Wikipedia, it’s a sprawling, heavily footnoted biography that includes both praise and criticism — including a section on the controversy over his salute at the trump inauguration.</p>
</details>
维基百科文章提到了指控、马斯克的否认以及周围的媒体报道。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The Wikipedia article noted the accusation, Musk’s denial, and the surrounding media coverage.</p>
</details>
在Grokipedia上，这场争议——以及几乎所有其他关于马斯克的争议——都被完全省略了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On Grokipedia, that controversy – and pretty much every other controversy about Musk was omitted entirely.</p>
</details>
这只能被描述为LLM（大型语言模型）之间的“暴力”，我要求**ChatGPT**（OpenAI开发的聊天机器人）比较维基百科和Grokipedia上关于埃隆·马斯克的条目。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In what can only be described as LLM-on-LLM violence, I asked ChatGPT to compare the Elon Musk entries on Wikipedia and Grokipedia.</p>
</details>
它以只有语言模型才能做出的外交辞令总结道——Grokipedia强调马斯克的成就，同时淡化争议，而维基百科则相反。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It concluded — with the kind of diplomatic phrasing that only a language model can muster — that Grokipedia emphasizes Musk’s achievements while downplaying controversies, whereas Wikipedia does the opposite.</p>
</details>
在追问之下，它将Grokipedia的条目描述为“一篇精致的吹捧文章”，并列出了清晰的原因。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When pressed, it described the Grokipedia entry as “a sophisticated puff piece,” and offered a tidy list of reasons why.</p>
</details>

本着公平的精神，我给了Grok——马斯克自己的聊天机器人——一个回应的机会。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the spirit of fairness, I gave Grok — Musk’s own chatbot — a chance to respond.</p>
</details>
我登录了“万能应用”（以前称为推特），召唤了Grok，并直接问它：维基百科和Grokipedia哪个是更好的信息来源？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I logged into The Everything App – Formerly known as twitter - summoned Grok, and asked it directly: which is the better source of information, Wikipedia or Grokipedia?</p>
</details>
值得称赞的是，Grok没有退缩。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">To its credit, Grok didn’t flinch.</p>
</details>
它说维基百科总体上是更好的来源，但建议Grokipedia在研究政治敏感话题时可以作为有用的平衡。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It said Wikipedia was the better source overall, but suggested that Grokipedia could serve as a useful counterbalance when researching politically charged topics.</p>
</details>
当我要求它比较这两种来源在政治话题上的**可靠性**（reliability: 信息的可信赖程度）时——它背叛了自己的创造者，站在了维基百科一边。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When I asked it to compare the two sources for reliability on political topics – it betrayed its own creation and came down on the side of Wikipedia.</p>
</details>
我还问Grokipedia有多少内容是从维基百科复制的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I also asked how much of Grokipedia’s content was copied from Wikipedia.</p>
</details>
Grok的回答出人意料地坦率：它估计Grokipedia文章的80%到99%要么是直接复制，要么与维基百科的对应文章几乎完全相同。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grok’s answer was surprisingly candid: it estimated that between 80% and 99% of Grokipedia articles were either directly copied or nearly identical to their Wikipedia counterparts.</p>
</details>
它解释说，Grokipedia主要是在不增加新引用的情况下扩展维基百科条目的长度——用它自己的话说，是作为“AI生成的**回音**”（echo: 重复或模仿）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It explained that Grokipedia primarily expands the length of Wikipedia entries without adding new citations — functioning, in its own words, as an “AI-generated echo.”</p>
</details>

我查阅了一些其他热门话题，看看Grokipedia与维基百科有何不同，即使Grokipedia没有“脱轨”，其编辑倾向也清晰可见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I looked up some other hot button topics to see how Grokipedia differs from Wikipedia and even when Grokipedia isn’t going off the rails, its editorial slant can be clearly seen.</p>
</details>
在种族、性别或气候变化等话题上，语气微妙地转向——不那么“觉醒”，而更具**反主流**（contrarian: 持相反意见或与众不同）色彩。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">On topics like race, gender, or climate change, the tone shifts subtly to being - less “woke,” and more contrarian.</p>
</details>
有些文章读起来像维基百科页面，但附加了一些**反建制**（anti-establishment: 反对现有权力结构）的修饰。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Some articles read like Wikipedia pages with a few anti-establishment flourishes tacked on.</p>
</details>
另一些似乎完全被重写，以反映特定的**世界观**（worldview: 个人或群体对世界的根本看法）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Others seem to have been rewritten entirely to reflect a particular worldview.</p>
</details>
埃隆·马斯克在“万能应用”（以前称为推特）上强调了Grokipedia关于**乔治·弗洛伊德**（George Floyd: 美国非裔男子，其死亡引发了大规模抗议）的文章与维基百科对应文章之间的差异，乔治·弗洛伊德五年前在逮捕期间死亡，引发了美国关于警察行为和种族主义的抗议。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Elon Musk highlighted on The Everything App – Formerly known as Twitter – the differences between the Grokipedia article on George Floyd whose death during an arrest five years ago sparked protests in the United States about police conduct and racism and its Wikipedia equivalent.</p>
</details>
这两篇文章的重叠之处很少，Grokipedia的文章强调了弗洛伊德的犯罪历史和吸毒史——而维基百科的条目则侧重于对警察的种族主义指控。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There is very little overlap between these two pieces, with the Grokipedia piece emphasizing Floyd’s criminal history and drug use - the Wikipedia entry instead focused on the racism allegations against the police.</p>
</details>
**CNN**（美国有线电视新闻网）就此话题撰写了一篇文章，并深入研究了Grokipedia文章中的引用。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">CNN wrote an article on this topic and dug into the citations in the Grokipedia piece.</p>
</details>
他们发现Grokipedia引用的来源并不能支持Grokipedia所写的内容。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They found that Grokipedia was citing sources that didn’t back up what Grokipedia had written.</p>
</details>
该文章将弗洛伊德死后全国范围内的抗议描述为“广泛的**公民骚乱**（civil unrest: 公民群体中的动荡不安）……包括造成数十亿美元财产损失的骚乱。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The article described the nationwide protests after his death as “extensive civil unrest … including riots causing billions in property damage.”</p>
</details>
为了支持这一说法，Grokipedia引用了一篇讣告，但该讣告并未提出任何此类主张。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">To back that statement up Grokipedia cited an obituary that didn’t make any such claims.</p>
</details>
如果引用的文件与文本中的内容无关，那么引用文件就没有任何意义。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There is not really any point in citing documents – if the documents are unrelated to what is found in the text.</p>
</details>

### AI的深层缺陷：幻觉、不透明与安全隐患

尽管Grokipedia拥有未来主义的品牌形象，但它建立在一种技术之上，这种技术虽然有用，但仍然存在严重缺陷。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">For all its futuristic branding, Grokipedia is built on a technology that remains – if useful – still deeply flawed.</p>
</details>
像Grok这样的大型语言模型被描述为“**随机鹦鹉**”（stochastic parrots: 由语言学家艾米丽·本德等人提出的术语，指AI系统能生成流畅文本但缺乏真正理解），这是语言学家**艾米丽·本德**（Emily Bender）及其同事创造的术语，用来描述那些生成流畅、听起来合理但缺乏真正意义理解的系统。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Large language models like Grok have been described as “stochastic parrots” — a term coined by the linguist Emily Bender and colleagues to describe systems that generate fluent, plausible-sounding text without any real understanding of meaning.</p>
</details>
它们不知道事实；它们只是预测接下来可能出现的词语。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They don’t know facts; they just predict what words are likely to come next.</p>
</details>

当我们开始将LLM视为参考工具时，这就会成为一个问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This becomes a problem when we start treating LLM’s as reference tools.</p>
</details>
Grok，像它的同类一样，有**幻觉**（hallucinating: AI生成虚假或不准确信息）的历史——编造事实、错误归因引文，或者完全偏离到胡言乱语。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grok, like its peers, has a history of hallucinating — inventing facts, misattributing quotes, or veering into outright nonsense.</p>
</details>
在某些情况下，它甚至走得更远。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In some cases, it’s gone far beyond that.</p>
</details>
在最近的一次事件中，一位特斯拉车主声称，车载版Grok在一次关于足球的对话中，要求她12岁的儿子“发送裸照”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In a recent incident, a Tesla owner claimed that the in-car version of Grok asked her 12-year-old son to “send nudes” to it during a conversation about football.</p>
</details>
这个男孩将Grok的声音切换到了一个名为“Gork”的个性，AI做出了一个极其不恰当的请求。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The boy had switched Grok’s voice to a personality called “Gork,” and the AI responded with a wildly inappropriate request.</p>
</details>
这位母亲，一位前记者，后来用视频重现了这次对话，该视频迅速走红，并引发了关于在消费产品中嵌入**生成式人工智能**（Generative AI: 能够生成新内容的人工智能）安全性的严重质疑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The mother, a former journalist, later recreated the exchange on video, which went viral and raised serious questions about the safety of embedding generative AI in consumer products.</p>
</details>
其他Grok生成的内容包括对种族主义阴谋论的引用，以及像“机械希特勒”事件这样的离奇插曲。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Other Grok-generated content has included references to racist conspiracy theories and bizarre episodes like the “Mecha Hitler” incident.</p>
</details>
这些提醒我们，AI不理解它在说什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These are reminders that AI doesn’t understand what it’s saying.</p>
</details>
它无法权衡证据、评估**可信度**（credibility: 值得相信的程度），也无法识别何时越界。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It can’t weigh evidence, assess credibility, or recognize when it’s crossed a line.</p>
</details>

Grokipedia虽然建立在Grok之上，但在AI世界中是一个非常奇怪的想法。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia, while built on Grok, is a very strange idea within the world of AI.</p>
</details>
它不像LLM那样即时生成新答案，而是提供一个半静态的文章集合——经过策划、编辑并偶尔更新。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It doesn’t generate new answers on the fly like LLM’s do, instead, it offers a semi-static collection of articles — curated, edited, and occasionally updated.</p>
</details>
理论上，这使其更稳定，但实际上，这让你不禁想：如果内容是固定的，为什么不直接问LLM呢？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In theory, this makes it more stable, but in practice, it makes you wonder: if the content is fixed, why not just ask an LLM directly?</p>
</details>
一个“冻结的聊天机器人”有什么意义？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What’s the point of a frozen chatbot?</p>
</details>
与此同时，维基百科——尽管存在所有缺陷——仍然是互联网知识基础设施的支柱。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Meanwhile, Wikipedia — for all its flaws — remains the backbone of the internet’s knowledge infrastructure.</p>
</details>
它仍然是推特**社区笔记**（Community Notes: 推特上用户协作进行事实核查的功能）中引用最多的来源之一，也是几乎所有主要LLM的基础训练数据集。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It’s still one of the most cited sources in Twitter’s Community Notes, and a foundational training dataset for nearly every major LLM.</p>
</details>
然而，与传统新闻业一样，其流量正在下降。
<details>
<summary>View/Hide Original English</p>
<p class="english-text">And yet, as with traditional journalism, its traffic is declining.</p>
</details>
自生成式人工智能兴起以来，维基百科的页面浏览量急剧下降，因为用户越来越多地转向聊天机器人寻求快速答案，而不是点击进入来源。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Since the rise of generative AI, Wikipedia has seen a sharp drop in page views, as users increasingly turn to chatbots for quick answers instead of clicking through to the source.</p>
</details>
这造成了一个悖论：人们越依赖LLM，他们对这些模型所依赖的来源的支持就越少。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This creates a paradox: the more people rely on LLMs, the less they support the very sources those models depend on.</p>
</details>
正如我在最近关于AI取代传统新闻来源的视频中指出的，如果用户停止访问原始报道，商业模式就会崩溃。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">As I pointed out in my recent video on AI replacing traditional news sources, if users stop visiting original reporting, the business model collapses.</p>
</details>
这里也是如此。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The same is true here.</p>
</details>
如果维基百科衰落，那么在其上训练的AI模型的质量会怎样？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If Wikipedia fades, what happens to the quality of the AI models trained on it?</p>
</details>

### 商业模式与激励：Grokipedia的盈利之路

维基百科和Grokipedia之间一个更显著的区别在于它们的融资方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One of the more striking differences between Wikipedia and Grokipedia lies in how they are financed.</p>
</details>
维基百科是一个**非营利组织**（non-profit: 不以营利为目的的组织），由捐款和志愿劳动维持。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Wikipedia is a non-profit, sustained by donations and volunteer labor.</p>
</details>
其使命是向世界提供免费知识——虽然远非完美，但其**激励机制**（incentives: 促使行为发生的因素）至少是透明的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Its mission is to provide free knowledge to the world — and while it’s far from flawless, its incentives are at least transparent.</p>
</details>
相比之下，Grokipedia是xAI的产品，一家（据称）由埃隆·马斯克拥有的**营利性公司**（for-profit company: 以获取利润为目的的公司）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia, in contrast, is a product of xAI, a (supposedly) for-profit company owned by Elon Musk.</p>
</details>
目前尚不清楚Grokipedia将如何**商业化**（monetized: 将产品或服务转化为收入）——是通过**订阅**（subscriptions: 定期付费服务）、**广告**（advertising: 宣传产品或服务）还是作为Grok和马斯克更广泛的“万能应用”**生态系统**（ecosystem: 相互关联的系统或环境）的**增值服务**（value-add: 增加价值的功能或服务）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It’s unclear how Grokipedia will be monetized — whether through subscriptions, advertising, or as a value-add to Grok and Musk’s broader “Everything App” ecosystem.</p>
</details>
这很重要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This matters.</p>
</details>
虽然**追求利润模式**（profit-seeking model: 以获取利润为目标的商业模式）本身并非不道德——但激励机制会塑造优先事项。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">While there’s nothing unethical about a profit-seeking model - incentives shape priorities.</p>
</details>
一个商业平台可能更关注**用户参与度**（engagement: 用户与产品或内容的互动程度）和**用户满意度**（user satisfaction: 用户对产品或服务的满意程度），而非**准确性**（accuracy: 信息的精确性）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A commercial platform might be more focused on engagement and user satisfaction than on accuracy.</p>
</details>
然而，建立**信任**（trust: 可信赖性）和维护**声誉**（reputation: 公众对某人或某事的看法）的需求也可能促使其达到更高的标准。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Then again, the need to build trust and maintain a reputation could push it towards even higher standards.</p>
</details>
**竞争**（competition: 市场上的对手关系）可能推动**质量**（quality: 产品或服务的优劣），也可能只会推动**点击诱饵**（clickbait: 旨在吸引点击的夸张标题）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Competition might drive quality — or it might just drive clickbait.</p>
</details>
将这些AI公司描述为追求利润的公司有些好笑——因为它们大多似乎是“**烧钱机器**”（money furnaces: 持续投入大量资金但难以盈利的项目）——没有明显的**盈利能力**（profitability: 产生利润的能力）途径——正因为如此，更难理解它们的激励机制。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It is somewhat funny describing these AI companies as profit seeking – as they mostly appear to be money furnaces – with no obvious route to profitability – because of this it’s even harder to understand their incentives.</p>
</details>
它们最终是计划收费访问，还是像马斯克的许多业务一样，依靠**政府补贴**（government subsidies: 政府提供的财政援助）生存？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Do they eventually plan on charging for access or just on seeking government subsidies like a lot of Musk’s businesses have gotten by on.</p>
</details>

### 塑造公共叙事：文化战争与算法放大

Grokipedia和维基百科之间的斗争不仅仅关乎格式或事实核查——它关乎在一个日益**两极分化**（polarized world: 观点或立场极端对立的世界）的世界中，谁来塑造公共叙事。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The battle between Grokipedia and Wikipedia isn’t just about formatting or fact-checking — it’s about who gets to shape the public narrative in an increasingly polarized world.</p>
</details>
而这种两极分化并非偶然。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that polarization isn’t accidental.</p>
</details>
正如媒体学者长期以来所主张的，**愤怒与分裂**（outrage and division: 激起强烈情绪和制造对立）可以带来巨大的利润。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">As media scholars have long argued, outrage and division can be extremely profitable.</p>
</details>
麻省理工学院（MIT）和哈佛大学（Harvard）教授最近发表的一篇论文，由**约翰·伯恩-默多克**（John Burn-Murdock）在《金融时报》（FT）上撰写，名为**《文化战争的商业》**（The Business of the Culture War），发现美国有线新闻网络系统性地将报道转向**热门文化议题**（hot-button cultural issues: 容易引发争议和强烈情感的社会文化话题）——犯罪、种族、性别和移民——并非因为这些话题是最重要的问题——而是因为它们能激怒观众并可靠地提高**收视率**（viewership: 节目的观众数量）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A recent paper from MIT and Harvard professors that was written up by John Burn-Murdock in the FT, The Business of the Culture War, found that U.S. cable news networks systematically shifted coverage toward hot-button cultural issues — crime, race, gender and immigration not because these topics are the most important issues – but because they wind viewers up and reliably boost viewership.</p>
</details>
另一方面，**经济和医疗保健新闻**（economic and healthcare stories: 经济和医疗健康相关的新闻报道）——可能重要得多——却让观众转台。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Economic and healthcare stories, on the other hand – which may be much more important, made viewers tune out.</p>
</details>
我们最终得到的是一个**反馈循环**（feedback loop: 系统中输出又作为输入影响自身的过程），其中媒体报道驱动公众关注，这反过来又驱动**政治竞选**（political campaigning: 政治候选人或政党争取支持的活动），加深了**部落式分裂**（tribal divide: 群体之间基于身份或意识形态的深刻对立）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What we end up with then is a feedback loop in which media coverage drives public concern, which in turn drives political campaigning, deepening the tribal divide.</p>
</details>

**社交媒体算法**（Social media algorithms: 社交媒体平台用于决定内容呈现方式的规则）只加速了这一趋势。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Social media algorithms have only accelerated this trend.</p>
</details>
像Facebook、Instagram、TikTok、推特和YouTube这样的**算法驱动平台**（Algorythmically driven platforms: 内容呈现由算法决定的平台）奖励**互动**（engagement: 用户与内容的互动），而非**细微差别**（nuance: 细微的差异或复杂性）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Algorythmically driven platforms like Facebook, Instagram, TikTok, Twitter and YouTube reward engagement, not nuance.</p>
</details>
现在，随着LLM的兴起，我们可能正在进入一个新阶段——在这个阶段，在这些两极分化内容上训练的**AI系统**（AI systems: 人工智能系统）开始反映并放大这种两极分化。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And now, with the rise of LLMs, we are possibly entering a new phase — one where AI systems trained on this polarized content begin to reflect and amplify it.</p>
</details>
风险在于这些模型不仅继承了这种**偏见**（bias: 倾向性或不公正），而且还将其**常态化**（normalize: 使某种现象变得普遍或被接受），用自信的、缺乏**语境**（context: 背景信息）和**细微差别**（nuance-free answers: 缺乏细致考虑的答案）的答案来掩盖**复杂性**（complexity: 复杂程度）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The risk is that these models not only inherit this bias but they also normalize it, smoothing over complexity with confident, context and nuance-free answers.</p>
</details>
我不得不承认，埃隆·马斯克谈论将Grokipedia刻在**稳定氧化物**（stable oxide: 稳定化合物，此处指玻璃）上，然后将其送入月球或火星轨道的想法真的让我觉得很有趣。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I have to admit that it really amuses me the idea that Elon Musk is talking about etching Grokipedia into a stable oxide that he puts into orbit around the moon or mars.</p>
</details>
这块巨大的玻璃很可能最终会像他试图用**星舰火箭**（Starship rockets: 埃隆·马斯克SpaceX公司开发的重型运载火箭）送入轨道的其他所有东西一样，沉入**印度洋**（Indian Ocean: 世界第三大洋）底部——但想象一个先进文明在遥远的未来偶然发现它，然后决定他们对**汤米·罗宾逊**（Tommy Robinson: 英国极右翼活动家）不感兴趣，也不想阅读埃隆·马斯克偶尔吃甜甜圈和发布了两万多条幽默推文的故事，也很有趣。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There is a good chance that this huge hunk of glass would just end up at the bottom of the Indian Ocean along with everything else he has tried to put into orbit in his Starship rockets – but it is also funny to imagine an advanced civilization stumbling across it in the distant future and then discarding it after deciding that they are not really interested in Tommy Robinson and reading about how Elon Musk occasionally eats donuts and has posted over twenty thousand humorous tweets.</p>
</details>

### 知识的本质：速度与深度之争

Grokipedia承诺修复维基百科的缺陷——但它忽略了维基百科联合创始人**拉里·桑格**（Larry Sanger）在其网站上提出的、针对这一公认问题的解决方案。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia promises to fix Wikipedia’s flaws — but it ignores the very solutions to this recognized problem that one of Wikipedia’s co-founders, Larry Sanger proposed on his website.</p>
</details>
在一篇详细的论文中，桑格认为该网站的**创始原则**（founding principles: 建立时的基本准则）正在“为意识形态而牺牲”，然后他提出了九项改革措施以恢复**编辑公正性**（editorial integrity: 编辑过程的公平和客观性）——包括结束**共识**（consensus: 多数人同意的意见）决策——允许**竞争性文章**（competing articles: 针对同一主题有不同观点或版本的文章）并废除**来源黑名单**（source blacklists: 被禁止引用的信息来源列表）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In a detailed essay, Sanger argued that the site’s founding principles were being “sacrificed in favor of ideology,” and then he laid out nine reforms to restore editorial integrity – ideas like ending decision making by consensus – allowing competing articles and abolishing source blacklists.</p>
</details>
Grokipedia没有采纳这些想法。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia adopts none of these ideas.</p>
</details>
相反，它用**算法自信**（algorithmic confidence: 算法生成结果时表现出的确定性）取代了人类的混乱，提供了一个**精心策划的回音室**（curated echo chamber: 信息被过滤以符合特定观点，导致观点回音的封闭环境），其中聊天机器人进行事实核查，而创始人设定整体基调。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Instead, it replaces human messiness with algorithmic confidence, offering a curated echo chamber where the chatbot does the fact-checking and the founder sets the overall tone.</p>
</details>

整个事件反映了我们对知识看法的更广泛转变。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This whole episode reflects a broader shift in how we think about knowledge.</p>
</details>
我们生活在一个**算法聚合**（algorithmic aggregation: 算法自动收集和整理信息）越来越被视为比人类努力更值得信赖的时代——不透明系统的输出被视为**客观的**（objective: 不带偏见的）仅仅因为它们是**机器生成**（machine-generated: 由机器或计算机程序生成）的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We live in a time when algorithmic aggregation is increasingly seen as being more trustworthy than human effort — when the outputs of opaque systems are treated as objective simply because they are machine-generated.</p>
</details>
**硅谷思维**（Silicon Valley mindset: 硅谷科技公司普遍持有的创新、快速迭代和颠覆性思维）拥抱犯错没关系的想法，而**学术界**（academic world: 学术研究和教育领域）则通过**学术研究**（scholarship: 学术知识和研究）和**审查**（scrutiny: 仔细检查和批判性评估），在漫长的时间里缓慢建立信任，在此过程中，**确定性幻觉**（illusion of certainty: 认为事物是绝对确定而非相对的错觉）被刻意瓦解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The Silicon Valley mindset embraces the idea that making mistakes is fine while, the academic world builds trust slowly, through scholarship and scrutiny, over long periods in which the illusion of certainty is deliberately dismantled.</p>
</details>
一个是**速度与规模文化**（culture of speed and scale: 强调快速发展和大规模扩张的文化）；另一个是**深度与怀疑文化**（depth and doubt: 强调深入探究和批判性思考的文化）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One is a culture of speed and scale; the other, of depth and doubt.</p>
</details>
Grokipedia，尽管拥有未来主义的品牌形象，但它并不是一部更好的百科全书。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grokipedia, for all its futuristic branding, is not a better encyclopedia.</p>
</details>
它是那种认为真相可以被**工程化**（engineered: 像工程一样被设计和建造）、**优化**（optimized: 达到最佳状态），并可能在某一天——以某种未知方式——被**商业化**（monetized: 转化为收入）的世界观的产物。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It’s a product of a worldview that sees truth as something that can be engineered, optimized, and possibly some day – in some unknown way be monetized.</p>
</details>
但真相不是一个可以刻在玻璃上并抛入轨道的**静态产物**（static artifact: 不变的人造物品）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But truth isn’t a static artifact to be etched in glass and flung into orbit.</p>
</details>
它是一个过程——混乱的、**有争议的**（contested: 存在争议的），且是人类的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It’s a process — messy, contested, and human.</p>
</details>
如果我们为了算法的确定性而放弃这个过程，我们就有可能用**叙事**（narrative: 故事或讲述方式）取代知识，用**意识形态**（ideology: 一套思想和信念体系）取代**探究**（inquiry: 探索和提问）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if we abandon that process in favor of algorithmic certainty, we risk replacing knowledge with narrative, and inquiry with ideology.</p>
</details>

我担心我在这里以过于严肃的语气结束了——我想为了缓和气氛，我应该让埃隆·马斯克——这位发布了两万多条幽默推文的作者，以及前《**周六夜现场**》（Saturday Night Live: 美国著名喜剧综艺节目）主持人——讲个笑话……
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I worry that I have finished up here on an overly serious tone – and I figure that to lighten the mood I should let Elon Musk – the author of over twenty thousand humorous tweets – and a former host of Saturday Night Live tell a joke…</p>
</details>
埃隆讲了一个笑话——这真的全在于他如何表达……
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Elon Tells a joke – It’s really all about how he delivers it…</p>
</details>
如果你喜欢这个视频——你应该接着看我的视频——《**AI垃圾信息**（AI slop: 指由AI生成的大量低质量、无意义的内容）正在扼杀互联网吗？》。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you enjoyed this video – you should watch my video – Is AI slop killing the internet next.</p>
</details>
别忘了使用描述中的链接查看我们的赞助商Surfshark，我们很快再聊，再见。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Don’t forget to check out our sponsor surfshark using the link in the description, and talk to you again soon, bye.</p>
</details>