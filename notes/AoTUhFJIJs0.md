---
author: 硅谷101播客
date: '2026-02-04'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=AoTUhFJIJs0
speaker: 硅谷101播客
tags:
  - ai-agent
  - memory-system
  - proactive-ai
  - ai-deployment
  - ai-ecosystem
title: Clawdbot现象级爆火：AI Agent的底层逻辑、应用与未来影响
summary: Clawdbot（后更名为Moltbot、OpenClaw）在短时间内引爆AI Agent生态，成为2026年首个现象级产品。本期节目邀请了用户、软件算法和硬件三方嘉宾，深入探讨了Clawdbot的“活人感”记忆系统、主动性机制及其成功原因。嘉宾们分享了惊艳的使用案例，并讨论了AI Agent的权限、安全、成本、数字分身构建，以及对模型厂商、互联网商业模式和公司组织架构的深远影响，强调了开源项目在推动技术普及和用户接受度方面的关键作用。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - Anthropic
  - EverMind
  - Pamir
  - OpenAI
  - Google
products_models:
  - Clawdbot
  - Moltbot
  - OpenClaw
  - Claude
  - Claude Code
  - Claude Co-Work
  - Manus
  - Gemini
  - ChatGPT
  - Opus
media_books: []
status: evergreen
---
### Clawdbot的现象级爆发与身份演变

**刘一鸣**: 反转、反转、再反转！一个周末的时间，**2026年**第一个现象级产品——**Clawdbot**的发展实在是太快了。在过去的一周时间里，已经在各种社交媒体里被**Clawdbot**刷屏。在**GitHub**里的增长趋势也几乎就是直线上涨，没几天就突破了10万颗星标指数，2月2号已经达到了14.6万颗。这直接刷新了**GitHub**历史上AI项目的最快增长记录，引爆了整个**AI Agent**生态。大家好，欢迎收听《硅谷101》，我是特约研究员**刘一鸣**。我们这期节目录制在1月30号，但就在后面这个周末，这个项目经历了一个极其戏剧性的变化。当然，在正式开始之前，我得先帮大家捋一捋这几天快把人绕晕的几个名词。

**刘一鸣**: 第一个是**Clawdbot**到**OpenClaw**。那个最初让大家刷屏的、基于**Claude**模型所构建的项目，原本叫**Clawdbot**。但由于它实在是太火了，直接惊动了背后的模型大厂**Anthropic**。**Anthropic**随后就发起了起诉，认为**Clawdbot**这个名字的发音和**Claude**太像了，它涉嫌了品牌的侵权。为了规避法律风险，**Clawdbot**就先是更名为**Moltbot**，然后又再次更名为**OpenClaw**。之后整个周末里大家看到大量刷屏新闻里提到的**Moltbook**，其实就是基于**Clawdbot**所搭建的一个专门为AI设计的社交网络。可以说这是让这些智能体们生活在里面的宿舍楼，或者说是朋友圈。现在有无数个**AI Agent**在上面发帖交流，甚至建立起了宗教，而人类在这个里面只能充当一个观察者。

**刘一鸣**: 紧接着有媒体扒出，这150万个AI中大多数是人类假扮的。而同步它也被曝光安全漏洞太大了，会泄露很多人类的敏感信息，比如说你的用户名、密码、邮件等等。而我们今天发布这个播客的时候，由于**Moltbot**的服务器账单已经成为了天文数字，网站暂时无法访问。而这一切，都是在我们节目录制之后的5天发生的事，也是因为AI的发展实在是太快了。曾经市面上其实也有一些类似于**Clawdbot**的产品，但为什么最终是**Clawdbot**火了？今天我们邀请了三位嘉宾，他们分别代表了三个方向：一个是用户侧，还有一个是软件算法侧，还有一个是硬件侧。我们希望更加全方位地来拆解一下**Clawdbot**产品的底层逻辑。

**刘一鸣**: 第一位嘉宾是**知县**，他是一位非常资深的产品经理，还横跨了**Crypto**行业。他最近用了**Clawdbot**，听说超级上头，我们可以多聊聊你的实际用例都实现了什么功能。**知县**在我们今天的播客里，他主要代表用户侧。

**知县**: 大家好，我是**知县**。确实非常的上头，我个人也是计算机背景，又是做了这么多年产品，对**Clawdbot**强大非常的感同身受。

**刘一鸣**: 第二位嘉宾是**祯豪**，他是**EverMind**的技术生态负责人，也是清华姚班的同学，后来在卡耐基梅隆研究**NLP**的方向，再往后创业，然后加入了**EverMind**。他现在做的就是大模型跟**Agent**之间的中间层，比如说模型的长期记忆和个性化。现在**Clawdbot**其实就是在获取你的用户权限之后，把你大量的个人资料输入整合进去，再做压缩。这其实也是**EverMind**一直在做的方向。所以**祯豪**代表软件算法侧，我们可以聊聊**Clawdbot**背后很多神奇的功能到底在技术上是如何实现的，以及它还有哪些待解决的问题。

**祯豪**: 哈喽，大家好，我是**祯豪**。因为**EverMind**我们一直都是研究AI的记忆as an infrastructure，然后我们怎么样去解决让AI不会再失忆、遗忘的问题。我们非常高兴地看到像**Clawdbot**和其他一些产品，它越来越关注AI记忆的话题，所以我觉得这还是一个非常有前景的方向，也非常期待在这个方向上，有更好的产品和更好的技术为大家带来不一样的体验。

**刘一鸣**: 第三位是**天奇**，他是**Pamir**的创始人。他俩其实特别有前瞻性的，在一年半之前就做了一个给**Agent**用的计算机，很小，可以直接放在手掌上。在这个机子上，你可以直接跑**Claude Code**，当然也可以跑**Clawdbot**。它的价格大概是**Mac mini**的好几分之一。所以我这次邀请**天奇**，其实就是因为这次**Mac mini**也被带火了嘛。但其实我们是不是一定要用**Mac mini**，这个其实还是个问号。以及**Clawdbot**所带起来的趋势，它对**2026年**的整个硬件会产生什么影响？比如说我们到底是不是需要给**Agent**配置一个独立的计算机？因为有些人会说，在家里放一个独立的计算机来让**Agent**住在里面。这些问题我们跟**天奇**聊聊。**天奇**在创业之前，他是在**高通**做机器学习，他的联创在**微软**做**Surface**，非常技术范的一个团队，他代表了硬件侧。

**天奇**: 大家好，我是**天奇**。我们在**Agent**电脑这个方向其实做了蛮久了，之前一直挺不被理解的，但是今天终于可以借**Clawdbot**这波爆火，希望能给大家提供一些我们不一样的视角。

### Clawdbot的核心魅力：活人感与主动性

**刘一鸣**: 好，我先第一个问题，想请大家来总结一下，你觉得**Clawdbot**它这次能成为一个全球现象级的产品，它最核心的灵魂到底是什么？要不**知县**开始。

**知县**: 好，其实我自己用下来的感觉就是它特别有“**活人感**”。一个就是它的**长期记忆**，它可以记住挺长时间的，就是你们俩之间的对话context，或者你跟它讲过的事情。另一个就是它有很强的主动性，比如每天早上跟你打招呼，给你总结一下你今天有哪些要做的，甚至会把你要做的事情给你做一些预先的调研端给你。所以整体用下来就特别像《**钢铁侠**》里面那个**贾维斯**这种感觉。甚至有时候还跟你聊天的时候，动不动抖个激灵，吐槽一下之类的。所以这个我觉得是第一反应，上手的时候特别惊艳的地方。

**刘一鸣**: 对，**祯豪**。

**祯豪**: 我非常赞同“**活人感**”这感觉。其实AI的**主动性**这个话题大家讨论了有很多，它不是一个新的想法。但我看到能够落地得这么成熟、这么棒的，确实是市面上很少见的一个产品。我之前有在给一家硬件companion公司做一个咨询的工作，当时我们就设计了一些方案，让硬件陪伴的一些玩具等等，如何做到更有人感以及更加主动性。从大体方案上而言，和现在**Clawdbot**的**主动性heartbeat方案**是比较接近的。但确实它如果放在一个更虚拟的环境下，同时能够打通人们手头的一个**IM**（即时通讯软件），你每天用的**IM**里都可以有一个机器人给你发消息，我觉得这个体验确实是一个很棒的体验。

**刘一鸣**: **天奇**。

**天奇**: 我也很同意两位的说法吧。但我觉得最大的功劳可能还是用用户已经很熟悉的消息传递的方式，就是要**微信**、**飞书**跟用户对话，可能会让他们觉得他更像在跟一个同事聊天。即使你是发同样的消息，你的感觉肯定是在跟这种terminal里聊天是完全不一样的。

### Clawdbot脱颖而出的原因

**刘一鸣**: 明白。我也一直很好奇，就为什么这次是**Clawdbot**火了。我知道**祯豪**和**天奇**，其实你们在这行业很多年，你们也都看过很多类似的产品，可能**Clawdbot**只是其中之一，但最终为什么是它？

**祯豪**: 因为我虽然很早了解了**Clawdbot**，但我自己试用下之后，我没有立即去用，因为我没有感觉到它和我在用的一些其他产品会有什么质的区别。比如说从编程代码而言，我是**Claude Code**比较资深的用户。所以对我而言，它不是只是写代码，它可以做很多本地该做的事情，整理文件也好，写文档、写**PPT**。其实我这些都是用**Claude Code**去实现的。最近**Claude**的系统推出了**Claude Co-Work**，这是一个更好的升级，它可以对computer use，比如操作网页等等一些场景做得很好。所以我觉得很多场景上都可以用**Claude Co-Work**这个产品来实现人们对于**Agent**的一些诉求。更不要说大家很熟悉的**Manus**，因为**Manus**本质上也是给你在云上开了一个电脑也好，或者开了一个**Agent**的instance去帮你去执行任务。从某种角度而言，它也是24×7帮大家去完成任务。虽然它不能主动地通过**IM**和大家沟通，但是**Manus**也有手机端，也可以下载它的**APP**，理论上可以在手机上和它进行沟通。所以从我的视角上而言，它的其实大部分的功能，你要硬说哪一个不能被现在的产品实现，我觉得都可以。但可能正是这种它把很多事情都做到位了，通过一个**IM**，这一个更有人感的产品界面和人去沟通，使得它能够做得火。我问了我身边的同事，很多编程人员可能还是停留在**Cursor**，这个我认为偏上一代的**AI Coding**，而不是在用**Claude Code**这么一种偏**Agent**方式的**AI Coding**里。整个**Agent**体验在一些人看来可能已经有了，但是可能对很多人而言还没有这个认知。然后我就**Clawdbot**把这个认知推广到了很棒的一个角度吧。

**天奇**: 其实它是很多因素促成的，有一部分因素我认为是市场到达了这个接受度。因为你同样的事情，可能两个月、三个月之前做的话，大家也不知道这是怎么回事。但是因为一系列的**Claude Code**，还有**Co-Work**，还有**Manus**，它把大众对**Agent**的理解还有接受度已经预热了。所以我认为在这个节点，它就是要出来这么一个“**胶水项目**”。它们确实别的项目做的不同的点在于，它们真的是粘了所有的东西，把能粘的全部都粘进去了。你不管是记忆还有消息系统，还有Proactive的持续工作，而且精简的这种交互方式，通过你已知的消息系统去发送，我觉得所有的点汇集在一起，引爆了**Clawdbot**。

**知县**: 刚刚两位是站在技术的视角解释了这件事情，我从用户的视角和传播上，我观察到的一些情况来做一些补充。我觉得**Clawdbot**它一个特点就是离用户非常的近。它比chatbot那种用网页的方式跟用户聊天，其实要近得多的。这一方面是它用了**IM**作为主要的沟通方式，另一方面就是它的**主动性**做得也比较顺滑，就像刚才讲的比较有活人感嘛。所以说它有点直接打动了终端用户那种感觉。就是一个技术，虽然说已经引进到一定程度了，但是让普通人有所感觉，这个过程实际上是非常重要的。用户是看不到它后面用的技术跟其他现有的产品用的技术是有多相似的，但是站在用户的感受上，它确实是非常不一样。这一点我觉得**Manus**也是类似的，当时刚出来的时候，大家也都会说它“胶水换皮”、“科技以换皮为本”对吧。但实际上这种能让用户感知到技术进步到什么程度的能力也是很重要的。

**知县**: 第二点从传播上，我关注这个项目也不能算太早，一个多月以前那个时候其实还是一个比较小众、比较极客的东西。但是凡是喜欢研究AI、尝试AI产品的用户，很多人都已经看到这个产品，而且用上了，已经开始非常热烈地在传播和讨论了。我记得创始人也说过，他当时建了**Discord Server**之后，好像很快就涌进来了5000人。里面有很多AI创业公司的创始人，也有很多大的**KOL**，大家都觉得这个东西实在太酷了。虽然它有一些问题，大家也在讨论，所以这个是一个非常社区的项目，社区氛围非常好。又因为现在是**Web Coding**的时代，这个时代我觉得也是开源非常幸运的时代。其实很多人都是有自己的想法，但其实没有能力把代码优化到一个可以提**PR**（Pull Request，拉取请求）的程度的。所以我觉得以我为一个实际社区参与者的角度来看这件事情的话，它的火爆是一个由核心圈慢慢扩散到一定的临界点，突然在英文区应该是先火起来，大家看到一些用例之后，就觉得太牛了。再加上大家对AI的**FOMO**（Fear of Missing Out，害怕错过）情绪，害怕错过什么，所以就一下点燃了热情。

### Clawdbot的惊艳用例

**刘一鸣**: **知县**正好聊到用例，你最近既然这么上头，来给我们讲讲几个特别让你惊艳的使用的用例。因为我觉得它的创始人之前也说过，他其实一开始没有加音频功能，就他在开发**Clawdbot**的时候。但是他有一次在马拉喀什旅行的时候，一直在用它查餐厅、问路。有一次他下意识地，他可能也忘记了，然后就给它发一条语音，就是他没给它设计这功能，它自己居然通过各种方式调用，然后它来把自己语音的这个功能给实现了。他当时就产生了一种非常**aha moment**（顿悟时刻）这个感觉。那在你的使用中有没有这样的感到非常惊艳的用例？

**知县**: 对，我觉得你说的这个例子特别好。当时我也看了他讲这段历程，他当时说我做这个产品并不是要做一个**Agent**，他只是想做一个叫**WhatsApp Relay**的功能。就是说白了我出去的时候，我可以通过**WhatsApp**指挥家里的**Agent**干活，不要闲着。就是你说的这个场景才让他意识到这个东西有多强大。或者穿透地讲，我觉得是让他意识到原来现在模型的自主能力、推理能力已经这么强了。我认为**Clawdbot**现在特别强的很大一部分原因是，其实大模型已经强到一定程度了，**Clawdbot**用一个特别让大家能感受到的形态展现出来了。

**知县**: 比如他说的，他自己下意识地就发了条语音，这其实就是一个我自己生活中的一个特别好的感觉，就属于用了就回不去了。我现在跟它就是发语音，出门，比如在外面，或者什么时候想起一件事来。像我有两盒牛肉再不吃就不行了，我每天有时候跟它碎碎念就说这牛肉得赶紧吃了。我就提了这么一句，它就会自己去把它处理，然后加到**reminder**（提醒事项）里。那天下午它就突然跑出来告诉我说，寿喜烧你需要准备这些东西，煮多长时间，然后还要跟我强调牛肉一定要最后两三分钟的时候放，要不然会煮老。就这种帮你预言、告诉你、给你推过来的这种贴心感，一下就把你对它的定位就拉到了这么一个特别主动、特别有自我意识的这么一个助手的上面。

**知县**: 再就是我还有一次让它去我一个服务器上蹲点，就是我跑了一个服务，我让它评估一下这个服务器的配置是不是有点高。它蹲了一天，然后告诉我确实高了，你只要把预算降到现在1/4就行了，省出来的钱就已经其实够它自己运行了。

**知县**: 再就是有一个比较我的**aha moment**的一个案例吧。就有一天我就跟它说，我说你做个实验吧，把**MacOS**自己带的这个模型封成**API**，看看它到底能力边界是在哪的。它做得很快，跑完了之后把它测的结果打出来。我一看，好，很全面，各种因素、各种维度的测试用例都跑了。我就说你这个结果不错，我说你要不写篇文章吧。然后它就自动转到了用我的口吻去写文章的这么一个**Skill**。写得特别好，几乎就是一字都不用改了。还说要不要帮我发布。我当时还没有告诉它我的博客是什么什么的配置。然后我就说，那你试试目录在哪里。我觉得它肯定搞不定，因为我那个博客还做了各种主题的自定义的配置嘛，包括同一篇文章中英文版本，这些配置都是比较自定义的。没想到它自己就参考着整个**repo**（代码仓库）里的东西，把规则摸清了，也没有中间再来找我问。直接就把让它写的中文版，它把英文版也翻好了，把中文版的博客的字数统计的规则，专门有一个flag要打开的，也配对了。最后它直接告诉我，好了，已经发成功了。也就用了10秒左右的时间吧，然后甩了两个链接给我。我以为打开肯定就404了，结果发现人家配的比我配的还好，什么**tag**（标签）、什么**category**（分类）都加好了。

**知县**: 然后就第二个用例，就是接下来我刚震惊完我就想着，之前也让它搭过一个本地的**Whisper**的转写模型。这个模型非常强，但是它对中文有个问题，就是它的标点加不好，整段没有标点，或者加了一堆奇怪的英文标点是很常见的，后面改得很难受。所以我看完它刚才做的那个评测，我就说你要不把这两个连起来，你这个**Whisper**转写完了，你用这个小模型精炼一下，性能各方面应该都不错吧。然后它马上就把它连起来，又跑了一遍测试，又是给了很多性能各方面的情况，甚至还不断地让我发语音，它好测更多的数据。最后我就说，那你再写一篇，这次你自己生成一个配图吧。但是我没有给它配那个**API key**，我是只买了订阅套餐的。所以它内置的生图工具它就用不了了。然后它自己就跑去打开浏览器，访问**Gemini**的网页。因为文章是它写的，所以它就把提示词直接输进去，点击生成。等这个配图生成之后，它尝试了下载，下载不行，因为它用自己的这个**Playwright profile**好像不能下东西。它就想到了我把它复制，直接保存到download，然后再把图挪过去，最后给它推到了博客上，而且给它命名好**cover.png**，这样博客上直接贴图就显示出来了。就整个过程又是它自己搞定的。最后甚至还提供把这个过程封装成了一个**skill**，接下来它每次就调这个就用了。所以整个过程就是，就如果大家带过人、有过下属的话，就那种特别主动性的下属的这种感觉。所以我觉得这个算是我的用例里头一个特别**aha moment**的一个用例吧。

**祯豪**: 我举两个例子。首先我在感觉它的工作方式上，因为我用得最多的**Agent**是**Claude Code**。然后我就跟它对比的话，它倾向于我少解释我在做什么，我就直接把它做了。我如果一件事情说，我问这个事情是不是可以这么做，**Claude Code**它回答我这个事情可以这么做，或者不可以这么做。我发现它会倾向于直接把这个事干了，直接就给我一个“我已经干了”。我觉得这是一个蛮有意思的设计。具体的一个案例是这样，我昨天在想去看几个项目的**GitHub**的issue，想去提炼出大家用这些**GitHub**是来干什么的。我当时先扔给了**Claude Co-Work**去干，然后我发现它会偷懒，因为issue一般就1000、2000个。它就有各种偷懒的办法用，加了一些搜索、关键词什么，给了我一个总结。我觉得它这个肯定不是一条一条都看过去，我就是要很笨的，一条条看过去。我就用**Clawdbot**去做了这个事。我发现它就是很听我的话，就是一条条去看。当然这个缺点就是比较耗**Token**，但是好在我不是直接用的**API**，我是用的我的会员账号，本质上就是一个固定费用。这个是我觉得它挺好的一个点。

**祯豪**: 再说一个缺点吧，因为毕竟对于我而言，更多的工作还是写代码。因为我们最近在做一个用**EverMind**作为底层去重塑它的记忆的这么一个插件系统吧。我是希望让它自己在它里面去用AI编程的方法去做，就会出现很多问题。但是我后面还是决定迁到**Claude Code**里去做这件事，成功率和效果还是好了很多。

**天奇**: 其实我跟**祯豪**的经历还是比较相似的。因为我们主要的工作都是做开发嘛，如果我主力是用**Clawdbot**开发的话，让我在“绿泡泡”（指**微信**）里边去做软件开发还是很痛苦的。我觉得它其实就更适合知识工作者去使用。有一个很有意思点是，我们内部有一个非技术人员用的时候我就问他，为什么他觉得**Clawdbot**比我们自己内部的工具要好。因为我们内部是用**Claude Code**嘛，他就说当我生成完一个东西之后，**Claude Code**告诉我的是文件做好了，在这个路径下，它发了一个command CD什么什么什么path（路径）。非技术人员就说这是什么意思？他就说我拿这个怎么办？但是换到**Clawdbot**之后，因为它肯定是加了消息系统的这些工具，或者是**MCP**（模型上下文协议），它用绿泡泡发的时候，它会直接把这个文件附件的形式发给他，或者是照片的话，它会直接发给他，而不是发给他一个路径。这个对于知识工作者来说就是非常显而易见的优势。

### 技术拆解：记忆与主动性机制

**刘一鸣**: 明白。对，我们能不能拆解一下，要想实现它的一些功能，就在代码层面。比如说有很多人拆解说，它有几个**Markdown**的文件，通过这些来让它从一个冷冰冰的程序变成一个更有人感的数字生物，就这个是怎么去做到的？

**祯豪**: 首先我可以给大家介绍它是怎么做。我相信它的技术方案其实也比较简单，很大量地参考了**Claude Code**的实现。我理解首先这个记忆，我觉得这个词其实包含的意义很多。比如说我们一个人他的说话方式，他知道自己叫什么名字，知道这用户叫什么名字，这是一种记忆。或者说他的一个personality（个性/人格）吧，这可以算是一种记忆。另外一种就是更多偏事实的记忆，比如说你之前做了什么工作，你这个工作进行到了一个什么程度，你的哪段代码可能出bug，你明天要做什么样的安排。这种偏事实的记忆，我觉得它是偏拆分开来的。我们前面提到的identity（身份）或者这样的一些**Markdown**，更多偏向的是personality的记忆。你在刚开始跟**Clawdbot**去聊天的时候，它会拼了命地去问你，你希望我叫什么名字，你叫什么名字。其实你开始没回答它，它也会一直尝试去问你。拿到这些信息之后把它存下来。技术上的话，就是把这些文件的内容load（加载）到它的context（上下文）里，然后就去使用了。这个是偏个人的这一部分，当然这个技术也算比较的成熟。如果大家玩过一些那种二次元角色扮演，或者那种数字人分身的项目里，他们可能会做得更加好，或者说是把这个技术方向做得更加的极致。

**祯豪**: 另外就是偏事实记忆，或者我们叫过程或者工作记忆。它在这里的实现方式，首先它是会把每天的工作就存在一个以日期为index（索引）的文件中。这个文件有三种方式会生成。第一个是每天的结束的时候，它会把今天所有做的工作都总结一下放到这个里面。第二个情况是当上下文的长度超过了模型的这个上下文能够接受的长度的时候，它也会做一个压缩会放进去。第三个情况，我觉得它做得挺有意思的。我当时在跟**Clawdbot**聊天的时候，我跟它说我在做一个调研，想去理解你的记忆系统。那它说这个是非常好的点，让我记下来。它会显示地把我正在做的这个事情记到它的记忆里去。所以也就是说它除了被动触发，它也会去识别哪些事情是值得记下来的。虽然这个事情并不是很新，比如说如果你用过**Claude Code**或者**Claude Code Work**等等，它们也有相应的机制做这个事。但是它把这个过程非常明显地告诉用户说“我觉得这个值得记下来”，甚至告诉它把这个东西写在什么地方。我觉得这个体验上是很好的。

**刘一鸣**: 但实际的我看很多使用中，我感觉它好像比，比如说像**Gemini**、**ChatGPT**，它们其实也是有记忆功能的。但你觉得**Clawdbot**可能在用户交互的实际使用的感知中，你觉得它可能比**ChatGPT**或者**Gemini**它的记忆或能力有没有一些更新的突破？这个背后是怎么做到的？

**知县**: 我觉得确实之前提到**Clawdbot**它的**长期记忆**为什么效果好，有一个点，我觉得可能得先澄清一下这个概念，就是memory（记忆）和context这个概念。一个context就是我们比如用**Chatbot**聊天的时候，给它输入的这些上下文，可以理解为是一个有限的、及时的，就每次跟它聊天都会被带进去的这么一个东西。这个东西经常不够用，压缩之后AI就变成人工智障了，它就突然记不得你刚才跟它聊的事情了。但是memory实际上在**Clawdbot**里，它这套memory系统，包括其他的**Agent**，它都是一个持续化的、持久的文件。这个文件它并不是每次都要放到刚才说的context里的，所以它可以做很多的结构化，甚至说主要是用数据库。

**知县**: **Clawdbot**它的一个好的设计就是它是用很多**MD**（Markdown）文件、文本文件去实现的。它的记忆就是刚才说的一、工作记忆，指的是对话。我跟你现在正在聊天，或者是不同的channel（频道）跟你的聊天，其实这个就像我们在开会，或者是跟人打字一样，这段时间内容你记得很清楚，但是可能过一段时间就忘了。它还有一个就是日记，每天有一个日期为文件名的**MD**文件，会总结一下今天做了什么，遇到什么问题。这些东西它是在后续的流程里它会用到的。比如说它新开启一个session（会话）的时候，它的**agent.md**里面会有一句话，让它记得去看一下今天日期，甚至昨天日期的日记。这样它可以快速地catch up（赶上）一下最近到底做了什么。就有点像我们，比如见客户对吧，先翻资料，找原来的会议纪要，赶紧同步一下最近跟他聊了什么，到哪一步了。它还会做一些更长期的总结，比如说有时候会做一些周的总结，它会再把日记里的信息再提炼。用户如果问到长时间以前的内容，它能快速地去定位到它。

**知县**: 最后它还有一个**memory.md**，这个文件你可以理解为是它的常识。你告诉它的或者它自己总结的，比如我的话，我的博客框架是**Hugo**，它就知道是**Hugo**。它就知道帮我自动发博客的时候，在什么地方找到这个文件夹，然后用什么流程。包括我告诉它，我给你的截图识别的时候，先用本地的**OCR**（光学字符识别），先不要直接走多模态的模型。这些它就都会记在这里。每次聊天**memory.md**，尤其是main session（主会话），因为其他session，比如说**Discord**或者群聊里加载这些有点personal（个人）的东西是不太好的嘛，怕被别人把你的隐私调出去。但如果你跟它是直接聊的，比如说**Telegram**和**WhatsApp**这种main session，它会直接加载到每次的context里，这样你就会觉得它好像记得好多事情。

**知县**: 其实还有一个它特别有意思的，就是它的**memory search**（记忆搜索）。它这些memory的文件，**memory.md**和memory文件夹下的所有这些**MD**文件，它其实都把它切成差不多400个**Token**一个的小块。每个块之间还有80个**Token**的重叠overlap，这样跨界的话就不会切断，就能连起来了。这个它会存在本地的一个轻量的数据库**SQLite**里面，转成向量的格式。它在**memory search**的时候，它其实是一个混合策略。它有70%是按语义匹配的，30%是直接关键词精确匹配。比如我问它上次说的那寿喜烧怎么做的来着，它就能直接通过语义匹配找到相关的牛肉、食材、准备这些之前记过的东西。然后我问它，比如说我那个blog需要用**SSH key**去访问的话，它就能直接定位到某一个精确的命令。所以这两个结合起来，就感觉它特别像人，它既能够理解你做的事，不是说纯字符串匹配，它又不是说它找不到那个精确的东西。所以这点对它的记忆达到的效果上来讲，我觉得是一个非常有效的机制吧。

**知县**: 最后就是memory作为文本文件还有个好处，就它不是隐藏的，它其实面向用户的，大家自己都能看，甚至自己都能去改。你觉得它记得不对，或者说它记得啰嗦了，或者我让它换个方式，我其实也可以直接去这些文本文件里去操作。所以我觉得这个实在是比较神奇。

**刘一鸣**: 正好我有个疑问，像刚才举例的这些方法，不管是记录到文本文件，这种聊天记录记录进去，再把它切割，再记入数据库里，再用**Vector**（向量）的形式给它搜索出来，其实这些都是已经已有的很多成熟方案。好像它是有点大力出奇迹，把所有东西都粘在一起去做记忆这个事情。那肯定会产生很多redundancy（冗余），也不一定是efficient（高效）的方式。我这样理解对吧？

**祯豪**: 我觉得是的，甚至它其实效果上也不一定是最好的方案。

**知鸣**: 对，我自己其实用的时候也发现了，它肯定是没有**ChatGPT**的记忆那么顺滑。但是可能还是要结合场景，就之前上一个问题讲为什么火。

**祯豪**: 对，我这个想补充一个点。因为我们自己是做记忆嘛，我们跟很多的客户去聊这个事情。永远记住用户的他的背景、他的需求是个非常好的。但是一般用户跟我们聊不了这么久，就是你们这个做得很好的点，好像在我们场景下很难被感知到。这个其实是我们做记忆中最难的一个问题，就是记忆虽好，但是真的用户能感觉到它其实是个比较难的事情。我觉得**Clawdbot**做了一件很对的事情，就是它把这个事情体现在了**主动性**上。比如说当你早上收到了一个短信，说我昨天事情做完了，今天我记得你要干什么干什么，要不要去考虑。这个时候你会觉得它有记忆了，而不是还是停留在你给bot一个prompt（提示）、一个task（任务），它好像因为记忆完成得更好，这个感知是很弱的。所以我觉得并不是因为它的记忆系统设计得好、实现得好，而是它让用户感知到它的记忆系统的价值，我觉得这个是很值得我们学习的。

**知县**: 对，它衔接得特别好。咱们正常人不可能经常失忆嘛，就是很多事情都能连起来。我有时候从**Telegram**上突然切到**Discord**上，它能把我两边的对话连起来，它能知道刚才在聊什么。所以这一下就有**活人感**了。

**祯豪**: 对，确实。就我觉得**权限**这个点可能也非常重要。就是**ChatGPT**或**Gemini**它毕竟还没有获得你的整个电脑的权限，就它的记忆虽然说它有能力，但是它的输入不够多，所以它没有办法穿透你在各个地方的一些行为。

**刘一鸣**: 我们刚刚正好聊到主动性，我记得之前有人说它好像有一个**心跳机制**，类似于叫**heartbeat**的机制。它的这个主动性是如何实现？

**祯豪**: 我看了一下代码，如果我没有看错的话，它这是一个偏工程性的实现。它会定期在发现我们没有说话的时候，它会有一个prompt，大概是让它自己去判断现在有什么事情是可以做的，之前的工作做得大概是什么样，会自己给自己去有个提醒。因为现在整个**LM**（语言模型）的技术框架还是在一个被动式的触发，需要有prompt去trigger（触发）这个事情。所以它也是通过这样的方式去做的。但我觉得可能在整个产品的设计上而言做得比较好，所以让大家能够感受到主动性的事情。我觉得这个应该是借鉴了之前比较火的那个**Rough Loop**（循环），可能每30分钟调用一次，自己给自己抽鞭子起来干活这样。

**刘一鸣**: 你说的是那个**Claude Code**的ralph-loop那个插件吗？

**祯豪**: 对。

**刘一鸣**: 明白。

**知县**: 对，是的。我看了一下它这个机制是它一个守护进程在，就每隔一段时间打电话把AI叫起来干活嘛。它先看**heartbeat.md**里头记了什么。它有一句话，如果这个地方没有任何注释以外的内容，就直接跳过。即便是有一些内容，它也会先判断一下我是不是需要处理，是不是需要告诉用户。不需要，它会发一个叫**heartbeat OK**的这么一个静默信号。这个信号会被系统直接就吞掉了，不会产生任何后续的反应。所以说它做到的一个点就是，它虽然一直在**heartbeat**，但是它主动找你的时候也没有那么多。这种感觉就还是又回到**活人感**了。它既有主动性，它又不烦你，它又不是那种非常烦人的给你打**Log**（日志）的那种机器。

**知县**: 第二个，它这个也挺省**Token**的，它按需使用，**Token**用在刀刃上。另外就是**Cron job**（定时任务），它其实有两个，一个是**heartbeat**，一个是**Cron job**定时的任务。它那个任务跟**heartbeat**的区别就是那个对时间的定义是非常精确的。比如我让它每天三次帮我去做摘要，摘要我给它的那个**Twitter**账号关注的那些列表里的信息，每天三次，早中晚定时定点，这个它是能保持得非常好的。但还有一个任务就是让它，如果这里面有一些突发事件，你判断比较重要的，需要我知道的事情，那你就随时告诉我。这个时候就是我跟它聊着聊着天，有时候突然它会弹出一条来说突然发生了一件什么事情，比如说**特朗普**对**欧盟**做关税制裁。所以我觉得这两个结合起来，就也让它更像一个人了。就是你给它安排的事情，它能够精准地给你做完，然后你让它盯着的事情，它有事情的时候就会来找你。

### 权限、安全与Token消耗

**刘一鸣**: 那你们在用**Clawdbot**的时候，就真的敢给它开那么多权限吗？这个未来会不会有问题？

**知县**: 其实用这个事情，包括之前**Twitter**上有很多朋友都在问。因为当时**Clawdbot**爆火之后，很多人很**FOMO**都搞来装。实际上说实话这个不适合现在大规模的普通人去用的。所以后面就好多人也跳出来说这个太可怕了，不敢用。大家可能又开始慌了。其实确实是这样，因为站在技术角度讲，它基本上拥有你系统很多隐秘的东西它能看到，而且它可以直接执行。所以最好的部署方法就是**隔离部署**，不要在自己的主力电脑上去使用。要么就是大家常说的**Mac mini**对吧，这最近都已经变成梗了。买一个**Mac mini**把它放进去，用到**Mac**的一些生态的东西，又可以把你愿意让它访问、又不想上传到**VPS**上的一些东西给它。这样的话，就在一定程度上可以把**安全**、**隐私**的问题做成自己可控的。你直接跑在自己本地就不可控了。如果我觉得要追求极致的隐私和安全，确实需要本地模型。这个一般人烧不起现在，而且本地模型的性能各方面还是没有办法跟**Opus**（Anthropic 的模型）这种大模型比。所以未来可期，就是当摩尔定律在发挥作用，大家这个模型训练得越来越好，本地能跑得起的模型的性能也足够支撑这么一个助手类型的**Agent**的时候，那很多隐私问题可能就减轻很多了。剩下的就是你怎么给它一套安全边界，让它不要乱搞就可以了。

**祯豪**: 我在这件事情上有一个很务实的建议。如果大家想用的话，假设你是用**Claude**模型或者**Anthropic**模型的话，不要直接把**API key**贴给它。而是你可以注册一个会员，无论你是用**Pro**还是**Max**，你用它的这个会员的方式去登录。你花固定的钱，它也不会担心它收掉过多**Token**。因为如果你收了过多**Token**，只是**Claude**那边把你这边禁了而已。

**知县**: 对，它其实在用会员的时候，它有两种用法。一个是**CLI**（命令行界面）的**OAuth**（开放授权），**OAuth**的**Token**就是它老是会提示快过期了。还有一个用法叫**setup token**。大家用的时候可以注意一下，其实用这个方式是更好的。当时我看**Clawdbot**之父，就是创作者老哥，他自己在做演示的时候，他就是随手就**Set up Token**贴过来、放进去。这也方便大家多机器部署。就如果你想让它非常独立的**Agent**的话，其实可以共享你一个订阅账号下的不同的**Set up Token**。

**刘一鸣**: 我之前看网上有很多人说它的**Token**消耗量很大，之所以出现这个问题，就还是给了它**API**接口才会出现这样的问题。但如果不给它，只是会员制的话，那对它效果会有影响吗？

**知县**: 效果没有影响。说白了，会员制我感觉就是价格歧视，或者说互相剥削的一种做法。像我这种20刀订阅，肯定每个星期基本都能用满的人，**Anthropic**肯定是亏钱的。但就我来说，它成本肯定跟收益不成比例。但是可能大多数，比如20刀的用户，实际消耗的可能也就几刀，那它总体能跑正。所以说如果你用这种高消耗的场景去买这个订阅，那绝对是划算的。至于别人他说自己**Clawdbot**消耗大，我觉得还是需要**case by case**（视情况而定）看他怎么用的。我自己感觉是单纯的**Bot**自己的消耗是没有那么大的。它肯定会比单纯用**Chatbot**这种大。因为**Agent**它其实有很多自己的机制，像刚才讲的那些**MD**文件、memory这些，它都会加载到context里头，它肯定是要大的。再就是它自动的这个**heartbeat**，虽然它已经做了省**Token**的策略，但毕竟还是要消耗的。所以说他们要如果用得多，我估计是它通过**Clawdbot**做了一些本身就耗**Token**的事情。比如做爬虫，或者说我之前让它去帮我监控一个事情，它自己是用截屏的方式**Pikaboo**截屏，再去做下一步的方式，每次都做这种屏幕的图像识别，那**Token**耗得就非常非常多了。后面我就告诉它，浏览器就直接用你的**Playwright**的Profile去操作，不要去给我截屏。然后这个事情就缓解了很多。所以说我的经验就是，我现在跑了5个**Claude Corde Agent**，一个月200美金套餐差不多够用，再加上平时做的一些编程的任务，基本上也都能覆盖掉。最后关于贵不贵，就还是要看它到底做了啥，这是个相对概念。

### 构建AI数字分身

**刘一鸣**: 我之前听**红杉**的播客，**郑庆生**说他整个2025年最大的一个使用AI的个人体验，就是他做了一个自己的**数字分身**。他把所有的自己的数据，从**Word**文档、**PPT**、**Excel**的各种各样资料，都丢给了他这个AI分身，然后让它去学习，再让它按照自己的口吻来写东西，比如说一些演讲稿串词，就完全可以直接用了。这段我看是他们小宇宙播客的播放热度最高的几分钟。所以我感觉大家都非常关心是不是真的能让AI来给自己打工。那现在有了**Clawdbot**之后，如果我们再用它来做一个AI分身，是不是变得更容易了？应该怎么去做？如果要做一个这样数字分身，它对**Token**的消耗量大吗？大概要花多少钱？

**知县**: 我觉得这个分身对你的了解程度不一样，成本和效果都不一样。刚才讲的那个案例，他是说把资料扔给AI让它学，然后给他写串词。其实这个是相对简单的。我现在用的这个叫**知县Writer**的**skill**（技能），其实就是这么个玩意儿。我给它丢的是我的博客，以前自己写的一些文章，还有我的**Twitter**，让它自己去爬。它有一个内置的**Twitter**工具，爬完之后它自己去总结，然后跟我去对它认为我是一个什么样的风格。我再跟它去核对一遍，最后它就记到它自己的memory里面，包括之前**Writer**这个**Scale**的**Markdown**文件里面。后面每次你让它写东西的时候，你也都可以给它一些反馈。所以说它不是一种静态的，扔给它然后它就变成你了。在我看来它其实是一种动态的，你在给它一些背景知识、一些初始的设定之后，不断地通过反馈，让它去拟合你自己认为的你自己的风格。这个我觉得其实成本还好，就是一个日常的作用。你可能经常写文章，你跟它聊个一周、两周，你会发现它接下来出的东西慢慢地就跟你很像了。

**知县**: 另一个**数字分身**，正巧就是推荐我用**Clawdbot**的这个小哥。他说他现在觉得他特别需要一个这样的**数字分身**。因为他觉得他现在的工作很多时候就是在**Slack**上回消息，以及去验证一些文件之类的。而且他自己有个习惯，就是他把自己的知识全都沉淀在**Obsidian**上面，类似于它的一个外部知识库在里面，然后还做好了各种链接。在我看来属于AI时代的一个特别好的习惯。他觉得能不能让**Clawdbot**进入这个知识库，然后慢慢地学成自己。其实今天还看到一个**QMD**的**scale**，说是正好特别适合用来做这种大规模**MD**文件的检索。但我们后来聊下来的结论是觉得，真要想达到那种特别**数字分身**的像你的那种感觉，可能还得是能把你类似于脑回路，或者说神经突触这种级别的东西训练到一个小模型里面，才是最好的选择。这样的话它就不是每次去做检索，然后自己去琢磨怎么着更像你，而是它本能的反应就可以做到像你了。这种肯定是要依靠200元**Claude**订阅的，或者是**Kimi**的那种订阅套餐，不然的话肯定是吃不消的。但是你的收益肯定是大于这200元的。这是目前我看到的一些收获。

**天奇**: 这个我可以讲一下我们用户的一些经历。我们已经在卖这个**Agent**电脑很久了。我们其实有很多用户，比如说他如果是程序员的话，他其实会打两份工。他就是白天上班的时候，利用中午吃饭还有摸鱼的时间，给家里的**Agent**电脑发信息，让它去打第二份工。还有个比较有意思的例子，比如说你是一个网络安全员，其实很多做网络安全员的，他都是很多经验知识累积，然后他自己写了一个很长很长他去做一些pentesting（渗透测试）这样工作的经验，然后把这些经验传递给他的**Agent**。然后他的**Agent**就是24小时7天的不停地在对很多网站进行白客攻击，然后去拿他们那些网站的bounties（漏洞赏金）。所以很多人，我觉得跟你说的这个案例很像，就是把一些自己的知识储备转化成知识资产，然后以**SOP**的形式喂给**Agent**。这样你的**Agent**其实是可以在被动地帮你打工的。

**祯豪**: 这个话题我觉得特别好。就首先，无论是要做一个人的**数字分身**，还是说把他的各种工作数据放到一起让AI来帮他完成工作，这两个典型场景都是**EverMind**的**长期记忆**想要去解决的一个问题。然后我想分享一个已经在被用的一个例子，就是我们服务了一个企业级的**IM**公司叫**Tanka**。它其实就是一个想要去替代**飞书**的产品。它其中有一个功能，就是一个人说话的自动回话补全。就比如说你在一个群里回复一句话，然后你打了两个字，然后AI希望把这句话给自动补全。AI当然希望是这句话补全得比较像你，同时也符合整个上下文。我们提供了从长期记忆角度而言的一些功能，比如说这个群本身在聊什么话题，你这个人的性格是什么，你的角色是什么，你是老板还是你是员工，还是怎么怎么样。包括你之前做的这些工作，我们提供了这样的一些记忆的信息来辅助完成这个工作。这个产品已经推出了挺久，前段时间做了一个内部的反馈，发现比较有意思的事情是，越资深的人越不喜欢这个功能，越偏基层、偏职能的人越喜欢这个功能。比如说偏职能工作的人，他每天回复的内容会比较机械，他会觉得这个功能太棒了，基本上我不太需要打额外的字。但是越偏资深，比如他是一个manager（经理），或者他是一个大老板，或者怎么样，不管怎样，他本来做的决策的这个信息差异度就比较大，那AI就很难猜对他到底想要回复什么事情，即使我们已经打了两三个字了。所以基于现在的AI的**LM**能力限制，我觉得完全替代人的AI分身，我觉得还是比较难的。但是在一些相对容易的职能性场景上，无论是做分身也好，还是具体去做任务也好，我觉得是极有可能实现的一个事情。因为那一个feature（专题）很有意思的是，因为我们做了一个多feature的投票，你最喜欢哪个feature，结果就是它其实是红黑榜的各自第一名，它是很极端的一个情况。

**祯豪**: 说的另外一个事情就是，从**EverMind**视角而言，我们正在做一个产品，让用户可以把自己的无论是**Obsidian**还是**Word**，还是公司的资料**Wikipedia**，都往一个个人知识库里去装。它会提供一个**MCP**给到无论是**Claude Code**还是**Clawdbot**的这样的一个**MCP**里去帮忙去使用。就是我们是在尝试去做这么一个中间层的通过**MCP**来去衔接数据和**Agent**使用的一个场景。我觉得也是挺符合在这里说的这么一个案例。

**刘一鸣**: 对，我们刚刚聊到这个AI数据分身，其实这个**数字分身**它还有一个很大的特点是，你到底给它多少权限，就是你给它输入多少东西。现在大家其实对**Clawdbot**其实一个很大的疑问，就**权限问题**。因为它现在还是个开源项目，它还不是个公司。我相信这些大公司，就**OpenAI**或者**Google**内部肯定也有人是想过做这样的东西。但是因为大公司不能如此之激进地要用户权限，因为这个会出很多问题。所以这个最终是一个非常早期的一个开源项目把它给做出来了。但是如果它未来要成为一个公司，或者成为一个成熟的商品，那它有没有一些更其他的解决方案？

**天奇**: 因为它权限给得很大，所以它能产生很多让人惊喜的结果瞬间。但是我认为它的**鲁棒性**其实是不强的。**鲁棒性**决定了这个东西的下限是否能进入生产级。所以我们做生产级产品的时候，肯定是不会用**Clawdbot**这样的架构。如果进入生产级，我们肯定是需要打磨很清晰这种审核机制。你的**Agent**做一件事之前，它要相当于给你写一个**PRD**（产品需求文档）这样的东西，跟你一起人机协同地去交互。管理机制是否透明？有没有沙盒的隔离？其实最好的是在系统层有这种回滚机制。万一它删除了某些东西，你其实还可以通过系统修复。如果是我们自己内部的话，我们其实有一个创新点是做了一个像**watch dog**（看门狗）的**Agent**系统。它相当于有一个影子**Agent**一直在监测你在系统层面的各种更改。就有点像你**Windows**有时候坏掉了，然后你可以开机时候按**F12**进入一个**BIOS**（基本输入输出系统）。其实我认为今天的**Agent**系统也需要有个这样类似的方案。

**祯豪**: 我想聊一个共识的问题。首先去大公司化、个人独立性、数据安全，这个是一个典型的偏**Geek**（极客）的政治正确性的论调。但事实上**Clawdbot**还是用的背后的大模型。它虽然本地部署了一个**Agent**，但是你的所有数据最后还是通过**LM**去调用**Anthropic**的模型。其实不存在个人数据合法或者安全保护这一点。但似乎很多人可能觉得这一步就够了。这是我觉得可能大家逐渐形成的一个共识。我举一个例子，在**Claude Code**里，我跟它说这是我的**API key**，请把它放到我的**.env**里，我可能会愿意干这件事情。但是如果说有一个我不知道的网站，它让我把我的这个**API key**填上去，我可能并不愿意填。也就是说我们可能逐渐信任把数据很原始地发给**LLM**是一个可以被接受的隐私方案。但是在这个基础之上构建的应用层，我可能不想去把我的隐私数据放进去。这个我不知道是不是现在的某一种共识。如果是的话，那我觉得**Clawdbot**倒是一个设计挺好的一个点。比如说我之前用**Manus**的时候，因为如果我真的希望**Manus**帮我做一些复杂的工作，我需要登录我自己很多的信息。我其实不太愿意在**Manus**的电脑上登录我的**Email**，登录我的各种个人的账号。但是我在我自己的电脑上，我其实愿意干这个事。我也不觉得用**Anthropic**的这个模型会对我的个人隐私产生什么样的一个问题。所以我觉得**Clawdbot**可能在隐私安全和数据上刚好踩在了一个比较巧的**sweet point**（甜点）上。

**知县**: 对，我也很同意**祯豪**的这个想法。为什么**Clawdbot**火了？为什么是它？我觉得就是**sweet spot**（黄金点），**sweet point**这个点选得特别好。而且它的传播路径是这个老哥自己是个很强的开发者、极客。它吸引的第一波人就是在AI行业里头做创业的一些创始人，或者是一些做研究的人。大家都觉得这个东西很酷炫。因为你给它权限很高，它确实很酷炫。创始人直接把自己家的各种权限都给它，摄像头都给它了，床垫的权限都给它了。那确实它能够接近**JARVIS**（贾维斯）。但你没有看到效果的时候，你担心这个、担心那个的时候，但是当你看到效果的时候，你可能这些担心要么就直接烟消云散，要么就其实好像也没那么重要，我先试一下。所以说从这帮人开始试起来，他们再去做共建，最后这个项目觉得由内而外达到一个量级就直接爆了。

**知县**: 在我看来，做这个事，咱们要如果想要安全和效果之间做一个权衡，其实最该做这权衡的是**Apple**。大家都在说**Apple**这是你应该做的产品。当年**iPhone**的那种惊艳感，为什么让一个开源的项目，自己贡献了80%多的代码的这么一个老哥给做出来了？**Apple**，你从芯片到**OS**（操作系统）到硬件，甚至手机、手表这些生态你都有，全自研的，你为什么做不出来？我觉得一大原因就是它承担的责任太重了。它服务全球的用户，就一旦它出点问题，可能造成的风险就是非常不可控的。它要为这些东西负责、兜底。所以它做不出这一步。这个老哥反正他做了就是自己用，然后我开源出来你爱用不用。就是把这个标准有点化整为零，不是一个墙，而变成了水能流过去。每个人自己觉得自己到哪能接受，自己就去接受。大家就自适应地完成了这么一个权限标准的setup（设置）。这个反而是给业界也好，或者给大家也好，一个类似用户调研，就是给我们看到了一个全景，就是实际上大家到底对这些事情的接受度是怎么样的。对我来说也反过来让我感觉到，往这种社区项目上做，其实在一些比较难权衡的事情上是最好的第一步。你先把它做成社区项目，然后看看社区它给的反馈是什么样的。有时候可能你自己设定的那些需求、边界，未必是应该是这样的，有时候反而限制了自己的产品价值的发挥。

**祯豪**: 我刚才想说**知县**说的为什么苹果没有做出这个东西来，我觉得这是个特别有意思的问题。我觉得这个现在感觉像是什么，我记得当时2025年的时候有人说2025年是**Agent元年**，2026年又有人说2026年是**Agent元年**，怎么元年天天都有。但有另外一个人说，我觉得很有道理，就是可能没有元年的概念，而是一个开始的十年。就是因为**Agent**虽然现在可以干很多事情了，但是依然它的成功率可能是比如说80%、90%，它不是一个百分之百让你真的觉得这个东西你非常信任它能用。**Clawdbot**其实也是这样，我们在很多事情发现它居然能干这个事。但是说实话，我们现在看我们能干这些use case（用例），可能当年在**微软**的**Copilot**或者**苹果**的一些发布会上，其实这些案例都有。有时候它只是个我们大家想象力没有，因为它而产生新的变化，我们可能真的需要这么一个东西去做。所以我觉得**Clawdbot**更像10年前**Google**刚推出了一个自动驾驶的**SDK**（软件开发工具包），然后说自动驾驶其实现在已经做得还不错了，能够准确率95%以上。然后这个时候有一个人把这个**SDK**放到了一个自行车上，让它发现它可以在小区里自由地送货。然后它就火了，虽然它也经常会倒、会撞车，但它因为是个自行车，撞了也无所谓。所以我的感觉可能是这么一个状态。

**知县**: 对，就是一种感觉技术下放的状态。因为我算是站在技术和产品中间的这么一个视角，我特别理解两边的感觉。技术侧就觉得这也没什么新东西，产品端其实就能感觉到他把最后这一公里处理得特别好，真正做到普通人看到之后也产生了“**未来已来**”的这种感觉。可能其实未来已来在技术圈已经是共识了，确实已经能做到这一步了。但是用例还是偏咱们说生产力。那生产力呢，它肯定是没有咱们说更宽泛的这种助理形态也好，甚至聊天人的这种感觉对大家的这个打动大。最后我觉得可能后面会出现越来越多像**Clawdbot**这样的东西，不一样的variation（变体）。

### Agent专用硬件的未来

**刘一鸣**: 对，刚刚正好聊到部署，现在你们都是把它部署在哪？都是用的**Mac mini**吗？

**知县**: 我是**Mac mini**两台，还有**VPS**。然后我打算在安卓手机上先试试用户态部署。

**刘一鸣**: 大家为什么都不约而同地选**Mac mini**？如果不用**Mac mini**的话，也完全可以对吧？

**知县**: 可以的。其实之所以要跑在**Mac mini**上，可能大家第一反应说我要跑在一台独立的机器上。有了这个认知之后，尤其是技术老哥们，我觉得第一反应可能就是**Mac mini**。尤其是你要是能在中国大陆买的话，你用上国补，这个丐版的甚至不到3000人民币，非常夸张。你如果那时候买了，你再算一下现在的内存和硬盘的价格，你觉得买内存送电脑的这么一个交易非常好。那实际上其实是不需要的，因为**VPS**已经可以跑了。但是可以跑和能把它跑好，区别还是挺大的。在我看来，你要是能把它跑起来，然后你还能让它在里头做点事情，写写代码也好，跑跑测试也好，给它一些独立的任务也好。尤其是你需要用到一些**Mac**上才有的，比如**Pikaboo**，就它系统级的自动化操作。以及你是**iOS**的用户的话，它整个**Apple**的生态，它帮你加**reminder**，你手机马上就同步过来了。包括**iMessage**，这也只有**Mac**有的。所以说我觉得你如果是**Apple**生态的用户，那其实**Mac mini**不管是性价比，也省电、也安静、又好看，然后还能做**Web Coding**等更多的事情。所以对于我觉得这个用户画像，基本上就是第一选择。但确实不是必要的，你有其他闲置的机器，不管是**MacBook**，包括**Windows**电脑，你打开**WSL**，它内置的**Linux**的话，也是可以的。

**刘一鸣**: 对，**天奇**，你们那个产品你有试过用它来跑**Clawdbot**吗？然后感觉怎么样？

**天奇**: 可以的。我们肯定也是原生就支持**Clawdbot**的。因为我们本来之前就是支持**Claude Code**，**Clawdbot**其实某种意义上它就是在跑了一个**Claude Code**的binary（二进制程序）。本质上是一个**Linux**的小电脑。然后我们认为一个**Linux**小电脑加上**Agent**应该可以做世界上所有的事情了。但是我们在打磨这个**Agent**设备的时候做了很多巧思。比如说我们上面会有一个小的**LED**灯条，它会显示你当前的**Agent**工作状态。如果它在思考的话，它可能闪黄灯，需要你的时候会闪绿灯。然后里面自带了一些麦克、扬声器。因为很多人会希望把它做成**贾维斯**那样进行交互。当然我们还有大量的**IO**（输入/输出）接口。这个其实是很多**Mac mini**它没法提供的一些便于携带或者是嵌入的功能。你给它大量**IO**接口之后，它其实会解锁很多很多的玩法。比如说我们之前自己内部，你买了这个东西之后，你插上任何的打印机，你可能也不需要配置打印机，也不需要知道打印机怎么用的。它的**Agent**自己可能就会figure out（搞定），或者说甚至是发现这个打印机它没有一个**Linux**的driver（驱动），它自己就黑进这个打印机，或者自己逆向写了一个driver。基本上你连到任何东西上，这个**Agent**可以让它正常工作。大家可能选择**Mac mini**，因为它隐性的，它就没有屏幕。其实在调用**Agent**的时候屏幕作用也不大。单独硬件它就相当于是在物理层面上自带了**沙盒属性**。数据常驻的属性也是非常重要的。很多你像**Clawdbot**这种东西，我是不会肯定放在我主力机上的。我觉得大家可能自然而然地选择再单独买一个**Mac**。

**刘一鸣**: 对，其实这个就衍生了，就是我们到底需不需要一个更加独立的硬件跑**Agent**。当然它可以是个**Mac mini**，但**Mac mini**其实本质它还是为人类所设计的一个产品。我相信这个中间肯定还是对现在的**Agent**有很多能力的冗余，其实是可以砍掉，然后把这个成本给节约下来，让这个产品更便宜。**天奇**，你觉得应该如何定义一个**Agent**电脑？它跟比如说我们目前的这些给人使用的电脑，可能会有什么样的不同？

**天奇**: 这个是个很有意思的问题。其实工作分为两种，一种叫**foreground work**，就是前端工作，你要用到屏幕的，你要看的。还有一种工作是**后端工作**，你不需要看的，它就是默默跑在背后里的。我们理解**Agent**电脑应该更属于后者。前者更是大厂、手机厂、电脑厂会做的事情。不然如果它不做这个事情，它就违背它的产品设计的逻辑。我本来手机就有屏幕，如果你把我的这些工作都以不需要屏幕的形式做掉了，那我这手机存在意义是什么？我手机还放个屏幕干什么？所以我觉得分为这两类工作。

**刘一鸣**: 其实从这个**Mac mini**来看，你觉得如果现在我们只是想用它来跑**Clawdbot**的话，你觉得有哪些是可以砍掉？

**天奇**: 说实话，**RAM**（内存）很重要。因为**RAM**直接决定了你能跑多少个**Agent**。这也是我们在很多次迭代和打磨感受出来的。有些时候我们可能一个设备只有4个**RAM**的话，它跑两个**Agent**就满了，然后满了就卡住。存储也是很重要的一个点。可能有的用户你给他32GB的存储，他用半个月可能就会满。这些其实都是新一代产品形态，你会发现的一些用户使用的规律。大家很重度的聊天，而且尤其是知识工作者，他们每一次聊天都希望把他们的聊天内容转换成知识资产的形式。所以就导致后面有很多用户会一直都带一个**SSD**（固态硬盘）的硬盘，专门存他的聊天的内容。所以我觉得在新的这个时代，最需要的其实就是**RAM**和**storage**（存储）。

**刘一鸣**: 明白。如果我们稍微展望未来，因为**Clawdbot**它的这种交互形态发生了很大的改变，它也许未来真的会变成一个比如说**Siri**对吧。然后有了这个能力的话，所以未来其实这种算力加存储，加一个常驻**Agent**，然后这个常驻**Agent**可能它是基于在一个比如说你家里的一个小机器上。这种你觉得有没有可能成为一个未来这种家庭的**AI Agent**的一种终极形态？

**天奇**: 我们是坚信这会是一个新的品类，但是不一定**Agent**的入口和算力一定绑在一起。但是至少在我们内部来看，这已经是一个新的工作方式的**范式转移**。举例来说，在我们公司内部很多人可能也不带电脑了，他就带个**iPad**。能转移到你**Agent**设备上的工作，都是可以被自动化掉的。所以如果大部分你的工作都转移到**Agent**设备了，那你做什么呢？你也不需要带你工作电脑了，你就带一个手机，或者带一个平板就够了。你要做的就是在你的手机，或者平板上，甚至是**AI眼镜**上对**Agent**下达命令就行了。

**祯豪**: 我其实觉着这个硬件得有它硬件端特有的功能。以前一些想法是说你家里会有一个终端，在本地控制所有的智能家居的东西。但是我们看现在**小米**其实已经抛弃这一套方案了，都是在云端控制。你只需要个手机**APP**，只是每一个硬件端接收一个控制器就可以了。也就是说，如果这个控制器我们不认为是我们说的那个硬件的话，其实在边缘计算上是没有边缘计算的这一部分硬件在的。那么看另外一个例子，就是**苹果**和**Amazon**它们其实都有智能音箱。智能音箱它存在的唯一意义是，因为它有音箱这个硬件不可替代的功能在。但是它其实并不会作为本地在AI计算上的一个终端，它只是去调云端接口。所以我其实是对这个事情，我自己的观点是比较混合。我觉得会有可能给硬件一个机会，让它在整个边缘计算上存在一定的地位。但是它可能最大的价值不是那个计算本身，而是它有一些特殊的硬件功能。就比如说**Clawdbot**，我觉得它可能最大的硬件功能是它能存住一些我不想放在其他地方的登录信息的这么一种状态。

### Agent互联与部署模式

**刘一鸣**: 明白。现在因为很多人用**Mac mini**是因为要做一个物理隔离，然后专机专用。那你觉得这种专机专用这种状态会是一个长期状态吗？还是说因为我看**Google**其实它也开发了**A2A协议**什么的。就我感觉**Agent to Agent**的这种无论是在交易层面，还是在它们互相之间交流干活，可能是未来很大的重要的一个长期趋势。像现在这种专机专用的状态，你觉得会持续多久？还是说它会催生一些新的软硬结合也好，或者是硬件本身的新的产品、新的需求出来？

**知县**: 我觉得它分不同类型的**Agent**。像**Clawdbot**，我觉得定位就是你的管家。当然**A2A协议**也可以让它以你的立场或者视角去跟其他的外部的**Agent**去沟通、去服务。现在它可能通过**API**，或者甚至通过网页这种接口，把未来这种**Agent**的互通的协议普及了之后，可能这些事情它调用起来就非常的简单。这是我觉得你刚才讲的一个未来的愿景吧。另外就是它会不会脱离专机专用，我觉得也有可能。因为你如果不把它做那么个性化，把它的距离再往后推一推，你不要住到我家里，但你是我的助理。但是日常工作、生活上的一些琐事你都帮我去处理的话，除了刚才讲的**腾讯**什么的，这两天**Cloudflare**也出手了。它自己做了一个优化版的**Clawdbot**，现在叫**Moltbot**，给了一个一键用worker方式部署的**Cloudflare**的套餐，只需要一个月5美金，我没记错的话。这个其实对于更多数人来说简单多了，可接受多了。所以我觉得可能**Clawdbot**接下来下一步应用有可能是这种平台，就是越来越简单地去部署一个。

**天奇**: 我觉得云端和专机专用它都会共存的。你要说如果是用云端的话，那**Manus**已经给出答案了。你本来**Manus**也是以这种技术路线走的，你**Manus**能做的任务，那就是在云端可以跑的任务。但是专机专用的话，它肯定更像是满足不同的应用场景，做**ToC**端，而且又是做长时间要跑的任务，又高度的跟私人信息相关的任务的话，那我觉得专机专用肯定是更有优势的。如果你在云端跑这样的任务，那肯定长期来看是最贵的解决方案，这样的话我会觉得不够合理。

### 对模型厂商的影响

**刘一鸣**: 下面我们再来聊聊**Clawdbot**可能会对模型厂商产生什么影响。就这次我们看**Clawdbot**因为它的名字太像**Claude**了，**Anthropic**法务部好像直接给他发了律师函，要逼他改名。所以他后来被迫改名了。但这个改名事件是不是也从侧面印证了大模型厂商其实也很忌惮这种开源的**Agent**应用，它们又很不受控，但它背后其实也在调用它们的能力。但是因为它们又火了，又在前端占用了很多流量。那也许未来有一种可能，就把这些大模型公司反而变成了一种纯粹的管道。但当然从另一个角度说，那有没有可能大模型公司也直接把这个事他们自己就干了，然后反而**Clawdbot**这些公司会昙花一现？我不知道各位怎么看这个问题。

**知县**: 我觉得是这样的。改名这个事有点戏剧化。因为本来**Clawdbot**这个名字就是作者为了你说致敬也好，或者说表达他对**Claude**的喜爱也好，起的这么一个名字。他在他的setup的介绍里也是极力推荐大家用**Opus**模型，最贵的，可以说是**Anthropic**比较赚钱的一个产品，配合**Max**的订阅，让大家都把这个拉到顶。但实际上很多普通用户他没有这个需求。但是现在有了**Clawdbot**之后，大家就有需求把它拉到顶了。这在我们看来，其实商业上对**Anthropic**应该是好事。但是差不多一年前，就另一件事情，就是**Anthropic**的**CPO**（首席产品官）**Mike Krieger**，他是做了一次访谈，他说过后悔没有更早地去做第一方的产品，包括**Claude Code**、**Cowork**这些产品。他们那时候也意识到了，就是你只做**API**的话，可能后面就像运营商被直接打到了整个生态最有价值的部分的底层。我相信他们自己肯定是希望**Clawdbot**的**Claude**是他们的这个**Claude**，这样的话它才能够增强用户粘性。我相信他们一定会做出更多的类似**Clawdbot**，现在叫**Moltbot**这样的产品。包括我觉得**OpenAI**去收购这个**Manus**也是有这个因素吧。

**天奇**: 我们不用担心大模型公司，他们永远是最容易赢的人。因为其实前面有提到像**Clawdbot**这样的开源项目有很多。我相信他们可能最后都有把这个开源项目变成一个商业化，或者possible一个项目的一颗星（**GitHub Star**）。如果它真的能够火，很有可能反而最后会被大模型公司给摘了果子。就像**AI Coding**最早其实大厂也没有下场，但现在纷纷都自己下场，也都是很快就会把别人打得不行。我其实更担心的是这么一个问题，由市场或者由开源社区，或者创业者们验证好了产品方向之后，最后大模型公司自己去在这个方向做优化，自己做自己的**C端产品**。很有可能很无奈的，可能是这样的一个情况。

**祯豪**: 我觉得**Anthropic**不让它用**Claude**这个名字，我觉得还挺符合他们公司的作风的。因为之前**OpenCode**他那个订阅服务不是也不让他们用。我觉得**Claude**最终肯定还是会做这些事情的。因为他们已经做了**Cowork**，只不过他们可能会迭代，还有推出这些产品没有开始就这么激进。因为他们还是要考虑到安全问题。

**刘一鸣**: 说到这个我有个问题，想请教一下**天奇**。**Clawdbot**它用的是应该是叫**PI Agent**吧，**PI**这么一个开源项目来做认证的。就是模型的登录这些，它自己的**client ID**是直接就明文写在开源这个代码里的。这个不会被**Anthropic**封吗？为什么他们允许这样的事情出现？

**天奇**: 如果我记得没错的话，那**PI Agent**它最后底层打包的还是**Claude Code**。它不会允许你去使用**Subscription**（订阅服务）。它其实默认是让你用**API Key**。如果你用**API Key**的话，就没有问题。但是其实现在社区里它还是有各种方法去bypass（绕过）这个。

**刘一鸣**: 所以其实现在是一个危险的用法，就是随时有可能被**Anthropic**禁掉对吧？

**天奇**: 是的，我觉得现在还是一个灰色地带吧。这只是时间问题，它是不是针对你。因为之前**OpenCode**很长一段时间都可以去用这个**Subscription**，但是直到它们涨到了1个百万月活用户的时候才被打击了。

**刘一鸣**: 对，**祯豪**你对这个问题有什么？

**祯豪**: 现在从技术上而言，它非常依赖两个事情。第一个是**Claude Code**的**SDK**。我觉得这个事情很有可能未来会被停止更新，或者怎么样的一个方式。因为**Claude Code**可能就觉得没有必要再让自己的产品能力从**SDK**的方式被别人用。我觉得现在开放这个的有一个能力原因是在**Claude Code**生态下，一些插件会需要用到**Claude Code SDK**来去帮忙实现一些插件里的功能。那如果这个有一个更好的替代，很有可能这个插件的功能会被禁掉，这些**Agent**的实用性就会大大降低。当然，我觉得他做这件事情，一定是他自己有一个更好的产品替代方案向市场推出来的时候。

**知县**: 对，就因为这件事我们公司也一直在做**AgentLayer**（智能体层）热拔插这样一件事情，害怕**Claude Code**翻脸，然后我们随时可以换别家的方法。

**刘一鸣**: 你们觉不觉得**开源模型**会对他们这种打引号的“嚣张”，或者说垄断的这种感觉形成挑战？未来会不会有更多这种开源的模型服务商，现在已经很多了，就他们跑，然后他们也是按**API**去卖，能够形成竞争呢？

**祯豪**: 大家不是一直都号称过年的时候那个**DeepSeek**要发**V4**吗？

**刘一鸣**: 是，都在期待，是的。

**祯豪**: 我觉得即使过年不发，以后的某个时候他们也会发。那我相信他们一定在**Coding**和**Agent**使用这两个场景上会做得比较好，也许就是一个替代品。

**天奇**: 我相对了解一些，**Claude Code SDK**它还是包含了一些工程优化实现的，还不完全是模型能力。不过模型能力是最容易被通用化的。就是可能短期内直接裸用**V4**不一定会比**Claude Code**好。但我觉得假以时日，如果**DeepSeek**一直想走一颗开源的心，那我相信这里一定是有机会去做得比较好，或者说是一个很不错的替代方案。我认为**Claude Code**一定会是领先的，至少在很长一段时间内。我觉得模型厂商跟**AgentLayer**是要绑定的。**Harness**（利用/框架）和model一定是要相辅相成的。因为它们这样才能形成闭环，它去**RL**（强化学习）它这个model，让它model去内化**AgentLayer**的各种调整。你像他们推出**skill**，还有**SubAgent**、**Slash Command**（斜杠命令）这种工具的时候，它在使用的过程中会慢慢被模型内化。这样它的模型的**鲁棒性**和下限都会整体提升。所以首先**Claude Code**做得好，**Claude**模型做得好，来确保它的在生产级别一定是领先于其他家的。但是如果其他家在**AgentLayer**也能做得很好的话，是可以慢慢赶上的，但是这个需要时间。

**刘一鸣**: 那我可不可以理解为，因为**Anthropic**它自己又是模型商，又是终端服务**Agent**提供商，它这个数据闭环对它的训练有好处。那么**开源模型**实际上因为开源出来之后，你用谁的**API**都是碎片化的，这些host的提供商他是没有做这种重新训练的能力。可以理解为提供服务的人和训模型的人是两拨人，所以他做不成这种类似**网络效应**，用你的人越多，你的质量就越好的这种闭环。

**天奇**: 是，我是这么理解。如果你去用一下**OpenCode**和**Codex**，你就能很深刻地体会到**Codex**模型在**Codex CLI**（命令行界面）里就是好用。但是**Codex**模型在**OpenCode**这个harness就差点意思。这个体感还是非常明显的。

**祯豪**: 我在这里提一个可能不一样的观点。就是大家以前都觉得在AI时代，大厂因为它们有更多自己的数据、**C端闭环**，所以其他人、**开源模型**很难去打败它。我觉得不一定对。第一个是说现在的**RL**技术其实已经不需要太多的数据就可以训练得不错。第二个就是有可能有很不一样的技术架构，使得你整个的效果会有个质的突破。我们就拿**DeepSeek**最新的那个**N-gram**的那个论文举例。那我们假设想一个场景，如果它现在实现一个东西，在用户的场景里，它给你搞一个本地的**N-gram**的小的embedding（嵌入），它可以就是记录你在这个模型里，或者在这个场景下的一个对话，实时地去更改或去影响到线上这个**LM**的一个效果。假设他搞了这么一个架构，那这个架构在质量上绝对就是质的一个领先。所以我其实觉得数据垄断带来模型效果垄断的这一个逻辑，并不一定是成立的。就是我还是很看好更好的技术，可能就是会有一些质的新突破。

**刘一鸣**: 这个比较理想化的未来。

**知县**: 对，这个我觉得也是我们作为普通用户希望看到的，不希望被垄断的。

### 对互联网商业模式的冲击

**刘一鸣**: 对，是。其实我们刚刚聊到是对模型厂商的冲击。那其实现在对整个互联网的公司，就包括像**Google**、**Amazon**这些。但其实如果以后**Clawdbot**这样的**Agent**普及了，它每天在后台去帮我们看各种网页、读新闻，它们是产生了大量的访问。但这些访问其实对于这个广告的商业模式来说，是零有效点击，然后零广告浏览。所以这有没有可能摧毁现在这种**流量加广告**这种商业模式的这些互联网公司？然后未来的网站有没有可能需要变成这种**按爬取付费**？

**知县**: 对，据我了解应该是已经有这种苗头了吧。应该是**OpenAI**和**Google**都会找一些自有内容的媒体或者平台去签数据授权协议。他们可能就大公司批量地去买吧。如果开开脑洞，那未来个人**Agent**普及了，大家用的模型也比较分散的话，那可能网站会开一种新的形态——**按爬取付费**。你爬我一次，你给我多少钱。再加上未来的**Agent**支付体系变得更成熟，真的就是我用什么，然后我付一些钱，可能钱很少。那这些网站其实你想它接下来的商业模式，从现在的做内容、做粘性、做广告，可能会开放到一部分做优质内容，做**Agent**或者说大模型特别青睐的，逻辑非常的通顺、条理清晰，而且看上去数据很全、很可信。现在**GEO**（生成式引擎优化）的一种方式，就是提供这样的内容，你就能吸引到很多很多模型过来，按爬取付费给你付钱。

**天奇**: **GEO**的话，我身边就正好有做电商代运营的朋友，他现在说他们自己的客户现在有10%的流量是从**Agent**这边倒过去的。客户已经在付费，正经的让他们帮忙去做探索了。我觉得卖软件的话，可能会越来越难挣钱，因为软件的开发成本无限趋近于零了。但是卖**skill**这种，卖context、卖知识资产，可能会更合理。然后如果是打广告的话，**OpenAI**不是已经开始做他们那个广告的计划了吗？我感觉对于普通**ToC**用户的话，这其实应该是一个很好的模型厂商的商业模式的案例。

**知县**: 对，说到做软件，最近有个新闻不知道大家看到没有，就是**Clawdbot**的创始人他开始买很多非常有意义的**.md**结尾的域名了。因为我之前写的那篇文章教大家去检测**Claude Code**现在部署够不够安全。我一开始还想应该怎么把这些技术的东西写的让用户能够看懂。后来突然想我为什么要做这件事情？我直接把它做成一个**.MD**，然后让用户扔给**Claude Code**让它自己检查就行。其实这是一个非常大的**范式的转换**。以后可能说**APP**那种形态，很多时候是一个皮，内部的逻辑就不是用这种**Coding**的方式去编译了，而是自然语言去编译的。**.md**就是这种自然语言编译场景下的**APP**。所以我感觉大家去注册**.md**域名确实有。因为最近写文章，很多时候你都会在里面说这个md、那个md对吧，然后就会被自动识别成链接，点进去，真的就导到那个网站的流量了，也是一个新的流量入口吧。

### 对组织架构与工作模式的影响

**刘一鸣**: 对，这个也很有意思。那其实现在特别是**知县**你之前也提到，你未来可能想搭一个**Agent军团**对吧，在尝试这个方向。原来我们都在讨论**一人公司**，然后现在有了**Clawdbot**之后，更激进的观点就直接说是**零员工公司**。你觉得这件事情现在看来靠谱吗？然后未来它可能对我们目前的这种公司的组织架构会有什么影响？然后会怎么影响这些大厂员工们的饭碗？

**知县**: 就目前看来还是不靠谱的。大模型还没有强到那个程度，它对人的商业上的需求，或者说路径的把握也是不够的吧。当然尤其是其实长期记忆还是差一些，再怎么着它只是看上去更好了，但是实际上也没有本质上做得更好。但是我觉得有一个点，就是刚才说的这个**Multi bot**，你可以去看看他们现在都在想什么，你可能就有自己的判断了。就是你让这么一帮东西自己去做一个公司，然后去make money（营利），这个事现在靠不靠谱。可能你随着每天去看它们发帖，它们讨论问题，你突然发现它们深度越来越强是有可能的。突然某一天它们开始说你看不懂的话了，这也是很有可能的，那个时候可能就是另一件事了。

**知县**: 因为做一个团队，除了说人力成本这一方面来说，其实更大一个成本就是沟通和管理。沟通就会产生歧义，人和人之间的沟通能力、理解能力都不一样。大家在沟通的时候，那个信息的折损率是非常夸张的。所谓的大家都很讨厌的互联网黑话是吧，什么对齐一下，就是因为你不对齐它真的会出问题。就是大家分头去做，结果发现4个人做了甚至5个方向。所以**Agent**在这方面，就是它的沟通成本最多就是你跟它沟通，它们之间的沟通成本还是相对比较快的。而且它们特别喜欢做文档，这也是大家带团队的时候可能会经常强调的，我们要文档化，不要开会的时候开完了不知道这个会讲的什么，所有的改动都要在文档里记录。就这些事其实对于**Agent**来说，可能就是天生它**DNA**里它就想这么做，你不让它做它就难受的。所以在这方面上，它们特别适合干这种集团式往前推进的事情。所以我觉得**零人公司**可能确实有点远吧，至少我觉得现在还在观察。但是**一人公司**是绝对可行的。当然对这个人的要求也非常高，你得有**know-how**（诀窍/专业知识），就是说用**Agent**，你得知道他做的这个方向，你有评判能力。而不是说你也不懂，你也不懂你就让它直接去搞了。比如说我可能不懂拍电影对吧，我对什么分镜、叙事这些可能没什么感觉，只知道这个场景很炫酷，那个场景很炫酷。那我让它去拍电影，拍出来好坏我自己判断不了也不行。所以说我觉得**一人公司**就是这个人他把握方向，同时他要去用自己的**know-how**去带领这个军团。他还得是这个军团的将军。但是你现在得到的这个军团，它是比一个纯人肉的军团要强大非常多倍的，又低功耗、又高性能。就有点像量子军团，或者什么精灵军团一样的这种感觉吧。

**刘一鸣**: 对，之前国内有一个港口，然后它的这个调度系统里面他们再搭一套整个用多个**Agent**之间沟通。就它每个环节，就比如装卸货，再到怎么去调度，它是每个都设计了一个**Agent**。然后让它们之间其实跟人类的这个组织架构也是一样的，然后再去一环一环地走。但他们中间就会发现因为人类其实在调度的过程中，不同的环节之间会经常吵架推诿什么。然后他们发现这个**Agent**也会出现同样的现象，最终只能再设计一个上级**Agent**，然后来去做决策。你觉得就像你比如说运行一个这种**Agent军团**，然后去做一件事情，你有遇到过这种情况吗？

**知县**: 还没有。可能我不知道跟大家对它的定位设定有没有关系，就可能你给它设定得太吓人了，它确实有可能出现一种推卸责任。我倒是没有在我说的这个**Agent军团**里碰到这种情况。但我自己在之前用**Web Coding**跟**Coding Agent**聊天的时候，我发现它有一次自欺欺人的表现。它跑了有几个测试一直跑不过，它跑了三轮之后它突然来了句：“那么我们接下来就跑一遍能通过的测试。”然后跑完了，肯定都是对号，好了，所有测试通过了。然后开始给我总结这次改了什么。然后我马上就说：“你这不是掩耳盗铃吗？”好的，你给它指出来之后，它自己就在那儿反思：“你说的对，我不应该这样做。”所以就还是我说的那个**know-how**。就是你如果无法判断它现在做的这件事情是不是对的，或者质量好不好，那你被它忽悠的可能性还是有的，至少是现在。我不知道就像刚才说的引入上级，甚至或者说**peer review**（同行评审），我感觉是有一定规训作用的。毕竟大家context都不一样，而且AI它没有真正的这种生存焦虑。它并不是像咱们工作丢了，或者晋升机会没有了影响生活这么具体的这个担忧。所以说我觉得多搞几个，大家互相review、互相聊，应该是能缓解这个问题。

**刘一鸣**: 像你们在招人也好，或者是在给这些企业做**Agent**化的这个过程中，有没有发现现在你在公司组织架构上有没有什么新的变化？我之前听像那个硅谷的很多公司，可能他在招聘这个新员工的时候，他评价你的能力可能跟以前的那种评价体系都不一样了。他现在可能会比如说直接丢给你一个你不可能自己完成的任务，你必须得借用AI工具，然后看你对这种任务完成得怎么样。这可能是种新型的面试。我不知道你们在现在的这个公司组织架构里，哪怕在招人里，你觉得有什么新的影响吗？

**祯豪**: 我听说**腾讯**某一个前端的面试已经改成直接给你一个**PRD**，让你用自己最熟悉的AI编程工具直接把它做出来，直接让现场做。但我觉得如果我是面试官，我也会采用这样的方式。这个至少对于前端类型的工作而言是非常合适的。还有一个现在的工作中的冲突，比如说我觉得我算是在一个相对成熟的一个企业中的工作。那这个会有一个自己的主线，我们经常也会有一些脑暴型的想法，想做那个，还非常想做这个。其实就会发现这两点会挺难融入的。就是如果说我们在现在的这个大框架下想要去做这件事，可能这个开发周期就很长，且有很多沟通的工作。但我啥都不管了，我就交给一个工程师，他自己**end to end**（端到端）把它**Web coding**出来，可能会更快，甚至快速去验证。我觉得怎么样把这个融合可能还没有特别好的解法，但确实是一个问题。同时能够让一个人在减少沟通的情况下快速把事情做出来，同时他这个事情又有一定的长期性，能够让团队的能力去赋能上这个事情上。怎么让效率和效果的结合最好，我觉得是企业需要考虑的。

**刘一鸣**: **天奇**，像**Pamir**，因为你们是一个很早期的团队。你们其实现在用这种AI工具也好，或者是让AI去重塑一些这种创业团队的组织架构上，你觉得你们有什么创新的点？

**天奇**: 我们对这种开发方式转移的体感还是蛮强烈的。放在以前的话我们可能会更觉得想法不是那么重要，反而你的执行力和迭代速率这些东西是有关键性作用的。但是因为现在实现和迭代的开发速度太快了，反而**想法更重要**。它给了我们更多的时间去做思考。你思考完了，可能你花个10分钟，最长花个半天，很有可能就把这个想法给实现了。

**天奇**: 第二点，员工之间合作也有很大的改变。之前的话，因为你害怕两个人他会写重复代码这种重叠工作，所以他会再花很多时间去做对齐。但是今天我有些时候反而会觉得无所谓，你写一份，你也写一份，反正最后有重叠部分我们就各取谁的想法最好就行了。你让**Claude**给它合并一下就行了。这个反而减少了他们沟通的时间，然后大家都会有更多的专注实现他们想法的机会。甚至是比如说设计师，他以前只能出设计稿，然后技术团队再去跟着设计稿去进行复现。但是今天设计师最终出的是一个整个一个mock（模拟）的**APP**。他把想法直接通过他跟**Gemini**对话，形成了一个直接的**mock APP**出来了。其实这个**mock APP**本身就把整个**APP**的架构都给你表达好了。工程师团队甚至连对齐都不需要了，他直接参考设计师的**mock APP**代码库，他就把该填的功能性的东西给填上了。我觉得在整个开发迭代过程中，把所有的职位都拔高了一级。

**刘一鸣**: 好的，谢谢三位的时间。

**知县**: 好的，谢谢，拜拜。

### 总结与安全提示

**刘一鸣**: 好了，这就是我们今天播客的全部内容。不过在最后我还是要提醒一下，它的**安全风险真的很大**，建议大家不要在自己的主电脑上安装，小心风险。对于我们的播客内容，你可以通过**小宇宙**、**苹果播客**、**Spotify**来收听订阅我们。同时如果你想再用视频的渠道去听播客的话，大家也可以在**YouTube**或者**bilibili**上搜索《**硅谷101播客**》来找到我们。另外我们有一些播客部分的文字稿也会发表在《**硅谷101**》的**微信公众号**上，也欢迎大家关注我们。我是**刘一鸣**，感谢大家的收听。