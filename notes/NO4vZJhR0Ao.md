---
author: 北美王路飞
date: '2026-01-07'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=NO4vZJhR0Ao
speaker: 北美王路飞
tags:
  - jagged-intelligence
  - rlvr
  - thinking-time
  - context-engineering
  - generative-ui
title: AI的幽灵与锯齿状智能：Karpathy深度解读2025年AI新范式
summary: Andrej Karpathy在其2025年度回顾中，将AI比作‘幽灵’，指出其非生物进化路径导致‘锯齿状智能’，即在特定领域极强而在常识和安全方面存在巨大缺陷。他强调当前基准测试的局限性，并介绍了RLVR、GRPO等新技术如何催生AI的‘思考时间’。报告还探讨了上下文工程、本地AI、生成式UI等新应用范式，以及‘氛围编码’带来的生产力提升与安全挑战，预示着AI正从被动工具转变为主动的、潜在危险的合作伙伴，但其真正潜力尚待挖掘。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - OpenAI
  - DeepSeek
  - Anthropic
products_models:
  - GPT-4o
  - DeepSeek r one
  - Claude Code
  - Gemini Nano
media_books:
  - Thinking, Fast and Slow
status: evergreen
---
在2025年12月19日，**Andrej Karpathy**发布了他的年度回顾报告，其中提出了一个惊人的观点：我们并非在进化动物，而是在“召唤幽灵”。他认为，当前人工智能（AI）的真实面目并非硅基生命，而是一种截然不同的存在。

### AI的非人进化路径

在深入探讨这一观点之前，先介绍一下Andrej Karpathy。他拥有斯坦福大学CS博士学位，是**OpenAI**的早期创始成员之一，后被Elon Musk招募至**特斯拉**担任AI总监，负责构建自动驾驶大模型。他在斯坦福的博士导师是著名AI科学家**李飞飞**。Karpathy目前创办了**Eureka Labs**，致力于普及高质量AI教育。他兼具深厚的学术背景和强大的动手能力，擅长将AI理论转化为实际可落地的代码。

Karpathy之所以称AI为“幽灵”，是因为AI的“大脑”——互联网上的静态文本——与人类大脑的进化路径截然不同。人类大脑经过数百万年的丛林生存竞争，每一根神经都服务于生存和繁衍。我们的恐惧、常识和直觉，都是为了在物理世界中生存下来。然而，AI没有身体，没有痛觉，也不在乎传宗接代。它的“生存压力”仅限于：一是预测下一个词，二是做对数学题获得奖励（强化学习），三是在**大语言模型竞技场 (Arena)**中获得点赞。这种训练方式并非生物进化，导致AI虽能掌握量子力学公式，却可能不知道杯子放在桌边会掉下去，因为它缺乏物理模型，是一个脱离肉体的纯粹信息实体。它像一个互动的百科全书，什么都知道，但在生活中却是个“白痴”，缺乏小孩都有的常识。这就是Karpathy所说的“幽灵”——一个极其强大但又非常诡异的存在。

### 锯齿状智能与常识缺失

这种非人的进化路径造就了AI一种奇特的现象，Karpathy称之为**“锯齿状的智能” (Jagged Intelligence)**。人类的智能通常是均衡的，逻辑推理、数学能力和对骗术的抵抗力相辅相成，形成一种平滑的智能图谱。但AI的智能图谱则像一把锯子，充满尖刺。在数学和代码等有明确对错标准的领域，AI可以被训练成超级天才，甚至获得数学界的菲尔兹奖。然而，在缺乏明确奖励信号的领域，如社交直觉或基本安全防御，它就表现得像个困惑的小学生。

这种“尖刺”与“深谷”并存的特性非常危险。人类会因AI在代码方面的完美表现而产生**晕轮效应 (halo effect)**，下意识认为它也理解代码发送密码给黑客是错误的。但AI并没有这个概念。它可能教你制造核弹，下一秒却可能被简单的提示词注入攻击骗得团团转，泄露公司机密。因此，AI是一个复杂的结合体，在2025年，我们看到AI在数学竞赛、物理竞赛等领域拿到满分，但实际使用时却感觉不到其聪明多少。

### 基准测试的局限性与“刷榜”现象

这种现象的根源在于，当前的**基准测试 (benchmarks)**已逐渐失去公信力。AI如同“做题家”，针对特定考题进行训练，能够理解出题套路，但难以将知识迁移到新的、未知的环境中。Karpathy称之为**“刷榜” (bench maxxing)**。这并非简单的作弊，而是实验室通过分析考题类型，在训练数据中专门制造大量类似数据，使AI在这些领域“长出巨大的能力尖刺”。这使得AI在榜单上看起来无敌，但一旦题目稍作变动或置于现实复杂场景，其能力便会丧失殆尽。Karpathy直言，即使粉碎所有基准测试，也离真正的通用人工智能（AGI）“差十万八千里”，这是一种分数通货膨胀，掩盖了AI发展的真实困境。

### RLVR、GRPO与“思考时间”的突破

然而，2025年也带来了重大突破。研究人员在训练**DeepSeek r one**、**OpenAI**的**o1**和**o3**模型时，发现了“顿悟时刻”。在训练DeepSeek r one时，工程师仅提供了一个难题和“做对给分，做错没分”的简单规则，模型在数千次失败后，竟学会了自我纠错、回溯和拆解问题，展现出**推理 (reasoning)**能力。这标志着AI不再是模仿人类的鹦鹉，而是开始拥有自己的思维链。

这一突破得益于训练范式的革新。从**RLHF (Reinforcement Learning from Human Feedback)**转向**RLVR (Reinforcement Learning from Verifiable Feedback)**。RLHF依赖人类主观评分，AI易学会“说话好听”来获取高分。而RLVR则以编译器和数学引擎作为考官，基于客观的“真理”（ground truth），AI无法再通过模仿人类语言来蒙混过关，被迫寻找真正的逻辑路径。

为了实现这种求真训练，传统的**PPO算法**因其笨重而难以胜任。**DPC**在2025年提出的**GRPO (Grouped Relative Policy Optimization)**被认为是“神来之笔”。GRPO摒弃了外部批评家，让模型针对一道题一次性生成64个不同解法（group），然后自行比较优劣，从中学习。这一方法直接节省了一半显存资源，使得在同等硬件条件下，模型能思考更久、探索更深，从而在数学和代码领域实现了数万步的自我进化。

这一系列技术进步解锁了AI的一个新属性：**“思考时间” (Thinking Time)**。过去，模型强弱主要看参数量（训练时算力），而现在，**测试时算力 (test time compute)**变得至关重要。这是一种全新的缩放定律：给模型更多时间思考，其智商就会飙升，如同人类的“快思考”与“慢思考”。例如，**GPT-4**倾向于直觉式的快思考，而**O3**或**r one**在面对难题时，会进入长思考模式，生成数千个思维链进行验证、推翻、重来。这意味着即使是参数量较小的模型，只要给予足够思考时间，也能超越那些依赖直觉的大模型。智力因此成为可以用时间兑换的商品，预示着商业模式的变革——未来可能按思考时间而非字数付费。

### 新应用范式：上下文工程、本地AI与生成式UI

有了会思考的模型，新的应用场景应运而生。**Cursor**被Karpathy视为**“后应用层” (post-application layer)**的代表，它标志着**“提示词工程” (prompt engineering)**的过时，进入**“上下文工程” (context engineering)**时代。Cursor的核心竞争力在于其智能管理AI的“记忆”（上下文）。在修复bug时，它会自动检索用户过往文件、函数定义、Git提交记录等，构建一个AI能正确回答问题的环境，让AI仿佛真正理解整个项目。

而**Anthropic**推出的**Claude Code**则将AI带入了本地终端，成为用户的“递数地缚灵”。Karpathy认为，真正的未来在于**本地主机 (local host)**。Claude Code直接驻留在命令行，能读取文件、运行命令、分析日志。其最令人惊叹的是**“代理循环” (agentic loop)**：用户给一个任务（如修复bug），AI能自主运行代码、读取错误日志、分析原因、修改代码，直至任务完成。这实现了“本地主权回归”，AI成为键盘下的幽灵，拥有电脑的读写权限，带来了巨大的生产力，但也引发了前所未有的安全焦虑。

### 氛围编码、一次性软件与安全隐患

在与AI交互方式上，2025年诞生了**“氛围编码” (Vibe Coding)**。其哲学是“只要它能跑，就是对的”。用户只需用自然语言描述所需功能和“感觉”（VIB），AI便生成代码。开发者无需深入理解代码细节，直接接受，出错则将错误信息反馈给AI。这使得编程不再是理科生的特权，而是“会说话”就能成为程序员，实现了技术民主化。然而，这也可能导致大量“屎山代码”，安全性堪忧。

软件定义也因此重写，进入**“一次性软件” (disposable software)**时代。过去开发软件耗时耗力，是长期资产；现在，AI能快速生成一次性工具，如用于测试的小软件，甚至用不熟悉的语言（如Rust）编写底层组件。软件变得像日抛用品，成本极低，用完即弃。这极大地加速了信息的流动速度，但代价是可能产生大量不可维护的代码，带来严重的**“影子 IT” (Shadow IT)**问题。AI生成的代码可能包含后门、硬编码密钥、SQL注入漏洞等，提供虚假安全感，成为潜在的“定时炸弹”。在涉及敏感信息时，将安全交给一个不完全了解的“幽灵”是一种巨大的信任让渡，需要格外小心。

### 生成式UI与未来交互

**Google**发布的**Gemini Nano Banana**（Karpathy认为名字滑稽）预示着**静态界面 (static interfaces)**的终结。未来的界面将是**“生成式 UI” (Generative UI)**。用户不再面对固定的菜单和按钮，而是可以通过自然语言与AI交互，AI会实时为其生成个性化的应用界面，如规划东京旅行时，会生成包含地图、滑块、时间轴的定制化APP。未来的软件将是无限灵活的画布，AI随时能为用户绘制最顺手的工具，如同钢铁侠的HUD。

### 总结与展望

回顾2025年，AI的发展是“物种层面的整合”：底层是具备推理能力的“幽灵”（RLVR, GRPO），中间层是管理记忆的上下文工程工具（Cursor），应用层是本地AI（Claude Code）和生成式UI（Nano Banana），人类则通过“氛围编码”获得驾驶权杖。AI从被动的搜索引擎转变为主动、会思考、甚至危险的合作伙伴，它不再只是寻找答案，而是在构建世界。

Karpathy谦逊地指出，我们目前挖掘的潜力还不到10%。他是一个乐观主义者，认为我们刚学会召唤幽灵，但远未懂得如何驯服它，如何填补“锯齿状智能”的深坑，如何在快感与严谨间找到平衡，以及每个人都能随手创造软件的世界将变成什么样。这是最迷人的地方：旧规则破碎，新规则未定，机会犹存。Karpathy建议大家“系好安全带”，因为“未来已到”。