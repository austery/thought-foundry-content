---
area: society-systems
category: psychology
companies_orgs:
- OpenAI
- Google
date: '2025-08-30'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- The Algebraic Mind
- Parallel Distributed Processing
people:
- Gary Marcus
- Sam Altman
- Nicolas Cage
- John Travolta
products_models:
- ChatGPT
- Gemini
- Claude
- Perplexity
- Multi-layer Perceptron
- PDP
project:
- systems-thinking
- personal-growth-lab
- historical-insights
series: ''
source: https://www.youtube.com/watch?v=GHxWZT5Mzcw
speaker: 北美王路飞
status: evergreen
summary: 本文深入解读认知科学家加里·马库斯20年前的著作《代数大脑》，探讨其对当前主流神经网络（连接主义）局限性的预言与批判。马库斯认为，人类智能的核心在于处理抽象变量、结构化表示和区分个体与种类的代数能力，而非单纯的模式识别。通过恒等函数、婴儿语言学习及结构化表示等思想实验，文章揭示了神经网络在泛化能力和结构理解上的根本缺陷。最终，文章倡导结合符号主义的代数能力与连接主义的学习能力，以期实现真正的通用人工智能，并为个人学习与AI认知提供新视角。
tags:
- cognitive
- health
- llm
- neural-network
- philosophy
title: 《代数大脑》：加里·马库斯揭示神经网络的局限与人类智能的代数本质
---

### 引言：对大语言模型的认可与批判性思考

作为大语言模型的忠实用户，我深知其在提升工作效率方面的巨大潜力，并付费使用包括ChatGPT、Gemini Ultra、Claude和Perplexity在内的多款顶尖模型。然而，认知科学家加里·马库斯（Gary Marcus）的批评同样切中要害，他指出的许多问题在实际测试中确实存在。今天，我们将深入解读马库斯20年前的著作《代数大脑》（The Algebraic Mind），这本书早已预示了他对神经网络技术不足的批判观点。

我们常被告知，大脑像一个复杂的神经网络，而当今的AI巨头，如ChatGPT，也正是基于此。但它们为何会犯下某些“低级错误”？马库斯在书中揭示了一个可能颠覆我们常识的真相：智能的核心或许并非单纯的模式识别，而是一套强大的代数系统。

### 婴儿的抽象逻辑与神经网络的局限

一个七个月大的婴儿，在话还不会说、路还不会走的情况下，竟然能像逻辑学家一样发现抽象的语法规则，这听起来似乎反常识。我们一直认为，大脑通过海量经验学习并识别模式，就像我们引以为傲的**人工智能**（Artificial Intelligence, AI: 模拟人类智能的技术）那样工作。但如果这种我们深信不疑的神经网络，从根本上无法解释人类智能最核心的能力呢？如果大脑深处存在一个更古老、更强大的**代数引擎**（Algebraic Engine: 能够处理抽象规则和结构化信息的系统）呢？

《代数大脑》这本二十多年前出版的著作，在今天看来更具预言性。它带领我们潜入智能的底层，探索理解人类自身以及真正**通用人工智能**（Artificial General Intelligence, AGI: 具备人类级别智能，能执行任何智力任务的AI）的关键。

### 认知科学的“华山论剑”：符号主义与连接主义

要理解《代数大脑》的精妙之处，我们必须回顾认知科学领域持续了几十年的“华山论剑”——**符号主义**（Symbolicism: 认为智能核心是处理概念、规则等心理符号的学派）与**连接主义**（Connectionism: 认为智能通过神经元网络在经验中学习，调节连接权重形成的学派）两大流派的争论。

符号主义者认为，大脑就像一台经典的计算机，智能的核心在于处理符号。例如，“所有狗都会叫”是一条规则，遇到新狗我们便能运用此规则推测它也会叫，简单清晰且富有逻辑。

连接主义者则认为，大脑由数十亿个神经元相互连接组成，智能并非依靠规则，而是神经元网络在经验中学习，通过调节神经元之间的连接权重逐渐形成能力，这更符合生物学事实。

上世纪80年代，随着《并行分布式处理》（Parallel Distributed Processing, PDP: 连接主义的里程碑式著作）一书的问世，连接主义迎来了高光时刻。这种受神经网络启发的模型似乎能模拟许多过去难以解释的认知现象，如语言学习。自那时起，连接主义一路高歌猛进，直至今日成为人工智能的绝对主流，所有大语言模型本质上都是连接主义思想的产物。

这引出了《代数大脑》想要挑战的终极问题：既然连接主义如此成功，我们是否可以彻底抛弃符号主义？人类智能真的只是一个超级复杂的神经网络吗？加里·马库斯响亮地回答：“不对！”

### 连接主义的核心：多层感知器与反向传播

为了理解马库斯的论证，我们首先需了解连接主义的“当家花旦”——**多层感知器**（Multi-layer Perceptron, MLP: 一种前馈人工神经网络，包含至少一个隐藏层）。你可以将其想象成一个超级复杂的调光系统。最底层是输入节点，如同开关；最上层是输出节点，如同最终亮的灯泡。最有意思的是中间的**隐藏层**（Hidden Layer: 神经网络中介于输入层和输出层之间的层），它像无数个错综复杂的调光器和线路，连接着输入开关和输出灯泡。每个连接线路上都有一个**权重**（Weight: 决定连接强度和信号传递影响的参数），决定信号的强度。当输入信号激活时，信号通过带权重的线路传到隐藏层，再传到输出层，最终亮的灯泡即为网络的答案。

这个神奇系统如何学习？最常用的方法是**反向传播**（Backpropagation: 一种训练神经网络的算法，通过计算输出误差并反向调整权重来减少误差）。形象地说，就像学生做题，给出答案后老师告知正确答案（目标输出）。学生发现答案与正确答案存在差距（误差），便从答案开始，一层层往回找原因，修改自己的“笔记”。这个修改笔记的过程，就是在网络中调整连接的权重。一次次重复，网络权重会越来越好，误差越来越小，从而学会。这个过程无需预设任何规则，只需足够数据和反馈，网络便能自主学习，感觉上比硬邦邦的符号规则聪明，也更像人类学习方式。

### 马库斯的三大核心支柱：代数智能的本质

马库斯认为，要真正理解人类智能，不能只看连接主义的表面风光，必须直面**符号加工思想**（Symbolic Processing: 智能通过操作抽象符号和规则来实现）的三个核心支柱。这三个支柱才代表我们智能的代数本质：

1.  **抽象变量关系表示：** 大脑能够表示变量之间的抽象关系，即理解和使用规则。例如，给动词加“ed”变成过去式（past verb = verb + ed），这里的“verb”就是一个变量，可以代入任何动词（如walk, jump），规则都成立。
2.  **递归和结构化表示系统：** 大脑拥有递归和结构化的表示系统。例如，“桌子上的书”和“书上的桌子”，词语相同但意义完全不同。大脑并非简单处理一堆词，而是在处理它们之间的连接关系，这种结构可以无限嵌套，如同俄罗斯套娃。
3.  **区分个体和种类：** 大脑能够明确区分个体和种类。我们知道“狗”是一个类别，也知道我家那条叫“旺财”的狗是一个独一无二的个体。这听起来简单，但对计算系统来说是巨大挑战。

现在核心问题来了：那个看起来很厉害、能从数据中学习的多层感知器，它能实现这三个核心能力吗？马库斯的答案是“不能”，或者说，标准的多层感知器在这些人类智能的核心领域存在根本性缺陷。

### 神经网络的致命弱点：恒等函数与训练独立性

马库斯用一系列精巧的思想实验和真实的认知心理学研究，像侦探一样层层剥茧，展示了看似万能的神经网络为何不能解释我们大脑中真正的智能引擎。

首先来看一个最简单的思想实验：**恒等函数**（Identity Function: 一种数学函数，其输出值始终等于输入值，即f(x) = x）。假设输入为1010，输出为1010；输入为0100，输出为0100。规律很简单：输出等于输入。现在，如果输入1111，我们99%的人会毫不犹豫地回答1111，因为我们瞬间发现了抽象规则：输出等于输入，并能将此规则自由泛化到所有未见过的新例子上，这种能力称为**自由泛化**（Free Generalization: 将学习到的规则或模式应用于全新、未见过的数据或情境的能力）。

然而，将同样的问题交给一个标准的多层感知器，经过训练后，输入1111，它可能输出1110。为什么？这就触及到这类神经网络的一个致命弱点——马库斯称之为**训练独立性**（Training Independence: 指神经网络在训练过程中，其学习到的模式可能过于依赖训练样本的特定特征，而非抽象规则，导致泛化能力受限）。在训练时，网络发现所有训练样本中，最右边一列的输出永远是0，于是它学到的潜规则是“不管输入什么，输出的最右边一位大概率是0”。它根本没有学到抽象的“输出等于输入”的代数规则。这就像一个只会死记硬背的学生，背下100道例题，但遇到新题型就懵了，因为他没有掌握背后的公式。而人类恰恰相反，我们天生擅长寻找公式。这个小例子就暴露了标准神经网络与人类智能之间的巨大鸿沟。

### 婴儿的语言学习：抽象规则的提取

刚才的0和1例子可能过于抽象，再来看一个更有趣的例子——七个月大婴儿的实验。科学家给一群七个月大的宝宝听一些毫无意义的音节序列：一组听的是ABA结构的句子（如“拉踢拉”），另一组听的是ABB结构（如“拉踢踢”）。仅仅听了两分钟，神奇的事情发生了：听过ABA的宝宝，当他们听到全新的ABA句（如“噢非噢”）时没什么反应，但一旦听到ABB结构的“奥菲菲”，他们会表现出明显的惊讶，盯着喇叭更长时间。

这意味着这些话都说不明白的婴儿，在短短两分钟内，超越声音本身，提取了一个抽象的代数规则——“第一项和第三项相同”，并能将这个规则应用到全新的声音上。这种强大的规则提取能力在儿童学习语言过程中随处可见。最经典的例子是学习英语过去式：大部分动词加“ed”（如walk变成walked），但有一小撮不规则动词（如sing变成sang，go变成went）。有意思的是，小孩子在学习说话时常犯一种“聪明”的错误：他们可能先说“ate”，但过一段时间反而会说“eaten”。为什么？因为大脑发现了一个更通用的规则——“动词加ed”，然后试图把这个规则应用到所有动词上，哪怕是不规则的。而许多早期的连接主义模型很难解释这个现象，它们要么很难学会通用的加“ed”规则，要么在泛化时会搞出奇怪的混合词。这再次说明，我们的语言系统里似乎内置了一个处理抽象规则的模块和一个负责处理特殊例外的模块，这是一种**双轨制**（Dual-Track System: 指大脑或认知系统同时运用两种不同的机制或策略来处理信息），而非一个大一统的神经网络。

### 结构化表示的挑战：叠加灾难与树苗

解决了规则问题，我们再来看第二个核心支柱——**结构化表示**（Structured Representation: 能够捕捉信息中内在关系和层次结构的方式）。我们前面提到“桌子上的书”和“书上的桌子”，在我们看来这两个意思天差地别。但对于一个简单的神经网络来说，可能就“傻眼”了，因为它看到的可能只是“书”、“桌子”、“上面”这几个概念被激活，至于谁在谁上面，这个结构信息就丢失了。

这个问题在AI领域被称为“**叠加灾难**”（Superposition Catastrophe: 当试图用同一组资源（如神经元）表达多个实体及其关系时，信息会互相干扰，导致结构信息丢失）。当你试图用同一组资源去表达多个实体和它们之间的关系时，信息就会互相干扰，变成一锅粥。

为了解决这个问题，马库斯在书里提出了一个非常有趣的概念——**树苗**（Treelets: 马库斯提出的概念，指大脑中预先存在的、具有固定槽位的结构化模板，用于填充概念以保持结构信息）。你可以把它想象成我们大脑里预先装好的一堆文件结构模板，每个模板都有固定的槽位，比如“施动者”、“动作”、“承受者”。当我们理解一句话时，就把对应的概念填到这些槽位里，这样结构信息就不会丢失了。例如，“桌子上的书”就是把“书”填到主体槽，把“桌子”填到位置槽，反之亦然。这个想法为大脑如何在神经层面实现结构化表示提供了一种可能的解释。

### 区分个体与种类：客体的永久性

最后我们再来看第三个、也是最容易被忽视的一点——区分个体和种类。一个标准的神经网络通过特征来识别物体，例如“四条腿”、“有胡须”、“会喵喵叫”，它就识别为“猫”。但问题来了，如果现在有两只长得一模一样的猫：菲利克斯和莫里斯站在你面前，神经网络怎么区分它俩？对网络来说，它们两个特征完全一样，所以它们就是同一个东西。网络无法理解这是两个完全不同的个体这样的概念。

而我们大脑则拥有一个神奇的能力，就是给每一个遇到的个体贴上一个独一无二的心理标签，并在时间和空间中持续追踪这个标签。这就像电影《变脸》里，无论是尼古拉斯·凯奇还是约翰·特拉沃尔塔，无论怎么换脸，我们始终清楚谁是好人谁是坏人，因为我们追踪的是持续存在的个体，而不是他表面的特征。这个能力就是**客体的永久性**（Object Permanence: 指个体即使在不可见的情况下，仍能理解其持续存在的认知能力），它是计数甚至是社会关系的基础。一个无法区分个体和种类的系统，是无法真正理解我们这个由无数独特个体组成的世界的。

### 《代数大脑》的当代意义：通往通用人工智能之路

大家可能会觉得，《代数大脑》毕竟是20多年前的书了，今天的神经网络，特别是新的大语言模型，已经比那时强大太多，它们是不是已经解决了这些问题呢？有意思的是，答案是“并没有完全解决”。

今天的大模型非常擅长识别和生成模式，这是连接主义的强项。但它们也暴露出了很多弱点：它们会一本正经地“胡说八道”（**幻觉**，Hallucination: AI生成虚假或无意义信息），缺乏真正的逻辑推理能力，而且有时会因为输入的一点点变化就得出完全错误的结论（**脆弱性**，Fragility: AI系统对微小输入扰动或训练数据偏差敏感，导致性能急剧下降）。这不正是马库斯当年指出的根本性缺陷在今天的体现吗？它们仍然很难完美处理抽象规则、复杂结构和个体追踪。

因此，《代数大脑》的观点在今天非但没有过时，反而变得更加重要。它告诉我们，通往真正通用人工智能的道路，可能不是把神经网络做得更大，而需要把符号主义的代数能力和连接主义的学习能力结合起来。这就是现在AI研究的前沿方向之一——**神经符号AI**（Neuro-Symbolic AI: 结合神经网络的模式识别能力和符号主义的逻辑推理能力的AI方法）。

### 了解代数引擎对普通人的启示

了解我们大脑的代数引擎，对我们普通人有何用处？这用处可大了：

1.  **改善学习方式：** 分清你是像神经网络一样死记硬背，还是像代数大脑一样掌握公式。下次学习新知识，别光记结论，多问几个为什么，去寻找背后那可以自由泛化的规则，这才是真正的高效学习。
2.  **提升解决问题能力：** 遇到问题，先判断这是一个需要模式识别的问题，还是需要逻辑推理的问题。如果是前者，你需要多找案例，凭感觉和经验；如果是后者，你就得静下心来，一步步分析结构，运用规则，把大脑的两个系统都用在刀刃上。
3.  **更清晰地看待AI：** 下次再看到天花乱坠的AI宣传，你就可以多一分批判性思考。问问自己，它是在做高级的模式匹配，还是真的具备了理解结构和规则的能力？这能帮助你更好地运用AI，而不是被它所“忽悠”。

### 结论：大脑的混合系统与心智的奇迹

所以，我们的大脑到底是什么？《代数大脑》给了我们一个新的启示：它既不是一台冷冰冰的逻辑计算机，也不仅仅是一台混沌的神经网络。它是一个无比精妙的混合系统，既有连接主义系统强大的学习和模式识别能力，又有符号主义系统精准的规则操作和结构表示能力。这就像一个伟大的艺术家，他既对色彩和光影有直觉（连接主义），又对透视和构图有严谨知识（符号主义），两者结合，才诞生了伟大的作品。

理解了这一点，我们不仅距离创造真正的人工智能又更近了一步，更重要的是，我们能够更深地体验到我们心智的奇迹。我们大脑里都运用着这个代数引擎，它赋予我们学习语言、理解世界、进行创造的能力，这本身就是一件值得惊叹和感恩的事情。

当然，也有人认为《代数大脑》出版于21世纪初，其中马库斯批判的一些具体模型和论文现在已被认为是过时了，机器学习领域已取得了长足的进步。一些读者也发现，如果没有专业背景，很难理解书中关于反向传播模型的技术细节。尽管有这些批评，但许多评论者一致认为，《代数大脑》提出的理论思考和思维方式，仍然具有很好的现实意义。