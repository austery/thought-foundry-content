---
area: society-systems
category: technology
companies_orgs:
- Meta
- FAIR
- OpenAI
date: '2025-11-11'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 硅谷101
people:
- 田渊栋
- Mark Zuckerberg
- Andrej Karpathy
- Sam Altman
- Ilya Sutskever
- Demis Hassabis
products_models:
- LLM
- Llama
- GPT-5
project:
- ai-impact-analysis
- systems-thinking
- personal-growth-lab
series: ''
source: https://www.youtube.com/watch?v=EsaUQNx59vA
speaker: 硅谷101
status: evergreen
summary: 本期专访前FAIR研究总监田渊栋，深入探讨了Meta人工智能部门裁员背后的行业深层趋势。他分享了对大型语言模型（LLM）发展路线、强化学习（RL）作用、AI开源与闭源策略以及AI人才未来走向的独到见解。田渊栋强调了人类洞察力在高级AI研究中的不可替代性，并反思了“缩放定律”（Skin
  Law）可能带来的挑战，同时展望了AI自动化对未来研究范式和职业发展的影响。
tags:
- development
- law
- open-source-ai
- reinforcement-learning
- research
- strategy
title: 田渊栋专访：Meta裁员背后的AI路线之思与未来展望
---

### Meta裁员与AI行业大趋势

大家好，欢迎收看硅谷101，我是陈倩。2025年10月22日，Meta首席执行官马克·扎克伯格批准了对公司人工智能部门裁减约600名员工的计划，这是Meta今年在AI领域最大规模的裁员，主要针对被称为超智能实验室的核心研发部门。Meta为何裁员，其AI开源路线如何碰壁，以及空降的新AI负责人Alex Wang将如何重塑Meta的AI策略，这些内容我们在上一期节目中已提及。我们也为此采访了这次裁员风波中的核心人物之一，前FAIR研究总监及AI科学家田渊栋。本次采访不仅限于Meta公司层面，更深入探讨了资深AI科学家们对AI路线和未来前沿研究的思考。本期视频将完整呈现采访内容，特别是关于**大型语言模型**（LLM: Large Language Model）的路线、开源与闭源研究实验室的存在，以及AI人才对研发和工程的选择等话题。

在被裁之前，我其实已经有了其他公司的Offer。因为我在公司已经待了十年多了，所以也许这正好是一个时机可以出来看看。在被裁之前，我已经跟我的经理们沟通过，表示我可能需要寻找新的机会，他们是知情的，所以被裁员我并没有特别惊讶。反正我有Offer，本来我拿到Offer之后，还想在Meta再待一阵子，毕竟还有绿卡方面的考虑，还可以再做点东西。但既然被裁了，那就顺其自然了。过去这两天，确实有很多人联系我，包括媒体和很多公司，甚至是一些联合创始人（co-funding）的机会。目前我还在考虑中，还没有做出最终决定。毕竟裁员到现在还不到一个礼拜，还需要一些时间思考。

这次裁员是否在意料之中？我当时确实有一些感觉，不然我也不会去找工作。我个人觉得，对我来说，在公司待了十年多，也许这正好是一个出来的时机。至于公司内部的具体情况，我现在不太方便评论，但这可能是一个个人选择，只是裁员加速了这个选择。也许我本来还会在公司里再待一会儿，比如再待个半年，然后再考虑。但现在既然出来了，就出来了。

裁员600人这个数字当时让我挺震惊的，我觉得有点多。虽然不是完全裁撤，只是说他们可能有机会转到其他组，但这个AI部门他们觉得没有必要用这么多人，需要重新调整部门结构。我觉得这其实是行业趋势。我们不谈Meta的具体情况，AI本身的自动化程度是最高的。今天可能需要很多人来标注数据，明天模型更强了，需要的人就会减少。以前有很多时候，比如系统出现问题，需要**On-call**（On-call: 轮班待命，处理系统紧急故障）的工程师立即处理、修复和调整参数。但现在，随着自动化工具的增多和整个系统的完善，这类事情会越来越少。各种各样的流水线（pipeline）都慢慢成熟并自动化，那么你还需要很多人吗？并不需要。所以我觉得大趋势肯定是从事AI工作的人会越来越少。

这不仅仅是Meta一家公司的问题，而是大趋势。总有一天，大家可能没有传统意义上的工作，或者说不再是受雇于一个公司，帮公司把事情做好。也许以后并不需要这样。比如说，如果我去当CEO或者一个小公司的负责人，或者自己去创业，拿到现在的这些工具，我都会觉得并不需要太多人来做这些事情。很多事情可以自动化，而且自动化程度非常高。以前可能需要一个几百人甚至几千人的团队去做一件事，现在也许不需要那么多人了，有很多事情可以用**智能体**（Agent: 能够感知环境、进行决策并执行动作的AI系统）来做。在这种情况下，总的来说，做AI的人可能会越来越少，但是探索如何用AI作为工具来探索其他领域的人会越来越多。

在**基础模型**（Foundation Model: 指在大量数据上预训练，可适应多种下游任务的模型）研究方面，探索性研究应该会越来越多。但如果只是按照工程上的逻辑把模型做出来、训练出来，这类人会越来越少。因为以后大家会发现，都遵循同样的逻辑把模型训练出来，代码都是可以跑的，都能有效果，那为什么还需要很多人呢？可能有更多人会去做研究或者其他探索性的工作，这样的人会越来越多。做应用的人也会越来越多，但这种应用不是一般性的，很多时候会落地到具体的垂直领域，或者用这个东西做一些你先想做的事情。做执行的中间层人员，他们的工作比较重复，如果工具的自动化程度越来越高，重复性劳动就会减少。

### AI研究的未来方向：LLM与强化学习

在裁员之前，我们今年一月份去JNI帮忙，那段时间大部分时间没有在做研究，而是在做各种比较救火的工作，比如Llama模型。我个人还是会和外面一些朋友合作，比如我们今年四五月份有一篇文章，分析了我们之前的**连续思维链**（CoT: Chain of Thought）在理论上的一些厉害之处。这篇文章的影响力也挺大，大家觉得它给连续思维链（Coconut这篇文章）加了一些备注，确实我们在理论上做了更深入的分析，让这个思路更有道理，可能会有更多工作继续做下去。

**大型语言模型**（LLM）是一个很有意思的路线，但我不知道它会不会是正确的路线。我最终希望找到更好的东西，而不是满足于现在的框架。总会有各种可能的问题，而这些问题如何用别的方式来解决，这是一个很大的课题。

现在大型模型最大的问题是需要大量数据，训练出来的模型质量肯定很好，但效率远不如人类。人学习的样本数非常少，一生能学到的**Token**（Token: 文本处理中的基本单位，可以是词、子词或字符）数目可能最多只有十亿级别。而现在大型模型的训练数据很容易达到十万亿甚至三十万亿的规模，中间有一千倍的差距。如何用人类的学习能力去弥补这个差距，非常困难。但人就是能学得很好。我们知道在人类意识场合中，有各种各样非常厉害的科学家，他们的思路和想法都是独一无二的。他们那个时候也没有看过那么多书，也没有那么多数据，但他们就是能够发现一个很有意思的新定理、新证明、新发现或新发明。对他们来说，这些能力是从哪里来的？大型模型现在用了那么多Token之后，有没有达到人的能力？这其实现在是一个很大的问号。

所以，如果真是这样，也许我们现在的训练算法并没有达到最优。有可能有更好的算法、更好的逻辑、更好的方式去学习数据中涌现出来的表征，用它来解决问题。也许梯度下降并不是一个特别好的方案，可能有一天也许不需要做梯度下降了，可能用别的方法来做。这可能是一个比较有意思的方向，可以去实验。

最近业界对**强化学习**（RL: Reinforcement Learning）有一些争论，特别是Andrej Karpathy最近接受播客采访时发表了一些比较负面的观点。我一直是做这个方向的。**强化学习**比较好的地方在于它本身是一个搜索过程。你给定一些难题让它去搜索答案，在搜索过程中学到的数据和获得的信息，其质量要优于被喂给它的数据。这相当于一个人去老师那边听课（监督学习），另一个人自己去玩，然后把问题解决了。我觉得后者学习出来的能力更本质，解决问题能力更强。所以我觉得在这方面，强化学习应该优于**监督微调**（SFT: Supervised Fine-Tuning）。

确实，现在很多文章表明，强化学习的能力在很多问题上，特别是在推理问题上，要比监督微调强。如果你要做强化学习，才能让模型真正学会推理。如果你做监督微调，模型可能只是记忆了之前的推理过程，但并没有产生泛化能力。在新的问题上，泛化能力可能没有那么强，特别是如果你做了大量的监督微调，模型质量可能会下降。这是两者的区别。

强化学习只是一个范式，它没有什么神秘的东西在里面，因为它最终的目的还是改变权重，这跟监督微调是一样的，只是改变权重的方式不太一样。最终也许存在一种方式可以统一强化学习和监督微调，因为最终目的都是改变权重。也许有更好的方法来解决这些问题。强化学习对大家来说，其实就是一种不同的数据采集方式，它通过边搜索边采集，然后把数据放在一起再训练。这种方式相当于一个主动学习的方式，跟监督微调的方式是不一样的。所以我觉得强化学习最大的好处是它是主动学习的，它能对数据的分布产生很积极的影响，这是它最最最核心的地方。而不是说它的目标函数不一样或者训练算法不一样。最终还是看它最终采集的数据的质量是跟监督微调不同的，所以它才能够解决一些比较难的问题。

Andrej Karpathy之前说的那些东西，有些我也觉得挺好的，比如关于**通用人工智能**（AGI: Artificial General Intelligence）还有十年的论断，就是我们是进入一个十年而不是立即就能获得通用人工智能能力的时间。这个我是相信的。我自己之前也用过GPT-5帮我一起做一篇文章，我最厉害的一篇文章其实是我和GPT-5通过**自我对弈**（Self-play: AI通过与自身对战来学习和改进的过程）探索出来的。就像在我没有任何学生的情况下，我每天跟GPT-5对话，提出问题，它会给出公式。但你会发现，如果你自己没有领域知识（domain knowledge），这个公式做出来的也跟大家差不多，没什么创新性或原创性。但作为研究员，如果我对这个问题有很深的理解，或者我知道这个公式、影响或思考方式是不对的，或者它的公式里有致命的问题，那么把它指出来，然后告诉GPT-5，它就会在这方面更深入，最终得到一个比较好的结果。所以，这种高层的人类洞察力（human insights）、人类知识（human knowledge）和对问题的独到见解，是现在的模型所缺乏的。你必须有这些东西之后，才能让这个模型变得更强。所以，如果说通用人工智能没有这些东西，那它就不能算是通用人工智能。

### 人类洞察力与AI的边界

最顶级的洞察力永远都来自人类。这个问题以前我也讲过，跟以前自动驾驶是一样的。一开始进展非常快，大家会觉得哇，马上就取代人了。但是越往后走，问题越大。为什么呢？因为好的洞察力、好的数据越来越难找，数据越来越少，那你的模型就训练不上去。人对于数据的获取能力和人对于数据的深度挖掘能力永远是超过计算机的，现在是这样，超过所有的模型。同样的问题，人可能只要一两个样本就能看到本质，但是计算机或者说现在的大模型，它可能需要至少几百上千的样本才能大概感觉到一个轮廓。预训练可能需要更多样本。在这种情况下，如果样本数不够的话，人永远是比现在的大模型厉害的。特别是对一些小领域的专家，他们甚至自己也没有办法把自己学过的样本呈现给计算机看，因为这些样本可能在他脑子里，就是他的经验，这些经验很难去量化成一些句子。所以，如果真是这样，那AI就只能永远跟着人后面走，人通过某种比较好的信息处理方式获得一些洞察力，然后关于资本经济，关于用AI让AI在这方向上做得更好，目前是这样的一个状态。

### Skin Law与效率挑战

这跟我之前的一些论断也比较接近，我以前也接受采访说**缩放定律**（Skin Law: 指模型性能随计算资源、数据量和模型参数增加而提升的规律）是一个悲观的未来。因为**缩放定律**这个话题本身是一个很奇怪的话题。如果在以前，大家说我加入指数级的样本或者指数级的计算能力之后，我们的性能正在上升，而且上升的速度是线性的，以前的机器学习科学家会觉得这些事情是微不足道的（trivial）。因为不管什么模型，你都可以做出这样的论断，就是往里面塞数据，然后就会有更好的结果，这都是这样子。但是我觉得我们真正追求的是什么样的模型能够在这条路线上走得更有效率（efficient）、更快，而不是满足于这个定律是对的。因为这个定律它给你通向的未来其实是一个比较悲观的未来，就是说你需要用指数级的样本塞进去才能得到一个比较好的结果。如果是这样的话，那么总有一天我们地球上所有的资源，就像所有的能源、所有的电力，全部都会被用来训练大模型。在这种情况下，我们是不是还要依赖于这样的能力去改变我们这个世界？这是一个很大的问题。我觉得在某个时候，大家可能会意识到计算量不是全部，我们可能需要对模型有更深的理解。而且这个改变应该会慢慢发生，这是我的一个想法。

我们需要一个更高效的方式来发展智能。但这需要很长时间才能找到这个解法吗？我觉得大家也在努力，所以应该会花一些时间去做这些事情。但至少对现在来说，大型模型的能力是很强的。就算我们现在这个模型能力停滞不前，它对于各行各业的影响也是非常大的。我觉得至少能够自动化很大一部分东西，然后能让很多人的能力变得更强。我觉得大型模型已经远远超过以前的我，这让我觉得这上面有很多功能可以做。我觉得这本身是一个新时代的到来，所以就算大型模型的进展不够快的话，未来至少两到三年，三到五年这段时间之内，我觉得还有很多很多机会。

### 开源与闭源之争

关于开源和闭源接下来的发展，现在很多人都在开源，特别是国内的公司。我觉得开源还是会有的，而且应该会继续发生。像我所知的一些公司，比如Reflect、AI2，他们都在做开源模型，他们有很多想法想做这些东西。像之前的OpenAI也做过一些开源的GPTOSS模型。所以我觉得开源还是会有的。

接下来的问题是这些模型有什么用？不管开源还是闭源，一旦模型出来之后，它可以用作聊天工具、创作工具、效率工具，这些大公司会做。还有很多其他方向，比如这个模型可以用来做一些科学发现（scientific discovery），或者做科学家，或者做垂直领域的一些工作，这些小公司就可以做。在一定程度之后，模型需要有多强才能把问题做出来，这可能是一个因人而异或者因问题而异的问题。因为最终会发现，在不同领域下面，我真的需要一个模型在所有方面都很强吗？不一定。可能就是说只在你关心的方向上比较强，那么这个时候可能就开始分化了。每个人、每个模型可能都有自己的想法，每个公司做这个模型有自己的目的，然后会有各种各样的不同模型做不同的事情。

在这种情况下，可能会有一个不同的策略。有些模型希望开源，因为开源之后大家用了，可以用来做一个社区或者一个工具平台，那么这个时候你开源是很合理的。比如说我有一个模型，训练完之后可以调用标准工具集，然后我在这标准工具集上可以用这个模型去做一个平台，大家用着，那肯定要开源。但如果是其他一些领域，比如如果这个模型是用来做个性化搜索（personalized search）或者个性化推荐（personalized recommendation），那这种模型应该说不太愿意开源，或者说每个人自己训练一个模型当然是不开源的。所以最终看最终的目的是什么，而不是泛泛地说开源和闭源哪个好哪个不好。最终看公司的策略，因为每个公司和每个人其实都是不一样的。

所以，在**最前沿**（SOTA: State-of-the-Art）的模型上面，可能很难有一个开源的去跟闭源的直接竞争。但在很多小的垂直模型上面，还是有非常非常多开源的机会。

### 研究范式与个人成长

我的下一步是什么？当然最好是把研究和应用结合起来，如果我能做一个前沿研究，并且这个前沿研究是自动化的研究，那就很厉害了。我已经感觉到我的研究范式可能都会被自动化的流水线（pipeline）所代替一部分。不一定是智能体（Agent），但智能体肯定是一个很重要的因素。用智能体可以帮你做很多事情，比如你也许不需要自己回邮件了，或者说你不需要自己去管理自己的待办事项，或者说你不需要自己去做一些繁琐的事情，这些东西都可以用计算机来帮你做一些自动化。这个问题肯定会发生。

更重要的是，AI能不能代替人的一些高级活动？人的一些比较高级的思路，比较难的，需要人的一些重要洞察力的活动，那些活动有多大程度上能够让AI帮忙去做成？有很多难的一些科学问题，AI能不能把这个事情做成？现在还不知道。如果能做成，反过来也可以对我研究产生影响。那么原则上来说，也许我会成为一个超级研究员，加入了很多AI之后，我一方面能做更好的研究，另一方面这些工具本身也可以用来造福别的东西。如果是这样的话，肯定会很有意思。

在被拉去救火Llama之前，我们这边在做一些关于推理（reasoning）的研究，主要是关于**思维链**（CoT: Chain of Thought）的形态和训练方式做了一些研究。其实我们在O1出来之前（O1是去年9月份出来的），我们就注意到非常长的思维链它会对整个模型的**缩放定律**（Skin Law）产生影响。如果一个问题没有那么长的思维链，它的**缩放定律**就没有那么有利（favorable），就是说你需要发很多很多样本才能获得一个比较好的结果。但是如果你有很长的思维链，你就会让模型的**缩放定律**曲线变得非常漂亮（nice），就是说我可以用比如十分之一的样本获得更好的效果，十分之一的参数就有更好的效果。这个我们已经发现了。

接下来我们就在这个思维链上做各种各样的变换或者探索，包括我们最近做的**连续思维链**，就是用连续空间来做隐空间推理。这篇文章现在确实受到了不少关注，可能半年就有200多个引用，很多人愿意做后续的探索性工作，而且确实能看到一些进展。所以我觉得这些东西都很有意思。我们去年也做了一篇叫**Duo Formal**的文章，比较早地提出了如何做**混合思维模型**（Duo Formal: 一种结合长短思维训练的AI模型），就是长思维和短思维放在一起训练，然后发现这模型其实比单纯训练长思维或单纯训练短思维效果更好。现在这已经成为标配了，大家所有的思维模型都有这种长短思维自适应的性质。所以应该说去年这些研究还是比较跟得上时代的。

在FAIR还有什么遗憾？我觉得遗憾可能是这样，我应该在FAIR做更多的工程工作，可能好一点。我刚去FAIR的时候，大概在前几年，工程化工作做得比较多。我之前的一些项目，像围棋这些项目，工程化都是自己做得比较多。当时我其实还被批评说“这个人过来是研究科学家，怎么天天做工程”。别人打开屏幕评论文章，我打开屏幕评论代码，当时我是这么被批评的。后来我就说好，如果研究科学家不能做工程的话，那我就看看文章。所以你会发现我在2015年到2018年这段时间之内基本上工程比较多，然后到2018年之后到现在研究比较多。这当然是跟FAIR当时的一个指挥棒有关系，另外一方面就是说我自己也有一些研究上的兴趣想要做更多的研究，那么就切过去了。但是现在你会发现，其实现在这个时代工程能力强的人反而更受欢迎。研究能力强的人也很受欢迎，但是最好是工程能力和研究能力都强，这样是最好的。这确实很难，但我觉得我可以做到这一点，所以我现在也在更多地做一些工程上的工作，我可以把很多东西再捡起来，把这些工程事情做好，这都是可以的。

在FAIR最大的收获，应该说是2018年之后，我在这段时间之内培养了很多**研究品位**（Research Taste: 指研究人员对有价值、有潜力研究方向的判断力和洞察力），知道了怎么做研究的一些方案，都慢慢学会了。而且应该说这些品位在最近几年的文章里面也慢慢体现出来。所以应该说有品位之后，其实对相关的道路应该说有很大的帮助，这很重要。因为如果一个只做工程的人，他有一个比较大的问题，他可能会只做工程上的一些难题，但并不知道这东西有什么用。但是如果有**研究品位**的话，那意味着自己给自己设一条道路，可以一直往前走。这对于一个人的人生来说有非常好的好处。

### AI人才的稀缺性与选择

现在各公司AI竞争激烈，人才抢夺战也很激烈，像OpenAI的Ilya Sutskever团队就花很多钱在一个人的身上。现在这个阶段什么样的AI人才是最稀缺的？我觉得这完全看每个人的定位。首先我想纠正一点，大家不要去想现在谁是最稀缺的，因为有可能过两年这个稀缺定义就发生变化。所以，大家应该想一想什么才是自己最想要做的事情，而不是去做那些可能公司喜欢的事情，我觉得这个可能更重要。因为整个过程可能已经跟以前不一样了。

以前的情况是，市场发出信号，说我们需要什么样的人才，这信号可以通过大学的方式慢慢往下传播。比如说最近十年之内什么样的技术吃香，这个信号传到大学，大学会扩招对应的系，扩招对应的老师，一些学生就会去投这个系，然后经过四年或者更长时间的培养之后，这些学生最终满足了市场要求，大概是这样的过程。以前这个循环是走得通的，因为整个逻辑、整个速度是比较慢的，这个行业周期可能以十年或者二十年的周期来波动，所以这个过程是可以的。

但是现在可能整个周期变得非常快。等到你想要学市场上火热的技术之后，全世界的人都在学。你想到了，别人也想到了。全世界都在学，世界上总有学得比你快的，总有学得比你好的，总有马上上手把事情做成的。所以你很有可能会发现你学了半年一年之后，你做不过别人，你还是没有办法出头。那么这样的话，市场发生变化，说我现在也许明年就不是某个方面的能力最重要的时代了，可能换了别的东西。那你这时候再去学，就可能一直会跟着别人屁股后面走。所以也许以后大家会突然发现，与其听从市场的号令，还不如说我自己做自己想做的事情。一个做得很开心，另外就是说一旦这个东西被人发现了，它的收益是很大的。这当然是理想情况了，因为实际情况肯定是会两边要结合，你肯定会希望这个东西你自己判断在将来一段时间之内有没有用，再加上你自己的爱好，做两个拼起来得到一个比较有意思的组合，那之后你可以在上面花功夫。所以应该说非常难去做判断，完全看你自己的能力。

### 理想化的研究环境

我感觉你还是一个非常有理想主义的人，FAIR之前也是一个非常有理想主义的团队。但在当下，市场有点扭曲了，因为竞争特别激烈的时候，很多的文化、很多的信仰就会出现一点偏差。你觉得在现在这样的情况下，还存在比较理想化的研究实验室吗？当然，比如我们看到Ilya Sutskever的团队，以及DeepMind的Demis Hassabis的团队，都被认为是比较有理想主义的。而他们的对面就是Sam Altman，非常激进。你怎么看这个平衡？

我觉得首先是这样，你不要把大厂当成铁板一块。其实有很多的组，很多组他们里面有研究团队，这些团队本身也会有一些研究上的自由（research freedom），这是会存在的。FAIR只是一个非常有名的品牌，但其实有很多地方，他们没有像FAIR那么有名，但他们也有一个自由空间可以做研究，这都是有的。就算在Meta内部也有不少的组，他们也有做研究的空间，我有很多客座研究员在Meta里面，他们也做一些研究。所以这个问题我不觉得是个问题。

也许就算FAIR可能因为这次的原因，导致以后可能研究做得就没有再那么“研究型”了，但是还是会有很多地方可以做。甚至你说做创业公司的时候，你也甚至有可能在有些地方，因为这个问题很前沿，那你在上面肯定会有些事情可以做。因为我们在讨论研究的时候，是指这个过程本身，就是找到一些新的解决方案来解决一些难题，这叫研究。所以它不是一个抽象的概念。

我觉得有很多地方可以做，不是说大厂不能做了，小厂可以做，不是那么简单。这完全取决于哪个组、哪个人有什么样的资源、什么样的东西，然后这些人放在一起会产生什么样的反应。可能今天可以做，明天不能做，或者一段时间之内他有这个空间，然后换一个其他时间就没有这个空间。无数人都在思考这个问题，也许会在这段时间之内肯定出一篇新的工作，然后去影响整个领域。所以应该说研究永远会继续进行，只是说它的形式可能会变成像游击战这种形式，并不是说有一些非常知名的研究机构他们会做研究，他们会说我投入我们所有的时间和精力去做研究，可能不是这样。但是你会总会发现有很多有理想的人、有理想的小的组织在继续做他们想做的事情。

### 下一步动向

我的下一步是什么？我刚才说了还没确定，还在讨论中。因为现在离被裁还不到一个礼拜，所以也会有一些考虑和想法。刚才问的是我想去做应用还是想继续做我的科研研究，我的回答是最好两个结合。听起来我们能找到一个办法，能够赋能我的科研研究，同时本身也能做很多别的事情，这样的一个东西。有这样的机会存在吗？我不知道，但是一般来说是这样，我们先瞄准高目标（aim high），然后再去看。因为一般来说人会表现是说有这样的机会我就不用想了，但是其实应该是倒过来，你先想一个不可能实现的目标，然后再去想有什么东西可以符合它，这可能会让你有更好的方向可以走。

好的，那就期待你接下来宣布你的下一步动向了。以上就是我们对田渊栋的采访全部内容，我们也期待他的下一步动向。我非常希望他能够找到满足前沿研究和工程应用两者平衡的新角色。我想这也是AI的前沿工程师们都在探寻的路，祝他好运。你们认为这样的AI工作存在吗？欢迎大家给我们留言、转发和点赞，你们的支持是我们硅谷101做好深度科技和商业内容的最佳动力。那我们就下期视频再见了，拜拜。