---
area: tech-insights
author: Lei
category: technology
companies_orgs:
- Meta
- FAIR
- Tencent
- OpenAI
date: '2025-11-01'
draft: true
guest: ''
layout: post.njk
media_books:
- Twitter
- Xiaohongshu
- 《金庸小说》
- 《Nature Machine Learning》
- 《关于ChatGPT最重要的五个问题》
people:
- Ilya Sutskever
- Rich Sutton
- Geoffrey Hinton
- Andrej Karpathy
- 孔子
- 课代表立正
- 田渊栋
products_models:
- GPT-5
- Claude
project:
- ai-impact-analysis
- systems-thinking
source: https://www.youtube.com/watch?v=zAzsDHpR4xs
speaker: ''
status: evergreen
summary: 前 Meta 资深研究员（Tianyu Lin）探讨了 AI 学习的核心机制，特别是模型如何从“记忆”跃迁到“泛化”（Grokking/顿悟）。他分享了其团队在
  Meta 的贡献、对研究者“洞察力”的定义，并提出了一个理论框架：学习过程是一个优化景观，泛化峰值随数据增加而超越记忆峰值。他还讨论了损失函数作为“代理”的本质，以及
  AI（如 GPT-5）在未来科研中的辅助角色。
tags:
- grokking
- health
- insight
- learning
- mental-model
- philosophy
title: 从 Grokking (顿悟) 到科研哲学：AI 如何从记忆转向泛化
---

## 关于 Meta 裁员与发帖初衷

田渊栋: 反正现在我没有 access 了，就是所以也算自由了吧，就是想干啥干啥了。 [00:00:00 - 00:00:06]

课代表立正: 恭喜。我是在准备访谈的时候，才发现你在 **Meta**（Facebook 的母公司）已经工作10年了。 [00:00:08 - 00:00:13]

田渊栋: 2015年...不是，15年 Meta 还是一家很小的公司。 [00:00:16 - 00:00:19]

课代表立正: 你加入的时候 Meta 多少人？ [00:00:21 - 00:00:23]

田渊栋: 那个时候可能大概有1万多一点吧。其实（公司）也不小了。不是特别小，但是现在可能几十万。 [00:00:24 - 00:00:35]

课代表立正: 我们可以聊一些论文，我觉得这个还是比较好。 [00:00:46 - 00:00:49]

田渊栋: 因为我其实并不想说太多裁员的事情。我也觉得这个不太好。 [00:00:49 - 00:00:54]

课代表立正: 小红书上也是，刷到你的名字，一天刷到了好多。 [00:01:02 - 00:01:05]

田渊栋: 其实我觉得，我这边本意就是，因为我这边 team 也有几个人是被影响到了，所以我当然希望他们有更好的机会。因为我是无所谓了，我最惨的话，不行就在家里待着。但是他们很多人身份（签证等）会有些问题，如果不能及时找到下一家（公司）的话，那肯定要想办法。我也帮帮忙，帮找一找，因为我毕竟这边认识人比较多。 [00:01:06 - 00:01:32]

田渊栋: 这个也是我的本意吧。我也不怕自己暴露自己被裁，i don't care。但是就是希望我的手下那些人（前同事）能很快找到工作。 [00:01:34 - 00:01:44]

课代表立正: 腾讯新闻的人，他说想采访你。说聊论文也行，聊 Meta 公司的内部问题也行。 [00:02:01 - 00:02:12]

田渊栋: 我觉得是这样，不要聊 Meta 公司内部问题，我觉得我已经说够多了，我不想再说了。 [00:02:17 - 00:02:21]

课代表立正: 那你有兴趣跟他们聊论文吗？ [00:02:23 - 00:02:24]

田渊栋: 聊论文，要看聊什么论文吧。那也是可以的。 [00:02:25 - 00:02:28]

## 澄清团队贡献：我们不是“背锅侠”

田渊栋: 我不希望聊太多 Meta 公司内部的。因为其实我觉得，我一般不太愿意说这些。然后我觉得，我在 Twitter 上唯一说的是，因为就是有人跳出来说，你们被裁是应该的，因为东西没做出来。但是，那我要至少给我们的 team 要做澄清。因为我们 team 说了很...的重要工作，那你不能把锅扣到我们头上。所以这个肯定是要讲清楚。 [00:02:29 - 00:02:56]

田渊栋: 但是我现在就比较 defensive，就是 OK，如果有人说这个是我们的锅，那我们会说回去。但除此之外我不会说太多，就是公司内部的事情。 [00:02:56 - 00:03:07]

课代表立正: 好，那你还有没有什么想澄清的？ [00:03:08 - 00:03:12]

田渊栋: 我觉得差不多了。我们其实还是做了很多的工作，就是把（公司）很多的之前的一些问题解决了。 [00:03:14 - 00:03:19]

田渊栋: 比如说，包括 long context 的那个 **reinforcement learning**（强化学习）有没有训练的好，还有包括前面的 **pertaining model**（预训练模型）啊，他们的 design 其实可能有些问题，像有 long attention 的问题。 [00:03:19 - 00:03:30]

田渊栋: 这个其实很多是我们团队解决的，就是，反正是我先发现的，关于这个 design（方面）有问题，然后去跟他们（公司侧）讲。 [00:03:31 - 00:03:37]

田渊栋: 但是一开始就很难去...就是他们不一定会听。因为我当时去的时候是，按照一个 research team 来做的。而对方（相关部门）是做大模型的。那么我这边 research team 过来的话，他们不一定会听。那他们可能会觉得这个（观）点，（或者说）这个事情没问题的，肯定是是对的。 [00:03:38 - 00:04:00]

田渊栋: 那我们这边要用各种实验就证明，我们之前的那些发现，或者说 **insights**（洞察）是对的。但是，后来是他们是被说服了，所以他们才会发现其中有问题。 [00:04:00 - 00:04:10]

田渊栋: 所以这其实都是我们团队的贡献。还包括，怎么样去让 long context first training 更加稳定，包括有很多的 blow up 的问题，怎么样去解决。这些东西都是我们这边做的。 [00:04:10 - 00:04:24]

田渊栋: 所以，这些东西，也属于“幕后英雄”嘛。就是，因为毕竟最终我们这个模型，也没有真正 official release。至少我们有一些贡献在里面，这个我是得说说出来。那么这样的话，至少为后面的人添砖加瓦，做一个比较好的 base。 [00:04:26 - 00:04:47]

## “洞察力”的价值：研究员的宝贵财富

课代表立正: 说到这，我有两个问题。第一，你们作为一个 research 团队，人家不信任你，可能是觉得，之前你没有这个 train（训练）大模型的经验。但是你们能很快发现问题，你觉得为什么可以做到？ [00:04:47 - 00:05:14]

课代表立正: 第二个就是，对面的大模型团队，是个什么样的团队？他们自己本身大模型训练经历丰富吗？ [00:05:14 - 00:05:20]

田渊栋: 他们是 Llama-1 或者 Llama-2 训练（团队）出来的，是经验丰富的。但他们有一些...应该说是，他们有一些地方（比如）之前的实验有 bug。然后这个 bug，导致他们做出错的判断。 [00:05:21 - 00:05:35]

田渊栋: 但是我们这边虽然说没有训练大模型，但是，毕竟也是做过关于大模型的一些文章嘛。对吧，包括我以前做过 **Sparse Attention**（稀疏注意力），那我当然对（比如）注意力结构，我知道是怎么回事。那当然，我一看这其中的设计，就觉得有问题。 [00:05:36 - 00:05:53]

田渊栋: 我相信，也有很多人都能看出来，这个并不说是，只有我能看出来。 [00:05:53 - 00:05:57]

田渊栋: 但是，也很难去说服他们。就是，你要花很多时间和精力去跟他们说，说这个是有问题的。一直到他们自己团队发现了问题，也是有这个问题，那么慢慢的就是会改变这个想法。 [00:06:07 - 00:06:22]

田渊栋: 所以应该，就是说，虽然作为研究员，就是可能我们当时做研究的时候，并没有直接去接触超大模型的训练，但是关于研究的那些直觉，或者说相关的经验其实很有用。能够很快的找到问题，能够发现什么地方是有问题，或者是有出错的，要怎么样去解决。我觉得这个是很重要的。 [00:06:22 - 00:06:47]

田渊栋: 这个是作为一个研究员的宝贵财富。就是因为说实在的，如果是一个完全没有任何 insights 的人，就是 OK，我天天就跑实验，然后调参数。那这个工作其实你说你能做，别人也能做。 [00:06:47 - 00:07:01]

田渊栋: 对吧，那研究员的优势是说，我能不能，根据一些非常稀疏的数据点，能够得到非常重要的结论，然后这结论能够推广到更难的问题上。这个是研究员的能力。 [00:07:01 - 00:07:17]

课代表立正: 你说的稀疏的数据数据点，是不同论文和不同实验的结果？ [00:07:17 - 00:07:24]

田渊栋: 对，比如说，如果我是一位新来的“菜鸟”，那么对我来说 OK，我的任务是调参数，跑程序。那我跑比如说我跑1万个点，那我就得到1万个点的参数值。然后我就说，我告诉大家，这1万个点数是我跑的。跑完之后跟大家说 OK，跑完了，那这个是我的结论。 [00:07:24 - 00:07:41]

田渊栋: 但是跑完之后，这1万点数值在那边是“死”的。那么你也没有什么 Insights，没有什么概念，说，这1万点其实背后代表了什么意思，有什么样的结构。 [00:07:41 - 00:07:50]

田渊栋: 那这个，其实只有那些有经验的人才能看到。（如果）有经验的人可能看到，看了，比如20个点，就知道（其中）有什么问题。甚至就说看了10个点，就看到，就说这个 training curve 刚 train 到一半，（发现）哦，我知道行不通了，不要继续跑下去，可能（是因为）这其中有些问题。 [00:07:50 - 00:08:03]

田渊栋: 所以这里其实（要表达的是），为什么 AI 研究员（整体）还是薪资比较高，我觉得很多时候是这样。就是你的一个 insights（能力）可以，比如说可以抵100块卡，或者说抵1000块卡，一万张卡等。就是比如我不需要那么多卡，但是我还是有 insights，可以得到一些比较好的结论。 [00:08:03 - 00:08:21]

## 什么是“洞察力” (Insight)？

课代表立正: 你刚才用了两个词，一个是经验，一个是 insights。然后我想 double click 一下，就是这个到底是个什么东西？有的人会觉得这是一个 taste，有的人会觉得是个 intuition。对吧，我们有好多词去形容这个东西。 [00:08:24 - 00:08:37]

课代表立正: 那你能不能就是给大家讲一讲，从你的经验来说，你用多长时间，能判断一个人，有这个还是没有这个？ [00:08:37 - 00:08:54]

田渊栋: 这个我觉得是这样，就是 Insights 呢，是一个比较，很难描述的一个概念。就是说，特别是一个有经验的人，对吧，比如说在某方面他是位“老师傅”。那么他怎么做？就是他要根据很少的数据，然后判断他就是这个现象，背后的真正原因是什么。这个是重要的。 [00:09:07 - 00:09:30]

田渊栋: 就是比如说一个修车师傅，他可能根据蛛丝马迹，会知道你车哪里坏了。或者说股票交易员，比如说操盘的时候，比如说有一个做股票交易的，那我说我根据这两个迹象，或者看看财报，嗯，比如这个这个股票（等）不能买。 [00:09:30 - 00:09:49]

田渊栋: 所以这种东西（能力）是很重要。然后他也不知道，也讲不清楚到底怎么回事，他就有种感觉说，这个不行，那个行。有一个 **mental model**（心智模型），然后这个 mental model 大概率是对的。 [00:09:49 - 00:09:58]

田渊栋: 所以这个（能力项）很重要了。就是有这些东西之后，其实就是很快能够发现问题在哪。然后有这问题我们怎么样，怎么样去解决，去解决这个问题。然后然后往正确方向去走嘛。这个是，可能比 GPU 还要重要。当然了 GPU 也很重要了，就是有 GPU 之后你会做更多实验，获得更多的 Insights。所以这两个是相辅相成的。 [00:59:59 - 00:10:23]

课代表立正: 你能很快的判断另外一个人，有没有一个好的 mental model 吗？ [00:10:24 - 00:10:28]

田渊栋: 这其实是有一些办法。就是说，你要跟别人聊嘛。然后大概聊一下，感觉一下他平时对这问题是怎么想的。 [00:10:31 - 00:10:40]

田渊栋: 对，其实我可以举个例子吧。比如说，那个学校里面有这种 PhD exam 啊，就是说 PhD **quantifier**（博士资格考试）啊。就是说一个学生，坐在那个教室中的一堆老师们面前。然后老师问他，就是，我请你，对这个问题有什么了解。 [00:10:41 - 00:11:00]

田渊栋: 比如说我们讨论一些学术问题。那么对这老师来说，他想办法就问到底。就是比如说，你对这个偏微分方程，有什么想法。然后就会抓住一个点，然后使劲问。问到，问到就是你能（了解到）他到底懂不懂。他到底知道这里面之间什么关系，这个是能用最简单的语言讲清楚。 [00:11:00 - 00:11:24]

田渊栋: 对，然后就能够知道，最重要的两个东西的关联是什么。那么这样的话，就知道这他真是懂的。或者说他真的是知道这是最关键的关联在哪里。然后可以用这关联去做更多的（比如）推广等。 [00:11:24 - 00:11:37]

田渊栋: 就是因为比如说像做研究的话，比较忌讳的是说，我就只懂书面知识。（比如有）12345，背出来了，概念套概念。但是他们（之间）有什么关系，然后什么时候他们两个（在什么条件下）能不能成立，什么时候要 a into b，什么时候 a into c，这个并不知道的话，其实是比较难搞的。 [00:11:37 - 00:12:00]

田渊栋: 对，其实这个很重要。就这说实在的，是我觉得现在的模型才做不到的地方。对，现在模型可能，没有办法用很少的数据，真的去预测将来的那个结果。 [00:12:00 - 00:12:14]

## Grokking (顿悟)：从记忆到泛化的底层机制

课代表立正: 那我们就直接到这个话题吧。你的论文是 Grokking。 [00:12:16 - 00:12:27]

田渊栋: 嗯嗯。 [00:12:28 - 00:12:28]

课代表立正: 但它是一个底层的这么一个...就是一个时间点，它有了一个学习的这样的东西，顿悟的感觉。 [00:12:28 - 00:12:35]

课代表立正: 对，我在看你跟志渊的专访里边，你也提到一个点。就是那个鸽子问题嘛。 [00:12:37 - 00:12:48]

课代表立正: 然后你是，当时和丹利.周，在这个 Twitter 上的，关于 chain-of-thought 的一些讨论。就是说确实，理论上，你的这个逻辑能表述 chain-of-thought，就似乎可以解。但是模型会用无限的数据，去试图解决这个问题。但是，人似乎一下子就能 get 到这个问题。我觉得和你刚说的那个东西，有一些联系。 [00:12:50 - 00:13:16]

课代表立正: 但是，如果你来定义这个能力的话，你会把它定义成 reasoning 吗？还是你把它定义成一个什么？ [00:13:19 - 00:13:25]

田渊栋: 这个顿悟呢，应该说呢，并不一定是，就是它是在 reasoning，或者说其他的一些 task 下面...是更底层的意思。 [00:13:25 - 00:13:40]

田渊栋: 就是说它是一个 **representation learning**（表征学习）的一些行为。就是，我随着这个训练的拓展，你会发现，它的表征会改变。 [00:13:40 - 00:13:51]

田渊栋: 就一开始就说，这就相当于比如说，你看《金庸小说》，然后张无忌，一开始被他义父谢逊逼着，需要你把东西全背出来。说先把东西全背，背出来之后，先反复，先全背出来。背出来之后，你不懂没关系。但是，不懂你可以脑子里存着。然后过了几年之后，突然之间就，练了乾坤大挪移，突然懂了。 [00:13:51 - 00:14:12]

田渊栋: 就是这个是很有意思的一个机制嘛。其实，比如说你当时教小孩子，可能也是这样。特别是教有些小孩说，你先把它背出来。这个叫“读书百遍其义自现”。就是你现在先读，读了之后你并不知道什么意思。但是过一段时间之后，或者说你跟其他的一些事情，能够联系在一起了之后呢，你就会有一个...就突然之间你会觉得，哎，这个意思，是跟我这个现实世界是有关系的。或者说，这两个意思之间是有关联的，我们知道更深的联系。这种其实就是应该说是顿悟的一部分。 [00:14:12 - 00:14:49]

田渊栋: 对，那这个是机制。其实是，就是思维链之下的。就说不管你用思维链做思维训练也好，不管你用那个直觉来判断那个答案也好，或者不管你用啥方式来判断答案也好。对吧，那么这些东西，它的下面有一个共同的机制，就是说，我到底用什么样的表示，用什么样的对这个世界的理解，导致了这个思维链。 [00:14:49 - 00:15:19]

田渊栋: 就比如说我举个例子吧。比如说吧，那个小学生做一道题，对吧，他可能说，我这道题怎么做？我用穷举法啊。那个1+1等于多少，1+2等于1+3等于多少。那么有一些，穷举的一个路径，可以把这个事情做了。 [00:15:20 - 00:15:34]

田渊栋: 但是你这种方式呢，其实可能很多方面解决不了。那么等到，比如说初中生或者高中生，他们的这个思维其实有种飞跃。什么叫飞跃呢？就是说，我们告诉它，我们可以用 **数学归纳法**（Mathematical Induction）来解决这个问题。 [00:15:45 - 00:15:58]

田渊栋: 那么数学归纳法这个思维，这个层次，是高于就是穷举法的。就如果你的数学归纳法，能够证明这个事情是对的。那么，它就对所有的那个自然数都成立。那这样的话，我的穷举法，就穷举无穷长的那个思维链，它其实都比不过数学归纳法的很短的证明啊。 [00:15:59 - 00:16:19]

田渊栋: 所以这个是一个飞跃。就是说这样的话，你对这个问题的理解跟那个两种方式的思维链，它的后面的理解是不一样的。所以这个理解或者说这个表示呢，其实就是神经网络学习的一个重要的，一个不同的地方。 [00:16:19 - 00:16:34]

## 两种科研范式：黑盒缩放 vs. 理解机制

课代表立正: 很清楚。然后我想跟你对齐一个认知。就是当时我引用的...就是当时是伊利亚（Ilya Sutskever）去 MIT...2016年的时候，他去讲的。 [00:16:36 - 00:16:58]

课代表立正: 总之他当时讲了一个东西，我觉得他说的很深刻。就说为什么 back propagation 会 work at all...就是 theoretically optimal hypothesis class 等于 short programs。 [00:17:02 - 00:17:22]

课代表立正: 对，就听你刚那个意思，也是就是，本来我要去走好多条点，走到这。然后突然找到了一个更好的联系，然后我就有一个更好的压缩，然后它就更 generalizable。 [00:17:22 - 00:17:34]

田渊栋: 对。就是说因为压缩，可能也可以说是更通俗的解释。对吧，但是什么时候这事情能压缩，什么事情这些不能压缩，其实现在不是很清楚。 [00:17:35 - 00:17:46]

田渊栋: 就是，为什么你要去研究 **Grokking**（顿悟：指 AI 模型在训练过程中，突然从死记硬背转变为真正理解和泛化的现象）这个机制，就是说，它给你提供了一个动力学过程，就是让你知道，它怎么从一个不压缩的状态，变成压缩的状态。 [00:17:46 - 00:17:57]

课代表立正: 我会发现，这个和人类理解知识的，似乎也很接近。就是这个，人类也是 information connect us 形成 knowledge。 [00:18:00 - 00:18:10]

课代表立正: 很多教育专家，他会发现就是人...reasoning 是一个人类固执的幻觉。对，然后这个教育专家说，the most important single factor is prior knowledge。对，你只要有 prior knowledge 就行了。 [00:18:13 - 00:18:28]

课代表立正: 那接下来的问题就是，我们不知道，我们的这些 knowledge，就是 connect us 是怎么形成的。对，我们没有办法去讲清楚。 [00:18:41 - 00:18:51]

课代表立正: 在大模型里边，你说在大模型里训练的过程中，似乎大家也不是很清楚。 [00:19:02 - 00:19:08]

田渊栋: 所以就是为什么，搞清楚其实可能会孕育着，就是下一个模型的一个契机嘛。对吧，如果你搞清楚了之后，你就知道什么地方你要修改。这样的话你就模型变得更强啊。 [00:19:08 - 00:19:20]

田渊栋: 所以这是也是个动力。就是因为我们现在就是...我把当黑盒子。然后我就上面调各种参数，开一个相当于一个很大的开关，有很多的开关。对吧，像以前那种电脑屏幕以前的那个大型机，然后有非常多的按钮开关。然后就是，我们就培养操作员坐在上面，然后我把按钮开关开开，就是各种组合，然后看效果怎么样。那这是一种方案。 [00:19:20 - 00:19:43]

田渊栋: 那另外一种方案，就是说我们要把这个大的机器打开，然后理解里面的机制是什么。然后有这个机制的理解之后，那我以后再去播这开关的时候呢，就非常有感觉。我就非常知道哪些开关要开，哪些开关要关，能把这个做出来。 [00:19:43 - 00:19:58]

田渊栋: 我觉得这可能是一个更好的一个做法啊。当然就是说，现在可能就是主流的思维，其实并不是这么说。并主流思维，觉得，（比如）我们就叫做 **Scaling Law**（规模法则：一种理论，认为模型性能会随着模型大小、数据量和计算量的增加而可预测地提升）。我说，我不需要搞清楚你们在干什么，我只需要知道，就（比如）机器量有很多很多，然后我放很多有分量厉害的人进去。然后呢，让他们去拨那些开关，然后这些开关的某种组合找到了，那我们就能够把这个模型做的很强。 [00:19:58 - 00:20:25]

田渊栋: 这两种不同的思维。但哪种是对的呢？现在也不好说对吧。因为现在确实 scaling law 有很大的应用，然后确实那个效果也非常好。 [00:20:25 - 00:20:35]

田渊栋: 所以至少目前为止看起来就是，我把当作黑盒子，然后让很多人去碰开关，得到一个更好的解，是一个比较好的方案。然后另外一方面，就是你从把那个模型打开那个，那个时间花的代价其实更大。因为其实并没有多少人真的知道，这模型里面在干什么。 [00:20:35 - 00:20:55]

田渊栋: 但是我觉得长远来说可能后者呢，会有更高的天花板吧。 [00:20:55 - 00:21:01]

课代表立正: 我同意你的判断。对，但这里边有这么一个点，就是我觉得，为什么黑盒子现在它是占主流？因为打开了以后人类似乎也没有办法，真的去判断什么东西是什么。 [00:21:02 - 00:21:24]

田渊栋: 所以就是能不能找到一个比较好的，能够理解整个结构的一个大的框架，是重要的。所以是这样，就是为什么我做成 paper 的原因，就是比如最近有一篇 paper，我们做 Grokking 对吧。那么证明这篇 paper，为什么要做这个 paper。所以我觉得就是通过这个方式，得到一个，对这个问题的一个大的理解框架，可能对以后的那个模型的改进，有很大帮助。 [00:21:29 - 00:21:52]

课代表立正: 似乎我们在学习 AI 怎么学习的过程中，我们会从人类身上，人类的学习过程中，取得灵感。 [00:21:59 - 00:22:07]

课代表立正: 包括最近很火的就是，Rich Sutton 出来说 RL 是学习的方式，是人类学习的方式。大模型这种方式不是要学习方式，它也不能学习，因为它没有 objective。 [00:22:08 - 00:22:20]

课代表立正: 那另外一派呢，可能我反而认为是 Hinton 而不是 Karpathy。Hinton 他说就是...你通过语言也可以得到经验。 [00:22:20 - 00:22:39]

课代表立正: 那这个 debate 我觉得很很重要的，最后就落到了，一个人到底是怎么学习的，然后什么是学习，以及怎么样子才能产生学习，或者产生新的知识，或者 connect the dots。 [00:22:40 - 00:22:56]

田渊栋: 我觉得就是通过经验学习，这个是对的。 [00:23:08 - 00:23:11]

田渊栋: 但说这个经验里面就是什么样的经验，是更有价值的。这个是一个比较大的一个问题。 [00:23:11 - 00:23:21]

田渊栋: 你要说，就是非常直观的经验。就比如说，有一派是这么说：我没有 **embodiment**（具身智能：指智能体通过与物理环境的实时交互来学习和发展的能力），我是没有办法去学到真正的感觉。这个是行万里路。对对对，你要行万里路，或者说你要真正感到痛，感到那个伤心，喜怒哀乐，你才能真正成为人。 [00:23:22 - 00:23:38]

田渊栋: 那么还有一种说法，就是说我有一些抽象的概念，我还是能够学会这样一些东西。对，我觉得这两个东西，其实应该说，不是说是互斥的。 [00:23:50 - 00:24:04]

田渊栋: 因为是这样的，就是其实最终是，我的目的，是要学到一个 representation，学到一个表关学习（表示学习）。因为如果你学到一个 representation 的话，那有个好的表征，那你对有的问题，你能够解决。 [00:24:04 - 00:24:19]

田渊栋: 就是表征是怎么学出来的，这个完全取决于，那个输入有多丰富，然后结构是什么样子的。 [00:24:19 - 00:24:27]

田渊栋: 所以就说，也许就是，不管你是直观的学习也好，还是抽象的学习也好，只要能学到这个表征，然后就能够最终得到一个比较好的那个泛化的效果。 [00:24:27 - 00:24:41]

田渊栋: 并不是说是一定是黑或者白，或者左或者右。很多时候是混在一起的，然后最终得到个表示，这表示能够，能够得到，就是能够进行预测，或者说能够操纵你的行动，然后能够泛化到一个新的没有见过的情况。 [00:25:02 - 00:25:19]

## Grokking 的数学解释：优化景观上的“山峰”之争

课代表立正: 那我觉得，顺着这个问的话，就是你刚刚所说的后者的工作，就是不是 black box，然后不是所谓的这种 scaling law，而是真的去打开它，然后去梳理它。那它的意义是什么？ [00:25:20 - 00:25:44]

田渊栋: 我觉得首先第一个就是说，数据遇到瓶颈的话，其实恰恰就需要这个了。因为如果数据到瓶颈的话，那你意味着 scaling law 不一定有效了。 [00:26:06 - 00:26:13]

田渊栋: 比如说你就这么点数据。对一些小众的领域，就是它可能每个小众，你看这样的坑就很少。所以这样的话呢，其实如果数据不够，再加上你的训练算法比较费数据的话，那你可能很难学会。就是说不管怎么样，你学会的永远是一个 memorization，或者说是记忆的结构，而不是一个泛化的结构。 [00:26:13 - 00:26:49]

田渊栋: 那么这种情况下，你怎么样去用 scaling law 做？你就说你得去找办法去做 data augmentation（数据增强）。也许这是一个办法。但是如果你对这个问题有理解，对这个模型有更好的理解的话呢，也许不需要 data augmentation。也许你需要，就是说，改变这个训练本身的算法，或者说训练的架构。 [00:26:50 - 00:27:09]

课代表立正: 嗯，你觉得我们现在就是，大模型产生出来的 inference，生成出来的这些新的 token，嗯嗯，它是记忆还是泛化？ [00:27:11 - 00:27:21]

田渊栋: 这个要看。我觉得这个是有些时候是混在一起的。 [00:27:22 - 00:27:25]

课代表立正: 比如说那个记忆越好，泛化越有可能，是这样吗？就是说，给它的记忆材料越多，它越有泛化的可能。 [00:27:34 - 00:27:43]

田渊栋: 你可以这么说。就是给他的材料越多，因为他看到各种组合了之后，他在组合里面可以得到一个比较好的那个表征。这个表征就可以，它能够有预测能力。或者说这个表征对没见过的那个组合，它有一些比较好的结构，可以算出来。那么这个是一个，其实就是泛化嘛。 [00:27:43 - 00:28:04]

田渊栋: 所谓我们真的懂这东西呢，往往它意识的一个是，它的方法能力很强。所以对新的情况下，对于这个，这个表征能够得到正确答案。 [00:28:04 - 00:28:17]

田渊栋: 然后第二个呢，就是说是，它能够细化到非常简单的这个逻辑。那么这个逻辑呢，可以 apply to everything，或者 apply to a lot of cases。那么这样的话呢，就是说这两个东西综综合起来，就是让你这个学出来的知识能够，能够 apply 到很多其他的地方。那么这叫泛化。 [00:28:17 - 00:28:40]

田渊栋: 那么如果大语言模型对于某个领域看了很多很多数据，它有可能学到更好的表征，然后这边就可以泛化。 [00:28:43 - 00:28:51]

田渊栋: 然后另外一个，就是说如果它看到的数据很少。那这样的话，有可能就说这个模型本身，它没有办法学到很好的那个表征。它没办法学到很好表征的话 OK，那它就只能把它背出来。它得到的那个表征呢，就是更偏于背诵的这样的一个结构。 [00:28:51 - 00:29:12]

田渊栋: 它能够至少对付好，就是训练的要求。就是说，我希望这个训练级上的错误率还是比较小的。但是，它一旦超越了训练级的范围之后，你就会发现，这个错误率就提高了。那么这个，其实大家就认为这个是过度拟合了，或者说是背诵了。 [00:29:12 - 00:29:31]

田渊栋: 所以大概就是这样子。其实我觉得就很多时候，你并不能说神经网络，是记忆还是背诵，还是记忆还是泛化。应该说是完全取决于这个数据的分布。如果数据多，那么这个虚拟网络是泛化多。如果数据少，那么这个神经网络是记忆多。这个是我的观点。 [00:29:31 - 00:29:49]

课代表立正: 我觉得这里边最 fascinating 的一点，就是它从记忆到泛化的那一步，到底是怎么发生的。 [00:29:49 - 00:29:55]

课代表立正: 那你觉得就是，帮我们总结一下...我的理解可能就停留在 emerge，一句话就就出来了。但是似乎人脑也是这样的。 [00:29:58 - 00:30:10]

田渊栋: 我觉得应该是这样吧。就是，至少从我最近的一篇 paper 来角度上来看呢，就是说这个 paper 就是告就告诉你，就是他有很很清楚的一个 picture，就是告诉你，这些是怎么发生的。就是说，是在什么点发生的。 [00:30:38 - 00:30:52]

田渊栋: 或者说它的内在机制是怎么发生的。就是我们现在感觉上是，我从记忆突然间跳到泛化，好像这个变化非常神秘。但是呢，这篇文章其实告诉你说，其实并不神秘。它有一个非常清楚的一个数学途径。 [00:30:52 - 00:31:06]

田渊栋: 就是比如说，我们要做优化问题...我们可以构造一个，就是比较复杂的，一个非凸优化的这样的一个结构。比如说很多山峰。对吧，然后 g 呢，对应其中一个山峰。然后呢，那个泛化的对应其中另外一个山峰。那么这两个山峰呢，其实对应着不同的表征。那么这个山峰的结构呢，其实完全是取决于数据的分布。 [00:31:06 - 00:31:31]

田渊栋: 如果你数据不够，你可能就只有记忆的山峰。如果你数据很多的话，就是，然后某些泛化能力强的山峰，就会慢慢慢变得越来越高。然后记忆的山峰就会变得越来越低。 [00:31:32 - 00:31:45]

田渊栋: 这样的话，你再让神经网络去找到那个，就是好的表征的时候，是相当于是个优化问题。优化这个神经网络，使得它能够收敛到某个局部的最大点。 [00:31:45 - 00:32:01]

田渊栋: 那么如果你的记忆的山峰缩下去，泛化山峰提上来...它的参数会收敛到那个泛化的山峰。那么这个模型就泛化了。 [00:32:01 - 00:32:15]

田渊栋: 那么从记忆到泛化，中间为什么会顿悟呢？其实很简单。就说两个山峰之间的变化，就是此消彼长。对吧，然后在某个情况下，我比你高一点点了，然后突然之间所有人都往那边扭。 [00:32:15 - 00:32:28]

课代表立正: 明白，是因为它可以泛化。 [00:32:28 - 00:32:30]

田渊栋: 对对，因为它能泛化，所以它可以，就是只要多一点点的话，它 piu 就全都过去了。 [00:32:30 - 00:32:35]

田渊栋: 比如说，你认为就神经网络，是一个一直在优化的过程。对吧，然后他会看见，如果这边高，那边低点，那么所有人都涌到那个高的山峰上去。那就突然之间，你就懂什么意思。 [00:32:35 - 00:32:47]

田渊栋: 也就是这样的话，你就可以从树叶上，或者说从整个树叶框架上，能告诉你这件事情呢，是这么发生的。而不是说是还是非常神秘的。 [00:32:47 - 00:33:00]

课代表立正: 我觉得非常清楚。那我是不是可以理解为，这个泛化的点一直都在数据里边，只不过我们之前没有找到它，没有搜索到它。 [00:33:00 - 00:33:10]

田渊栋: 或者说就搜索到了，但是没有 pay enough attention。然后现在因为，就是越来越，随着越来越多的数据点，凸显了它的价值，然后我们才 pay enough attention。 [00:33:10 - 00:33:23]

田渊栋: 对对。但前提是它要存在。对的，它存在，一个是存在，然后它有你要足够的数据，让它显得与众不同。可以这么想。 [00:33:24 - 00:33:31]

田渊栋: 对，就是如果数据不够的话呢，你可以有很多泛化的思想。但是呢，这些泛化的思想，它的说服力不足以说服记忆这边。就是因为还不如把它记住。这些规律可能没有那么显然。 [00:33:31 - 00:33:48]

课代表立正: 你举个例子就是，孔子和一个傻子，可能说的话都是一样的。但是你给孔子100个问题的时候，问他怎么治国理政，然后问他什么，然后你就说哦，原来这个是个厉害的孔子，然后那个是个傻子。 [00:33:51 - 00:34:05]

田渊栋: 对，就是如果给孔子100本书，那么他告诉你所有的东西。那么这些东西拼在一起，就是让你觉得他，那他在解释这些书的背后，其实是有一个统一的理论，或者统一的一个思路。那么这个思路在100本书的解释中，慢慢的浮现出来。那么你会觉得这个东西就很有用，也许可以拿来解释101本书。 [00:34:06 - 00:34:29]

## 真正的目标：Loss Function 只是“代理”

课代表立正: 那这又回到了另外一个问题，就是怎么样做 evaluation，怎么样子做做 reward。 [00:34:30 - 00:34:36]

课代表立正: 因为孔子解释书解释的好不好，这件事儿听起来...然后，现在大语言模型还是，你看你 next token predict 准不准，作为 reward 吗？还是有其他的方式，可以让这个有泛化能力的人，显得更厉害一些？ [00:34:36 - 00:34:54]

田渊栋: 应该是这样。现在你要看大语言模型，有呢一种是 Pre training 预训练，和 post training 后训练，这两个都有。 [00:34:54 - 00:35:02]

田渊栋: 所以你很难讲。就是你说预训练，我们现在还是用大量的，就是 predict next token。然后后训练呢，其实我们可以说，那个有很多办法可以做训练。 [00:35:02 - 00:35:13]

田渊栋: 那么预训练 Pre next token，那么这个结构，或者说这个损失函数一直没有变。因为现在相对来说，这个还是比较一个比较好的损失函数。 [00:35:13 - 00:35:28]

田渊栋: 当然现在有一些新的方案，比如说什么 reinforcement training，就是我在训练的时候加一段思维链，然后希望这个思维链会引起，导致最后的预测是比较准的。 [00:35:28 - 00:35:39]

田渊栋: 那后训练它的花样就很多了。对吧，花样，比如说，你可以改那个 reinforcement learning 的一些函数，比如说改一些函数的值函数，改它的一些 evaluation 对吧，value function 对吧，reward 对吧，改 rubric 这些东西都可以改。 [00:35:49 - 00:36:02]

田渊栋: 那么这里改了之后，你就可能就是，你其实是希望这个模型往不同的方向走。然后你往不同的方向走了之后呢，那么有些方向，可能就强化模型的某个能力。某些方向强化模型另外一种能力。那么这样的话，你这个模型最后就是百花齐放了。 [00:36:02 - 00:36:21]

田渊栋: 当然了就是说很多时候，你要优化它到某个能力的时候呢，你其实还是希望，能够优化的比较...一个是避免，就是 reward hacking 啊。有些时候，就是，模型还是会最大化你的某个值函数，但是这个最大化的路径是偏的。你不想让他这么做，但是他就这么做。这么做有 shortcut 啊。 [00:36:21 - 00:36:44]

田渊栋: 就比如说你答案就只有 a b c d 四个，然后那就瞎猜一个，25%（准确率）对吧。那我我不希望它瞎猜怎么办？那我就希望我的思维链，一个是希望它的每一步，就是经得起考验。对吧，每一步逻辑是正确的。你可能需要一个 one model 去做这个事情。 [00:36:44 - 00:37:00]

田渊栋: 这个是比较重要的。就是怎么样去做这个事情。那么这样的话，你中间肯定要引入各种 ribick（rubric），引入各种东西，去把这个模型给算出来。就是所以其实花样还是挺多的。而且有很多地方是可以有人为，有一些人类的那个思维，和概念能够放进去。 [00:37:00 - 00:37:21]

课代表立正: 我稍给大家，给频道前面的观众做个比方吧。我觉得一个用比方去理解的话呢，就是，大模型是个非常非常勤奋，算力非常高，就是一天到晚学习的人。对，然后它就可以不断的读书。然后它读了唐诗300首，结果发现它又找到了唐诗3万首，然后读了300万首唐诗，然后它会作诗了。是因为它穷尽了这里面所有规律，然后它找到了行之有效的方法。 [00:37:23 - 00:37:49]

课代表立正: 然后你刚刚所说的，就是希望用另外一种方式去学习，是说，我们不光要让它去背3万还是300万首唐诗，我们能不能，就是像发现数学公式那种方式，去发现一个规律。 [00:37:49 - 00:38:15]

课代表立正: 从而让它直接“piu”的跳到那个...我在23年写那个文章的时候（《关于ChatGPT最重要的五个问题》），就是讲到尤里卡阿基米德发现浮力定律，他其实是干了两件事。是两件不同的事。第一件事呢，是他穷尽了，他肯定当时在想很多很多的方案，很多很多的可能性。然后他脑子里边找到了这么一个点。但是第二件事是，他马上意识到这个是对的。 [00:38:15 - 00:38:41]

课代表立正: 我觉得这两者在机器都挺难做到的。他很难马上意识到这个东西是对的。 [00:38:41 - 00:38:48]

田渊栋: 意识到这东西对的是有可能的。就比如说你发现一个新的假设，这假设能够解释更多现象，而且它假设更简单，那你会马上意识到这个是对的。 [00:38:48 - 00:38:57]

田渊栋: 比如说地心说跟日心说。对吧，那其实说，说实在的那个地心说也是对的。只是说那个，地心说你也可以拿来预测。只是在地角上来看，就其他行星的那个运行轨迹，非常复杂。就是它是那个，就是本轮均轮这种运行轨迹。就是轮子套轮子。 [00:38:57 - 00:39:17]

田渊栋: 然后你通过这个方式，你可以预测那个每个行星的行为。对吧，所以这两个其实都是对的。只是说日心说，如果你切到日心说，你会发现突然之间，所有的轨道都非常漂亮，就是一个椭圆，非常非常简单。 [00:39:17 - 00:39:35]

田渊栋: 那么这个时候你会马上意识到，那个理论，或者说那种解释是更加完美的，或者说更加接近真实，或者更加接近那个更美的。 [00:39:35 - 00:39:45]

课代表立正: 你觉得 Elegance (优雅) 这个东西，在模型现在训练的 reward function 里吗？ [00:39:47 - 00:39:53]

田渊栋: 这个我觉得是这样。就是因为它不是 reward function。但是它在训练的时候呢，应该有 implicit bias 往这方向走。 [00:39:53 - 00:40:01]

田渊栋: 就比如说那个，你展示的那个 PPT 里面，对吧，提到伊利亚说过这个，就是我希望它压缩。我希望找这个模型，会自动的找到一个比较优美的，或者比较少的，那个压缩比最高的那个解释。这个我是同意的。 [00:40:01 - 00:40:19]

田渊栋: 这个确实是会发生的。但是呢，这个不是一个 loss function。是说，它内建在神经网络的训练过程里面。这训练过程，会让这个模型自然的发现更加好的，或者说更加优美的解释。 [00:40:19 - 00:40:37]

田渊栋: 那么这样的话呢，就是神经网络，它才有这个能力去学会更好的表征，然后才有泛化能力。 [00:40:37 - 00:40:44]

课代表立正: 在 loss function 之外，之上还有一层更隐含的 reward。 [00:40:45 - 00:40:50]

田渊栋: 是的。是可以这么说。这个很重要。因为说实在，所有的 loss function 都是 **surrogate**（代理）。就是说都是代理。 [00:40:50 - 00:40:56]

田渊栋: 就比如说 predicting next token 或者是 whatever。或者什么 contrastive loss，non contrastive loss。对吧，这种，或者说 player loss。这些东西都是都是代表。就它的目的是产生一个梯度流。这个梯度流，能够让这个表针往正确的方向走。这个是最重要的一个逻辑。 [00:40:56 - 00:41:15]

田渊栋: 至于这个，目标函数是什么，其实并不重要。重要的是这个（梯度流）。 [00:41:15 - 00:41:22]

课代表立正: 我直到今天之前，我一直觉得 loss function 是整个学习的，就是目标。现在我才知道了它是 surrogate。这个，这个是共识吗？ [00:41:22 - 00:41:35]

田渊栋: 我自己，毕竟还是做过很多表征学习的工作的。我知道，就是很多表征学习的目标函数，做过些拆解之后，你会发现它们其实就是反传梯度的不同形式嘛。对吧，你的 loss function 换了，你的反射梯度的结构是不一样的。那么这个结构，其实最终能够影响你的表征的学习。 [00:41:40 - 00:41:59]

田渊栋: 但是你这个 loss function 其实可以换，甚至换成一些奇怪的东西，你从来没见过。但是，得到的梯度是差不多的，那比如说表征也差不多。 [00:41:59 - 00:42:08]

课代表立正: 你对梯度这个词的使用，也让我觉得非常的 intuitive...我心中就是一个一个等高线。但是我觉得这个这个等高线，最后画出来的是我们的一个知识，很本质的东西，可能就是刻画我们世界规律的。 [00:42:08 - 00:42:25]

田渊栋: 对对。等高线这个逻辑呢，是经常用的。但是等高线这样的一个思路呢，其实它忽略了，这个神经网络本身的结构。因为它把整个 landscape，做成一个高维空间中的一个，非常复杂的山峰。但是这个山峰，其实你要知道，山峰其实对应着神经网络的结构。所以这两个是有关系的。 [00:42:26 - 00:42:46]

田渊栋: 所以应该说，把这个梯度在山峰上的指引，去映射到神经网络的，具体的，哪个梯度对于哪个神经元的，或者每一组神经元的这样的一个过程。那么这个时候你能看见，就是它的表征是怎么学出来的。 [00:42:46 - 00:43:03]

课代表立正: 我觉得，它对于我们对这件事儿的 intuitive understanding 挺重要的。 [00:43:07 - 00:43:11]

田渊栋: 对。就是像你可能刚刚说的就是那个 insight。那个 insight 就是你有了这个东西，我觉得就比较好，容易建立起一个更好的世界模型。 [00:43:13 - 00:43:23]

田渊栋: 但这个是一家之言。就是说，我觉得我也是，我也非常 bias 以我自己（的观点）。 [00:43:26 - 00:43:31]

课代表立正: 我们来听的就是一家之言。如果这个事情有有教科书的话，我们就去学教科书了。 [00:43:31 - 00:43:36]

田渊栋: 我这边也是做一些，做很多 research，我有这样的一个大概的感觉。那么我在上面有很多文章，也是做一些这样的工作，去分析这个梯度的结构，它训练出来这个表示什么，改的变化，这个是重要的。 [00:43:39 - 00:43:55]

田渊栋: 我相信就是再往上走呢，也许这样的一个理解呢，是能够改变，最后的那个，这个神经网络的学习的方案。这是这是我们的最终目的。 [00:43:55 - 00:44:08]

## 科研哲学：长期主义与“双线作战”

课代表立正: 我再用十五分钟的时间，稍稍回顾一下你的科研史。因为你刚刚也聊到了远期的目标，就是，也要有一些近期的目标结合。 [00:44:18 - 00:44:31]

课代表立正: 我记得你有一个专访，里面有讲到，就是你在刚读博士的时候，大部分的时间是在想，但是你后来觉得想的是没有用的。对，而且关键是你想的那些东西，没有做工作的话，就相当于没有存盘。 [00:44:31 - 00:44:42]

课代表立正: 我看你的工作，其实我能感觉到，是有一个很强的主线。我就会发现你前面的一个工作，lead 到下一个工作，然后再 lead 到下一个工作。就是每一次，都能在前面非常重要的结果上，再往前走。而且似乎都能跟时代挂钩。对吧,就是从围棋开始，然后到大语言模型，然后到模型训练的效率方面。 [00:44:45 - 00:45:12]

课代表立正: 所以我想听一下你对，选择科研 topic，以及在 FAIR 这样的环境中，你到底是怎么决定你的科研方向？你怎么决定，把兴趣，商业和自己的长处结合起来的？ [00:45:16 - 00:45:41]

田渊栋: 对,我觉得是这样的，就是你肯定是要结合的。否则很有可能会比较惨。 [00:45:41 - 00:45:47]

田渊栋: 我们大家都有家庭，大家都希望能够有一些比较高的收入。对吧，然后，然后能够，希望有比较好，有个比较好的环境。对吧，然后比如社会地位也比较高。大家都希望全都要。成年人说全都要，不是说小孩子，只选一个。 [00:45:47 - 00:46:03]

田渊栋: 对，所以最终你肯定是要找到那个结合点。就是因为我从博士开始，就已经是“双线作战”了。就是我有很多的想法，就是你之前说的也是对的。就是我会，我可能花9个月时间，去想一些不着边际的东西。然后3个月说，不行了，我今年要发 paper，否则老板会不高兴。 [00:46:03 - 00:46:23]

田渊栋: 对吧，那.我可能会跟老板说，你有什么题目我来帮你做。那我花3个月，就把这个事情做了，出一篇 paper。就要对老板有交代。他当时比如说课题，这些课题需要有文章去填。那么通过这方式，至少让我觉得，我在博士阶段会有工作，然后我能毕业。对吧，然后老板也开心。 [00:46:23 - 00:46:48]

田渊栋: 这很重要。那么工作之后也是一样的。就是我们当然希望做一些方向，这方向是迎合时代潮流的。就是我不可能说，完全脱离时代潮流。比如大家都在做大语言模型，你却不做。那我说，我做别的，然后我说我就是要做，比如我就要做 SVM，或者就要做视觉。这个当然可以。对，但是这种肯定，在公司里面，是没有办法活下去的。 [00:46:48 - 00:47:15]

田渊栋: 所以会想一想，就是首先，你比如说，我这边的一些比较偏理论的研究，它对这个问题有更深理解。比如之前我们有一些关于 attention sparsity，就是注意力机制如何变得稀疏的，这样一些研究。那么这研究本身是比较理论的。 [00:47:19 - 00:47:38]

田渊栋: 但是，你可以拿来做一些比较实用的工作。比如说我们想到最近的，之前的 **Attention Sink**（一种用于高效处理长序列的注意力机制），那么这种文章，就是说，我们其实没有太多理论，但是我们可以通过观察神经网络的稀疏性，我们可能得到新的算法。 [00:47:38 - 00:47:53]

田渊栋: 用这新的算法可以把上下文扩展到，扩展到比如400万以上。那这样的话，这个东西就有用了。就是突然之间你可以拿来做大语言模型的 decoding，对吧，解码的这样的一个应用。那么这应用，其实本身也可以放在很多手机上。这是个有用的应用。 [00:47:53 - 00:48:14]

田渊栋: 其实这样的联系，应该说还是比较紧密的。应该容易想到。对吧,你想你的 attention，如果有稀疏性的话，那我为什么...我就把大部分的 attention 的 score 砍掉，那不就加速了吗？对吧，那就省内存了。对吧，那你有各种办法，可以提高这个效率。所以这两个关系是很大的。 [00:48:14 - 00:48:36]

课代表立正: 我要打断一下。你这个体感，你觉得在别人身上成立吗？因为有的人觉得赚钱好容易，到处都可以赚钱。像你就，好多 research topic，然后随便拿一个都可以做。但是很多人绞尽脑汁都觉得想不出来。 [00:48:45 - 00:49:01]

田渊栋: 这个应该说是很长时间的积累。就是说我觉得是挺难的。 [00:49:05 - 00:49:09]

田渊栋: 比如说我拿我的理论研究来说吧。就是，这个方向其实做很久。我其实不是数学科班出身。我很多时候，有人跑来问我，说你是不是数学系的？我说我不是数学系，我所有数学都是我自己学的。 [00:49:09 - 00:49:20]

田渊栋: 然后很多时候是这样。我特别是，比如一开始想做一些表征理论的研究，那很痛苦。因为你很难去想，你的思考，你可能会在很多地方转圈子，然后浪费时间。你会发现浪费很多时间，然后真正的事情都没干。 [00:49:20 - 00:49:37]

田渊栋: 但是你如果持之以恒，一直在想，一直在思考反思的话，慢慢就会发现，有些地方你可以存盘。存下来你就知道，这个地方，是你发现一个好的 insight 的节点。然后这个 insight 你既然想到了，那就是你的了。那你把它写下来，存下来。那么有了这个阶段之后，你存盘这个能力就成立了。 [00:49:37 - 00:49:59]

田渊栋: 然后第二个就是说你看很多文章，做很多 research。那么可能对这个问题，有大的概念和思路，就是知道这一块要怎么做。 [00:50:01 - 00:50:09]

田渊栋: 比如说我们做 reasoning，做 self improvement。对吧，这些方向其实是一个很火的方向。那么你看了很多文章之后，就可以知道什么东西能做，什么东西不能做。 [00:50:09 - 00:50:23]

田渊栋: 所以说，比如说你要改进思维链的长度，长和短，对吧，然后怎么做混合的 thinking。这种东西，其实都是，通过我们过去的经验，能够发现一些可能性的。然后在这上面，你怎么去做更好的工作。对,这个也是一个经验积累。 [00:50:23 - 00:50:43]

田渊栋: 就是我建议是多看，多看文章，然后多想，多跟别人讨论，看看这个思路是怎么出来的。 [00:50:43 - 00:50:51]

课代表立正: 到了一个阶段，是你看到了现在的应用，然后你能很快地比如说，找到一些新的应用和论文。这似乎对你来说，就变成一个比较简单的事情了。 [00:51:03 - 00:51:16]

田渊栋: 对。因为，就是说，很多时候是这样。就是特别数学好的人，物理好的人，他们转到其他领域是很快的。 [00:51:17 - 00:51:24]

田渊栋: 就是，为什么是很快的呢？我个人感觉是这样。就是数学和物理，就是，它给你一个预训练，让你脑子里面表征比较好。然后它可能很容易能够，映射到不同的领域。然后它们之间，这个领域的知识可以迁移。 [00:51:24 - 00:51:42]

田渊栋: 比如说，我说我要，抓住本质。对，这个很重要。就是比如说，我说做 efficiency，那就是优化问题。优化问题的话，你可以说我有个目标函数，我有一堆优化的变量，对吧，然后有约束，那就可以优化了。 [00:51:43 - 00:51:56]

田渊栋: 那么这么想的话，你有很多问题可以归结在一起。那么你的思维就比较连贯，比较一致。 [00:52:03 - 00:52:10]

课代表立正: 哦，就是回到你刚才说的，模型的那个点。就是你能在同一个区间发现更多的问题，你能产生更多的，就是组合出来更多 data points，你就更容易找到这里面的泛化。 [00:52:12 - 00:52:26]

田渊栋: 是的。exactly。就是其实就是这样子。然后如果你已经有一个好的表征的话，那你就很容易泛化到其他领域。对吧,因为可能在别人看来，这些点都是离散的，然后它们没有关联。 [00:52:26 - 00:52:41]

田渊栋: 但是作为一个比如说，表征比较好的研究员，他能看到它们这些关联。然后，并且欣赏这些关联之间的美感。那么首先他能记住更多东西。对吧,因为这些东西，在他们脑子里面是有结构的。 [00:52:41 - 00:52:53]

田渊栋: 然后另外就是说他不觉得，把这些东西连起来，或者说把东西记下来，找到想法是痛苦的。他能很自然地找到新的想法。所以这个其实是连上前面一个点，就是脑子里就放烟花，这种感觉。 [00:52:53 - 00:53:06]

田渊栋: 对,对。你会有很多其他的想法。你很多想法是有关联的，然后你能看到它们之间更本质的关联。那么这更本质的关联，本身其实就是一篇很好的文章，或者说一个很重要的思路可以往下走。 [00:53:06 - 00:53:17]

田渊栋: 对吧,别人只能看到表层的关联。比如说别人觉得A加B，两个加起来可能是一个好的工作。对,那么另外就是说，这种工作可能很多。但是有些人就觉得A和B，之间有个本质的联系 C,然后我发表一篇关于C的工作。那么C可能就比A和B更本质。那么这篇工作可能就，凌驾于其他工作之上。在它对学术界的影响力，可能更大。 [00:53:17 - 00:53:44]

课代表立正: 我觉得最后人和机器还是很像的，在这些角度来说。 [00:53:59 - 00:54:01]

田渊栋: 对的。应该是这么说。就是其实最近有些文章，应该说最近我看到有一些，比如说《Nature Machine Learning》这种文章，就是它论证，人的表征和机器的表征是很接近的。 [00:54:02 - 00:54:16]

田渊栋: 它们可以通过扫描人的大脑，然后发现一些神经元的 activation。对吧，它们跟神经网络的 activation，是很有关联度的。 [00:54:16 - 00:54:26]

田渊栋: 这种我是觉得，不管你是结构什么样的，开始不同没关系。只要你数据是一样的，数据结构是差不多的，那它的表征，可能学到的差不多。但是可能人的学习能力，人的学习效率，是比机器要高的。 [00:54:26 - 00:54:46]

## 未来展望：AI 作为“勤劳的 PhD”

课代表立正: 那最后一个问题，就是，until recently，你的科研，你感觉是按照自己的想法走，还是，要做很多 application 的工作？以及，接下来可能会吸引你做的事情是什么？是继续你对后一种研究范式的继续探索,还是？ [00:54:46 - 00:55:09]

田渊栋: 我觉得研究范式探索是很重要的。对，那当然了，就说我们现在也要与时俱进。对吧，我不可能说我关起门来说，我就用以前的方式来做研究。 [00:55:11 - 00:55:18]

田渊栋: 比如说我们可以想，也许我们以后要找到一个，AI scientist。或者说，我自己写一套比如说 agent 的框架，然后帮我一起做研究。这也是可以的。 [00:55:18 - 00:55:29]

田渊栋: 其实我说，我们这篇 Grokking the paper，这篇文章，其实说实话，是我和 **GPT-5**（此处应指代 OpenAI 的某代先进模型，如 GPT-4o 或未来版本）进行对话，做出来的。 [00:55:29 - 00:55:39]

田渊栋: 其实这样子，我觉得这个很有点，像 **self-play**（自我博弈：一种强化学习方法，AI 通过与自身或其他副本的对抗来提升能力）。就是我给它一些问题，然后我这边有些想法，然后发给 GPT-5，然后让它去思考。然后让它，给一些比如 formulation。 [00:55:39 - 00:55:53]

田渊栋: 对吧,一开始你这么做，它给你的答案，都是非常大路的，没什么意思。但是你通过思考之后，我觉得有些关键的 insight 给它，它可能会有不一样的输出。然后这样的输出，可以往下面挖，往下面深挖一层。 [00:55:53 - 00:56:09]

田渊栋: 但是你还是要找到它的错误，找它的一些矛盾的地方，找到它做不出来的地方，然后继续深入。然后一直深入到，就是，这个问题的理解，或者说，这个问题的数学描述，已经达到了我想要的目的。那么这部分就成功了。 [00:56:09 - 00:56:30]

课代表立正: 你用的是 GPT-5 Pro 吧，我猜。 [00:56:37 - 00:56:40]

田渊栋: 不是 Pro。其实就是 thingking...其实说实话 Pro 没什么用。 [00:56:40 - 00:56:44]

课代表立正: 我相信 o1 Pro 和非 Pro 区别还挺大的。 [00:56:45 - 00:56:48]

田渊栋: 是。但是我用下来我觉得...因为其实我有 OpenAI 的朋友，他们送我一个月的 Pro。我后来用了一下，我觉得，好像也没有特别出众的地方。 [00:56:48 - 00:57:00]

课代表立正: 回头把鸭哥（Yang Song）做的那个 second mind...我一直觉得这个事非常神奇。就是鸭哥做了一个，就是可以几个模型放到一起用，而且可以 handle knowledge 的东西。 [00:57:00 - 00:57:11]

课代表立正: 我 consisitently...我现在几乎都只跟它交流了。因为我发现它就是比那些，这边的 Claude 和 o1，给的答案更好。 [00:57:12 - 00:57:21]

田渊栋: 对,但是我回头跟鸭哥说一下，然后你可以来试用一下这个东西。 [00:57:22 - 00:57:29]

田渊栋: 对,对,对,那我很感兴趣。就是因为，我觉得鸭哥做的事情都非常厉害，我非常佩服他。 [00:57:29 - 00:57:35]

课代表立正: 你那是个 solo author paper。你没有把 GPT-5 放到 co-author 里面，听起来它做了不少工作。 [00:57:40 - 00:57:48]

田渊栋: 按照逻辑，你可以看，就是这篇文章是 conference 投稿。conference 投稿说，大语言模型不能作为，不能作为作者。所以没有放。 [00:57:48 - 00:58:00]

田渊栋: 对吧，那我后面写了一段，这段话是说，作者...我是说我们，我们广泛使用大语言模型。我给大语言模型各种想法，让它去 formulate，让它证明一个东西。然后发现问题怎么解决。 [00:58:00 - 00:58:10]

田渊栋: 对吧，它基本上所有东西都是错的。但是它有一些比较有意思的 insight，有些东西可以细化。然后把你的 idea 从一个想法，变成一个具体的过程。这个它很擅长。 [00:58:10 - 00:58:22]

田渊栋: 就相当于它是一个非常勤劳的，职业的 PhD。你可以这么想。就是它非常勤劳，然后我给它一个想法，它马上写出来，写出一个很长的论述，让我能够很快进入状态。这很重要。 [00:58:22 - 00:58:39]

田渊栋: 对,你比如说你以前要进入状态，比如说，我要做 research。好，我现在有一个小时的时间。我可能一开始半小时，我要进入状态。就我通过写公式，看文章，思考一下，我进入状态了。进入，这个叫 **心流**（Flow State）。对吧，然后去想，然后才能得到一些结果。那这个时间其实比较漫长。 [00:58:39 - 00:59:01]

田渊栋: 但是有了 GPT-5 之后，我觉得很重要的一点是，你进入心流时间很短了。就是你跟它有一个小想法，然后它给你写一大段。比如，3分钟之内给你写一大段东西。你看完这段东西之后，你马上会进入这个状态。就说我知道我要怎么去想问题。 [00:59:01 - 00:59:17]

田渊栋: 就现在这个问题在那放着，然后哪个地方它做得不好，或者说有什么 insight 可以进来。所以这是很大的一个，应该说效率的改进。 [00:59:17 - 00:59:25]

田渊栋: 对，我可能觉得，以前你需要几个月的时间做一篇文章，你现在可能几个礼拜，甚至是更短的时间。我觉得，这是非常大的效率提升。如果用得好的话，是很厉害的。 [00:59:25 - 00:59:39]

田渊栋: 当然，现在还是一个非常初级的 self-play。对吧，也许说不定以后，我们可以做一个，更加自动化版的，那就很有意思。 [00:59:39 - 00:59:47]

课代表立正: 我自己也有一些经验了。就是我跟当时是 GPT-o1 Pro 去探讨，这是我一直对量子力学的那个 many-world theory，我特别感兴趣。然后我一直觉得它最 make sense。 [00:59:55 - 01:00:08]

课代表立正: 但是我们没有对应的哲学。然后我觉得其实你看佛经也好，或者看什么，就是很多东西，它的哲学,反而那种所谓玄学的哲学，和这个 many-world theory 的哲学是吻合的。 [01:00:08 - 01:00:23]

课代表立正: 我就说这个世界的本质，就是一个非确定的 many worlds。然后我们之所以现在 share 一个 reality，这是我们的，就是最大概率。当然这个概率可能极大...所以说，我们就会觉得这个桌子是确定无疑地存在。但是其实它可能并不是真的存在。 [01:00:26 - 01:00:47]

田渊栋: 对，这个是对的。就是从科学上也是对的。因为你可以认为，它是一堆波函数的组合。对吧，然后存在一种可能是，这个桌子，突然之间跑到那堵墙另外一边去了。这概率非常小，但是不是0。 [01:00:49 - 01:01:04]

课代表立正: 但是我就发现，这个 idea，我没有办法和它写成一个文章。因为我自己的水平不行。 [01:01:17 - 01:01:22]

课代表立正: 所以说就是现在 AI 能辅助你写出来，像你这样的文章，还是主要是自己？ [01:01:22 - 01:01:29]

田渊栋: 主要是自己。是的。就是人还是比较重要。有很多重要的 insight 还是要人给。 [01:01:29 - 01:01:35]

田渊栋: 然后 AI 现在有很多莫名其妙的问题。比如说它就会卡在一个地方动不了，就是它会跟你说很多重复的话。然后就是它说不到本质上。这个很有意思。 [01:01:35 - 01:01:45]

田渊栋: 就像感觉，它就是你去面试一个新来的 PhD。然后说一大堆话，它像背诵概念。就是但它又绕不到，它就找不到那句最重要的，本质的话能够说出来。 [01:01:45 - 01:01:57]

田渊栋: 那这个，其实是一个表达的问题。但是这个就需要人去总结，然后告诉它，是我们认为的最本质的东西。然后让它继续往下走。 [01:01:57 - 01:02:08]

课代表立正: 你就是说这是一个 fresh PhD。fresh PhD 意味着它可能是可以被训练的。 [02:02:11 - 02:02:17]

课代表立正: 我想到是 Duolingo 的那个 founder，他是一个计算机教授...他叫 Luis von Ahn。 [02:02:17 - 02:03:04]

田渊栋: 对对，他是，应该说我当时在 CMU 读博的时候，他就在那了。 [02:03:04 - 02:03:09]

课代表立正: 他有这么一个故事。就是他去读博士的第一年...他老师是图灵奖的获得者。然后几个月，他去了以后，就是他老师，就只跟他干一件事，就是你这个东西跟我讲讲，我没听懂，下次再来。 [02:03:09 - 02:03:45]

课代表立正: 结果后来才发现，就是他自己没有讲清楚。 [02:03:50 - 02:03:52]

田渊栋: 对，没有，你没讲清楚，说明你理解不深。对吧，如果理解深的话，讲清楚了，别人会觉得，你确实理解深了，你确实懂了。 [02:03:52 - 02:04:00]

课代表立正: 不知道模型是不是也可以这么训练。 [02:04:00 - 02:04:03]

田渊栋: 我觉得有希望。希望可以。当然了，就是大模型可能会，可能会强行记住，就是我怎么样讲能讲清楚，但是它自己不懂也是有可能。 [02:04:03 - 02:04:11]

田渊栋: 而且就说，你怎么才能获得训练数据，能够让大模型找到最优的讲清楚的...因为讲清楚这个事情是个非常主观的东西。就是很难，很难用这个模型去 model 它。 [02:04:12 - 02:04:29]

课代表立正: 在要求大语言模型之前，我们先要求自己。我们先要求自己把一个东西想清楚，已经是一个很高的要求了。 [02:04:30 - 02:04:39]

田渊栋: 对对，这个很难。就是说，这部分其实可能就需要人有美感。就是人觉得，它的讲解是非常有美感的，或者说非常简单扼要，那这个才可以。那这个怎么去设计一个 loss function，是一个 question。 [02:04:39 - 02:04:56]

课代表立正: 好的，那我们今天已经聊了不少了。你觉得还有没有什么想聊的东西？ [02:04:57 - 02:05:01]

田渊栋: 那应该没有了。对，我觉得已经挺好了。而且其实我们已经把这篇文章讲出来了。我也不想要通过非常枯燥的方式来讲，通过这个对话来讲，我觉得非常好。 [02:05:01 - 02:05:09]

课代表立正: 而且能看出来的是，我觉得通过这个对话，我也更深层次地理解了，就是这件事有多重要，它的 context 是什么。和它其实对人也好，或者对模型来说，其实都有很多共通的地方。 [02:05:09 - 02:05:18]