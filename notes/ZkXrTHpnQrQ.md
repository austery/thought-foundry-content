---
author: TED
date: '2025-12-26'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=ZkXrTHpnQrQ
speaker: TED
tags:
  - ai-influence
  - reality-distortion
  - algorithmic-bias
  - language-evolution
  - perception-manipulation
title: AI如何重塑我们的语言与现实认知
summary: 本文探讨了人工智能和算法如何通过社交媒体和聊天机器人，扭曲我们对现实的感知。从‘感知差距’到语言的‘delve’现象，再到平台驱动的文化潮流，演讲者揭示了AI如何制造并放大虚假现实，并最终影响我们的思想和行为。文章强调了这些工具的非中立性，以及保持批判性思维以对抗‘平台版本现实’的重要性。
insight: ''
draft: true
series: ''
category: psychology
area: society-thinking
project: []
people: []
companies_orgs:
  - OpenAI
  - Spotify
  - TikTok
products_models:
  - ChatGPT
  - Grok
media_books: []
status: evergreen
---
### 算法塑造的感知

我们有多确定自己能辨别网络上的真实信息？你可能认为识别明显由AI生成的图像易如反掌，也可能意识到算法在某种程度上存在偏见。然而，所有证据都表明，我们在潜意识层面理解这些影响的能力相当薄弱。以美国日益扩大的**感知差距**为例，我们不断地高估他人政治信仰的极端程度。这种情况随着社交媒体的普及而加剧，因为算法倾向于向我们展示最极端的现实图景。作为一名内容创作者，我总是发现争议性信息传播得更快，因为它们能产生比中立观点更多的互动。但这意味着，我们最终看到的都是更极端的现实版本，并且我们显然开始将其与真实现实混淆。

<details><summary>Original English Source</summary>
How sure are you that you can tell what's real online? You might think it's easy to spot an obviously AI generated image and you're probably aware that algorithms are biased in some way, but all the evidence is suggesting that we're pretty bad at understanding that on a subconscious level. Take for example the growing perception gap in America. We keep over and over estimating how extreme other people's political beliefs are. This is only getting worse with social media because algorithms show us the most extreme picture of reality. As an etmologist and content creator, I always see controversial messages go more viral because they generate more engagement than a neutral perspective. But that means we all end up seeing this more extreme version of reality and we're clearly starting to confuse that with actual reality.
</details>

### AI的语言印记

同样的事情目前也发生在AI聊天机器人身上。你可能认为ChatGPT在和你讲英语，但它并非以纯粹的英语交流。正如算法不会呈现未经过滤的现实一样，AI模型会根据其训练数据产生固有的失真。例如，我们知道ChatGPT使用“delve”这个词的频率远高于正常水平。这可能是因为**OpenAI**将其训练过程外包给了尼日利亚的工人，而他们确实更频繁地使用“delve”。但随着时间的推移，这种轻微的语言过度代表性在模型中被进一步固化，甚至超过了工人们自己方言中的使用频率。现在，这正在影响每个人的语言。多项研究表明，自ChatGPT问世以来，世界各地的人们在自发的口语对话中说“delve”的次数有所增加。本质上，我们正在潜意识地将AI版本的语言与实际语言混淆。但这意味着，真实的事物正讽刺地变得越来越接近机器的版本。我们陷入了一个正反馈循环：AI呈现一个现实版本，我们认为那就是真实现实，然后我们又将其复述出来，供AI获取更多数据。

<details><summary>Original English Source</summary>
The same thing is currently happening with AI chat bots because you probably assume that chatbt is speaking English to you except it's not speaking English. In the same way that the algorithm is not showing you reality, there are always distortions depending on what goes into the model and how it's trained. Like we know that Chad says delve at way higher rates than usual, possibly because OpenAI outsourced its training process to workers in Nigeria who do actually say delve more frequently. Over time though, that little linguistic over representation got reinforced into the model even more than in the workers own dialects. Now that's affecting everybody's language. Multiple studies have found that since Chad GPTt came out, people everywhere have been saying the word delmore in spontaneous spoken conversation. Essentially, we're subconsciously confusing the AI version of language with actual language. But that means that the real thing is ironically getting closer to the machine version of the thing. We're in a positive feedback loop with the AI representing reality, us thinking that's the real reality, and then regurgitating it so that the AI can be fed more of our data.
</details>

### 算法创造的潮流

这种现象也可以通过算法在诸如**hyperpop**之类的词汇中看到。这个音乐流派实际上并非我们文化词汇的一部分，直到**Spotify**在其算法中注意到一个新兴的相似用户群体。一旦被识别并引入一个hyperpop播放列表，这种审美就获得了一个明确的方向。现在，人们开始争论什么符合hyperpop的定义。这个标签和播放列表通过提供一个认同或反对的参照点，使得这一现象更加真实。随着越来越多的人认同hyperpop，越来越多的音乐人也开始创作hyperpop音乐。与此同时，相似听众的群体和算法的影响力越来越大，Spotify不断地加大推广力度，因为这些平台希望通过放大文化潮流来留住用户。但这同时也意味着我们失去了真实潮流与人为夸大的潮流之间的区别。然而，这正是如今所有时尚进入主流的方式。

<details><summary>Original English Source</summary>
You can also see this happening with the algorithm through words like hyperpop which wasn't really part of our cultural lexicon until Spotify noticed an emerging cluster of similar users in their algorithm. As soon as they identified it and introduced a hyperpop playlist, however, the aesthetic was given a direction. Now, people began to debate what did and did not qualify as hyperpop. The label and the playlist made the phenomenon more real by giving them something to identify with or against. And as more people identified with hyperpop, more musicians also started making hyperpop music. All the while, the cluster of similar listeners and the algorithm grew larger and larger and Spotify kept pushing it more and more because these platforms want to amplify cultural trends to keep you on the app. But that means we also lose the distinction between a real trend and an artificially inflated trend. And yet this is how all fads now enter the mainstream.
</details>

### 现实的商品化

这个过程通常始于一种潜在的文化渴望，比如人们对**matcha**、**labu**或**Dubai chocolate**的兴趣。算法识别出这种渴望，并将其推送给相似用户，从而放大了这一现象。然而，正如ChatGPT误用了“delve”一词一样，算法很可能也误读了现实本身。因此，越来越多的企业开始制作“labu”相关内容，因为他们认为这是人们的普遍需求。网红们也创造“labu”潮流，因为我们必须抓住潮流才能走红。然而，算法主要展示的是适合视频格式的、视觉上引人注目的内容。**TikTok**对用户的理解是有限的，这远远无法满足人类复杂的欲望。这导致了输入数据的偏差，即便我们假设社交媒体真的试图忠实地反映现实——而它常常并非如此。相反，它的主要目标是创造收入。让**Spotify**让你听hyperpop符合其利益，让**TikTok**让你观看诸如“boo boos”之类的热门内容也符合其利益，因为这些内容是可商品化的。因此，我们再次看到现实与其呈现之间存在持续的差异，两者不断相互影响。

<details><summary>Original English Source</summary>
We start with a latent cultural desire like maybe some people are interested in matcha or labu or Dubai chocolate. The algorithm identifies this desire and pushes it to similar users, making the phenomenon more of a thing. But again, just like how chatp misrepresented the word delve, um the algorithm is probably misrepresenting reality. Now, more businesses are making labu content because they are think that's the desire. More influencers are also making labu trends because we have to tap into trends to go viral. And yet the algorithm is only showing you the visually provocative items that work in the video format. Tik Tok has a limited idea of who you are as a user and there's no way that matches up with your complex desires as a human being. So, we have a biased input and that's assuming that social media is trying to faithfully represent reality, which it isn't. Instead, it's only trying to do what's going to make money for them. It's in Spotify's interest to have you listening to hyperpop and it's in Tik Tok's interest to have you looking at the boo boos because that's commodifiable. So once again, we have this difference between reality and the representation of reality where they're actually constantly influencing one another.
</details>

### 危险的正反馈循环

忽视这种区别是极其危险的，因为其影响远远超出了我们的语言和消费习惯，它深刻地影响着我们所认为可能的世界。有证据表明，ChatGPT在说波斯语时表现得更为保守，这很可能是因为伊朗有限的训练文本反映了该地区更为保守的政治气候。这是否意味着伊朗的ChatGPT用户会产生更保守的想法？我们知道**Elon Musk**会定期修改他的聊天机器人**Grok**，当他不满意其回应时，并且他利用他的平台**X**来人为地放大他的推文。这是否意味着数百万Grok和X用户正在被潜意识地训练，以认同马斯克的意识形态？我们必须时刻记住，这些并非中立的工具。最终出现在你的社交媒体信息流或聊天机器人回复中的一切，都经过了多层过滤，这些过滤基于对平台的益处、盈利能力以及平台对你身份的错误认知。当我们忽视这一点时，我们就会通过持续的幸存者偏差来看待现实，这影响了我们对世界的理解。

<details><summary>Original English Source</summary>
But it's incredibly dangerous to ignore that distinction because this goes beyond our language and our consumptive behaviors. This affects the world we see as possible. Evidence suggests that chatbt is more conservative when speaking the Farsy language, likely because the limited training texts in Iran reflect the more conservative political climate in the region. Does that mean that an Iranian chat GPT user will think more conservative thoughts? We know that Elon Musk regularly makes changes to his chatbot Grock when he doesn't like how it's responding and that he uses his platform X to artificially amplify his tweets. Does that mean that the millions of Grock and ex users are subconsciously being trained to align with Musk's ideology? We need to constantly remember that these aren't neutral tools. Everything that ends up in your social media feed or in your chatbot responses is actually filtered through many layers of what's good for the platform, what makes money, and what conforms to the platform's incorrect idea about who you are. When we ignore this, we view reality through a constant survivorship bias, which affects our understanding of the world.
</details>

### 保持真实

毕竟，如果你说话越来越像ChatGPT，你很可能也越来越像ChatGPT一样思考，或者像TikTok、Spotify那样思考。但是，如果你不断地问自己“为什么”，你就可以对抗这种影响。我为什么会看到这个？我为什么会说出这句话？我为什么会这样想？平台又为什么会奖励这种行为？如果你不问自己这些问题，那么他们（平台）的现实版本就会变成你的现实版本。所以，请保持真实。

<details><summary>Original English Source</summary>
After all, if you're talking more like ChattyBT, you're probably thinking more like Chat GBT as well, or Tik Tok, or Spotify. But you can fight this if you constantly ask yourself why. Why am I seeing this? Why am I saying this? Why am I thinking this? And why is the platform rewarding this? If you don't ask yourself these questions, their version of reality is going to become your version of reality. So stay real.
</details>