---
area: tech-insights
category: technology
companies_orgs:
- Google
- OpenAI
- DeepMind
- Anthropic
- NVIDIA
- Cursor
- Symbolica
- Reflection AI
- Periodic Labs
- UCSF
date: '2025-11-21'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- Yann LeCun
- Jason Wei
- Ilya Sutskever
- Mira Murati
- Leon Feddas
- Danny Zhou
- Brian Cheng
products_models:
- Gemini 3
- Claude 3
- GPT-4
- GPT-5
- Llama
- DeepSeek
- TPU
- AlexNet
- Transformer
- Mamba
- Kimi
project:
- ai-impact-analysis
- systems-thinking
series: ''
source: https://www.youtube.com/watch?v=1pgCnlJRuxE
speaker: 硅谷101
status: evergreen
summary: 多位AI科学家深度探讨谷歌最新发布的Gemini 3模型。内容涵盖了从编程、小说续写到多模态推理的实际使用体验，分析了其在各项基准测试中的突破，并深入讨论了“全模态”概念、思维树架构以及谷歌在执行“规模法则”（Scaling
  Law）上的优势与挑战。此外，对话还延伸至AI领域的前沿方向，如可解释性AI、新模型架构的探索以及硬件在未来竞争中的决定性作用。
tags:
- agentic-ide
- llm
- model
- multi-modal-ai
- scaling-law
title: 谷歌Gemini 3深度解析：AI全模态时代的来临与Scaling Law的极限执行
---

### 引言：Gemini 3 引发的行业热议

**硅谷101:** 今天我们最感兴趣的是，借此机会与各位顶尖的AI科学家探讨，除了大语言模型（LLM）之外，还有哪些前沿研究分支是大家所关注的。我们先从Gemini 3谈起，然后再聊聊超越Gemini的研究方向。

首先，我们还是需要讨论一下刚刚发布的Gemini 3。我看到所有社区和媒体都在赞扬它。能否请各位先谈谈自己的使用感受？它在各个排行榜上的表现真的名副其实吗？

### 初体验：从编程、创作到多模态应用的全面评测

**Nathan:** 我可以分享一下使用Gemini 3及其应用的体验。我主要用了三款应用：一是Gemini 3 Pro；二是谷歌针对开发者发布的模型，叫做Google Anti Gravity，大家可以理解为谷歌推出的**智能体集成开发环境**（Agentic IDE: 一种集成了AI智能体的编程工具，能自主理解任务并完成编码、测试等工作），方便开发者和程序员编程，有点像Cursor或Codeium的竞品；第三个是今天刚发布的Nano Pro。

我个人从开发角度更关注模型的编程能力。我看了一下它的benchmark跑分，在Switch Bank上其实不是最高的，最高的是Claude 3.5 Sonnet，它稍微低一点，但已经非常接近了。在使用Gemini应用的过程中，我发现一个很新的功能，就是你可以直接在它的应用内进行编译，生成很多前端小程序。网上有很多人用它调用电脑摄像头，让它看你的表情、听你的声音，然后给出反馈。我觉得这一点能让很多人快速尝试如何开发一个APP并投入使用。

不过，它的局限性可能更多在于前端，比如后端部署或调用其他agentic框架，在它的主应用中可能无法完成。我认为它走的第二步棋就是发布了Anti-Gravity，一个完全针对开发者的Agentic IDE。它的好处与Cursor或Claude等工具不同，它完全希望AI编码智能体能非常自主地帮你完成任务。它的界面设计分成了“Manager view”和“Editor view”两大块。Editor View就像传统的编程编辑器，你可以看到程序不断修改变化的过程。而Manager View则让你能同时与一系列（比如8到10个）智能体协作，你可以不断给这些智能体布置任务，像一个经理一样看着它们写程序。这样在做系统级工作时，玩法就更多了，比如你可以创建一些智能体帮你审查代码、运行单元测试。

它最新的功能是利用了Gemini 3.0 Pro里的Browser Use能力。我不知道大家是否用过MultiOn AI，它很多功能就是基于Browser Use，让大模型使用你的浏览器进行操作。Gemini模型的Browser Use跑分现在应该是最高的，它利用这个功能可以调用Chrome浏览器，拿到一些底层API，让浏览器帮你测试前端程序，实现了测试与开发的完全自动化和一体化。这是一个非常好的亮点。但在实际使用中，我发现它在执行一些复杂操作时，比如上传文件做测试，常常会卡住，需要人工干预。

最后，关于Nano Pro，我发现它最好的功能是生成复杂的图片甚至幻灯片。比如，你想解释Gemini从1.0到3.0的发展路线以及每个模型的特点，以前的工具无法完成整个逻辑链并清晰地条理化，但现在用Nano Pro做幻灯片已经能非常好地完成了。我觉得市面上那些做幻灯片的相关软件可能都要被它取代了。

**田博士:** 我这几天也一直在使用Gemini 3。我主要用它来写小说，这是我的副业。我通常用《星球大战》的同人小说来测试模型，这算是我个人的benchmark。这样做的好处是，首先它不会过拟合，因为除了少数人，没人会拿这个作为官方基准测试；其次，因为我有领域知识，能看出很多细微的变化，从而大致判断模型本身的能力。

测试之后，我感觉Gemini 3的模型比以前更好了，这是一个很大的突破。一两年前，无论是GPT-4还是Llama，续写的小说都像官方文书，和原文的语境、文笔完全不同。从去年开始，续写作品的质量越来越好，风格能与原文匹配，人物也开始具有一定的连续性。但仍然不像在“写作”，因为它会把每个人的心理活动都直白地写出来，缺乏复杂小说的含蓄。

这次的Gemini 3让我有些惊喜。它不仅能进行人物描写、渲染氛围，还能知道在小说里用什么样的情节可以抓住读者的心。这种写法已经和以前的小说续写不一样了。我以前用Gemini 2.5时，觉得它文笔比较好，会做很详细的场景描写，像个文学系学生，但在情节上比较平淡。而Gemini 3构思的一些情节，甚至一些转折，都非常有趣，能够很好地契合先前的人物设定，并创造出富有创意的互动。我甚至觉得有些互动情节可以保存下来，用在我自己的小说里。这是我第一次看到模型能在情节和人物互动上做得如此有趣。

从技术上讲，这种能力的提升应该不是通过特定的后训练任务实现的，而很可能是因为模型的基础建模能力更强，对小说的理解更深入，甚至理解了作者创作的动机和深层思路，并有意识地将这种理解融入到续写中。

此外，我也用大模型帮我做头脑风暴，讨论一些有趣的话题和想法。在这方面，我感觉Gemini 3没有太大突破，仍然像一个知识非常广博但缺乏深度思考的博士新生。它能提出一些新的想法、框架或数学工具，但对于一个问题的深入探讨，仍然需要人的引导和建议。

在编程方面，我只是随便写了点东西，比如让它创建一个三维小游戏，它也能写出来，虽然方向键是错的（按前进键会后退）。这种bug应该不难修复，但它确实大大降低了前端开发的门槛。

### 技术剖析：全模态、思维树与Scaling Law的极限执行

**Gavin:** 首先，我感觉谷歌大厂之力恐怖如斯，它有一个非常完整的、端到端的AI技术栈。从技术层面看，基础模型的benchmark中，我最惊艳的是Arch-HRI2。这个benchmark测试的是少样本学习（Few-Shot Learning）或元学习（Meta-Learning），它考验的不是“做题家”能力，而是像人一样，看过一两个例子就能快速掌握某种模式的真正智能。Gemini 3在这个benchmark上有了质的突破，从之前的百分之十几甚至个位数提升到了百分之三十几，这说明它能通过简单的例子和模式捕捉到人类的推理能力。我认为这得益于它的**多模态**（Multi-modal: 指AI模型能够同时理解和处理多种不同类型信息，如文本、图像、音频、视频的能力）推理能力。以前的思维链是单模态的，通过语言层面自我思考，而多模态推理可能对此有巨大帮助。

另一项是Math Arena Apex，它在基于符号学的数学推理上也有了质的突破。还有Nathan提到的ScreenSport Pro，以前的OS智能体或浏览器智能体需要通过视觉模型理解屏幕，标注图像后扔给语言模型做推理。现在Gemini 3相当于能一边看着屏幕，一边在语言层面进行推理，这是模型原生的多模态能力，和去年我们讨论的完全不一样，打开了很多新的可能性。

去年我尊敬的一位前辈曾说，模型生成图片时会出现一个人有六根手指的情况，因为它缺乏基于物理常识或因果关系的理解。但现在从Gemini 3自我评估的角度来看，它内部采用了一种**思维树**（Tree of Thoughts: 一种比“思维链”更复杂的推理方法，允许模型同时探索多条并行的推理路径，并对它们进行评估和选择，从而找到最优解）的架构。它不再是线性的思维链，而是有多条思路并行，并在模型内部进行打分和筛选。同时，它在基础模型之上还包裹了一层工程封装，就像在树中进行搜索，验证哪条思路是可行的。这正应了那句话：一开始我们做提示工程（prompt engineering），后来做上下文工程（context engineering），现在要做环境工程（environment engineering）。

谷歌的这种做法，让工程与模型科学结合起来，继续突破**规模法则**（Scaling Law: 一种理论，认为只要持续增大模型的大小、计算量和数据量，模型的性能就会可预测地提升）的壁垒。之前垂直扩展基础模型本身可能遇到了瓶颈，但现在他们采用了**混合专家模型**（Mixture of Experts, MOE: 一种神经网络架构，它由多个“专家”子网络组成，每个专家专注于处理特定类型的数据或任务）架构，使模型本身可以水平扩展，同时工程上的自我验证又让它不断提升。对我来说，这在技术上的意义不亚于三年前的GPT时刻。

**高瑜备:** 我最近比较忙，还没来得及亲自使用Gemini 3，所以今天分享的都是一些二手信息，但可能是一些有价值的早期反馈。

首先，一个好的方面是，大家普遍反映Gemini 3在回答通用问题时表现很好，不像2.5版本那样有强烈的幻觉或答非所问。这次的预训练和后训练都做得不错，回答不仅简单而且相当准确。

另一个早期反馈来自视觉团队，他们用一些内部benchmark测试后，发现Gemini 3在真实世界视觉理解（Real-world visual understanding）能力上反而下降了。这里的真实世界视觉理解，指的是分析在真实场景中（如安防摄像头）部署的摄像头所捕捉到的用户行为、潜在风险等。当然，这是一个非常早期的、小规模的测试，方差可能较大，不能作为定论。他们在回看Gemini 3的测评报告时也发现，报告中只有一个真正关于视觉或视频理解的benchmark，且结果没有提升。

这个现象也提出了一个问题：公开的benchmark可能无法完全反映实际产品的性能。真正的产品团队内部有自己的衡量标准，这些标准可能更贴近实际应用。

语言组的反馈是，虽然Gemini 3有很大改进，但在涉及重复性多跳（multi-hop）、外部搜索和信息聚合的复杂任务上，比如分析一家公司20年的财报，其性能似乎还达不到GPT-4 Pro的水平。但Gemini 3的优势是速度快，对于一些简单任务，用户可能更倾向于使用它。

在科研写作方面，学生的反馈是性能反而下降了，不如Gemini 2.5好用。在辅助编码方面，接入Gemini 3后性能似乎也下降了。但这都可能是因为新产品刚发布，大家还没找到正确的使用方法。

总的来说，大家还是觉得这次谷歌对于Scaling Law的执行较为彻底，凭借其得天独厚的硬件优势，似乎正在迎头赶上。

### 谷歌的制胜法宝：生态、算法还是数据？

**硅谷101:** 总体来看，谷歌现在几乎成了一个追赶者。大家如何理解谷歌在模型上的优势？是生态、算法还是数据？Gemini 3的项目负责人说，秘诀在于改进了预训练和后训练，这是否意味着Scaling Law并非万能，算法优化仍有很大空间？

**田博士:** “预训练和后训练都有改进”这句话其实等于没说。每个环节做得比原来好，模型自然会变强。我更好奇的是他训练的秘诀是什么。预训练如果做得非常强，模型就会变得很聪明，后训练教起来就容易。如果预训练做得不好，后训练就像教一个笨学生，事倍功半。从反馈来看，Gemini 3的预训练应该做得不错。当然，也有传言说谷歌修复了之前训练中的一些bug，但这无法证实。

**Gavin:** OpenAI的一位研究员Jason Wei曾提到，所有有确定方法论的领域最终都会被模型所吞噬。Gemini 3也看到了这个趋势。我们更关心的其实不是基础模型的能力，而是它能否为我们的产品带来实际价值，提升用户体验或KPI。我认为现在的瓶颈在于，智能体仍然只是在自动化人类已有的工作，蛋糕没有变大。我们需要创造新的商业模式和产品形态。

**Nathan:** 我觉得谷歌整个Gemini模型生态从1.0到3.0，一直坚持在做多模态。其实在1.0的技术报告里就写了他们开始使用原生的多模态训练。到1.5时开始用MOE，2.0时加入了思维模式，到3.0时，我跟Gemini讨论它为什么这么好用，它给出的答案也和Gavin说的思维树很像，它称之为“深度思考”（deep thinking）模式，即尝试多轮步骤，从多个不同方向探索，最后反思并选择一个最好的结果来生成。

另外，我在看开发者API文档时发现一个彩蛋，里面写着“context engineering is a way to go”。这让我想到，我在使用大模型时，也会先让它搜索如何写一篇病毒式传播的推文，整理学习资料，再根据这些知识来创作。谷歌自身强大的搜索能力，是否让它在模型使用过程中，已经能自动抓取这些上下文信息，并融入思维链，从而生成更好的结果？

**高瑜备:** 我比较认同我朋友Brian Cheng的一个观点，就是谷歌这次的迭代体现了它能够纠正之前的问题，并且在执行Scaling Law上非常极致。为什么谷歌更能够执行Scaling Law？因为它有硬件优势。只有它的TPU是软硬件完全一体化结合的。NVIDIA硬件有70%的利润率，这意味着没有硬件能力的公司在坚定执行Scaling Law时会面临经济上的障碍。谷歌可以更坚定地投入更大的模型和更多的训练。这对其他团队来说将是一个巨大的挑战。

### 超越LLM：探索AI研究的前沿领域

**硅谷101:** 除了主流的Scaling Law，硅谷还有很多团队在探索非主流路径以达到AGI。我想请问各位，除了LLM，还有哪些研究方向特别引人注目，值得我们关注？

**田博士:** 我个人认为Scaling Law是一个有趣且实用的方向，但总有一天地球上所有的资源都无法满足计算需求。我们不能把整个地球变成一块巨大的显卡。作为研究者，我还是希望有一些更根本性的探索。我一直在做一些工作，比如探索神经网络如何产生智能，如何学习和表达知识。我们常说模型有一个好的内部结构，这会让后训练更高效。但这些都是比较模糊的概念。

有人说神经网络是压缩数据，压缩即智能。但为什么压缩软件不能产生智能？一定是神经网络的某种特殊结构在起作用。我希望能从第一性原理出发，基于优化过程推导出一些有趣的结论，并用实验去验证。我相信，一个如此简洁的规则和训练范式能产生这样的效果，其背后一定有某种完美或奇妙的数学和谐。随着现代AI工具的辅助，我相信这个方向的进展会更快。

**高瑜备:** 我非常同意田博士的观点。研究AI或智能的基本原理，从第一性原理出发，是一个非常重要的方向，需要有信念的科学家投入其中。我喜欢从极限的角度思考问题，问一些别人觉得疯狂的问题，这些问题可能恰恰是引领我们走向不一样未来的关键。

如果Scaling Law是我们唯一的学习法则，那对人类来说是悲观的。我希望它不是唯一的法则。作为研究者，我们有责任去寻找其他的法则。比如，信号的原子结构是怎样的？我们是如何从语言中提炼出智能的？语言从宏观上看是一种捷径，是我们已有文明的蒸馏。我希望机器能重新发明一种新文明，而不仅仅是在所有事情上都比我们做得好一点点。

自然界也给了我们证据，人类和动物在学习过程中是相当高效的。一个13岁前的人类获取的语言token肯定少于100亿，甚至10亿。我们能否用这么少的数据训练出一个模型？人类模型的规模很大，但数据量却很小。我们是如何实现这种学习的？

另一个有趣的方向是机器人学（Robotics）。今天的机器人学有点像AlexNet刚出来的时候，效率不高，很多地方做得不好，但这恰恰是研究者的机会。当它还不是一个成熟产业时，研究者有时间去思考那些“无用”之事，而这些事未来可能会慢慢变成一个产业。

### 未来展望：新架构与生成式UI的兴起

**硅谷101:** 有观众提问，未来三到五年，大公司会使用不同于Transformer的新架构吗？

**Gavin:** Transformer架构有两个竞争者，一个是Mamba，另一个是RWKV。它们可以将一些旧的记忆压缩成状态，以O(1)的时间复杂度进行检索。在AI需要长期记忆时，这会与Transformer架构形成权衡。

**田博士:** 这些技术其实已经在使用，比如Kimi的长文本能力就用到了类似的技术，可以和滑动窗口注意力（Sliding Window Attention）混合使用。但在三到五年内完全取代Transformer是比较困难的，因为激烈的竞争使得大家不愿意在架构上花费太多时间进行颠覆性创新。

**高瑜备:** 在Scaling Law结束之前，短期内Transformer仍有很大空间，因为我们对文明的“蒸馏”还远未完成。但从我个人信念出发，我不认为Transformer就是终点。最终，架构上仍然有很多创新的机会，尤其是在追求极限性能时，架构会产生更大的影响。

**硅谷101:** 还有观众问到“生成式UI”（Generative UI）的概念。

**Nathan:** 我个人感觉它能给用户带来更好的交互质感。比如，Gemini通过这种模式可以生成动态的UI让你与信息互动。我曾用它将一篇上千字的推文转换成一个图文并茂的解说图，一步步引导我理解，比我自己看文字快得多。这大大加强了获取信息的速率和交互体验。但它的局限可能在于，这种体验非常个性化，难以大规模普及。

**Gavin:** 我认为世界模型（World Model）是一个重要方向。语言模型已经趋于稳定，接下来空间智能将与传感器和硬件结合。我非常支持开源模型，因为智能不应该被困在少数基于GPU的数据中心里。端侧的小语言模型、小世界模型的发展，能让普通人更多地被智能赋能，而不是仅仅为之付费。