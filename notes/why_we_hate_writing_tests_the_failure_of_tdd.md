---\
title: 测试驱动开发（TDD）的兴衰：为何我们讨厌写测试？
summary: 本文探讨了测试驱动开发（TDD）的起源、核心理念及其在实践中遇到的困境。文章分析了TDD为何未能广泛普及，并指出其核心问题在于将测试置于开发之前，忽略了软件需求多变的本质。最后，文章提出了一种更现代、更有效的测试理念，即在模拟真实生产环境中进行基于属性的测试（Property-Based
  Testing），以确保软件的健壮性。
area: null
category: null
project: []
tags:
  - tdd
  - 极限编程
  - 测试驱动开发
  - 软件工程
people: []
companies_orgs: []
products_models: []
media_books: []
date: 2025-08-17
author: Lei
speaker: 原子能
channel: null
draft: true
file_name: why_we_hate_writing_tests_the_failure_of_tdd.md
guest: null
insight: null
layout: post.njk
series: null
source: https://www.youtube.com/watch?v=TzOaXepgEtQ
---\
## TDD 简介：先写测试，再写代码

**Test Driven Development (TDD)** 是一种以测试驱动开发的模式。简单来说，就是拿到开发需求后，先凭空把测试写出来。因为这个时候是没有实际代码的，所以测试必然是失败的。然后你的工作就是把实际代码写出来，让测试结果的红灯一个个变绿，直到全部通过。之后再对代码进行重构增加新功能时，也要确保已有测试继续保持绿灯状态。

作为一个程序员，你应该多多少少都听说过 **TDD**，但你们中的大部分应该都没有做过 **TDD**。毕竟这种做法还是有点极端的，和大家平常的开发模式的区别较大。愿意冒着风险尝试的，一般情况下都是因为项目负责人自己就是 **TDD** 教徒，这里的人相对而言不太多。

所以，与前两期的 **UML** 和 **Azure** 相比，**TDD** 在计算机行业的影响力没有那么大。但同样是90年代个人计算机热潮中诞生的软件开发理念，**TDD** 之于代码测试，就像 **UML** 之于系统设计，**Azure** 之于项目管理，都是具有历史代表意义的。所以 **TDD** 绝对值得一席之地。而且从它的失败中，我们还能尝试解答一个困扰大家已久的问题：为什么我们都不想写测试，都不想更新它，修复它？即使我们在日常工作中，最讨厌的就是别人不写、不更新、不修复测试。测试本应该是我们的守护者，却活成了我们最讨厌的邻居。答案就在 **TDD** 犯下的错误里。

## TDD 的历史渊源：从 NASA 到极限编程

在60年代，美苏冷战进入到比拼载人航天的环节。**NASA** 的水星计划只有一个硬指标，就是要比苏联快。所以它们的软件开发部门被设计成开发和测试并行的组织结构。一旦产品的功能需求文档定稿，它们被同时发送给开发组和测试组，两边同时开工，最后顶峰相见。

作为美国历史上最成功的工程项目，水星计划中用到的诸多项目管理方式，也自然成为后人借鉴的模板。这其中就有一位叫做 **Kent Beck** 的青年。没错，他就是上一期的男主角，**Extreme Programming (XP)** 的创始人。他很喜欢借鉴古人的做法，然后再把他们推到极限的程度，这也是 “Extreme” 这个词的来源。当他在克莱斯勒的项目组里打造 **XP** 模式时，在测试这个工作上，他也借鉴了 **NASA** 的做法。只不过他更极端，直接把测试的位置提到了最前沿。

在他的模式下，需求文档确认后，首先要做的是用 **Unit Test** 把所有可能出现的状况都测一遍。这相当于用测试代码将需求文档翻译了一轮。那么接下来入场的开发就不再是由需求文档来引导。我们的第一个任务就是写下能让这些测试通过的代码。这就是测试驱动的开发，**Test Driven Development** 的来源。

即使在 **XP** 全家桶里，**TDD** 也算是比较极限、比较极端的那个。因为大多数 **XP** 理念只是一种指导型方案，只包括对大方向的描述。具体怎么做，还得是看程序员自己的理解，和开发团队的相互配合。但 **TDD** 是一个非常具体的方案，它基本上是在手把手教你怎么写代码。它会深入影响每个人的编程风格，你每次敲击键盘都要遵循它的规则。这也是为什么喜欢它的人很喜欢，讨厌它的人很讨厌。那些喜欢 **TDD** 的，通常都会非常积极地向周围的人推荐 **TDD** 的做法，具体原因可以参照人类宗教史。某种程度上，这也造成了 **TDD** 无处不在的假象，因为它的存在感确实是比它的实际存在要大很多。

## TDD 的实践困境与演变

与出自于 IBM 管理模式的 **UML** 类似，**TDD** 也因为它广泛的通用性，脱离了 **XP**，成为一个独立传播的开发模式。只不过它的传播显然没有 **UML** 那么成功。作为一个诞生在90年代的开发模式，**TDD** 的第一个国际级 conference 是在2021年才召开的。14位演讲者通过线上会议的形式，从各个角度分享了自己的 **TDD** 成功故事，以及为什么大家都应该用 **TDD**。这是本视频发布时，据我所知，这也是 **TDD** 的最后一个 conference，算是 RIP 了。

在 **Unit Test** 层面定下代码要求，在有经验的人听起来就像是一个坏主意。因为这相当于让具体代码的实现细节和测试过度耦合了，会锁死代码之后的调整空间。而作为首个应用 **TDD** 的软件项目，Kent Beck 主导开发的克莱斯勒员工薪酬管理系统，在第一个版本交付后，就因为员工过劳，无法继续，两年后就被关停了。作为 **XP** 发源地的克莱斯勒也宣布，集团内部禁止一切 **XP** 模式。

不知道是不是受到这次失败的教训，**TDD** 的执行也开始从 **Unit Test** 层面往上走。他们不再追求最小单位的测试，而是转向更大范围的、在需求层面的测试。这也衍生出了 **Accepting Test Driven Developments**，将 **Unit Test** 替换成 **Accepting Test**，即面向客户的验收测试。

## 核心谬误：透支未来

但不管测试的范围怎么调整，**TDD** 有一个本质是不变的，那就是尝试在实际开发开始之前，在测试代码中想象和框定最终成果。这种透支未来的做法，听起来是不是有点既视感？因为这也是前两期主角 **UML** 和 **Azure** 在做的事情。不管是代码测试、系统设计，还是项目管理，正常的顺序都是应该先有需求，然后有实现，最后有结论。但 **TDD**、**UML** 和 **Azure** 想的都是把后面两步反过来，先下结论，再去实现，这样是不是就能运筹帷幄，事半功倍了呢？

这种超捷径的想法，统统放弃考虑了最重要的一个影响因素，那就是在软件项目中，需求不是一个常量，而是一个时刻在变化、在游走的变量。不管这个需求是来自于业务方的功能需求，来自领导层的业绩压力，还是来自生产环境的安全隐患，它往往都是一个移动靶。当你的理论是基于一个假设的常量，然后在这个常量的基础上画坐标，在这个坐标上建公式，最后自证这个公式在理论上成立，那么在你发现这个常量不存在，固定的坐标也不存在的时候，你的公式就会出现越来越大的偏差，直至无法使用。

## 测试的本质：一种模拟

测试本应该是我们的好朋友，前提是摆正它的位置。在 **TDD** 眼里，测试是一种代码化的需求文档。比起普通的需求文档，它过于具体，没有解读空间，让写代码的程序员觉得自己就是个工具人。而且不管是下到 **Unit Test** 还是上到 **Accepting Test**，**TDD** 提前定好的各种函数和功能接口的做法，都会让后续开发中任何的调整都十分吃力。

而且很多项目的管理团队会把测试定义为一种 **KPI**，将其包括在交付的指标中。所以很多测试工作只是在纯粹的刷数据，比如经典的100%测试覆盖。它们的价值定位被扭曲，也难怪程序员嫌弃了。

在我看来，测试本质上就是一种模拟。测试的价值，就是可以伪装成真正的客户，模拟使用代码和功能，模拟检验返回的结果。这个模拟的场景应该是很重要的。这个模拟的场景越真实，越接近现实的生产环境，效果自然越好。我们见过很多测试是通过了，但是在生产环境还是出 bug 的情况。这是因为测的场景和实际场景不一样。

所以我不会在项目的设计阶段，甚至是开发初期考虑测试问题，而是在软件初见雏形，设计基本定型，大致流程跑通，可以看到结果之后。因为在这个时候，我有了一个基本能用的产品，可以想象得到真实的使用场景是怎么样的。这个产品在哪里最薄弱，哪里交互最复杂，哪里出错最危险，都已经有了一个大概的范围。就像著名程序员 Atomic Energy 说过的，The moment you know what to fear, is the moment you know what to test。

这种理念听起来很凭感觉，很不客观。但如果你有看完前两期，你应该能够感受得到，软件工程就是无法完全客观的东西。所以我觉得在大方向上，制定规则，然后在具体执行上，让有经验的人自主决定，才是最优解。

## 一种更现代的测试之道：基于属性的测试

我简单分享一下我的做法，不是为了安利，只是拿来跟 **TDD** 做一下对比，是好是坏你们自己决定。

我这里有一个系统，它包括了 **Postgres**、**Redis**、一个前端 API、一个支付 API、一个义务工作机。这里只有前端 API 是面向客户的。回到二三十年前，因为技术限制，我们没有能力在本地模拟全套的系统，所以要么只做一些简单的 **Unit Test**，要么就用各种 Mocking 框架来做假惺惺的所谓模拟。

但现在容器技术已经很成熟了，所以在本地1:1还原生产环境，只需要一个简单的 **Docker Compose** 配置文件。不熟悉容器技术的，可以去看第26期视频的介绍。

模拟环境搭建好后，我用的是一种叫做 **Property Based Testing** 的测试手法。具体做法就是模拟真实客户可能做的操作，随机生成各种输入参数，随机调用各个前端 API，然后针对系统返回的结果，当场判断它是否符合所测功能应有的特性。比如说，某个随机生成的输入是不合要求的，那么按照这个功能的特性就应该返回400；又比如某个 API 的调用顺序不对，就应该返回403之类的。这样我们就不需要手写 test case，而是随机模拟，从而把所有乱七八糟的可能性都测一遍。

因为整个测试环境都在本地，所以响应速度也很快，普通笔记本也能在一秒内模拟100个 test case。在稍微好一点的台式机上，我们还能搞个100倍并发，顺便也把压力测试给做了一石二鸟。这种测试我们写起来很积极，维护起来也很认真，因为我们知道只要这些测试能通过，我们就很有信心，这个系统上线之后不会被客户玩坏，我们晚上就能安睡。而这就是我们的测试之道。