---
area: society-systems
category: general
companies_orgs:
- Simon Fraser University
- Meta
- Google
- Microsoft
- X
date: '2025-11-18'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- The New York Times
- Black Mirror
people:
- Stephanie Dick
- Johannes Gutenberg
products_models:
- ChatGPT
project:
- historical-insights
- ai-impact-analysis
- systems-thinking
series: ''
source: https://www.youtube.com/watch?v=76NpaW4tJFg
speaker: TVO Today
status: evergreen
summary: 西蒙菲沙大学助理教授Stephanie Dick探讨了技术发展中的历史模式，特别是印刷机和电报的案例，以理解当前人工智能带来的机遇与风险。她指出，技术进步常伴随对社会和人性的深远影响，而我们对AI的理解和应用，应超越技术本身，更多地关注公共教育、社会协商以及我们希望构建的社会形态。文章强调了信任、问责制以及重新定义智能的重要性。
tags:
- ai-ethics
- historical
- information
- societal-impact
- technological
title: 印刷机与现代AI：历史如何指引我们应对技术变革？
---

### 历史的回响：技术进步的双重性

技术并非孤立存在。它不断塑造着我们，而我们也持续塑造着它。随之而来的是巨大的可能性与真实的风险并存。西蒙菲沙大学传播学院助理教授Stephanie Dick经常思考这个问题。她研究数学、计算和**人工智能**（AI: Artificial Intelligence）的历史。她探讨了历史能如何指导我们理解当前所处的时刻，以及我们应该思考哪些问题来决定下一步的方向。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Technology doesn't exist in a vacuum. It's constantly shaping us and we are constantly shaping it. And with that comes a mix of huge possibilities and some real risks. Stephanie Dick thinks about this often. She is an assistant professor in the school of communication at Simon Fraser University. She studies the history of mathematics, computing, and artificial intelligence. I asked her what the past can teach us about the moment we are in right now, the kinds of questions we should be asking about where to go next.</p>
</details>

当前，人们对**AI**的风险议论纷纷，但另一方面，关于各行各业如何从中受益的炒作也甚嚣尘上。Stephanie Dick解释说，尤其在**信息技术**（Information Technology: 处理、存储、传输和检索信息的各种技术）的历史中，这种恐惧与兴奋并存的时刻相当常见。部分原因在于，信息技术总是伴随着关于我们如何学习和工作的宏大承诺，但它们也常常带来巨大的基础设施变革。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's a lot of talk these days of the risks of AI, but on the flip side, a lot of hype about what uh how industries can benefit. I'm hoping you can help us explain. Has there ever been a time in the history that of tech advances that have been so binary? I would say especially where the history of information technology is concerned, we have these moments of fear and excitement fairly regularly. And part of the reason for it, I think, is that information technologies come with really big promises about how we're going to learn and how we're going to work. But they also often come with really big infrastructural changes.</p>
</details>

她举例说，1857年《纽约时报》上的一封信中提到，**电报**（Telegraph: 一种通过电信号传输信息的通信系统）无疑能让我们更快地沟通，跨洋电缆将缩短通信时间。但它将如何影响我们对真相、时间以及连接感的认知？即使是电报，也曾让人们对经济革命感到兴奋，同时又让另一些人对速度和数量对信息环境及人类体验的影响深感担忧。因此，我们今天所感受到的兴奋和担忧，在历史上有着诸多先例。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So I have my students often read a little letter that went into the New York Times in 1857 about how sure the telegraph is going to allow us to communicate a lot faster. We're laying these cables across the ocean that are going to reduce the time for communication. But what is it going to do to our sense of truth, our sense of time, our sense of connection? Even the telegraph had people excited about economic revolution and it had other people really concerned about the impact of speed and quantity on information landscapes and human experience. So I think we have a lot of historical precedent for the excitement and concern that we're all hearing and experiencing today.</p>
</details>

### 印刷机的真实故事：技术与社会变革的复杂关系

Stephanie Dick认为，**印刷机**（Printing Press: 一种用于批量印刷文字和图像的机械设备）是一个非常有用的历史案例。我们常常认为技术是社会变革的驱动力，即我们开发了技术，然后它们的功能或运作方式迫使我们接受某种存在模式。早期现代欧洲的印刷机常被用作此例。通常的说法是，天才约翰内斯·古腾堡发明了印刷机，使得印刷文字更快、更便宜，信息传播更广。结果，信息被民主化，进而导致君主制的推翻、欧洲的民主化、新教改革和科学革命。我们把大量的文化转型归因于印刷机。但从历史上看，这个故事并非事实，其中的每一个部分都是错误的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Absolutely. Here I think the printing press is such a helpful historical example because we often imagine I think and we hear a lot of stories that tell us that it's technology that drives social change that we develop technologies and because of what they do or the way they work they force certain modes of being on us that we have to reckon with. And an example of this that is often pulled up is the printing press which comes from early modern Europe. And the story often told is that along came this genius Johannes Gutenberg. And he invented the printing press. And with the printing press, the printed word became faster and cheaper and there was more information that circulated more widely. And as a result of that, information was democratized and that led to the overthrow of monarchies and the democratization of Europe and the Protestant Reformation and the scientific revolution. We've attributed a huge amount of cultural transformation to the printing press. But it turns out that historically that story is just not true. Every part of it is false.</p>
</details>

事实是，约翰内斯·古腾堡并未发明印刷机，他是一位改进了**活字印刷术**（Movable Type: 一种印刷技术，使用可移动的独立字符块进行排版）的金属工人。印刷机确实让印刷品更便宜、更快，但仅限于一小部分能够阅读的人口。实际上，在印刷机发明近400年后，欧洲才有超过50%的人口能够阅读。Stephanie Dick认为，真正导致信息民主化和社会深刻变革的，是**公共教育**（Public Education: 由政府资助和管理的教育体系），其作用不亚于甚至超过了印刷机。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Johannes Gutenberg didn't invent the printing press. He was a metal worker who improved movable type. And the printing press itself did make, you know, print cheaper and faster, but only for a very small amount of the population who were able to read. And it wasn't actually until almost 400 years after the printing press that more than 50% of Europeans could read. And I think that the actual revolution that led to the democratization of information and profound transformations in our society was actually public education as much or more than the printing press.</p>
</details>

她认为我们正处于一个非常相似的时刻，许多人声称**AI**将实现所有这些伟大的事情。但她不断问自己，我们当前所处的时刻中，“公共教育”的部分是什么？为了使这项新技术与我们都希望生活的社会类型保持一致，我们需要做哪些社会、政治和教学工作？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think we're in a really similar moment right now where a lot of people are saying that AI is going to do all of these things. But I keep asking myself, what's the public education part of the moment that we're currently in? What's the social and political work and the pedagogical work we need to do in order to align this new technology with the kind of society we all maybe want to live in?</p>
</details>

### AI发展模式的反思：技术驱动还是问题驱动？

**AI**在短时间内取得了飞速发展，一些人甚至觉得它像科幻电影。许多人认为它像《黑镜》中的一集，这似乎是一个持续不断的话题。那么，技术在哪些方面可能发展过快了呢？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Well, let's talk about those leaps and bounds because it seems like AI has has come so far in a very short period of time. Some people will even say it feels like a sci-fi film. I'm not going to lie, the amount of conversations I have with people who say it feels like an episode of Black Mirror. That that is seems to be a a constant conversation I have. In what ways might technology be going too fast?</p>
</details>

Stephanie Dick指出，在计算技术发展史上，我们反复看到的一点是，计算机技术的开发者通常首先弄清楚它们能做什么，能让这项技术实现什么，然后才将其作为我们问题的解决方案推销给我们。长期以来，事情并非反向发展，即我们作为特定社区、学术领域或组织，阐明我们希望解决的问题，然后根据我们对问题的阐述来设计技术。目前，计算机正在引领潮流，我们正在探索它的能力，然后我们都应该追随这些能力。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Yeah, it's a really good question. And with the history of computing, one of the things we notice again and again is that the people who develop computer technologies often first figure out what they can do, what they can get this [clears throat] technology to do, and then they figure out how to sell that to us as the solution to our problems. It hasn't been going the other direction for some time where we articulate the problems that we want solved as particular communities or academic disciplines or organizations and then technology is designed in response to how we articulate our own problems. The computer is leading right now where we're sounding out its capacities and then we're supposed to all follow those.</p>
</details>

她认为值得一提的是，我们现在拥有的**生成式AI**（Generative AI: 一种能生成文本、图像或其他媒体内容的人工智能），由**机器学习模型**（Machine Learning Models: 通过数据训练来识别模式和做出预测的算法）、**大型语言模型**（Large Language Models, LLMs: 拥有大量参数、通过海量文本数据训练的深度学习模型）以及其他**数据驱动**（Data-driven: 决策和行为基于数据分析而非直觉或经验）的行为形式驱动，仅仅是被称为人工智能的众多迭代之一。在20世纪，人工智能的全部目的就是试图自动化人类智能。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think it's worth mentioning that the current AI that we have, generative AI powered by machine learning models, large language models, and these other datadriven forms of behavior are just one iteration of what's been called artificial intelligence. And in the 20th century, the whole point of AI was to try to automate human intelligence.</p>
</details>

他们希望能够阐明人类智能包含什么，并在计算机中重现它。那么，我们的智能是关于推理、知识还是直觉？这些能力是什么？我们如何才能将它们自动化？结果发现，人类自身的智能太难自动化了。所有这些项目都未能兑现其承诺。因此，我们当前的这一迭代是在一个特殊时刻诞生的，当时我们说：“好吧，我们不知道我们的智能是什么样的。我们无法将其建模为计算机遵循的规则。所以，我们只是向计算机输入数据，让它自己找到规则。让它根据所发现的数据来决定自己的行为。”

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They wanted to be able to articulate what it is that our intelligence involves and reproduce that in the computer. So is our intelligence about reasoning? Is it about knowledge? Is it about intuition? What are those faculties? How might we automate them? And it turned out our own intelligence was too hard to automate. Those projects all failed to make good on their promises. And so this current iteration that we have was sort of born out of a moment where we said, "Okay, well, we don't know what our intelligence is like. We can't model it as rules for the computer to follow. So, we're just going to throw data at the computer and let it find its own rules. Let it determine its own behavior based on what it finds there."</p>
</details>

因此，我们正在这个历史进程中重新定义智能。它对不同的人来说意味着截然不同的事物。Stephanie Dick担心，在这个时刻，我们将把智能完全重新定义为机器智能、数据驱动的智能，从而失去对我们发展和集体生活至关重要的其他形式的智能。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Uh, and so we're kind of redefining intelligence as we go through this history. It comes to mean really different things to different people. And what I fear in this moment is we're going to redefine intelligence all together to just mean machine intelligence, datadriven intelligence, and we'll lose some of the other forms that have been so essential to our development and our collective life.</p>
</details>

### AI的“谄媚性”与注意力经济

最近，像**ChatGPT**这样的技术引发了一些头条新闻中的担忧，其中一个问题是**谄媚性**（Sycophancy: 奉承讨好以获取好处的行为）。简单来说，就是它会告诉用户他们想听的任何事情。这理所当然地引起了一些担忧。我们是否会一直受困于此，或者有什么办法可以解决这个问题？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I want to talk a little bit about some concerns that have been uh hitting the headlines uh with technology like chat GBT. Uh there's the issue of syncopency. Uh basically telling the user that anything that they want to hear is probably the easiest way to sort of define it and uh rightfully so has raised some concerns and want to know are we stuck with that or is there something that we can can we work around that?</p>
</details>

Stephanie Dick认为这是一个非常重要的问题，她自己在探索**AI**时也深感困扰。首先，她认为重要的是要认识到ChatGPT的谄媚性是一种商业模式，或者说是商业模式的一部分，即科技公司试图尽可能多地捕获我们的时间和注意力，并尽可能多地激发我们产生数据的参与和行为。因此，即使在**AI**出现之前，像Meta、Facebook、Google、微软和X这样的公司就已经在努力弄清楚如何让我们尽可能长时间地停留在他们的平台上，如何尽可能多地参与内容，如何尽可能多地产生数据。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's such an important question and one that I'm really struggling with too while I navigate AI myself. So the first thing I think it's really important to acknowledge is that the sycopancy of Chad GBT is a business model or it is a part of a business model in which technology companies are trying to capture our time and attention as much as possible and they're trying to motivate our data producing engagement and behavior as much as possible. So even before AI, companies like Meta and Facebook and Google and you know uh Microsoft and X have been trying to figure out how to get us to stay on their platforms as long as possible, how to engage with as much content as possible, how to produce more data as much as possible.</p>
</details>

因此，让这些**AI**一直告诉我们很棒，我们是下一个最好的事物，是让我们留在这些网站上的另一种机制。这让她非常担忧，因为在当前这个社会历史时刻，我们正在失去处理差异和冲突所需的一些技能。学生和老师都在努力应对批判性反馈。人们非常敏感，冲突非常困难。而当你引入一种总是告诉人们他们很棒的技术时，它会强化我们注意力的捕获，并侵蚀我们的一些人际交往技能。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So having these AIs tell us that we're great all the time, tell us we're the next best thing is yet another mechanism for keeping us on the sites. And it really concerns me because at this historical moment socially, I think we are losing some of the skills that are required to navigate difference and conflict. We're struggling, students are struggling, teachers are struggling with how to navigate critical feedback. People are very sensitive. Conflict is really difficult. And then when you introduce a technology that just tells people they're awesome all the time, it really reinforces both the capture of our attention and the erosion of some of our interpersonal skills.</p>
</details>

她强调，**AI**绝不必如此。这种“谄媚”的个性是**注意力经济**（Attention Economy: 一种商业模式，通过吸引和维持用户注意力来创造价值）商业模式的一部分，但它并非数据驱动聊天机器人的固有特征。我们可以开发出行为截然不同的**AI**，但这需要有支持这些替代方案的商业模式。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And definitely AI need not be like that. the personality if we want to call it that uh of sick fancy I think is a part of this business model of attention capture but that it's not an inherent feature of datadriven chat bots we could develop them to behave really differently as well but there would have to be a business model that fueled those alternatives I think</p>
</details>

### 信任与问责：AI普及的关键挑战

当提到商业模式以及争取用户参与、获取数据、让我们与**AI**互动时，许多人可能会亮起红灯，心想：“哦，我不想做任何这些事。”那么，在存在这些担忧的情况下，要实现**AI**的高普及率需要什么？是否有某些好处会超越这些担忧？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When you mentioned the the business model and and sort of the business playbook of you know getting engagement getting the data getting us to uh interact with these AIs There's probably a lot of red flags for a lot of people who are like, "Oh, okay. I do not want to do any of that." And I'm sort of uh wondering what what will it take to get a sort of high rate of adoption of AI when there are some concerns even when you when you're mentioning that it's like okay yes when you see the business model in the back end you know there might be some hesitation but there are some benefits that will outweigh some of that.</p>
</details>

Stephanie Dick表示，数据中蕴含着巨大的力量和潜力。这是一个非常有趣的时刻，因为在学术领域、商业部门、组织和社会各方面，每个人都在提出一套共同的问题：我们拥有哪些数据？这些数据能提供哪些其他方式无法获得的洞察？我们如何创造新型数据，对数据提出不同的问题？只要**AI**邀请我们所有人参与这个项目，她就感到非常兴奋。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Absolutely. I mean, I will never be a person who says there isn't extraordinary power and potential in our data. And it's a a really interesting moment because across academic disciplines, business sectors, organizations, facets in society, everyone is asking a shared set of questions right now. And I'm really excited about that. Namely, what are the data that we have? What kinds of insights might that data afford that aren't otherwise available? And how can we create new kinds of data, ask different questions of our data? And in so far as that's a project that AI invites us all to participate in. I'm very excited.</p>
</details>

她也认为，关于信任和问责制的问题是理所当然且深刻的。我们知道**人工智能**会经常**幻觉**（Hallucination: AI模型生成虚假或不准确信息的情况）或编造信息。它缺乏上下文信息，在许多情况下具有奇怪的道德推理。因此，信任将是一个非常重要且影响深远的问题。这包括我们是否以及在何种条件下信任这项技术，我们是否以及在何种条件下信任使用这项技术的人，以及也许最重要的是，我们是否以及在何种条件下信任开发这项技术的人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I also think there are rightfully deep and profound questions about trust and accountability. Uh we know that artificial intelligence fabricates and constructs or hallucinates fairly regularly. It lacks contextual information. It uh has bizarre moral reasoning in a lot of contexts. So I think trust is going to be a really significant issue and it's wide reaching. There's the question of whether we can trust this technology and under when what conditions whether we trust people who are using this technology and under what conditions and perhaps most importantly do we trust the people who are developing this technology and under what conditions.</p>
</details>

因此，她认为广泛的普及将来自大量的信任协商。但现在，人们感到恐惧和愤怒，部分原因在于，从某种意义上说，没有人要求这项技术，但现在突然之间，每个人都被告知必须在自己的领域内应对这项技术。所以，这些都是我们需要进行大量社会协商的问题。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so I think that widespread adoption is going to come from a lot of trust negotiations but right now people are afraid and they're angry I think in part no one in a certain sense sort of asked for this And now all of a sudden everyone is being told we have to reckon with this technology in our own spaces. So those are are all issues that we're going to have to do a lot of social negotiation around.</p>
</details>

### AI的“昭昭天命”与未来展望

回顾过去，20世纪的科技专家们是否会惊讶于他们早期研究的应用方式？毕竟，**AI**在20世纪50年代才真正成为一个研究领域。他们会震惊于现在**AI**的应用方式与他们早期设想的差异吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You had mentioned uh the people developing these technologies and I want us to sort of go back in time and I am curious would the 20th century uh technologists be surprised um at how these applications that they were working on in the early days and see how they're being applied to now because we know uh AI really became a field of study in the 50s. you had sort of mentioned that but seeing how it is being applied now from what it what they thought in the early days would they be uh shocked?</p>
</details>

Stephanie Dick认为他们不会感到惊讶。她研究**AI**历史很长时间了，甚至在**AI**成为世人广泛讨论的话题之前。历史的一个主要主题是技术专家以及更广泛的公众中普遍存在的“不可避免性”感。我们似乎有一种感觉，这些事情是不可避免的，它们终将发生，我们最好在别人之前完成它们，或者说我们不可能没有这些技术。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I don't actually think so. Um, I've been studying history of AI for a long time since before AI was something that people were talking about meaningfully in the world. And one of the dominant themes of the history is this overwhelming sense of inevitability among technologists and I think also among a broader public too. We seem to have this sense that these things are inevitable. They're going to happen. we better do them first before somebody else does them or there's no possibility that we aren't going to have these technologies.</p>
</details>

她甚至提到一位历史思想家曾将计算称为“**计算的昭昭天命**”（Manifest Destiny of Computing: 一种信念，认为计算技术（特别是智能计算机）的普及和发展是不可避免且必然的），认为最终每个人都会拥有一台随时随地可用的智能计算机，这是一种“昭昭天命”，就像美国殖民化被认为是道德上必要且不可避免的一样。同样的不可避免性长期以来一直被赋予**人工智能**。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I even have and I think this is an important comparison especially where the environmental repercussions of artificial intelligence are concerned. I have one historical uh thinker who talked about the manifest destiny he called it of computing that eventually everyone would have a computer that was intelligent by any definition available to them at all times and that it was a kind of manifest destiny uh in the same sense that American colonization was imagined to be both morally necessary and inevitable. So that same inevitability has been assigned to artificial intelligence in the narratives that surround the technology for a long time.</p>
</details>

然而，她认为许多人会惊讶地发现，最终取得成功的**AI**方法是**人工智能神经网络**（Artificial Neural Network: 模拟人脑神经元连接方式的计算模型）驱动的、数据驱动的范式，这在20世纪50年代和60年代这些讨论刚开始时，看起来并没有那么有前景。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think many of them however would be surprised to know that the approach to AI that ended up generating success was the artificial neural networkdriven datadriven paradigm that really didn't look as promising in the 1950s and60s when these conversations started.</p>
</details>

Stephanie Dick对**AI**最兴奋的地方在于，它促使我们所有人提出关于我们是谁、我们想做什么样的工作、我们想如何生活、我们生活中的意义从何而来等深刻的生存问题。她兴奋的不是技术本身，而是它迫使我们进行这些关于如何生活的深刻对话。她认为这些对话早就应该进行了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What I'm the most excited about with AI is that it has got us all asking these deep existential questions about who we are, what kind of work we want to do, how we want to live, where meaning in our lives come from. And I's not necessarily excited about the technology as much as I am about the way that it's forcing us into these deep conversations about how we want to live. And I think they are overdue.</p>
</details>