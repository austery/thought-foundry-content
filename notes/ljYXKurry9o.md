---
area: tech-insights
category: technology
date: '2025-11-11'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《嵌套学习：深度学习架构的幻象》
products_models:
- HOPE模型
- Transformer
project:
- ai-impact-analysis
- systems-thinking
series: ''
source: https://www.youtube.com/watch?v=ljYXKurry9o
speaker: Best Partners TV
status: evergreen
summary: 当前大语言模型存在“记忆缺陷”，即训练后难以持续学习新知识。谷歌研究院的《嵌套学习：深度学习架构的幻象》论文提出了一种全新的“嵌套学习”范式，借鉴人脑记忆机制，构建多层次、多时间尺度的学习框架。论文还设计了HOPE模型，在语言建模和常识推理任务中超越了主流架构，为持续学习和长上下文推理提供了颠覆性解决方案。
tags:
- architecture
- continuous-learning
- learning
- memory
title: 谷歌重磅论文揭示深度学习“记忆缺陷”：嵌套学习与HOPE模型如何突破AI瓶颈
---

### 深度学习的“记忆缺陷”与传统架构的局限

近几年，**大语言模型**（Large Language Models: 简称LLM，指参数量巨大、能够理解和生成自然语言的人工智能模型）带来了很多震撼，但这些看似强大的模型背后，隐藏着一个致命的先天缺陷：它们本质上是静态的。这就像得了一种特殊的记忆疾病，训练结束后就很难再学习新的知识，只能依赖有限的上下文窗口进行即时适应，一旦超出了这个范围，就会忘记之前的信息。更关键的是，深度学习几十年来依赖的**层叠结构**（Layered Architecture: 指深度学习模型中由多个计算层堆叠而成的结构）在解决复杂算法的实现和持续学习等问题上，并没有我们想象中那么有效。

今天，我们要聊的这篇来自**谷歌研究院**的重磅论文《嵌套学习：深度学习架构的幻象》（Nested Learning: The Illusion of Deep Learning Architectures），或许为这些问题提供了颠覆性的解决方案。论文的四位作者提出了一种全新的学习范式——**嵌套学习**（Nested Learning: 一种将机器学习模型及其训练过程表示为一组嵌套的、多层次的、并行的优化问题的范式）。它不仅从数学上重构了深度学习的底层逻辑，还以此设计出了一个名为**HOPE模型**（HOPE Model: 基于嵌套学习范式设计的一种新型深度学习模型），在语言建模和常识推理任务中超越了**Transformer**、**RetNet**等主流架构。

在深入嵌套学习之前，我们必须先搞清楚当前深度学习的核心痛点到底是什么，以及为什么层叠结构不是万能的。几十年来，深度学习的发展路径似乎很明确：堆叠更多的层、扩大模型的参数规模以及设计更复杂的目标函数。从**CNN**到**Transformer**，从百万参数到万亿参数，这条路径确实带来了巨大成功。但是作者们在论文中指出，这种层叠思维存在四个无法回避的局限：
首先，模型的计算深度并不会随着层数增加而无限提升，很多深层模型的算法表达能力其实和浅层模型相差无几。
其次，部分参数的容量提升会随着深度或宽度的增加而边际递减，继续扩大规模只是无效堆叠。
第三，训练过程容易陷入次优解，这很大程度上是因为优化器及其超参数的选择不够合理。
最后，也是最关键的一点，模型的快速适应能力、持续学习能力和分布外泛化能力几乎不会因为堆叠更多的层而得到提升，这也是为什么模型训练结束后就无法再高效学习新知识的核心原因。

更形象地说，当前模型的记忆系统类似于一种**顺行性遗忘症**（Anterograde Amnesia: 一种神经系统疾病，患者在发病后无法形成新的长期记忆）。患者在发病后无法形成新的长期记忆，但是发病前的记忆依然完好。大语言模型的发病时间点就是预训练结束的时刻。预训练阶段学到的知识被存储在**MLP**层中，相当于发病前的长期记忆；而推理时的上下文信息只能暂时存在注意力机制中，相当于即时的短期记忆。一旦上下文窗口超出限制，或者遇到预训练中没有见过的新知识，模型就无法将其转化为长期记忆，只能视而不见。

### 人脑记忆机制的启发：多时间尺度巩固

那么，人类为什么能避免这种记忆缺陷，实现高效的持续学习呢？这正是论文灵感的来源——神经科学中的人脑记忆机制。论文指出，人脑的持续学习能力源于**神经可塑性**（Neuroplasticity: 大脑能够根据新的经验、学习和损伤进行自我调整的能力），也就是大脑能够根据新的经验、学习和损伤进行自我调整的能力。而记忆的巩固过程主要分为两个互补的阶段：
第一阶段是**在线巩固**（Synaptic Consolidation: 记忆巩固的第一阶段，发生在学习后立即或不久的时间内，将新的记忆痕迹稳定下来），发生在学习后立即或者不久的时间内，即使在清醒状态下也会进行。这个阶段会将新的、脆弱的记忆痕迹稳定下来，并且开始从短期记忆向长期记忆转移。
第二阶段是**离线巩固**（Systems Consolidation: 记忆巩固的第二阶段，主要发生在睡眠中，通过重复回放记忆模式强化并重组记忆），主要发生在睡眠中，通过**海马体**（Hippocampus: 大脑中负责记忆形成和巩固的关键区域）的**尖波涟漪**（Sharp Wave Ripples, SWRs: 海马体中与记忆巩固相关的电生理活动）与大脑皮层的**睡眠纺锤波**（Sleep Spindles: 睡眠期间大脑皮层出现的短暂脑电波，与记忆巩固有关）和**慢波**（Slow Waves: 深度睡眠期间大脑皮层出现的低频高振幅脑电波，与记忆巩固有关）协调，重复回放最近编码的记忆模式，强化并且重组记忆，最终将它转移到大脑皮层中进行长期存储。

对于大语言模型来说，它们既没有在线巩固机制，也没有离线巩固机制。因此，论文的核心思路是借鉴人脑的多时间尺度记忆巩固机制，来构建一种嵌套式的学习框架，让模型的每个组件都能在不同的时间尺度上更新，形成多层次的记忆系统，从而突破传统深度学习的局限。

### 嵌套学习（NL）的核心概念与框架

接下来，我们进入论文的核心部分：嵌套学习（NL）到底是什么？论文给出的定义是，嵌套学习是一种将机器学习模型及其训练过程表示为一组嵌套的、多层次的、并行的优化问题的范式，每个优化问题都有自己的上下文流（context flow）。简单来说，传统深度学习是扁平的，所有参数基本在同一个时间尺度上更新；而嵌套学习是立体的，模型的不同组件有不同的更新频率，形成层级结构，就像人脑中有不同频率的脑波，对应不同的信息处理速度。

要理解嵌套学习，首先必须明确两个核心概念：**关联记忆**（Associative Memory: 在机器学习中，指将一组键映射到一组值的算子）和学习的区别，以及更新频率（Update Frequency）。

首先是关联记忆与学习的定义。在神经心理学中，记忆和学习是两个不同的概念：记忆是输入引起的神经更新，而学习是获取有效且有用记忆的过程。论文将这个定义迁移到机器学习中，认为所有机器学习模型的组件，无论是神经网络本身，还是优化器，本质上都是关联记忆系统。它们的核心作用是压缩自身的上下文流。这里的关联记忆被定义为一个将一组键（key）映射到一组值（value）的算子。

比如，对于一个简单的1层**MLP**，训练过程就是让它学习将输入数据映射到**局部意外信号**（Local Surprise Signal, LSS: 指当前输出与目标函数要求的结构之间的不匹配），也就是当前输出与目标函数要求的结构之间的不匹配的过程。为了让大家更直观地理解，论文举了一个非常经典的例子：用**梯度下降**（Gradient Descent: 一种优化算法，用于最小化函数，通过迭代地沿着函数梯度的反方向移动）训练1层的MLP。这个训练过程可以被重新表述为一个优化问题：MLP的权重W本质上是一个关联记忆算子，目标是最小化输入数据x与局部意外信号u的点积，再加上权重的正则项。这里的局部意外信号u就是输出y对目标函数L的梯度。也就是说，传统的梯度下降训练本质上是让模型学习输入数据到局部意外信号的映射，而这个映射过程就是记忆的压缩过程。

如果把梯度下降换成带动量的梯度下降（SGD with Momentum），情况就会变得更加复杂，也更能体现嵌套的含义。带动量的更新规则中，除了权重W，还有一个**动量项**（Momentum Term: 在梯度下降中引入的项，用于加速收敛并抑制震荡）m。论文指出，这个动量项m本身也是一个关联记忆模块，它要么是一个无键关联记忆，负责压缩梯度信息；要么是一个有键关联记忆，学习将数据点映射到对应的局部意外信号。此时，整个训练过程就变成了一个两层的嵌套优化问题：内层优化动量项m，压缩梯度信息；外层利用m更新权重W。这种结构与**快速权重程序**（Fast Weight Programs, FWPs: 一种学习范式，其中一部分权重更新速度快，另一部分更新速度慢）的思路不谋而合，动量项是快速更新的权重，而MLP的权重W是慢速更新的权重。

另一个例子是**线性注意力**（Linear Attention: 一种简化版的注意力机制，计算复杂度较低）的训练。线性注意力的核心是通过M_t = M_{t-1} + v_t k_t^⊤ 来更新记忆矩阵M，再通过y_t = M_t q_t 生成输出。论文发现，这个记忆矩阵M的更新过程同样可以表述为一个关联记忆的优化问题：M的目标是最小化输入键k和值v的点积，加上与前一时刻M_{t-1}的正则项。这与梯度下降的更新规则完全等价。而线性注意力中的投影层（W_k、W_v、W_q），它的训练过程本身也是一个关联记忆的优化问题。因此，线性注意力的训练是一个两层嵌套优化：外层优化投影层，进行慢速更新；而内层优化记忆矩阵M，进行快速更新。

从这两个例子可以看出，传统的深度学习模型其实都可以被拆解为多层次的嵌套优化问题，只是我们之前没有从这个角度去理解。而嵌套学习的核心贡献之一，就是将这种隐性的嵌套结构显性化，并且提出了更新频率这个关键指标，来定义不同组件的层级关系。论文对更新频率的定义是：对于模型的任何组件，它的频率f_A是单位时间内的更新次数。基于更新频率，我们可以对模型组件进行排序：如果组件A的更新频率高于组件B（f_A > f_B），或者A和B频率相同、但是B的计算依赖A的状态，那么A比B更快（记为A ≻ B）；如果频率相同而且计算独立，则记为A ≡ B。基于这个排序规则，模型的所有组件会被划分为不同的层级，同一层级的组件更新频率相同，层级越高，更新频率越低。每个层级的组件都有自己的优化问题和上下文流，从而形成独立的梯度流。这意味着嵌套学习允许模型在不同的抽象层次和时间尺度上处理数据：快速更新的组件处理即时的、细节的信息；慢速更新的组件处理长期的、抽象的信息，就像人脑的不同脑区处理不同时间尺度的信息一样。

### 嵌套学习的三大核心贡献

理解了嵌套学习的核心框架后，我们来看论文的三大核心贡献。它们都是基于嵌套学习的视角，对传统深度学习的组件进行重构和升级。

第一个贡献是**深度优化器**（Deep Optimizers: 基于嵌套学习提出的更具表达力的优化器扩展方向）。论文指出，我们常用的基于梯度的优化器本质上都是关联记忆模块，核心作用是压缩梯度信息。基于这个洞察，作者们提出了四种更具表达力的优化器扩展方向。
第一种是更具表达力的关联（More Expressive Association）：传统的动量法是无值关联记忆，只将梯度映射到单一的值，表达力有限。论文提出给动量法增加一个值参数P_i，让动量项学习将梯度与P_i的映射关系，相当于对动量GD进行**预条件化**（Preconditioning: 一种优化技术，通过改变优化问题的条件数来加速收敛）。这种优化器的更新规则是这样的，其中P_i可以是梯度的函数，比如**海森矩阵**（Hessian Matrix: 一个二阶偏导数组成的方阵，描述函数的局部曲率）的信息，让映射关系更有意义。
第二种是更具表达力的目标函数（More Expressive Objectives）：传统优化器的内部目标函数多是点积相似度，容易导致记忆效率低下。论文提出用**L2回归损失**（L2 Regression Loss: 一种常用的损失函数，衡量预测值与真实值之间平方差的平均值）来替代点积相似度，最小化损失函数。这种更新规则基于**delta规则**（Delta Rule: 一种用于训练感知机的学习规则），能让动量项更好地管理有限的容量，更高效地记忆过去的梯度序列。
第三种是更具表达力的记忆（More Expressive Memory）：传统动量项是线性的矩阵值记忆，只能学习梯度的线性函数。论文提出用MLP来替代线性矩阵作为动量项的记忆模块，形成**深度动量梯度下降**（Deep Momentum Gradient Descent, DMGD: 用MLP替代线性矩阵作为动量项的记忆模块），让动量项能够捕捉梯度的非线性动态特征，提升学习能力。
第四种是非线性输出（Non-Linear Outputs）：在动量项的输出上增加非线性激活函数，比如**牛顿-舒尔茨迭代**（Newton-Schulz Iteration: 一种用于计算矩阵逆的迭代方法）。这种优化器与**Muon优化器**等价，能够进一步提升优化器的表达力。
除此之外，论文还对传统的**反向传播**（Backpropagation: 神经网络中用于计算梯度并更新权重的算法）过程进行了扩展。传统反向传播中，权重更新规则本质上是忽略了数据样本之间的依赖关系。论文提出用L2回归目标来替代点积目标，得到新的权重更新规则。这种优化器能考虑数据样本之间的依赖，尤其适合在token空间中使用，因为token之间并不是独立的。

第二个贡献是**自修改Titans**（Self-Modifying Titans: 一种序列模型，能够学习和调整自身的更新算法）。Titans是作者们之前提出的一种序列模型。基于嵌套学习的洞察，他们对它进行了升级，让模型学会修改自身，也就是学习自己的更新算法。具体来说，自修改Titans将优化器的更新规则本身作为学习对象，通过嵌套的优化问题，让模型在训练过程中不断调整更新策略，从而适应不同的任务和数据分布。这种自修改能力让模型摆脱了固定优化器的束缚，能够根据实际情况动态调整学习方式，这也是持续学习所必需的核心能力。

第三个贡献是**连续记忆系统**（Continuum Memory System, CMS: 一组具有不同更新频率的MLP块链，实现多时间尺度的记忆存储）。传统的记忆系统被划分为短期记忆和长期记忆，这种二分法过于简单，无法适应多时间尺度的记忆需求。论文提出的连续记忆系统是一组MLP块的链，每个MLP块都对应一个特定的更新频率。每个MLP块的参数θ会每隔C^(ℓ)步更新一次，而更新频率越高的MLP块，更新的间隔越短。连续记忆系统的输出的计算方式和参数更新规则是这样的，这里的f点是优化器的误差项。值得注意的是，传统的**Transformer块**其实是连续记忆系统的一个特殊情况，当k=1时，只有一个**FFN层**（Feedforward Network Layer: 前馈网络层，Transformer中的一个组件），所有参数都在同一个时间尺度上更新。而连续记忆系统的核心优势在于，每个MLP块都负责压缩自己对应的上下文流，形成不同抽象层次的知识表示。高频更新的MLP块存储短期的、具体的信息；低频更新的MLP块存储长期的、抽象的信息，从而实现从短期记忆到长期记忆的连续过渡，完美复刻了人脑的多时间尺度记忆巩固机制。

### HOPE模型架构与实验结果

有了深度优化器、自修改Titans和连续记忆系统这三大组件，论文最终构建出了HOPE模型，一个具有自指学习能力和连续记忆的嵌套学习模块。HOPE的架构核心是将自修改Titans与连续记忆系统融合，连续记忆系统提供多层次的记忆存储，自修改Titans提供动态的更新算法学习，再结合论文提出的改进型梯度下降优化器，形成一个端到端的学习框架。从结构上看，HOPE与Transformer有着明显的区别：Transformer只有单一频率的FFN层，而HOPE有高、中、低不同频率的FFN层，对应不同的记忆更新节奏。同时，HOPE的自修改Titans模块能够动态调整键、值、查询的投影方式，而Transformer的投影层是固定的。

为了验证HOPE的性能，论文在语言建模和常识推理两大类任务上进行了实验。对比的基线模型包括**Transformer++**、**RetNet**、**DeltaNet**、**TTT**、**Samba**、**Titans (LMM)**等主流架构。实验中，HOPE的参数规模分为340M、760M和1.3B三个等级，训练数据量分别为30B和100B tokens。

我们先看语言建模任务的结果。在Wiki数据集上，1.3B参数的HOPE**困惑度**（Perplexity, ppl: 衡量语言模型性能的指标，值越低表示模型越好）达到了15.11，而同样参数规模的Titans (LMM)是15.60，Transformer++是18.53，RetNet是19.08。在LMB数据集上，HOPE的困惑度为11.63，准确率为50.01%，而Titans (LMM)的困惑度是11.41，准确率是49.14%。虽然困惑度略高于Titans，但是准确率更高，综合表现更优。

再看常识推理任务。这包括**物理常识推理PIQA**、**日常场景推理HellaSwag**、**代词指代推理Winograd**、**科学常识推理ARC-e/ARC-c**、**社交常识推理SIQA**以及**自然语言是非问答BoolQ**等8个任务。在1.3B参数规模下，HOPE在PIQA上的准确率达到73.29%，超过Titans (LMM)的73.09%；在HellaSwag上准确率为56.84%，高于Titans的56.31%；在Winograd上准确率60.19%，超过Titans的59.81%；在ARC-c上准确率41.24%，高于Titans的40.82%；在BoolQ上准确率61.46%，高于Titans的60.97%。最终，HOPE的平均准确率达到57.23%，超过了所有的基线模型，包括混合架构Samba（54.00%）和Titans (LMM)（56.82%）。

从实验结果可以看出，无论是语言建模还是常识推理，HOPE在不同参数规模下都表现出了优异的性能，尤其是在1.3B参数规模下，全面超越了传统Transformer和现代循环神经网络。这充分证明了嵌套学习范式的有效性，通过多时间尺度的记忆更新和自修改的学习算法，模型能更好地捕捉数据中的依赖关系，提升表达力和泛化能力。

### 嵌套学习的深远影响与未来展望

那么，嵌套学习的提出到底给深度学习领域带来了哪些深远的影响呢？
首先，它打破了堆叠层数等于模型能力的固有认知，为深度学习开辟了一个新的维度，也就是**层级深度**（Level Depth: 嵌套学习中指优化问题的嵌套层级）。传统深度学习的深度是指网络的层数，而嵌套学习的深度是指优化问题的嵌套层级。这意味着，未来提升模型的能力不一定需要堆叠更多的层，也可以通过增加嵌套层级、设计更丰富的多时间尺度更新机制来实现。
其次，它为解决**持续学习**、**长上下文推理**（Long-Context Reasoning: 模型处理和理解长篇文本信息的能力）等传统难题提供了全新的思路。通过连续记忆系统，模型能够实现从短期记忆到长期记忆的平滑过渡，避免了**灾难性遗忘**（Catastrophic Forgetting: 持续学习中模型在学习新任务时遗忘旧知识的现象）。而多时间尺度的更新机制让模型能同时处理即时上下文和长期知识，提升长上下文推理能力。这对于大语言模型的实用化至关重要，未来的模型可能不需要依赖越来越大的上下文窗口，就能高效处理长文本，并且持续学习新的知识。
第三，它将神经科学与深度学习的结合推向了新的高度。嵌套学习的核心灵感来自于人脑的记忆巩固机制和神经可塑性，而论文通过严格的数学推导，将这种神经科学洞察转化为可实现的机器学习框架，实现了从脑到AI的有效迁移。这种跨学科的研究思路可能会引发更多神经科学与AI的交叉研究，推动AI向更接近人脑的方向发展。

当然，嵌套学习也存在一些局限性。论文里提到，当前的嵌套学习框架主要关注的是在线巩固阶段，对离线巩固的研究还不够深入。同时，嵌套学习的计算复杂度相对较高，如何在保持性能的同时提升计算效率是未来需要解决的问题。此外，嵌套学习的理论分析还需要进一步的完善，比如不同嵌套层级对模型性能的影响、更新频率的自适应调整等问题，这些都需要更加深入的研究。