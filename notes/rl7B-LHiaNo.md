---
area: tech-work
category: ai-ml
companies_orgs: []
date: '2024-06-12'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- Francois Chollet
products_models: []
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=rl7B-LHiaNo
speaker: Dwarkesh Patel
status: evergreen
summary: 本次讨论深入探讨了人工智能领域的扩展定律（scaling laws），并质疑其是否真正衡量了智能的提升。演讲者 Francois Chollet
  认为，当前的基准测试（benchmarks）主要依赖于记忆能力，而非真正的通用智能。他区分了‘技巧’（skill）和‘智能’（intelligence），指出模型通过扩展数据和计算能力可以提高技巧和性能，但这并不等同于智能的增长。文章还探讨了两种‘推理’的定义，并对比了人类学习与AI训练的差异。
tags:
- intelligence
- memorization
- philosophy
- scaling-law
title: 'Scaling Laws: Memorization vs. Intelligence'
---

### 智能的定义
通用智能并非特定任务技能的扩展，而是能够快速掌握任何问题或技能的能力，并利用过往数据来应对未知挑战。这一定义的核心在于“**通用性**”（generality），它不是将单一技能规模化，而是指能够将思维应用于任何事物、任何情境的能力。要实现这一点，根本上需要具备高效、即时适应和学习的能力。

### 扩展定律的争议
所谓的“**扩展定律**”（scaling laws: 指在训练模型时投入的计算量与模型在基准测试上表现之间的经验关系）是当前AI研究中的一个核心论点。支持者认为，增加计算量和数据能够提升模型性能。然而，关键问题在于如何衡量这种性能提升。衡量标准本身并非技术细节，它会直接影响我们提出的问题和寻找的答案。

### 基准测试的局限
目前用于评估大型语言模型（LLMs）的许多基准测试，本质上是基于“**记忆**”（memorization）能力的。有些测试纯粹是知识型，如同学校考试；即使是那些明确涉及“**推理**”（reasoning）的测试，仔细分析也会发现，只需记忆有限的推理模式并加以套用即可解决。大型语言模型擅长记忆静态程序，它们拥有一个“解决方案库”，能够检索并应用已有的程序来解决新问题，这看起来像是推理，实则是程序检索而非即时合成。因此，这些测试可以通过记忆来解决。

### 智能与技巧的区分
当我们扩展模型时，实际上是在扩展其“**插值数据库**”或“**记忆**”的规模。增加知识和模式可以提高模型在记忆基准测试上的表现，但这并未真正提升系统的“**智能**”（intelligence）。我们增加的是系统的“**技巧**”（skill）、实用性和应用范围，而非智能本身。混淆技巧与智能是人们常犯的一个概念性错误。

### 示例与推理定义
以一个名为“**GSS 8K**”的基准测试为例，它包含需要高中生才能解决的数学问题，模型在此类测试上能达到95%的准确率，这表明它们擅长记忆。例如，一个关于学生年龄分布的数学应用题，虽然需要理解分数和上下文，但其核心是套用已知的解题模板。

### 推理的两种定义
关于“推理”，存在两种定义。第一种：拥有预设的“**程序模板**”（program templates），识别出问题的结构，将新数据输入模板运行得到答案。这可以被视为一种推理。第二种，也是更困难的定义：当面对一个没有现成程序可用的新问题时，必须基于已有的知识片段，即时（on-the-fly）合成一个全新的程序来解决问题。这需要真正的“**即时程序合成**”（on-the-fly program synthesis）。

### 人类学习与AI训练
我们可能高估了人类在学习上的“**样本效率**”（sample efficiency），认为他们无需大量重复训练就能掌握复杂推理。人类学习数学需要多年的系统性教学，从基础到高等数学。这与AI模型需要大量训练数据来“**钻研**”（drill）各种推理路径相似。然而，要实现即时程序合成，确实需要基础的“**知识**”（knowledge）和“**记忆**”（memory）作为构建模块。有效的推理离不开记忆的支持。