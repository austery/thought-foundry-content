---
area: tech-insights
category: technology
companies_orgs: []
date: '2025-11-15'
draft: true
guest: ''
insight: ''
layout: post.njk
products_models:
- DeepSeek-OCR
project:
- ai-impact-analysis
- knowledge-pipeline
series: ''
source: https://www.youtube.com/watch?v=3dJ3s_ddIfc
speaker: AI超元域
status: evergreen
summary: 本视频深入探讨了开源OCR模型Chandra OCR，展示其在处理复杂版面、长文档、模糊扫描件及手写体方面的卓越能力。相较于DeepSeek-OCR等模型，Chandra
  OCR在基准测试中表现更优，支持40多种语言和结构化输出。视频详细演示了如何在LM Studio和Ubuntu系统上进行本地部署，并通过多项真实案例测试，验证了其在页眉页脚、表格、公式、繁体字识别上的强大效果，为用户提供了解决长文档识别痛点的革命性方案。
tags:
- ai-model
- society
- technology
title: Chandra OCR：复杂文档识别的革命性突破与本地部署指南
---

### 开源OCR模型现状与挑战

最近，各种开源的**OCR**（Optical Character Recognition: 光学字符识别技术）模型发布得越来越多。在我之前的视频中，也为大家演示过非常多的开源OCR模型，比如说**DeepSeek-OCR**（DeepSeek-OCR: 一款开源的光学字符识别模型）、**OMOCR**（OMOCR: 一款开源的光学字符识别模型）以及**DUTS OCR**（DUTS OCR: 一款开源的光学字符识别模型）等。虽然这些模型的OCR能力效果比较不错，但是遇到复杂版面、长文档、多页PDF时，就可能出现漏字、漏掉页眉页角、排版混乱、表格错位等问题。所以，想找到一款真正稳定、效果够强、适合长文档以及复杂文档场景的OCR模型还是有一定难度的。

举例来说，我用一个内容非常长的PDF扫描件进行测试，然后DeepSeek-OCR模型它就会漏掉扫描件上的页眉以及页角等内容。换成DUTS OCR，它也会同样漏掉扫描件上的页眉以及页角等内容。

### Chandra OCR：超越现有模型的革命性突破

为了找到更强大的开源OCR模型，本期视频将在这里演示另一款开源的OCR模型——**Chandra OCR**（Chandra OCR: 一款开源的、针对复杂文档优化的光学字符识别模型）。相比其他开源OCR模型，这款模型针对复杂文档也有很好的识别效果，而且它在基准测试中的得分超过了DUTS OCR、OMOCR以及DeepSeek-OCR等常见的OCR模型。本期视频，我们将用多种复杂的文档来测试这款模型的OCR能力。

### Chandra OCR模型介绍与核心能力

视频的开始，我们先看一下这款模型的介绍，然后为大家演示本地部署这款模型，再对这款模型进行OCR能力测试。这款模型具备结构化文档理解能力，它的参数为**9B参数**（9B参数: 指模型拥有90亿个参数，通常参数量越大，模型能力越强）。它支持40多种语言，包含中文以及中文的手写体。它支持结构化输出，可以直接导出**Markdown格式**（Markdown格式: 一种轻量级标记语言，用于创建格式化文本）、**HTML格式**（HTML格式: 超文本标记语言，用于创建创建网页的标准语言）、**JSON格式**（JSON格式: JavaScript对象表示法，一种轻量级的数据交换格式），能够保留标题层级、段落、列表、表格与图像引用。而且它支持手写体与表单，对手写记录、医生病历、问卷、合同等有良好的还原度，支持表格、数学公式、报纸、多栏、页眉页角等复杂元素。

### Chandra OCR本地部署指南

想在本地部署这款模型非常简单，我们可以在**LM Studio**（LM Studio: 一个用于在本地运行大型语言模型的桌面应用程序）中来使用这款模型。我们只需要点击“发现”，在搜索框输入这款模型的名称，然后这里我们可以安装**4bit**（4bit量化: 一种模型优化技术，通过降低模型参数的精度来减少模型大小和计算需求）的，也可以安装**8bit**（8bit量化: 一种模型优化技术，通过降低模型参数的精度来减少模型大小和计算需求）的，然后再点击下载，我们就可以在LM Studio中来使用4bit或者8bit量化的Chandra模型。

下面我们也可以使用官方仓库给出的部署方式进行部署。下面我将在**Ubuntu**（Ubuntu: 一种基于Linux的开源操作系统）系统上为大家演示如何部署这款模型。首先我们先用这条命令安装一下**uv**（uv: 一个快速的Python包安装器和解析器）。下面我们就可以将官方仓库**克隆**（Git clone: Git版本控制系统中的一个命令，用于复制远程仓库到本地）下来，我们只需要执行`git clone mini`。下面我们就可以用`cd mini`进入到这个项目的路径，然后再执行`uv mini`来安装这个项目。下面我们再执行这条命令来激活一下**虚拟环境**（虚拟环境: Python中用于隔离项目依赖的独立环境），然后我们再用**pip install**（pip install: Python的包管理工具pip中的一个命令，用于安装Python包）命令来安装一下Chandra OCR。

下面我们就可以使用官方给出的命令直接对PDF文件进行OCR识别。为了方便演示，我们还可以使用这条命令来启动官方给出的**Demo**（Demo: 演示程序或示例），然后我们只需要执行这条命令就可以。这里启动成功，下面我们就可以在浏览器中打开。打开之后，我们就看到了这个UI界面的Demo。在左侧这里我们点击下拉选择**Hugging Face**（Hugging Face: 一个专注于机器学习和人工智能的平台，提供模型、数据集和工具）来运行这个模型。这里开始下载模型，在终端界面就可以看到它正在下载模型的权重文件。

### Chandra OCR真实测评：复杂文档识别效果

然后我们就可以选择需要进行OCR的文件。我们先上传一个扫描版的长文档的文件进行测试，这里包含页眉还有底部的页角，然后我们直接点击运行测试一下这个OCR效果。然后我们可以查看一下它的**显存占用**（显存占用: 显卡内存的使用情况，影响模型运行的性能）情况。这里识别完成，它可以对PDF扫描件里的这些元素进行标记。在这个Demo中，它就按HTML的格式进行了输出，包括页眉的内容还有页角的内容，它全部都提取了出来。在提取的正文中，它使用了HTML的P标签，按照原文的格式进行了分段。像同样的文档，我们在使用其他OCR模型的时候就会漏掉文档中的页眉、页角等内容。如果不想在本地部署的话，也可以使用官方提供的平台进行测试。比如说在官方提供的平台这里我们就可以上传PDF文档，这里就成功识别出来了我刚才上传的PDF文档里的这些内容。然后我们还可以查看它的JSON格式，也可以查看它的HTML格式，还可以查看它的Markdown格式。

下面我们继续在Demo中进行测试。我们上传一个手写体的文件测试一下它能否准确地识别出来。这是它的识别结果，通过对比可以发现它识别的这些内容与这个文件上完全一致，没有任何识别错误的地方，而且我们还可以查看它标记的这些内容，它将每一行都标记了出来。

下面我们加大难度，我们上传一张比较模糊的PDF扫描件。这个PDF文档上既包含中文还包含这些代码。这里提取成功，可以看到标题这里它保持了原有的加粗的格式，然后这里的这一行小字它也成功提取了出来。然后在原始文档上这些代码我故意设置成了有重叠的区域，然后针对重叠的部分它这里都成功提取了出来，包括文档中的这些序号，它也都成功提取了出来。然后在Windows中这一段小字它也完整地提取了出来。

下面我们再加大难度，我这里用一张模拟的考试试卷让它进行识别。这是它的识别结果，试卷上这一部分它成功提取了出来，它提取的这些字体都保持了试卷上原有的这些格式，并且没有任何识别错误的地方。包括这些字体中加了注音的这些它也都成功显示了出来。然后我们还可以查看它对这些元素的标记，包括左侧的这一部分它都进行了标记并且进行了识别。还有底部的这些页码内容它也都成功提取了出来。

下面我们用一个非常模糊而且排版复杂、既有中文又有英文、还有这些公式以及表格的文件让它进行OCR。这是它的识别结果，在标题这里它用了加粗，这里是论文的作者。然后我们可以查看一下，它完全还原了扫描件上的格式，包括这些序号它都成功识别了出来。然后我们再看一下最重要的公式。这是它提取的这些公式。然后我们再看一下它提取的表格内容是否正确，它提取的表格内容也都完全正确。在参考文献区域里它提取的也都是正确的。可以看到我们用的这个非常复杂的、既有中文又有英文、还有这些公式、还有表格、并且扫描的比较模糊的这个文件内容，它都成功识别了出来，并且保持了原有的格式进行的输出。

下面我们再选择一个扫描版的、排版比较混乱的学习笔记进行测试。可以看到这个文件里的内容排版比较混乱。下面我们重点对比一下这些对号和差号的标记是否正确。可以看到这一部分它提取的完全正确，然后这一部分它提取的也完全正确。下面这一部分我们再来对比一下，可以看到这里提取的也是完全正确的。在这一部分包含两颗星，可以看到它输出的内容也保持了这两颗星，而且右上角的小字它也成功识别了出来并且在这里进行了输出。在左下角这个红色的“关键”这两个字在这里它也成功识别了出来。可以发现我们用的这个排版没有规律的一个文件它也都成功进行了识别，并且成功进行了输出。

下面我们再加大难度，我们选一个更加复杂的表格进行测试。为了增加难度，在单元格里我故意设置了很多重叠的字，我们看一下这些重叠的部分它能否正确的识别。这里提取完成，我们对比一下表格中的内容提取的是否正确。我们重点对比有重叠的这部分，这两个单元格中的内容它提取的是正确的。这两个单元格中有重叠的内容它这里也成功提取了出来。我们再对比一下这一部分，这一部分它也成功正确地提取了出来。然后下面这里的内容它提取的也都是正确的。可以看到我们用的这个比较模糊且复杂的表格内容它都能成功地提取。

下面我们再选一张比较模糊且内容复杂、而且还包含柱状图还有表格内容的一个文件进行测试。这里成功识别了出来，而且它将扫描件上的柱状图直接提取了出来，按照图像的格式进行了展示。然后这个文件中这些表格里的内容它也都成功提取了出来。

下面我们再选一张古书的扫描件，看一下它能否识别繁体字的内容。下面我们看一下它识别的是否正确。可以看到它把扫描件里这些有标点符号的内容它也成功提取了出来，而且它提取了这些繁体字的内容也都和原文中保持一致，没有出现任何识别错误的地方。这样看来它对繁体字的识别效果也是非常不错的。

### 总结与展望

通过我们多方面的测试可以发现，这款模型它对这些复杂且模糊的PDF文档识别效果确实非常不错，而且不会漏掉页眉页角等重要内容，还能保持与原文档一致的格式进行输出。像这样的话，我们针对复杂的PDF文档的识别就可以使用这一款模型，它比其他同等参数的开源OCR模型效果要好非常多。本期视频所用到的笔记和代码我都会放在视频下方的描述栏或者评论区，如果你在视频下方无法找到的话也可以通过我的博客去查找本期视频所对应的笔记。本期视频就做到这里，欢迎大家点赞、关注和转发，谢谢大家观看。