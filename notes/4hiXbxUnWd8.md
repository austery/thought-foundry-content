---
area: "work-career"
category: ai-ml
companies_orgs:
- Anthropic
- OpenAI
date: '2024-03-11'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- Dario Amodei
- Einstein
products_models:
- GPT-3
project: []
series: ''
source: https://www.youtube.com/watch?v=4hiXbxUnWd8
speaker: Dwarkesh Patel
status: evergreen
summary: Anthropic CEO Dario Amodei 探讨了人工智能（AI）的发展，指出尽管缩放定律（scaling laws）可预测，但商业爆发和模型形态难以预料。他认为智能并非单一光谱，而是多维度、多领域的技能集合。AI
  在受限写作等任务上表现出色，但缺乏复杂推理和纠错能力。Amodei 对比了模型规模与人脑，并指出 AI 虽拥有海量知识，但尚未产生重大科学发现，其创造力更偏向“普通创造力”。他认为，生物学等领域因知识密集型特点，AI
  或许能加速发现，但目前模型仍需提升技能水平以实现知识的有效整合。
tags:
- creativity
- discovery
- intelligence
- llm
title: 对智能的普遍误解：Anthropic CEO Dario Amodei 的见解
---
### AI 发展与预测的挑战
我感觉这些 **scaling laws**（缩放定律）一直非常可预测，但当你说“这些模型何时会爆发商业应用？它的形式会是什么样？模型是会独立于人类行事，还是与人类协同工作？”时，我感觉我预测这些事情的记录确实很糟糕。但同时放眼望去，我并没有看到谁的记录很出色。

### 智能的非线性与多维度
我曾正确预测过一些事情，但即便如此，在那些理论性的图景中，我仍然在大部分事情上犯了错。能说对 10% 的事情，就已经比很多人强很多了。回想起来，我记不清是谁画了那些图，比如“这里是村里的傻瓜，这里是爱因斯坦，这里是智能的尺度”，而村里的傻瓜和爱因斯坦非常接近。也许在某种抽象意义上这仍然是真的，但我们看到的并非如此。

### 人类能力的多样性
我们看到的是，人类的能力范围相当广泛，而且对于不同的任务，我们不会在同一个地方或同一时间达到人类的极限。比如，写一首科马克·麦卡锡风格的十四行诗，我不知道，我不太有创造力，所以做不到。但你知道，那是一项相当高级的人类技能。

### AI 的局限性与强项
即使是模型，在一些受限的写作任务上，比如写一页不使用字母“e”的文字，或者写一篇关于 X 且不使用字母“e”的页面，模型可能已经达到了 **superhuman**（超人水平）或接近超人水平。但当涉及到证明相对简单的数学定理时，它们才刚刚起步，有时会犯非常愚蠢的错误，并且它们确实缺乏广泛的、能够纠正错误或执行扩展任务的能力。

### 智能的本质：多领域技能
所以，智能并非一个单一的谱系。存在许多不同的领域专业知识，也存在许多不同的技能类型，比如记忆力就是不同的。我的意思是，这一切都形成于大脑这个“大团块”中，并不复杂。但即使在某种程度上存在谱系，这个谱系也是宽泛的。如果你十年前问我，我完全不会这么预期，但我想事实确实如此。

### 认知能力的关联性猜想
令人惊讶的一点是，我曾以为事情会比现在更“咔哒”一下就到位。我曾以为不同的认知能力可能都相互关联，背后有一个共同的秘密。但模型只是在不同时间学习各种东西。你知道，它可能在编程方面非常出色，但却无法证明素数定理。对于人类来说，情况也有些类似，尽管事物如何分布（能做什么，不能做什么）确实很奇怪。

### 智能理论的消解
我想，主要的教训是，关于智能或智能如何运作的理论，很多时候这些词语会消解为一个连续体，它们会“去物质化”。我认为我们应该更多地从我们眼前所见出发，而不是从抽象的智能概念出发。

### AI 能力的现实评估
如果你在 2018 年告诉我，到 2023 年我们会拥有能够以莎士比亚风格写定理、写任何你想要的定理、通过标准化测试、回答开放式问题，总之是各种令人印象深刻的模型，你当时肯定会说：“哦，你有了 **AGI**（Artificial General Intelligence: 通用人工智能，指具备与人类相当或超越人类的智能水平的机器），你显然拥有了人类水平的智能。”

### 期望与现实的差距
然而，尽管这些模型令人印象深刻，但显然我们还没有达到人类水平，至少在当前一代是如此，甚至可能在未来几代也难以企及。是什么解释了这些模型在基准测试和你能描述的各种任务上表现出超乎寻常的性能，与我们实际并未达到人类水平之间的巨大差距呢？

### 早期模型与语言本质
所以，这确实是一个让我感到意外的领域。是的，当我第一次看到 **GPT-3**，以及我们在 **Anthropic** 早期构建的那些东西时，我的总体感觉是：它们似乎真正掌握了语言的本质。我不确定我们需要将它们扩展多少，也许从现在开始，更需要的是 **RL**（Reinforcement Learning: 强化学习，一种通过试错和奖励来学习的机器学习方法）以及其他一些东西。

### 模型规模与效率的权衡
也许我们已经接近了。我记得 2020 年时，我认为我们可以进一步扩展。但我现在想知道，是继续扩展更有效，还是开始添加其他目标，比如强化学习？我曾以为，如果像 2020 年那样，在预训练之后进行大量的强化学习，那将是前进的方向，并且继续扩展会奏效。但这是最好的路径吗？我不知道，它就是这样不断发展。

### 模型规模与生物大脑的对比
我曾以为它已经理解了语言的很多本质，但后来发现还有很长的路要走。与人脑相比，模型可能只有两到三个 **orders of magnitude**（数量级: 表示事物规模或大小的指数级差异，例如 10 的 n 次方）那么小，如果与 **synapses**（神经突触: 神经元之间传递信号的连接点，是构成神经网络的基础）的数量相比。但同时，它们接受的训练数据却是人脑在 18 岁前接触到的词汇量的三到四倍甚至更多。我们不得不承认，这是一个奇怪且不匹配的现象。

### 生物类比的局限性
你知道，这也是我有点怀疑生物类比的原因之一。五六年前我还在考虑这些，但现在我们有了这些模型作为实际的产物，感觉几乎所有来自那方面的证据都被我们所见的事实所掩盖了。我们看到的是，模型比人脑小得多，却能做很多与人类相同的事情，但又矛盾地需要更多的数据。

### 能力衡量而非类比
所以，也许我们会发现一些能让一切变得高效的东西，或者也许我们会理解为什么会出现这种差异。但归根结底，我认为这并不重要。如果我们继续按当前方式扩展，我认为目前更相关的是衡量模型的能力，看看它们与人类的差距有多大，而对我来说，它们似乎并没有差得很远。

### AI 的知识记忆与发现能力
你如何看待这些模型基本上记住了整个人类知识的 **Corpus of human knowledge**（人类知识语料库: 指人类积累的全部知识的总和）？据我所知，它们还没有能够做出任何一个导致发现的新连接。然而，如果一个智力中等的人拥有这么多知识，他们可能会注意到“哦，这件事导致了这种症状，另一件事也导致了这种症状，这里就有治疗方法”。我们难道不应该期待这样的事情发生吗？

### 创造力与新连接
我不确定。我认为，像“发现”和“创造力”这样的词语，是我学到的教训之一，在庞大的计算总量中，这些概念往往变得模糊、难以捉摸且难以追踪。但我认为这里确实有些东西：我认为模型确实展现了一种 **ordinary creativity**（普通创造力: 指模仿、组合现有元素或进行常规性创新的能力，而非突破性或颠覆性创造）。再次强调，比如写一首科马克·麦卡锡或芭比风格的十四行诗，这其中确实包含一定的创造力。我认为它们确实能够建立普通人会建立的那种新连接。**模型展现普通创造力**。

### 科学发现的要素
我同意你说的，还没有出现像“重大科学发现”那样的事情。我认为这是模型技能水平尚未足够高，但随着扩展会发生改变的混合结果。我确实认为有一个有趣的观点是，模型拥有一个优势，那就是它们比我们知道得多。你觉得它们是否应该已经拥有优势了？即使它们的技能水平还不够高，也许这就是你的意思？我对此没有答案。但它似乎确实是，记忆事实和建立联系是模型领先的领域。我确实认为，也许你需要这些联系，并且需要相当高的技能水平。我确实认为，尤其是在 **biology**（生物学）领域，无论好坏，生物学的复杂性在于，当前模型现在知道很多事情，而这就是你需要做出发现和进行推断的。

### AI 的知识与技能差距
这不像 **physics**（物理学），你需要思考并想出一个公式。在生物学中，你需要了解很多事情。所以，我认为模型确实知道很多事情，但它们的技能水平还不够高，无法将这些知识整合起来。我认为它们正处于能够整合这些知识的临界点。**AI 处于整合知识的临界点**。