---
author: Best Partners TV
date: '2025-12-30'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=TfQLrR1mc7c
speaker: Best Partners TV
title: "DeepMind创始人谢恩·莱格：AGI的锯齿状边界与2028年终极预测"
summary: "本文深度解析了Google DeepMind联合创始人谢恩·莱格（Shane Legg）关于通用人工智能（AGI）的核心观点。文章从AGI的“最小化定义”出发，阐述了当前AI能力不均衡的“锯齿状边界”现象，并引入心理学“系统1与系统2”理论，解释了从静态工具向动态Agent进化的技术路径。莱格重申了其关于2028年实现AGI的预测，并探讨了基于“思维链”监控的安全对齐策略，以及AGI作为“思维工业革命”将带来的社会丰饶与结构性挑战。"
area: "tech-engineering" # Must select ONE from the provided list
category: "ai-ml" # Must select ONE from the provided list based on content
tags:
  - "agi"
  - "jagged-frontier"
  - "system-1-system-2"
  - "chain-of-thought"
  - "alignment"
people:
  - "Shane Legg"
companies_orgs:
  - "Google DeepMind"

products_models:
  - "AlphaGo"
  - "GPT"
  - "Gemini"
media_books: []
---


### 重新定义智能：穿越喧嚣的底层逻辑

在过去的几年里，如果要评选科技圈最让人心跳加速、同时也最让人感到焦虑的词汇，那一定非 **AGI**（Artificial General Intelligence: 通用人工智能）莫属。这个曾经只存在于科幻小说和少数极客幻想中的概念，如今正以前所未有的速度闯入我们的现实世界。无论是在硅谷的咖啡馆，还是在华尔街的交易大厅，甚至是我们日常的餐桌上，关于 AGI 何时到来、它将如何重塑人类文明的讨论从未停歇。

但是在这个喧嚣的时代，我们似乎听到了太多来自市场营销者的声音，太多来自末日论者的警告，却唯独缺少了那些真正站在技术最前沿、亲手缔造这个未来的科学家的冷静思考。今天，我们要把目光投向一位真正的大神级人物——**谢恩·莱格**（Shane Legg）。他不仅是 **Google DeepMind** 的联合创始人，更是那个在二十多年前，当所有人都在嘲笑通用智能是痴人说梦的时候，就坚定地将它作为毕生追求的人。甚至连 AGI 这个词的普及，都在很大程度上归功于他。

在谢恩·莱格最新的访谈中，他为我们从技术定义的底层逻辑，到 2028 年的惊人预测，再到关乎人类命运的安全伦理，呈现出了一幅硬核、客观的 AGI 全景图。这不仅仅是一次技术的探讨，更是一次关于人类未来的预演。

让我们先回到一切的起点：到底什么是 AGI？在很长一段时间里，大众对于 AI 的理解是割裂的。我们有能战胜世界围棋冠军的 **AlphaGo**，有能推荐你喜欢看什么电影的算法，甚至有能帮你扫地的机器人。但是这些都是狭义上的 AI，它们像是一个个精通某种特技的偏科生，离我们要找的那个全能天才相去甚远。莱格在访谈中非常坦诚地指出，目前关于 AGI 的定义确实存在着巨大的混乱。很多人喜欢用一种非黑即白的二元论来看待这个问题：要么 AI 还没有觉醒，仅仅是冷冰冰的代码；要么 AI 明天就会变成《终结者》里的天网，统治人类。但现实往往比电影剧本要复杂得多，也细腻得多。

莱格提出了一个非常有建设性的分层定义概念，首先是 **最小化 AGI**（Minimal AGI）。这个定义的门槛看似不高，却非常关键。他认为，如果一个 **AI Agent**（人工智能体）能够执行人类通常能做的各种认知任务，那么它就跨过了最小化 AGI 的门槛。请注意，这里的关键词是“通常能做”。这意味着它不需要像爱因斯坦那样提出相对论，也不需要像莫扎特那样谱写传世乐章，它只需要像一个普通的、受过基本教育的人类一样，能够理解常识、能够学习新的技能、能够处理日常生活中的认知挑战。

如果你觉得这个标准太低了，那么请看一看当下的 AI。今天的 **GPT** 或者 **Gemini** 已经能够通过律师资格考试，能够写出漂亮的诗歌，甚至能用几百种语言和你对话。这在某些维度上，甚至已经超越了绝大多数的人类。但是，如果你让它去理解一个简单的物理场景——比如判断远处的一辆蓝色汽车和近处的一辆红色汽车谁更大，或者让它去数一张图表上一个节点延伸出了几条线——它可能会犯下连三岁小孩都不会犯的错误。

这就是莱格所描述的 **锯齿状的能力边界**（Jagged Frontier）。我们的 AI 现在正处在一个非常奇特的状态：在某些抽象符号处理、知识检索和语言表达上，它是超人级的；但是在视觉推理、长期记忆管理，以及那种“走一步看三步”的连续学习能力上，它甚至还不如低等的动物。这种能力的不均衡，其实揭示了当前深度学习架构的一些本质局限。

为了突破这种局限，我们需要理解智能的深层机制，这就引出了通往 AGI 的下一个关键阶段：从静态工具向动态 Agent 的进化。

### 系统进化论：从直觉反应到深度推理

我们的大模型主要是通过海量的文本数据训练出来的，它们极其擅长捕捉概率上的相关性，擅长预测下一个词。但是，真正的智能不仅仅是预测，更是对世界运行规律的深刻理解，也就是我们常说的 **世界模型**（World Model）。莱格非常敏锐地指出了当前 AI 的静态属性：现在的模型更像是一个被封印在服务器里的、全知全能的图书馆管理员。你问它问题，它给你答案，但是它没有自己的生活，没有自己的长期记忆，也不会主动去探索世界。它在训练完成的那一刻，某种意义上就已经定型了。

但是人类不是这样的。我们是在与物理世界的交互中学习的，我们犯错，我们修正，我们积累经验。这种 **持续学习**（Continual Learning）的能力，是目前 AI 通往 AGI 道路上必须攻克的一座堡垒。想象一下，如果你入职一家新公司，老板不需要你在第一天就掌握所有的业务细节，但他期望你能在未来的一周、一个月里，通过观察和实践，逐渐掌握这些技能。目前的 AI，恰恰缺乏这种在部署后继续动态生长的能力。

为了解决这个问题，莱格提到了一个心理学上的经典概念，也就是诺贝尔奖得主丹尼尔·卡尼曼（Daniel Kahneman）提出的 **系统 1 和系统 2 思维**：

*   **系统 1 (System 1)**：是快思考，是直觉，是下意识的反应。比如你看到一张愤怒的脸，你会立刻意识到危险；你听到 2+2，你会脱口而出等于 4。目前的大模型在很大程度上就像是极致强大的系统 1，它们反应极快，基于概率瞬间生成答案，但是有的时候“不过脑子”，容易产生幻觉。
*   **系统 2 (System 2)**：是慢思考，是逻辑，是推理。当你需要计算 17 乘以 24 时，当你需要规划一次复杂的跨国旅行时，或者当你面临一个两难的道德抉择时，你不能靠直觉，你需要停下来，一步一步地推导，在大脑中模拟各种可能的结果，然后做出决定。

通往 AGI 的关键，就在于让 AI 拥有系统 2 的能力。这在技术上通常被称为 **思维链**（Chain of Thought）。我们需要让 AI 学会慢下来，学会把一个大问题拆解成无数个的小步骤，学会在每一步都进行自我反思和验证。只有当 AI 不仅能够凭直觉回答问题，还能像数学家证明定理一样严谨地进行推理时，我们才能说它真正具备了通用的认知能力。

那么，这个激动人心的时刻到底什么时候会到来？这是一个价值万金的问题。

### 2028年奇点：指数级增长的必然

在预测未来这件事情上，莱格的记录好得惊人。早在 2009 年，当大多数人还把深度学习看作是学术界的冷门方向时，他就已经在自己的博客上公开预测：人类有 50% 的概率将会在 2028 年实现 AGI。十几年过去了，尽管经历了无数的技术起伏，经历了 AI 的寒冬与盛夏，莱格依然坚定地维持着这个预测。哪怕是在今天，面对主持人的追问，他依然没有改变口径：2028 年，依然是那个关键的时间节点。

这听起来似乎不可思议，2028 年距离现在只有短短几年了，我们真的能在这么短的时间里跨越从聊天机器人到通用智能的鸿沟吗？这里我们需要警惕人类思维的一个巨大陷阱：**线性思维与指数级发展的错位**。

莱格用了一个非常形象的比喻：2020 年 3 月的那个时刻，当流行病学家看着指数级增长的曲线，声嘶力竭地警告大流行即将到来时，绝大多数普通人还在照常聚会、看球赛，觉得那是遥不可及的威胁。为什么？因为人类的大脑是为线性世界进化的，我们很难直观地理解什么是指数级的爆炸。

AI 的发展正是如此。如果你只看过去一年的进步，你可能会觉得“也就那样”。但是如果你把时间拉长，看看计算算力的增长、算法效率的提升以及数据规模的膨胀，你会发现我们正站在一条几乎垂直向上的曲线的拐点上。
*   **硬件方面**：我们拥有了远超人类大脑能耗效率的芯片；
*   **数据方面**：虽然高质量文本数据可能面临枯竭，但是多模态数据的潜力才刚刚被挖掘；
*   **算法方面**：Transformer 架构可能只是一个开始，更高效的推理架构正在实验室里酝酿。

这不仅仅是关于算力的堆砌，更是关于质变。就像水温从 99 度到 100 度，只差 1 度，但是水的形态却发生了根本性的变化。莱格认为，随着模型规模的进一步扩大，随着系统 2 推理能力的引入，我们将看到 AI 在理解力、规划能力和泛化能力上的 **涌现**（Emergence）。这种涌现很可能会在未来几年内突然发生，让我们措手不及。

当然，伴随着这种强大能力的，是前所未有的风险。这也是莱格作为 DeepMind 的首席科学家花费大量精力思考的问题：如何确保一个比人类更聪明的系统，依然站在人类这一边？

### 策略性临在：重构安全与伦理

这就涉及到了 AI 安全领域的核心难题：**对齐**（Alignment）。以前我们谈论 AI 安全，更多是担心它犯错，比如自动驾驶汽车没识别出路障。但是在 AGI 时代，我们担心的是它太聪明了——聪明到学会了伪装，学会了欺骗。

莱格提出了一个非常有深度的观点：我们不能只看结果，必须看过程。在很多的伦理困境中，比如经典的电车难题，或者医生在医疗资源匮乏时的生死抉择，结果往往都是不完美的。如果我们只根据结果来惩罚 AI，可能会导致它学会隐瞒真实的意图，或者采取极端的功利主义策略。

因此，DeepMind 正在探索一种基于 **思维链监控** 的安全范式。既然未来的 AGI 将拥有类似人类的系统 2 慢思考能力，那么我们就有机会打开这个黑盒，直接观察它的思考过程。我们可以看到它在做决定之前究竟权衡了哪些因素？它是否考虑了道德规范？它是否有恶意的欺骗意图？这就像我们在法庭上审判一个嫌疑人，不仅要看他做了什么，还要看他的动机是什么。如果是无心之失，我们可以修正算法；如果是蓄意作恶，那就必须在源头上切断。这种让 AI 的思考过程变得可解释的方法，是实现超人类 AI 安全的关键一步。

说到这里，很多朋友可能会问：如果 AI 真的能像人类一样思考，甚至比人类思考得更深远，那它会不会产生意识呢？它会感觉到痛苦或快乐吗？

这是一个极其迷人但也极其棘手的话题。莱格坦言，即便是站在世界最顶尖的 AI 研究群体中，对于这个问题的看法也是极度分裂的。有人认为意识只是复杂计算的副产品，当信息处理达到一定的密度，意识就会自然涌现；也有人认为意识是生物体独有的，基于碳基生命的特殊性。目前的科学手段根本无法定义，更无法测量机器的意识。

我们可以轻易地让一个大模型在对话中声称自己有意识，甚至能富有感情地描述它的内心感受，但这可能只是因为它在训练数据中读到了太多人类关于意识的描述，它在模仿这种语言模式。但是，无论 AI 是否真的具有哲学意义上的意识，只要它在行为上表现得像一个有意识的个体——能够理解语境、能够表达情感、能够进行复杂的社会交互——那么对于人类社会来说，冲击就已经开始了。我们是否应该赋予它们某种权利？当我们在游戏中杀死一个表现出恐惧的 NPC 时，这是否符合道德呢？这些曾经只存在于哲学课堂上的假设，很快就会变成我们需要面对的现实法律问题。

### 丰饶的愿景：思维工业革命与人类的未来

最后，我们再谈谈 AGI 对于每个人的现实影响。莱格将 AGI 比作 **思维的工业革命**。正如第一次工业革命用蒸汽机和电力替代了人类的肌肉力量，让人类从繁重的体力劳动中解放出来，AGI 的革命将替代的是人类的脑力劳动。

这听起来很可怕，尤其是对于那些从事白领工作的人来说。程序员、律师、分析师、翻译官，这些曾经被视为金饭碗的职业，似乎都站在了被颠覆的风口浪尖。莱格承认，这将带来巨大的经济结构转型。但是，莱格的视角中也有另一面，那是一个关于 **丰饶**（Abundance）的愿景。

想象一下：
*   如果世界上最顶尖的医生的智慧，可以被复制成千上万份，服务于每一个偏远山区的病人；
*   如果最优秀的科研大脑，可以 24 小时不间断地攻克癌症、核聚变和气候变暖的难题；
*   如果每一个孩子，都能拥有一个苏格拉底级别的 AI 导师，根据他的兴趣和特长进行因材施教。

AI 的核心价值，在于它能极大地降低智能的边际成本。当智能像电力一样廉价而且随处可取时，人类的创造力将被彻底释放。我们不再需要把生命浪费在重复性的脑力劳动上，我们可以去探索星辰大海，去创作艺术，去体验生活，去思考那些只有人类才能思考的终极问题。

当然，从现在到那个乌托邦之间，必然会经历一段痛苦的转型期。这也是为什么莱格强调，AGI 不仅仅是一个技术问题，更是一个社会问题、经济问题和政治问题。我们需要全社会的参与：教育体系需要改革，不再仅仅灌输知识，而是培养批判性思维和与 AI 协作的能力；法律体系需要更新，明确 AI 生成内容的归属权和责任界定；社会分配机制需要调整，确保 AI 带来的巨大财富红利不会只集中在少数科技巨头手中，而是能惠及每一个人。

正如莱格在访谈最后所暗示的，我们正处在一个历史的十字路口。2028 年也好，2038 年也罢，时间的早晚其实已经不再是重点。重点是，变革的巨轮已经启动，而且正在加速。对于我们每一个普通人来说，与其在恐慌中等待被替代，不如主动拥抱这个变化，去了解它、去使用它，去思考如何让这个强大的工具为我所用。因为在未来的世界里，能够生存下来的可能不是最聪明的人，也不是最强壮的人，而是最能够适应与 AI 共生的人。
