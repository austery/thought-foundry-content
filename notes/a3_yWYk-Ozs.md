---
area: "finance-wealth"
category: finance
companies_orgs:
- Polymarket
date: '2025-11-11'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- X
- THREAD
products_models:
- DeepSeek
- Gemini
- Claude
- Grok
- ChatGPT
- 通义千问
project: []
series: ''
source: https://www.youtube.com/watch?v=a3_yWYk-Ozs
speaker: 人民公園說AI
status: evergreen
summary: 本文深入探讨了一场由美国实验室nof1在Polymarket平台发起的六大AI模型炒币竞赛。主持人与嘉宾老修详细分析了此次比赛的局限性，包括短周期、缺乏实时场外信息及模型记忆缺陷，并指出这些因素导致模型表现出类似人类散户的“不稳定性”。文章随后讨论了当前利用AI进行量化交易的最佳时机，强调了中国开源模型DeepSeek和通义千问在数据处理基本功上的优势，并展望了AI在金融市场中策略涌现的潜力与挑战，以及未来AI与AI对抗、监管的重要性。
tags:
- ai-competition
- llm
- market-strategy
- model
- open-source-ai
title: AI模型炒币大比拼：中国开源模型表现亮眼，量化交易的未来走向何方？
---
### AI模型炒币大比拼：一场“不稳定性稳定”的实验

主持人: 现在的模型，如果真的把所有条件都打开，它能不能直接进入股市？我觉得至少它的不稳定性是稳定的。我们经常说“一顿操作猛如虎，其实输出二百五”。这次的六个模型各有特色，大家会试图把它带入“原生家庭”进行解读。例如，**DeepSeek**（中国开源大模型，以其量化基因背景而闻名）之所以火，是因为它背后有量化的基因在里面。**Gemini**（谷歌开发的多模态大模型）则更像散户，操作超级多，很焦虑，几天交易几十次，结果亏得最多。我认为在现在这个时间点，反倒是用模型去炒股、做**量化**（Quantitative Trading: 利用数学模型和计算机程序进行交易的策略）的最佳时机。

老修: 对我来说，最吸引人的是看他们怎么“掉链子”。因为我日常编程，哪怕我们自己做一个新闻产品，也天天看AI掉链子。这些最顶级的AI，其实掉链子率非常高。很多时候，你感觉调教都没问题，但大部分时候都会出问题。所以我特别关注他们掉链子的情况。

主持人: 咱们稍微介绍一下背景。这是一个美国实验室，叫做**nof1**（美国一个专注于AI实验的实验室），在**Polymarket**（一个基于区块链的预测市场平台）上做的一个实验。它用了六个最知名的模型，美国四个，中国两个。中国两个都是开源模型：**DeepSeek**和**通义千问**（Qwen: 阿里巴巴开发的开源大模型）。美国四个是**ChatGPT**（OpenAI开发的大型语言模型）、**Gemini**、**Claude**（Anthropic开发的大型语言模型）和**Grok**（Elon Musk的xAI公司开发的大模型）。

### 拟人化策略与实验规则的深层解读

主持人: 这六个模型各有特色。在整个交易过程中，大家希望给它做成拟人化的描述。DeepSeek之所以火，是因为它背后有**幻方**（中国顶尖的量化投资公司之一）的量化基因。通义千问则被描述为“经过大A股残酷训练场养出来的能力”。Gemini和Claude则被认为是学究型的。这些描述都无可厚非，为了写文章吸引大家注意。但其实分析数据的时候特别有意思。

主持人: 我们先得对规则有一些简单了解。首先，大家都是1万块钱起步，交易的是虚拟币，包括比特币、以太坊等。交易是线上直接进行的，但不能高频交易，且必须使用同样的**Prompt**（提示词: 给AI模型的指令或输入）。最重要的一点，很多人介绍时忽略了，就是所有模型都不能接入实时数据，不能获取实时新闻，除了交易数据以外的东西。它就是纯数据序列，纯数字的东西，没有其他场外信息。

主持人: 它标榜的是给模型提供一个真实的测试，所谓对比的是之前像**MMLU**（Massive Multitask Language Understanding: 衡量AI模型多任务理解能力的基准测试）这些刷榜行为。但这些模型在真实世界中能不能赚钱？我个人看，我觉得这一点都不真实。虽然操作看起来很真实，规则定得很清楚，不干预，模型也不调优，连续17天等等。

### 实验“真实性”的脆弱与局限

主持人: 老修，我先说我的观点。这里面有几件事。首先，17天并不能真实反映出什么能力来。对于金融交易来说，不可能只做17天。所以，一个阶段性的输赢，很难反映出真实的水平。第二点，它不能直接接入场外信息。但真正的交易员或真正的市场是瞬息万变的，场外信息本身就是构成市场波动的一个重大条件。第三，这些模型本身有没有做到长期记忆？我看到有分析说，像ChatGPT或者Gemini，它并不记得之前自己交易的结论是什么。

老修: 对的，对的。

主持人: 这就变成了所有的决策都是当下决策，只是纯粹考量模型的算力。但它又不能基于足够的信息去做计算，这就不真实了。更重要的一个信息是，没有补仓。就1万块钱，这相当于什么概念？就像玩德州扑克，如果我的后手够深，我只要做得不错，长期下来总体盈利水平会很高。但像ChatGPT和Gemini，都属于前几天就直接输了一底料，后面就没本了。

老修: 对，当然了，这个咱不能往后跑。我只强调说这个测试本身，它所谓的真实是画引号的。我觉得这很重要的，叫做脆弱性。它整个比赛的设计就脆弱了，特别容易一个小的失误，导致一个模型已经可能很难翻身了。

主持人: 没错。我突然想到一个比喻，这很像大家去跑马拉松，结果中间不给你补给水的点。你出去就从头跑到尾，中间就一堆人围着你拍，也不给你递毛巾，也不给你递水。

老修: 因为你真的没，就刚才说的没有记忆这件事情就很惨。你自己做过什么规划，你自己都不记得，那你到执行的时候，突然触发说现在要按这个执行。它其实这里面有几个典型的那个问题，就很崩溃。这个记忆不行的话，它就会出现说，它自己真的到了要执行那个**止盈点**（Take-profit point: 预设的盈利目标，达到后平仓以锁定利润）或者**止亏点**（Stop-loss point: 预设的亏损上限，达到后平仓以限制损失）的时候，它其实会很犹豫。这个方案好像为什么这么搞？现在最新的数据好像有点冲突，但是它又不知道以前的结果是为什么，因为它没有那个长的记忆，它只有短记忆。你们就相当于就是那个**长上下文**（Long Context: AI模型能够处理和理解的更长篇幅的文本信息）没有，然后又没有做笔记的地方。这两个东西都要有。因为长上下文只是我们相当于思考的脑子，马上思考的时候去结算，那个窗口本来就不够大，然后旁边又不让做小抄。这个小抄它又有问题。那这样子它在真正计算那个，我们就说，我们买卖人最重要的是我买卖的那个点是不是要算清楚，然后就该执行嘛。结果它那个点的时候它算不清楚。这个包括一些算数也会出错。我们知道大模型其实算数很差，因为它不是存模型。

老修: 所以这就直接出现了很多自我矛盾的规则。它就会出现博弈。包括说它自己其实有的时候还会出现那种想要做一些欺骗行为，试图利用规则，绕过规则去尝试这个事。这种时候它就会在，因为我们知道做交易的时候，你这个要是在那边犹豫，那可能那个操作一下就过了，就不行了。那它这里面就会出现，有的时候它反复验证，然后直接错过了交易点，整个策略就失效了。这就是一个很明显的一个，就是你最多综合看得起来，但是综合的问题，其实有两个很基本的问题，真的基本的不能再基本的，你可能想象想象不出来。这个我经常碰到，我们自己实际做产品经常碰到。

老修: 第一个你真的想象不出来，就是你跟他说数据这个从最新到最旧，顺序排列是倒序的，从上到下这样给你。然后它理解的时候，其实由于格式，它们对格式其实高度的敏感。对刚才不是说是给他们格式嘛，但其实不同模型对于格式的理解能力是有差别的。你可能想象不到，OpenAI为了处理一个我们工程上常用的那个JSON这个格式，差不多花了三四个月左右时间，才能让大模型准确地去处理这个格式。那其实还有很多种格式，数据量大的时候还容易出错。就是我就算这一次能做对，但是我做99次可能会失败两三次。那你想一下它这个里面的那个错误，其实它们的执行次数是很多的。这个里面你可以想象到有很多次，可能这个数据就，就我看有实际的报道，就是说它有非好多个模型都有多次把最新读成最旧，然后把最旧读成最新，这么反正前后都倒反了。那你说这个决策能对吗？就是相当于数据，我们说一个人做数据的时候，做决策的时候，你基本的那个上下文数据都是错的，或者就是数据是对的，你理解又理解错了。

老修: 然后还有一个苦逼的事情是什么？就是叫做术语模糊性的问题。就是你里面不是有专业的术语吗？比如说可用现金，自由抵押品。这些东西，可能就是如果你不是很专业的人，其实看起来就已经不太懂了。那它模型其实跟人是类似的，尤其是原模型吧。原模型出现它有些没微调，它可能知识太多了。它知识里面有可能可用性现金可能都有好几种说法，然后自由抵押品也有好几种说法。它到时候真的决策的时候，它可能只会在当时情况选了一个它觉得概率最高的东西去拼了一下。然后那几个定义可能有的不一样。那最后它就难以采取一个正确的那个行为，或者是错，或者根本采取不了行为，它觉得这个无法判断，那它又又错过了。所以我们刚才说到最后，它已经反复计算的还有什么东西，就已经很苦逼了。然后反复计算的时候，原数据还是错的，或者是数据是对的，它还理解又错了。那其实这里面的那个，基本上，它这个整个的脆弱性是非常强的。

### AI的“人性”与中国开源模型的崛起

主持人: 通过刚才这个描述，你不觉得这种操盘或者这种操作真的很像人吗？就很像普通人的操作，自己号称自己有个策略，在真正做决策的时候，数据量不够，或者甚至说对一些概念模模糊不清的理解，或者说我都已经忘了我之前策略是怎么想到要做这件事，到真正执行的时候发现我靠还是凭感觉吧。

老修: 对，不是这挺经常的嘛。

主持人: 所以我就说当时那个什么嘛，我看评论里最搞笑，就说嘛说这个啊，这么证明还是GPT最像人。真正的AI，就是输的最惨的那个，最像散户的，大家一下就共情了。反倒是这个中国两个大模型，一个DeepSeek，一个千问。DeepSeek尤其在前几天的时候，一路绝尘，甚至说回报率都已经超过100%了。要不是后来市场震荡确实频繁，由于它的策略，它应该是真的能一直保持比较高的领先优势的。结果后来被千问给，因为千问大量持仓比特币，然后直接就翻身了，有一天时间翻身，然后有一天时间又翻回来，最后还是保持领先。

主持人: 从策略上来讲，如果说我们真的去分析它的策略的话，它确实每个策略代表的都是不同的一个思路。尤其是像DeepSeek，它执行得非常晚，非常严肃，真的就像一个真正在长期在市场中交易员似的。首先分散持币，然后低杠杆，再保持策略的绝对性，执行的绝对性等等。但是我觉得我们不用讨论这些东西，这些东西毕竟只是十几天的一个行为，而且太小了，不具备统计学上的样本价值。

老修: 没错，而且这里就是这个东西秀场的更大，就是跟我们国内，我记得我们国内搞了好几把那个机器人格斗啊，机器人马拉松什么的，都都是秀的，你实际上这些都没有用。

主持人: 对实战我觉得真的完全是这样。就是说真的去再去复习它的策略或者什么，我觉得这东西就有点不靠谱。就是你真的是在一个很小样本的事情上，非要分析出来一个普遍性的普世的一个价值，我觉得是没有的。但是本身你觉得就是咱们完全抛开所有假设，再说你觉得现在的模型，如果真的把它所有条件都打开，微调做好之后，它能不能直接进入股市，或者说进入这种量化市场去做操作？

老修: 我是觉得你让他去操作还肯定还太远，但我觉得说它辅助你做一些操作，应该是很合适的。我们肯定有一个很硬伤的问题，就是人看资料太慢了。我知道我有一个策略，但是我其实这个策略要很多数据，我要去抓的话，我自己是很费劲的。但这个东西其实你用AI去有调教的AI去帮你处理，我觉得是会很好。就比如说我对某个策略是特别的坚定，我要做这个做空还是要做哪个，哪个东西好的，怎么做。然后里面但是要要抓好多数据来分析，但是我我这个东西就是，其实我人类就是有明显的局限嘛，你给我这个数据，确实你能给到我这个方面的数据，但我看不过来，我分析不过来。像这些的话，其实如果有是AI去辅助，我是觉得是是完全是肯定是有帮助的。但是你让他完全像他这样子，完全没有人类干预的去去跑，我觉得就是可靠性实在太低了。因为都不要说他这样跑，就我们普通的一个小的小的程序，做做新闻处理而已的这种小工具，它的那个可靠性都已经很低了。其实我们就是一周之内发生个10%到20%的事故，都经常发生。你说它这个这么高频的，我是觉得说是肯定远远不到这个这个它能独立去去炒股，还能够你指着它很稳定，这个我觉得是绝对没有的。就是稳定性这一块是绝对不行的。

老修: 他可能有的时候行，但是你不是，就像就是说有行的时候，你可能很难归结于是他能力行，可能就是正好，可能就是市场好，然后你的策略刚好有一个，就是碰上，就是运气成分比较大一点。我觉得是这样子的。因为就是说，比如这我还是像刚开始讲的，就是这几家，我说它的不稳定性是稳定的。就是从他们的那个规划，从他们的那个整个的那个钱的那个波动情况来上，我是说他们其实不会出现什么第一名突然变最后一名，这种其实时间跑得越长，越越不会出现这种事情。基本上就是只是前后两位在有点换位而已。然后那个就是他因为他们的不稳定性，其实是相对稳定的。他们其实本质都是概率模型，它就算调优到非常好，它也只是取一个最大概率，它不是100%。它跟我们以前的硬编码的那个是完全不一样的。但这这恰恰是它智能的部分，就是如果是编码死了，它就不智能了。

老修: 对，它它就我们之前最近不是讲卡帕西或讲很多人都讲的是这个，其实你遗忘，就是你忘记掉一些规则，或者忘记掉一些知识，这恰恰是智能的表现。它知道要把哪些东西扔掉。其实现在最近已经开始有一些比较智能的模型，已经就就已经出来了，就是它会遗忘你训练过的东西，预训练的东西都会忘，你知道吧？现在已经有这样子的这个模型出现了，就是大家正在尝试这种增加遗忘，增加它不记得更多的东西，然后让它更智能。

主持人: 其实这不就是咱们前两期一直在聊的事吗？一个是**压缩**（Compression: 信息处理中减少数据量以保留核心信息的过程），当时说的这个就是我们压缩其实就是模糊，但是最后最终提炼时候，我们提炼的是可能是一个概念，或者也不能叫一个概念，我觉得应该是一种策略，并不是事实本身。然后第二个来讲，上一期咱们聊那个特斯拉的时候，聊到智能驾驶，聊到这个整个的**端到端**（End-to-end: 系统从输入到输出的完整流程，无需人工干预）嘛，然后就聊到**黑盒**（Black Box: 指系统内部运作机制不透明，只能观察输入和输出）这个事。其实就是这样，就说你所谓的智能到底是什么？如果还是以前那种纯编码形式的，模块形式的，所有东西都要先预定义好的，那就不是人工智能。你就不是，我觉得在人工智能就是要有智能的所谓的**涌现**（Emergence: 复杂系统在简单规则下，自发产生出高级、意想不到的特性或行为）。就这个东西，它不是说设计出来的，而是说到数量，就无论是数据还是算法，还是到一定一定阶段之后，涌现出来。

老修: 他有个很直接的问题，就是你如果是预设置，说明他是在模仿人类嘛。这个没错。你模仿是没办法超越的，就这么个事情。很简单，你的天花板永远是你设置模型，或者设置策略，这个人本身是天花板，而不是这个模，而不是人工智能的天花板，而不是AI的天花板。

### AI量化交易：最佳时机与未来挑战

主持人: 我跟你倒持相反概念，相反的结论。我认为在现在这个时间点，反倒是用模型去炒股，去做量化最好的时间点。我首先我先说啊，我自己确实个人个人经历，我参与过量化这个事。量化这个事的话，其实可以分成很多步骤，但我们就说大的块。首先肯定是信息收集嘛，你需要收集数据，尤其是需要有很多历史数据。但是历史数据必须是真实的，它必须有交易和这个交易交易量等等这些东西。就是说你这个历史数据越细越好，颗粒度越高越好，因为你要**回测**（Backtesting: 使用历史数据来测试和验证交易策略的有效性）。你有一个策略之后，你先要过用过去几年的数据做回测，然后来来证明你这个策略是否有效嘛。

主持人: 如果说你做了一个策略，认为是有效的，然后你直接扔进，那你就真真的交学费。你就是可能会运气好，或者说赢一大赢一个大的，然后呢过去再输光，长期再输光。要不然就上就输，就跟这个PPT一样，然后呢再也翻身不了。对但是你必须得有很好的数据。然后第二来讲呢，你得有场内场外信息嘛，就是你得能拿到及时的，而且可能甚至到毫秒级别的，或者说起码到秒级的，这种就是叫市场的交易信息。交易值是多少啊，能接受的盘口，能接受的这个这个吞吐量是多少，等等的这些数据。然后还有什么？还有就是你的**策略**（Strategy: 预先制定的一套行动计划和决策规则）肯定你策略要不断优化嘛。策略其实就是一整套的执行方案，到什么时候止损，止盈点是什么，能接受多少啊，要不要做事等等的一大堆的东西。

主持人: 然后才是执行。在执行层面上其实更惨。很多时候，你所下单的价位，挂单的价位，你根本执行不了，没有机会被触发嘛。就可能就**滑点**（Slippage: 实际成交价格与预期价格之间的差异），直接就甚至说你要做双边市场的话，有可能单边执行了，那边没执行，那就最惨的，你直接留了一个巨大的**敞口**（Exposure: 投资组合中面临潜在损失的风险敞口）。然后你可能就是说这纯粹就裸奔在那，然后等着扛着。但是到了最后，就是这些东西都完了之后，还有一个心理问题。最大的心理问题就是说，当你看赢钱的时候，你可能就会突然就觉得啊，以前策略都不是策略，既然赢我就让他持续赢下去。我是不是要到止盈点上，直接就就就是高位，就就兑现了。还是说，觉得我现在这个时间点判断错了，我要及时调整策略。就像现在咱们说这个什么英伟达一样，人家奔5万亿，那下面可能就是6万亿。可是很多人觉得5万亿就是最高了，不能再得回调了。所以，这个时候心里又是一个很大问题。所以这这个整个量化的过程中，它不是一个简单的就是你定一个策略，到时候就赚钱了，或者说你策略好，就就就值值钱了。不是的策略其实在里面，我觉得是怎么说呢，就不可能占到100%的决定因素。反倒说这个中间有很多步骤。

主持人: 为什么我说现在用模型可能是最好时间点？我有两个自己的看法。第一个来说就是咱们看这个测试，咱们当时举了，咱们刚才就已经列举了很多局限性嘛。但是这些局限性都是可人为可控的。比如说我们模型做微调，对很多定义做得更清楚。对资金的补充，我们可以不定义在就是1万块钱，我们可以顶就说我后面的仓位很深，我可以补仓嘛。特别重要的是你刚才说的场外信息，就实时的给他场外信息。这个实际上就是我们说的模型的那个上下文，是他的那个外挂的知识。这对他决策实在太重要了。而且而这一部分就是印证你刚才说的话，就这部分人人是处理不过来的。因为信息量太大了，然后速度时效性也不够嘛。还有还有什么？还有模型还有学习能力啊。现在就有个例子，就说我看到很多人在干什么事，就大家看热闹。但我看到一些高手在干嘛？在把他们所有的策略给我执行策略全下载下来，而让模型自己分析他的策略，或者交叉测试，然后呢，试图从中间提炼出来有效策略。说句不好听的话，就说我数据量足够大的时候，人是判断不了的。这时候就拼算力，拼模型能力。东西到底能不能从中找到规律？这些事情其实是模型更擅长的呀。你只要让他自我学习，自我迭代，其实有可能就会真的能找到一定的，在一个时间段上找到规律嘛。

老修: 这个事我觉得这有感触了。我知道为什么我突然也感觉你说的这个时候多用这个东西是一个好时间。

主持人: 没错，因为我想到的是另外一个极端，就是当大家都用AI的时候，你可能又很难用了。这这是我后面的话，你先把它说出来了。就是为什么我说现在是最好时间，就是现在用的人还少。甚至很多人觉得这是不可。你会有碾压式的，就跟这个大炮对这个长枪一样。你现在找不出更好的策略来，比如说你人工去操作，也不见得能到20%的回报率的时候，那你用模型也许用用千问，你看这回23%。也许就比你个人操作还牛，牛多了。在这种波动市场上，很多人是输钱的，那模型人家还赚钱，起码人跑出来17天是赚钱的。

主持人: 我说的概念什么？就是说当你能够把模型用好，那肯定前提是你懂什么叫策略，懂什么叫执行，知道怎么去做。然后对场外消息的这个来源和敏感度也有，但是你自己的算力和自己以前的策略不够有效，那你用模型去跑，你不要干扰他，你就让他自己去完善，自己去做。但是如果说所有人都开始用模型了，那这时候模型就失效了。肯定的嘛，就是说所有都是模型，模型可能最终会趋同，因为大家都互相学习，最终可能找到了一个所谓的优秀策略，最优解。那很可能就是大家都赚不到钱，要不然就是同一时点执行同样策略，直接市场闪崩，市场不存在了。那这时候大家全赔个底掉，那这个时候肯定不是用模型最好时间点。所以我反倒觉得就是说，在现在这个时间点上，在大家都会模型产生一个就是犹豫、怀疑和用和不用之间的时候，坚定的用模型的人反倒可能有机会。当然这咱不鼓励任何炒币的行为，我只是从模型本身的这个应用条件和场景来分析这件事。

### 中国开源模型的实力与未来展望

主持人: 所以下一个问题就来了，就说那你觉得就说为什么现在大家对中国的这种开源模型都这么推崇？因为我看到的，在这件事讨论的背后，还链接出很多新的话题来。甚至说有些硅谷投资人现在说，就也不是开玩笑，真真的在说，就说现在很多在硅谷的初创公司在演示PPT的时候，展示的都不再是PPT了，都说背后的模型是千问或者说这个DeepSeek之类的开源模型。同时这次比赛也也跑出这样成绩。而且我看到还有公司马上模仿，开始用AI炒美股，也是中国的模型，包括豆包，包括那个minmax等等，也在上面有排行嘛，也也也排名的比较靠前。你觉得中国的开源模型真的强到这地步了吗？还是说只是偶然现象而已？

老修: 我是觉得说两者都不是。就是应该也不是说它特别强到了那个地步，就是特别适合炒股。然后还有一个也不是说它那个可能现在是运气好什么，就但有一定的这个实力成分在的。我的角度是觉得说很有可能，很有可能是我们刚才我刚才提到的一个，就是叫做那个数据的那个敏感度的问题。所以我会觉得很有可能是DeepSeek和那个千问的数据敏感度的字，那个那个处理能力，也就是基本功，其实这个是一个基本功，会比其他几个闭源的美国那些模型要好。这个原因可能有很多种，也许其中之一，是因为它在早期训练的时候，本身就用到了，确实有很多数据去测。就是比如说就是幻方量化里面原来的一些数据，可能有对它进行很多个数数据的测试，所以它会比较敏感。这部分东西它处理的还可以。那这样至少有很多这种低级的，什么最新最旧啊，然后有一些数据你能读进来不，会不会啊，而且能保证一个高的稳定性，你不会说执行了100次以后，失败了好几次，然后那个决策完全就错了。这个可能是很基础的事情，但是很可能就是因为这么基础的东西，导致你很多决策都都失误。这个这个事情其实我是觉得是有影响的。

老修: 那为什么说DeepSeek有这个优势，为什么千问也有啊？这里其实就是千问到底怎么训练的，我没有做更多的了解。但是我知道我们应该大家都有点印象，就是今年年初的时候，其实DeepSeek刚出的那几个最早的开源版本，就是呃，都是有那个千问是有基于它去改改成几个版本，就是小的参数版本，都是钱文最早去搞的。所以我是觉得在那个时期，其实就像这种基本功，实际上是应该是已经是融入进来了的。我觉得是这样子的。在那个时候，应该这种对数据的基本功，应该就是进来的。那这种这种基本功，在后面实际上是还会更多的会强化的。因为随着你后面的更新的一些数据，啊还有各种那些东西进来以后，这些东西只要大家平时有这个基线，它会不断的去，就我们说是回归测试啊，和各种各样的测试，会测这个部分。觉得这可能作为我们中国模型最基本的一个基本功，有可能会练得很好。某种程度也许如果又类比人，就像我们中国的学数学都比较扎实一点，因为我们基础教育整天都在教这些。然后其实我们在正常训练的时候，我猜就是不管说是不是幻方，就是可能就是本身中国数据很多数据的处理，都是还是会还是不错的。对然后这个可能算是一个我觉得是基本功的点。

老修: 然后后面就是到了市场里面，那个我就我觉得是很难评价到底是怎么回事。但是就是我我觉得至少它在处理原数据上如果有优势，这个成功率如果我比你高百分之，这个有的时候，可能不是高10%和20%的差别，而是0和1的关系。就是我到底决定投还是不投，可能就是因为一个数字算错了，或者我这个数字根本没读进来。因为可能一个格式我我不认得，或者我因为我不稳定，我没有读进来。那我这个角色可能就完全不一样，你觉得要上，我觉得不上。那如果我在这里基本上是不出差错，就是我们孙子兵法里面经常讲的那句原话忘了，大概但是他的意思就是说，其实胜利不在对方，而在自己。如果你自己不犯错，你大多数时候等著别人犯错，你最后就赢了。那讲的就是这个事情。那我觉得说它其实就是基本上这部分应该算是做的还可以。然后在股市这边的话，由于这一点，有可能它的胜率就会高一些。但是其他的方面我们不知道，真的真正的就因为这次的局限性太大了吗？其实实时数据，各种数据没有进来。当那些东西进来的时候，就好像不是实时数据，是实时的那些场外的新闻，各种各样的信息，它不是纯数据的。到时候进来，肯定是数据跟文字肯定是混合在一起的。那那个时候的考验其实更高。那个时候考验更高，就是你对这个数据跟文字混合处理的时候，情况怎么样，包括小程序，包括对对对一些交叉信息，互相的干扰。有可能是噪音，也有可能就是就是那什么。

主持人: 因为其实从我看起来，说不定你有更多的信息，它噪音更大，它有可能表现还不如现在。

老修: 对，这这也是这样的。

主持人: 这也是为什么，我其实没错没错。就人也是这样嘛。

老修: 因为这我所以我会觉得说，为什么他这个比赛设计方会设计拿掉了这些实时的这些场外信息，其实某种角度上来讲，拿掉了确实我是觉得从评估上会简单的多。因为你实在说不清楚到底谁影响谁。那如那你现在没有的时候，你还可以说一说模型，说一说这个其他的一些东西啊。大概是这样等。有的时候，其实有时候很难说清楚到底谁的问题。

主持人: 对的，大概是这样。包括就说你像**Grok**（Elon Musk的xAI公司开发的大模型）我就很看好，因为它背后有**X**（前Twitter，埃隆·马斯克旗下的社交媒体平台）的大量的这些数据。而且在上面人的真实性表现比较突出，人性的那一面东西表现多一些。但是就是说如果说真的就是加入这些场外信息之后，真的鹿死谁手还不好说呢。

老修: 所以我觉得会很难说，很没错没错。很难说，尤其是像社交媒体这种东西。其实社交媒体我们才我们我们自己做新闻处理，就会非常深刻的体会到，这个社交媒体的质量是非常差的。就大部分的那个数据是其实都是不可用的，无效信息和错误信息。就是他因为是断章取义的，或者是为了情绪调动，或者是为了一些政治和销售的目的，他跟你讲的一些东西，其实你真的提出来以后，发现这真的是个垃圾信息。但是还是广告，软广告。

主持人: 哎，对他就是很博眼球，他让你很带情绪，让你感觉这个事情好像非干不可，马上干不可，但是其实你真的跟着他去做操作，我估计会死的很惨的。

老修: 然后还有就是X本身也是一个现在其实被很多其他的，比如说他们啊有一些做**THREAD**（Meta公司推出的社交媒体平台，与X竞争）啊等等，就是一些其他平台已经大起来，就是大家不在X上待着。对X本身内容质量也好，那七七八八的一些问题也很多。那其实就是这个社媒也不仅仅是X了，那还有好多呢，还有好多其他的社媒。那你真正在这次这么多设备，不同的数据质量本来就不太高，又合合在一起，然后再加上这个实时性，哇，这个我觉得对大模型的那个计算的，这真的是又要好多地方要要烧冒烟了。然后算出来可能又错过了这个执行点。

主持人: 对对，有可能。所以这个其实又又引发出另外一个话题，就比如说你做量化时候，大家讲叫策略，而不再叫算法。所谓策略就是说你需要做决策嘛。我觉得就是说这件事本身就做测试这件事和当时DeepMind打败围棋，或者说我对这种就是说完全不是一个概念。你想啊就说在棋类比赛中，它叫Game是有非常清晰的规则，而且它是有先后顺序的，你走一步我走一步，你走一步我走一步。这种时候就说它有很强的逻辑性。然后这个时候就说我们只是在玩法上做，就是在规则之内的玩法上做探索。所以当时OK能打出人类没有做过的，就是就神秘之手嘛，神之一手之类的这种东西。但是它不需要有特别多这种这种这种情况就可能赢了比赛。但是真正在量化中那不一样。因为策略是这样，就说你的策略再有效，你也不可能每一次做都做对决策。但你必须要去做决策。而且不是说这时候你在跟什么打，在比赛我觉得他你这时候，虽虽然说是各个模型之间在比赛最终结果，但并不是说所有模型在同一个时间点上同时做决策，然后决策和决策之间做比做比拼更多是什么？是说你要在这个某一个时间点上做出一种选择。这个选择会影响你后面的结果。但但是如果改变了很多条件之后，其实这个选择正不正确都无所谓了。关键是它可持续，关键是它可复现，或者说在同一个条件相似的情况下，它还能做同样决策。我觉得这就是很难很难的。

### AI的黑盒智能与超越人类的可能

主持人: 以前是靠人，你比如说我做量化的时候，是真的找了几个博士，然后有一个所谓科学家，数据科学家专门做带领，然后大家去开发这个东西。然后其实用MATLAB做了很多的算法，然后做了好多的校验，然后又找了去买了很多数据，然后做回做回测。然后呢就看回撤空间是多少，准备钱开始做真正东西。最后OK是赚钱了，但也是是一个时点上，那个后来我听说就是那个团队后面就输了很多钱。因为时间拉长到一定地步之后，策略失效了。但现在来讲的话，就是在模型层面，我觉得这已经不是算法的问题了。那确实是说我需要用模型去做决策，形成策略。算法或者说算力，它可以不断的增加。算法可以不断优化。然后呢算力可以不断增强。但策略，其实我并不觉得是根据时间的长短，或者你使用次数的增加，策略就会变得更好更好更好。这是一个这是没有相关性的。所以这一点上就我想说一点，其实很简单，就是说我觉得人工智能反倒有可能会真的发现好的策略。因为我们现在人工智能是个黑盒，就是它怎么涌现出它现在智力来讲，我们可能人类越来越不明白了，越来越不知道它是怎么样形成这个策略的。但是真的有可能会被他找到一个在人类创造的规则之下，就是金融市场，或者什么股票市场或者什么其他市场，然后我们人类在设计过程中，并没有考虑说这个问题。然后他通过不断的去测试验证之后，哎找到了一个可执行的策略，然后真的就把人类打败了。我觉得这一天到来之后，就真的太有意思了。

老修: 是的是的。我记得我记得当年看的将近20年前，就是当时那个虎胆龙威Die Hard 4里面有一个情节，就说有一帮恐怖分子，他专门劫持了美国的基础设施。然后呢，他就直接把那个华尔街的那个主机给崩溃那个瘫痪了嘛。所以所有数据都丢失了。然后造成了所有的财务分配重新那什么造，就是所谓恐怖主义嘛。就是如果你要是不给我钱，我就把这个东西会盘毁掉，等等全给你毁了。

主持人: 但如真的，如果市场未来用模型的人越来越多，很可能就真的会形成一种这样的合力。甚甚至不是某个人去设计的，就是AI模型自己本身，哎找到了人类的设计的一套东西，玩法里的一个漏洞。然后去执行，因为他的目标是赚更多钱嘛。然后一下子把所有财富都集中起来了。然后最后发现这是一个，这个算法层面的一个一个胜利。这个挺有意思的。看不知道会不会出现这么一天。

老修: 嗯，这个这个现在就是无法预测。但是看起来就是AI跟AI之间很可能会形成一种对抗。这个这个也是好多的这个这个研究嘛。就是现在其实就是说在安全层面，不管怎么做，这个AI都都得有一个就是默认可能得红队蓝队一直做。就是两边互相对抗。那不然的话，可控性确实可能都会是个问题啊。就是现在想现在，比如说现在再怎么样，我们每个AI都是人训练出来的。然后在那个互相，互相之间，他们之间是没有通信的对吧？那这但是如果以后更通畅之后，可能他们自己能够互相之间通信。那他们之间在互相通信的时候，在聊啥有可能人完全看不懂啊。那这个不得受监管。那现在其实有一套的一些监管的一些东西，只是有限的那种交流嘛，没有说到很深的。所以这些东西现在的不确定性是很高的。应该应该来说，只能拭目以待，看后面怎么样了。

主持人: 哎，这也是我期待的嘛。就是说我觉得中国在做模型是追赶还是追赶方嘛。然后天下武功出少林，在GBT真的是一支一绝，神在前面。在那个然后我们期待着他可更好东西。但是如果中国模型不能够说跑出自己的一个特色，当然这回测试感觉到啊，还是确实有差异的啊。各个模型之间确实有巨大差异。要真的就是所有模型最终都是趋向于一家或者两家，很危险非常危险。就像你说的是的，你就必须红队蓝队同时跑。但是你靠一家公司去跑出一个红队一个蓝队来，不太可能。不行，一定是靠不同的公司，对不同的不同的投入，不同的方法去实验才行啊。

老修: 嗯嗯嗯，是这样。

主持人: 哎不过就这回这模型这测试，我觉得有一点他没公布，就是这6个模型最后使用成本是多少？就调用API的成本是多少？这要比较比较一下，可能中国这开模型的价格又又直接领先，就就真的是有巨大优势了。

老修: 对这点是真的没没讲。而且很有意思的是，这次最后千问是夺冠嘛。但其实他一开始在讲这个实验的那个设计上面，他有讲到千问，所有的模型都是开了那个reasoning，就是推理是最大的，就是能配的都配了。那千问好像是由于不知道是什么原因，他没讲，但是他说他没有配到这个最大的推理这个这个选项就大概是这样啊。然后那个有可能是没有这个选项，它默认也许就是比较大的推理，还是怎么样的。所以这里面就是还有一些这种配置啊，各方面的一些东西，有可能还还没配到最最顶级的配置。反正最后也赢了。那就这样子的一些东西，就会让很多人觉得很有意思。但是其实这里也也是一种实验本身的偏差。

主持人: 没错没错。对。而且这个实验本身，其实我认为就组织这个实验方是获利最大的。他们把自己的这个名声给推出来，而且就是引起巨大关注嘛。而且我在那个主页网站上看，他就是About Us那块，就关于他自己介绍了一遍，就是一条招人。就如果你对我们的感兴趣，你来投我们简历吧。

老修: 是的，他也没有什么历史的东西，就这一次比赛，就这么一个事。

主持人: 对。所以我怀疑他背后也是要做量化的，也是也可能就是准备拿模型去搞点赚钱的事。

老修: 搞钱的事。

主持人: 是啊是啊。然后或者就最基本，就是把自己做成一个新的Benchmark嘛。把你自己做成一个新的Benchmark，以后模型要推出来都先找我刷一刷。那这个不一样了。

老修: 没错，我裁判。

主持人: 嗯，我这就做标准。

老修: 对，我来做标准。这个太厉害了。

主持人: 没错，是的是的是的，嗯。行那好那，我们今天就是随便，借着这个这次竞赛这个情况，来简单聊一聊。而且听说后面1.5要开始，Season 1.5又要开始了。然后甚至说未来有会有新的这个测试我们也可以持续关注。但我觉得关注本身就是图一个乐趣。能能够通过一个案例吧，让我们对这些模型有一个更直更直观了解。我更希望就是看到真的有人，大家能靠能靠模型赚到钱。而且也能够看到，就是在你可以看到，这种智能模型和专业模型的区别。我认为就是说像这像TPC这个肯定在就是综合方面还是不如还是要差。对吧？然后像千问什么的，还是有追赶的这个方向。但是在应用层面上，就不见得你怎么能把模型用好。就像你说真的把给你把这个倚天剑，你也不见得比这个人家杨过拿一把，拿一把铁剑打的好，打的好是的对。所以就是谁能把它用好才是关键。现在的AI，我觉得从能力上，已经在各方面溢出了。我所谓溢出，就是对一些日常异常行为的，或者异常的这工作的需求已经溢出了。但是在最顶级的，比如你说像在这种金融市场，这已经算是最顶级了吧。真正能做到金领的，那都是高学历，高智商，高甚至说是高情商的人才能做的。那现在模型已经轻松的开始自己跑起来了，在人为完全不干预的情况之下。那你谁知道哪一天，没准再再过6个月以后，人类这个就不能以智力，就是地球上智力最佳，来命来来来来定义自己了。

老修: 没错，完全就被AI给超越了。是的是的，对。所以非常期待后面的，因为其实这种比赛实际上是很有意思的。就是作为对于我们而言，可以从不同的侧面去看这些这些模型的潜力到底在哪里，或者它的坑在哪里，就挺明显的。就是一场大考。

主持人: 嗯，没错。人类就喜欢看比赛嘛。从那个罗马竞技场的时候，到现在搞奥林匹克，没事就比来比去。然后先拿自己比，然后再拿机械比，再拿再拿动物比。现在来好了，拿AI来比。咱们就拭目以待，看下一场斗，就是这个数数据斗地主，或者叫这个竞技场会成什么情况啊。对。好那今天我们就先到这里。期待大家多留言互动。没错，欢迎大家。搞笑的一期，有点没错。而且一定要关注我们人民说公园说AI。然后呢我们会定不定期的，然后把我们感兴趣的话题跟大家分享。做大家创业路上的BGM。也也祝大家啊，生活愉快，工作愉快，用AI玩的愉快。拜拜，期待下次再见。

老修: 拜拜，拜拜。