---
author: Internet of Bugs
date: '2026-01-08'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=ofdGHCoJSug
speaker: Internet of Bugs
tags:
  - disinformation
  - societal-polarization
  - election-influence
  - personalized-content
  - ai-regulation
title: AI 的真正威胁：操纵心智而非生存危机
summary: 本文指出，生成式AI当前最大的危险并非科幻电影中的生存威胁，而是其操纵个体心智和价值观的能力。通过类比电影《全面回忆》，作者揭示了AI如何通过个性化虚假信息，特别是聊天机器人，加剧社会分裂，影响政治选举，而现有监管措施对此束手无策，预示着一个信息真实性被严重侵蚀的未来。
insight: ''
draft: true
series: ''
category: ai-application
area: tech-engineering
project: []
people: []
companies_orgs:
  - OpenAI
products_models:
  - ChatGPT
media_books:
  - Total Recall
  - Terminator
status: evergreen
---
### AI 的真正威胁：操纵心智而非生存危机

当前，绝大多数生成式AI公司在整体上正在使世界变得更糟，并且事态正朝着比现在严峻得多的方向发展。我曾制作过关于“AI末日论”为何是干扰的视频，也讨论过为何连声誉卓著、本应知情的人士也在推波助澜，宣扬我们需要担忧AI毁灭我们。今天，我将探讨AI真正最大的问题，或者至少是我目前所知的最大问题。我当然希望没有更糟的情况。令人遗憾的是，我所见过的或提议过的任何AI监管措施都无济于事。或许，我能让至少一些人理解我们所处的危险。

简而言之：AI公司和AI末日论者希望我们把AI想象成《终结者》中的天网，但这完全是阿诺德·施瓦辛格电影中的误用。AI不是《终结者》里的机器，而是《全面回忆》里的机器，而生活在这种机器的世界里，简直是……这是个“bug”遍地的互联网。我叫卡尔，自20世纪80年代以来一直是软件专业人士，我正尽我所能，尽我一份力，让互联网成为一个更安全、更少出错的地方。

首先，我想让你们明白的是，到了这个阶段，神灯里的精灵已经不可能再被收回瓶子里了。无论我们做什么，AI都不会消失，我们只能与之共存。对于那些在我的评论区说“所有AI都糟透了”或“直接禁止它”的人，感谢你们的参与，但你们是在浪费时间。即使这个泡沫破裂了，只要那些从生成式AI中获利的人能够利用它让自己变得更富有，它就将成为未来世界事件的一个持续因素。这就引出了《全面回忆》。

顺带一提，我指的是1990年的版本，而不是那个糟糕的新版翻拍。但即使是轻微的剧透，如果你还没看过的话：其前提是存在一种机器，可以向人的大脑植入虚假记忆。因此，好人不知道什么是真实的，什么是被植入的记忆；而那个亿万富翁反派则利用这台机器将他想要的任何想法植入人们的脑海，并在此过程中改变他们的价值观和个性。我不知道这是否开始让你觉得似曾相识了。

### 个性化信息操纵：聊天机器人与社会共识的瓦解

早在生成式AI出现之前，我们社会就已经在应对分裂的政治问题了。研究表明，至少在美国社会，现在的两极分化程度比1860年代内战以来任何时候都要严重。我读到欧洲的情况不像这里这么糟，但那里的两极分化程度也在上升。即使在生成式AI介入之前，不同政治光谱的人们就已经无法就基本事实达成一致。生成式AI已经开始让情况变得糟糕得多。我可以举很多例子：2023年，斯洛伐克一位政界人士的AI生成假录音在选举前疯传；芝加哥一位市长候选人的假录音可能导致他输掉了选举。有一个网站记录了2024年美国大选前出现的20多个AI生成的政治深度伪造内容。但即便如此糟糕，它也只是刚刚开始，而且这还不是最坏的部分。

单纯的假新闻图片、音频和视频本身并不是问题。真正危险的是，当这些AI生成的假信息通过社交媒体算法被大量推送给人们时。这并非一个全新的问题，社交媒体上的虚假信息已经存在了十多年，但AI使得生成和发布到社交媒体上的错误信息数量增加了几个数量级，并且其精良程度是前所未有的。

但更糟糕的是，研究表明，与聊天机器人的对话会对人们的政治观点产生影响。请记住，社交媒体上的虚假故事可以被注意到并进行事实核查。这些故事仍然会造成损害，而且很多人会拒绝相信事实核查的结果，但至少这是某种程度的制衡。然而，在人与聊天机器人的对话中，却不可能进行任何事实核查。这是AI首次使其成为可能的一个真正新方面：**个性化（individualization）**。

到目前为止，每个人看到的都是一份由相同社交媒体帖子组成的精选列表。你动态消息中帖子的具体组合可能对你来说是独一无二的，但你看到的每一个帖子也都被其他人看到过，这大大增加了某人产生怀疑、去查找并纠正事实的可能性。而在聊天机器人对话中，没有人能意识到正在发生什么，更不用说纠正了。直到现在，一个人接收到这样一份孤立的、个性化的信息流从未成为可能。很快，这可能将成为常态。

### 监管的盲点与政治操纵的风险

理论上，聊天机器人公司可能要对其对话中的任何虚假信息负责，因为聊天机器人不被认为受到1996年《通信规范法案》第230条的保护，尽管这一点尚未在法庭上得到真正检验。然而，如果没有人能看到内容，那么除了可能在事后（而且很可能为时已晚）的诉讼中，没有人能提出异议，即使那样也只是“可能”。在一个日益两极分化的民主社会中，一家聊天机器人公司可能拥有的影响力是巨大的。

通常情况下，要影响美国总统大选所需的人数仅占总投票人数的0.5%，而据报道，高达7%的美国人每天都在使用ChatGPT。一些研究表明，社交媒体确实会影响投票模式。聊天机器人可能对投票产生的影响似乎会更糟。在迄今为止有限的实验室实验中，聊天机器人的影响似乎要强得多。

但试图监管AI的努力根本没有触及这一点。请注意，我不是律师，我只是在重复我从引用的大学页面上读到的内容。例如，《加州AI法案》要求大型AI供应商发布关于其内部程序的报告，在24小时内报告任何灾难性问题，并保护举报人。《UAI法案》（被认为是世界上最严格的法案）要求聊天机器人供应商提供文件，以证明AI生成的内容并防止非法内容生成。这些措施都无济于事。这确实说明了AI实际构成的风险与立法者关切之间的脱节。

这是否可以修复？也许吧，但几乎肯定赶不上下一轮选举周期。我们知道这将产生影响，只是不知道影响有多大或朝哪个方向。然而，AI末日论者却想让你担心“如果有人制造出来，所有人都会死”，而Hank Green则邀请你与你的立法者谈论AI超级智能。这要么是极其虚伪，要么是极其天真，因为……是的，我这样说不太合适。他们要么在撒谎，要么就是愚蠢。因为如果他们真的希望我们的民选代表制定能够阻止AI杀死我们所有人的法律，第一步应该是阻止AI影响谁当选。因为一旦有足够多的支持AI的立法者上任，通过任何反AI法律的可能性就会降为零。

### 虚假现实的来临：信任危机与无望的抵抗

试想一下，如果AI将对选举产生影响，你认为它更有可能支持那些认为AI糟糕的候选人，还是支持那些认为AI有益的候选人？欢迎来到《全面回忆》的世界，在这里，你无法相信任何在网上看到、听到或读到的东西，除非你自己验证了原始来源；在这里，亿万富翁拥有一个可以用来将虚假信息直接推送到人们脑海中、改变人们对关键问题的看法的杠杆；甚至连长期以来受人尊敬的公众人物都在误导你。

我实在想不出任何办法，除了对着镜头咆哮，并试图自我催眠，相信足够多的人可能会观看、点赞和分享这个视频，使其有可能产生微乎其微的影响。通常，我会在这个时候给你一些充满希望的东西，但是……我一无所有。我们已经……

<details>
<summary>Original English</summary>

So, the current crop of generative AI companies
 on balance are currently making the world a
 much worse place, and things are on track to
 get much, much worse than they are now.
 I've made videos about why the AI Doomer
 narrative is a distraction, and I've talked
 about how even people with trusted reputations
 who ought to know better are pushing the
 narrative
 that we need to worry about AI killing us all.
 Today, I'm going to talk about what the biggest
 problem with AI really is, or at least the
 biggest problem I know of so far. I certainly
 hope there isn't anything worse.
 And unfortunately, none of the regulations of
 AI that I've seen or the proposed regulations
 I've seen would help at all.
 Maybe I can make at least some people
 understand the danger that we're in.
 Okay, so here's a short version:
 The AI companies and the AI Doomers want this to
 think about AI as if it was Skynet from
 the Terminator, but that's the wrong Arnold
 movie entirely.
 AI is not a machine from the Terminator.
 It's the machine from Total Recall, and living
 in a world with that machine is a BIT-----
 This is the Internet of Bugs.
 My name is Carl.
 I've been a software professional since the
 1980s, and I'm trying to do my best, my part,
 to make the Internet a safer and less buggy
 place.
 The first thing I want you to understand is
 that the genie can not be put back into
 the bottle at this point.
 AI is not going to go away, no matter what we
 do, we're stuck with it, and we're going
 to have to live with it.
 To those people in my comments that say, "All
 AI is bad" or "Just ban it all," thanks
 for the engagement, but you're wasting your
 time.
 Even once this bubble pops, as long as the
 people getting rich off of Generative
 AI can use it to make themselves even a little
 bit richer, it's going to be a constant factor
 in what happens in the world from now on. Which
 brings us to Total Recall.
 And for the record, I'm talking about the 1990
 version, not the really bad recent remake.
 But summary with only minor spoilers if you
 haven't seen it.
 The premise is that there's a machine that can
 implant fake memories into a person's
 mind.
 Because of this, the good guy doesn't know what's
 true and what's just an implanted
 memory, and the billionaire bad guy uses the
 machine to put any thoughts he wants into
 people's minds, and in the process changes
 their values and personalities.
 I wonder if that's starting to sound familiar
 to you yet.
 So we as a society were already having problems
 with divisive politics before Generative
 AI.
 Research says that we, at least American
 society, is more polarized now than at any time
 since
 the Civil War in the 1860s.
 I've read that Europe isn't as bad as it is
 here, but that polarization levels there
 are also increasing.
 Even before Generative AI entered the mix, it
 was already the case that people on different
 sides of the political spectrum were unable to
 agree on basic facts.
 Generative AI has already started to make that
 much, much worse.
 I can give you lots of examples.
 AI-generated fake recordings of a politician in
 Slovakia in 2023 that went viral right
 before an election, a fake recording of a
 Chicago mayoral candidate that may have
 contributed
 to him losing an election. There's a site that
 cataloged more than 20 AI-generated political
 deep fakes leading up to the US 2024 election,
 but as bad as that is, and it's bad, it's
 just getting started, and that's not the worst
 of it.
 Fake news pictures, audio, and video by
 themselves aren't really a problem.
 The thing that makes them dangerous is when
 those AI-generated fakes get promoted to a
 lot of people by social media algorithms.
 This is not a completely new problem,
 disinformation on social media has been a
 problem for more
 than a decade, but AI allows orders of
 magnitude more misinformation to be generated
 and put
 on social media and with a level of polish that
 could never have been done before.
 But even worse, research says, is the effect
 that conversations with chatbots can have
 on people's political views.
 Remember that fake stories on social media can
 be noticed and fact-checked.
 The stories still do damage and a lot of people
 will refuse to believe the fact-checking,
 But at least it's something, and no such fact-checking
 is possible in a conversation between a person
 and a chatbot.
 This is the really new aspect of this that AI
 makes possible for the first time: individualization.
 Up until now, everyone has gotten a curated
 list of the same social media posts that were
 available to everyone else.
 The particular combination of posts in your
 feed might be unique to you, but every post
 that you see has also been seen by other people,
 which greatly increases the odds that someone
 might be skeptical about it and look it up and
 try to set the record straight.
 And in a chatbot conversation, no one else can
 even be aware of what's being said, much
 less try to correct anything.
 Up until now, it has never been feasible for a
 person to receive an isolated individualized
 feed like that.
 Soon, it may be the norm.
 In theory, a chatbot company could be held
 liable for any falsehoods in such conversations
 since chatbots are not believed to be protected
 by Section 230 of the 1996 Communication
 Disease Agency Act, although that hasn't been
 really tested in court.
 However, if no one else can see the content, no
 one else can object, except maybe in a
 lawsuit after it's probably too late, but still
 even then only maybe.
 In a democracy as polarized as we are becoming,
 that's an enormous amount of influence a
 chatbot company could potentially have.
 The number of people it takes to swing a US
 presidential election is generally half of
 1%, whereas it's been reported that as many as
 7% of Americans use chat GPT every single
 day.
 We have some research that shows that social
 media does affect voting patterns.
 How chatbots might affect voting seems like
 it will actually be worse. In the limited
 lab experiments that have been done so far, the
 effect from chatbots seems much stronger.
 But the efforts to try to regulate AIs don't
 address this at all.
 Note, I'm not a lawyer, I'm just repeating what
 I've read on the pages I'm citing here
 from accredited universities.
 For example, the California AI Act requires the
 big AI vendors to just publish reports
 about some of their internal procedures, report
 any catastrophic issues within 24 hours
 and protect whistleblowers.
 The UAI Act, considered the world's strictest,
 requires chatbot vendors to provide
 documentation
 to show AI generated content and prevent
 illegal content generation.
 None of those would help at all.
 This really illustrates the disconnect between
 the risk that AI actually poses and the
 concerns
 of legislatures.
 Is this fixable?
 Maybe, but almost certainly not before the next
 election cycle.
 We know this is going to have an impact, we
 just don't know how much or in which direction.
 And yet, the AI Doomers want you to worry about
 "If Anyone Builds It, Everyone Dies" and
 Hank Green invites you to talk to your
 lawmakers about AI super intelligence.
 And this is either incredibly disingenuous or
 incredibly naive because... Yeah, that's
 not how I should say that.
 They're either lying or they're stupid. Because
 if they truly wanted our elective
 representatives
 to pass laws that would prevent an AI from
 killing us all, step one would be preventing
 AIs from influencing who gets elected.
 Because as soon as enough pro-AI legislators
 are in office, the chances of getting any anti-AI
 laws passed at all becomes zero.
 And think about it for just half a second.
 If AI is going to have an effect on an election,
 do you think it's more likely to favor
 candidates
 that think AI is bad or candidates that think
 AI is good?
 Welcome to the world of Total Recall, where you
 can't believe anything that's seen or
 heard or read online without verifying the
 original source yourself, where billionaires
 have a lever they can choose to use to push
 disinformation directly into people's minds
 and change people's opinions on critical issues,
 and even long-time trusted public figures
 are telling you to look in the wrong direction.
 And there is absolutely nothing I can think to
 do about it except rant into a camera and
 try to gaslight myself into believing that
 enough people might watch and like and share
 this video that it might actually have a minuscule
 chance to make even a tiny difference.
 Normally, I'd try to give you something hopeful
 here, but... I've got nothing.
 We are so FU-----
</details>