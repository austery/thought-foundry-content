---
area: "tech-engineering"
category: technology
companies_orgs:
- Google
date: '2025-11-15'
draft: true
guest: ''
insight: ''
layout: post.njk
products_models:
- DeepSeek-OCR
- Colab
project: []
series: ''
source: https://www.youtube.com/watch?v=QpCj4LAMYJg
speaker: AI超元域
status: evergreen
summary: 本视频详细介绍了如何通过微调（Fine-tuning）提升小参数OCR模型（如DeepSeek-OCR）的中文识别准确率，尤其针对手写体和扫描件。视频演示了如何利用Google
  Colab的免费GPU，在不到10分钟内完成模型微调，并讲解了中文OCR数据集的制作方法，实现识别错误率降低70%以上。这是一个零成本打造专属领域OCR识别神器的保姆级教程。
tags:
- chinese
- llm
- model
title: 微调的力量：DeepSeek-OCR中文识别蜕变与零成本教程
---
### OCR模型挑战与微调的必要性

在之前的视频中，我为大家测试了多款开源OCR大模型，涵盖了从10亿参数到30亿参数再到90亿参数的模型。通过测试发现，参数量越大的模型识别准确率越高，但对显卡的要求也更高。而参数量较小的模型对显卡要求较低，但识别准确率往往不尽如人意。特别是我们之前测试的**DeepSeek-OCR**模型，在测试时甚至将清晰的汉字“1”错误识别为“2”。此外，我们可能需要在更细分的领域使用OCR模型，例如特定格式的文本或手写体。在这些场景下，小参数模型的表现往往不理想。

那么，有没有更好的办法在不依赖高配置显卡的情况下，提升这些OCR模型的准确率呢？答案是肯定的。我们可以通过**微调**（Fine-tuning: 在预训练模型基础上，使用特定领域数据进行二次训练）的方式，来提升这些小参数OCR模型的准确率。本期视频将演示如何使用中文OCR数据集微调**DeepSeek-OCR**这款小参数模型，从而大幅提升其识别中文的能力。

### 什么是微调？小参数模型蜕变专家

对于不了解微调的用户，我们可以用更通俗的语言来解释：微调就是利用自己的数据或特定领域的知识，对模型进行“开小灶”式的训练。因为通用的**大模型**（Large Language Model: 拥有大量参数，在海量数据上预训练，具备广泛通用能力的模型）更像是一个什么都会却又什么都不精通的“通才”。通过喂养特定领域的知识，可以将通用模型转变为某个领域的专家。例如，我们今天的主题就是让**DeepSeek-OCR**这款通用的OCR模型，从能识别多种语言但每种都不够精准，转变为能精准识别中文的专家模型。

为了提升**DeepSeek-OCR**模型识别中文的能力，我们将使用制作好的中文数据集，并利用**Google Colab**提供的免费GPU。整个微调过程耗时不到10分钟，即可大幅提升**DeepSeek-OCR**模型在中文识别方面的准确率。微调后，其中文识别错误率将降低70%以上。接下来，我将为大家演示如何微调**DeepSeek-OCR**模型，并展示如何制作中文OCR数据集。

### 准备中文OCR数据集

我们可以直接使用Anthlux提供的微调脚本。在他提供的脚本中，默认使用波斯文数据集，图像上的文字并非汉字。因此，我们需要将其替换为中文数据集。如果大家希望通过微调提升模型在通用中文领域的准确性，可以使用**HuggingFace**上开源的高质量中文数据集。这个数据集包含多种样式的中文内容，左侧的`image`字段对应图像，右侧的`text`字段则包含左侧图像上的完整文字。由于该数据集涵盖了不同样式、不同场景下的中文扫描内容，使用它进行微调，可以大幅提升**DeepSeek-OCR**模型在通用中文场景下的OCR准确率。

如果大家希望使用特定领域的数据进行微调，可以参考这个数据集的格式来制作自己的数据集。例如，我这里准备了一些用于OCR场景的图像。这些图像是扫描版PDF中的文字内容，其中包含比较模糊的文字。我还创建了一个文件，其中记录了每张图像的路径，以及右侧图像上完整的文字和标点符号。为了节省时间，我一共准备了10张图像，可以打开查看。放大后，我们可以看到扫描件上的文字内容非常不清晰。

接下来，我们就可以生成数据集了。我准备了一个脚本，它能根据我们刚才准备的图像及其对应的文字内容，生成可用于微调大模型的数据集。点开这个创建数据集的脚本，会发现它非常简单，并且我加入了详细的注释，包括使用方式和完整的中文说明。我们可以在终端直接运行这个脚本，输入`pyse`命令加上脚本名称，然后跟上我们准备的文件名称（即完整的图像路径），再跟上图像上完整的文字内容。运行后，就会生成对应的数据集。生成的数据集后缀是`Pucky`，这与我们之前看到的中文数据集的后缀相同，并且其格式也一致，都包含`image`字段和`text`字段。这样，大家就可以用自己特定领域的数据来制作数据集，用于微调大模型。

### Google Colab上的DeepSeek-OCR微调实战

好的，下面就为大家演示如何使用这个通用的中文OCR数据集微调**DeepSeek-OCR**模型。

接下来，我们在**Google Colab**中打开Anthlux提供的微调脚本。打开后，点击`Runtime`，再点击`Change runtime type`，选择免费的**T4 GPU**。因为使用**T4 GPU**微调30亿参数的**DeepSeek-OCR**模型速度非常快。然后点击保存。接下来的步骤非常简单，我们首先执行安装，在**Colab**上安装微调所需的**环境**（Environment: 运行程序所需的软件和库的集合）与依赖。

现在，我们执行这段代码来下载**DeepSeek-OCR**相关的完整文件，它将把文件存储在指定路径下。接着，我们可以执行这里的代码，将下载的模型加载到内存中，然后直接运行。现在，我们可以添加数据集了。这里我将Anthlux默认的数据集更改为我们刚才查看的中文数据集。由于两个数据集的差异，默认数据集是图像路径，而中文数据集的第一个字段是图像本身，所以我们需要在微调脚本中将图像路径更改为对应的图像。

在这个参数中，我们加载数据集中前2000个样本。我们直接执行加载数据集的代码，然后执行这段代码，从数据集中随机找一张图像进行测试，以评估未微调的**DeepSeek-OCR**模型的效果。再执行保存图像的代码，然后我们可以点击显示这张图像。图像中有一个汉字“1”，因为**DeepSeek-OCR**模型很容易将“1”识别成“2”，所以我们可以测试它能否正确识别数据集中这张图像。

接下来，我们可以运行这段代码，使用未经微调的模型进行**推理**（Inference: 使用训练好的模型对新数据进行预测或识别的过程），让它识别这张图像，查看效果。可以看到，输出结果不出意外地将“1”识别成了“2”。然后，我们可以运行这段代码查看数据集中对应的真实文字。可以看到，数据集中对应的真实文字是“1”，但未经微调的**DeepSeek-OCR**模型却识别成了“2”。由此可见，未经微调的**DeepSeek-OCR**模型识别准确率确实有待提高。

好的，接下来我们就可以配置这个模型了。我们可以使用**LoRA**（Low-Rank Adaptation: 一种高效的参数微调技术，通过在预训练模型中注入少量可训练参数来适应新任务）来配置它。这是一种高效的参数配置方式。这里是详细的**超参数**（Hyperparameters: 在模型训练前设定的参数，如学习率、批次大小等，影响模型训练过程和性能）设置，我还加入了中文注释，这里就不再为大家做过多解释了，我们直接执行这段代码即可。接下来，我们需要准备并处理数据集，直接执行这段代码将数据集样本转换为对话格式。

这里加载了我们刚才查看的中文数据集，并且我们只加载前1000个样本用于微调大模型，直接执行这段代码即可。然后我们再执行这段代码，将数据集转换为正确的微调格式。接下来，我们可以完整运行这段用于创建**数据整理器**（Data Collector: 负责将数据集中的样本进行批处理和格式化，以适应模型训练输入的工具）的代码。这段代码中包含完整的中文注释，为了节省时间，这里我们就不再具体查看了，直接执行即可。

现在，我们就可以微调这个模型了。我们可以执行下面的代码来创建**训练器**（Trainer: 负责管理模型训练过程的组件，包括迭代、优化、评估等）并设置超参数。这些具体的参数在之前的微调视频中我已经详细解释过，这里就不再一一解释了，我们直接执行即可。接下来，我们还可以执行这段代码查看当前的硬件配置，这里显示的是**T4 GPU**，最大内存为14GB。然后，我们就可以运行这段代码开始微调了，直接执行即可。现在微调正在进行中，我们需要稍等几分钟。

大约等待了六七分钟后，微调过程已经完成，可以看到它执行了60步。

### 微调效果验证与模型部署

接下来，我们可以运行下面的代码，将微调后的**LoRA Adapter**权重和**Tokenizer**（分词器: 将文本拆分成模型可理解的更小单元，如单词或字符）保存到本地目录，直接执行即可。现在，我们可以运行这段代码加载刚才微调好的模型，用于识别之前没有正确识别的图像。直接运行后，它成功识别出了图像上的文字内容，将之前识别错误的“2”成功识别成了“1”。然后，下面的代码就是将模型保存为支持**ONNX**（Open Neural Network Exchange: 一种开放式神经网络交换格式，用于在不同深度学习框架之间进行模型转换和部署）推理的文件。

这里我们只需要将`FALSE`改为`TRUE`即可。为了节省时间，这里就不再为大家详细演示了，大家也可以查看我之前发布的关于微调的详细视频。通过微调**DeepSeek-OCR**模型可以发现，它之前识别错误的文字在微调之后能够正确识别。像这样，我们就可以针对特定领域或特定任务场景来微调**DeepSeek-OCR**大模型或其他OCR模型。

### 总结与资源获取

本期视频所用到的代码和指令，我都会放在视频下方的描述栏或评论区。如果大家在视频下方无法找到，也可以通过我的博客查找本期视频对应的笔记。本期视频就到这里，欢迎大家点赞、关注和转发。感谢大家的观看！