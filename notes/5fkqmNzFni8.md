---
area: "work-career"
category: ai-ml
companies_orgs:
- OpenAI
- DeepMind
date: '2024-11-19'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- Ray Kurzweil
- Shane Legg
products_models:
- GPT-2
- GPT-3
- Transformer
project: []
series: ''
source: https://www.youtube.com/watch?v=5fkqmNzFni8
speaker: Dwarkesh Patel
status: evergreen
summary: 本文追溯了 Gwern 对 AI 规模化假说的思想历程。从早期对连接主义的怀疑，到关注 Shane Legg 的预测，再到观察到深度学习领域数据、模型和算力的持续增长，最终在
  GPT-3 出现后，他确信智能的涌现与规模化紧密相关，并对当时主流观点提出质疑。
tags:
- learning
- llm
- neural-network
- scaling-law
title: Gwern 如何预见 AI 规模化浪潮
---
### 引言：规模化假说的提出

你是少数在 2020 年就拥有详细的**规模化**（scaling: 指模型、数据量或计算能力的增加）实证模型的人之一，我很好奇你当时使用了什么方法，让你能够看到你在《规模化假说》（scaling hypothesis）一文中描绘的图景。

### 早期怀疑：连接主义的挑战

如果我要梳理这段思想史，我认为它大概始于 2000 年代中期，那时我阅读了更多关于 **Ray Kurzweil** 的著作。当时，他们提出了一个根本性的**连接主义**（connectionist: 一种人工智能研究范式，认为智能可以通过大规模并行处理单元（如神经网络）涌现）论点：只要拥有足够的计算能力，就可能发现与人脑匹配的**神经网络**（neural network: 受人脑结构启发的计算模型）架构。在此之前，在有足够计算能力之前，AI 似乎基本上是徒劳的。

### 对“建好即来”的质疑

对我而言，我发现这个论点非常不可信，因为它是一种‘建好它，它们就会来’（build it and they will come）的进步观，我并不认为这是正确的。我觉得这简直是荒谬的，仅仅因为你拥有一个匹配人脑的超级计算机，就能凭空召唤出正确的算法。算法非常复杂，很难，需要深刻的洞察力，或者至少我当时是这么认为的。这似乎是极其困难的数学问题，你不能仅仅购买大量计算机就期望从中获得高级人工智能，这简直是痴心妄想。

### Legg 的预测与 AI 时间表

所以我知道这个论点，但我非常怀疑，并没有太在意。但后来 **Shane Legg** 和其他人对此非常热衷。在我对**超人类主义**（transhumanism: 一种哲学思想，主张通过技术手段增强人类能力）、**LessWrong**（一个理性主义者社区）和**AI 风险**（AI risk: 指人工智能发展可能带来的潜在危险）感兴趣的背景下，我密切关注了 Legg 的博客文章，他根据 Ray Kurzweil 和 Moravec 的数据进行趋势外推，给出了非常精确的预测：大约在 2019 年将出现第一个通用人工智能系统，随着摩尔定律的持续，到 2025 年将出现具有通用能力的类人智能体，并预测到 2030 年将实现 **AGI**（Artificial General Intelligence: 通用人工智能）。

### DeepMind 的崛起与趋势观察

在此过程中，**DeepMind**（此处推测 "Dan net and Alex net" 指代 DeepMind 的工作）的研究成果涌现。看到这些时，我惊叹不已，这似乎是连接主义观点的又一个令人印象深刻的成功案例。但这仅仅是孤立的成功，还是 Kurzweil、Moravec 和 Shane Legg 所预测的那样，我们能获得 GPU，然后算法就会自然而然地出现？

### 深度学习中的规模化证据

于是我开始思考，这确实是一个值得关注的趋势，也许这个想法不像我最初认为的那么愚蠢。我持续阅读**深度学习**（deep learning: 机器学习的一个分支，使用多层神经网络来学习数据表示）的文献，一次又一次地注意到，数据集规模不断增大，模型规模似乎也在不断增大，GPU 的算力也逐渐提升，从一个 GPU 到两个，再到八个。你可以清楚地看到，神经网络的规模不断扩大，从极其狭窄的个别用例，扩展到几乎无所不包的领域，其应用范围越来越广泛。

### 智能的本质：计算、数据与参数

我当时想：“哇，**CNN**（Convolutional Neural Network: 卷积神经网络，一种常用于图像识别的深度学习模型）还有什么做不到的？”我看到人们每天都在 Archive（预印本网站）上将 CNN 应用于新的领域。这种逐渐的、细微的信息不断在我生活中不经意间出现。每隔几天，就会有新的进展出现，我便会想：“嗯，**也许智能真的只是大量的计算能力应用于大量数据和大量参数的结果**”。也许 Moravec、Legg 和 Kurzweil 是对的。我记下这一点，继续思考：如果这是真的，那将带来巨大的影响。

### 少数派的洞察

所以，我认为并没有一个‘尤里卡时刻’，只是持续地观察着这个趋势，而似乎没有人注意到，除了少数人，比如 **Elias Carter** 和 **Schmid Huber**。我密切关注，并注意到随着时间的推移，世界越来越像他们的世界，而不是我原先的世界——那个算法至上、需要深刻洞察力才能成事的领域。他们的世界一直在发生。

### GPT-1/GPT-2：规模化的初步迹象

然后 **GPT-1** 问世，我惊叹于这个无监督的**情感神经元**（sentiment neuron: 指代模型中能够识别情感的特定部分）竟然能自主学习。这看起来非常了不起。它也体现了一种计算密集型的观点：你只需构建 **Transformer**（一种在自然语言处理领域取得巨大成功的深度学习模型架构），智能就会随之而来。接着 **GPT-2** 发布，我产生了‘神圣时刻’（holy moment）的感受。看看它的提示（prompting）和总结能力，我心想：“天哪，**我们真的活在他们的世界里了**！”

### GPT-3：规模化假说的关键验证

然后 **GPT-3** 问世，这成为了真正的关键考验。它是一次巨大的、史无前例的规模升级，是神经网络历史上最大的规模升级之一，从 GPT-2 到 GPT-3。它并非针对某个狭窄的特定任务，而是真正成为了关键测试。如果规模化是错误的，那么 GPT-3 的论文本应毫无亮点。但如果规模化是正确的，那么它必然会带来比 GPT-2 更令人印象深刻的结果。我打开论文，看到‘**少样本学习**’（few-shot learning: 指模型在仅看到少量示例后就能执行新任务的能力）的图表，我心想：“天哪，我们真的生活在规模化的世界里！Le、Moravec 和 Kur（此处推测指代相关研究者）是正确的！”

### 对抗主流：愤怒与纠正

然后我转向 Twitter，发现大家都在说：“哦，这表明规模化效果很差，为什么它甚至不是最先进的？”这让我非常生气，我必须写下这一切，因为“互联网上有人错了”。