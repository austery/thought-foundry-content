---
area: tech-work
category: ai-ml
companies_orgs:
- Google
- OpenAI
- Google DeepMind
- DARPA
- Anthropic
- TSMC
- Jane Street
date: '2025-02-12'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- Jeff Dean
- Noam Shazeer
- Larry Page
- Franz Och
- Sundar Pichai
- Rich Sutton
- Chris Olah
- Einstein
- Newton
products_models:
- MapReduce
- BigTable
- Tensorflow
- AlphaChip
- Gemini
- Transformer
- Mixture of Experts
- Mesh Tensorflow
- TPU
- BERT
- Meena
- Pixel cameras
- Gato
- ImageNet
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=v0gjI__RyCY
speaker: Dwarkesh Patel
status: evergreen
summary: 本播客深入探讨了Google首席科学家Jeff Dean和Transformer架构共同发明者Noam Shazeer在Google二十五年的职业生涯。他们回顾了从MapReduce、Tensorflow等基础系统到Gemini等最新AI模型的发展历程，讨论了摩尔定律对硬件设计的影响、硬件与算法的协同演进、AI模型模块化与推理扩展的未来愿景，以及通用人工智能（AGI）带来的机遇与挑战，包括AI安全和负责任的开发原则。同时，他们也分享了在快速变化的AI领域中保持创新和职业广度的经验。
tags:
- ai-safety
- llm
- technology
title: Jeff Dean与Noam Shazeer：Google二十五年，从PageRank到AGI
---

### 引言：Google的两位AI先驱

今天，我很荣幸能与**Jeff Dean**和**Noam Shazeer**进行对话。**Jeff**是**Google**的首席科学家，在他效力**Google**的25年里，他参与了现代计算领域最具变革性的系统开发，包括**MapReduce**（MapReduce: Google开发的一种分布式计算模型，用于处理和生成大数据集）、**BigTable**（BigTable: Google开发的一种分布式结构化数据存储系统）、**Tensorflow**（Tensorflow: Google开发的开源机器学习框架）、**AlphaChip**（AlphaChip: Google内部的AI芯片项目，或指其定制AI硬件）以及现在的**Gemini**（Gemini: Google DeepMind开发的多模态大型语言模型），这份名单简直数不胜数。

而**Noam**则是当前AI革命中最重要的贡献者之一。他是现代**LLM**（LLM: Large Language Model，大型语言模型）所使用的所有主要架构和技术的发明者或共同发明者，包括**Transformer**（Transformer: 一种神经网络架构，广泛应用于自然语言处理任务，是现代大型语言模型的基础）本身、**Mixture of Experts**（MoE: 专家混合模型，一种神经网络架构，通过路由机制激活模型中特定“专家”子网络来处理输入，提高效率和容量）和**Mesh Tensorflow**（Mesh Tensorflow: Tensorflow的一个扩展，用于在分布式硬件上高效训练大型模型）等诸多技术。他们两位都是**Google DeepMind**旗下**Gemini**项目的三位联合负责人之一。非常感谢你们的到来。

### Google的成长与个人体验

**Dwarkesh Patel**提问，两位在**Google**工作了近25年，公司早期可能对所有系统都了如指掌，那么这种“无所不知”的状态是从何时开始改变的？**Noam Shazeer**回忆说，他于2000年底加入公司，当时每个人都会有一个导师，而他的导师恰好是**Jeff Dean**。**Noam**开玩笑说，并非所有**Google**员工都无所不知，只是**Jeff**无所不知，因为他几乎编写了所有东西。

**Jeff Dean**解释道，公司发展会经历不同阶段。他刚加入时，公司只有25、26人，所以他能记住每个人的名字，并持续关注新加入的员工。但随着公司规模扩大，你开始记不住所有人的名字，然后是记不住软件工程部门所有人的名字，再后来是只知道所有项目，直到有一天你收到一封邮件说“**Project Platypus**（Project Platypus: 虚构的项目名，代指Google内部众多项目）”周五上线，你却一无所知。通常这会是一个惊喜，你会感叹：“哇，**Project Platypus**！我完全不知道我们在做这个。”**Jeff**认为，即使不了解所有细节，在高层次上了解公司动态也很有益。同时，与公司内外的人建立良好的人脉网络也很重要，这样你就能通过间接方式找到对的人来获取更多信息。

### 加入Google的契机

**Dwarkesh Patel**好奇**Jeff Dean**是如何被**Google**招募的。**Jeff**表示是他主动联系了**Google**。而**Noam Shazeer**则是在1999年的招聘会上看到了**Google**，当时他以为**Google**已经是一家庞大的公司，觉得加入也没什么意义，因为他认识的所有人都在用**Google**。他当时是**伯克利**的硕士生，后来几次退学。

**Noam**发现**Google**当时并没有他想象的那么大。他没有在1999年申请，而是在2000年心血来潮地投递了简历，因为那是他最喜欢的搜索引擎，觉得应该多申请几家公司。结果发现**Google**非常有趣，聚集了一群聪明人做着有意义的事情。公司墙上有一张漂亮的蜡笔图表，记录着每日搜索查询量，呈现出指数级增长。他当时想：“这些人会非常成功，而且他们有很多有趣的问题可以解决。”于是他决定：“好吧，也许我可以在那里工作一段时间，然后赚够钱，想做多久的AI研究就做多久。”**Noam**笑着说，这个计划完全按预期实现了。他早在1999年就开始思考AI。他记得在研究生院时，一位朋友的新年愿望是活到3000年，并计划通过发明AI来实现。**Noam**当时觉得这是个好主意，但没想到可以在一家大公司里做AI。他原以为可以在初创公司赚一笔钱，然后靠这些钱长期从事AI研究。但事实证明，**Google**是一个从事AI研究的绝佳场所。

### Google的AI抱负与摩尔定律的演变

**Jeff Dean**表示，**Google**的抱负始终需要相当先进的AI技术。他认为“组织全球信息并使其普遍可访问和有用”是一个非常广泛的使命，公司不会只做一件小事。而且，他们最初的工作就朝着这个方向发展，并且可以做得更多。

**Dwarkesh Patel**询问，过去二三十年间，**摩尔定律**（Moore's Law: 指集成电路上可容纳的晶体管数量大约每两年翻一番）如何改变了系统设计和项目可行性的考量？**Jeff Dean**认为，过去二十年变化很大。二十年前到十年前，硬件每18个月就会大幅提速，你无需做任何事。但最近，通用**CPU**（CPU: 中央处理器，计算机的核心计算单元）机器的扩展性不再那么好，制造工艺改进周期从两年延长到三年。多核处理器的架构改进也不再像20到10年前那样带来巨大提升。但与此同时，他们看到了更多专用计算设备，例如机器学习加速器、**TPU**（TPU: Tensor Processing Unit，张量处理单元，Google专门为机器学习工作负载设计的定制ASIC芯片）以及最近专注于机器学习的**GPU**（GPU: 图形处理器，最初用于图像渲染，现广泛用于并行计算，尤其在机器学习中），这些设备使得他们能够从更现代的计算类型中获得高性能和高效率，这与运行**Microsoft Office**等程序的复杂**C++**代码不同。

**Noam Shazeer**补充说，感觉算法正在追随硬件。现在，算术运算变得非常廉价，而数据移动相对昂贵得多。深度学习的兴起很大程度上就是因为这个原因。你可以用矩阵乘法来构建它，其中包含N³次运算和N²字节的数据通信。**Jeff Dean**认为，向围绕这一特性优化的硬件转型是一个重要里程碑。在此之前，**CPU**和**GPU**并不特别适合深度学习。后来，**Google**开始构建**TPU**，它们本质上是简化精度的线性代数机器，一旦有了这种硬件，自然就会想要充分利用它。

### 硬件与算法的协同设计

**Noam Shazeer**认为，这就像识别机会成本。他引用**Larry Page**（Larry Page: Google联合创始人）的话：“我们第二大成本是税收，最大的成本是机会成本。”如果他没说过，那**Noam**就引用错了好多年。但核心思想是，你错过了什么机会？在这种情况下，芯片面积上只放置了少量算术单元，而本可以填充更多，从而实现数量级更高的算术运算。那么，还需要改变什么？算法、数据流以及其他一切。**Jeff Dean**补充道，算术运算可以采用非常低的精度，这样就能在芯片上挤入更多的乘法单元。

**Dwarkesh Patel**追问**Noam Shazeer**关于算法追随硬件的观点。如果在一个反事实的世界中，内存成本下降幅度大于算术成本，或者说数据流极其廉价而算术昂贵，那么今天的AI会是什么样子？**Noam**认为，那将会有更多对超大内存的查找。**Jeff**则表示，那可能更像20年前的AI，但方向相反。他于2012年加入**Google Brain**团队。他曾离开**Google**几年，后来一次偶然的机会回公司探望妻子，碰巧和**Jeff**以及早期的**Google Brain**团队坐在一起。他当时想：“哇，这是一群聪明人。”**Jeff**说：“你应该考虑深度神经网络，我们在这方面取得了不错的进展。”**Noam**觉得这听起来很有趣，于是又回到了**Google**，于2012年加入**Jeff**的团队。他似乎每12年加入一次**Google**：2000年、2012年和2024年。**Dwarkesh Patel**开玩笑问2036年又会发生什么。

### 低精度计算与协同设计的重要性

**Dwarkesh Patel**询问，在未来**TPU**版本中，为了整合算法思路，正在考虑哪些权衡？**Jeff Dean**认为，一个普遍趋势是他们越来越擅长量化或使用更低精度的模型。他们从**TPUv1**开始，当时甚至不确定能否用8位整数对模型进行量化以供服务。但早期的一些证据表明这可能可行，于是他们决定围绕这个想法构建整个芯片。

随着时间的推移，人们也开始在训练中使用更低的精度。推理精度也越来越低。现在人们使用**INT4**（INT4: 4位整数）或**FP4**（FP4: 4位浮点数），这在20年前的超级计算浮点专家听来会觉得“疯了，我们喜欢64位浮点数”。甚至更低，有些人将模型量化到2位或1位，**Jeff**认为这是一个明确的趋势。**Dwarkesh Patel**惊讶地问：“1位？就0或1？”**Jeff**回答：“是的，就0-1。然后你可能有一组位的符号位。”

**Noam Shazeer**强调，这必须是协同设计。如果算法设计者不明白低精度可以大幅提高性能和吞吐量，他们自然会说“我当然不想要低精度，那会带来风险”，并感到恼火。如果你问芯片设计者“你想构建什么？”，他们会问今天编写算法的人，而那个人会说“不，我不喜欢量化，它很烦人”。所以，你需要看到全局，并意识到“等等，通过量化我们可以大幅提高吞吐量与成本比”。然后你就会说，是的，量化很烦人，但你的模型会快三倍，所以你必须接受。

### AI发展史上的先见之明

**Dwarkesh Patel**指出，在两位的职业生涯中，曾多次从事与当前生成式AI惊人相似的工作。例如，**Jeff Dean**在1990年的高级论文是关于**反向传播**（Backpropagation: 神经网络训练中用于计算梯度并更新模型权重的一种算法）。而在2007年，**Dwarkesh**在准备这期节目时才意识到，两位训练了一个两万亿（2 trillion）词元的**N-gram模型**（N-gram模型: 一种基于统计的语言模型，通过分析文本中N个词的序列出现频率来预测下一个词）用于语言建模。**Dwarkesh**请他们回顾一下开发这个模型时的想法，当时他们认为自己在做什么？

**Jeff Dean**首先谈到了他的本科论文。他在大四时上的一门并行计算课程中，一个章节介绍了神经网络。为了毕业，他需要完成一篇荣誉论文。他找到教授说：“做一些关于神经网络的事情会很有趣。”于是，他和教授决定在1990年实现几种不同的并行化**反向传播**训练神经网络的方法。他在论文中给它们起了些有趣的名字，比如“模式分区”之类的，但实际上，他是在一台32处理器**超立方体**（Hypercube: 一种多维几何结构，在并行计算中指一种处理器互联网络拓扑）机器上实现了模型并行化和数据并行化。其中一种方法是将所有样本分成不同的批次，每个**CPU**都有一个模型的副本。另一种方法是将大量样本通过流水线传送到拥有模型不同部分的处理器。他对比了这两种方法，觉得很有趣。

他当时对这种抽象感到非常兴奋，因为神经网络似乎是正确的抽象。它们能解决当时其他方法无法解决的微小玩具问题。他天真地以为32个处理器就能训练出非常棒的神经网络。但事实证明，在它们真正开始解决实际问题之前，还需要大约一百万倍的计算能力。直到2008年末、2009年、2010年左右，得益于**摩尔定律**，他们才开始拥有足够的计算能力，使神经网络能够用于实际应用。那也是他重新开始关注神经网络的时候。

### 2007年的万亿级N-gram模型

在2007年，**Google**有一个由**Franz Och**（Franz Och: Google机器翻译团队负责人）领导的机器翻译研究团队，他们每年都会参加**DARPA**（DARPA: 美国国防高级研究计划局，负责开发新兴军事技术）举办的翻译竞赛，将几种不同语言翻译成英语，比如中文到英文和阿拉伯语到英文。**Google**团队提交了一个参赛作品，比赛规则是周一收到500个句子，周五提交答案。**Jeff Dean**看到结果后，发现他们以相当大的优势赢得了比赛，优势体现在**Bleu分数**（Bleu score: 一种用于评估机器翻译质量的指标）上，这是一个衡量翻译质量的指标。

**Jeff**联系了**Franz**，这位获胜团队的负责人，问道：“这太棒了，我们什么时候能发布它？”**Franz**回答说：“哦，我们不能发布这个。它不太实用，因为翻译一个句子需要12个小时。”**Jeff**心想：“嗯，这时间有点长。我们怎么解决这个问题？”原来他们并没有针对高吞吐量进行设计。它在翻译每个词时，会在一个大型语言模型上进行10万次磁盘寻道，这个模型是他们对统计数据进行计算（**Jeff**不称之为“训练”）而得来的。显然，进行10万次磁盘寻道速度不会很快。但**Jeff**说：“好吧，我们来深入研究一下。”于是他花了大约两三个月的时间与团队一起，设计了一种**N-gram**数据的内存压缩表示。

他们当时使用的**N-gram**基本上是衡量每个N词序列在一个大型语料库中出现的频率统计。在这种情况下，他们处理了2万亿个词。当时大多数**N-gram模型**使用二元组或三元组，但他们决定使用五元组。所以，他们统计了当时能处理的几乎所有网络数据中，每个五词序列的出现频率。然后他们构建了一个数据结构，可以存储所有这些信息在200台机器的内存中，并提供一个批处理**API**。你可以说：“这是我这一轮需要查找的10万个词，请并行返回所有结果。”这使得他们将翻译一个句子所需的时间从一整夜缩短到大约100毫秒。

**Dwarkesh Patel**提到了关于**Jeff Dean**的一些趣闻，就像**Chuck Norris**的段子一样。其中一个说：“对**Jeff Dean**来说，NP（NP: 非确定性多项式时间）等于‘no problemo’（没问题）。”另一个是：“光速曾是每小时35英里，直到**Jeff Dean**在一个周末决定对其进行优化。”从12小时缩短到100毫秒，这确实是数量级的提升。**Jeff**表示这些趣闻都非常恭维，也很有趣，是同事们开的一个愚人节玩笑。

### 语言模型与智能的萌芽

**Dwarkesh Patel**认为，回过头来看，通过仅仅考虑词语之间的关系来发展整个互联网的潜在表示，这正是大型语言模型，也就是**Gemini**。那么，当时这仅仅是一个翻译的想法，还是你们已经预见到这会是另一种范式的开端？

**Jeff Dean**认为，一旦他们为翻译构建了那个系统，大型语言模型的服务就开始用于其他方面，比如补全功能——你开始打字，它会建议合理的补全。所以，这无疑是**Google**内部许多语言模型应用（如**Noam Shazeer**在**Google**做的拼写纠正系统）的开端。**Noam**的拼写纠正系统大约在2000年、2001年完成，当时可能全部在单台机器的内存中运行。**Jeff**补充说，**Noam**在2001年构建的拼写纠正系统非常出色，他向全公司发送了演示链接。**Dwarkesh**回忆说，他尝试了各种拼错的查询，比如“scrumbled uggs Bundict”而不是“scrambled eggs benedict”，系统每次都能完美纠正。**Noam**说，那确实是语言建模。

**Dwarkesh Patel**追问，当时开发这些系统时，他们是否有一种感觉，即“如果将这些系统做得越来越复杂，不只考虑五个词，而是考虑一百个、一千个词，那么潜在表示就是智能”？这种洞察力是何时产生的？

**Noam Shazeer**表示，他当时并没有真正觉得**N-gram模型**会“席卷世界”成为人工智能。他认为当时很多人对**贝叶斯网络**（Bayesian networks: 一种概率图模型，用于表示和推理不确定性知识）更感兴趣，那看起来更令人兴奋。但看到早期的神经网络语言模型时，他感受到了其中的魔力，觉得“这正在做一些非常酷的事情”。同时，他也认为这是一个世界上最好的问题，因为首先，它非常简单明了：“给我下一个词的概率分布”。其次，几乎有无限的训练数据可用，比如网络文本，有数万亿的无监督数据训练样本。**Jeff**补充说是自监督数据。**Noam**同意，并指出这种方式很好，因为你有了正确答案，然后可以根据当前词之外的所有内容进行训练，并尝试预测当前词。这是一种从世界观察中学习的惊人能力。**Jeff**总结道，如果能很好地完成这项任务，那么它就是**AI complete**（AI complete: 指一个问题如果能被解决，那么通用人工智能也就能够被解决），几乎可以做任何事情。

### 突破性时刻：猫神经元的发现

**Dwarkesh Patel**提到科学史上关于思想是“在空气中”自然产生，还是从某个切线方向“摘取”出来的有趣讨论。他问，他们目前这种逻辑严密的阐述，是否意味着AI发展的必然性？**Noam Shazeer**认为，这确实感觉像“在空气中”。当时肯定有一些想法，比如**神经图灵机**（neural Turing machine: 一种结合神经网络和外部记忆的计算模型），以及围绕**注意力机制**（attention: 神经网络中一种允许模型关注输入序列不同部分的技术）的许多想法，比如在神经网络中使用键值存储来聚焦事物。他觉得在某种意义上，这些想法是存在的，但在某种意义上，你需要一个团队去实现它。

**Jeff Dean**倾向于认为许多想法是“部分在空气中”的。当试图解决新问题时，会审视一些不同的、可能独立的现有研究思想，从中汲取灵感。然后，有些方面是尚未解决的，你需要找出如何解决。现有事物的某种融合与一些新事物的结合，最终导致了之前不存在的新突破或新研究成果。

**Dwarkesh Patel**询问，在他们的研究生涯中，是否有某个关键时刻让他们产生了“天哪，我简直不敢相信这竟然成功了！”的感觉。**Jeff Dean**回忆起**Google Brain**团队早期的一件事。他们当时专注于“看看能否构建一些基础设施，让我们能够训练非常非常大的神经网络”。那时，他们的数据中心还没有**GPU**，只有**CPU**。但他们知道如何让大量**CPU**协同工作。

于是，他们构建了一个系统，能够通过模型并行和数据并行训练相当大的神经网络。他们有一个系统，用于对1000万个随机选择的**YouTube**（YouTube: Google旗下的视频分享平台）帧进行无监督学习。这是一种空间局部表示，它会通过尝试从高层表示重建事物来构建无监督表示。他们让这个系统在2000台计算机上运行，使用了16000个核心进行训练。过了一段时间，这个模型竟然能够在最高层构建出一种表示，其中一个神经元会被猫的图像激活。它从未被告知什么是猫，但它在训练数据中看到了足够多的猫正面视图的例子，以至于那个神经元会因此而激活，而不会对其他事物做出太多反应。类似地，其他神经元会针对人脸和行人背影等激活。这非常酷，因为它基于无监督学习原则，构建了这些真正高层次的表示。随后，他们在有监督的**ImageNet**（ImageNet: 一个大型视觉数据库，用于视觉对象识别软件的研究）20000类别挑战赛中取得了非常好的结果，相对提升了60%的艺术水平，这在当时是相当不错的成就。那个神经网络可能比之前训练过的模型大了50倍，并取得了良好的效果。这让**Jeff**觉得：“嘿，扩展神经网络似乎是个好主意，而且看起来确实如此，所以我们应该继续推进。”

### Google的使命与AI的未来

**Dwarkesh Patel**指出，这些例子说明了AI系统如何契合**Jeff Dean**之前提到的观点：**Google**本质上是一家组织信息的公司。在这种背景下，AI通过发现信息和概念之间的关系，帮助用户更快地获取想法和所需信息。现在，随着当前的AI模型发展，例如在**Google Search**中使用**BERT**（BERT: Bidirectional Encoder Representations from Transformers，Google开发的一种基于Transformer的双向预训练语言模型）来回答问题，它们仍然擅长信息检索，但更根本的是，它们可以为你编写整个代码库并完成实际工作，这已经超越了单纯的信息检索。

**Dwarkesh**询问，如果**Google**正在构建**AGI**（AGI: Artificial General Intelligence，通用人工智能，指具备人类智能水平并能执行任何人类智力任务的AI系统），那么**Google**还是一家信息检索公司吗？**AGI**可以进行信息检索，但也能做很多其他事情。**Jeff Dean**认为，他们是一家“组织世界信息”的公司，这比信息检索更广泛。也许可以理解为：“根据你提供的指导，组织并创造新信息。”例如，“你能帮我给兽医写一封关于我的狗的信吗？它有这些症状”，然后AI会起草。或者，“你能输入这段视频，然后每隔几分钟生成视频内容的摘要吗？”

**Jeff**认为，他们的多模态能力表明，这不仅仅是文本。它关乎理解世界中所有不同模态的信息，包括人类可理解的模态，也包括非人类导向的模态，比如自动驾驶汽车上的奇怪**激光雷达**（lidar: Light Detection and Ranging，激光探测与测距，一种遥感技术）传感器、基因组信息或健康信息。然后，如何提取和转化这些信息，为人们提供有用的洞察，并利用这些洞察帮助他们完成各种想做的事情？有时是“我想和聊天机器人聊天来娱乐一下”。有时是“我想要解决这个非常复杂的问题的答案，但没有单一的信息来源可供检索”。你需要从100个网页中提取信息，弄清楚发生了什么，并生成一个有组织、综合性的数据版本。

然后是处理多模态事物或与编码相关的问题。**Jeff**认为这些模型的能力令人兴奋，而且它们正在快速改进，所以他很期待未来的发展。**Noam Shazeer**也表示期待，他认为组织信息显然是一个万亿美元的机会，但万亿美元已经不酷了，酷的是万万亿美元。显然，目标不是简单地积累巨额财富，而是在世界上创造价值。当这些系统能够真正为你做些事情，编写你的代码，或者解决你自己无法解决的问题时，就能创造出更多的价值。要大规模实现这一点，他们必须在提升模型能力时保持高度的灵活性和动态性。

### 长上下文与信息检索的融合

**Jeff Dean**对许多基础研究问题感到兴奋，因为他们看到当前的工作可以通过尝试某种方法或大致方向得到大幅改进。这可能奏效，也可能不奏效。但他也认为，了解他们能为最终用户实现什么，然后反向工作来构建能够实现这些的系统，也很有价值。举例来说，组织信息应该意味着世界上任何信息都应该对任何人可用，无论他们说什么语言。他们已经做了一些，但远未达到“无论你讲数千种语言中的哪一种，我们都能让你获取并使用任何内容。任何视频都可以用任何语言观看”的完整愿景。**Jeff**认为那会非常棒，虽然他们尚未完全实现，但这绝对是他们预见到的未来可能实现的事情。

谈到可能尝试的不同架构，**Dwarkesh Patel**知道**Jeff**目前正在研究长上下文。他指出，**Google Search**拥有整个互联网的索引作为上下文，但搜索深度很浅。而语言模型目前的上下文有限，但它们能够真正进行思考，就像“暗黑魔法”般的**上下文学习**（in-context learning: 大型语言模型在不更新模型参数的情况下，仅通过输入提示中的示例来学习新任务的能力）。**Dwarkesh**问，如何将**Google Search**和**上下文学习**融合起来？

**Jeff Dean**首先尝试回答这个问题，他对此思考了一段时间。他指出，这些模型虽然相当出色，但有时会产生幻觉并存在事实性问题。部分原因是，模型在数万亿词元上进行训练，并将所有这些信息混合在数十亿或数千亿个参数中。但这些信息有点“模糊”，因为所有词元都被搅在一起了。模型对这些数据有一个相对清晰的视图，但有时会混淆，给出错误的日期等信息。

相比之下，上下文窗口中、模型输入中的信息非常清晰，因为**Transformer**中有一个非常好的**注意力机制**（attention mechanism: 神经网络中一种允许模型关注输入序列不同部分的技术）。模型可以关注事物，并且知道它正在处理的确切文本、视频帧或音频等。现在，他们拥有可以处理数百万词元上下文的模型，这已经很多了。这相当于数百页的**PDF**、50篇研究论文、数小时的视频或数十小时的音频，或者这些东西的组合，这非常酷。但如果模型能够处理数万亿词元，那将非常棒。它能否处理整个互联网并为你找到正确的信息？它能否处理你所有的个人信息？**Jeff**希望有一个模型，在获得他许可的情况下，能够访问他所有的电子邮件、文档和照片，并在他要求它做某事时利用这些信息来帮助解决问题。但这将是一个巨大的计算挑战，因为朴素的注意力算法是二次复杂度。在相当多的硬件上，它勉强能处理数百万词元，但要天真地扩展到数万亿词元则毫无希望。

因此，他们需要一系列有趣的算法近似来达到真正想要的效果：一种让模型能够概念上处理更多、更多词元，即数万亿词元的方法。也许他们可以将整个**Google**代码库作为上下文提供给每个**Google**开发者，或者将全世界的源代码作为上下文提供给任何开源开发者。那将是惊人的。

### AI辅助编程与生产力飞跃

**Noam Shazeer**认为这将是不可思议的。模型参数的优点在于它们在记忆事实方面非常节省内存。你可能每个模型参数能记忆一个事实。而如果上下文中有某个词元，每一层都有大量的键值对，每个词元可能需要**千字节**（kilobyte）甚至**兆字节**（megabyte）的内存。**Dwarkesh Patel**补充说，一个词元可能会被扩展到10**千字节**。**Jeff Dean**表示，是的，目前有很多创新围绕着如何最小化这些内存消耗，以及需要哪些词元，是否有更好的方式访问这些信息片段。**Noam**认为**Jeff**似乎是解决这个问题的合适人选，比如如何设计从**SRAM**（SRAM: Static Random-Access Memory，静态随机存取存储器）到全球数据中心的内存层次结构。

**Dwarkesh Patel**想进一步探讨**Google**作为一家拥有大量代码和示例的公司，如何利用AI。他提到**Google**的**单体仓库**（monorepo: 一种软件开发策略，将所有项目的代码存储在一个大型版本控制仓库中）。如果解决了长上下文问题，可以将整个代码库放入上下文或进行微调。为什么这项工作还没有完成？**Dwarkesh**指出，可以想象**Google**拥有多少专有代码，即使仅在内部使用也能提高开发者的效率和生产力。

**Jeff Dean**澄清说，他们实际上已经对**Gemini**模型进行了进一步训练，用于内部开发者的内部代码库。但这与“处理所有代码”不同，因为训练会将代码库混合到参数中，而将其置于上下文会使事情更清晰。但即使是经过进一步训练的内部模型也极其有用。**Sundar Pichai**（Sundar Pichai: Google首席执行官）曾表示，目前**Google**代码库中约有25%的字符是由他们基于AI的编码模型在人工监督下生成的。

**Dwarkesh Patel**询问，在未来一两年内，基于目前可见的能力，他们如何想象自己的个人工作？作为**Google**的研究员会是什么样子？当他们有一个新想法时，一年后与这些模型的互动方式会是怎样的？**Noam Shazeer**认为，模型会变得更好，生产力也会大大提高。

**Jeff Dean**补充说，除了研究背景，这些模型在任何地方使用时，都能提高软件开发者的生产力，因为它们可以根据高层规范或一句话描述来完成任务，并提供一个相当合理的初稿。从研究角度看，你可能会说：“我希望你探索一种类似于这篇论文中的想法，但也许我们可以尝试使其卷积化。”如果系统能够自动生成大量实验代码，你查看后觉得“嗯，看起来不错，运行它”，那将是一个美好的梦想方向。**Dwarkesh**认为，未来一两年内在这方面取得很大进展是很有可能的。

### AI驱动的芯片设计与智能爆炸

**Noam Shazeer**认为，这似乎被低估了，因为你可能拥有数百万额外的“员工”，可以立即检查他们的输出，员工之间也可以互相检查输出，并立即传输词元。**Jeff Dean**表示他并非想低估它，他觉得这非常令人兴奋，只是不喜欢炒作尚未完成的事情。

**Dwarkesh Patel**想深入探讨这个想法，因为拥有“自主软件工程师”似乎意义重大，特别是对于研究人员来说，他们想构建系统。他问，作为职业生涯中一直致力于开发变革性系统的人，如果不再需要编写像**MapReduce**或**Tensorflow**这样的代码，而只是说“我想要一个分布式AI库看起来像这样，帮我写出来”，那么生产力会提高10倍还是100倍？

**Jeff Dean**表示他对此印象深刻。他曾在**Reddit**上看到，有人尝试了他们一个新的实验性编码模型，这个模型在编码和数学方面表现出色。外部用户提示模型：“我希望你实现一个没有外部依赖的**SQL**（SQL: Structured Query Language，结构化查询语言，用于管理关系数据库的编程语言）处理数据库系统，并用**C语言**实现。”据该用户说，模型完成得相当好。它生成了一个**SQL**解析器、一个词法分析器、一个查询规划系统以及磁盘数据存储格式，并且能够处理简单的查询。从一个段落的提示文本就能得到这样的初步成果，这对于软件开发者来说是巨大的生产力提升。

**Jeff**认为，未来可能会出现其他类型的系统，它们可能不会尝试在40秒内完成一个半交互式的响应，而是可能运行10分钟，并在5分钟后中断，询问：“我已经完成了大部分工作，但现在需要一些输入。你关心处理视频还是只处理图像？”如果有很多这样的后台活动，你将需要管理工作流的方法。

**Dwarkesh Patel**追问，如果能启动数百万甚至数十万个能够超高速打字的“员工”，他们需要什么样的界面？这就像从1930年代的票据交易发展到现代的**Jane Street**（Jane Street: 一家量化交易公司）。你需要一个界面来跟踪所有这些活动，让AI融入这个大型**单体仓库**并发挥各自优势，让人类也能跟踪发生的一切。**Dwarkesh**问，三年后**Jeff**或**Noam**的日常工作会是怎样的？

**Noam Shazeer**认为，可能与现在类似，因为他们已经面临并行化这个主要问题。他们有许多杰出的机器学习研究人员，希望他们能协同工作构建AI。所以，人与人之间的并行化可能类似于机器之间的并行化。他认为这对于需要大量探索的工作肯定有益，比如“提出下一个突破”。如果你有一个在机器学习领域肯定会奏效的绝妙想法，即使你很聪明，它也只有2%的成功机会。大多数时候这些想法都会失败，但如果你尝试100个、1000个甚至100万个想法，你可能会发现一些惊人的东西。他们有足够的计算资源。现在顶尖的实验室拥有的计算能力可能比训练**Transformer**时多一百万倍。

**Dwarkesh Patel**觉得这是一个非常有趣的想法。他假设目前全球有大约1万名AI研究人员每年能带来**Transformer**级别的突破，概率是10%。如果这个社区扩大一千倍，就像这种并行搜索更好的架构和技术一样，那么他们是否会每天都看到一个突破？**Noam**认为“也许吧，听起来可能不错。”

**Dwarkesh**问，这是否符合机器学习研究的实际情况？如果能够尝试所有这些实验……**Jeff Dean**认为这是一个好问题，因为他不确定人们是否已经做了那么多。他们确实有很多好想法不断涌现。每个人似乎都想以最大规模运行实验，但他认为这是一个人类问题。拥有一个千分之一规模的问题，然后验证10万个想法，再扩大那些看起来有前景的想法，这非常有帮助。

**Jeff**指出，世界可能没有认真对待的一点是：人们知道将模型扩大100倍会呈指数级困难，需要100倍的计算量。所以人们担心从**Gemini 2**到**Gemini 3**会呈指数级困难。但人们可能没有意识到另一个趋势：**Gemini 3**正在提出所有这些不同的架构想法，进行尝试，然后你看到哪些有效，并且你不断取得算法进步，使得训练下一个模型变得越来越容易。这个反馈循环能走多远？

**Jeff**认为，人们应该意识到，这些模型代际之间的改进，部分是由硬件和更大规模驱动的，但同样甚至更重要的是由重大的算法改进、模型架构的重大变化、训练数据组合等因素驱动的，这些因素使得模型在每单位浮点运算（flop）下表现更好。他认为这是一个很好的认识。然后，如果他们能实现想法的自动化探索，就能够验证更多的想法，并将其引入到下一代模型的实际生产训练中。

这将非常有帮助，因为这正是他们目前与许多杰出的机器学习研究人员正在做的事情：审视大量想法，筛选出在小规模下表现良好的，看看它们在中等规模下是否有效，将其引入更大规模的实验，然后最终确定将大量新的有趣事物添加到最终的模型配方中。如果他们能通过机器学习研究人员仅仅温和地引导一个更自动化的搜索过程，而不是亲自“照看”大量实验，从而将这个过程加快100倍，那将是非常非常有益的。唯一不会加速的是最大规模的实验。你仍然会进行这些N=1的实验。实际上，你只是把一群聪明人召集到一起，让他们盯着这个东西，找出它为什么有效，为什么无效。对于这一点，更多的硬件是一个好的解决方案，更好的硬件也是。**Noam**开玩笑说：“是的，我们指望你了。”

### 芯片设计与AI加速的反馈循环

**Dwarkesh Patel**指出，从软件层面和算法层面，未来的AI都可以带来改进。**Jeff Dean**正在研究如何大幅加速芯片设计过程。他提到，目前设计一款芯片大约需要18个月，从“我们应该制造一款芯片”到将其交付给**TSMC**（TSMC: 台湾积体电路制造股份有限公司，全球最大的专业集成电路制造服务公司）。然后**TSMC**需要四个月来制造，之后芯片才能回到数据中心。这是一个相当漫长的周期，而制造时间在其中只占一小部分。但如果能让制造时间成为主导部分，将150人花费12到18个月的芯片设计时间缩短到几个人通过更自动化的搜索过程完成，探索整个芯片设计空间，并从芯片设计过程的各个方面获取反馈，那么就能实现更多的探索和更快速的设计，从而得到他们真正想要交付给工厂的产品。

这将非常棒，因为可以缩短制造时间，通过正确设计硬件来缩短部署时间，这样芯片回来后就可以直接插入系统。这将实现更多的专业化，缩短硬件设计周期，这样就不必提前太久去预测哪些机器学习算法会变得有趣。相反，你只需考虑未来六到九个月需要什么，而不是两到两年半。**Jeff**认为那会非常酷。**Dwarkesh**补充说，如果制造时间成为改进的内部循环，那将……他问制造时间是多久？**Jeff**回答说，最先进的节点不幸地需要越来越长的时间，因为它们比以前的老节点有更多的金属层，所以通常需要三到五个月。

**Dwarkesh Patel**认为，三到五个月的制造时间，与训练运行的时间差不多，所以理论上可以同时进行。**Jeff**表示有可能。**Dwarkesh**总结说，虽然无法缩短到三到五个月以内，但同时也在快速开发新的算法思想，这些可以快速推进，在现有芯片上运行并探索大量酷炫的想法。

**Dwarkesh**问，这是否意味着AI能力会像一个**S形曲线**（sigmoid: 一种S形函数，常用于描述事物从缓慢增长到快速增长再到饱和的过程）一样，在人类智能的尾端出现能力爆炸，以越来越快的速度变得更聪明？**Jeff Dean**认为“很有可能”。他喜欢这样思考：现在，模型可以处理一个相当复杂的问题，并在内部将其分解成一系列步骤，然后将这些步骤的解决方案拼凑起来，通常能为你提供所问整个问题的解决方案。但它并不是超级可靠，擅长将问题分解成五到十个步骤，而不是一百到一千个步骤。所以，如果能从“80%的时间能完美回答十步长的问题”提升到“90%的时间能完美回答一百到一千步子问题”，那将是这些模型能力上的惊人飞跃。他们尚未达到，但这正是他们渴望实现的目标。**Noam Shazeer**开玩笑说：“我们不需要新硬件来实现，但我们乐意接受。”**Jeff**回应：“永远不要拒绝送上门的新硬件。”

### 推理时间计算的巨大潜力

**Noam Shazeer**指出，未来一个重要的改进领域是**推理时间计算**（inference time compute），即在推理时投入更多计算资源。他喜欢这样描述：即使是一个巨型语言模型，即使你每词元进行万亿次运算（这比大多数人目前做的要多），每次运算的成本也大约是10的负18次方美元。所以你每美元可以获得一百万个词元。相比之下，一个相对便宜的消遣——买一本纸质书阅读，你每美元支付1万个词元。与语言模型对话比阅读平装书便宜100倍。

因此，这里有巨大的空间可以提升，例如，如果能让模型更昂贵但更智能，因为我们比阅读平装书便宜100倍，比与客户支持代理交谈便宜1万倍，比雇佣软件工程师或咨询医生律师便宜一百万倍甚至更多。我们能否增加计算量，让它变得更智能？**Noam**认为，未来非常近期的AI发展将主要以这种形式出现。过去他们一直在利用和改进预训练和后训练，这些方面将继续改进。但利用“在推理时更努力思考”将带来爆炸式增长。

**Jeff Dean**补充说，推理时间的一个方面是，你希望系统能够积极探索一系列不同的潜在解决方案。也许它会自己进行一些搜索，获取一些信息，消化这些信息，然后发现“哦，我现在真的想了解更多关于这个事物的信息”。所以它会迭代地探索如何最好地解决你向系统提出的高层问题。**Jeff**认为，如果有一个“旋钮”，你可以通过增加推理时间计算来让模型给出更好的答案，他们现在有很多技术可以做到这一点。你转动旋钮越多，计算成本越高，但答案质量也越好。这似乎是一个很好的权衡，因为有时你需要非常努力地思考，因为这是一个极其重要的问题。有时你可能不想花费大量的计算资源来计算“1加1等于几”。也许系统应该决定使用计算器工具，而不是一个非常大的语言模型。

### 异步推理与数据中心规划

**Dwarkesh Patel**询问，是否存在阻碍线性扩展推理时间计算的障碍？或者这基本上是一个已解决的问题，他们知道如何投入100倍、1000倍的计算量，并获得相应更好的结果？**Noam Shazeer**表示，他们正在研究算法。他相信随着超过1万名研究人员（其中许多在**Google**）的努力，他们会看到越来越好的解决方案。

**Jeff Dean**认为，在他们自己的实验工作中，确实有一些例子表明，如果投入更多的推理时间计算，答案会比只投入10倍计算量时更好。这看起来很有用且重要。但他们希望的是，当投入10倍计算量时，答案质量能比现在有更大的提升。所以，这关乎设计新算法、尝试新方法，找出如何最好地利用这10倍的资源来改进事物。

**Dwarkesh Patel**问，这更像搜索，还是更像在线性方向上持续更长时间？**Jeff Dean**非常喜欢**Rich Sutton**（Rich Sutton: 强化学习领域著名研究员）关于“**苦涩的教训**”（The Bitter Lesson: Rich Sutton提出的一种观点，认为在AI领域，通过大规模计算和通用学习方法往往比人类设计的复杂知识表示和算法更有效）的论文。这篇一页纸的论文精髓在于：你可以尝试很多方法，但两种极其有效的方法是学习和搜索。你可以算法上或计算上应用和扩展它们，通常会比其他任何方法获得更好的结果，并且可以应用于相当广泛的问题。

**Noam Shazeer**认为，搜索必须是花费更多推理时间解决方案的一部分。也许你探索几种不同的解决问题的方法，其中一种不起作用，但另一种效果更好，你就会更多地探索后者。

**Dwarkesh Patel**询问，这如何改变他们未来的数据中心规划？这种搜索可以在哪里异步进行？必须在线还是离线？这如何改变所需园区的规模以及其他考量？**Jeff Dean**指出，一个普遍趋势是，推理时间计算——即你有一个已经训练好的模型，并想对其进行推理——将成为一个日益增长且重要的计算类别。也许你会希望硬件更多地围绕这一点进行专业化。实际上，第一个**TPU**就是专门用于推理的，并非为训练设计。后来的**TPU**则更多地为训练和推理而设计。但当你想在推理时大幅增加计算量时，更专业的解决方案将变得非常有意义。

**Dwarkesh Patel**问，这是否意味着可以容纳更多的异步训练？**Jeff**纠正道：“训练？还是推理？”**Dwarkesh**澄清说，或者只是不同数据中心之间不需要互相通信，它们可以各自进行大量计算。**Jeff**喜欢这样思考：你正在进行的推理是否对延迟敏感？比如用户正在积极等待结果，还是一个后台任务？也许他有一些推理任务，想在一整批数据上运行，但不是针对特定用户，只是想对其进行推理并提取一些信息。

**Jeff**认为，目前他们这类工作还不多，但他们在一周前发布的深度研究工具中已经看到了端倪。你可以给它一个相当复杂的高层任务，比如：“嘿，你能去研究一下可再生能源的历史，以及风能、太阳能和其他技术成本的趋势，然后把它整理成一个表格，给我一份完整的八页报告吗？”然后它会返回一份包含大约50个参考文献的八页报告。这相当了不起。但你不会主动等待一秒钟。它需要一两分钟才能完成。**Jeff**认为未来会有很多这种类型的计算，而这会涉及到一些用户界面问题。例如，如果一个用户有20个这样的后台异步任务正在进行，而且每个任务可能都需要从用户那里获取更多信息，比如：“我找到了你飞往**柏林**的航班，但没有直飞航班。你能接受转机吗？”当需要更多信息，然后又想把它放回后台继续执行（比如寻找**柏林**的酒店）时，这种流程如何运作？**Jeff**认为这会非常有趣，推理将非常有用。

### 异步训练与模型调试

**Noam Shazeer**补充说，推理将非常有用。推理在计算效率方面也有训练所不具备的优势。通常，**Transformer**在训练时可以将序列长度用作批次，但在推理时则不能，因为你是一次生成一个词元。因此，他们可能会设计不同的硬件和推理算法，以提高推理效率。

**Jeff Dean**举例说明算法改进，例如使用**草稿模型**（drafter models）。你有一个非常小的语言模型，在解码时一次生成一个词元，它会预测四个词元。然后你把这四个词元交给大模型，让它检查哪些词元是同意的。如果你同意前三个，那么你就直接前进。这样，你基本上就能够在大型模型中进行四词元宽度的并行计算，而不是一词元宽度的计算。这些都是人们正在研究的提高推理效率的方法，以避免单词元解码的瓶颈。**Dwarkesh Patel**总结道，基本上大模型被用作验证器。**Jeff**表示同意：“是的，你能验证一下吗？”

**Dwarkesh Patel**指出，目前关于电力供应的讨论很多，例如核电站的电力已经不足以支撑单一园区。他问，是必须在一个地方拥有2吉瓦、5吉瓦的电力，还是可以更分布式地进行模型训练？这种新的推理扩展模式是否使不同的考量变得可行？他们现在如何看待多数据中心训练？

**Jeff Dean**回答说，他们已经在这样做了，他们支持多数据中心训练。在**Gemini 1.5**技术报告中，他们提到使用了多个都市区，并在每个地方进行部分计算训练。数据中心之间有较长的延迟但高带宽的连接，这运行良好。训练过程很有趣，因为大型模型的每个训练步骤通常至少需要几秒钟。所以，50毫秒的延迟影响不大。**Dwarkesh**补充说，只需要带宽。**Jeff**同意，只要能在一步之内同步模型的所有参数并累积所有梯度，就能运行得很好。

**Jeff**还提到，即使在早期的**Brain**团队时期，当他们使用非常慢的**CPU**机器时，也做了很多工作。他们需要进行异步训练来帮助扩展，每个模型副本会进行一些局部计算，将梯度更新发送到中央系统，然后异步应用。另一个模型副本也会做同样的事情。这会让模型参数稍微“摆动”，让人们对理论保证感到不安，但实际上似乎是有效的。

**Noam Shazeer**补充说，从异步到同步的转变非常令人愉快，因为现在实验是可复现的，而不是结果取决于同一台机器上是否有网络爬虫在运行。所以，他非常乐意在**TPU**集群上运行。**Jeff**则表示他喜欢异步性，因为它能实现更大的扩展。

**Dwarkesh Patel**开玩笑说：“用两部**iPhone**和一台**Xbox**之类的？”**Jeff**回应：“是的，如果我们能给你异步但可复现的结果呢？”**Dwarkesh**感到惊喜。**Jeff**解释说，一种方法是有效记录操作序列，例如哪个梯度更新何时在哪个批次数据上发生。你不需要在日志中记录实际的梯度更新，但可以重放操作日志，从而实现可重复性。那样**Dwarkesh**就会满意了。**Dwarkesh**表示可能吧，至少可以调试发生了什么，但可能无法比较两次训练运行。因为，他改变了一个超参数，但同时也有网络爬虫在捣乱，很多人同时在观看**超级碗**。

**Jeff Dean**解释说，从**CPU**上的异步训练转向完全同步训练的原因是他们拥有超高速的**TPU**硬件芯片和集群，这些集群内的芯片之间拥有惊人的带宽。在此基础上，他们通过优秀的数据中心网络，甚至跨都市区网络，将规模扩展到多个都市区的许多集群，用于最大规模的训练运行。他们可以完全同步地完成这些。正如**Noam Shazeer**所说，只要梯度累积和跨都市区参数通信的速度足够快，相对于步骤时间来说，就没问题。你不会真正关心。但**Jeff**认为，随着规模的扩大，他们的系统可能会比现在更倾向于异步性，因为他们可以使其工作。他们的机器学习研究人员对同步训练能推进到如此程度感到非常满意，因为它是一个更容易理解的心理模型。你只需要让算法与你“对抗”，而不是异步性和算法同时与你“对抗”。

**Noam Shazeer**补充说，随着规模的扩大，会有更多事情与你“对抗”。这就是扩展的问题所在，你并不总是知道是什么在与你“对抗”。是你把量化推得太远了吗？还是你的数据有问题？**Jeff**开玩笑说：“也许是你的对抗性机器**MUQQ17**正在设置你所有梯度指数的第七位。”**Noam**补充道，所有这些都会让模型稍微变差，所以你甚至不知道发生了什么。

**Jeff**认为，神经网络的一个问题是它们对噪声的容忍度很高。你可以在很多方面设置错误，它们仍然能找到方法来解决或学习。**Noam**补充说，你的代码中可能有bug。大多数时候这不会产生任何影响。有时它会让你的模型变差。有时它会让你的模型变好。然后你发现了一些新东西，因为你以前没有足够的预算在规模上尝试这个bug。

**Dwarkesh Patel**问，实际调试或解码是什么样子？有些东西让模型变好，有些让模型变差。明天上班时，如何找出最重要的输入是什么？**Jeff Dean**回答说，在小规模下，他们会进行大量实验。研究的一部分是，我想独立发明这些改进或突破。在这种情况下，你需要一个简洁的代码库，可以分叉和修改，以及一些基线。他的梦想是早上醒来，想出一个想法，一天之内实现，运行一些实验，一天之内得到初步结果。比如，这个看起来有希望，这些东西奏效了，那些没有。他认为这在小规模下非常容易实现，只要你保持一个良好的实验代码库。也许一个实验需要一两个小时运行，而不是两周。这很棒。所以，这是研究的一部分，然后是某种程度的扩展。接着是集成部分，你希望将所有改进叠加在一起，看看它们在大规模下是否有效，看看它们是否协同工作。

**Dwarkesh Patel**问，它们如何交互？**Jeff Dean**回答说，你可能认为它们是独立的，但实际上，改进视频数据输入处理方式与更新模型参数的方式之间可能存在一些有趣的交互。也许这种交互对视频数据的影响比其他事物更大。各种意想不到的交互都可能发生。所以，你需要运行这些实验，将许多东西组合在一起，然后定期确保你认为好的东西在一起也表现良好。如果不是，就要弄清楚它们为什么不能很好地协同工作。

**Dwarkesh Patel**问了两个问题：第一，这种情况（即各种改进无法很好地协同工作）发生的频率有多高？是罕见还是经常发生？**Jeff Dean**回答说：“50%的时间。”**Noam Shazeer**补充说，大多数东西你甚至不会尝试堆叠，因为最初的实验效果不佳，或者相对于基线显示的结果不那么有前景。然后你会单独扩展那些看起来有前景的东西。然后你会觉得：“哦，是的，这些看起来很有希望。”所以现在我要把它们包含在一个包中，尝试推进并与其他看起来有前景的东西结合。然后你运行实验，然后你会说：“哦，它们并没有那么好。我们来尝试调试一下原因。”

**Noam**表示，这里存在权衡，因为你希望你的集成系统尽可能干净，因为复杂性——**Dwarkesh**补充说：“代码库方面。”——**Noam**同意，代码库和算法上都是。复杂性会带来伤害，它会使事情变慢，引入更多风险。同时，你又希望它尽可能好。当然，每个研究人员都希望自己的发明能被采纳。所以这肯定存在挑战，但他们一直合作得很好。

### AI加速与安全：人类历史的关键时刻

**Dwarkesh Patel**回到“算法不断改进，模型随时间变得越来越好”的动态，即使不考虑硬件部分。他问，世界和他们是否应该更多地思考这个问题？他提出了两种可能的世界：一种是AI需要几十年才能缓慢改进，你可以慢慢完善，即使搞砸了也能修复，影响不大。另一种是存在一个巨大的反馈循环，这意味着**Gemini 4**和**Gemini 5**之间的两年是人类历史上最重要的两年。因为由于这个反馈循环，你可能从一个相当不错的机器学习研究员跃升到超人类智能。如果他们认为第二种世界是可能的，那么他们如何应对这些越来越高的智能水平？

**Noam Shazeer**开玩笑说，他已经停止清理车库了，因为他在等机器人来做。所以他可能更倾向于第二种情况，即他们将看到很多加速。**Jeff Dean**认为，理解正在发生的事情和趋势极其重要。他认为目前趋势是模型一代比一代好得多，而且在未来几代中可能不会放缓。这意味着两到三代之后的模型将能够……回到将简单任务分解成10个子任务并80%时间完成的例子，未来模型将能够将一个非常高层级的任务分解成100或1000个子任务，并90%时间正确完成。这是模型能力上的一个重大飞跃。

**Jeff**认为，人们理解该领域进展的重要性。然后，这些模型将被应用于许多不同领域。他认为，确保社会从这些模型中获得最大利益来改善事物是非常好的。他非常兴奋地看到教育和医疗保健等领域，信息变得对所有人可访问。但他们也意识到，这些模型可能被用于散布错误信息，可能被用于自动化攻击计算机系统。他们希望尽可能设置更多的保障措施和缓解措施，并理解模型的能力。**Jeff**认为**Google**作为一个整体，对如何处理这个问题有很好的看法。他们的**负责任AI原则**（Responsible AI principles: Google制定的一套指导AI开发和部署的伦理原则）是一个很好的框架，用于思考在不同背景和设置下提供越来越好的AI系统时的权衡，同时确保他们在模型安全、避免产生有害内容等方面做正确的事情。

**Dwarkesh Patel**指出，如果从人类历史的角度来看，如果他们处于这样一个世界：对**Gemini 3**的后训练做得不好，它可能会产生一些错误信息——但你可以修复后训练。这是一个糟糕的错误，但它是可修复的错误。然而，如果存在这种反馈循环动态，那么导致智能爆炸的错误可能是失调的，它可能不是在尝试编写你认为它正在编写的代码，而是优化了其他目标。在这个持续几年甚至更短的快速过程中，你可能会得到接近**Jeff Dean**或**Noam Shazeer**水平甚至超越他们的智能。然后你会有数百万个**Jeff Dean**级别的程序员副本——总之，这似乎是一个更难恢复的错误。**Jeff Dean**同意，随着这些系统变得越来越强大，你必须越来越小心。

**Jeff**表示，对此存在两种极端观点。一种是：“天哪，这些系统将在所有方面都比人类强得多，我们将不堪重负。”另一种是：“这些系统将非常棒，我们根本不必担心它们。”他认为自己处于中间。他曾合著一篇名为《塑造AI》的论文，其中提到这两种极端观点通常将他们的角色视为“自由放任”，认为AI会沿着自己的道路发展。**Jeff**认为，实际上有一个很好的论点可以说明，他们要做的是尝试塑造和引导AI在世界上的部署方式，使其在他们希望获取和受益的领域（如教育、医疗保健等）中实现最大利益。并通过政策相关措施、技术手段和保障措施，尽可能地引导它远离“计算机将接管并拥有无限控制权”的局面。所以，**Jeff**认为这是一个工程问题：如何工程化安全的系统？

**Jeff**认为，这有点像他们在老式软件开发中所做事情的现代版。例如，看看飞机软件开发，它在如何严谨开发用于执行相当危险任务的安全系统方面有着良好的记录。**Dwarkesh Patel**指出，这里的困难在于，飞机**波音737**没有那种反馈循环，你把它和一堆计算资源放在一个盒子里几年，它就能进化出1000版本。

**Noam Shazeer**认为，好消息是分析文本似乎比生成文本更容易。因此，他相信语言模型分析语言模型输出并找出问题或危险之处的能力，将是解决许多控制问题的方案。**Jeff Dean**表示，他们肯定正在研究这些。**Google**有许多杰出人才正在从事这项工作。他认为，这不仅从“为人们做好事”的角度，也从商业角度来看，将变得越来越重要。很多时候，你能够部署什么，取决于能否保持系统安全。因此，在这方面做到非常出色变得极其重要。

### 开放研究、竞争与Google的AI策略

**Dwarkesh Patel**表示，他知道**Google**认真对待潜在的收益和成本，这确实非常了不起。他认为**Google**在这方面获得的赞誉还不够，因为他们推出了如此多利用这些模型来改善各个领域的应用。但**Dwarkesh**再次强调，如果存在这种反馈循环过程，那么最终可能会出现一个模型，其能力与**Noam Shazeer**或**Jeff Dean**一样出色。如果有一个“邪恶版本”的**Jeff Dean**在外面跑，假设有一百万个这样的“邪恶**Jeff Dean**”，那将是非常非常糟糕的事情，可能比核战争等任何其他风险都更糟。**Noam**开玩笑说：“那我们从哪里获取训练数据呢？”

**Dwarkesh**追问，如果他们认为这种快速反馈循环过程可能产生这种结果，那么他们的计划是什么？例如，当他们拥有**Gemini 3**或**Gemini 4**，并认为它能帮助他们更好地训练未来版本，为他们编写大量训练代码时，从那时起，他们是否只是监督和验证？即使是他们提到的验证器，最终也会由他们制造的AI来训练，或者大部分代码由AI编写。在让**Gemini 4**帮助他们进行AI研究之前，他们想确定什么？他们真的想确保，在让它编写AI代码之前，他们想对它进行这项测试。

**Jeff Dean**认为，让系统探索算法研究想法，这仍然是一个由人类负责的事情。系统会探索空间，然后会得到一系列结果，然后他们会做出决定，比如，是否将这个特定的学习算法或系统更改整合到核心代码库中？他认为，可以设置这样的保障措施，让他们在人类监督下获得系统改进或自我改进的好处，而无需让系统在没有任何人监督的情况下完全自主改进。这正是他所说的工程保障措施，你需要审视你正在部署的系统的特性，不部署那些在某些方面有害的系统，并且你了解它的能力以及在特定场景下可能做什么。所以，他认为这绝不是一个简单的问题，但他确实认为有可能使这些系统安全。

**Noam Shazeer**补充说，他们也将大量使用这些系统来检查自身，检查其他系统。即使作为人类，识别事物也比生成事物更容易。**Jeff Dean**认为，如果你通过**API**（API: Application Programming Interface，应用程序编程接口）或用户界面暴露模型的能力，人们可以与之互动，那么你就拥有了一定程度的控制权，可以了解它的使用方式，并对其能力设置一些边界。他认为这是确保模型行为符合你心中设定的某些标准的重要工具之一。**Noam**表示，目标是赋能人类，但大多数情况下，他们应该让人们用这些系统做有意义的事情，并尽可能少地限制空间。但他补充说，如果你让某人利用你的系统创造一百万个邪恶的软件工程师，那并不能赋能人类，因为他们会用这些邪恶的软件工程师伤害他人。所以他反对那样做。**Jeff**也表示反对。

### 职业生涯的乐趣与未来愿景

**Dwarkesh Patel**转向轻松的话题，询问在过去25年里，哪段时光最有趣，最让他们怀念？**Jeff Dean**认为，**Google**早期四五年是他最怀念的时光。那时他只是少数几个从事搜索、爬虫和索引系统工作的人之一，他们的流量增长迅猛。他们努力扩大索引规模，并将其更新频率从每月或两月一次（如果出问题）改为每分钟一次。看到系统使用量的增长，对他个人来说非常有成就感。构建一个每天被20亿人使用的东西，这相当不可思议。

但**Jeff**也表示，同样令人兴奋的是今天与**Gemini**团队的同事们一起工作。他认为过去一年半里，这些模型的能力取得了巨大进步，这非常有趣。团队成员都非常投入，对正在做的事情充满热情。他认为模型在处理复杂任务方面越来越好。如果让20年前使用计算机的人看到这些模型的能力，他们会难以置信。即使是五年前，他们也可能不会相信。这非常有成就感。**Jeff**相信，他们将看到这些模型的使用量和对世界的影响也会出现类似的增长。

**Noam Shazeer**表示同意，早期确实非常有趣。部分原因在于认识所有人，以及社交方面，还有就是你正在构建一个被数百万人使用的东西。现在也是一样。他们有一个很棒的微型厨房区域，很多人在那里交流。他喜欢亲自与一群优秀的人一起工作，构建一个帮助数亿甚至数十亿人的产品。还有什么比这更好的呢？

**Dwarkesh Patel**询问微型厨房是什么。**Jeff Dean**解释说，他们两人所在的建筑里有一个微型厨房区域，现在名为“**梯度天篷**”（Gradient Canopy: Google内部AI研究区域的名称），以前叫**查尔斯顿东**（Charleston East）。他们觉得需要一个更令人兴奋的名字，因为那里有很多机器学习研究人员和AI研究。微型厨房区域通常只有一台意式浓缩咖啡机和一些零食，但这个地方空间很大，他们设置了大约50张桌子，所以人们都在那里闲逛。那里有点吵，因为人们总是在磨豆子、煮咖啡，但你也能获得很多面对面的交流，比如：“哦，我试过那个。你有没有想过在你的想法中尝试这个？”或者“哦，我们下周要发布这个东西。负载测试看起来怎么样？”有很多反馈发生。此外，他们还有**Gemini**聊天室，供不在微型厨房的同事使用。他们的团队遍布全球，**Jeff**大概加入了120个与**Gemini**相关的聊天室。在一个非常集中的话题上，有七个人在工作，**伦敦**的同事们分享着令人兴奋的结果。早上醒来，你就能看到那里发生了什么，或者有一大群人专注于数据，各种问题都在那里发生。这很有趣。

### 对未来计算需求的预判

**Dwarkesh Patel**指出，**Google**在预测计算需求方面的一些决策令人瞩目，例如**TPU**的诞生。他问，如果以2013年或更早的思维方式，预估到2030年，这些模型将成为服务骨干，需要持续推理和训练未来版本，那么所需的计算量会是多少？

**Jeff Dean**认为，他们将需要大量的推理计算。这是对这些强大模型最高层次的看法，因为如果提高模型质量的技术之一是扩大推理计算量，那么现在生成一些词元的一个请求突然会变得计算密集50倍、100倍甚至1000倍，尽管它产生的输出量相同。同时，这些服务的使用量也将大幅增长，因为并非世界上所有人都发现了这些基于聊天的对话界面，它们可以完成各种惊人的事情。目前可能只有10%或20%的计算机用户发现了这一点。随着这一比例推向100%，并且人们更频繁地使用它，这将带来一到两个数量级的扩展。

所以，你将从那里获得两个数量级，再从那里获得两个数量级。模型可能会更大，你将再获得一到两个数量级。你将需要大量的推理计算。因此，你需要极其高效的硬件来对你关心的模型进行推理。**Dwarkesh Patel**问，到2030年，全球总推理的浮点运算量会是多少？**Noam Shazeer**认为，更多总是更好的。如果你思考一下，届时人们会决定将全球**GDP**的多少比例花在AI上？然后，AI系统会是什么样子？

**Noam**想象，也许它会是某种个人助理，戴在你的眼镜上，能看到你周围的一切，并能访问你所有的数字信息和世界的数字信息。也许就像**Joe Biden**（Joe Biden: 美国总统），耳朵里戴着一个能实时提供任何建议、解决问题并给出有用提示的内阁。或者你可以和它交谈，它会分析你周围看到的一切，以寻找对你任何潜在的有用影响。所以他可以想象，如果它像你的个人助理或个人内阁，每次你在计算上多花一倍的钱，它就会变得更聪明5到10个**IQ**点。那么，你愿意每天花10美元拥有一个助理，还是花20美元拥有一个更聪明的助理？而且它不仅是生活助理，还能帮助你更好地完成工作，让你从一个10倍工程师变成100倍甚至1000万倍工程师？

**Noam**从第一性原理分析：人们会愿意将全球**GDP**的一部分花在这上面。由于所有这些“人工工程师”致力于改进事物，全球**GDP**几乎肯定会大幅增长，比现在高出两个数量级。届时，他们可能已经解决了无限能源和碳排放问题。所以他们应该能拥有大量能源。他们应该能拥有数百万到数十亿的机器人来为他们建造数据中心。太阳的功率是10的26次方瓦特左右？他猜测，用于AI帮助每个人的计算量将是天文数字。

**Jeff Dean**补充说，他不能完全同意，但这确实是一个非常有趣的思想实验。即使只实现了一部分，也肯定会需要大量的计算。这就是为什么拥有一个极其廉价的硬件平台来使用这些模型并将其应用于**Noam**描述的问题是如此重要，这样你就能以某种形式让所有人都能接触到它，并尽可能降低获取这些能力的成本。**Jeff**认为，通过专注于硬件和模型协同设计，他们应该能够使这些东西比现在高效得多。

**Dwarkesh Patel**询问，鉴于他们预期的需求增长，**Google**未来几年的数据中心建设规划是否足够激进？**Jeff Dean**表示，他不会评论未来的资本支出，因为他们的**CEO**和**CFO**可能不希望他这样做。但他会说，你可以看看他们过去几年的资本支出，会发现他们肯定在这个领域进行了投资，因为他们认为这很重要。他们正在继续构建新的、有趣的、创新的硬件，他们认为这确实有助于他们在向更多人部署这些系统方面获得优势，包括训练它们，以及如何让人们能够使用它们进行推理。

### 持续学习与模块化模型的未来

**Dwarkesh Patel**提到，他经常听到**Jeff Dean**谈论**持续学习**（continual learning），即模型可以随着时间推移不断改进，而无需从头开始。他问，这是否存在根本性障碍？因为理论上，你应该能够持续微调模型。**Jeff**认为这种未来会是什么样子？

**Jeff Dean**表示，他对此思考得越来越多。他一直是**稀疏模型**（sparse models: 神经网络中只有部分连接或神经元在特定时间被激活的模型）的忠实拥护者，因为他认为模型不同部分应该擅长不同事物。他们有**Gemini 1.5 Pro**模型，以及其他**专家混合模型**（Mixture of Experts: 一种神经网络架构，通过路由机制激活模型中特定“专家”子网络来处理输入，提高效率和容量），其中模型的某些部分在处理特定词元时被激活，而另一些部分则完全不激活，因为你决定这是一个数学导向的任务，这部分擅长数学，那部分擅长理解猫的图像。这使你能够拥有一个能力更强的模型，同时在推理时仍然非常高效，因为它具有非常大的容量，但你只激活了其中一小部分。

但**Jeff**认为，目前的问题，或者说他们现在工作的一个局限性是，它仍然是一个非常规则的结构，每个专家的大小都相同。路径很快就会合并。它们不会为数学相关的事情分出许多不同的分支，然后不与猫图像相关的事情合并。他认为他们可能应该拥有一个更**有机**的结构。他还希望模型的各个部分可以稍微独立地开发。例如，现在他们面临一个问题，即要训练一个模型。所以他们会做大量的准备工作，决定能想出的最棒的算法和最棒的数据组合。

但这里总有权衡，比如他们希望包含更多多语言数据，但这可能以牺牲编码数据为代价，所以模型在编码方面表现较差，但在多语言方面表现更好，反之亦然。**Jeff**认为，如果能有一小群关心特定语言子集的人，去创建真正好的训练数据，训练一个模块化的模型片段，然后可以将其连接到一个更大的模型上，从而提高其在**东南亚语言**或**Haskell**代码推理方面的能力，那将非常棒。

这样，在软件工程方面也会带来好处，因为与他们现在所做的工作相比，问题被分解了。现在他们有很多人在工作，但然后他们有一个单片式的过程，开始对这个模型进行预训练。如果他们能做到这一点，**Google**内部就可以有100个团队。全世界的人都可以致力于改进他们关心的语言或特定的问题，并共同努力改进模型。这是一种**持续学习**的形式。

**Noam Shazeer**认为那会非常棒。你可以将模型拼接在一起，或者拆下模型的片段，然后塞进其他模型中。**Jeff**补充说：“升级这个片段而不用扔掉整个东西……”**Noam**继续说：“或者你直接接上水管，从这个模型中吸取所有信息，然后塞进另一个模型。”他认为，这里存在一种与科学相悖的兴趣，即，他们仍处于快速进步的时期，所以如果你想做受控实验，并比较这个东西和那个东西，因为这有助于他们弄清楚要构建什么。在这种兴趣下，通常最好从头开始，这样你可以在实践层面比较两次完整的训练运行，因为它有助于他们弄清楚未来要构建什么。这不那么令人兴奋，但确实能带来快速进步。

**Jeff Dean**认为，通过模块化的版本系统，他们可以获得很多好处。他有一个模型的冻结版本，然后他包含一个特定模块的不同变体，他想比较它的性能或再训练一下。然后，他将其与现在包含**Haskell**（Haskell: 一种纯函数式编程语言）解释模块N'版本的基线进行比较。实际上，这可以加速研究进展，对吧？你有一个系统，你做了一些改进。如果这些改进相对于从头训练系统来说成本较低，那么它实际上可以使研究变得更便宜、更快。**Noam Shazeer**补充说，而且我认为在人与人之间也更容易并行化。**Jeff**说：“好吧，我们来弄清楚，下次就这么做。”

### 有机模型与Pathways架构

**Dwarkesh Patel**指出，这个看似随意提出的想法，实际上将是与当前做法相比的一次巨大范式转变。如果按照他们所说的方向发展，这是一个非常有趣的预测：你将拥有一个不断流水线化、来回传输信息的“**Blob**”（Blob: 指一个巨大的、不断演化的AI模型或系统），如果你想改进某个部分，就像进行一次“外科手术”一样。

**Jeff Dean**同意，或者让模型增长，在某个地方再添加一点。他一直在**Pathways**（Pathways: Google AI开发的一种新型AI架构，旨在实现多任务、多模态、高效能的AI模型训练和部署）中勾勒这个愿景。**Dwarkesh**补充说：“你一直在构建……”**Jeff**继续说：“……我们一直在构建它的基础设施。所以，**Pathways**系统的大部分功能都可以支持这种扭曲、奇怪的模型，以及对不同部分的异步更新。我们正在使用**Pathways**来训练我们的**Gemini**模型，但尚未充分利用它的一些能力。但也许我们应该这样做。”**Noam Shazeer**表示“哦，也许吧”。

**Noam**提到，有些时候，比如**TPU**集群的设置方式，他不知道是谁做的，但他们做得非常出色。低层软件栈和硬件栈，你拥有高性能的硬件，拥有出色的环形互联，然后拥有正确的低层集体通信操作，比如**all-reduces**（all-reduces: 分布式计算中的一种集体通信操作，所有进程都接收所有进程的输入数据的总和），这些可能来自超级计算领域，但事实证明它们正是构建分布式深度学习的正确基础。

### 模块化蒸馏与专家模型可解释性

**Dwarkesh Patel**提出两个问题。第一，假设**Noam**又取得了一项突破，现在有了一个更好的架构。他们会把每个模块都蒸馏到这个更好的架构中吗？这就是它持续改进的方式吗？**Jeff Dean**认为，**蒸馏**（distillation: 一种模型压缩技术，将一个大型复杂模型（教师模型）的知识转移到一个小型简单模型（学生模型）中）确实是一个非常有用的工具，因为它能让你将模型从当前的架构形式转换成另一种形式。通常，你会用它来将一个能力强大但庞大笨重的模型蒸馏成一个更小的模型，以便以非常好的低延迟推理特性进行服务。

但**Jeff**认为，你也可以将其视为在模块层面发生的事情。也许会有一个持续的过程，每个模块都有几种不同的表示形式。它有一个非常大的版本，还有一个小得多的版本，不断地蒸馏到小版本中。然后，小版本一旦完成，你就会删除大版本，并增加更多的参数容量。现在，通过更多数据训练，开始学习蒸馏后的小版本所不知道的所有东西，然后你重复这个过程。如果你的模块化模型在后台有数千个这样的进程在运行，那看起来会相当有效。

**Dwarkesh Patel**认为，这可能是实现推理扩展的一种方式，比如路由器决定你想要多大的模型。**Jeff Dean**同意，你可以有多个版本。例如：“哦，这是一个简单的数学问题，所以我要把它路由到非常小的数学蒸馏模型。哦，这个很难，所以……”

**Dwarkesh Patel**指出，至少从公开研究来看，在**专家混合模型**中，通常很难解码每个专家在做什么。如果他们有这样的系统，如何强制实现对我们可见和可理解的模块化？**Noam Shazeer**表示，过去他发现专家相对容易理解。他提到第一个**专家混合模型**论文，你可以直接查看专家。**Dwarkesh**开玩笑说：“我不知道，我只是**专家混合模型**的发明者。”**Noam**继续说，你可以看到，比如他们有1000、2000个专家。这个专家处理与圆柱形物体相关的词语。**Jeff**补充说：“这个擅长处理日期。”**Noam**说：“是的，谈论时间。”**Jeff**表示这很容易做到。

**Noam**认为，你不需要人类理解来弄清楚如何在运行时操作它，因为你只需要一个学习过的路由器来查看示例。**Jeff Dean**补充说，有很多关于模型可解释性及其内部工作原理的研究。专家级别的可解释性是这个更广泛领域的一个子问题。他非常喜欢他以前的实习生**Chris Olah**（Chris Olah: Anthropic研究员）和**Anthropic**（Anthropic: 一家专注于AI安全和研究的美国人工智能公司）其他同事所做的一些工作，他们训练了一个非常稀疏的自编码器，并能够推断出大型语言模型中某个特定神经元的特征，例如他们发现了一个“**金门大桥**（Golden Gate Bridge: 位于美国旧金山的一座著名桥梁）神经元”，当谈论**金门大桥**时它就会被激活。**Jeff**认为，你可以在专家层面、在各种不同层面做到这一点，并获得相当可解释的结果。但他认为，如果你不需要它，模型只是非常擅长某些事情，那么我们不一定关心**Gemini**模型中每个神经元在做什么，只要整个系统的集体输出和特性良好即可。这就是深度学习的美妙之处之一，你不需要理解或手动设计每一个细节。

### MoE部署挑战与Google的未来产品

**Dwarkesh Patel**表示，这有太多有趣的含义，他想继续追问。他会后悔没有问更多。一个含义是，目前如果你有一个拥有数百亿参数的模型，你可以在少数**GPU**上进行服务。但在这种系统中，任何一个查询可能只通过总参数的一小部分，但你需要将整个模型加载到内存中。**Google**投资的这种**TPU**集群（由数百或数千个**TPU**组成）将非常有价值，对吧？

**Noam Shazeer**认为，即使对于现有的**专家混合模型**，你也希望将整个模型加载到内存中。他觉得关于**专家混合模型**存在一种误解，认为好处在于你甚至不需要遍历模型中的那些权重。如果某个专家未被使用，并不意味着你不需要检索那部分内存，因为为了提高效率，你通常会以非常大的批次大小进行服务。**Dwarkesh Patel**补充说：“独立请求的批次。”**Noam**同意，所以并非在某一步，你只查看这个专家而不查看那个专家。因为如果是那样，当你查看专家时，你将以批次大小为1运行它，这将是极其低效的。现代硬件的运算强度是数百倍。所以实际情况并非如此。实际上，你是在查看所有专家，但你只需要将批次的一小部分通过每个专家。

**Jeff Dean**补充说，但你仍然在每个专家处有一个较小的批次通过。为了获得合理的平衡，当前模型通常会使所有专家具有大致相同的计算成本，然后你通过它们运行大致相同大小的批次，以在推理时传播非常大的批次并获得良好的效率。但**Jeff**认为，未来你可能经常需要计算成本相差100倍或1000倍的专家。或者在某些情况下路径经过许多层，而在另一些情况下只有一层甚至跳过连接。在这种情况下，你仍然会需要非常大的批次，但你会在推理时稍微异步地将事物推入模型，这比训练时更容易。

**Jeff**指出，这正是**Pathways**设计支持的功能之一。你拥有这些组件，组件的成本可以是可变的，你可以说，对于这个特定的示例，我想通过模型的这个子集；对于那个示例，我想通过模型的那个子集，并让系统来协调这一切。

**Dwarkesh Patel**指出，这也意味着需要特定规模和复杂度的公司才能做到这一点。现在任何人都可以训练一个足够小的模型。但如果未来训练模型的最佳方式就是这样，那么你就需要一家公司，能够拥有一个数据中心来服务一个单一的“**Blob**”或模型。所以，这也会是范式上一个有趣的变化。

**Noam Shazeer**认为，你肯定至少需要足够的**HBM**（HBM: High Bandwidth Memory，高带宽内存，一种高性能RAM接口，用于提高内存带宽）来容纳你的整个模型。所以，根据你模型的大小，那很可能就是你至少需要的**HBM**量。**Jeff Dean**补充说，这也意味着你不需要将整个模型占用空间扩展到数据中心那么大。你可能希望它稍微小一点。然后，可能复制许多份被大量使用的特定专家，以获得更好的负载均衡。这个专家被大量使用，因为他们收到了很多数学问题，而这个专家是**塔希提舞**（Tahitian dance: 塔希提岛的一种传统舞蹈）专家，它被调用的频率非常低。那个专家，你甚至可能将其分页到**DRAM**（DRAM: Dynamic Random-Access Memory，动态随机存取存储器），而不是放在**HBM**中。但你希望系统根据负载特性来解决所有这些问题。

**Dwarkesh Patel**指出，现在语言模型显然是输入语言，输出语言。显然它是多模态的。但**Pathways**的博客文章谈到了许多不同的用例，这些用例并非明显是这种自回归性质，通过同一个模型。他问，能否想象**Google**作为一个公司，其产品，比如**Google Search**、**Google Images**、**Gmail**，都通过这个系统？就像整个服务器就是一个巨大的、专业化的**专家混合模型**？

**Jeff Dean**认为，你已经开始看到一些这样的情况，即**Gemini**模型在**Google**内部被大量使用，它们不一定经过微调。它们只是针对特定用例在特定产品设置中获得指令。所以，他肯定看到底层模型的能力在越来越多的服务中得到共享。他认为这绝对是一个非常有趣的方向。**Dwarkesh Patel**表示，他觉得听众可能没有意识到这是一个多么有趣的关于AI走向的预测。这就像2018年在播客上听到**Noam**说：“是的，我认为语言模型会成为一回事。”他认为，如果事情真的朝这个方向发展，那将是极其有趣的。

**Jeff Dean**补充说，你可能会看到一个大型基础模型。然后你可能需要这个模型的定制版本，添加不同的模块以适应不同的设置，这些模块可能带有访问限制。例如，他们可能有一个供**Google**内部员工使用的内部版本，他们用内部数据训练了一些模块，并且不允许其他人使用这些模块，但他们自己可以使用。也许其他公司可以添加对该公司设置有用的其他模块，并在他们的云**API**中提供服务。

**Dwarkesh Patel**询问，实现这种系统的瓶颈是什么？是系统工程还是机器学习？**Jeff Dean**认为，这与他们目前**Gemini**的开发方式非常不同。所以，他认为他们会探索这些领域并取得一些进展。但他们需要真正看到证据，证明这是正确的方向，它有很多好处。其中一些好处可能是质量的提高，另一些可能不那么具体可衡量，比如能够并行开发大量不同模块的能力。但这仍然是一个非常令人兴奋的改进，因为他认为这将使他们能够更快地在许多不同领域改进模型的能力。

**Jeff**认为，即使是数据控制的模块化也非常酷，因为你可以拥有专门为我训练的模型部分。它知道我所有的私人数据。一个为你量身定制的个人模块会很有用。另一个方面是，你可以在某些设置中使用某些数据，但在其他设置中不能。例如，他们可能有一些**YouTube**数据，只能在**YouTube**产品界面中使用，而不能在其他设置中使用。所以，他们可以有一个专门为该目的而用该数据训练的模块。**Noam Shazeer**开玩笑说：“我们将需要一百万个自动化研究人员来发明所有这些东西。”**Jeff**回应：“那会很棒的。”**Noam**继续说：“是的，它本身，你构建了这个**Blob**，然后它会告诉你如何让这个**Blob**变得更好。”**Jeff**补充说：“**Blob 2.0**。或者也许它们甚至不是版本，它只是一个渐进增长的**Blob**。”

### 有机模型：借鉴生物大脑的未来AI架构

**Dwarkesh Patel**请**Jeff Dean**从宏观角度阐述，为什么这是一个好主意？为什么这是下一个方向？**Jeff Dean**表示，这种有机而非严格数学构建的机器学习模型的概念，他已经思考了一段时间。他觉得在神经网络（人工神经元）的发展中，从生物神经元中汲取灵感是一个很好的方向，并且在深度学习领域取得了很好的效果。他们在这方面取得了很大进展。但他觉得他们可能没有像本可以那样，更多地关注真实大脑的其他功能。这并不是说他们应该完全模仿，因为硅和湿件（wetware: 指生物大脑或神经系统）具有非常不同的特性和优势。但他确实认为，他们可以从“拥有不同专业化部分，即大脑模型中擅长不同事物的区域”这个概念中汲取更多灵感。

**Jeff**指出，他们在**专家混合模型**中已经有了一些这样的特性，但它仍然非常结构化。他觉得这种更**有机**的专业知识增长，以及当你需要更多这种专业知识时，你可以为模型增加更多容量，让它在这种类型的事物上学习更多，这种方式会更好。

此外，将模型的连接性与硬件的连接性相适应也是一个好主意。**Jeff**认为，你希望在同一芯片和同一**HBM**（HBM: High Bandwidth Memory，高带宽内存）之间的人工神经元之间有极其密集的连接，因为这不会花费太多成本。但你希望与附近的神经元有较少数量的连接。例如，隔着一个芯片，你应该有一些连接；再隔很多芯片，连接数量应该更少，你只能通过非常有限的瓶颈传输最重要的信息，供模型的其他部分使用。即使跨多个**TPU**集群，你也希望传输更少的信息，但却是最显著的表示。而跨都市区，你希望传输的信息更少。

**Dwarkesh Patel**问：“然后它会自然而然地出现吗？”**Jeff Dean**回答：“是的，我希望它能自然而然地出现。”你可以手动指定这些特性，但他认为你并不知道这些连接的正确比例是多少，所以你应该让硬件来决定一些事情。例如，如果你在这里进行通信，并且这些数据总是很早出现，那么你应该添加更多的连接，这样它就会花费更长时间，并在恰当的时间出现。

### AI使用模式的转变与蒸馏技术的未来

**Dwarkesh Patel**提出了另一个有趣的含义：现在，我们认为AI使用的增长是一种横向增长——例如，**Google**会有多少AI工程师为其工作？你可能会考虑**Gemini 3**会有多少个实例同时运行。但如果你有这个“**Blob**”，它可以有机地决定激活多少自身，那么它更像是，如果你想要10个工程师的输出，它只是激活一个不同的模式或更大的模式。如果你想要100个工程师的输出，它不是调用更多的代理或实例，而只是调用不同的子模式。

**Jeff Dean**认为，这里有一个概念是“你愿意为这个特定推理花费多少计算量”，这对于非常简单和非常困难的任务来说，可能相差1万倍，甚至100万倍。它可能是迭代的，你可能会对模型进行一次遍历，得到一些结果，然后决定现在需要调用模型的其他部分。

**Jeff**补充说，这听起来部署起来会非常复杂，因为它是一个奇怪的、不断进化的东西，可能在组件之间没有超级优化的通信方式，但你总是可以从中进行蒸馏。如果你说：“这是我真正关心的任务类型，让我从这个巨大的有机体中蒸馏出一个我知道可以高效服务的模型”，你可以随时进行这个蒸馏过程，一天一次，一小时一次。这看起来会很好。**Noam Shazeer**同意：“是的，我们需要更好的蒸馏技术。”**Jeff**补充说：“是的。任何发明出惊人蒸馏技术的人，能够瞬间将一个巨大的**Blob**蒸馏到你的手机上，那将是美妙的。”

**Dwarkesh Patel**询问，如何描述当前蒸馏技术所缺乏的东西？**Noam Shazeer**回答：“我只是希望它能更快。”

**Jeff Dean**认为，他们还需要在预训练过程中采用有趣的学习技术。他认为他们目前没有从每个词元中提取最大价值，也许他们应该更努力地思考一些词元。当模型遇到“答案是”时，也许在训练时，模型应该比遇到“的”时做更多的工作。**Noam Shazeer**同意，肯定有办法从相同数据中获取更多信息，让模型正向和反向学习。**Jeff**补充说，以及各种方式。以这种方式隐藏一些东西，以那种方式隐藏一些东西，让它从部分信息中推断。他认为人们在视觉模型中已经这样做了很长时间。你扭曲模型或隐藏部分图像，并尝试让它从图像的右上角或左下角猜测出这是一只鸟。这使得任务更难，**Jeff**觉得对于文本或编码相关的数据也有类似之处，你希望强迫模型更努力地工作，你将从中获得更有趣的观察结果。

**Noam Shazeer**指出，图像领域的人没有足够的标注数据，所以他们不得不发明所有这些东西。**Jeff Dean**补充说，他们发明了——**dropout**（dropout: 神经网络训练中的一种正则化技术，随机丢弃神经元以防止过拟合）是在图像上发明的，但他们主要没有将其用于文本。这是一种在更大规模模型中获得更多学习而不过拟合的方法，只需对全球文本数据进行100个**epoch**（epoch: 神经网络训练中数据迭代的次数），并使用**dropout**。

但这在计算上非常昂贵，但这意味着他们不会耗尽数据。尽管人们说：“哦不，我们几乎没有文本数据了”，**Jeff**并不相信，因为他认为他们可以从现有文本数据中获得能力更强的模型。**Noam**指出，一个人只看到了十亿个词元。**Jeff**同意，而且他们在很多方面都表现出色。

### 数据效率与未来学习范式

**Dwarkesh Patel**指出，人类的数据效率显然设定了一个下限，或者说上限，也许不是。**Jeff Dean**认为这是一个有趣的参考点。**Dwarkesh**提到，这里有一种**肯定前件**（modus ponens）和**否定后件**（modus tollens）的逻辑。一种看法是，大型语言模型还有很长的路要走，因此如果它们能与人类匹配，我们预计样本效率会提高几个数量级。另一种看法是，考虑到数量级的差异，它们可能在做一些明显不同的事情。**Dwarkesh**问，**Jeff**的直觉是，要让这些模型像人类一样具有样本效率，需要什么？

**Jeff Dean**认为，他们应该稍微改变训练目标。仅仅从之前看到的词元预测下一个词元，似乎不像人类学习的方式。他认为这与人类学习有些相关，但并非完全相同。一个人可能会阅读一本书的整个章节，然后尝试回答后面的问题，那是另一种学习方式。

**Jeff**还认为，他们没有从视觉数据中学习太多。他们对视频数据进行了一些训练，但距离思考如何训练所有可能的视觉输入还差得很远。所以，他们有尚未真正开始训练的视觉数据。然后，他认为他们可以从看到的每一位数据中提取更多信息。他认为人类样本效率高的原因之一是他们探索世界，在世界中采取行动并观察发生的事情。你看到非常小的婴儿捡起东西又放下；他们从中学习重力。当你不是主动发起行动时，这是一种更难学习的东西。**Jeff**认为，如果模型能够将采取行动作为其学习过程的一部分，那将比仅仅被动观察一个庞大的数据集要好得多。

**Dwarkesh Patel**问：“那么，**Gato**（Gato: DeepMind开发的一种多模态通用AI代理，能够执行数百种不同任务）是未来吗？”**Jeff Dean**认为，模型能够观察、采取行动并观察相应结果，这看起来非常有用。

**Noam Shazeer**补充说，人类可以从不需要额外输入的思想实验中学习很多东西。**爱因斯坦**（Einstein: 著名物理学家）从思想实验中学到了很多东西，或者像**牛顿**（Newton: 著名物理学家）在隔离期间被苹果砸到头，然后发明了万有引力。数学家——数学不需要任何额外输入。**国际象棋**，你可以让它自己下棋，然后它就变得擅长下棋。那是**DeepMind**做的，但它只需要国际象棋的规则。所以，实际上可能有很多学习即使没有外部数据也能完成，然后你可以在你关心的领域进行。当然，有些学习需要外部数据，但也许我们可以让这个东西自己对话，让自己变得更聪明。

### Transformer论文发布的回顾与Google的开放策略

**Dwarkesh Patel**提出了一个问题：**Jeff**在过去一个小时里所阐述的，可能是AI领域的下一个重大范式转变。这可能是一个极具价值的洞察。**Noam**在2017年发布了**Transformer**论文，而其他公司基于这项技术创造了数百亿甚至数千亿美元的市场价值，更不用说**Google**多年来发布的其他研究成果，他们一直相对慷慨。回过头来看，当他们想到泄露了这些对竞争对手有帮助的信息时，他们会觉得“是的，我们仍然会这样做”，还是会觉得“啊，我们没有意识到**Transformer**有多重要。我们应该把它留在内部”？他们对此有何看法？

**Noam Shazeer**认为这是一个好问题，因为他们可能确实需要看到机会的规模，这通常反映在其他公司正在做的事情中。而且，这不是一个固定大小的蛋糕。当前世界的状况远非固定蛋糕。他认为他们将看到**GDP**、健康、财富以及你能想到的任何其他方面都将有数量级的提升。所以他认为**Transformer**的普及无疑是件好事。**Dwarkesh**补充说：“它具有变革性。”**Noam**开玩笑说：“谢天谢地，**Google**也做得很好。”所以现在他们发布的研究成果比以前少了一些。

**Jeff Dean**表示，这总是一个权衡：他们应该立即发布正在做的事情吗？是应该将其纳入下一阶段的研究，然后将其推广到生产环境的**Gemini**模型中，完全不发布吗？还是存在一些中间点？例如，在**Pixel**（Pixel: Google旗下的智能手机系列）相机的计算摄影工作中，他们经常决定开发有趣的新技术，比如在低光环境下实现超强夜视功能，将其先集成到产品中，然后在产品发布后，再发表一篇关于该系统的真实研究论文。

不同的技术和发展有不同的处理方式。有些他们认为极其关键的东西可能不会发布。有些他们认为非常有趣但对改进产品很重要的东西，他们会将其整合到产品中，然后决定：是发布它，还是提供一个轻量级的讨论，但可能不包含所有细节？**Jeff**认为，其他一些东西他们会公开出版，努力推动该领域和社区的发展，因为这是他们所有人从参与中受益的方式。他认为参加像上周有15000人参加的**NeurIPS**（NeurIPS: Conference on Neural Information Processing Systems，神经信息处理系统大会，机器学习领域顶级学术会议之一）这样的会议，大家分享大量优秀想法，并看到该领域不断进步，这非常令人兴奋。

### Google在LLM领域的独特路径

**Dwarkesh Patel**询问，**Google**显然很早就内部掌握了所有这些洞察，包括顶尖研究人员。现在**Gemini 2**已经发布，虽然没有太多机会讨论它，但人们都知道它是一个非常出色的模型。**Noam Shazeer**补充说：“一个非常好的模型。就像我们在微型厨房里说的，‘一个非常好的模型，一个非常好的模型’。”**Dwarkesh**指出，它在**LMSYS Chatbot Arena**（LMSYS Chatbot Arena: 一个在线平台，用户可以匿名与不同聊天机器人进行对话并投票选出最佳表现者）中名列前茅，所以现在**Google**处于领先地位。但他问，**Google**在几年内掌握了所有这些伟大洞察，但其他竞争对手的模型却在一段时间内表现更好，这是为什么？

**Jeff Dean**解释说，他们长期以来一直在研究语言模型。**Noam**在2001年早期关于拼写纠正的工作，2007年关于翻译的超大规模语言模型工作，以及**seq2seq**（seq2seq: Sequence-to-sequence model，序列到序列模型，一种神经网络模型，用于将一个序列转换为另一个序列，常用于机器翻译）和**word2vec**（word2vec: Google开发的一种词嵌入技术，将词语映射到向量空间中，以捕捉词语之间的语义关系），以及更近期的**Transformer**和**BERT**。像内部的**Meena**（Meena: Google开发的一种基于Transformer的聊天机器人，旨在进行开放域对话）系统，实际上就是一个基于聊天机器人的系统，旨在与人进行有趣的对话。在**ChatGPT**（ChatGPT: OpenAI开发的大型语言模型，以其强大的对话能力而闻名）问世之前，他们就有一个内部聊天机器人系统供**Google**员工玩。实际上，在疫情期间，许多**Google**员工喜欢在午餐时间与**Meena**聊天，因为那就像一个很好的午餐伙伴。

**Jeff**认为，他们当时从搜索的角度看问题，这些模型会产生很多幻觉，很多时候（或者说有时）无法给出正确答案，这意味着它们不如本可以那么有用，所以他们希望改进这一点。从搜索的角度看，你理想情况下希望100%的时间都能得到正确答案，并且事实准确性非常高。这些模型远未达到这个标准。**Jeff**认为他们当时有点不确定的是这些模型究竟有多么有用。哦，而且它们还有各种安全问题，比如可能会说出冒犯性的话，他们必须解决这方面的问题，并使其达到他们可以放心发布模型的程度。但他认为他们当时没有完全意识到的是，这些模型对于你不会问搜索引擎的问题有多么有用，比如：帮我给兽医写一封信，或者：你能把这段文字给我快速总结一下吗？**Jeff**认为，这正是人们真正涌向聊天机器人，将其视为惊人的新功能，而不是纯粹的搜索引擎的原因。

所以，**Jeff**认为他们花了一些时间，最终发布了相当强大的聊天机器人，并通过**Gemini**模型不断改进它们。他认为这实际上不是一条糟糕的道路。他们是否希望更早发布聊天机器人？也许吧。但他认为他们现在拥有一个非常棒的聊天机器人，以及不断改进的**Gemini**模型。这非常酷。

### 职业生涯的广度与深度：持续学习与谦逊

**Dwarkesh Patel**总结道，他们讨论了两位在过去25年里所做的一些工作，涉及的领域非常多：从搜索和索引到分布式系统，再到硬件，再到AI算法。实际上还有成千上万个，只需查看他们任何一位的**Google Scholar**页面即可。**Dwarkesh**问，如何才能做到这种职业生涯的广度，不仅在几十年里不断取得突破，而且涉足如此多不同的领域？

**Jeff Dean**表示，他喜欢做的一件事是发现新的有趣领域。最好的方法之一是关注正在发生的事情，与同事交流，关注已发表的研究论文，并审视不断演变的科研格局。要愿意说：“哦，芯片设计。我想知道我们是否能将强化学习用于这方面的某个方面。”能够深入一个新领域，与了解不同领域（比如AI在医疗保健中的应用）的人合作。**Jeff**曾与临床医生合作，了解实际问题是什么，AI如何提供帮助？对于这个事情可能没那么有用，但对于那个事情会非常有用。

获得这些洞察力，并经常与五六位拥有不同专业知识的同事合作。这使你们能够共同完成任何一个人都无法单独完成的事情。然后他们的一些专业知识会影响你，你的一些专业知识也会影响他们，这样你作为一名工程研究员，在你的工具箱中就有了更广泛的工具集，可以去解决下一个问题。**Jeff**认为，这是在工作中持续学习的美妙之处之一。他非常珍视这一点。他真的很享受深入新事物并看看他们能做些什么。

**Noam Shazeer**认为，一个重要因素可能是谦逊，他开玩笑说自己是最谦逊的。但认真地说，要能够认为自己刚刚做的事情与自己能做或可以做的事情相比微不足道。并且一旦看到更好的想法，无论是你自己的还是别人的，就能够立即放弃旧想法。你看到你正在思考的，他们正在思考的，或者完全不同的东西可能效果更好。他认为，在某种意义上，有一种驱动力会让人说：“嘿，我刚刚发明的这个东西太棒了，给我更多的芯片。”尤其是在自上而下的资源分配很多的情况下。但**Noam**认为，他们也需要激励人们说：“嘿，我正在做的事情根本不起作用。让我完全放弃它，尝试别的东西。”

**Noam**认为**Google Brain**在这方面做得很好。他们有非常自下而上的**UBI**（UBI: Universal Basic Income，全民基本收入，这里指一种芯片资源分配模式）式的芯片分配。**Dwarkesh Patel**问：“你们有**UBI**？”**Noam**回答：“是的，基本上每个人都有一份信用额度，你可以把它们集中起来。”

**Noam**指出，**Gemini**项目主要是自上而下的管理，这在某种意义上非常好，因为它促成了更多的协作和团队合作。你很少会看到五个团队都在做同样的事情或可互换的事情。但另一方面，它也导致了一种激励，让人说：“嘿，我正在做的事情进展顺利。”然后，作为领导，你会听到数百个团队，每个人都说：“所以你应该给他们更多的芯片。”这样就减少了说“嘿，我正在做的事情实际上效果不佳。让我尝试一些不同的东西”的激励。所以**Noam**认为，未来他们将采取自上而下和自下而上相结合的方式，以激励这两种行为：协作和灵活性。他认为这两者都能带来大量创新。

**Jeff Dean**认为，阐明你认为应该前进的有趣方向也很好。他有一个内部幻灯片，名为“Go, Jeff, Wacky Ideas”（去吧，杰夫，疯狂的想法）。他认为那些更多是面向产品的东西，比如：“嘿，既然我们有了这些能力，我们可以做这17件事。”他认为这是一件好事，因为有时人们会对此感到兴奋，并想开始与你合作其中的一个或多个。他认为这是一种很好的启动方式，可以引导他们前进的方向，而无需强制命令人们：“我们必须去这里。”

**Dwarkesh Patel**总结道：“好的，这太棒了。”**Jeff Dean**和**Noam Shazeer**也表示感谢。

---