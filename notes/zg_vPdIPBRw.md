---
area: tech-insights
category: technology
companies_orgs: []
date: '2025-08-25'
draft: true
guest: ''
insight: ''
layout: post.njk
products_models: []
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=zg_vPdIPBRw
speaker: Best Partners TV
status: evergreen
summary: 强化学习之父Rich Sutton提出OaK架构，批评大语言模型路径依赖，强调AI应通过运行时经验持续学习、建立世界模型、创造开放式抽象，以实现真正超级智能的涌现，并指出当前持续学习和新特征元学习的挑战。
tags:
- ai-philosophy
- architecture
- reinforcement-learning
- superintelligence
title: 强化学习之父Rich Sutton的宏大构想：OaK架构如何让超级智能从经验中涌现
---

### 警世之言：AI发展方向的迷失与终极目标

在人工智能（AI）行业巨头们普遍追逐**缩放定律**（Scaling Laws: 指模型性能随参数量、数据量和计算量增加而提升的经验法则）之时，强化学习之父、图灵奖得主**Rich Sutton**（强化学习之父、图灵奖得主，人工智能领域的思想泰斗）却发出了警示：AI行业在某种程度上已经迷失了方向。在RLC 2025的讲台上，Sutton再次抛出了一套宏大的构想，直指AI的终极问题——**超级智能**（Superintelligence: 拥有超越人类智能水平，并能解决各种复杂问题的人工智能）将如何从经验中涌现？

他将这个架构命名为**OaK**（Options and Knowledge Architecture: Sutton提出的一个AI架构，旨在实现超级智能从经验中涌现），全称为“Options and Knowledge Architecture”。这不仅仅是一个技术框架的发布，更像是一篇檄文，深刻地批评了当前AI领域对**大语言模型**（Large Language Model, LLM: 基于海量文本数据训练，能够理解和生成人类语言的人工智能模型）的路径依赖，试图将研究焦点重新拉回到那个最经典也最核心的命题上：我们究竟该如何创造一个能够像人类一样，通过与世界互动、在生命周期中不断学习和成长的智能体？

Sutton认为，要回到通往“真正智能”的正确轨道上，我们需要做到以下几点：
1.  能够**持续学习**（Continual Learning: 智能体在面对新任务时，能够不断学习新知识，同时不遗忘旧知识的能力）的智能体。
2.  能够建立**世界模型**（World Model: 智能体对环境动态和行为后果的内部模拟或预测）并进行规划。
3.  能够学习高层次、可学习的知识。
4.  能够实现**元学习**（Meta-Learning: 学习如何学习，即智能体能够从经验中学习到更有效的学习策略或算法）**泛化**（Generalization: 模型对未见过的数据或情境表现出良好性能的能力）。

OaK架构正是他对上述所有需求的回应。Sutton在演讲中重新定义了AI研究的终极目标，形容为一场伟大的远征，其重要性堪比地球生命的起源，因为我们不仅是在制造一个强大的工具，更是在理解**心智**（Mind: 思考、感知、情感、意志等高级认知功能的总称）的本质。他指出，最大的瓶颈是我们缺乏足够的学习算法，现有的算法，包括**深度学习**（Deep Learning: 机器学习的一个分支，通过多层人工神经网络学习数据表示），都还非常粗糙。

### 大世界视角与“设计时”批判

Sutton建立了一个宏大的世界观，称之为**大世界视角**（Big World Perspective: Sutton提出的一种世界观，认为世界远比智能体庞大和复杂，智能体无法获得完整精确的知识），这是他所有思考的基石。这个视角的核心思想是世界远比智能体本身要庞大和复杂得多，包含了数十亿种其他智能体、所有原子和物体的复杂细节，以及朋友、爱人甚至敌人头脑中发生的事情。

在这个“大世界”中，智能体永远不可能获得关于世界的完整、精确的知识。因此，它的**价值函数**（Value Function: 在强化学习中，衡量在给定状态下执行某个策略所能获得的未来累积奖励的期望值）必然是近似的，**策略**（Policy: 在强化学习中，定义智能体在特定状态下选择何种动作的规则或函数）是次优的，对世界的模型也必然是高度简化的。更重要的是，由于智能体无法观察到世界的全部状态，这个世界在它看来必然也是**非平稳**（Non-stationary: 指环境的统计特性随时间变化，而非保持不变）的。

这个看似简单的假设，却直接引出了Sutton对当前AI发展路径的第一个核心批判：**设计时**（Design-time: AI模型在发布前，由人类工程师构建知识和能力的阶段）对**运行时**（Run-time: AI模型部署到真实世界后，通过与环境实时交互学习和成长的阶段）。“设计时”指的是在工厂里、在模型发布之前，由人类工程师将知识和能力构建到智能体中的阶段；而“运行时”指的是智能体被部署到真实世界后，通过与环境的实时交互来学习和成长的阶段。

Sutton毫不客气地指出，一个大语言模型的所有事情都在设计时完成，当它被部署到世界上使用的时候，它什么也不再做，不再学习了。他的观点非常明确，所有重要的事情都必须在运行时来完成。为什么？因为在一个大世界里，不可能在设计时预见到智能体将要面对的所有情况。例如，一个家用机器人需要记住主人的名字、工作项目的内容、同事是谁，这些信息都不可能预先内置在它的领域知识里，它必须在运行时去学习、去适应。

这就自然地引出了Sutton多年前提出的著名论断——**苦涩的教训**（The Bitter Lesson: Rich Sutton提出的一个观点，强调通用学习方法最终会超越特定领域知识的工程化），其中写到：“我们想要构建的，是能够像我们一样去发现的智能体，而不是包含了我们已经发现的东西的智能体。”大语言模型在某种意义上，正是包含了人类已发现知识的极致体现，它通过在设计时吞噬海量的人类知识文本，构建了一个庞大的知识库，但却缺乏在运行时发现新知识、抽象成新概念的能力。Sutton认为，这是一种本末倒置，真正的智能，其核心能力应该是在运行时的学习，而设计时提供的只应该是那些最通用的、能够支持这种学习的元方法。

不过，他也指出了当前运行时学习所面临的巨大技术瓶颈，包括**灾难性遗忘**（Catastrophic Forgetting: 持续学习中，模型在学习新任务时，对旧任务知识的快速遗忘现象）和**可塑性**（Plasticity: 模型适应新数据和学习新知识的能力）的丧失，这也造成了今天的深度学习方法在持续学习方面表现得并不好。Sutton抛出的时代之问是：当整个行业都在为缩放定律欢呼，将大模型的参数竞赛推向新的高潮时，我们是否忽略了通往真正智能所必需的、更根本的东西？而OaK架构，就是他给出的答案。

### OaK架构的三大设计准则与奖励假说

在构建OaK架构之前，Sutton首先清晰地定义了他所追寻的AI圣杯需要满足的三个核心设计目标。这三大准则支撑起了OaK架构的整个哲学思想。

**准则一：领域通用**
智能体的设计本身不应该包含任何关于特定世界的知识。这是一个非常激进但又无比纯粹的目标。Sutton强调，这并不是要否定领域知识在具体应用中的价值；如果想快速开发一个解决特定问题的应用，内置一定的领域知识当然是高效的。但是，如果目标是理解心智的本质，是寻找一个关于智能如何运作的、简洁而普适的理论，那么就必须将那些任意的、内在复杂的外部世界的细节排除在智能体的核心设计之外。智能体的任务正是去学习这个世界中那些古怪的、繁复的细节和高层结构，而不是将这些细节变成自身设计的一部分。我们想要的是一个简洁、优雅、能够理解任何世界的智能原理，而不是一个装满了特定世界知识的、复杂的百科全书。简单来说，关于特定世界的知识应该让AI自己去学习，而不是被人类工程师硬编码进去。

**准则二：完全经验主义**
智能体的心智应该完全从运行时的经验中生长出来，而不是依赖于一个特殊的训练阶段。这个准则与对设计时和运行时的讨论一脉相承。Sutton的逻辑非常清晰：既然在一个大世界中，智能体必须具备在运行时学习、规划、构建和调整抽象概念的能力，那么，为什么不将这种能力作为设计的唯一核心呢？那些在设计时预先构建的能力或许能让智能体在起跑线上抢跑，但从概念的简洁性上来看，一个只依赖运行时经验的纯粹设计无疑是更加根本、更为优雅的。也就是说，既然智能体必须有能力在运行时完成这些事，那为什么不干脆在一个地方把它们都做了呢？

**准则三：开放式抽象**
智能体应该能够持续不断地创造出任何它所需要的概念和抽象，这个复杂度的上限只应该受限于它的计算资源。这才是通往超级智能的关键。智能体不能够只停留在学习预设的特征或概念上，它必须有能力在与世界的互动中自己发现这个世界的联结，自己定义出新的、更加有用的概念，并利用这些新的概念去构建更为复杂的知识体系。同时，这个过程必须是开放的、永无止境的。

为了给这三大准则提供一个明确的目标函数，Sutton重申了他坚信不疑的**奖励假说**（Reward Hypothesis: Sutton提出的一个假设，认为所有目标和目的都可以被理解为最大化一个接收到的标量奖励信号的累积和期望值）。所有我们所说的目标和目的，都可以被很好地理解为对一个接收到的标量信号（也就是奖励）的累积和的期望值的最大化。这个假说将智能体所有复杂的行为动机统一到了一个极其简洁的数学框架下。无论是寻找食物、探索未知，还是进行艺术创作，这些行为的根本驱动力都可以被建模为最大化某个单一的标量奖励信号。在一个足够复杂的世界里，仅仅是最大化一个简单的奖励信号，就足以涌现出我们所认为的智能的所有属性。

至此，Sutton的AI圣杯画像已经逐渐清晰：那是一个领域通用的智能体，完全通过运行时的经验，在一个开放式的抽象创造过程中，以最大化标量奖励为唯一目标，最终成长为真正的超级智能。

### OaK架构的核心：选项与知识

有了清晰的目标后，我们可以来揭开OaK架构的神秘面纱。首先，让我们来拆解它的名字：OaK，也就是“Options + Knowledge”。

在**强化学习**（Reinforcement Learning: 智能体通过与环境互动，依据奖励信号学习最佳行为策略的机器学习范式）中，**Options**（选项: 在强化学习中，指一个时间上扩展的动作，包含自身策略和终止条件）指的是一个时间上扩展的动作，它不仅仅是一个**原子动作**（Atomic Action: 强化学习中最小的、不可再分的动作单元），比如向左走一步，而是一个包含了自身策略和终止条件的行为片段，比如“走到门口”这个选项。

**Knowledge**（知识: 在OaK架构中，特指执行某个Option后会发生什么的模型，是一种高层次的世界模型），在OaK架构中，特指当你执行某个Option后会发生什么的模型。这是一种更高层次的世界模型，它让你能够以更大的时间步长来进行推理和规划。因此，OaK的核心就是让智能体不断地学习新的Options，并围绕这些Options建立起关于世界的Knowledge，让智能体能够在一个更高的、更抽象的层面上理解和规划世界，从而实现在更大的时间尺度上进行跳转，并且在世界的关键节点上剖析世界。

从OaK架构的整体示意图中，我们可以看到，它包含了经典强化学习智能体的所有组件，包括从世界接收观察（Observation）和奖励（Reward），输出动作（Action），内部有策略（Policy）、价值函数（Value Function）、世界模型（Model）和规划器（Planner）。但是其中最关键的不同在于**辅助子问题**（Auxiliary Subproblems: 智能体为自己创造的、内部驱动的子任务）。

Sutton认为，智能体不应该只有一个由环境给定的主任务（比如最大化奖励信号），它必须能够为自己创造新的、内部驱动的子问题。这其实也是一个困扰AI和认知科学多年的问题：好奇心、内在动机和玩耍的本质是什么？Sutton用一个生动的例子解释了这一点：一只年幼的猩猩在树枝上摆荡，它不是为了获取食物，只是对摇摆这种感觉本身产生了兴趣；一个婴儿不断地摇晃拨浪鼓，也不是为了完成某个外部任务，而是为了重现和理解那个有趣的声音。这些所谓玩耍的行为，在Sutton看来，就是智能体在为自己设定子问题。

那么这些子问题又是从何而来的呢？Sutton给出了一个极其简洁的机制：那就是从**特征**（Feature: 智能体从感知数据中构建出的对世界状态的描述）中来。当智能体在与世界交互的时候，它的感知系统会构建出世界的状态特征。这些特征可以是任何东西，一个明亮的光斑、一个特定的声音，或者是一种特殊的感觉。

因此，OaK架构的核心思想是：任何一个足够有趣的特征，都可以成为一个新子问题的目标，而这个子问题就被定义为“尊重奖励的特征达成”。具体来说，对于某个特征i，智能体会创建一个子问题，它的目标是在不过多损失主任务奖励的前提下，尽可能地让特征i的值变高。这个定义的精妙之处在于：智能体在追求自己的小目标（比如探索一个有趣的声音时），不会完全忘记自己的大目标（比如生存），它会在两者之间进行权衡。再打个比方，为了喝到一杯咖啡（也就是达成“咖啡”这个特征），它会寻找一条安全的路径，而不会选择跳下悬崖，因为这会导致巨大的负奖励。通过这种方式，智能体得以源源不断地为自己创造出探索世界的内在动力，从而构建出一个持续发现、持续抽象的、永动机式的学习循环。

### OaK的永动学习循环：从感知到规划

Sutton将OaK架构的学习过程描述为一个由多个并行步骤构成的运行时循环，这个过程正是OaK架构中那棵智慧之树的生长脉络。

**循环的第一步：特征构建**
一切始于感知。因此，智能体需要从与世界交互的原始数据流（比如观察和动作）中，构建出对它当前所处状态的描述，也就是状态特征。Sutton强调，这个过程不是为了逼近某个人类标注的标签，或者是某个外部世界的真实状态，而是为了服务于智能体自身的决策和学习。一个特征是否有用，取决于它能否帮助智能体更好地解决问题。

**循环的第二步：提出子任务**
智能体内部有一个评估机制。当智能体构建或者发现了一个有趣的特征后，它会将这个特征本身变成一个新的目标，即一个子任务。然后，它会基于这些高价值特征，按照前面提到的“尊重奖励的特征达成”原则，生成一系列新的子问题。Sutton认为，智能体必须能够自己创造自己的子任务，而不是等待人类来设定。

**循环的第三步：学习选项**
一旦一个子任务被提出，智能体就会利用强化学习的方法，去学习一个能够完成这个子任务的策略，也就是一个Option。例如，针对“再次发出摇铃声”这个子任务，智能体可能会学到一个Option，包含了一系列特定的手臂和手腕动作，以及在听到声音后就终止的条件。于是，OaK架构中会同时存在大量这样的Options，每一个都对应着一个由特征转化而来的子任务。

**循环的第四步：模型学习**
当智能体拥有了大量的Options后，它接下来要做的就是为每一个Option学习一个模型。这个模型要回答的问题是：如果我在某个状态下启动了“发出摇铃声”这个Option，世界会发生什么变化呢？我会到达一个什么样的新状态呢？在这个过程中我会得到多少奖励呢？这是一种高层次、时间抽象的世界模型，它不再是对单步原子动作的建模，而是对整个行为片段（也就是Option）的结果进行预测。这使得智能体的规划能力得到了质的飞跃。

**循环的第五步：规划**
拥有了基于Options的高层世界模型后，智能体就可以进行高效的、长远的规划。它可以像在脑中下棋一样，推演执行一系列选项组合的后果，从而找到解决主任务的最佳宏观策略，并以此来更新自己的整体策略和价值函数。另外，当面临一个新的目标（比如主线任务的奖励发生了变化时），它不再需要从原子动作开始一步步地进行模拟推演，而是可以直接在Options的层面上进行思考。例如，它会想：“我可以先执行‘走到门口’的Option，然后再执行‘打开门’的Option”，等等。这种基于高层抽象的规划，其效率和深度远非单步规划所能比拟。Sutton强调，规划的本质就是通过模型来让价值函数与世界动态保持一致。

需要注意的是，这些步骤并非线性执行一次就结束，它们构成了一个永动的学习循环。循环的关键就在于反馈：当智能体利用学到的Options和Models进行规划的时候，它会发现某些Options对于解决主线任务特别有用，某些Options的模型更容易学习、预测更准，又或者在学习某个Option的策略或模型时，某些底层的状态特征比其他的特征更加有用。这些信息会形成一个反馈信号，反过来告诉第一步的特征构建模块哪些类型的特征是有用的、哪些是无用的。这个反馈机制会引导智能体去构建出更多、更好的新特征，而这些新特征又会成为新一轮提出子任务的原材料，从而开启新一轮的Option学习、Model学习和Planning。就这样，智能体从解决简单子任务的过程中发现了构建更复杂子任务所需要的特征，又从解决这些复杂子任务的过程中发现了构建更复杂任务的特征。这个循环不断往复，使得智能体的认知能力和抽象水平就会像滚雪球一样，不断地自我提升，最终形成一个开放式的、没有上限的智能成长阶梯。这就是Sutton对超级智能如何从经验中涌现给出的机械论的回答：智能本质上是一个自我驱动、自我创造、自我提升的永恒循环。

### 面临的挑战与OaK的深远意义

尽管OaK架构的愿景激动人心，但Sutton在演讲中也坦诚地指出了实现这个宏大愿景所面临的巨大挑战，以及当前仍然缺失的一些关键技术拼图。其中，最关键的两个老大难问题，正是视频开头提到的如何可靠的持续学习和新特征的元学习。

**挑战一：如何可靠地持续学习**
这是整个OaK架构的基石。无论是学习主线任务的价值函数和策略，还是学习成百上千个子任务的Options和Models，所有组件都必须能够在运行时持续不断地学习新知识，同时不忘记旧知识。Sutton明确指出，我们还没有可靠的、能够用于非线性函数逼近器（即深度神经网络）的持续学习算法。**灾难性遗忘**（Catastrophic Forgetting: 持续学习中，模型在学习新任务时，对旧任务知识的快速遗忘现象）的问题仍然是深度强化学习领域的一座大山。尽管已经有了许多研究方向，但目前还没有一个公认的、能够大规模应用的解决方案。

**挑战二：新特征的元学习**
这是学习循环的起点，也是最具挑战性的一环。智能体如何从零开始，自动地、创造性地生成那些有用的新特征呢？这个问题也被称为**新术语问题**（New Terms Problem: 指智能体如何自动地、创造性地生成新的、有用的概念或特征的问题），可以追溯到上世纪60年代Minsky等AI先驱的思考。Sutton认为，虽然1986年提出的**反向传播算法**（Backpropagation Algorithm: 神经网络训练中用于计算损失函数梯度的一种方法）本应该解决这个问题，但事实证明，单纯依赖**梯度下降**（Gradient Descent: 一种优化算法，通过迭代调整参数以最小化损失函数）来学习表征是远远不够的。当前的大多数方法都基于“生成与测试”的思想，也就是随机或者启发式地生成大量的候选特征，然后通过某种方式（比如对下游任务的贡献度）来评估和筛选。但是，如何设计一个高效、可扩展、而且具有创造性的特征生成器，仍然是一个开放性的核心问题。Sutton相信，解决这两个问题将会是未来几年AI领域最重要的突破。一旦我们拥有了能够持续学习的深度学习方法，它将接管人们用深度学习所做的一切。

Rich Sutton的OaK架构与其说是一个具体的算法，不如说是一个思想纲领、一个研究范式。它提醒着我们，在追逐模型参数和数据集规模的竞赛中，不要忘记AI研究最初的梦想——那就是创造一个能够自主学习、理解和改造世界的智能。

总的来说，OaK提供了一套关于心智如何运作的、极具说服力的计算理论，回答了这个领域深埋已久的一些问题：
*   高层知识如何从底层经验中学习？答案是通过循环。
*   概念是从何而来的？答案是来自于为解决子任务而构建的特征。
*   推理的本质又是什么？答案或许就是基于Option模型的规划。
*   玩耍和好奇心的目的是什么？答案是为了发现并且设定那些能够构建我们认知结构的子任务。
*   感知的目的又是什么？答案是为了形成那些能够作为子任务基础的、有用的内部概念，同时无需人类标签的监督。

对于整个AI行业而言，OaK也提供了一个全新的思考框架，一个可以指导未来几十年研究的宏大愿景。它强调了在当前大语言模型热潮中可能被大家所忽视的几个关键能力，包括基于学习模型的规划、根植于经验而非人类标签的感知，以及子问题、选项和特征的自主发现。OaK让我们开始重新思考究竟什么是真正的学习，什么又是真正的智能。正如Sutton在演讲结尾所说，OaK的愿景正是如何基于运行时的经验，培育出一个开放性的**AGI**（Artificial General Intelligence: 人工通用智能，指拥有与人类同等或超越人类智能水平，并能应用到各种任务领域的人工智能）——也许将始于经验，成于循环，达于无限。