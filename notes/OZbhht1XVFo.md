---
author: Big Think
date: '2026-02-20'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=OZbhht1XVFo
speaker: Big Think
tags:
  - semiconductor-manufacturing
  - moore-law
  - ai-infrastructure
  - global-supply-chain
  - geopolitical-competition
title: 芯片战争：现代科技的基石、全球供应链与AI未来
summary: 本文深入探讨了半导体芯片作为现代科技核心的地位，从其基本构成、纳米级制造工艺、摩尔定律的经济驱动力，到全球产业的历史演进与区域专业化格局。文章详细分析了台积电等巨头的崛起、中美芯片竞争的地缘政治风险、疫情期间的供应链短缺，以及AI革命对芯片需求的巨大影响，强调了芯片在未来经济和国家战略中的关键作用。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people:
  - William Shockley
  - John Bardeen
  - Walter Brattain
  - Jack Kilby
  - Robert Noyce
  - Gordon Moore
  - Morris Chang
companies_orgs:
  - AT&T
  - Bell Labs
  - Texas Instruments
  - Fairchild Semiconductor
  - Intel
  - TSMC
  - ASML
  - Apple
  - Qualcomm
  - AMD
  - Samsung
  - SK Hynix
  - Phillips
  - Sony
  - Nintendo
  - NVIDIA
  - SMIC
  - Huawei
  - Google
  - Amazon Web Services
  - Microsoft
  - Facebook
  - OpenAI
  - Anthropic
products_models:
  - ChatGPT
  - Sony Walkman
media_books:
  - 'Chip War: The Fight for the World''s Most Critical Technology'
status: evergreen
---
### 芯片：现代科技的基石与核心原理

我们通常将技术等同于社交媒体、搜索引擎或手机应用，然而支撑这一切的底层核心是**芯片**（Chip: 半导体器件的统称）。我们所熟知的技术之所以存在，正是因为芯片每年都在不断进步。因此，我们可能误解了技术的真正含义：编写软件是相对容易的部分，而真正困难的是制造出能够推动计算进步的芯片，正是这些芯片让手机成为便携式电脑，让设备能够连接互联网。所有这些进步都离不开日益精良的**半导体**（Semiconductor: 介于导体和绝缘体之间的材料，用于制造电子元件）。正如弗莱彻学院教授、《芯片战争：争夺世界最关键技术》一书作者**克里斯·米勒**（Chris Miller）所言，要理解世界的运作，就必须理解芯片。

芯片在国际贸易中占据主导地位，是贸易量最大的商品，同时也是全球地缘政治动态，特别是中美技术竞争的核心。一个典型的芯片，通常只有指甲大小，由一块硅片构成。在这块硅片上，刻蚀着成千上万、甚至数十亿个微小的**晶体管**（Transistor: 一种半导体器件，用于放大或切换电子信号和电能），它们像开关一样控制电路的通断。当晶体管导通时，产生“1”；断开时，产生“0”。所有计算、数据存储，包括你在Instagram上的点赞和发送的短信，本质上都是由这些晶体管的通断所产生的“1”和“0”的长字符串。芯片大致可分为几类：有些用于处理数据，有些用于存储数据，还有一类负责将真实世界的信号（如音频或图像）转换为“1”和“0”，以便进行处理或存储。例如，手机摄像头捕捉光线，然后将其转换为可存储的数字信号。因此，针对图像、声音、无线电波等都有专门的传感器，它们利用半导体将这些真实世界的信号转化为数字串，以便后续重新呈现为图像。

芯片的制造过程对材料纯度有着极致的要求。虽然芯片以**硅**（Silicon: 一种常见的半导体材料）为基础，但其上还需分层叠加数十种其他材料，才能在纳米尺度上形成晶体管。一个先进的芯片可能包含几十种材料，其中硅是基底，但许多其他化学物质也参与其中。尽管沙子和芯片都源自硅，但两者的相似之处仅此而已。芯片制造所用的硅是目前已知纯度最高的元素之一。在制造微小晶体管时，几乎每个原子都必须精确放置才能确保芯片正常工作。这意味着，如果硅或任何其他材料含有哪怕一个原子级的杂质，都可能导致芯片功能缺陷。因此，用于芯片制造的**硅晶圆**（Silicon Wafer: 制造半导体器件的基底）的生产需要达到极高的纯度。目前全球只有四家公司能够以现代制造所需的规模和纯度生产硅晶圆。虽然硅在地壳中广泛分布，但其提纯和精炼过程极其复杂，以确保没有任何杂质干扰制造。除了硅，芯片制造还会使用硼、镓、砷化镓等多种化学物质，每家芯片制造商都有其专有工艺，对外严格保密，这正是它们生产高性能芯片的“独门秘方”。尽管镓和锗等某些材料的精炼和加工主要集中在中国（约占90%），可能存在地缘政治风险导致供应中断，但总体而言，我们不会面临硅或其他芯片制造常用材料的枯竭。

<details>
<summary>Original English Source</summary>

- When we think about technology, we think about social media, we think about search engines, we think about apps on our phones, but undergirding all of this are chips. The reason that technology that we think of exists is because every year chips get better and better. And so I think we've actually misunderstood what technology means. We think of the easy part, which is writing the software. But the hard part is actually manufacturing the chips that give us the advances in computing that enable us to have a computer on our phone or to attach devices to the internet. All that has been made possible by better and better semiconductors. I'm Chris Miller, a professor at The Fletcher School and author of, "Chip War: The Fight for the World's Most Critical Technology."
- [Announcer] Chapter One, "How to Build a Microchip."
- Well, I first got interested in chips when I realized you really couldn't understand how the world works without them. Whether it's walking around your house and realizing there are chips in almost every device you rely on. Or trying to understand big shifts in international trade, there's no good that is traded more than semiconductors. Or looking at the political dynamics around the world, with the US-China competition focusing on technology. Chips are at the center of all of these major trends. But a chip is a piece of silicon, often the size of your fingernail. And in it is carved thousands, or millions, in some cases billions of tiny devices called transistors, which flip circuits on or off, on and off. And when they're on, they produce a one. When they're off, they produce a zero. And all of the ones and zeros undergirding computing, undergirding data storage, all of your Instagram likes, all of your text messages, these are all just long strings of ones and zeros, which are created on the chip by these circuits flipping on and off. There are a couple different categories of chips. Some chips process data, other chips remember data, and a third category turns real world signals, like audio or pictures into ones and zeros so that they can then be processed or remembered. And so when we look at the world, we see pictures. But when a phone, for example, uses its camera to look at the world, it takes in lots of rays of light, and then has to learn how to convert those into ones and zeros that can be stored. And so there's very specific sensors for pictures, for sound, for radio waves that use semiconductors to convert these real world signals into strings in ones of zeros that can then be re-represented as pictures later on, for example, when you pull a photo up on your phone. All of this is done by different types of semiconductors. So, generally, chips have a foundation of silicon, but there are dozens of other materials that are layered on top to make the transistors at such tiny scale. So a typical advanced chip could have several dozen materials. The foundation is silicon, but there are many other chemicals involved in the process. Yeah, it's true that sand is from silicon and so are chips, but the similarities basically end there. The silicon that's used in manufacturing chips is among the most purified elements that we have. And the reason is that when you're manufacturing chips with tiny transistors, you need to place almost every atom perfectly to make those chips work. Which means that if your silicon, or any of the other materials that you're using, has even a single atomic impurity, it can cause defects in the way your chip functions. And so the production of the silicon wafers that are used in the chip manufacturing process requires extraordinary levels of purity. There's really just four companies in the world today that are capable of producing silicon wafers at the right level of purity at the scale that's required for contemporary manufacturing. The good news is that there's silicon everywhere. It's one of the most widely-distributed elements in the Earth's crust. The hard part is really the refining and the purification of silicon to make sure there aren't any impurities that could disrupt the manufacturing process. So on top of your silicon, you could have boron, gallium, gallium arsenide, lots of different chemicals that are used, and every chip maker has its own proprietary process. So we don't really know, inside of a typical chip, what materials are used, because chip makers usually keep it pretty secretive. That's their special sauce that lets them manufacture chips with the right level of capability. Now we're not gonna run out of silicon, nor will we run out of the other materials that are generally used in chipmaking. There are some concerns that certain materials are predominantly refined and processed in a single country. So for some of the materials like gallium and germanium, China produces around 90% of those materials. So there's geopolitical issues that could interrupt supply, but it's not gonna be that we're running out of the capability to produce them.

</details>

### 纳米级制造：芯片产业的极致工艺与全球分工

芯片制造的复杂性远超想象，其核心在于**纳米尺度**（Nanometer Scale: 衡量微观尺寸的单位，1纳米等于十亿分之一米）的超精密加工。现代芯片的晶体管尺寸以纳米计，比细菌、线粒体甚至冠状病毒还要小。事实上，半导体是人类目前能够制造出的最小规模的产品。每年生产的晶体管数量超过了人类历史上所有其他商品的生产总量。例如，一个典型的智能手机主处理器芯片就可能包含100亿个晶体管，而大型数据中心中的晶体管数量更是难以计数。

芯片制造设施，即**晶圆厂**（Fab: 半导体制造工厂），内部高度自动化，鲜有人类操作，因为人手操作的精度远不足以达到纳米级制造的要求。这些工厂内充满了巨大的机器，其内部的微观操作肉眼无法察觉。全球仅有少数几家公司在制造这些生产芯片的机器方面扮演着主导角色，包括美国的几家、荷兰的**ASML**（ASML: 荷兰半导体设备制造商，全球领先的光刻机供应商）以及日本的一家大型企业。这些工具的制造难度甚至超过了芯片本身，因为它们是人类有史以来部署过的最精密工具之一。以ASML为例，其生产的机器能够基本在原子层面操纵材料，制造出包含数百亿晶体管的芯片，这些芯片广泛应用于智能手机和**人工智能**（Artificial Intelligence: 模拟人类智能的计算机系统）训练系统。

全球芯片制造商数量相对较少，尤其在特定芯片类型上，集中度更高。例如，**台积电**（TSMC: Taiwan Semiconductor Manufacturing Company，全球最大的专业集成电路制造服务公司）是全球最大的芯片制造商，占据了先进处理器芯片（如手机和电脑芯片）约90%的市场份额。台积电凭借其卓越的市场份额，被认为是全球最重要的半导体公司，甚至可以说是全球最重要的公司之一，因为我们几乎所有活动都依赖其生产的芯片。

过去几十年，芯片行业经历了大规模整合，这主要由经济和技术因素驱动。如今，一座尖端的芯片制造工厂可能耗资200亿美元，成为人类历史上最昂贵的工厂之一。因此，只有少数公司能够定期投入如此巨额资金建设先进设施。为了实现财务可行性，这些公司必须生产海量芯片。这种规模效应为大型企业带来了巨大优势：生产的芯片越多，成本结构越合理，技术也越先进，因为每次制造都能积累数据，从而不断优化生产流程，减少杂质。因此，台积电不仅是全球最大的芯片制造商，也是技术最先进的，正是因为它比任何其他公司都收集了更多的数据。

芯片制造需要超高纯度材料和极其复杂的设备，没有任何一家公司能够独立完成。每家公司都需要与供应链伙伴合作，以获取制造先进芯片所需的材料、知识产权、软件和工具。例如，你智能手机中的主处理器可能在台湾制造，但使用了来自荷兰、美国和日本的芯片制造工具，日本的化学品，最终在马来西亚组装和封装。这种全球协作是常态，一个典型芯片的生产需要来自数十家不同公司的组件和材料，因为整个过程对任何一家公司而言都过于复杂，无法独自承担。

<details>
<summary>Original English Source</summary>

- I visited a bunch of chipmaking facilities over the course of the research. The interesting thing though is that, when you go inside one of these massive facilities, called fabs, what you find is that there are huge machines and not much else. Because the manufacturing process has to be extraordinarily automated because humans are way too imprecise for manufacturing at nanometer scale. And so inside of a chipmaking facility, there are very few humans, and lots of big machines that, from the outside, are impressive in their size, but you can't see what's actually happening because it's happening at microscopic level. So there are a handful of companies that play a big role in the making of the machines that make chips, a couple in the United States, one in the Netherlands, and one other large one in Japan. Five companies play the dominant role in the manufacture of the machines that make chips. And in some ways, it's actually harder to make the machines that make chips than it is to make the chips themselves. Because these tools are among the most precise tools that have ever been deployed. Just to give you one example, ASML, a company based in the Netherlands, produces machines that are used in the manufacture of almost every high-end chip today. And these machines are capable of manipulating materials at basically the atomic level to produce chips with billions and billions of transistors like those that are inside of your phone or that are used for training AI systems. So there's a pretty small number of companies that make chips. And when you look at specific types of chips, you find that there's even more concentration. The biggest chip maker in the world is the Taiwan Semiconductor Manufacturing Company. When it comes to advanced processor chips, like the chips in your phone, or the chips in your computer, TSMC makes around 90% of them. So they've got an extraordinary market share, and are probably the most important semiconductor company, and arguably the most important company, in the world, because the chips that they produce, we rely on for basically everything. There's been a lot of consolidation in the chip industry over the past couple of decades, and it's been driven by economics and by technology. Today, a single cutting edge chipmaking facility can cost $20 billion, one of the most expensive factories in all of human history. And so there's just a couple of companies that can afford to put up that sum of money on a regular basis to build more and more cutting edge facilities. And to make that work financially, you've gotta produce a ton of chips. And so there are huge benefits that accrue to the largest firms. The more chips you produce, the more your cost structure makes sense, and the better your technology gets, because you learn from every chip you manufacture, you gather data from it, and you tweak your manufacturing process to make sure you've got fewer and fewer impurities at every step. And so TSMC is both the world's largest chip maker, but it's also the world's most advanced, precisely because it gathers more data than anyone else. Because chipmaking requires ultra-purified materials and hugely complex equipment, there's not a single company that can do it on its own. Everyone requires a set of partnerships with supply chain providers to give them the materials, and the intellectual property, and the software and the tools that they need to produce advanced chips. And so if you take for example, the primary processor inside of your smartphone, it was probably made in Taiwan, but it was made in Taiwan using chipmaking tools from the Netherlands, and from the United States, and from Japan. It was produced using chemicals from Japan, and then often assembled and packaged in Malaysia before ending up inside of your smartphone. And that's typical. A typical chip requires components and materials sourced from dozens of different companies because the process is simply too hard for any one company to do on its own.

</details>

### 摩尔定律：驱动半导体创新的经济学法则

**纳米**（Nanometer: 十亿分之一米）是当今芯片尺寸的衡量单位。智能手机芯片上的数十亿个晶体管，每个都只有几纳米大小，比原子略大，比任何生物体都小，甚至最尖端的晶体管只有冠状病毒一半大小。在如此微小的尺度上进行制造，是半导体独有的成就。每年生产的晶体管数量超过了人类历史上所有其他商品的生产总和，并且没有任何其他产品能与之匹敌。例如，一个典型的智能手机主处理器芯片可能包含100亿个晶体管，而大型数据中心中的晶体管数量更是难以估量。我们甚至无法统计每年生产的晶体管总量，因为数量实在过于庞大，已知其数量已超过人体细胞总数。

**摩尔定律**（Moore's Law: 由戈登·摩尔提出，预测芯片上晶体管数量及其计算能力大约每两年翻一番）预测，芯片上的晶体管数量及其计算能力将每两年翻一番。自20世纪60年代以来，这一预测在实践中一直准确无误，意味着芯片的能力以比其他任何事物都快的速度大幅提升。举例来说，如果飞机速度自20世纪60年代以来每两年翻一番，我们今天飞行的速度将超过光速，而芯片却做到了这一点。芯片能力的提升正是因为晶体管的尺寸不断缩小，如今已达到比病毒还小的程度。这促成了计算能力的爆炸式增长，不仅体现在高性能数据中心和手机的计算能力上，也体现在计算技术在各种设备中的广泛应用。如今，计算无处不在，从洗碗机、冰箱、咖啡机到汽车，都能找到芯片的身影。之所以能实现计算的普及，是因为芯片成本极低，几乎可以免费生产，从而使其能够应用于各种不同设备。

为了理解这种创新速度，我们可以回顾一下：在20世纪50年代，一个晶体管可以握在手中；而今天，一个指甲大小的芯片上可以容纳100亿个晶体管，且成本仅约50美元。晶体管尺寸的缩小和成本的下降，在经济的任何其他领域都是前所未有的。在晶体管出现之前，计算机使用**真空管**（Vacuum Tube: 一种早期的电子元件，用于放大或切换电子信号），它们像灯泡一样通过通断来产生“1”和“0”。尽管在当时属于尖端技术，但真空管效率低下，产生大量热量，运行缓慢，还会吸引飞蛾，导致早期计算机需要定期“调试”（清除飞蛾）。由此可见，将其扩展到100亿个单元的系统是多么困难。晶体管是实现这种小型化的关键原因，在整个经济领域，没有其他产品能以如此规模和成本持续缩小。这一趋势已持续了半个多世纪，使得计算行业的进步与任何其他行业都无可比拟。

摩尔定律并非自然法则或物理定律，而是一种**经济学法则**（Economic Law: 描述经济现象和行为规律的原则）。它指出，如果能够将晶体管做得更小，就能找到更大的市场。这种经济激励推动了在缩小尺寸、改进制造工艺和提高化学品纯度方面的巨额投资，从而维持了技术进步的速度。一旦摩尔定律的经济基础崩溃，技术进步也将随之停滞。然而，令人欣慰的是，当前我们正迎来计算应用的新一轮热潮，这不仅带来了对人工智能的巨大投资，也推动了对半导体的投资。因为很明显，如果能进一步缩小芯片尺寸，将开启人工智能发展的新时代，而这需要比以往任何时候都更强大的计算能力。

摩尔定律的定义方式多种多样，例如可以基于晶体管的二维或三维尺寸，或者基于其处理速度。行业内许多人为了推销特定芯片，会根据某些特性声称摩尔定律已失效。然而，如果我们观察**机器学习**（Machine Learning: 人工智能的一个分支，使系统能从数据中学习并改进）半导体的增长速度，即为AI能力优化的芯片，在过去十年左右，其能力每两年翻一番，这与**戈登·摩尔**（Gordon Moore: 英特尔联合创始人，摩尔定律提出者）在1965年提出的预测完全一致。因此，从宏观角度看，技术进步的速度并未放缓。

在开始半导体研究时，我曾以为芯片无处不在，所以制造起来应该很容易，而核弹仅由少数政府控制，所以制造起来很难。然而，我意识到事实恰恰相反。核武器技术自20世纪60年代以来几乎没有进步，甚至朝鲜都能制造核弹。但芯片之所以无处不在，是因为它们便宜且微小，而将产品做得极其廉价和微小是极其困难的，这就是为什么全球只有少数几家公司能够站在技术前沿。其原因在于，芯片制造成本极高，且制造工艺每年都在不断改进。因此，如果想追赶芯片行业的尖端技术，你追赶的不是一个静态的尖端，而是一个以摩尔定律速度飞速前进、每两年翻一番的尖端。这是一场企业间的竞争，也是人类有史以来最快的竞争，因此达到技术前沿异常困难。

几年前，二维晶体管的缩小变得更加困难。长期以来，芯片都是**平面芯片**（Planar Chip: 晶体管都在同一平面上的芯片）。现在，我们开始制造**三维晶体管**（3D Transistor: 采用立体结构堆叠的晶体管），通过堆叠它们来在更小的空间内集成更多晶体管，从而提供更强大的计算能力。因此，未来几年的一个关键趋势将是更多地采用晶体管的3D结构，这将使更多晶体管被封装在有限的空间内。

<details>
<summary>Original English Source</summary>

- [Announcer] What is nanometer scale, and how does it relate to the innovation process of silicon chips?
- So a nanometer is a billionth of a meter, and chips today are measured in nanometers. If you look at the chip inside of your phone, for example, and try to measure the size of the transistors, of which there will be billions on your smartphone chip, each one of these will be measured in a handful of nanometers. And so that makes them only slightly larger than atoms, smaller than any sort of living thing, far smaller than a bacteria, smaller than a mitochondria, half the size, for the most cutting edge transistors, of a coronavirus. There's basically nothing we manufacture at such tiny scale as we do with semiconductors. Every year, we make more transistors than we've made all other goods combined in all of human history. And in fact, nothing else really comes close. A typical smartphone chip could have 10 billion transistors just in the main processor chip. A big data center run by Google or Amazon Web Services would have more transistors than you could plausibly count. We know that we make more transistors than there are cells in the human body, for example. We don't even know how many we make in aggregate, because there are just so many. Moore's Law predicts that the number of transistors per chip, and as a result, the computing power per chip will double every couple of years. And that's been empirically true since the 1960s, which means that the capabilities of chips have gotten vastly better, and continue to get much, much better at a faster rate than anything else. So I like to think, for example, of airplanes to illustrate the difference. If airplanes doubled in speed every two years from the 1960s up to the present, we'd be flying faster, literally, than the speed of light. But chips have done that. Chips have increased in that capability because the scale of the transistors has shrunk to the level that today we're manufacturing them smaller than even viruses. And that has enabled the explosion of computing power, both in terms of the computing capabilities in high-powered data centers or in your phone, but also the application of computing to all sorts of devices. 'Cause today, there's computing everywhere. It's in your dishwasher, it's in your refrigerator, it's in your coffee maker, it's in your car. And it's possible to put computing everywhere because today it's so cheap, we can produce it almost for free. And that has enabled the application of chips to all sorts of different devices. To understand the change and the rate of innovation, in the 1950s, you could hold a single transistor in your hand. Today, you can hold 10 billion transistors in your hand in a chip that's the size of your fingernail. And that's not an expensive chip, that's a chip that often will just cost $50 or so. So the rate of shrinking transistors, as well as the rate of decline in their cost, has been unparalleled in any other segment of the economy. So before transistors, computers used vacuum tubes, which are sort of light bulb like-devices that would turn on and off, on and off to produce the ones and zeros. And they were cutting edge for their time, but they had huge inefficiencies. They wasted a lot of heat, for example, they worked pretty slowly. And they also, because they created light, attracted moths, and so computers had to be regularly debugged in the early days of computing, which meant removing moths from the lights that they were attracted to. You can see why it was hard to scale that up into a 10 billion unit system. You know, I think the transistor is the key reason why we've been able to scale down. There's really nothing else, if you look all across the economy, that has shrunk in size and shrunk in cost at that level. And it's done so not just for a couple years, it's done so now for over half a century. And that's why when you compare progress in the computing industry to progress anywhere else, there's really no comparison. Well, Moore's Law is not a law of nature, it's not a law of physics. We wish it were, because then we could rely on it to keep delivering advances far into the future. But it's really a law of economics. It says that, if you're able to find a way to shrink, shrink your transistors smaller, then you will be able to find a larger market as well. And that has incentivized huge investments in shrinking, in improving manufacturing processes, and making chemicals more purified to enable it, which has sustained this rate of advance. And if ever it turns out that the economics are on Moore's Law break down, the technology will immediately break down as well. Thankfully, the good news is that, right now, we're seeing a new wave of excitement about ways you can deploy computing, which has led to a surge of new investment into AI, but also a surge of new investment into semiconductors, because it's now clear that if we can shrink even further, we'll enable a whole new era of advances in artificial intelligence that rely on even more computing than we've been able to muster thus far. You can define Moore's Law in a bunch of different ways. Is it based on the 2D size of the transistor, or the 3D size of the transistor? Is it based on the processing speed that comes out of it? And I think there's a lot of people in the industry that are trying to sell a certain chip with given characteristics that have an incentive to say Moore's Law, based on the other characteristics, has come to a halt. If you look at the rate of increase of machine learning semiconductors, for example, chips that are optimized for AI capabilities, they've been doubling in their capabilities every two years for the past decade or so. In other words, exactly what Gordon Moore predicted when he set out Moore's Law in 1965. And so my view is that when you zoom out and look at the rate of technological progress, there's really no slowdown that's happening. When I started my research on semiconductors, I thought that because chips were everywhere, chips were easy to make, and because nuclear bombs were only controlled by a handful of governments, they were hard to make. But what I realized is it's actually the exact opposite. If you take nuclear weapons, that technology has barely improved since the 1960s. It's so easy to make nuclear bombs, even the North Koreans can do it. But chips are everywhere because they're cheap and they're tiny, and making things very inexpensive and very small is extraordinarily difficult, which is why there's just a couple companies in the world that can do it at the cutting edge. And the reason is that it's brutally expensive, and it requires manufacturing processes that get better, and better, and better every single year. And so if you're trying to catch up to the cutting edge in the chip industry, you're not trying to catch up to a static cutting edge, you're trying to catch up to a cutting edge that is racing forward at the rate of Moore's Law, doubling every two years. And so it's a race between companies, but it's the fastest race humans have ever undertaken, which is why it's extraordinarily difficult to reach the cutting edge. A couple years ago, it became harder to shrink transistors in two-dimensional format. For a long time, chips were made, they were just described as planar chips, chips in a plane, in which all the transistors were on the same level. Now we've started making transistors that have three dimensions, because we're learning to stack them on top of each other to package more of them together in a way that produces more computing power. And so one of the key trends over the next couple of years is going to be more 3D construction of groups of transistors, which will enable more of them to be crammed into a small amount of space.

</details>

### 半导体产业演进：从贝尔实验室到全球专业化格局

20世纪中叶，所有电话业务均由**美国电话电报公司**（AT&T: American Telephone and Telegraph Company，曾是美国最大的电话公司）垄断管理。作为受政府监管的垄断企业，AT&T的一项规定是其研究实验室必须与世界分享其发明。当时，**贝尔实验室**（Bell Labs: AT&T的研发机构，在科学和工程领域做出了许多重大贡献）汇聚了世界上最杰出的物理学家和化学家，他们受雇于此以改进电话系统。然而，在此过程中，他们创造了许多关键发明，这些发明在未来几十年里推动了计算领域的技术进步。**晶体管**就是贝尔实验室的重大发明之一，而如今用于设计和制造半导体的许多工艺也最早由贝尔实验室的研究人员开创。由于贝尔实验室并非一家计算机公司，它能够将这些技术或孵化成自己的初创公司，或出售给其他企业，这正是许多支撑半导体发展的关键技术进步的最初来源。

**威廉·肖克利**（William Shockley）、**约翰·巴丁**（John Bardeen）和**沃尔特·布拉顿**（Walter Brattain）在贝尔实验室工作期间发明了第一个晶体管，最初计划将其用于电话网络。但在20世纪50年代末，工程师们意识到可以将多个晶体管制作在同一块半导体材料上，这便诞生了第一个**芯片**（Chip: 集成电路的俗称，将多个电子元件集成在一块半导体基片上）。这一突破意义重大，因为单个晶体管通过导线连接，少量尚可管理，但若有上千个晶体管，将形成错综复杂的“导线丛林”。芯片通过在材料内部实现电连接，将这种“丛林”替换为单一的材料块，不仅更可靠，也更易于小型化。因此，芯片的发明使得大量晶体管能够经济高效地协同工作，避免了复杂的布线问题。

首批芯片由**德州仪器**（Texas Instruments: 美国一家全球领先的半导体公司）和硅谷的**仙童半导体**（Fairchild Semiconductor: 硅谷早期重要的半导体公司）的工程师同时发明。**杰克·基尔比**（Jack Kilby）于1958年在德州仪器实验室发明了其中一种。长期以来，德州仪器一直处于芯片制造的前沿，最初主要为美国政府的太空计划和武器系统制造芯片。但他们很早就意识到，用于航天器导航的芯片同样可以应用于商业领域，如计算机和袖珍计算器。这推动了芯片行业在20世纪60、70和80年代的第一波增长。然而，在过去的15年里，德州仪器改变了策略，不再大量生产用于计算或AI系统的芯片，而是专注于工业应用和汽车领域。因此，德州仪器的芯片无处不在，但你可能看不到它们，因为它们深藏在设备内部，确保汽车的雨刷器和车窗升降功能正常运作。

硅谷最早的初创公司之一由晶体管发明者之一**威廉·肖克利**创立。他是一位杰出的物理学家，但却是一位糟糕的管理者和人。他在硅谷雇佣了一批才华横溢的工程师，并为此搬到了他母亲居住的加利福尼亚州帕洛阿尔托。尽管他雇佣了许多优秀人才，但他们都厌恶为他工作。因此，在20世纪50年代末，其中八人离职，创立了**仙童半导体**。这家公司成为硅谷崛起的关键初创企业之一，并在硅谷得名“硅谷”的过程中发挥了重要作用，因为长期以来，它一直是芯片设计和制造的绝对中心。**罗伯特·诺伊斯**（Robert Noyce: 集成电路的共同发明者之一，英特尔联合创始人）、**戈登·摩尔**（Gordon Moore: 英特尔联合创始人，摩尔定律提出者）以及许多其他人都曾在仙童半导体开始他们的职业生涯。

**英特尔**（Intel: 美国一家全球领先的半导体公司，主要生产微处理器）于1969年成立，最初计划专注于存储芯片。但他们很早就意识到，一种不仅能存储数据，还能处理数据，且能针对不同用例进行编程的芯片，可能拥有更大的市场。英特尔迅速将重心转向个人电脑芯片，尽管当时个人电脑市场规模很小，但他们准确地预测到，很快每个人都会拥有一台个人电脑。如今，英特尔仍然是全球最大的PC芯片生产商。戈登·摩尔是英特尔的两位联合创始人之一，他最著名的成就是提出了摩尔定律，但他也在英特尔早期多年的研发运营中扮演了极其关键的角色。在**微处理器**（Microprocessor: 集成在一个芯片上的中央处理单元）方面，他早期就主张将重心放在微处理器上，而非英特尔之前更侧重存储的芯片。因此，在某种程度上，他是推动英特尔专注于微处理器的关键人物，将其称为“芯片上的微型计算机”。这催生了在不重新设计芯片本身的情况下，将芯片应用于多种不同场景的理念，因为芯片本身可以运行程序。如今，我们理所当然地认为手机、洗碗机和汽车中都有芯片。但在当时，这需要为每个用途设计不同的芯片。而现在，多亏了微处理器，我们有了可编程芯片。这曾是芯片行业的主要收入来源和技术焦点，直到大约20年前第一批智能手机开始生产。

如今，智能手机芯片通常由一类公司设计，但主要在台湾制造。例如，最大的智能手机芯片设计商包括在加利福尼亚设计自家芯片的**苹果**（Apple: 美国科技公司），以及**高通**（Qualcomm: 美国一家全球领先的无线技术创新者）等公司。这些公司几乎所有设计的芯片都在台湾制造。因此，今天的芯片行业分为两个主要部分：**芯片设计**（Chip Design: 规划和创建集成电路布局的过程），这在本质上类似于一种编程，决定每个晶体管在芯片上的位置；以及**实际制造**（Actual Manufacturing: 将芯片设计转化为物理产品的过程），这通常在台湾或东亚其他地区进行，由专门从事精密规模制造的公司完成。

<details>
<summary>Original English Source</summary>

- [Announcer] Chapter 2, "The First Chip Builders."
- In the middle of the 20th century, all telephones were managed by AT&T. They were a monopoly, and the government regulated them, and one of the rules was that their research lab had to share its inventions with the rest of the world. And they had some of the most brilliant physicists and chemists working in the world at that time, which they hired to improve the phone system. But in the process, they created some of the key inventions that drove technological progress in computing for decades to come. The transistor was one of the inventions that emerged out of Bell Labs, but actually many of the processes that are used to both design and manufacturer semiconductors today were first pioneered by researchers working at Bell Labs. But because Bell Labs wasn't a computer company, they were able to take those technologies and either spin out their own startup or sell it to somebody else. And that's how many of the key technological advances undergirding semiconductors first emerged. So William Shockley, John Bardeen, and Walter Brattain invented the first transistor while they were working at Bell Labs. They were initially planning to use these transistors as part of the telephone network. But in the late 1950s, the first engineers realized that you could take multiple transistors, and make them on a single piece of semiconductor material. And so that was the first chip, a piece of material with multiple transistors carved into it. And that was important, because if you had individual transistors, they were connected via wires in a way, that was okay if you had a handful of transistors. But if you had 1,000 connected together, you had a jungle of wires you had to manage. But the chip managed to have the electrical connection in a piece of material. And so the jungle of connections was replaced by a single block of material, which was much more reliable, and also much more easy to shrink in its size. And so it was the invention of the chip that made it possible to deploy lots and lots of transistors together in a way that was economical, but also possible to engineer and avoided all of the wiring. The first chips were invented by engineers working at Texas Instruments and a company called Fairchild Semiconductor in Silicon Valley. They were invented simultaneously. Jack Kilby invented one in 1958 working in a Texas Instruments lab. And for a long time they were really at the cutting edge of chip manufacturing. At first, they were building chips primarily for the U.S. government, for the space program, for example, and for weapon systems. But they realized early on you could take the exact same chips that the government wanted to guide spacecraft, and use them for commercial applications, like computers or pocket calculators. And that set the industry off into its first phase of growth in the 1960s and '70s and '80s. For the past 15 years, they've taken a different tack. They don't today produce chips that are used in computing, they're not, for example, in AI systems in a large way. Instead, they produce a lot of chips that are in industrial applications, or in automobile uses. And so Texas Instruments chips are all around you, but you don't see them because they're buried deep in your devices, making sure your windshield wipers work, for example, on your car, or that your windows move up and down when you press the button. Those are the types of use cases that Texas Instruments produces chips for. One of the first startups in Silicon Valley was created by one of the researchers who invented the first transistor, William Shockley, who was by all accounts, a brilliant physicist, but a horrible manager and a horrible person. And so he hired a very talented set of engineers in Silicon Valley. He moved to Palo Alto, California, where his mother lived, for the purpose. And although he hired lots of great people, they detested working for him. And so eight of them in the late 1950s went out on their own, and created Fairchild Semiconductor, which became one of the key startups that would give rise to Silicon Valley, and played a major role in Silicon Valley even being named Silicon Valley, because for a long time it was the absolute epicenter of chip design and manufacturing thanks to people at Fairchild Semiconductor. Robert Noyce, one of the two inventors of the integrated circuit, Gordon Moore, who later would go co-found Intel, and many others first started their career working at Fairchild. Intel was founded in 1969, and it initially planned to focus on making memory chips. But they realized early on that there was a potentially larger market for a type of chip that wouldn't just remember data, but would also process it, especially if that processing could be programmed in different ways for different use cases. And it quickly focused on making chips for personal computers, which at the time was a very small market, but they correctly bet that soon, everyone, would have a personal computer. And Intel, even today, is the world's largest producer of chips that go inside of PCs. Gordon Moore is one of the two co-founders of Intel. He's most famous today probably for coining the term Moore's Law, but he also played an absolutely critical role running Intel's R&D operations from the earliest days for many years. And when it came to the microprocessor, he was an early advocate of focusing on microprocessors at the expense of the more memory-focused chips that Intel had previously made. And so in some ways, he was the key figure in Intel in making the company focus on microprocessors. A tiny computer on a chip, as they originally called it. And it gave rise to the idea that you could deploy chips in lots of different use cases without having to redesign the chip itself, because the chips themselves could have a program running on top of them. Today, we take it for granted that you can have a chip in your phone, and a chip in your dishwasher, and a chip in your car. But at the time, that would've required many different chips for each of those purposes. Whereas, today, thanks to the microprocessor, we have programmable chips. And that was the main source of revenue for the chip industry, the main focus of technology, until about 20 years ago when the first smartphones began being produced. And today, smartphone chips are generally designed by one set of companies, but they're manufactured largely in Taiwan. So the largest designers of smartphone chips are Apple, which designs its own chips in California. Qualcomm, and other companies, almost all of them manufacture all of the chips that they design in Taiwan. And so today, the chip industry is split into two different parts. There's the chip designers, which, today, is essentially like a type of programming almost, programming where each of the transistors goes on the chip, and the actual manufacturing takes place generally in Taiwan or elsewhere in East Asia, where different companies specialize in manufacturing at precision scale.

</details>

### 区域崛起与技术竞合：日韩荷台的产业贡献

芯片产业从一开始就具有全球化特征。**仙童半导体**在硅谷成立后不久，就在香港设立了第一家工厂。然而，过去几十年间，一个显著变化是，如今每个地区都专注于半导体供应链的不同环节。20世纪50年代末至60年代初发明的首批芯片主要用于太空计划和导弹系统，因此它们处于冷战竞争的核心。美国在技术上领先，但苏联也意识到需要芯片来更精确地制导导弹或更有效地发射航天器。因此，苏联致力于建立自己的芯片产业，并尽可能地复制西方的技术。冷战初期，就有苏联物理系学生在**斯坦福大学**（Stanford University: 美国著名研究型大学）学习，并将所学知识传回苏联国防工业体系。

然而，苏联犯了两个关键错误。首先，他们过于侧重复制而非创新，虽然擅长复制，但在创新方面却落后了。其次，他们只关注军事应用。尽管军事是芯片最初的应用领域，但如今99%的芯片流向了私人部门，用于手机、个人电脑或数据中心，而非国防设备。如果只关注政府和军事用途，市场规模相对于庞大的消费市场而言微不足道。美国企业以利润为导向，尽早地将重心转向消费市场。苏联从未完成这一转变，因此其芯片产业与美国相比始终规模很小，导致投资不足，雇佣的工人也较少，最终技术落后，尽管他们擅长复制。

目前，美国的大部分关键芯片公司只负责设计芯片。芯片的制造主要发生在东亚，例如台湾和韩国。芯片制造所需的许多化学品来自日本。而制造芯片的机器则来自硅谷（部分仍在制造）、荷兰或日本。因此，芯片产业已经全球化，并在这一过程中实现了专业化。如今，没有任何一个地区能够独立制造尖端芯片。所有人都依赖于这个连接美国、台湾、欧洲、日本和韩国的国际化供应链。

日本在20世纪50年代和60年代早期是电子产品组装的主要参与者，当时劳动力成本较低。但日本企业致力于向价值链上游移动，生产更复杂、更昂贵的商品。日本企业很早就意识到消费电子产品是其重要的增长领域，不仅可以内销，还可以销往全球。因此，像**索尼**（Sony: 日本跨国企业集团）这样在70、80年代的领导者，押注消费市场，生产利用当时先进芯片技术的产品。尽管今天我们可能不太记得，但80年代的**索尼随身听**（Sony Walkman: 索尼推出的便携式磁带播放器）曾是科技产业的中心，让日本在全球科技版图上占据一席之地。当时，日本在制造先进芯片并将其应用于索尼随身听等高利润产品方面，在许多指标上与美国不相上下。

日本在**视频游戏**（Video Games: 电子游戏）领域表现出色，这可能出乎大多数人的意料，但要呈现逼真的图形需要极其复杂的计算能力。因此，索尼、**任天堂**（Nintendo: 日本著名视频游戏公司）等日本公司专注于如何制作更好的图形，这需要越来越强大的计算能力。如今，它们已不再是该领域的主要参与者，但作为人工智能核心参与者的**英伟达**（NVIDIA: 美国一家设计和销售图形处理器、芯片组和相关多媒体软件的公司），最初就是一家视频游戏公司，为计算机制造显卡。在早期历史中，英伟达主要向游戏玩家销售芯片，因为其显卡能提供更好的图形和更快的渲染速度。然而，事实证明，用于屏幕图形显示的数学原理与训练AI系统所用的数学原理非常相似。因此，英伟达能够将为视频游戏和电脑游戏制造的芯片，转向应用于AI系统，这也是为什么一家成立于20世纪90年代的视频游戏公司，如今不仅成为一家AI公司，而且是全球最重要的AI公司。

20世纪80年代，韩国看到了日本在芯片产业的崛起，以及日本企业在技术和盈利方面都达到了顶峰，销售芯片和使用芯片的设备。韩国希望复制日本的战略。因此，**三星**（Samsung: 韩国跨国企业集团）和**SK海力士**（SK Hynix: 韩国半导体制造商）等公司成立，旨在韩国建立芯片产业。他们复制了日本模式，在制造方面表现出色，并在成本上有效竞争。它们也为日本生产提供了替代方案。因为80年代的美国企业非常担心日本会主导芯片产业，因此乐于看到日本之外的另一个选择，并将业务转向韩国企业，这不仅因为韩国生产商具有成本竞争力，也因为这为行业提供了更多样化，限制了日本企业的主导能力。

20世纪60、70和80年代，欧洲最大的芯片制造商之一是荷兰公司**飞利浦**（Phillips: 荷兰跨国科技公司）。尽管飞利浦如今仍在运营，但已不再生产半导体，几十年前就退出了半导体业务。然而，他们创建的一个遗留部门专门生产制造芯片的工具，特别是专注于在芯片上刻蚀晶体管的**光刻工具**（Lithography Tool: 用于在半导体材料上转移电路图案的设备）。**ASML**几十年前从飞利浦分拆出来。当时，大多数人认为它很可能会失败，因为荷兰在芯片产业中并不重要，硅谷遥不可及。但ASML在许多被认为会失败的技术上进行了一系列大胆的技术押注。其中最好的例子就是当前最尖端的光刻技术——**极紫外光刻**（Extreme Ultraviolet Lithography, EUV: 一种使用极短波长紫外光进行半导体光刻的技术）。生产这些工具每台成本高达3.5亿美元，其他所有人都认为这项技术永远不会成功。它花了三十年才实现商业化，投入了数百亿美元的研发资金。ASML做出了这个赌注，而且在很多年里看起来都是一个非常糟糕的赌注，直到大约十年前，他们才首次成功制造出最初的EUV光刻机。

芯片制造商一直使用光刻技术来制造半导体，但随着晶体管变得越来越小，我们需要越来越好的光刻系统才能在硅芯片上打印更小的晶体管。几十年前，很明显当时的光刻尖端技术所使用的光波长（193纳米）对于打印微小晶体管来说太宽了。尽管193纳米听起来很小，也确实很小，但如果你的晶体管尺寸是10纳米或5纳米，193纳米的光波长仍然太宽，无法在硅芯片上精确刻蚀晶体管。因此，ASML押注了一种使用13.5纳米波长光的全新光刻系统，其波长窄得多。这听起来合乎逻辑，但生产起来极其困难。研究始于20世纪90年代初，经过25年才实现这些机器的商业化，因为这需要建立一个涉及极其复杂组件的供应链，包括人类制造过的最平坦的镜子、商业设备中使用过的最强大的激光，所有这些都必须在制造这些机器的过程中发明出来。

台湾在20世纪50年代和60年代是电子产品组装的主要参与者，例如组装晶体管收音机和电视机。他们在这些方面做得很好，但组装环节利润微薄，真正的利润在于复杂组件的制造。因此，台湾政府早在20世纪70年代就意识到，他们需要向价值链上游移动，学习更复杂的电子制造环节。1987年，美国工程师**张忠谋**（Morris Chang: 台积电创始人）在德州仪器工作了几十年后，未能获得CEO职位。于是他离开了德州仪器，寻求新的发展方向。他与台湾政府已有多年接触，因为他的前雇主德州仪器在台湾运营着多家工厂。台湾方面找到他，问他是否愿意在台湾建立一家芯片工厂，他欣然同意。他有一个想法，即以不同于其他任何公司的方式进行制造。当时，大多数芯片都是由同一家公司设计和制造的，但张忠谋意识到制造过程每年都变得越来越复杂，如果专注于制造，就能比竞争对手做得更好。因此，他于1987年在台湾创立了**台积电**，目标从未是设计芯片，而仅仅是制造芯片。他的愿景有点像**古腾堡**（Gutenberg: 活字印刷术发明者）之于书籍：古腾堡不写书，只印刷书；张忠谋不想设计芯片，只想制造芯片。台积电正是这样做的。这使得台积电赢得了世界上一些最大公司的客户，如苹果、英伟达、高通、**AMD**（AMD: Advanced Micro Devices，美国一家全球领先的半导体公司），它们都依赖台积电生产芯片。这意味着台积电是全球迄今为止最大的芯片制造商。因此，它拥有更大的规模，可以降低成本，并比任何其他公司更精进其技术。凭借这种独特的商业模式，台积电既是全球最大，也是最先进的芯片制造商。

<details>
<summary>Original English Source</summary>

- [Announcer] Chapter three, "Global Impact." How has the semiconductor industry spread globally?
- The chip industry was a global industry from really the earliest days. Fairchild Semiconductor was founded in Silicon Valley before it was even called Silicon Valley, but they opened their first facility in Hong Kong just a couple years later. So there was already a globalized nature to the chip industry from day one. But one of the things that's changed a lot over the past couple of decades is that, today, each region focuses on a different part of the semiconductor supply chain. The first chips that were invented in the late '50s and early '60s were used for space programs and missile systems. So they were at the center of the Cold War competition. And the U.S. was ahead, but the Soviet Union realized that they also needed chips to guide their missiles more accurately or to help their spacecraft launch effectively. And so they were focused on building their own chip industry, but also on copying whatever they could from the West. And so since the earliest days of the Cold War, there were Soviet exchange students in physics, for example, studying at Stanford University, but also transmitting the knowledge that they gained back to the Soviet Defense industrial complex. And so there was a lot of copying, a lot of efforts to replicate what the U.S. was doing. But the Soviets made a couple of key errors. One was that they focused too much on copying, and not enough on innovating. And so they got very good at copying, but not so good at innovating, and that left them behind. And the second error they made was that they only focused on the military aspects. And the military was where the first chips were used, but today, most chips go to the private sector. 99% of chips that are made go into phones, or PCs, or data centers, not for defense equipment. And so if you only focus on the government and military uses, you've got a tiny market relative to the vast consumer market that was out there. U.S. firms were profit-seeking, they focused on the consumer market as early as they could. In the Soviet Union, they never made that shift, and so their chip industry was always tiny in comparison to the U.S., which meant they could invest less, they could hire fewer workers, and ultimately their technology fell behind even though they were pretty good at copying. So in the U.S. right now, most of the key chip firms only design chips. Most of the manufacturing of chips happens in East Asia, in Taiwan, for example, or in Korea. Many of the chemicals that go into chipmaking come from Japan. And the machines that are used to make chips come from either Silicon Valley, where some of them are still made, or the Netherlands or Japan. So the industry has globalized, but it's also specialized in the process. And so there's not a single region today that can make cutting edge chips on its own. Everyone relies on this internationalized supply chain that brings together the U.S., Taiwan, Europe, Japan, and Korea. Japan was a major player in electronics assembly early in the 1950s and 1960s, so devices would be assembled in Japan because labor costs at the time were lower. But Japanese firms were fixated on moving up the value chain, producing more complex, more expensive types of goods. And Japanese firms realized very early on that consumer electronics could be a major growth area for them, where they could sell not just domestically, but all around the world. And so companies like Sony, which were among the leaders in the 1970s and 1980s, bet on the consumer market to produce the types of goods that would take advantage of the advanced chip technology that they were pursuing at the time. And so although we don't remember it much today, devices like the Sony Walkman in the 1980s was at the center of the tech industry, and it put Japan really on the map. And at that point, Japan was, by a lot of metrics, just as capable as the United States when it came to building advanced chips and then deploying them in very profitable uses like the Sony Walkman. One of the places where the Japanese excelled was in video games, which most people might not think of as driving technological advances, but actually, the computing that's required to show graphics that look real life is extraordinarily complex. And so the Japanese companies like Sony, Nintendo is another one, were fixated on how to make better graphics, and it required more and more computing power to make better and better graphics. And today, they're no longer major players in that sphere, but NVIDIA, which is the central player in AI, actually started as a video game company, it made graphics cards for computers. And for most of their early history, they were selling chips primarily to gamers, because the graphics were better and rendered more rapidly. But it turns out that the same essential math that's used for showing graphics on a screen is pretty similar to the math that's used in training AI systems. And so NVIDIA was able to take chips that were made for video games, and made for computer games, and pivot them to be used in AI systems, which is why a video game company that was founded in the 1990s has now become not just any AI company, but the most important AI company in the world. In the 1980s, the South Koreans saw Japan becoming a major player in the chip industry and saw Japanese firms rise to the top, both in terms of technology and in terms of the amount of money they were making, selling both chips and devices that used them, and South Korea wanted to replicate Japan's strategy. So companies like Samsung and SK Hynix were founded to establish chip industries in Korea. And they replicated the Japanese model, they get very good at manufacturing, they competed very effectively on cost. They also represented an alternative to Japanese production. 'Cause U.S. firms in the 1980s were very worried that Japan was gonna take over the chip industry. So they were excited to have another option besides Japan, and shifted business towards Koreans, both because the Korean producers were cost competitive, but also because it provided a bit more diversification in the industry that would limit the ability of Japanese firms to dominate. One of the biggest European chip makers in the 1960s, '70s, and '80s was the Dutch company Phillips, which today still exists, but doesn't produce any semiconductors. They got out of the semiconductor business several decades ago. But one of the legacy units that they'd created was a unit that made the tools that make chips. And in particular, they focused on the lithography tools that are capable of patterning transistors on a chip. ASML was spun out of Phillips several decades ago, and at the time, most people thought it would likely fail, the Netherlands wasn't a big part of the chip industry, Silicon Valley was a long way away. But ASML took a series of pretty wild technological bets on technologies most people thought would fail. And the best example of this is the current cutting edge of lithography called extreme ultraviolet lithography, the tools that cost $350 million a piece to produce, everyone else thought that was a technology that would never work. It took three decades to commercialize, tens of billions of dollars of research and development money went into it, but ASML made that bet, and it was a bet that looked like a very bad bet for many years until about a decade ago when they first were able to build the initial EUV lithography machines. So chip makers have always used lithography to manufacture semiconductors, but as transistors have gotten smaller and smaller, we've needed better and better lithography systems to print smaller transistors onto silicon chips. And several decades ago, it was clear that the cutting edge in lithography at the time was gonna be too broad in terms of the wavelength of light used to print tiny transistors. The cutting edge used light with a wavelength of 193 nanometers, which sounds really small, and it is really small. But if your transistors are measured in 10 nanometers, or 5 nanometers, 193 nanometers is still too broad of a brush with which to paint your transistors on the silicon chip. And so ASML bet on a new type of lithography system using light with a wavelength of 13.5 nanometers, much more narrow. Which sounds logical, but it was extraordinarily difficult to produce. Research started in the early 1990s, and it took 25 years before these machines were commercialized, because it required building a supply chain that involved these extraordinarily complex components, the flattest mirrors humans have ever made, the most powerful laser ever in a commercial device, all of these had to be invented in the process of making these machines work. So Taiwan was a major player in electronics assembly, and putting together transistor radios, for example, in the 1950s and '60s, or assembling televisions. And they did quite well on that, but there's not much money to be made in the assembly, the money is made in the manufacturing of the complex components involved. And so the Taiwanese government realized, as early as the 1970s, that they needed to move up the value chain and learn to do the more complex parts of electronics manufacturing. In 1987, there was a American engineer named Morris Chang who was passed over for the CEO job of Texas Instruments where he'd worked for several decades. And so he left TI, and was looking for something else to do, and he'd gotten to know the Taiwanese government for several years, because Texas Instruments, his former employer, operated a number of plants in Taiwan. And so the Taiwanese approached him and said, "Would you like to build a chip factory in Taiwan?" And he said yes. And he had an idea, which was to do manufacturing differently than anyone else. At the time, most chips were manufactured and designed by the same companies, but Morris Chang realized that manufacturing is getting more and more complex every single year, that if you specialized on manufacturing, you could manufacture better than your competitors. And so he established TSMC in Taiwan in 1987 with the aim never of designing chips, only of manufacturing. His vision was sort of like to do for chips what Gutenberg had done for books. Gutenberg didn't write any books, he only printed them. Morris Chang didn't wanna design any chips, he only wanted to manufacture them. That's exactly what TSMC has done. And it's enabled TSMC to win among its customers, some of the largest companies in the world, Apple, NVIDIA, Qualcomm, AMD, they all rely on TSMC to produce its chips, which means that TSMC is the largest chipmaker in the world by far. And as a result, it's got more scale, it can drive down its costs, and it can hone its technology more than anyone else. And so TSMC, thanks to this unique business model, is both the largest and the most advanced chipmaker in the world.

</details>

### 地缘政治博弈：芯片供应链的脆弱性与战略风险

如今，中国是全球最大的芯片进口国，每年进口芯片的花费与进口石油相当，这表明中国对外部世界的芯片依赖程度极高。中国进口这些芯片既用于自身使用，也因为全球大部分手机、电脑和服务器都在中国组装。因此，芯片流入中国，组装成设备，然后其中许多设备再出口到美国、欧洲、日本或国际市场。目前，中国与芯片产业的主要互动方式是购买芯片、组装，然后出口。

然而，中国政府意识到这并非行业中的最佳位置。他们希望像台湾和日本一样，向价值链上游移动，从事更高附加值的产业环节。因此，在过去十年中，中国一直致力于建设自己的芯片产业，以增加国内芯片制造能力。目前，中国在低端芯片领域取得了显著成功，这类商品化芯片广泛应用于各种设备，中国正在大幅扩大其制造能力，并在实现自给自足方面取得了实质性进展。但在尖端领域，例如手机或AI系统中的芯片，中国仍显著落后于台积电等行业领导者。目前，中国最先进的芯片公司**中芯国际**（SMIC: Semiconductor Manufacturing International Corporation，中国大陆最大的晶圆代工企业）落后台积电约五年，这听起来可能不多，但相当于落后了2.5个摩尔定律周期。这意味着，在最尖端应用中，如果选择中国制造商而非台湾制造商，性能会受到明显影响。

直到2020年，台积电的两大客户分别是美国最大的智能手机制造商**苹果**，以及中国最大的手机公司**华为**（Huawei: 中国领先的信息与通信技术解决方案供应商）。台积电曾为这两家公司的手机制造芯片。然而，美国担心华为受中国政府控制，并担忧其可能带来的监控能力，因此一直试图限制华为获取先进技术。自2020年以来，美国禁止华为在台积电制造先进芯片。因此，华为不得不转向国内供应商来制造其所需的大部分芯片。这是一个挑战，虽然可以找到中国国内供应商，但它们的水平不如台积电，成本更高，性能更低。在过去几年中，华为一直面临着巨大的阻力，因为它试图建立自己的供应链，以弥补失去台湾尖端技术的劣势。

直到最近，印度在芯片产业中扮演的角色非常小。印度有几家芯片公司，但它们既不处于尖端，规模也不大。大部分半导体制造以及供应链的其他环节，例如手机和电脑的组装，都发生在印度南部，例如**泰米尔纳德邦**（Tamil Nadu: 印度南部的一个邦）是主要的制造中心之一，而**班加罗尔**（Bangalore: 印度卡纳塔克邦首府，被称为“印度硅谷”）则是印度芯片设计的重要中心。然而，目前印度在半导体投资方面正在经历最迅速的变化。印度正在启动一系列新项目，旨在提升其在电子制造领域的地位。我认为，今天的印度就像30年前的中国，或者50年前的台湾，正处于制造业重大变革的早期阶段。因此，如果未来10到20年，印度成为我们所依赖的所有计算和电子产品生产的核心参与者，我一点也不会感到惊讶，因为他们正在采取与中国、台湾以及更早的日本相同的步骤，以成为主要的制造商。

芯片产业的讽刺之处在于，它既是全球化的，又在某些特定生产类型上高度本地化。这种现象是不可避免的，因为所涉及的工程技术极其复杂，所需的投资额巨大，因此需要专业化。而专业化意味着我们必须依赖他人来协助完成整个过程。因此，美国公司将长期依赖台湾的制造、日本的化学品以及供应链的其他环节，因为没有任何一家公司能够独自拥有生产所需芯片的全部能力。

在**新冠疫情**（COVID-19: 由新型冠状病毒引起的传染病）期间，芯片行业的供需动态严重失衡。例如，许多人为了居家办公而订购了新电脑，导致PC产量意外飙升；或者在疫情初期，人们购买的汽车减少，导致汽车产量下降。企业无法准确预测所需芯片的类型。这种影响导致在疫情后期需求恢复时，某些类型的芯片出现了短缺。汽车公司尤其发现，他们无法获得生产汽车所需的芯片。长期以来，汽车公司并未将芯片视为供应链的重点，他们更关注发动机、车轮、车轴等传统汽车零部件。然而，现代汽车需要大量芯片，最复杂的汽车甚至需要数百甚至数千个芯片。对于汽车而言，即使缺少一个芯片，汽车也常常无法正常工作。在疫情期间，汽车公司经常面临这种困境。仅仅一个芯片，甚至是最便宜的芯片，都可能导致汽车停在工厂停车场，等待正确的芯片到货。

这揭示了几点：首先，汽车等复杂制造设备需要大量芯片。其次，它们不仅需要同一种芯片，还需要由不同制造商生产的数千种不同类型的芯片，其中任何一种延迟都会导致整车等待。第三，这表明不仅科技行业需要芯片，实际上万事万物都需要芯片。汽车、拖拉机、医疗设备等所有行业在疫情期间都面临芯片短缺。更令人惊讶的是，疫情期间我们实际生产的芯片数量并未减少，反而每年都在增加。问题在于供应无法跟上需求，而且需求出现在了行业意想不到的领域。这给汽车制造商等企业造成了数千亿美元的损失，因为他们无法完成停放在工厂停车场的商品，从而无法销售。

更重要的是，2021年和2022年我们看到的短缺，与如果台湾等大型芯片制造商发生问题时可能出现的短缺相比，简直微不足道。任何扰乱台湾芯片生产的事件都将对全球经济、美国、欧洲、日本以及所有依赖台湾制造芯片的国家造成灾难性影响。地震是可能导致问题的一个因素，但台湾地震频发，因此准备充分。芯片工厂为了避免振动，通常是现存最抗震的建筑之一。这并非万无一失，但意味着他们在防震方面做了大量工作。水是芯片制造中许多步骤最广泛使用的材料之一，且需要超纯水。因此，芯片工厂需要从当地供水系统抽取大量水，并在生产结束后进行回收，以确保没有化学物质排放回环境。这对芯片制造商来说是一个重大挑战，因为用水量巨大，而许多芯片制造地并不拥有充足的水资源。例如，台湾近年来多次面临干旱问题，这对台积电在台湾扩大制造规模构成了主要限制。另一个限制因素是能源。电力对芯片制造至关重要，随着工厂使用更先进的芯片制造工具，它们需要更多的电力来运行。尤其当各国尝试使用更多绿色能源时，挑战更大，因为既需要更多能源，又需要绝对可靠的能源。太阳能或风能并非总是可靠的。这意味着，如果台湾要规划未来的电力供应，可选择的方案数量有限。

我认为更大的风险并非地震，而是地缘政治。中国经常威胁对台湾动用武力以控制该岛，如果这些威胁变为现实，将是巨大的风险。长期以来，人们可能认为这种风险不大，因为中国曾相对弱小，而美国承诺保护台湾。但如今，中国每年都在变得更强大，其军事能力持续增长。这引发了人们对中国是否可能在某个时候对台湾采取行动的担忧。问题在于，即使是小规模的行动或冲突，对芯片行业来说也将是灾难性的，因为它不仅关乎工厂设施本身的安全，还关乎供应链。台湾需要进口能源、化学品、材料、工具、备件，其中许多来自日本、美国、欧洲，能源则来自中东。如果其中任何环节中断，芯片生产都可能崩溃。而如果台湾的芯片生产崩溃，将影响到所有人，因为每个人都在使用台湾制造的芯片。

<details>
<summary>Original English Source</summary>

- [Announcer] What happened during the COVID-19 chip shortages?
- During the pandemic, the supply and demand dynamics on the chip industry were out of whack. Because a lot of people ordered new computers, for example, to work from home, and so PC production shot up in ways that weren't expected, or people bought fewer cars in the early days of the pandemic, and so car production declined. And companies couldn't predict what type of chip they would need. The effect of that was to create shortages of certain types of chips, when demand roared back in the later stages of the pandemic. Car companies in particular found they couldn't get the types of chips that they rely on to produce cars. And that was something they hadn't focused on for a long time, they thought of their supply chain as being about engines, and wheels, and axles, and other parts of the car that you think of when you think of car parts. But today, contemporary cars require a lot of chips, hundreds or even thousands of chips for the most sophisticated cars. And the thing about cars, if you're missing just one chip, your car often doesn't work. And during the pandemic, car companies found themselves often in that situation. Just a single chip, often even the cheapest chips, were causing them to have to leave cars in the factory parking lot as they waited for the right chip to arrive. And that illustrated a couple of things. First is that complex manufactured devices, like cars, need a lot of chips. Second, they don't just need the same type of chip, they need a thousand different types of chips produced by different manufacturers. And if even one of those is late, the car has to wait until it arrives. And the third thing it illustrated is that it's not just the tech sector that needs chips, it's actually everything. It's cars, it's tractors, it's medical devices, all of these faced shortages during the pandemic because they couldn't get the types of chips that they needed. And the really interesting thing about the pandemic that most people don't realize is that we didn't actually produce fewer chips. We actually produced more chips each year of the pandemic. The problem was that supply couldn't keep up with demand. And we had demand in segments in the industry that we weren't expecting. That created hundreds of billions of dollars of losses for manufacturers like automakers, because they couldn't finish the goods that were sitting in their factory parking lots, and therefore couldn't sell them. And that matters, because the shortages we saw in 2021 and 2022 are tiny in comparison to the shortages we would see if something happened to a large scale chipmaker, like those in Taiwan. Anything that disrupted chip production in Taiwan would be catastrophic for the world economy, for the United States, for Europe, for Japan, for everyone, because everyone relies on chips made in Taiwan. Earthquakes are one thing that could cause problems. And the reality is that Taiwan's had a lot of earthquakes, so they're pretty well prepared. And chip facilities, because they have to be extraordinarily safe from vibration, they're actually among the most earthquake-safe buildings that exist today. So it's not a guarantee, but it means that they've done a lot in terms of ensuring themselves from earthquakes. Water is one of the materials that's actually most widely used in chip manufacturing for a number of the manufacturing steps. And it needs to be ultra-purified water too. And so chip plants have to draw huge volumes of water from the local water supply, and then try to recycle that at the end to make sure there aren't any chemicals that are being discharged back into the environment. And it's a major challenge for chipmakers, because the volumes that they use are huge. And many of the places where chips are manufactured don't have surplus water. So in Taiwan, droughts have been an issue many times in recent years, and it's a major limitation on TSMC'S ability to expand its manufacturing footprint in Taiwan. The other is energy. Electricity is very important for chipmaking, and as we use more advanced chip making tools in factories, they require even more power to operate. And so electricity is a second limiting factor as well. And especially as countries try to use more green energy, that creates more challenges, because you need both more energy, but also you need energy that's perfectly reliable. And so the Sun or wind power can't always be relied on. Which means that if you're in Taiwan trying to map out your future power supply, you've got a limited number of options to look at. I think the bigger risk is not seismic, but rather geopolitical. It's that China carries through on the threats it regularly makes to use force against Taiwan to take control of the island. And for a long time, I think people wrote off that risk as unlikely, because for a long time, China was weak, and the United States was pledging to protect Taiwan. But today, China's getting stronger every single year, its military capabilities are growing on a regular basis. And this has raised questions about whether we need to worry that China might at some point move on Taiwan. And the problem is that even a small move, a small conflict would be disastrous for the chip industry, because it's not just about the security of the facilities themselves, it's also about the supply chain. Taiwan needs to import energy, needs to import chemicals, materials, tools, spare parts, many of which come from abroad, from Japan, from the United States, from Europe, energy coming in from the Middle East. And if any of this is disrupted, chip production could break down. And if chip production in Taiwan breaks down, that matters for everyone, because everyone uses Taiwanese made chips.

</details>

### AI革命：芯片需求激增与未来挑战

过去几年最大的变化是人工智能投资的爆炸式增长。2022年末**ChatGPT**（ChatGPT: OpenAI开发的大型语言模型）的发布，促使所有大型科技公司投入数百亿美元建设庞大的人工智能基础设施，这意味着数据中心将充满最强大的半导体。我们目前正处于新兴AI产业新一轮投资的早期阶段。可以肯定的是，这个行业将需要大量的半导体。因为AI历史上的一个关键趋势是，更先进的系统需要用更大规模的数据进行训练。如果想用更多数据训练系统，就需要更强大的计算能力，这意味着需要更好的芯片来训练。因此，如今**OpenAI**（OpenAI: 美国人工智能研究实验室）或**Anthropic**（Anthropic: 美国人工智能安全和研究公司）等公司正在花费数百万、乃至数十亿美元来训练其AI系统，其中大部分预算都用于购买**英伟达**等公司生产的超先进半导体。

训练一个尖端AI系统需要数万个英伟达最先进的芯片，并需要这些芯片连续运行数天甚至数月。这意味着需要投入数亿甚至数十亿美元用于数据中心容量，并且这些数据中心专门用于AI训练。由于摩尔定律，最先进的芯片平均比前一代性能提升一倍，因此数据中心需要配备最先进的芯片。即使芯片本身极其昂贵，每年购买英伟达最好的芯片仍有强大的经济激励，因为这实际上可以降低训练成本。

人工智能面临的一个关键挑战将是降低AI系统的部署成本。目前我们知道如何训练大型系统，OpenAI和Anthropic等公司正在这样做。但要使AI在经济中真正普及，其使用成本必须低到我们几乎无需考虑。这就像今天的**谷歌搜索**（Google Search: 谷歌提供的网络搜索引擎）一样，没有人会考虑“我的谷歌搜索价格是多少？”因为它的成本几乎为零。谷歌在数据中心上花费了一些钱，但成本如此之低，以至于你无需考虑。然而，今天的AI实际上相当昂贵。对ChatGPT的单次查询费用相当可观，以至于OpenAI有时不得不放慢推出新功能的速度，因为部署成本太高。许多公司正在探索如何更有效地进行部署。一些初创公司正在开创新的芯片设计模式，旨在提高AI模型部署的速度并降低成本。这对于使AI足够廉价并因此足够普及，从而对经济产生重大影响至关重要。

目前处于AI生态系统核心的英伟达芯片，其功能相当通用。它们可以训练多种不同类型的模型，并且对训练和部署都很有用。但如果为特定类型的模型或特定类型的部署设计芯片，就可以使其完美优化以适应该用例。因此，现在许多初创公司正在研究单个工作负载或单个部署机会，并表示：“我们将设计一个完全针对该用例进行优化的芯片。”这样，它将比英伟达GPU等通用芯片运行得更快、效率更高。不仅初创公司在涉足这个行业，大型科技公司如**Facebook**（Facebook: Meta Platforms旗下的社交媒体平台）、**微软**（Microsoft: 美国跨国科技公司）和**谷歌**（Google: 美国跨国科技公司）也在设计自己的内部芯片。因为它们了解自己数据中心内部的特定工作负载，并意识到，如果专门围绕这些工作负载设计芯片，在许多情况下，它们可以比英伟达的通用AI芯片更高效地运行。

在硅芯片上，晶体管的通断控制着电路的通断。因此，是电流流经刻蚀在硅芯片上的铜线，产生了芯片所依赖的所有“1”和“0”。所以，电是芯片工作核心。过去几十年，我们看到芯片在功耗方面变得越来越高效，但在计算能力方面也变得越来越强大。我们面临的一个挑战是，我们生产更强大芯片的速度，快于我们提高能源效率的速度。这意味着我们每年消耗的总电力都在增加。

当我们审视人工智能时，它涉及到一些最耗电的芯片。构建庞大AI基础设施的一个限制因素将是电力供应。因为大型数据中心，相对于不专注于AI的小型数据中心，需要巨大的电力增量。硅谷有许多聪明人认为，AI的最大限制可能不是芯片质量或AI背后的算法，而是向数据中心供电的能力。因为在许多情况下，这需要上线新的电源，建设新的发电厂，以提供电力来驱动这些新数据中心内部的芯片。

<details>
<summary>Original English Source</summary>

- [Announcer] Chapter four, "The AI Revolution."
- The biggest change in the past couple of years has been the explosion of investment in AI. The release of ChatGPT in late 2022 encouraged all the big tech firms to spend tens of billions of dollars building vast AI infrastructure, which means data centers full of the most capable semiconductors. And I think right now we're seeing just the early phases of a new wave of investment in an AI industry that is just emerging. And if we know one thing, it's that this industry will require a ton of semiconductors. Because one of the key trends in the history of AI is that more advanced systems require being trained on larger volumes of data. If you wanna train a system on more data, you need more computing power, which means better chips to train it. And so today, companies like OpenAI or Anthropic are spending millions and millions, and soon billions of dollars training their AI systems. And most of that budget goes to buying chips, buying ultra-advanced semiconductors from companies like NVIDIA. So to train a cutting edge AI system requires tens of thousands of NVIDIA's most cutting edge chips. It requires using these chips for days, or sometimes months on end. So you're investing hundreds of millions of dollars, if not billions of dollars in data center capacity, and using the data center solely for the purpose of AI training. And you need the most advanced chips inside, because the most advanced chips are twice as good, on average, than the prior generation due to Moore's Law. And so there's a strong incentive to buy the best chips that NVIDIA has every single year, because it actually drives down your training costs, even though the chips themselves are extraordinarily expensive. One of the key challenges of AI is gonna be to drive down the cost of deploying AI systems. So we know how to train big systems right now, that's what open AI and Anthropic and others are doing. But to make AI really widespread across the economy, we need the cost of using it to be so cheap we don't even think about it. It's sort of like Google Search today. No one thinks, "What's the price of my Google search?" Because it's approximately zero. Google spends a bit of money on the data centers, but it's so low, you don't have to think about it. Today, AI is actually pretty expensive. A single query to ChatGPT is an appreciable amount of money, such that sometimes OpenAI has to slow the rate at which it rolls out new capabilities, because it'd be too expensive to actually deploy. There are a lot of companies that are exploring, how do you do deployment more efficiently? And there are a number of startups that are pioneering new models of chip design that are intended to increase the speed and drive down the cost of deploying AI models. Which I think is gonna be really important in making AI cheap enough, and therefore prolific enough to make a major impact on the economy. NVIDIA's chips, which are at the center of the AI ecosystem right now, are pretty general purpose in their capabilities. They can train many different types of models, and are useful both for training and also for deployment. But if you design a chip for a specific type of model, or a specific type of deployment, you can make it perfectly optimized for that use case. And so a lot of startups right now are looking at individual workloads, or individual deployment opportunities, and saying, "We're gonna design a chip that's perfectly tweaked for that use case." And if so, it'll run a lot faster, and run more efficiently than a sort of general purpose chip like an NVIDIA GPU will. Now, this is startups tackling this industry, but it's also big tech companies, Facebook, Microsoft, Google, they're all designing their own in-house chips as well. Because they know the specific workloads that are inside their data centers, and they've realized, if they design chips specifically around those workloads, they can operate more efficiently in many cases than a general purpose AI chip like NVIDIA's can do. On a silicon chip, the transistors flipping on and off are turning on and off electrical circuits. And so it's electrons flowing through copper wires that are carved into your silicon chip that make all of the ones and zeros that chips rely on. And so electricity is at the center of how chips work. And one of the things that we've seen over the past several decades is that chips get much, much more efficient in terms of how much power they use, but they also get much, much more capable in terms of computing. And one of the challenges that we face is that we're getting better at producing more capable chips at a faster rate than we're getting better at producing energy efficiency gains. Which means that we're using more power, in aggregate, every single year. When you look at artificial intelligence, which involves some of the most power-hungry chips that exist, one of the limiting factors to building vast AI infrastructures is gonna be the availability of power. Because for big data centers, they require a huge increase in electricity relative to smaller data centers that aren't focusing on AI. And there are very smart people in Silicon Valley who think that the biggest limitation to AI might actually not be the quality of the chips, or the algorithms that are behind AI, it might be the ability to deliver power to data centers. Because in many cases, this requires bringing new power supplies online, building new power plants that are capable of delivering electricity to power the chips inside of these new data centers.

</details>

### 芯片的无处不在：现代生活的基石与未来展望

汽车是现代生活对芯片依赖的典型案例。一辆新车平均包含1000个芯片。从控制车窗升降、雨刷器摆动，到自动制动系统管理传感器并向刹车发送指令，再到内燃机中的芯片管理燃油喷射，以及GPS和显示屏中的多个芯片提供导航，这些都离不开芯片。这仅仅是几十个芯片，还有数百个芯片共同确保汽车正常运行。汽车并非特例，如今我们所依赖的一切，几乎所有带有开关的设备，都至少含有一个，通常是几十甚至数百个芯片。

要理解芯片的普及性，只需环顾你的公寓或房屋中的设备：洗碗机、微波炉、咖啡机、洗衣机，任何消费电子产品都需要芯片，而且往往不止一个。芯片越复杂，制造难度越大，因此公司收取的费用也越高。例如，智能手机中运行操作系统的芯片极其复杂，包含数十亿个晶体管，必须以极高的速度运行，同时尽可能降低功耗以延长电池续航。因此，拥有完美优化的智能手机处理器至关重要，这也是苹果公司自主设计其智能手机处理器的原因，它不信任其他任何公司来完成这项工作。相比之下，洗碗机或洗衣机中的许多其他类型芯片成本可能不到一美元，因为它们不需要执行特别复杂的任务。随着设备越来越先进，越来越多的设备连接到Wi-Fi和蓝牙，集成更多传感器和AI功能，我们预计未来将使用越来越多的芯片。

中美两国都将芯片视为当前技术竞争的核心。中国担心，由于其依赖从台湾和韩国（均为美国盟友）进口芯片，未来可能会被切断所需芯片的供应。目前，这种情况已在一定程度上发生，美国正在限制英伟达等AI公司向中国销售其最尖端芯片，因为美国希望将最先进的AI能力掌握在自己手中。因此，中国的担忧是可以理解的。美国则担心，如果向中国出售先进AI芯片，这些芯片可能不会用于优化外卖应用，而是用于军事和情报用途。美国的这种担忧并非毫无根据，因为正如企业正在探索如何使用AI一样，军队和情报机构也已在部署AI来优化其系统。因此，两国都认识到芯片将是AI竞赛的核心，并因此试图提升自身地位，实现自给自足，并阻止其技术惠及竞争对手。

截至2022年，美国已立法禁止将英伟达等公司制造的最先进AI芯片转让给中国。因此，如今中国企业可以获得经过美国限制专门降级、合法销往中国的较不先进的英伟达芯片。但如果想要获得尖端技术，就必须去国外。这些法规的目标是赋予美国企业优势，确保美国公司在AI领域处于领先地位，并由美国来制定AI发展规则。因此，中国AI行业的公司因此面临劣势，它们拥有较差的芯片，这意味着训练AI系统的成本更高，耗时更长，效率更低。这正是美国的目标，即“给中国AI生态系统的齿轮中撒沙子”，并希望美国因此能够遥遥领先。

促使美国国会通过《**芯片法案**》（CHIPS Act: 美国旨在促进半导体制造和研究的法案）有两个主要担忧。首先是对台湾先进芯片的依赖，其次是担心随着中国加大投资，美国相对于中国的技术优势正在缩小。因此，2022年，国会拨款约500亿美元用于投资美国芯片产业。其中一部分资金直接用于激励企业在美国建设新的制造工厂，而过去美国企业在这方面做得不多，主要依赖台湾和韩国的供应商。另一部分资金将用于研发，开发更好的芯片、更好的芯片制造设备以及芯片制造过程中使用的更好化学品，以帮助美国公司保持领先地位。美国政府认为（我认为这种信念是合理的），在芯片领域保持技术优势是维持在半导体下游一系列产业中优势的关键。随着AI在经济各个领域的部署，这一点已经显现出来。

审视当前AI芯片投资的激增，我没有理由怀疑摩尔定律不会在很长一段时间内继续有效。这意味着将有更先进的芯片，从而有更强大的计算能力可以应用于各种用途，包括AI和各种设备。这也意味着我们将使用更多的半导体，因为芯片越好，成本越低，应用范围越广，这是一个持续的趋势。因此，如果今天你的汽车有1000个芯片，十年后有10倍的数量，我也不会感到惊讶。这种基本趋势适用于我们所依赖的一切。而这只有通过芯片每年变得更好，以更低的价格提供更多计算能力才能实现。

迄今为止，最大的地缘政治风险是中美与台湾之间在**台湾海峡**（Taiwan Straits: 位于中国大陆与台湾岛之间的海峡）发生冲突。因为今天悬而未决的不仅仅是台湾的命运，更是我们整个经济的命运。如果你想到美国最大的公司，如苹果、英伟达、微软、亚马逊、谷歌、Facebook，它们都依赖目前只能在台湾制造的芯片。因此，这不仅仅是东亚地缘政治问题，更是关乎我们科技行业以及我们所依赖的所有设备的问题，因为今天，许多设备所依赖的芯片，在某些情况下只能由台湾的一家公司在一个工厂生产。这充分说明了台湾制造的芯片对我们生活方式的关键作用。

<details>
<summary>Original English Source</summary>

- [Announcer] How would you describe the ubiquity of chips in modern life?
- Well, I like to think of cars as a case study in how we rely on chips for almost everything. If you sit in a new car, it'll have, on average, 1,000 chips inside of it. It's a chip that makes the window move up or down when you press the button. It's a chip that manages the windshield wipers going back and forth. If you have any sort of autonomous braking features in your car, there's a chip that manages the sensor, a chip that sends that information to the brakes to step on the brakes if there's a object in front of your vehicle. If you've got a internal combustion engine, there's a chip that manages fuel injection into your engine to make sure it's operating the right way. There's of course, a chip that's attached to your GPS, multiple chips in the display that tells you where to go when you're looking for directions. I've only mentioned a dozen or so chips, and there are several hundred more that make your car work the way you expect. And cars are not really unique. Today, everything that we rely on, almost anything with an on-off switch has at least one, and often dozens or hundreds of chips inside. The other way to think about the ubiquity of chips is just to walk around your apartment or your house, and look at the devices. The dishwasher, the microwave, your coffee maker, your washing machine, any sort of consumer electronic you have, they all require chips. And it's often not just one chip, it's often a fair number of chips. And the more complex the chip, the harder it is to make, and therefore, generally, the more companies can charge for selling it. So the chip in your smartphone, for example, that runs the operating system, is extraordinarily complex, billions of transistors, it has to operate at extraordinary speed, draw on as little power as possible because your battery life is constrained. And so having perfectly optimized smartphone processors is really important. Which is why Apple designs its own smartphone processors in-house. It doesn't trust anyone else to do it. And so those chips are really expensive, compared to many other types of chips that you'd find in a dishwasher or a washing machine, which can cost less than a dollar, because they're not required to do anything particularly complex. And the reality is that, as devices get more advanced, as we have more and more things connecting to wifi and Bluetooth, more sensors, more AI capabilities installed in devices, we're gonna be using more and more chips as far as we can see into the future. Both China and the U.S. see chips as really central to the technology competition between them right now. China's worried that because it relies on importing chips from Taiwan and from Korea, which are both U.S. allies, it's gonna be cut off in the future from getting the chips that it needs. And right now, that's already happening to some degree, the U.S. is limiting the ability of AI firms like NVIDIA to sell their most cutting edge chips to China, because the U.S. wants to keep the most advanced AI capabilities for itself. And so China's concerns are understandable. The U.S. is worried that if it sells advanced AI chips to China, they're gonna be used not for optimizing food delivery apps, but used for military and intelligence use cases. And the U.S. is not wrong to believe that, because just as companies are trying to figure out how they're going to use AI, it's already the case that militaries and intelligence agencies are deploying AI to optimize their systems too. And so both countries recognize that chips will be at the center of the AI race, and as a result, they're trying to improve their position, become more self-sufficient, and prevent their technology from benefiting their competitor. As of 2022, the U.S. has made it illegal to transfer the most advanced AI chips made by companies like NVIDIA to China. So today, if you're a Chinese firm, you can access a less advanced NVIDIA chip that's been specifically downgraded to meet the U.S. restrictions and is now legal to sell to China. But if you want the cutting edge, you've gotta go abroad. And the aim of these regulations is to give U.S. firms an advantage. To make sure that U.S. companies are leaders in AI, and that the U.S. gets to write the rules of how AI will play out. And so Chinese companies in the AI industry face a disadvantage as a result, they've got worse chips, which means that the cost of training AI systems is higher, it takes more time, it's more inefficient. And that's the U.S. goal, to kind of throw sand in the gears of China's AI ecosystem, and hope that the U.S. can race ahead as a result.
- [Announcer] What is the CHIPS Act, and what did it do to boost manufacturing capabilities in the United States?
- There were two concerns that prompted the Congress to pass the CHIPS Act. The first was reliance on Taiwan for our most advanced chips. And the second was a fear that the technological edge that the U.S. has vis-a-vis China was narrowing as China invested more and more. And so in 2022, Congress put forward around $50 billion to invest in the U.S. chip industry. Part of that money goes to directly incentivizing companies to build new manufacturing facilities in the United States, which in the past, they hadn't been doing much, they'd been relying on suppliers in Taiwan and Korea instead. And part of the money would go on R&D, building better chips, better chip making equipment, better chemicals used in the chip manufacturing process to help U.S. companies stay ahead of their competitors. Because the U.S. government believes, and I think they're justified in believing this, that keeping a technological advantage in chips is key for retaining your advantage in a whole set of industries that are downstream of semiconductors. And as we deploy AI in all sorts of different segments of the economy, you can already see that playing out.
- [Announcer] Chapter four, "The AI Revolution."
- The biggest change in the past couple of years has been the explosion of investment in AI. The release of ChatGPT in late 2022 encouraged all the big tech firms to spend tens of billions of dollars building vast AI infrastructure, which means data centers full of the most capable semiconductors. And I think right now we're seeing just the early phases of a new wave of investment in an AI industry that is just emerging. And if we know one thing, it's that this industry will require a ton of semiconductors. Because one of the key trends in the history of AI is that more advanced systems require being trained on larger volumes of data. If you wanna train a system on more data, you need more computing power, which means better chips to train it. And so today, companies like OpenAI or Anthropic are spending millions and millions, and soon billions of dollars training their AI systems. And most of that budget goes to buying chips, buying ultra-advanced semiconductors from companies like NVIDIA. So to train a cutting edge AI system requires tens of thousands of NVIDIA's most cutting edge chips. It requires using these chips for days, or sometimes months on end. So you're investing hundreds of millions of dollars, if not billions of dollars in data center capacity, and using the data center solely for the purpose of AI training. And you need the most advanced chips inside, because the most advanced chips are twice as good, on average, than the prior generation due to Moore's Law. And so there's a strong incentive to buy the best chips that NVIDIA has every single year, because it actually drives down your training costs, even though the chips themselves are extraordinarily expensive. One of the key challenges of AI is gonna be to drive down the cost of deploying AI systems. So we know how to train big systems right now, that's what open AI and Anthropic and others are doing. But to make AI really widespread across the economy, we need the cost of using it to be so cheap we don't even think about it. It's sort of like Google Search today. No one thinks, "What's the price of my Google search?" Because it's approximately zero. Google spends a bit of money on the data centers, but it's so low, you don't have to think about it. Today, AI is actually pretty expensive. A single query to ChatGPT is an appreciable amount of money, such that sometimes OpenAI has to slow the rate at which it rolls out new capabilities, because it'd be too expensive to actually deploy. There are a lot of companies that are exploring, how do you do deployment more efficiently? And there are a number of startups that are pioneering new models of chip design that are intended to increase the speed and drive down the cost of deploying AI models. Which I think is gonna be really important in making AI cheap enough, and therefore prolific enough to make a major impact on the economy. NVIDIA's chips, which are at the center of the AI ecosystem right now, are pretty general purpose in their capabilities. They can train many different types of models, and are useful both for training and also for deployment. But if you design a chip for a specific type of model, or a specific type of deployment, you can make it perfectly optimized for that use case. And so a lot of startups right now are looking at individual workloads, or individual deployment opportunities, and saying, "We're gonna design a chip that's perfectly tweaked for that use case." And if so, it'll run a lot faster, and run more efficiently than a sort of general purpose chip like an NVIDIA GPU will. Now, this is startups tackling this industry, but it's also big tech companies, Facebook, Microsoft, Google, they're all designing their own in-house chips as well. Because they know the specific workloads that are inside their data centers, and they've realized, if they design chips specifically around those workloads, they can operate more efficiently in many cases than a general purpose AI chip like NVIDIA's can do. On a silicon chip, the transistors flipping on and off are turning on and off electrical circuits. And so it's electrons flowing through copper wires that are carved into your silicon chip that make all of the ones and zeros that chips rely on. And so electricity is at the center of how chips work. And one of the things that we've seen over the past several decades is that chips get much, much more efficient in terms of how much power they use, but they also get much, much more capable in terms of computing. And one of the challenges that we face is that we're getting better at producing more capable chips at a faster rate than we're getting better at producing energy efficiency gains. Which means that we're using more power, in aggregate, every single year. When you look at artificial intelligence, which involves some of the most power-hungry chips that exist, one of the limiting factors to building vast AI infrastructures is gonna be the availability of power. Because for big data centers, they require a huge increase in electricity relative to smaller data centers that aren't focusing on AI. And there are very smart people in Silicon Valley who think that the biggest limitation to AI might actually not be the quality of the chips, or the algorithms that are behind AI, it might be the ability to deliver power to data centers. Because in many cases, this requires bringing new power supplies online, building new power plants that are capable of delivering electricity to power the chips inside of these new data centers. Well, when I look at the surge of investment in AI chips right now, I see no reason to doubt that Moore's Law won't continue for a very long time. That means more advanced chips, which means more computing power that we can apply to all sorts of uses, AI and all sorts of devices. And that means we'll be using even more semiconductors, because the trend has been that, as chips get better, they get cheaper, and we put them in more and types of uses. And so today, if your car has 1,000 chips, I wouldn't be surprised if it has 10x that number in a decade. And that basic trend is true of everything we rely on. And that's only made possible because chips get better, and they provide more computing for a lower price on an annual basis. The biggest geopolitical risk by far is that something goes wrong between China and Taiwan and the Taiwan Straits. Because it's not just Taiwan whose fate hangs in the balance today, it's our entire economy. And if you think of the biggest companies in the United States, Apple, NVIDIA, Microsoft, Amazon, Google, Facebook, they all rely on chips that, today, are only made in Taiwan. So it's not just a question of geopolitics in East Asia, it's a question of our tech sector, and it's a question of all the devices we rely on, because, today, for many of those devices, they rely on chips that, in some cases, can only be made by one company in a single factory in Taiwan. And so that illustrates the ways in which chips made in Taiwan are critical for the way we live our lives.

</details>