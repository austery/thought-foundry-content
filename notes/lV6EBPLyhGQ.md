---
area: "finance-wealth"
category: geopolitics
companies_orgs:
- OpenAI
- Microsoft
- xAI
- Meta
- Google
- Oracle
- NVIDIA
- AMD
- Broadcom
- Samsung
- SK Hynix
- TSMC
- GE Vernova
- Caterpillar
- FedEx
- 白宫
date: 2025-10-31
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- CNBC
- SemiAnalysis
people:
- 泓君
- Jason Furman
- Ethan徐
- Sam Altman
- Andy Grove
- Bill Gates
- 黄仁勋
- Elon Musk
- 扎克伯格
products_models:
- Stargate
- GPT-4
- GPT-4.5
- H100
- GB200
- Vera Rubin
- Dojo
- Llama
- Llama 4
- Sora
- Veo
project: []
series: ''
source: https://www.youtube.com/watch?v=lV6EBPLyhGQ
speaker: 硅谷101播客
status: evergreen
summary: 哈佛大学经济学家Jason Furman的研究指出，2025年上半年美国GDP增长将几乎全部来自AI基础设施建设。OpenAI等科技巨头正激进投入万亿美元建设数据中心，以应对“投资不足风险远大于过度投资”的行业共识。然而，美国电力系统发展缓慢，面临巨大电力缺口，涡轮机、变压器等供应链也存在严重瓶颈。文章深入探讨了AI大基建带动的行业、电力建设困境、高压直流输电等创新方案，以及中美在基础设施建设速度上的差异，揭示了这场AI军备竞赛背后的经济与能源博弈。
tags:
- ai-infrastructure
- crisis
- data-center
- financial
- power
- supply-chain-bottleneck
title: AI数据中心万亿基建潮：美国经济增长引擎与能源挑战
---
### AI大基建：美国GDP增长的新引擎

欢迎收听硅谷101。最近，哈佛大学经济学家Jason Furman（杰森·弗曼）的一项研究数据引人深思。他指出，在2025年上半年，整个美国**GDP**（Gross Domestic Product: 国内生产总值，衡量一个国家经济活动的指标）的增长，几乎将全部来自于人工智能的基础设施建设。如果将信息技术和软件这一部分拿掉，那美国**GDP**的增长将仅仅只有0.1%。

与此同时，OpenAI发布公告称，已完成公司架构重组，旨在为潜在的**IPO**（Initial Public Offering: 首次公开募股，公司首次向公众出售股票）铺路。其核心目标是未来承诺投入1.4万亿美元用于整个AI基础设施的建设。此外，OpenAI在架构调整前夕致信**白宫**，提到中国2024年新增电力为429**吉瓦**（GW: 电力单位，1吉瓦等于10亿瓦），而美国仅贡献了51吉瓦，希望美国政府能优先审批AI基础设施建设项目。

这些公司之所以如此激进，最根本的原因在于它们普遍意识到：“Underinvestment is riskier than overinvestment”，即投资不足带来的风险，要远远大于过度投资带来的风险。因为没有人想成为诺基亚。此前，OpenAI的5000亿美元“星际之门”（Stargate）项目已令人震惊，但现在这个“饼”已经画到了1.4万亿美元。美国也亟需基础设施建设，这是一个比想象中更加疯狂的大基建时代。极少数的美国科技公司正联合金融巨头，不成比例地对美国经济产生决定性影响。

本期节目将探讨这一轮AI大基建带火了哪些行业，以及为何美国的电力建设如此困难。今天，我们邀请到了字节跳动数据中心与能源项目经理Ethan徐，以及即将加入xAI的前特斯拉供应链总监王辰晟，一同聊聊AI军备竞赛背后的数据中心与能源之争。

### AI巨头的激进策略与投资规模

泓君: 现在所有AI巨头都在建设数据中心，你们觉得哪几家做得最猛？

Ethan徐: 新闻报道上，OpenAI和微软的5000亿Stargate项目是焦点。第二个是最近OpenAI与甲骨文合作的3000亿美元数据中心项目，尽管其中有重合。但据我所知，马斯克的xAI在数据中心布局和抢购方面也非常激进，扎克伯格的Meta也在全力投入。

泓君: 从你们的角度来看，哪些公司最激进，以及他们的策略是什么？

Ethan徐: OpenAI的野心非常大。他们公布的数据是要做10吉瓦的Stargate项目，但这可能只是一个开始，他们的野心可能是这个的10倍甚至更多，在未来5-10年内实现。

泓君: 十倍，那就是5万亿美元的一个产业？

Ethan徐: 我觉得这个数量级基本没有问题。美国现在的**GDP**是二十几万亿美元，这几乎要占到美国一年**GDP**的25%。

泓君: 当然也不是一年。

Ethan徐: 对，整体上占一年。我觉得这个比例很高。我们可以拭目以待，看看今年美国**GDP**增长中有多少是数据中心基础建设贡献的，这个比例到70%我也不会吃惊。

泓君: 你有可能低估了。

Ethan徐: 甚至有可能低估。我也看过一些黄仁勋或咨询公司的观点，他们也认为未来五年，整个数据中心基础设施建设的投资规模应该会达到5-7万亿美元级别。

泓君: 钱从哪来？

Ethan徐: 钱从哪来确实是一个很有意思的问题。我记得你们之前做过一期节目，讲的是钱从互相之间的循环经济的AI资本论循环，未来也是一种比较创新的融资方式。

泓君: 辰晟怎么看，哪一家最激进？

王辰晟: OpenAI肯定是相对比较激进的。它现在很多公告显示，未来几年与英伟达有一个10吉瓦的意向，与AMD有一个6吉瓦的意向，同时最近还有与博通的一个10吉瓦的意向，加起来就已经是26吉瓦。按照500亿美元一个吉瓦来算，这已经是一个1.5万亿美元的概念了。

泓君: 未来五年？

王辰晟: 对。同时，它在一些供应链上也非常激进地做其他布局。最近它与三星和SK海力士包了每月90万片晶圆的产能，基本上占了整个**DRAM**（Dynamic Random-Access Memory: 动态随机存取存储器，一种计算机内存）市场可能三分之一，**HBM**（High Bandwidth Memory: 高带宽内存，一种高性能内存接口）市场60%，就它一家。

泓君: 如果你是马斯克或者扎克伯格，你看到这个会怎么应对？因为你也不希望被他们卡脖子。

王辰晟: 所以每个公司现在从供应链角度可能做得都不一样。马斯克的xAI横扫了所有小型涡轮发电机。Meta过去几年来说，就已经做得非常激进，去各种买一些能源成本比较低的地来建设它的数据中心。最近在爱达荷州还是俄亥俄州，又有一个5吉瓦的项目上线，其规模基本能占大半个曼哈顿。谷歌也会做一些供应链上的布局，比如说把他们一些互联或光缆都会做非常激进的供应链产能买断。所以说，每个巨头都在发力，都不想在这场竞争中输人一头。

泓君: 微软我们好像没有提到。

Ethan徐: 微软的话其实也蛮有意思的。它去年与OpenAI的合作关系非常融洽，但在年初的时候，大家也看到一些新闻提到OpenAI和微软的关系已经有了一些变化，包括OpenAI开始去找甲骨文或其他公司合作建设数据中心，所以微软不是它唯一的数据中心提供商了。同时，微软可能也在某些数据中心开始暂停施工，或者退租了一些数据中心等等。我们看最近这几个月的发展，能够感觉到微软在数据中心投资这方面，是和其他公司比相对比较稳健一些的。OpenAI就完全是另外一种风格，几乎每隔一两个星期就会有一个非常大的公告，说要建5吉瓦、7吉瓦的数据中心，与普通公司合作，与整个产业链合作。所以能看出这两个公司可能在AI数据中心或整个数据中心行业的投资和策略方面，已经有一些不同了。

泓君: 所以就是说微软中间稍微缓慢了一点，最近又在加速？

Ethan徐: 对，现在能看得到微软，比如说最近刚刚宣布了一个全世界最大之一的AI数据中心刚刚落成。所以今天看到的微软，可能跟年初的时候看到的微软，可能又有一些不一样的变化。我觉得这个行业的变化确实还是蛮快的。可能年初的时候我记得微软的**CEO**（Chief Executive Officer: 首席执行官）也在公开采访中提到过，他觉得这个行业有一些过度建设，有一些泡沫，他是想用更稳健的方式去建设数据中心的。但是我们现在看到的是，微软速度也蛮快的，可能并没有像年初的时候说的那样很快地慢下来。所以我猜想也许各个公司高层在这一年过程中，他们的策略和想法上是有一些波动的，但是此时此刻能感觉到，所有人都基本上是全速前进了。

王辰晟: 我觉得几个巨头，包括谷歌、亚马逊和微软，他们的态度可能是因为他们过去在云上其实有很多的**数据中心**（Data Center: 集中存放计算机服务器和网络设备的场所，用于数据存储、处理和分发）投入了。像谷歌、微软他们现在已经有的**数据中心**可能已经超过10吉瓦。对于像OpenAI就从零开始发展的话，大家需要的增长速度是不一样的，因为它的基数不同，反馈出来他们的激进程度可能也会有不同的地方。

泓君: 这个点很关键，这是为什么我们现在经常听到的名字是Meta、xAI还有OpenAI，而不是这些云厂商的巨头，像谷歌、亚马逊和微软。我们刚刚其实提到了OpenAI，它在做Stargate项目，在抢地，在跟芯片厂商达成合作。马斯克也是在抢发电机，Meta也在抢地。我是在想，那你的芯片供应其实也就这么多，大家不会在某种程度上都有短缺吗？

王辰晟: 从纯产业链的产能来讲的话，芯片现在并没有像能源这么紧缺的一个状态。如果你每一片芯片把它用到刀刃上，从**台积电**（TSMC: 台湾积体电路制造公司，全球最大的专业集成电路制造服务公司）的产能，它也是在积极地去布局，所以它相对是比较充足的。包括像**台积电**，可能两年之前有在说**CoWoS**（Chip-on-Wafer-on-Substrate: 台积电的一种先进封装技术）它的先进封装的产能会有些落后，但是它最近也在说在亚利桑那州要建两个晶圆厂。其实这些产能已经在过去两年经历这个周期的时候，他们已经有在做投资了。我只能相信**黄仁勋**（Jensen Huang: 英伟达CEO）他的直接声明是对的，在**GPU**（Graphics Processing Unit: 图形处理器）芯片的供应上肯定是不缺的。但是可能会有一些别的配套产业上面会有一些额外的缺口，包括我刚刚提到的存储器，无论是说线束也好，甚至于一些数据机柜。但是可能这个缺口相比能源来说，它并没有那么大。

### “电力优先”与“投资不足风险”策略

Ethan徐: 我觉得这点可以补充一下。我能看到的一个比较重要的几个策略上的观点。一个观点就是我们刚才一直在聊的，所谓的“电力优先”或者是“Power First”这个策略。因为大家都已经明显看到，可能最缺的就是电。谁能拿到电，就意味着你能买更多的**GPU**，你就更有可能训练出更好的模型，你就可能获得更多的用户，更好的用户体验，从而占据更大的市场份额。而这样的市场份额，可能会给你带来更多的营收和利润，然后又可以再次循环到我拿这些营收和利润去买更多的电和地，继续让我的模型变得更好。所以“Power First”这个策略在很多大型公司里边是一个非常重要的策略。

Ethan徐: 还有另外一个策略是大家都考虑到的，就为什么这些公司都那么激进？最根本的一点是因为大部分公司现在都意识到一点：“Underinvestment is riskier than overinvestment”，就是所谓的投资不够给你带来的风险，要远远大于你过度投资带给你的风险。为什么会这样呢？像AI这个行业，大家目前可能有一个大致的共识，就是很有可能谁最先获得最好的AI模型，或者所谓的**AGI**（Artificial General Intelligence: 通用人工智能，能像人类一样理解、学习和应用知识的AI）的话，这家公司就会占据比较大的一个市场份额，其他公司的生存空间就会很快地缩小。所以投资不够的一个风险是非常大的。我们再看一下过度投资会有什么样的风险？你无非就是买了更多的地、更多的电、更多的房子建数据中心，最后你发现可能你买多了。无非就是你可以把它用作自己公司内部的一些使用，效率的提升，或者你可以把它租给其他人，或者就把这些地、电卖给其他公司。总体来说就是过度投资的风险，它实际上是有一个封顶的，因为它其实都是固定资产，然后这些固定资产你转卖它也是容易的。

泓君: 也是容易的。

Ethan徐: 比如说**GPU**你买多了，那你卖给其他公司也没有什么问题。所以它过度投资的风险相对来说是比较小的。而对于某些大的科技公司来说，如果投资不够，导致它没有在这场竞争中胜出的话，它有可能面对的是一个生死存亡的一个境地。所以这也是为什么绝大部分公司他宁愿多投资，哪怕华尔街现在已经有一些质疑了，是不是过度投资了，你们能不能收得回利润来，这个营收能不能覆盖住你们这个投资，甚至股价上也开始反映出来了。但是这些公司，我觉得现在都没有一个眨眼睛的，都是继续在加大投资。像所有公司今天说的话都是，我们年初的时候预算今年会投资这么大的规模，已经很震惊市场了，但是现在看起来我们还是投资的没有我们应该投资的那么多。所以这也是投资不足比投资过度风险更大的这个策略。

泓君: 对，因为没有人想当诺基亚。

王辰晟: 你跟股东说我4万亿的市值会变成3万亿的市值好呢，还是说我的4万亿的市值会变成0？然后你更多是说有个梦想说，我现在投资，如果我经历过这一场退潮，然后我活下来其他人死掉了，我就从4万亿可以变成10万亿。这是大家更喜欢听的一个故事，不代表它就一定会发生。

王辰晟: 还有一点，在硅谷有一句话就是比尔总会吃掉安迪。**Andy**（Andy Grove: 英特尔前CEO）是代表**Andy Grove**，英特尔的一届**CEO**。**Bill**（Bill Gates: 微软创始人）是**比尔·盖茨**。所以就是说你只要有基础设施，你只要有硬件，软件总有些办法可以想办法把你（的资源）运用掉的。这周早些时候**OCP**（Open Compute Project: 开放计算项目，旨在为数据中心设计和硬件提供开放标准）Meta的人就在里面说，其实他们目前的**GPU**光用来去做他们内部一些AI，比如说Instagram或者Facebook，然后去筛除一些不合适的内容，他们其实也已经需要很多算力了。他就算有多余的闲置算力，他用来做内部的降本，Cost Reduction，他其实也是完全可以用的。所以我觉得现在主流的这些公司都不会担心说这些会过度投资，然后他们没有办法去用掉，而更多的是说我怎么把我有的这些资源去做更好的配置，去扩大他的利润和收入。

Ethan徐: 我可以稍微补充一下辰晟刚刚讲的一点，就是为什么大家要建大的数据中心。有两笔账，一笔就是经济账。谷歌自己也有发布过说，我在爱荷华州去建一个1吉瓦的AI数据中心，比同样分布式的，它一年可以省5亿美元的运营成本，因为它更加高效，无论是从输电、冷却、运营来说。这是谷歌一年在1吉瓦的这个数据中心可以省5亿美元。同时从一个AI算力的训练角度来讲，比如说**GPT-4**（Generative Pre-trained Transformer 4: OpenAI开发的大型语言模型），按照以前一张**H100**（NVIDIA Hopper H100: 英伟达高性能AI加速卡）的卡，需要差不多16000张卡，90天的时间去做这样一个1.7万亿数据量的模型的训练。如果到**GPT-4.5**，它可能是10的26次方，它需要的可能是一个两三倍的卡，甚至于说一个**GB200**（NVIDIA Grace Blackwell GB200: 英伟达新一代AI超级芯片），25000张卡也需要90-120天去计算。在这样一个AI军备竞赛的前提下，你肯定是不希望你需要花一个季度甚至以上，三四个月才能训练出一个模型。你更加希望的是，你每一周或者每两周可以去有一个模型，然后你不停地去进步，不停地去迭代。所以它会造成了一个指数级别（的需求）。所以从一个万卡集群变成十万卡集群，甚至到百万卡集群，而且你可能需要训练更大的一些数据模型的体量。这样就会把整个AI数据中心的算力从以前一个30**兆瓦**（MW: 电力单位，1兆瓦等于100万瓦）的AI数据中心推到一个可能1吉瓦，甚至于5吉瓦的这样一个数据中心的体量，因为大家都不想输。

### 训练与推理：数据中心需求的变化

泓君: 那我再问一个更底层一点的问题，大家为什么需要建这么大的数据中心？我知道大数据中心跟小数据中心是一个问题，还有一个更底层的问题是，你们觉得这个数据中心未来用的更多的是做模型的训练，还是用作应用方向？就是说我们还需要这么大规模的预训练的电量吗？还是说它只是说大家都开始用AI代替日常的这种搜索，代替日常的这种应用，它的整个的产业规模会很大，就是这个数据中心是支持谁的？

王辰晟: 两年之前的话，大家主要可能有60%-70%算力是用于做预训练的。当然预训练也有它自己的瓶颈，包括现在有很多不一样的工程上的（优化），无论是从有专家的模型，包括说有一些训练后去做强化学习的，这些都是一些厂商觉得怎么样提高这个模型的效率，而从预训练转换成一个后训练的过程。同时因为这本经济账，大家要确保我有收入，训练是不能给你带来收入的，而一定要从应用或者订阅交的会费才能给你带来收入。所以大家现在所有的大厂都是转型到了把更多的资源用到推理上。今年早些时候，推理和训练的比例已经转成推理会占比更高，可能有六成，训练是四成。我的理解是它之后可能推理的比例会大大增高，甚至占到80%以上。所以我理解现在的数据中心是给这些AI厂商做推理来用的。

Ethan徐: 我基本上同意这个观点的。在未来的话，一定是推理和应用那方面的数据中心的利用，或者是能源的利用，那个一定是会占比越来越高，而且是占大头的。但是当然了，AI的训练它是需要不断地去迭代的，会有更好的模型出来，所以那个一定也会有一定的占比的。但是很高兴看到推理的占比越高，意味着它越来越多的在应用层面开始创造出价值。就像微软**CEO**之前说的，AI只有在真正创造**GDP**的时候，才是有价值的时候，那个也是真正关键的时候。

泓君: 所以根据你刚刚的观点，就是现在大公司他们如果激进，他们可能留下的是一堆的固定资产。如果往回撤的话，那他未来可能他要发展所有这些AI应用，他后面的算力跟不上。整体大逻辑是这样子的。

Ethan徐: 对的，是这个逻辑。

泓君: 那我们一定需要这种大的数据中心吗？小的数据中心行不行？就是我们零散地把一些，我假设就是居民用电的这些闲置的电集中起来，然后再做储能，再分配给各个应用或者大厂，这种方式是有可能的吗？

王辰晟: 它有一个基础，如果是做训练的话，它其实这个规模可能不太允许它去做这样的一些调整。因为它需要所有的**数据**（Data: 经过收集、整理和加工的原始事实）再同时进行计算，需要机柜和机柜之间的互联，所以它需要一个大的集群。但是如果去做推理的话，它其实是可以根据用户的需求去进行一个合理的配置，然后用现在的闲置的算力或者电力去做的。这个有点像以前**PPTV**（PPLive: 中国早期的网络电视平台），或者说类似于这样的一些产品。确实现在也有一些公司在用闲置的算力去做，比如说**Novita**（Novita: 一家提供低成本算力的新兴公司），它是一个新兴公司，更多的就是用闲置的这些算力，提供一个更低成本的算力，相比别的供应商。可是你作为一个大厂的话，你更多的是说要去算一笔经济账，无论是说我用户需求的时候，我是不是它一直有可用性，它一直能去调用这些算力资源。同时如果是分散的话，它的管理、物流各方面，它其实是没有效率的。包括我刚刚也提到，如果它有个大的规模集群，它又可以用来做训练，等到不需要训练的时候，把这些用来去做推理的话，其实这个经济账是更容易算的。因为它能更好地去做整个电力的分布，以及它的一些备电的备份，甚至于说冷却当中的这些运营成本，它都是可以大大降低的。

Ethan徐: 没错，我也非常赞同。可能要看具体的应用是什么，它可能会决定对数据中心的要求是什么样的。举一个例子，现在大家也有一个初步的共识，就是对于AI的训练来说，也许这样的数据中心并不需要离大城市太近，也不需要可靠性太高。因为可靠性不高的后果，无非就是影响了一下你公司内部的一些研究人员的进度。一些AI的云厂商，如果他要提供给第三方客户的话，他的可靠性可能需要达到所谓的“5个9”这样的可靠性，就是99.999%的可靠性。但是对于AI的训练来说，也许不需要达到那么高，也许“3个9”，99.9%就可以了。而这些AI的数据中心又需要很多能源，所以也许它可以建在离能源更接近的地方。就比如说OpenAI他们这个策略，我觉得就是非常好的策略。他们是把他们的Stargate的很大一部分项目放到了德州的西部，而那是一个又有风又有光，同时还有一定的电网接入能力的地方，而且还有大量的地。这就非常适合做AI的训练了。所以它并不是所有的数据中心都需要和客户离得那么近。所以这个时候，在资源非常紧缺的情况下，可能就可以根据你的应用的不一样，去看你的数据中心要建在哪个地方，去实现什么样的目标。

### 美国电力困境：缓慢增长与巨大缺口

泓君: 数据中心首先我们说它需要有电，其次它还需要有发电机跟各种各样的小型的我们可能想不到的设备，比如说变压器，还有一层就是它需要有芯片。这三个问题怎么解决？我觉得我们今天可以一个一个地来分析一下。首先是数据中心现在的电从哪来？Ethan我记得你之前其实在我们节目上讲过，整个美国的电它是处在一个比较稳定的增长状态，但从今年的数据来看还是这个样子吗？

Ethan徐: 我记得在上周，**黄仁勋**和一个**CNBC**（Consumer News and Business Channel: 美国消费者新闻与商业频道）的采访中，他也提到它可以生产出整个市场所需要的**GPU**没有问题，但是现在最大问题是没有电。你有了**GPU**你没有电，你也没办法去运行你的数据中心。在过去的20年，美国的整个电力系统的发展是非常缓慢的，它几乎是以每年低于1%的增速在慢慢地扩张自己的电力系统。这和中国几乎百分之五六七这样的年增速是完全没有办法比的。美国过去20年的**GDP**或者是经济的发展和它的电力系统的发展几乎是脱钩的。这也导致一个问题，哪怕你现在开始加倍你的增长速度，那也只是2%而已。所以这个增长速度是远远跟不上数据中心的高速增长速度的。美国的新增电力的负载当中，我们估计数据中心可能就会占到40%左右。剩下的60%可能是电动车的增长或者是生产制造业的回流到美国等等，但是这个也是要看经济发展的状态的。

Ethan徐: 还有一个数据可以分享的是，像有一些机构他们预估出来是，美国每年应该需要增加大概80个吉瓦的发电量，才能够大概地满足美国的数据中心、电动车和生产制造业的回流到美国这样的一个增长的需求。但是目前来说，美国每年的发电量增长可能只有50多到60左右这个水平。也就是说，每年可能美国面临的是大概20个吉瓦的发电量的一个巨大的缺口。如果保持这样的缺口的话，未来5年左右，很可能美国将会面临一个大概100个吉瓦的发电量缺口。因为今天的话，美国的总发电量大概是在1300个吉瓦，所以这个缺口占的比重也是非常大的。

泓君: 20个吉瓦是一个什么概念？比如说一整个纽约市或者旧金山的发电量会有20个吉瓦吗？

Ethan徐: 这个是很好的问题。像纽约的话，它的平均用电量大概是在6个吉瓦左右，它每年的峰值可能是在十一二个吉瓦左右。所以如果说是差20个吉瓦的缺口的话，那这个缺口可能就相当于可能2-3个纽约的发电量的水平。

泓君: 但现在我们说居民用电跟工业用电都要保证，AI的数据中心也得建，因为它用户数一直在增长的。所以现在缺的这部分电从哪来？或者说我们拉回到现在的这个时间点，现在对于AI来说大家缺多少电？

Ethan徐: 我们预估出来，可能今年数据中心可能会新增大概8个吉瓦的新增用电量。这个电从哪里来？美国过去几十年的电网建设中，它有一些余量。还有一个就是像**GE**（General Electric: 通用电气公司）这样的公司，也在大量地制造和出售自己的天然气发电站。还有一些清洁能源，也有一些研究机构预测，像新增的这些发电，可能60%会需要靠天然气发电站，40%左右可能是需要靠光伏、风能和储能这些来弥补。当然我们希望未来像核能能够尽快地成为一个新的主力。现在美国的发电当中，大概20%的发电是来自于核能，但这些都是属于过去几十年一直存在的存量核能。像新增核能这一块的话，我们可能还要等到比如说2028年左右，才会看到新增的核能上线。像一些新的核能技术，比如说小型或者微型核反应堆，像**SMR**（Small Modular Reactor: 小型模块化反应堆，一种紧凑型核反应堆设计）这样的技术，我个人估计可能还要等到2030年左右，才会真正地成为主力。

泓君: 我看最近**Sam Altman**（OpenAI CEO）他投了一家公司，他们是做小型的核裂变反应堆的，股价也是涨得很厉害。这家公司叫**Oklo**。

Ethan徐: 它这个股价确实涨得是非常疯狂的，但是我也没有想到它在短短的几个月之内就能上涨那么快。我觉得这应该更多的不是反映基本面，而是反映市场对它的期待和情绪，而不是它技术本身基本面在突飞猛进，或者是施工运营方面在突飞猛进吧。

泓君: 所以这家公司它现在是已经实际用于发电了吗？还是并没有？

Ethan徐: 现在还并没有。我记得有一次开一个能源和AI相关的会的时候，**Oklo**的一个高管他跟我们观众说的是，他预计最理想的情况可能是2027年能够开始实现商业运营。但是据我过去对核能行业的理解，其实核能是一个难度非常大的一个行业，跟软件行业跟IT行业是不可同日而语的。所以我觉得这个日期可能是比较乐观的。但是考虑到美国过去几十年核能这个行业基本上没有怎么动过，很多人才也去转行做了其他行业，很多地方可以说是断档的。所以如果要很快地把核能能够开始进行规模化的商业运营的话，我觉得这个时间可能没有那么的乐观吧。

王辰晟: 我补充一点，美国一年增加五十几吉瓦时的发电量，但是更多其实它的组成当中，如果是按照火力发电，它的组成其实不到5吉瓦。所以更多的是大概有差不多45吉瓦是太阳能，另外5吉瓦可能是风能。这些发电都是不可持续的，它会有一个根据日照、根据天气的变化。所以它实际真的有效的发电量可能一年就不足20-25吉瓦。我觉得这个是更加去增加一个缺口的。算一笔账，我们按照数据中心的投资，**黄仁勋**有一个数据就是500亿美元1吉瓦。所以它整体的话，如果真的有60吉瓦，那它就是一个3万亿资本的投入。但是目前来说，所有的大公司预计明年的投入量基本上在1万亿不到一点。所以从整的发电的量来说，只看这个数字，我觉得它更多没有到一个这么缺的一个状态。如果把美国**GDP**的增长全部归功于AI数据中心的增长来说，因为它可能在电网里还有一些余量可以去使用。

Ethan徐: 你说的很对，如果是太阳能的一个吉瓦和一个天然气的一个吉瓦，其实是不一样的概念的。因为太阳能的话，只有在有阳光的时候你才能发电。所以还有一个概念叫做**容量系数**（Capacity Factor: 发电厂实际发电量与最大可能发电量之比）。你的平均发电大概是你的峰值的多少？像太阳能的话，可能只有25%左右。也就是说1吉瓦的太阳能的容量，最后发出来的电的话，平均下来可能只有1吉瓦的25%左右。但是如果是核电发电的话，就完全不一样。因为核能的话，它可以几乎全年一直都是在它的峰值发电，只有偶尔它需要维修保养的时候，才会需要把发电站暂时停一下。所以它的那个**容量系数**可能已经达到了93%左右。而天然气的话也很高，它在常年运行的历史数据可能会达到85%左右。所以不同的发电技术，虽然是同样的Gigawatt，但是它实际的发电量是不太一样的。

泓君: 所以你刚刚说的那个80吉瓦一年的需求是指一个混合的数据吗？

Ethan徐: 就是混合起来看，如果我们有一部分的天然气发电站，有一部分的光伏发电站和风能发电站，所有的这些吉瓦加起来，可能会在80个吉瓦左右。

### 电网脆弱与供应链瓶颈

泓君: 但是我又听说美国的电网是相对比较脆弱的，这个Ethan不知道你能不能多介绍一下？

Ethan徐: 美国的电力系统确实有很大的问题。我们一直在关注发电这个点，但是稍微有一点片面。因为数据中心需要的电的话，它其实是通过整个电力系统来获得电的，而不只是通过一个发电机、一个电厂来获得电的。所以我们要看的是从发电到输电到配电，整个产业链都得形成一个有效的系统，才能够给居民、工业或者是数据中心以足够的电。当然这里边最重要的一块确实就是发电。发电大概是占整个电力系统投资的大概50%左右。输电的话大概会占到百分之十几到二十左右。然后配电的话大概是占到20%-30%左右。这个输电网的发展在过去也是非常缓慢的。理想状况下，如果这些电站都能进入到美国电网里边，那么数据中心的供电是没有问题的。但问题就在于电网本身连吸纳这些新的发电站都能力不足。再并入到新的数据中心的时候，也会有很大的问题。

泓君: 刚刚辰晟有一个数据，你是说60个吉瓦差不多背后是3万亿的资金支持。所以反推OpenAI的Stargate如果说是5000亿美元的一个项目，它可能就能建成10个吉瓦的电。然后这10个吉瓦是现在在Stargate的一个规划中吗？如果说我们不管什么方式，就把这个电建成了，它是不是按照Ethan你刚刚的说法，它输入到这个电网，它可能也是有阻力跟难度的？

Ethan徐: 没错。现在我们了解到的Stargate，它目前的目标是能够建到10个吉瓦。现在可能已经签约和宣布的这些大概有个7个吉瓦左右。这些都还只是签约和意向，真正要到电网里边，应该还会有一些阻力。就比如说它需要在很多地方找到现存的容量。对于这么大的一个体量的话，很显然OpenAI或者它的合作的伙伴，像甲骨文，他们需要想办法去创造新的容量在电网上。现在的很多科技公司，他得自己去建发电机、建发电站、变电站和一些配网的设施，甚至建一些稍微短一点的电力传输线等等，去满足自己的需求。因为电力公司已经完全跟不上他们的需求了。

泓君: 我们刚刚提到了输电是一块问题，建电网跟发电可能就是一个更大的问题了。我注意到其实不管是OpenAI的Stargate项目，还是**马斯克**（Elon Musk: 特斯拉、SpaceX和xAI创始人）的xAI项目，其实大家现在用的基本上还是说燃气涡轮机的方式去建电网。但是这一块，辰晟你可能比较了解，涡轮机现在它的供应链是一个怎样的情况？它是不是也是一个比较短缺的物品？

王辰晟: 对，因为它本身的产能完全是不足的。因为你可以去看，包括**GE Vernova**（GE Vernova: 通用电气能源业务部门）的财报，它过去10年吧，它的增长其实是非常平缓的。到峰值的时候，可能是2019年、2020年的时候，大概到七十几台一年。每一台大概在30-50兆瓦。我们做一个对比，涡轮发电机其实和我们的飞机引擎就非常像。一年大概有将近4000台飞机引擎下线，而涡轮发电机市场最大占比的**GE Vernova**只有小100台。这是一个数量级的差别。一来是之前的需求没有这么旺盛，二来之前政府对于可持续能源、零碳排的这些标准，大家对于需要会增加碳排放的行业其实也没有这么多的投入，因为它相当于是一个夕阳产业。只有在最近，因为有AI数据中心确定的这样一个背景下，大家才找到了这样一个短期止损的这样一个方案，而不是说所有的数据中心现在都愿意去长期地使用涡轮发电机。更多的是说，如果我并入电网，需要一个两年的许可审批的时间，而我需要数据中心，比如说**马斯克**需要6个月就上线，那他们一年半的**时间差**（Gap: 差距或间隔）只能使用一些短期的，比如说涡轮发电机的这样一个状态。哪个公司也不一样，比如说xAI，根据公开的信息，它横扫了美国将近70%以上的燃气涡轮发电机的库存，已经用来给孟菲斯它两个非常大的数据中心供电。

泓君: 所以70%根据你刚刚一年的产量，差不多就是50多台？

王辰晟: 不，是存量。根据**SemiAnalysis**（SemiAnalysis: 一个专注于半导体行业的博客或研究机构）一个博主的分析，如果我没有记错的话，光Colossus 2它一个数据中心，它基本上有160台的涡轮发电机在那边给xAI提供发电。

泓君: 我想问一个问题，是不是涡轮发电机它其实也是分几种类型的？

Ethan徐: 涡轮发电机，比如说像**GE**的涡轮发电机的话，是几百个兆瓦的这种大规模的。现在可能是不是**GE**的发电机，我听他们财报说，已经2028年以后才可能接新的订单了。是不是现在大家就开始买一些隐形的发电机，是吧？这一部分是不是大家也开始扫货了？

王辰晟: 对，有一种就是通过飞机引擎改造的，叫**航空衍生燃气轮机**（Aero-derivative Gas Turbine: 由航空发动机改装而来的燃气轮机），通过一个蒸汽箱，无论是从发热转换以及它的蒸汽，做两个Cycle去提高它的燃料效率，做小型的涡轮发动机，比如说**Caterpillar**（Caterpillar: 卡特彼勒公司，主要生产工程机械和发动机）。可是它的产能也是一个需要很长时间去Build Up的这样一个过程。当然了，你造十台涡轮发电机也只抵得上一台300兆瓦的发电机，其实它对于供应链的挑战还是很大的。

Ethan徐: 所以大的涡轮发电机，它的发电效果是更好的，像你刚刚提到的**GE**的这种。然后小型的涡轮发电机它也是可以发电的，只是说它的功率没有那么强，或者它的效率是比大的涡轮发电机稍微差一点点。

王辰晟: 对，**GE**也做小型的，但是大型的更多只是供给原来的发电站。就像Ethan所说的，它每年美国可能之前火力发电只有少于5吉瓦，但是我现在需要20吉瓦。它短期供应链是需要很长的周期去做的。就像你说的，它现在的订单已经排到2028年了。

泓君: 中国可以做吗？

王辰晟: 中国据我所知，火力发电或者用天然气发电不是一个非常主流的选项。包括涡轮里面这些叶片，它需要一些专业的合金，这些都是到一个军工级别的Security。中国现在的产业并没有像美国或者韩国一些工业这么发达在这一块上。所以我理解其实就是造涡轮发动机，它是一个高技术产业，它并不是一个说我靠供应链跟制造优势就可以解决的问题。如果给一定的时间它肯定能解决，但是大家现在是在一个抢占能源的一个战争当中，所以并没有留给供应链这么多的时间。

王辰晟: 对，这是涡轮发电机的一部分。发电它可能还会有很多的零部件。我记得之前**马斯克**有一句话就是说“transformer lead transformer”，第一个说的是算法，第二个Transformer的意思就是说变压器。我知道变压器在整个市场上它也是一个供货周期很长，可能到18-24个月，这样一个非常缺货的产品了。但是它又是在你这个电厂发电中必须存在的一个环节。

王辰晟: 是的。先分享一个小故事吧。在大概一年半两年之前，**特斯拉**还在做**Dojo**（Dojo: 特斯拉内部的AI训练项目）就是我们自己内部AI Training的这个项目的时候，我们想要在Palo Alto硅谷的中心去建一个非常小型的，只有十几台Training的这样一个集群。那个时候Palo Alto市政府跟我们说，你们没有电。如果你们需要的话，现在交期已经从3个月涨到18个月了。当然**马斯克**的公司最后怎么做，就是我们自己买了两台变压器，然后给Palo Alto市政府装好，然后说我们交付给你，你们让我用。那个时候只是3兆瓦，现在我们动辄是谈3吉瓦，1000倍的差别。变压器这一块，其实它需要的就是一个基于电磁的原理，从一个高压转化到一个低压，到使用再传输。里面需要很多的特殊的钢材，**硅钢**（Silicon Steel: 一种用于变压器和电机核心的合金钢），或者说**取向型硅钢**（Grain-oriented Electrical Steel: 一种磁性能优异的硅钢，用于高效变压器），因为它会带一些磁力的方向，提高它的效率。这种钢材美国只有一家公司可以做，它每年的产能是25万吨。全世界大概有500万吨的产能，中国光**宝钢**（Baosteel: 中国宝武钢铁集团有限公司）一家大概有将近200万吨的年产量。所以美国在这个产业链上是非常落后的。据我所知，2016年、2020年包括2024年，美国政府都出了一些关于使用这些钢材，无论是反倾销也好，还是说**两党基础设施法案**（Bipartisan Infrastructure Law，或称OBBBA法案: 旨在促进美国制造业回流，限制从特定国家进口材料的法案）也好，都会有各式各样的法案去禁止这些美国的公司从中国来进相关的材料，因为为了想要发展制造业的回流。可是短期来说，美国的制造业并没有能力去接载这么大的一个体量的需求。这也造成了过去两年来说，它的交期一直没有有效地去缩短。

泓君: 我理解的所有的这些，包括**宝钢**这家公司，都是指的是原材料层面，而不是说真正地做成变压器的这个层面。

王辰晟: 是的。

### 数据中心供电创新：高压直流技术

泓君: 但我觉得今天我们再来聊建电厂的时候，可能变压器只是其中的一个环节。而最新的电厂就像英伟达，它其实有在今年的**GTC**（GPU Technology Conference: 英伟达GPU技术大会）上也讲了一种新的直输电场的方式，就是**高压直流**（HVDC: High-Voltage Direct Current: 高压直流输电，用于长距离或海底输电）的方式，包括他也提了一个800伏的**高压直流**输电的方法。大家可不可以讲一下现在整个数据中心跟电厂到底是在用新的这种方式去做，还是在用传统的这种方式去做？它的区别跟效率是怎么样的？

王辰晟: 英伟达这一次**OCP**展会上讲的800伏直流，更多的是用于数据中心以内整个AI数据机柜的输电。它是用来去替代之前的54伏机柜。我们先退一步来说，整个电是怎么产生的？**高压电线**（High-Voltage Power Line: 用于远距离输送高电压电力的线路）如果是跨距离传输，是350**千伏**（kV: 电压单位，1千伏等于1000伏特）的这样一个体量。到本地的一个变电站，大概是3.8-35**千伏**中压的电。它到数据中心之内，可能通过一个**UPS**（Uninterruptible Power Supply: 不间断电源，在主电源中断时提供备用电力）传到数据中心里面。目前来说一般是480伏或者415伏，它是**交流电**（AC: Alternating Current: 电流方向周期性变化的电）。通过一个交流转直流，把它转换成54伏，去给所有的芯片或者服务器去供电。为什么我们要去把54伏拉到800伏？是因为目前整个数据中心，就以**NVIDIA**的几代产品为例，它之前的**Hopper**（NVIDIA Hopper: 英伟达H100 GPU架构），我们所说的**H100**，它的一个机柜可能是一个30**千瓦**（kW: 电力单位，1千瓦等于1000瓦）左右的数量级。最近一代**GB200**，它一个机柜就到了100**千瓦**。它之后的**Vera Rubin**（NVIDIA Vera Rubin: 英伟达未来GPU架构），包括之后的这个卡，都是要往400**千瓦**甚至到1**兆瓦**一个机柜去做。我们简单算一个算术，功率等于电压乘以电流。**NVIDIA**自己有一个数据，如果你还是用54伏做柜内的传输，你一个一**兆瓦**的机柜就需要200公斤的铜用来做传输电。电流如果纯电阻，就是电压除以电阻，所以功率是和电压的平方是成正比的。也就是说你去增加电压，可以大大地减少你效率的损失。800伏**直流**（DC: Direct Current: 电流方向不变的电）和54伏**直流**，如果是一**兆瓦**的机柜，54伏可能需要光在传输电上会损失22%的效率。那我们现在缺电，当然这个损失是不能去承担的。如果拉到800伏的话，它的损失可以只在铜上会降到0.6%。这是好几个数量级的进步吧。

泓君: 现在数据中心是不是有做到800伏的**DC**的能力？

王辰晟: 目前并没有。现在主要还是以415伏交流为例。

泓君: 为什么并没有？是进不去电网吗？

王辰晟: 不是，是因为现在没有按照这个标准去做。有一点很重要就是**NVIDIA**的**黄仁勋**说他能自己造出所有的芯片，但是他没有电去Power他的芯片。所以他现在定这样一个标准，是想要整个生态链共同进步。如果你还是415伏的交流，54伏的直流，它一个1吉瓦的数据中心需要差不多50万吨的铜。这个是没有人可以去提供得了的。如果是做成这样，下一步可能就是缺铜了。所以他不得不要去促使整个产业链或者生态链去往一个更高的**高压直流**的数据机柜的输电，往这样去做转换。

泓君: 那卡点在哪呢？

王辰晟: 我觉得更多是在大家怎么去理解它这一周刚出的规范，以及怎么去把供应链拉起来去做规范的理解、设计、生产。

泓君: 是不是可以这样理解，就是这个规范其实就是看到今天的缺点，很严重的现实情况，要重新定义这个行业里边的各项标准？

Ethan徐: 现在刚刚发布这个新的标准，还需要一点时间让整个生态链的各个环节的企业重新设计他们的，比如说各种电器产品能够适应，或者是能够进入到这样一个新的标准当中。让我们看到了下一代的数据中心就有可能会根据这个标准去建立起来。这样的话，整个数据中心的效率等等都会提高很多。

王辰晟: 是的，是的。

泓君: 但我看见现在大家虽然没有去建800伏的**高压直流**，但是相比于你之前提到的54伏的**直流电**，已经有人开始尝试比如说200伏、400伏，大家已经在往这个方向去靠了，只是说我们还没有把那个标准一下拉得那么高。

王辰晟: 对，在**NVIDIA**的白皮书里面也有提到它的几个阶段，就是从415伏交流到54伏的直流转换，也有415伏的交流直接转成415伏或者400伏的直流去做这个机柜。之后再是说把整个配套的基础设施提到800伏，去内部直接做直流的这个传输。甚至于到最后的Ultimate Stage，就是用**固态变压器**（Solid-State Transformer: 使用电力电子器件实现电压变换）在数据中心的输电入口就直接做到800伏直流。当中可以去除一些**UPS**，以及整体的效率，把从92%-98%的效率甚至提到98.5%甚至99%的End to End的效率。

泓君: Ethan是不是我们去做这种数据中心的高压直流电，跟整个居民用电方式是完全不一样的？就是这个方式它是不可以提供给居民用电的，就限定了它只能做数据中心？

Ethan徐: 我的理解大概确实是这样的。因为我们现在整个的电力系统其实都是建立在所谓的**交流电力系统**（AC Power System: 以交流电为基础的电力系统）这个基础上的。刚才我们说的高压直流的这个概念，其实在电网侧其实也是有很多的应用的，尤其是中国。就比如说电网在传输电力的时候，如果是长距离传输的话，你的电流越大的话，你的损耗就越多。怎么让电流变小呢？你就把电压升高。所以这也是为什么我们在输电的时候，会需要很多的变压器。一方面变压器是要在发电机那一侧把电压提得很高，在传输的过程中它的损耗就会比较小。在用电的时候，你又在用变压器把它的电压给降低。这样的话就在居民或者是商业工业使用的时候，这个电压是比较安全的。所以在中国的话，其实建了很多的也是叫**高压直流**，不过那个是输电线的**高压直流**，那个可能就是500**千伏**、750**千伏**，那个电压就比800伏要高1000倍左右了。而现在我们看到的基本上整个社会都是以**交流电**作为一个主要的用电方式的。但是我觉得现在确实是到了一个时机，数据中心内部应该用**高压直流**来提高它的效率了。

Ethan徐: 2025年很有可能在美国数据中心的所有用电量加起来，可能会占到整个美国用电量的大概5%左右。就是整个加利福尼亚州整个今年的用电量大概是占美国所有用电量的大概是百分之六点几左右。也就是说今年数据中心的用电量就稍微比整个加利福尼亚州的用电量要稍微低一点点。而这个数字大概会在2030年的时候会翻倍。也就是说在2030年的时候，很可能整个数据中心行业的用电量是加州今天用电量的大概两倍左右。这是非常大的一个用电量。所以我也觉得到2030年大概会涨10%的话，这意味着这是一个很大的用电行业，完全值得为这个行业设计一套专有的用电的标准。就比如说**NVIDIA**的800伏这样一个标准，能够让整个占据美国用电10%的这个行业的效率，比如说提高20%左右，这是非常大的经济收益。我觉得我们可能看到的，比如说上周公布的这个报告，就是这一切的开始。

泓君: 大概给听众一个印象，我们用**ChatGPT**（ChatGPT: OpenAI开发的大型语言模型）搜索一次会有多耗电？

王辰晟: 它差不多就是用谷歌搜索一次耗电量的10倍。

### 中美基建差异与未来展望

泓君: 我另外看到一个数据是说中国今年整个电力的建设是有495个吉瓦的，美国今年的整个电力的建设是50个吉瓦。为什么中国可以建设得那么快，而美国在这么缺电的情况下，它的建设速度还是这么慢？

Ethan徐: 总体来说有几个主要的原因吧。一个就是中国的电网很多时候它有一个集中规划的概念，这和政治制度、经济制度是息息相关的。而美国的很多电网它是小区域局部规划，但是很少有跨区域的大规模集中的规划。当然美国也意识到有这个问题了，也开始做出这方面的改进，也有一些政策出来去鼓励这样做，但是这方面也刚刚开始。这和中国一直以来的电力从西边送到东边，从南方送到北方，通过**高压直流**，通过整个中国大规模的电网建设来实现电力的大规模传输，完全不能同日而语的。

Ethan徐: 还有一方面就是，在建设电网的过程中，你需要很多的审批。而在中国的话，它有一个相对集中的一种管理的方式吧。而在美国的话，很可能你的**高压传输线**需要经过一个农场主，这个农场主说不，我不允许你在这建。你可能就要绕道个几百个英里。而这个过程中，可能你会遇到几百个这样的农场主，你一个个谈下来的话，这个时间是非常漫长的。

泓君: 这就是为什么美国高铁建不成？

Ethan徐: 对，是同样的一个道理。所以还有一个数字可以给大家参考，在美国建一个新的长距离的传输线大概需要的时间是7-12年。这是非常漫长的一个过程。所以在过去的几年，美国几乎没有大规模的传输线建设。但这只是整个电力系统建设中的一角了。其实如果你看输电也好配电也好，整个建设都会遇到很多类似这样的问题。

泓君: 长距离传输线的建设主体是谁？是政府吗？我其实现在的角度是说，如果现在来做这件事情的人不是政府而是科技公司，因为他们其实有实打实的利润跟业务需求上的考量，所以他们是不是在做同样的事情的时候，它的推进速度会更快？

Ethan徐: 我觉得在整个电力系统建设的某些环节，科技公司是有优势的。但是在传输线进入这个环节，可能跟电力公司遇到的问题是一样的，你还是要去跟无数人去谈判，这个还是非常难的。所以现在科技公司采取一个策略就是，我不去参与很多大规模的传输线的建设，但是我走另外一条路，比如说我自己去建我自己的发电站，而我就把这个发电站建在我自己的数据中心附近不远的地方。很多东西是在它的经济资源、政治资源的影响力范围内，它可以做得更快更好的。

泓君: 数据中心的建设是需要大量的水吗？

Ethan徐: 在建设过程中水用得并不多。在运行的过程中，看你是用什么样的方式去制冷，可能会决定了你的用水的量。液冷用水量就会非常大。其实也看具体的技术，因为有些液冷量它是闭循环的，所以它用的水也不是很多。但是在数据中心运行过程中，用水量和用电量往往有一个此消彼长的关系。当你想降低用水量的时候，往往意味着你要用更多的电去制冷。如果你想降低用电量的话，可能你要依靠当地的很多水资源帮助你制冷。这也是一个矛盾的点。所以在数据中心的建设过程中，或者在选址的过程中，每个公司都会看，OK，在这个地区是不是电更多一些，还是水更多一些？要根据当地的禀赋，它可能会决定一个策略。

泓君: 对，我看其实现在整个科技巨头它在建数据中心的时候，还是有遭到很多当地居民的抵制的，不管你说污染还是缺水，就是各种各种各样的问题可能都会有。所以再回到我刚刚提的那个问题，为什么中国建设得这么快？Ethan你的观点是行政效率的问题？

Ethan徐: 对，我觉得可能还有一个原因就是成本的问题。一个是设备的成本，一个是人力的成本。中国在过去的可能10年左右，在政府还有政策的推动下，整个清洁能源行业的发展是非常非常快的。一个简单的数字可以让大家留下深刻印象，就是中国在一年的太阳能的装机容量，相当于世界上所有其他国家加在一起的总和，甚至有时候还更多。这也就意味着整个行业已经把清洁能源的发电成本已经压得非常非常低了。比如说我们看到大规模的储能等等，像美国的设备可能是中国价格的两倍左右。所以这个成本的差异也是一个比较大的原因。

### AI军备竞赛的投资机遇与挑战

泓君: 对，现在整个电力的建设带火了哪些能源股？

Ethan徐: 其实我们刚才聊的天然气涡轮机，像**GE**的话，可能是最受益的一家公司。因为在过去很多年我们一直在做清洁能源转型，要降低碳排放什么的，天然气的发电这个业务其实一直都不是很好。但是因为现在AI的爆发，需要发电特别多，所以天然气能够上线的速度又比较快。所以像**GE**这样的公司已经涨得非常高了，因为大家都已经明确地看到它的订单在疯狂地涨，它的溢价能力也非常高，需求还远远没有得到满足。除了这个之后比如说核能，但核能的话我个人认为可能不是一个短期能够实现的一个技术，但是未来的五年左右可以实现的技术。所以这块也应该是一个比较受益的板块。还有很多可能就是供应链上的很多一些规模稍微小一点的企业，比如说做各种电器设备的，可能还有一些做各种原材料的，比如说铜，就是一个很关键的原材料等等。我觉得这些企业和公司应该都会受益的。

泓君: 对，辰晟，之前有一个公司它是做化学燃料电池的，它可以短期去解决（问题），（如果）买不到天然气涡轮发电机，最近股票也涨得非常好。

王辰晟: 但是从资本的角度来说，它其实这笔经济账是算不过来的。同样100**兆瓦时**（MWh: 能量单位，1兆瓦时等于1000千瓦时），你一个涡轮发电机可能是在200个百万美元左右的投入。像一些其他的替代选项，它的资本支出投入可能要翻3-3.5倍。所以它可能要到700个百万美元。同样一个100**兆瓦时**，它的能源效率虽然提高了，但是它的燃料其实每年的运营的费用，可能同样100**兆瓦时**，它也要花额外可能20-50个百万美元的这样一个不等。你可能五年算下来，就要多花将近六亿到十亿美元，去解决一个100个**兆瓦**的能源。可是现在大家去做一些竞争，我要比你更快到通用人工智能，我要比你更快实现商业化。所以促使了大家疯狂地去购买这些产能。当然了，整条行业上面，现在如果纯从股票或者纯从供应链来讲，AI其实缺的东西是很多的。它从大到变压器这些基础设施，甚至小到芯片。之前我们过去两年一直在谈缺芯，无论是说这个芯片本身的晶圆的产能，包括**台积电**是全球独此一家做**CoWoS**一些特殊封装的这些产能，它其实还是在相对紧缺的这个状态。比如说因为**Sora**（Sora: OpenAI的文生视频模型）或者**Veo**（Veo: 谷歌的文生视频模型），OpenAI和谷歌的视频模型，它会转成说我对于我的储存的存储器，它的需求会有指数级的增长。造成了我看到一个研报说，明年年底如果不考虑现在的这些新的模型对于储存的需求，它的缺口还有5%-8%。如果我们考虑上的话，它的缺口可能会更加大。这是由于过去好多年产能没有有效投资，因为有经济的波动而造成的。所以其实各个方面都缺。

王辰晟: 我再举一个有意思的例子。比如说现在10万张卡的这样一个AI数据中心，如果之前我们训练**Meta Llama**（Meta Llama: Meta公司开发的大型语言模型）的时候，它用了差不多25000张卡还是16000张卡，训了54天。它训练平均3个小时会断一次，由于**GPU**产生的问题占到58%。那OpenAI训**GPT-4**的时候，或者Meta训**Llama 4**的时候，它用一个10万卡的级别，它平均32分钟就要宕一次，需要恢复大概15分钟。退下来的芯片当然是退回给**NVIDIA**。你光一个10万张卡，你每周1%的故障率，它可能就有差不多1000张卡需要去运回去。这是什么样的体量？它可能需要100吨。连**FedEx**（FedEx: 联邦快递公司）都要去买额外多的货车，去做这样一个运回100吨的卡。

泓君: 对，如果只有10万张卡的前提下的话，我们做一个合理的1%的退货的假设。

王辰晟: 所以其实整条供应链上，有太多太多的卡点现在是不能支持到这样一个体量的。

泓君: 我可不可以简单总结一下，整个现在AI的问题，我们理解前两年它是缺芯片，这两年它的核心问题就是缺电跟缺能源，以及搭建数据中心整个供应链环节各种各样的小的卡点？

王辰晟: 是的。

泓君: 好的，好的，非常精彩。我觉得我们之前的节目都还是在聊10亿美元的独角兽就算很大了，之后我们聊这个大模型可能是几百亿、几千亿的这种估值。今天我们是在聊一个Trillion Dollars，就是万亿美元的市场。感觉我们的野心也是在慢慢变大了。

Ethan徐: 没错，没错。这个投资的规模实在是太大了。

泓君: 对，我觉得这个也可以说是载入人类史册的一个投资时期。好，非常精彩，谢谢两位。

Ethan徐: 谢谢。

王辰晟: 谢谢，谢谢。

泓君: 这就是我们看到的现在整个美国经济冰火两重天的现状。一端是科技巨头热火朝天的大基建，另一端是传统的行业那0.1%的增长。那我们说，在这样的一个资金传导链条中，任何一个环节出现信任危机，不管是有公司的造假，或者是整个AI的落地不及预期，会不会是这个多米诺骨牌倒塌的第一步呢？感兴趣的听众可以给我们写下你的评论，我们一起来讨论一下。那这就是我们今天的节目。如果大家喜欢我们的节目，记得在小宇宙、苹果播客、Spotify上来收听、订阅我们。同样大家也可以在YouTube或者bilibili上搜索“硅谷101播客”来关注订阅我们。我是泓君，感谢大家的收听。