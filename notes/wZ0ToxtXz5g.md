---
author: Dwarkesh Patel
date: '2024-06-13'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=wZ0ToxtXz5g
speaker: Dwarkesh Patel
tags:
  - llm
  - agi
  - ai-benchmarks
  - intelligence
  - memorization
title: If an LLM solves this then we'll probably have AGI – Francois Chollet
summary: 本次对话探讨了人工智能的通用性问题，重点关注了ARC基准测试。嘉宾认为，如果一个多模态模型能达到人类80%的水平解决ARC，则可能预示着AGI的到来。讨论深入到智能的本质，将其类比为寻路算法，并对比了人类学习与LLM训练中的“记忆”与“推理”界限。文章还触及了通过大规模数据生成和自动化在静态分布下的潜力，以及当前模型相对于人脑的参数限制。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-work
project:
  - ai-impact-analysis
people:
  - Francois Chollet
  - Dwarkesh Patel
companies_orgs: []
products_models:
  - LLM
  - multimodal model
media_books: []
status: evergreen
---
### ARC基准与AGI的可能迹象

假设一年后，一个**多模态模型**（能够处理多种类型数据（如文本、图像、音频）的AI模型）能够解决**ARC**（A.R.C.: AI Reasoning Challenge，一个衡量AI推理能力的基准测试），并达到人类平均水平的80%，那么**AGI**（Artificial General Intelligence: 人工通用智能）很可能就指日可待了。主持人**Dwarkesh Patel**和嘉宾**Francois Chollet**对此进行了探讨。嘉宾表示，他个人希望看到一个**LLM**（Large Language Model: 大型语言模型）类型的模型能以80%的准确率解决ARC，但前提是其训练信息不包含明确旨在预测ARC测试集的内容。

### 智能的本质与基准测试的局限

嘉宾进一步阐述，ARC的核心在于其每次都呈现一种新型的**智能**（intelligence）挑战，而非固定模式。如果ARC是一个完美的基准测试，那么其内容就不应被预测。ARC自四年前发布以来，一直难以被“**记忆**”（memorization）所攻克，这在一定程度上证明了其有效性。然而，嘉宾也指出，如果通过手工创建数十万个ARC任务，再通过程序化生成数亿种变体，那么在训练数据和测试集之间就可能产生足够的重叠，从而导致模型得分虚高。这表明，在足够大的规模下，模型可能“作弊”。

### 智能的计算视角

如果一个模型可以通过“作弊”的方式解决所有需要智能的任务，那么智能本身的意义何在？嘉宾提出，或许智能就是一种可以被“**暴力破解**”（Brute Force）的能力。他将**intelligence**类比为一种“**寻路算法**”（pathfinding algorithm: 在图形或网络中寻找从起点到终点的最优路径的算法），在未来的情境空间中寻找路径。这类似于**即时战略游戏开发**（RTS game development: 一种电子游戏类型，玩家需要实时管理资源和单位进行战斗）中的地图探索，存在“**战争迷雾**”（fog of war: 游戏或战略中，指玩家对地图未知区域的遮蔽），玩家拥有的是部分信息，并且只能了解过去的地图状态而非当前状态。

### 现实世界的约束与类比

然而，这种寻路算法受到可用信息的严格约束，无法在未知领域找到路径，也无法预测变化。如果拥有关于地图的完整信息，路径寻找问题可以通过纯粹的记忆来解决。但在现实生活中，由于未来是不断变化的，我们无法做到这一点。嘉宾认为，在讨论人类学习时，我们很少使用“记忆”这个词。例如，当孩子学会代数再学微积分，我们称之为“学习”，而非“记忆微积分”。人类的学习和推理并非纯粹的记忆或纯粹的逻辑推导，这很大程度上源于我们对人类行为的语义化标签。

### LLM与人类学习的对比

当LLM通过基准测试解决数学问题时，这种行为常被归类为“记忆”。嘉宾认为，人类学习加法等基础技能，本质上也是在记忆一个算法或程序，而非实时合成。虽然人类发明了加法，但孩子学习加法并非从零开始推导。嘉宾的观点是，学校教育内容主要是记忆，而当前的AI模型在参数量和计算量上远不及人脑，因此它们无法像最聪明的人类那样创造新定理，但大多数人也做不到。大多数人类所做的，与嘉宾所称的“记忆”——即回忆学到的技能或技巧——非常相似。

### 自动化与未来工作

嘉宾进一步探讨了这种“记忆”模式在自动化中的应用。如果所有远程工作者都被模型取代，而这些模型是通过记录他们的屏幕操作并从中提取技能而训练出来的**synthetic data**（合成数据），那么我们是否仍然处于“记忆”的范畴？在这种情况下，我们将产生数万亿美元的经济活动。嘉宾总结道，通过记忆确实可以自动化几乎任何任务，前提是任务所处的环境是静态分布，且无需应对变化。