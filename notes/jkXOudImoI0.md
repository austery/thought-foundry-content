---
author: Big Think
date: '2025-11-21'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=jkXOudImoI0
speaker: Big Think
tags:
  - rationalism
  - intuition
  - neural-networks
  - allocation-economy
  - consciousness
title: 理性主义的局限：从苏格拉底到神经网络
summary: 演讲者探讨了理性主义从古希腊到科学启蒙的历史演变，将其基于规则、显性化的方法与现代人工智能（如神经网络和大型语言模型）的直觉、模式匹配特性进行对比。他认为，人工智能凸显了直觉思维的价值，挑战了传统科学方法，并将工作模式转变为“分配经济”，同时丰富了我们对人性的理解。
insight: ''
draft: true
series: ''
category: technology
area: society-systems
project:
  - ai-impact-analysis
  - systems-thinking
  - personal-growth-lab
people:
  - Dan Shipper
  - Socrates
  - Protagoras
  - Plato
  - Descartes
  - Newton
  - Galileo
  - Herbert Simon
  - Alan Newell
  - Freud
  - Eliezer Yudkowsky
companies_orgs:
  - Every
  - Big Think
  - Apple
  - Meta
  - Google
products_models:
  - ChatGPT
  - General Problem Solver
media_books:
  - Protagoras
status: evergreen
---
### 理性主义的局限：从苏格拉底到神经网络

我经常有机会与人们交流他们如何在工作和生活中使用人工智能，以及人工智能如何改变了他们个人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I get to talk to people all the time about how they use AI in their work and in their lives, and also how it has changed them as people.</p>
</details>

认识事物和理解事物有许多不同的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's many different ways of knowing things, and many different ways of understanding things.</p>
</details>

计算机和科学，这两种看待世界的方式都试图将世界简化为一套适用于任何情况的、极其清晰的普适法则。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Computers, science, what both of those ways of seeing the world are trying to do is reduce the world into a set of really clean universal laws that apply in any situation.</p>
</details>

如果X为真，那么Y就会发生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If X is true, then Y will happen.</p>
</details>

而语言模型看到的则是一个由世界不同部分组成的密集因果关系网络，这些关系以独特且高度依赖情境的方式汇聚在一起，从而产生接下来的结果。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what language models see instead is a dense web of causal relationships between different parts of the world that all come together in unique, very context specific ways to produce what comes next.</p>
</details>

关于**神经网络**（Neural Network: 模拟人脑神经元连接方式的计算模型）真正有趣的地方在于，它们的思考或运作方式与人类直觉非常相似。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting about neural networks is the way that they think or the way that they operate is a lot like human intuition.</p>
</details>

人类直觉也是通过成千上万小时的直接经验训练而成的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Human intuition is also trained by thousands, and thousands, and thousands of hours of direct experience.</p>
</details>

我喜欢这一点，是因为我希望它能让我们更清晰地看到直觉思维的价值和重要性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The reason I love that is because I hope that it makes more visible to us, the value and importance of intuitive thought.</p>
</details>

我是Dan Shipper，Every的联合创始人兼首席执行官，也是“AI与我”播客的主持人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">My name is Dan Shipper, I'm the Co-Founder and CEO of Every, and I'm the host of the AI & I podcast.</p>
</details>

### 理性主义的起源与影响

我认为**理性主义**（Rationalism: 强调理性是知识主要来源的哲学思想）是过去两千年来最重要的思想之一。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think rationalism is one of the most important ideas in the last, like 2,000 years.</p>
</details>

理性主义的核心理念是，如果我们能明确我们所知，如果我们能真正将所知简化为一套关于世界如何运作的理论和规则，那么这就是关于世界的真实知识，它不同于其他那些扰乱我们思绪、影响我们在社会中运作的一切。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Rationalism is really the idea that if we can be explicit about what we know, if we can really reduce what we know down into a set of theories, a set of rules for how the world works, that is true knowledge about the world, and that is distinct from everything else that kind of messes with our heads, messes with how we operate in society.</p>
</details>

你可能没有听过这个词，或者可能听过，但它已经融入了你观察世界的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you may not have heard that word, or maybe you have, but it is built into the way that you see the world.</p>
</details>

例如，计算机的运作方式、疫苗的作用原理、我们预测天气的方式，或者我们在思考“我不想对此过于情绪化，我想对这个问题进行精确思考”时做决策的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">For example, the way computers work, or the way vaccines work, or the way that we predict the weather, or the way that we try to make decisions when we're, you know, thinking about, I don't wanna be too emotional about this.</p>
</details>

即使是我们进行心理治疗的方式，很多治疗都关乎理性化，或者通过理性思考你所想和所感。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I want to get really precise about my thinking on this issue. Even the way that we do therapy, a lot of therapy is about rationalizing, or rationalizing through what you think, and what you feel.</p>
</details>

所有这些都源于古希腊开始、在启蒙运动期间真正繁荣发展的一系列广泛思想，现在已成为我们文化和我们思考世界方式的基石。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">All that stuff comes from an extensive lineage of ideas that started in Ancient Greece, really blossomed during the enlightenment, and now is like the bedrock of our culture, and the way that we think about the world.</p>
</details>

我认为理性主义的创始人是哲学家**苏格拉底**（Socrates: 古希腊著名哲学家，西方哲学的奠基人之一）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think the father of rationalism is Socrates, the philosopher.</p>
</details>

苏格拉底是第一批真正审视“我们知道什么以及如何知道”这个问题的人之一。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Socrates is one of the first people to really examine the question of what we know and how.</p>
</details>

什么是真的，什么不是真的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What is true and what's not true.</p>
</details>

能够描述我们所知以及我们如何知道，使其清晰明确，这样只有那些了解真相、了解世界真正运作方式的人才能掌舵国家。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">To be able to describe what we know, and how we know it, to make that clear and explicit so that only people that knew the truth, that knew how the world really works were the ones that were steering the state.</p>
</details>

这真正成为了哲学的诞生，即如果你深入探究我们对世界通常模糊不清的直觉，你就能找到、识别出一套关于世界是什么样子、什么是真什么不是真的规则或理论，你可以明确地阐述它们，并用它们来区分真假。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That really became the birth of philosophy, is this idea that if you inquire deeply into what is usually kind of like the in explicit intuitions that we have about the world, you can find, you can identify a set of rules, or a theory, about what the world is like, and what's true and what's not, that you can lay out explicitly, and that you can use to decide the difference between true and false.</p>
</details>

我认为理性主义的诞生可以追溯到**柏拉图**（Plato: 古希腊哲学家，苏格拉底的学生）的对话录《**普罗泰戈拉**》（Protagoras: 柏拉图的一部对话录，探讨美德是否可教）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think that you can trace the birth of rationalism to this dialogue, Protagoras.</p>
</details>

在对话中，是苏格拉底与**普罗泰戈拉**（Protagoras: 古希腊著名智者，主张“人是万物的尺度”）之间的辩论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And in the dialogue, it's a debate between Socrates on the one hand, and Protagoras.</p>
</details>

普罗泰戈拉是我们所说的**智者**（Sophist: 古希腊的教师和演说家，以修辞和辩论技巧闻名，有时被批评为诡辩）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And Protagoras is what we call a sophist.</p>
</details>

“诡辩”（sophistry）这个词就是由此而来，它指的是那种说得头头是道但实际上胡说八道的人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's where the term, sophistry which means like kind of, you know, someone who says really compelling things but is actually full of shit.</p>
</details>

普罗泰戈拉和苏格拉底争论的是：卓越能否被传授？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What Protagoras and Socrates are debating is, can excellence be taught?</p>
</details>

“卓越”（excellence）这个词在英语中常被翻译为“美德”（virtue），但我认为更恰当的翻译是“卓越”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And excellence, the word is often translated in English as virtue, but I think a more appropriate translation is excellence.</p>
</details>

在古希腊，这种卓越备受推崇。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And in Ancient Greece, like that kind of excellence was really prized.</p>
</details>

它有点像一种普遍的能力，能够擅长生活中和社会中的重要事情。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's sort of like a general ability to be good at important things in life, and in society.</p>
</details>

他们从截然不同的角度探讨这个问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And they approach it from very different angles.</p>
</details>

普罗泰戈拉认为每个人都有能力，每个个体都有能力变得卓越，他讲述了一个关于人类如何获得卓越能力的神话故事。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Protagoras believes that everyone has the capacity, every human has the capacity to be excellent, and he tells this big myth about how we, as humans, gain the capacity to be excellent.</p>
</details>

而苏格拉底则说：“不，不，不，我不需要那些。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And Socrates is saying, no, no, no, I don't want any of that.</p>
</details>

我想要的是一个定义。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What I want is I want a definition.</p>
</details>

我希望你明确地说出它是什么，不是什么，以及它的组成部分。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I want you to say explicitly what it is and what it's not, and what are the components of it.</p>
</details>

这是一个非常重要的时刻。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's a really big moment.</p>
</details>

至少在柏拉图的笔下，苏格拉底拆解了普罗泰戈拉的论点，到最后很明显，普罗泰戈拉无法以一种不矛盾的方式定义什么是卓越，什么是善良。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">At least the way that Plato writes it, Socrates kind of like takes apart Protagoras, and it's pretty clear by the end, that Protagoras doesn't know, doesn't have any way to define in a non-contradictory way what excellence is, what it means to be good.</p>
</details>

其含义是，那么他就不了解它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the implication is that then he doesn't know it.</p>
</details>

这使得西方社会走上了一条道路，即试图为我们所谈论的事物找到非常清晰的定义和理论，并将知识——即了解事物的能力，或者你是否了解某事——与你是否能清晰地定义它联系起来。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that sort of set western society on this path of trying to find really clear definitions and theories for the things that we talk about, and to identify knowledge, the ability to know something, or whether or not you know something with whether or not you can really clearly define it.</p>
</details>

这个思想在科学启蒙运动中变得极其重要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that idea became incredibly important in the scientific enlightenment.</p>
</details>

哲学方面的思想家，如**笛卡尔**（Descartes: 法国哲学家、数学家、科学家，西方现代哲学奠基人），以及科学方面的**牛顿**（Newton: 英国物理学家、数学家、天文学家，经典力学创始人）和**伽利略**（Galileo: 意大利物理学家、天文学家，现代科学的奠基人之一），都采纳了这个思想，并将其作为理解和解释世界的新方法。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Thinkers on the philosophy side, like Descartes, and on the science side, like Newton and Galileo, took this idea, and used it as a new method to understand and explain the world.</p>
</details>

因此，它演变为：我们能否使用数学来解释和预测世界上的不同事物？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So what it became is, can we use mathematics to explain and predict different things in the world?</p>
</details>

从苏格拉底到伽利略，再到牛顿，他们不断强化这一理念：要真正了解某事，你必须能够明确地描述它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And from Socrates, to Galileo, to Newton, they continually reinforced this idea that in order to truly know something, you have to be able to describe it explicitly.</p>
</details>

你必须能够有一个关于它的理论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You have to be able to have a theory about it.</p>
</details>

理想情况下，你必须能够用数学来描述它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You have to be able to describe it mathematically ideally.</p>
</details>

我们周围的世界就是由这个框架塑造的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The world around us is shaped by this framework.</p>
</details>

所以，从智能手机到电脑，到汽车，到火箭，到相机，到电力，你家里的每一个电器，疫苗，我们世界中的一切都是由这个思想，或者说这种看待世界的方式塑造的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So everything from smartphones, to computers, to cars, to rockets, to cameras, to electricity, every appliance in your house, vaccines, everything in our world is shaped with this idea, or this way of seeing the world.</p>
</details>

它的影响力是巨大的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's been incredibly impactful.</p>
</details>

你也可以在文化的其他方面找到这一点，比如每当你看到一本书、一部电影、一篇博客文章或其他什么，谈论“权力的五大法则”或“谈判的五大法则”时。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you can find this too in the rest of the culture, like anytime you see, you know, a book, or a movie, or a blog post or whatever, talking about like the five laws of power, or like the five laws of negotiation.</p>
</details>

所有这些都是物理学和普遍理性主义渗透到我们日常思考世界方式中的体现。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">All that stuff is ways that physics has, and rationalism in general has like sort of seeped into the everyday way that we think about the world.</p>
</details>

需要明确的是，它非常成功。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And to be clear, it's been super successful.</p>
</details>

但在心理学、经济学或神经科学等领域，以物理学取得进展的同样方式取得进展一直非常困难。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But in areas of the world like psychology, or economics, or neuroscience, it has been really hard to make progress in the same way that physics has made progress.</p>
</details>

我认为，如果你看看社会科学，例如，很多社会科学的结构都受到了物理学的启发。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think if you look, for example, at the social sciences, a lot of the way that the social sciences are structured is inspired by physics.</p>
</details>

我们试图做的是将非常复杂的更高层次现象——比如心理学、经济学，或者任何其他社会科学分支——简化为一套定义、一个理论和一套关于该领域事物如何运作的规则。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What we're trying to do is take very complex higher level phenomena, so like maybe psychology, or economics, or you know, any other branch of social science. And we're trying to reduce it down to a set of definitions, and a theory, and a set of rules for how things in that domain work.</p>
</details>

真正有趣的是，如果你看看这些领域，比如心理学，它正处于一场巨大的**可重复性危机**（Replication Crisis: 科学研究中许多发现难以被独立重复验证的现象）之中。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting is if you look at those fields, so like psychology, for example, it's in the middle of a gigantic replication crisis.</p>
</details>

尽管我们已经进行了大约100年的心理学研究，但我们在此建立的知识体系，就其普遍适用性而言，我们找到普适法则的能力，与牛顿找到普适法则的方式相比，似乎非常可疑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Even though we spent like 100 years doing psychology research, the body of knowledge that we've been able to build there in terms of its universal applicability, our ability to find, you know, universal laws in the same way that Newton found universal laws seems pretty suspect.</p>
</details>

我们觉得不能停止这样做，因为我们没有更好的替代方案。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we feel like we can't stop doing it because we have no better alternative.</p>
</details>

### AI与理性主义的局限

这个看待世界的方式在很多方面也未能奏效的另一个真正有趣且重要的领域是人工智能。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Another really interesting and important part of the world that this way of looking at things didn't work for in many ways is AI.</p>
</details>

所以，这通常是我试图定义“什么是AI”的部分。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So this is usually the part of an explanation where I try to define it. And like, what is AI?</p>
</details>

真正有趣的是，对于AI，并没有一个普遍公认的定义，就像我们很难就“知道某事是什么”或“焦虑是什么”达成普遍定义一样，后者在心理学中也是一个很好的例子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting is, there's no universal agreed upon definition for this, in the same way that there's, we've struggled to come up with a universal definition for what it is to know something, or universal definition for what anxiety is, for example, in psychology is another really good example.</p>
</details>

有很多方法可以大致描述AI是什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There are a lot of ways to kind of like gesture at what AI is.</p>
</details>

但实际上，很明显，或者也许不那么明显，AI代表**人工智能**（Artificial Intelligence: 模拟人类智能的机器能力）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But really it's like obviously, or maybe not obviously, AI stands for artificial intelligence.</p>
</details>

人工智能项目旨在构建一台能够像人类一样思考和学习的计算机。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the AI's project is to build a computer that can think and learn in the same way that humans learn.</p>
</details>

由于计算机的工作方式，在很长一段时间内，这是一个非常困难的问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And because of the way that computers work, for a very long time, that was a really hard problem.</p>
</details>

人工智能作为一个领域始于20世纪50年代的达特茅斯，你可以查阅原始论文。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">AI started as a field in the '50s at Dartmouth, and you can like actually look at the original paper.</p>
</details>

他们当时非常乐观，认为可能只需一个夏天的工作就能搞定。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They were very optimistic. They were like, you know, maybe like, you know, a summer's worth of work and we'll have nailed this.</p>
</details>

他们将其定义为能够将人类智能简化为一套符号系统，这些符号可以根据明确的规则组合在一起，从而模仿人类智能。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the way that they defined it is to be able to reduce down human intelligence into a system of symbols that they could combine together based on explicit rules that would mimic human intelligence.</p>
</details>

因此，从苏格拉底的最初项目到启蒙运动，再到早期人工智能理论家所采用的被称为**符号人工智能**（Symbolic AI: 基于逻辑规则和符号操作来模拟人类智能的方法）的方法，有着一条非常清晰的脉络。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so there's a really clear through line from Socrates's original project to the enlightenment, to the original approach that AI theorists took called symbolic AI.</p>
</details>

这种思想认为你可以将思维体现在本质上是逻辑、逻辑符号以及逻辑符号之间的转换中，这与基本哲学非常相似。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The idea that you could embody thinking in, essentially like logic, logical symbols, and transformations between logical symbols, which is, it's very similar to just basic philosophy.</p>
</details>

实际上，早期取得了很多成功。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there were actually a lot of early successes.</p>
</details>

例如，人工智能的两位创始人**赫伯特·西蒙**（Herbert Simon: 美国经济学家、计算机科学家，诺贝尔经济学奖得主）和**艾伦·纽厄尔**（Alan Newell: 美国计算机科学家，人工智能领域的先驱）构建了他们称之为“**通用问题解决器**”（General Problem Solver: 早期人工智能程序，旨在解决各种问题）的机器。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">For example, the two founding fathers of AI, Herbert Simon and Alan Newell, built this machine that they called the general problem solver.</p>
</details>

真正有趣的是，它甚至不是作为一台计算机建造的，因为当时的计算机极其昂贵。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting is it wasn't even built as a computer because computers were extremely expensive back then.</p>
</details>

他们最初在纸上编码了通用问题解决器，然后手动执行。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They originally codified the general problem solver on paper and then executed it themselves by hand.</p>
</details>

实际上，我认为其中一人还让家人一起参与，试图模拟计算机如何解决复杂问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Actually, I think one of them had their family do it with them to try to simulate how a computer would work to solve complex problems.</p>
</details>

通用问题解决器试图将复杂的现实世界情境简化为简单的逻辑问题，这些问题有点像游戏。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the general problem solver, they kind of, they tried to reduce down, you know, complex real world situations into simple logical logic problems, that they look a little bit like games.</p>
</details>

然后他们试图看看能否构建一台计算机来解决其中一些游戏。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And they were actually quite successful at first.</p>
</details>

他们发现它对简单问题非常有效。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What they found was it worked really well for simple problems.</p>
</details>

但随着问题变得越来越复杂，可能的解决方案的搜索空间变得非常非常大。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But as problems got more and more complex, the search space of possible solutions got really, really, really, really big.</p>
</details>

因此，以那种方式表示问题，他们构建的系统一旦脱离玩具问题转向更复杂的问题，就开始失效。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so by representing the problem in that way, the systems that they built started to fail as soon as they moved away from toy problems to more complex ones.</p>
</details>

我认为一个非常有趣且简单的例子是，思考你如何判断收件箱中的电子邮件是垃圾邮件还是重要邮件。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think a really interesting and simple example of this is thinking about how you might decide whether an email in your inbox is spam, or whether it's important.</p>
</details>

你可能会说：“如果它提到我中了彩票，那就是垃圾邮件”，对吧？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you might say something like, if it mentions that I won the lottery, it's spam, right?</p>
</details>

这种“如果-那么”规则，与早期符号人工智能理论家试图提出的规则非常相似，旨在帮助你解决任何问题，即将“如果X、Y、Z为真，那么这就是其含义”编码化。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so that sort of like if then rule, is a lot like the kinds of rules that early symbolic AI theorists were trying to come up with to help you solve any problem, is to codify like if X, Y, Z is true, then here are the implications.</p>
</details>

如果你仔细观察，总会有许多小例外。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What happens is if you look at that really closely, there are always lots of little exceptions.</p>
</details>

例如，如果邮件说“紧急”，你可能想把它放在收件箱顶部。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So an example might be, if it says emergency, maybe you wanna put that at the top of your inbox,</p>
</details>

但很快垃圾邮件发送者就会发现，只要在主题行加上“紧急”字样，邮件就会置顶。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But very quickly you'll have spammers obviously being like, just put emergency in the subject line, and they'll shoot to the top.</p>
</details>

所以你必须创建另一个规则，即“紧急”，但仅限于来自我的同事或家人的邮件。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So then you have to kind of like create another rule, which is it's emergency, but only if it's from my coworkers or my family.</p>
</details>

但计算机并不知道什么是同事或家人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But computers don't really know what coworkers or family is.</p>
</details>

所以你必须定义，好吧，它怎么知道谁是同事或家人？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So then you have to define, okay, like how is it gonna know what a coworkers or what a family member is?</p>
</details>

你可以这样做：也许同事是公司里的任何人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So what you can do is maybe it's like a coworker is anybody from my company.</p>
</details>

所以，如果邮件说“紧急”，并且来自我公司的任何人，就把它放在收件箱顶部。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so if it says emergency, and it's from anybody in my company, put it at the top of my inbox.</p>
</details>

但你可能会发现，公司里有些人很烦人，总想引起你的注意，即使你并不希望他们联系你。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But what you may find is that there are certain people at your company who are annoying and want your attention, even if you don't really want them to contact you.</p>
</details>

所以他们开始在邮件中加上“紧急”字样，现在你又必须创建另一个规则，比如“不要让那些滥用特权的人，即使是同事，也滥用置顶收件箱的特权”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so they start putting emergency into their inbox, and now you have to create another rule which is like, don't let people who are abusing the privilege of getting to the top of my inbox, abuse it even if they're coworkers.</p>
</details>

你发现，每当你试图创建规则来定义这些事物时，总会遇到例外。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what you find is anytime you try to create rules to define these things, you always run up against exceptions.</p>
</details>

例如，如果你想定义一封重要邮件是什么，你几乎必须定义关于世界的一切。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you wanna, for example, define what an important email is, you have to define pretty much everything about the world.</p>
</details>

你必须创建一个充满定义的世界。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You have to create a world full of definitions.</p>
</details>

而将整个世界明确地定义化的项目根本行不通。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that project of making the entire world explicit in definitions just didn't work.</p>
</details>

它太脆弱，太困难，需要太多的计算能力来遍历所有不同的定义，以决定这封邮件是否重要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's too brittle, it's too hard, there's too much computational power required to loop through all the different definitions to decide, you know, if this email is important or not.</p>
</details>

而且，需要创建的定义太多了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's just, there are too many definitions to create.</p>
</details>

这只是一个太大的项目。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's just, it's too big of a project.</p>
</details>

因此，那个符号人工智能项目在某些有限的领域奏效了，例如在20世纪70年代和80年代出现了所谓的**专家系统**（Expert Systems: 早期AI系统，通过编码人类专家的知识和推理规则来解决特定领域问题），它们试图将医疗诊断简化为一套规则。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so that symbolic AI project worked in some limited domains, and there were these things called expert systems, for example, in the '70s and '80s that tried to, for example, reduce medical diagnosis down to a set of rules.</p>
</details>

它们取得了一定的成功，但即使在医疗诊断这样的案例中，试图将“你是否得了麻疹”甚至“你是否有焦虑或抑郁”这样的问题简化为一套简单的规则，结果也证明非常复杂，非常困难。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And they were somewhat successful, but even in a case like medical diagnosis, trying to reduce down to a simple set of rules, something like do you have measles, or maybe even do you have anxiety or depression, turned out to be really complicated, and really, really hard.</p>
</details>

事实上，以明确的方式每次都做到100%正确是不可能的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And in fact, impossible to get right 100% of the time in an explicit way.</p>
</details>

### 神经网络与直觉思维的回归

另一种方法，大约在人工智能本身诞生的时候就出现了，但直到20世纪80年代和90年代才真正被认真对待，那就是**神经网络**（Neural Network: 模拟人脑神经元连接方式的计算模型）。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The alternative, which originated around the time that AI itself originated, but really wasn't taken that seriously until probably the '80s and '90s is what's called a neural network.</p>
</details>

神经网络受到我们大脑工作方式的启发。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And a neural network, it is inspired by the way our brains work.</p>
</details>

它并非完全以相同的方式运作，但确实受到了大脑的启发。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It doesn't work exactly the same way, but it is inspired that way. It is inspired from brains.</p>
</details>

它基本上由相互连接的人工神经元层组成。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it basically consists of layers of artificial neurons that are connected to each other.</p>
</details>

通过给神经网络大量的例子，你可以让它识别模式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what you can do with a neural network is you can get it to recognize patterns by giving it lots of examples.</p>
</details>

例如，如果你想让它识别一封邮件是否重要，你可以给它一个例子，比如“这是一封来自同事的邮件”，然后让它猜测答案。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can, you know, for example, if you want it to recognize like whether an email is important, what you can do is you can give it an example, say like, you know, here's an email from a coworker, and have a guess the answer.</p>
</details>

如果答案错误，我们已经创建了一种训练网络纠正错误答案的方法。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if the answer is wrong, what we've done is we've created a way to train the network to correct its wrong answer.</p>
</details>

结果是，经过许多许多次迭代和许多许多不同的例子，我们发现，在没有任何明确定义或明确规则（比如“这是一封重要邮件”或“这是一只猫”或“这是国际象棋中的好棋”）的情况下，神经网络学会了识别模式，并能够完成早期符号人工智能无法完成的许多更复杂的思维任务。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what happens is over many, many, many, many iterations, and many, many different examples, what we find is without any explicit set of definitions, or explicit rules about like, you know, this is a important email, or this is a cat, or this is a good move in chess. The neural network learns to recognize patterns, and is able to do a lot of the more complex thinking style tasks that early symbolic AI was unable to do.</p>
</details>

语言模型是一种特殊的神经网络，它通过在语言中寻找复杂模式并利用这些模式来生成序列中的下一个内容。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Language models are a particular kind of neural network that operates by finding complex patterns inside of language and using that to produce what comes next in a sequence.</p>
</details>

我们对语言模型所做的是，基本上将互联网上的所有文本都喂给了它们。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So what we've done with language models is fed them basically, you know, all of the text on the internet.</p>
</details>

当我们给它们一段文本时，我们会给它们一大块文本。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And when we feed them a piece of text, we'll give them, you know, of a big chunk of text.</p>
</details>

然后我们会说，基于这块文本，接下来的词是什么？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then we will say, based on this chunk, what's the next word that comes after this chunk?</p>
</details>

语言模型学会了有成千上万条部分适用的规则，它们可以根据之前看到的文本历史来预测接下来会发生什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And language models learn that there are many, many thousands of partially fitting rules that they can apply based on the previous history of texts they've seen to predict what comes next.</p>
</details>

所有这些规则都是非显性的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And all of those rules are inexplicit.</p>
</details>

它们有点像，你可以在网络的整体行为中观察到它们，但它们在网络中并不以任何形式存在。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They're kind of like, you can observe them in the overall behavior of the network, but they don't exist anywhere in the network.</p>
</details>

你无法进入神经网络内部，找到“这就是它拥有的全部规则集”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can't go and look inside of a neural network, and find like this is exactly, this is the entire set of rules that it has.</p>
</details>

你可能能找到几个，但你找不到一个明确的列表。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You may be able to find a couple, but you can't find a definitive list.</p>
</details>

就像我用显微镜观察你的大脑，我也无法找到那样一个列表。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the same way that if I like took a microscope and looked in your brain, I would not be able to find that.</p>
</details>

我无法找到你用来识别猫或下国际象棋下一步棋的规则列表。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I would not be able to find the list of rules that you use, for example, to, you know, recognize a cat, or do the next move in chess.</p>
</details>

它们都是非显性地表示的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They're represented all inexplicitly.</p>
</details>

神经网络真正有趣的地方在于，它们的思考或运作方式与人类直觉非常相似。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting about neural networks is the way that they think, or the way that they operate is a lot like, it looks a lot like human intuition.</p>
</details>

人类直觉也是通过成千上万小时的直接经验训练而成的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Human intuition is also trained by thousands, and thousands, and thousands of hours of direct experience.</p>
</details>

我们对心智的最佳隐喻往往是我们使用的工具。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Often our best metaphor for our minds are the tools that we use.</p>
</details>

一个很好的例子是**弗洛伊德**（Freud: 奥地利精神病学家，精神分析学派创始人），他提出了最具影响力的心智模型之一。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So a really good example is Freud, has one of the most impactful models of the mind.</p>
</details>

他提出这个模型的方式是，他将蒸汽机作为隐喻，所以这是一个明确基于蒸汽机的思想。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the way that he came up with that, is he used the steam engine as a metaphor, so it's an explicitly steam engine-based idea.</p>
</details>

在20世纪，我们心智的隐喻转变为计算机，这成为了我们都想成为的样子，我们想变得逻辑和理性，像机器一样运作以做出最佳决策。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the 20th century, the metaphor for our minds moved into being like a computer that became the kind of thing that we all wanted to be like, we wanted to be logical and rational, and operate like a machine to make the best decisions possible.</p>
</details>

我认为这种思维方式最有趣的一点是，它使我们看不见——我认为这与苏格拉底启蒙式的思维方式也有很大关系——它使我们看不见直觉作为我们所做、所想、所知一切的基础的重要性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think one of the most interesting things about that way of thinking is it makes invisible to us. And this, I think, relates a lot to the like sort of Socratic enlightenment type of thinking as well. It makes invisible to us the importance of our intuition in being the foundation of everything that we do, everything we think, everything that we know.</p>
</details>

在很多方面，你可以将理性视为从直觉中产生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In a lot of ways you can think of rationality as emerging out of intuition.</p>
</details>

所以，我们对世界上发生的事情有一种模糊不清的直觉理解方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So like we have this sort of like squishy inexplicit, intuitive way of understanding what's going on in the world.</p>
</details>

我们的理性思维从中产生，一旦直觉为我们设定了框架，它就能以更系统、更理性、更逻辑的方式进行操作。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And our rational thought comes out of that, and is able to, once intuition sort of sets the frame for us, is able to go in, and sort of manipulate things in a more methodical, rational, logical way.</p>
</details>

但你两者都需要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But you sort of need both.</p>
</details>

神经网络是我们发明的第一种像人类直觉一样运作的技术。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And neural networks are the first technology we've ever invented that works a lot like human intuition.</p>
</details>

我喜欢这一点的原因是，我希望它能让我们更清晰地看到直觉思维的价值和重要性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the reason I love that is because it, I hope that it makes more visible to us the value and importance of intuitive thought.</p>
</details>

这实际上又回到了普罗泰戈拉的观点，也是我们从理性主义诞生之初，在卡利亚斯家中失去的东西，因为普罗泰戈拉认为每个人都在不断地教导我们卓越。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that actually loops back and takes us all the way back to Protagoras, and is sort of the thing that we lost in this birth of rationalism, and back in Callias's house, because Protagoras is arguing that everyone teaches us excellence all the time.</p>
</details>

他通过故事、神话和隐喻来帮助理解他从个人经验中获得的知识。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">He's arguing, he's using stories, and myths, and metaphor to help understand something that he knows from his own personal experience.</p>
</details>

而苏格拉底则说：“如果你无法定义它，如果你无法准确告诉我你通过什么规则知道它，那么你就不了解它。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And Socrates is saying, well, if you can't define it, if you can't tell me exactly the rules by which you know something, then you don't know it.</p>
</details>

这种看待世界的方式对我们来说非常成功，但它也使我们对一个重要的观念视而不见：每个人都在教导我们变得卓越，故事和亲身实践的经验为我们提供了一种我们可能无法明确表达但仍然了解的知识，就像我们明确能说出的知识一样。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that way of thinking about the world has been very successful for us, but it also kind of blinded us to how important that idea that everyone teaches us to be excellent, that stories and personal hands-on experience give us a way of knowing about things that we may not be able to explicitly talk about, but we still know, just as much as we know things that we can explicitly say.</p>
</details>

直到我们开始将这种存在于世界的方式或这种认识事物的方式，这种思维方式融入机器中，我们才开始获得真正的人工智能。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it was only when we began to embody that way of being in the world or that way of knowing things, that way of thinking into machines that we started to get actual artificial intelligence.</p>
</details>

认识事物有许多不同的方式，理解事物也有许多不同的方式，我们可能无法理解人类，例如，我们的大脑如何直观地得出某些结论的所有细节。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's many different ways of knowing things, and many different ways of understanding things, and we may not understand all of the particulars of how, humans, for example, how our minds come to certain conclusions intuitively.</p>
</details>

我们也可能无法理解语言模型，例如，如何得出任何特定输出的所有细节，但这并不意味着我们不理解它们，它只是意味着我们以一种我们可能不习惯的方式理解它们。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we may not understand all the particulars of how language models, for example, come to any particular output, but that doesn't mean that we don't understand them, it just means that we understand them in a different way than we might be used to.</p>
</details>

例如，如果你经常使用**ChatGPT**（ChatGPT: 由OpenAI开发的大型语言模型，能够生成类似人类的文本），你会对它擅长什么、不擅长什么，以及何时可能产生幻觉、何时不会产生幻觉，形成一种直觉。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So for example, if you use ChatGPT all the time, you develop an intuition for what it's good at and what it's not good at, and when it might be hallucinating, and when it might not be.</p>
</details>

就像你可能会对你的朋友何时悲伤，或者何时没有完全对你坦诚，产生一种直觉一样。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the same way that you might develop an intuition for when a friend of yours is sad, or when a friend of yours is not being totally truthful with you.</p>
</details>

这并非一套适用于所有人、所有情况，甚至适用于你朋友所有情况的普遍规则。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's not a universal set of rules that applies to everyone in every situation, or even to your friend in every situation.</p>
</details>

它只是一种直觉感受，是理解的核心部分，但我们通常会忽视它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's just a sort of like intuitive feel that is a core part of understanding, but that we normally discount.</p>
</details>

历史表明，对更多看待和处理世界的方式持开放态度会更好。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">History shows that it is better to be open to more ways of seeing and working with the world.</p>
</details>

在这个特殊时代，能够处理一些有点神秘的事物并对此感到舒适非常重要。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that in this particular era, it's very important to be able to work with things that are a little bit mysterious, and be comfortable with that.</p>
</details>

### 像大型语言模型一样看待世界

我一直是个狂热的笔记爱好者。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I've always been like a real huge note-taking nerd.</p>
</details>

我喜欢做笔记，尤其是在我大学时期创办第一家公司的时候。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I love taking notes, especially because when I started my first company, I started my first company in college.</p>
</details>

我最终把它卖掉了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I ended up selling it.</p>
</details>

我从大学毕业典礼飞到波士顿，完成出售公司的谈判。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I flew from my college graduation to Boston to finish negotiating the deal to sell it.</p>
</details>

所以对我来说，整个情况就像是一场火的考验，我觉得我必须——我当时就像一个信息消防水带。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So that whole situation for me was this trial by fire of like, I felt like I had to, I was like an information firehose.</p>
</details>

我必须学到很多东西才能成功运营一家软件公司，当时我大概20、21、22岁。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I had to learn so much in order to successfully run a software company as a, I guess I was 20, 21, 22.</p>
</details>

我觉得我能做到最好的方式就是开始做笔记，比如“好吧，我从一本书里学到了这个东西，它是关于如何招聘人才的。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the way that I felt like I could do that best was to start taking notes, is to be like, okay, I learned this thing from a book, and it's about for how to hire people for example.</p>
</details>

我知道，我认为它对我会有用，但我不知道它何时会派上用场。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I know, I think it'll be relevant for me, but I don't know when it's gonna be relevant.</p>
</details>

所以我把它写下来，并试图创建一个完美的组织系统来分类所有这些东西，以便在我需要时能找到它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So I'm gonna write it down and I'm gonna try to create like the perfect organizational system to categorize all this stuff so it'll come back to me when I need it.</p>
</details>

如果你认真对待“如何构建完美的笔记或组织系统”这个问题，你实际上会遇到早期符号人工智能理论家和哲学家们长期以来遇到的同样问题，那就是我们如何创建一个完美的系统来组织现实？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if you really take seriously that question of like how do you build the perfect note taking or organizational system, you actually run into the same problems that early symbolic AI theorists run into, and philosophers have been running into for a long time, which is how do we create the perfect system to organize reality?</p>
</details>

你如何知道，你知道，把一个特定的笔记放在哪里？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">How do you know, you know, where to put a particular note?</p>
</details>

这与“我们如何知道我们所知？”是同类问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Is the same sort of question as like, how do we know what we know?</p>
</details>

所以当我第一次接触语言模型时，我意识到它们具有这种灵活和情境化的能力，这意味着我不需要创建一个完美的组织系统来教计算机如何组织我的笔记。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so when I first bumped into the language models, I realized that they had this ability to be sort of flexible and contextual in a way that meant that I didn't have to create the like perfect organizational system to teach a computer how to like organize my notes.</p>
</details>

它以一种无规则、模糊和灵活的方式运作。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It operated in this way that was ruleless, and fuzzy, and flexible.</p>
</details>

我以前从未见过计算机能做到这一点。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I had just never seen a computer do that before.</p>
</details>

第一次看到文字在屏幕上滚动，它有点像你的声音，有点像你上次停下来的地方，它有点理解所有那些细微的情境线索，告诉你你在谈论什么，这是以前任何计算机都无法做到的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like the first experience of seeing that line of words go across your screen, it's kind of in your voice a little bit, and it's kind of like picking up where you left off, and it kind of understands all the little contextual cues that tell it about what you're talking about that no computer previously could do.</p>
</details>

语言模型看待世界的方式与另一种计算机看待世界的方式之间有趣的差异在于，计算机和科学，这两种看待世界的方式都试图将世界简化为一套适用于任何情况的、极其清晰的普适法则。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The interesting difference between the way that a language model might see the world and maybe another kind of computer is computers, science, what both of those ways of seeing the world are trying to do is reduce the world into a set of really clean universal laws that apply in any situation.</p>
</details>

也就是说，如果X为真，那么Y就会发生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Is to say if X is true, then Y will happen.</p>
</details>

非常清晰的因果关系，非常清晰的链条，它们是普遍且与情境无关的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like really clear cause and effect, really clear chains that are universal and context-free.</p>
</details>

而语言模型看到的则是一个由世界不同部分组成的密集因果关系网络，这些关系以独特且高度依赖情境的方式汇聚在一起，从而产生接下来的结果。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what language models see instead is a dense web of causal relationships between different parts of the world that all come together in unique very context-specific ways to produce what comes next.</p>
</details>

我认为语言模型做了一件非常非常独特的事情，那就是它们能够在正确的时间、正确的地点，在你特定的情境下，为你个人提供人类所知最好的信息。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think language models do something really, really unique, which is that they can give you the best of what humanity knows, at the right place, at the right time in your particular context, for you specifically.</p>
</details>

例如，以前在互联网上，你可能会得到一个为非常普遍的读者或非常普遍的情况而写的答案，你可能需要在一个维基百科页面中搜索，才能找到回答你问题的唯一一句话。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Where, you know, for example, previously on the internet, you could get an answer that was written by someone for like a very general reader or a very general situation, and maybe you'd have to like hunt through a Wikipedia page to find like the one sentence that answers your question.</p>
</details>

语言模型更进一步，它们将回复为你量身定制，在你特定的情境、地点和时间下。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Language models go one step further, which is they reduce down their response to you to be written for you in your context, in your place, and in your time.</p>
</details>

如果你回顾机器学习的历史，从符号人工智能（我们试图将智能分解为一套定义、一个理论和一套关于思维如何运作的规则），一直到神经网络和语言模型，后者更具情境性，更注重模式匹配，更注重解释特定情境的丰富性，并以一种非显性的方式利用所有先前的经验来预测接下来会发生什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you look at the history of machine learning from symbolic AI, where we're trying to break down intelligence into a set of definitions of, you know, a theory and a set of rules for how thinking should work, all the way up to neural networks and language models where it's much more contextual, it's much more about pattern matching, it's much more about interpreting the richness of a particular situation, and using all prior experience in a sort of, in an explicit way to predict what comes next.</p>
</details>

人工智能历史的这一进程，在很多方面都在“快进”哲学史。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That sweep of the history of AI, in a lot of ways is speed running the history of philosophy.</p>
</details>

哲学始于试图明确“知道某事是什么”的尝试。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So philosophy started with this attempt to make explicit what it is to know something.</p>
</details>

现在我们处于一个“实际上一切都模糊不清，都是模式匹配，并且非常情境化和关联性”的境地。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now we're in this place where it's like actually, like it's all kind of like fuzzy, and pattern matching, and it's very, very contextual and relational.</p>
</details>

但也不是“什么都行”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But it's also not anything goes.</p>
</details>

而且它以一种我们创造了一个你可以使用并用它在生活中建造东西的积极工具的方式进行。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's being done in a way that like, we've created a positive tool that you can use, and like build stuff with in your life.</p>
</details>

我们不仅仅是在解构我们周围的一切。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We're not just sort of deconstructing everything around us.</p>
</details>

因此，在很多方面，机器学习和人工智能正在“快进”哲学，并且它更进一步，因为它用它构建了一些你可以做的事情。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so in a lot of ways, machine learning and AI's speed running philosophy, and it's gone a little bit of a step further, because it's built something with it that you can do.</p>
</details>

一种你可以在世界中存在的方式，或者一个你可以使用的工具。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">A way of being in the world that you can, or a tool you can use.</p>
</details>

我认为，A，这至关重要且非常有趣。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think, A, that's just like critically important and very interesting.</p>
</details>

B，我认为哲学和人工智能以及机器学习中发生的许多变化也将发生在文化的其他方面。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And B, I think a lot of the changes that have happened in both philosophy, and in AI, and machine learning are going to happen in the rest of culture.</p>
</details>

所以，从这种关于知识的思维方式——即让一切明确化，寻找理解世界的理论、定义和规则——转向对两者更平衡的欣赏：即一种更直观、关联、模糊的模式匹配式、经验式、情境式的认识世界的方式，必须作为理性事物的基础，才能使理性事物发挥作用。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So moving from this way of thinking about knowledge, which is about making everything explicit, finding theories, and definitions, and rules for how to understand the world, to a more balanced appreciation for both that, and the way that a more intuitive relational fuzzy pattern matching type experiential, contextual type way of knowing about the world has to be underneath the like the rational stuff in order for the rational stuff to work at all.</p>
</details>

这实际上是关于认识到更直观的认识世界的方式是理性的原始父母和伙伴，并欣赏它的本质。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's really about recognizing the more intuitive ways of knowing about the world as being the sort of original parent and partner of rationality, and appreciating that for what it is.</p>
</details>

我们谈论的很多内容是，寻找关于世界某个特定部分的某个普遍规则或普遍理论有时非常有价值，有时却会把我们引入死胡同。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You know, a lot of what we've been talking about is that looking for one general rule, or one general theory about a particular part of the world sometimes is really valuable, and sometimes leads us down dead ends.</p>
</details>

相反，我们必须将其与基于经验的深度情境理解相结合，这种理解使我们能够处理任何特定情境的丰富性和新颖性，从而理解接下来会发生什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And instead, what we have to pair it with is, deeply contextual understanding based on experience that allows us to work with the richness and novelty of any particular situation to understand what comes next.</p>
</details>

这就是语言模型能够做到的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's what language models are able to do.</p>
</details>

这不禁引发一个问题：我们是否应该停止寻找普遍理论？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it sort of begs the question of like, should we stop looking for general theories?</p>
</details>

例如，我们是否不应该试图统一量子物理学和牛顿力学？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And for example, should we, you know, not be trying to unify quantum physics with Newtonian mechanics?</p>
</details>

我当然认为我们试图统一这些事物，并试图建立一个普遍理论是非常棒的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I definitely think that it's awesome that we're trying to unify those things, and trying to build a universal theory.</p>
</details>

但我也认为值得思考，一旦我们有了物理学的普遍理论（如果我们能达到那一步），那实际上会告诉我们什么，以及它能带我们走多远。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But I think it's also worth thinking about what that will actually tell us, and how far that will get us once we have a universal theory of physics, if we do get there.</p>
</details>

我的论点，或者说我的感受是，它会很美，会很惊人，它会告诉我们很多。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And my contention, or the way that I feel is it will be beautiful, and it'll be amazing, and it will tell us a lot.</p>
</details>

但同时，世界上还有许多许多许多许多部分它根本不会触及。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But also, there are many, many, many, many parts of the world that it won't touch at all.</p>
</details>

即使我们有了物理学的普遍理论，那可能也不会渗透到我们对抑郁症的理解中。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That we still, even if we have a universal theory of physics, like that probably won't filter into our understanding of depression.</p>
</details>

比如，什么是抑郁症？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's like, what is depression?</p>
</details>

它如何产生？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">How is it caused?</p>
</details>

如何治疗？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">How do you treat it?</p>
</details>

什么是焦虑？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What is anxiety?</p>
</details>

它如何产生，如何治疗？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">How is it caused, how do you treat it?</p>
</details>

我们寻找这些东西已经很长时间了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We've been searching for those things for a really, really long time.</p>
</details>

我们有很多不同的答案。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we've had a lot of like different answers.</p>
</details>

如果你问弗洛伊德，他会说一回事；如果你问现代精神病学家、神经心理学家、精神病学家，他们可能会说另一回事。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like if you ask Freud, he'd say one thing, and if you ask like a modern psychiatrist, neuropsychologist, psychiatrist, they might say something else.</p>
</details>

但实际上，我们仍然不知道。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But really, like we just, we still don't actually know.</p>
</details>

我们一直在尝试这样做。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we keep trying to do that.</p>
</details>

我们一直在试图找到那种普遍理论，那种解释说：“如果X，那么Y；如果你的生活或大脑中发生这种情况，那么你就会抑郁。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We keep trying to find that kind of like universal theory, that explanation that says, well, if X, then Y, if you have this going on in your life or in your brain, then you're gonna get depressed.</p>
</details>

或者“如果你服用这种药物，抑郁症就会消失。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Or if you take this medication, then depression will go away.</p>
</details>

我们寻找这个已经很长时间了，因为我们觉得别无选择，因为通常为了预测结果，为了知道“如果我这样做，就能治愈某人的抑郁症”，为了预测它，你必须有一个潜在的科学解释，你必须有一个关于它的理论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We've been trying to find that for a really long time, because we felt like we had no other options, because normally in order to predict an outcome, to know, oh, if I do this, then it'll cure someone's depression. To predict it, you have to have an underlying scientific explanation, you have to have a theory about it.</p>
</details>

我认为人工智能实际上改变了这一点。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think AI actually changes this.</p>
</details>

有了人工智能，你可以做的是——人们已经开始这样做了——你可以训练神经网络，例如，它们能够识别谁是抑郁症患者或谁将患上抑郁症。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So with AI, what you can do is, and people are really already starting to do this, you can train neural networks that are, for example, able to identify who is depressed or who will get depressed.</p>
</details>

你可以训练神经网络来预测哪些干预措施可能对哪些人、在哪些情境下有效，以一种非常情境化、超个性化的方式，而无需事先发现任何关于我们试图预测的潜在现象的科学解释。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can train neural networks who will be able to predict which interventions might for which people and which circumstances in a very contextual, hyper-personalized kind of way without having to discover beforehand any scientific explanation for the underlying phenomena that we're trying to predict.</p>
</details>

所以，我们不需要对抑郁症有一个解释，我们只需用足够的数据训练一个模型，它就能预测什么可能有效，或者你是否患有抑郁症，或者你是否会患上抑郁症。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So like we don't have to have an explanation for depression, we can just train a model on enough data that it will be able to predict what might work, or whether you have it or whether you're gonna get it.</p>
</details>

我认为这非常有价值的原因是：第一，它让我们能够立即取得进展，因为我们将曾经的科学问题转变为工程问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The reason why I think that's so valuable is, one, it allows us to make progress immediately, 'cause we turn what used to be a scientific problem into an engineering problem.</p>
</details>

第二，它真正改变了我们应该如何进行科学研究，科学应该如何完成。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then, two, it like really changes how we should conduct science, how science should be done.</p>
</details>

它改变了我们对此的看法，因为现在，如果你是一名科学家，你想弄清楚抑郁症，或者心理学领域的任何其他事物，你想要做的是进行一项小规模研究，比如“我将招募16名本科生，他们可能患有抑郁症，我将要求他们每天微笑。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It changes our view of that, because right now, if you're a scientist, and you wanna like figure out depression, or any number of things in the field of psychology, what you're gonna want to do is like, a really small scale study where you're like, I'm gonna take 16 undergrads, and I'm going to, maybe they have depression, I'm gonna ask them to like smile every day.</p>
</details>

我将让他们进行功能性磁共振成像（fMRI），然后测量结果。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I'm gonna put them in an fMRI, and then I'm gonna like measure the results afterwards.</p>
</details>

如果我在非常非常少量的本科生身上得到一点结果，那么我就会获得更多资金来做一项有100人或更多人的研究。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if I get a little bit of a result on a very, very small number of undergrads, then I'm gonna like get more funding to do a study with a hundred or whatever.</p>
</details>

你就像在努力攀登这个阶梯，从非常小规模的干预到非常大规模的干预。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you're kind of like trying to climb this ladder of going from very small scale interventions, to like very big ones.</p>
</details>

并利用它来得出某种关于这些情况中实际发生什么的潜在理论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And to use that to come to some sort of underlying theory about what is actually going on in those situations.</p>
</details>

由于可重复性危机，我们发现，使用那16名本科生，很难发现任何感觉普遍或普遍适用的东西。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what we found because of the replication of crisis is like, it's just really hard to using that, you know, those 16 undergrads, it's really hard to like find out anything that feels universal or universally applicable.</p>
</details>

这也是为什么尽管抗抑郁药已经问世大约60年了，但我们仍然不知道它们何时起作用或如何起作用的原因之一。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's one of the reasons why even though antidepressants have been around for like 60 years or something like that, like we still actually don't know when they work or how they work.</p>
</details>

我们知道它们对某些人在某些时候有效，但我们能说的就只有这些了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We know they work for some people some of the time, but that's pretty much all we can say.</p>
</details>

人工智能的作用是，我认为，它帮助我们认识到有更好的方法，那就是我们不应该让随机的学者进行小规模研究，而应该让世界上的**苹果**（Apple: 美国科技公司）、**Meta**（Meta: 美国科技公司，Facebook母公司）和**谷歌**（Google: 美国科技公司）等公司将其数据捐赠给科学和数据信托，以便科学家可以访问这些数据来训练模型。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What AI does is it kind of helps us, I think, to me, it helps us realize that there's a better way, which is rather than have, you know, random academics doing small scale studies, what we should do is have like the, you know, Apples, and Metas, and Googles of the world donate their data to science and data trusts so that scientists can access 'em to train models.</p>
</details>

你可以找到在保护隐私的方式下进行的方法，这样就不会侵犯用户的信任。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can figure out ways to do it in ways that are privacy-preserving so that doesn't violate the trust of users.</p>
</details>

但我认为这将极大地促进科学的进步，这是数十亿美元的小规模研究无法做到的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But I think that would seriously enhance the progress of science, in a way that like doing billions of dollars worth of like small scale studies like has not been able to.</p>
</details>

我认为更有趣的是，一旦你训练出能够很好地预测抑郁症的模型，你可能会发现，模型实际上比大脑更容易解释和理解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what I think is even more interesting is once you have, once you've trained models that can, for example, predict depression really well, what you may be able to do is, models are actually easier to interpret and understand than brains are.</p>
</details>

所以，如果你有一个足够好的预测器，你就可以进入神经网络，试图弄清楚它是如何连接的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so if you have a good enough predictor, what you can do is just go into the neural network and try to figure out how it's wired.</p>
</details>

抑郁症的解释可能过于庞大和复杂，你无法完全弄清楚。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it may be that the explanation for what depression is is like too big and too complicated, and you can't figure it out.</p>
</details>

但机械可解释性已经足够好，你或许能够在一个训练好的神经网络的权重中找到一个关于抑郁症的可靠理论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But mechanical interpretability is good enough that you may be able to like find what is a solid theory for depression in the weights of a trained neural network.</p>
</details>

对我来说，我一生中大部分时间都在试图以这种理论定义的方式解释事物，或理解我自己，或理解我的世界，我看到了它的重要性，也看到了它的局限性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">For me, I've just spent so much of my life trying to explain things, or understand myself, or understand my world in this sort of theoretical definitional way, and I've seen how important that can be, and also how limiting it can be.</p>
</details>

特别是，如果你停止关注你的直觉告诉你什么，而只依赖你的逻辑大脑，就很容易迷失。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In particular, if you stop paying attention to what your intuition tells you, and you just rely on your kind of logical brain, it's really easy to get lost.</p>
</details>

生活和你所知的一切都有一种丰富的内涵，它源于你对自己的直觉感受，这在我的商业、个人生活、决策能力以及写作或创作优秀艺术作品的能力上都帮助了我。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's like this whole richness to life that, and to like what you know that comes out of this sort of like intuitive sense of yourself that helps you in your, helps me, for example, in business, in my personal life, and my ability to make decisions, and my ability to write or make good art.</p>
</details>

所有这些都基于我多年来建立的这种难以言喻的直觉。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">All of that is sort of based on this ineffable intuition that I built up over many, many, many, many years.</p>
</details>

我的逻辑大脑在某些情况下很有用，但我认为它可能会掩盖或取代我的直觉自我，以一种对我来说具有破坏性的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And my logical brain is helpful in certain circumstances, but I think like it can blot out, or take over from my intuitive self in ways that have been destructive for me.</p>
</details>

我认为这对社会也具有破坏性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think also have been destructive just as a society.</p>
</details>

我们错过了很多东西，因为我们错过了直觉的重要性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's a lot of stuff that we miss because we miss how important intuition is.</p>
</details>

现在我们有了能够体现许多这种直觉的工具，它们可以汲取我们建立的一些直觉，并将其放入世界上的其他事物中，我们可以传播这些事物，这以前从未可能。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And now we have tools that can embody a lot of that intuition, that can take some of that intuition that we built up, and we can put it into something else in the world that we can pass around, which was never possible before.</p>
</details>

你知道，我认为我们长期以来一直在追求事物的明确定义和科学解释，因为如果你能写下来，你就能传播它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You know, like I think we've been pursuing explicit definitions and scientific explanations for things for a long time, because if you can write it down, you can spread it.</p>
</details>

这成为了社会进步的方式，即这些传播的解释。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that becomes a, like the way that society progress is sort of like these spreading explanations.</p>
</details>

但如果你处理的是无法明确写下的世界部分，那么就没有好的方法来协作或在这些方面取得进展。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But if you're dealing with parts of the world that you can't write down explicitly, there's been no good way to collaborate on them or make progress on them.</p>
</details>

神经网络让我们能够将一些直觉经验，或者我们自己建立的直觉，放入一台可以传播的机器中。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what neural networks allow us to do, is to take some of that intuitive experience, or intuition that we might have built up ourselves, and put it into a machine that we can pass around.</p>
</details>

这对于医生，例如专家临床诊断来说很有用。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's useful, for example, for like doctors, for expert clinical diagnosis.</p>
</details>

世界上最好的临床医生对如何处理病人有一些他们无法写下来、无法融入一套规则中、被困在他们脑海中的知识。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The best clinicians in the world know something about how to deal with patients that they can't write down, they can't embody in a set of rules, and is trapped in their head.</p>
</details>

但语言模型和人工智能总体上允许我们将这种直觉放入一个工具中，这个工具将允许世界上任何人访问，例如，世界上最好的临床医生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But language models and AI in general allows us to put that kind of intuition into a tool that will allow anyone in the world to access, for example, the best clinician in the world.</p>
</details>

即使我们无法写下他们所知。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Even if we can't write down what they know.</p>
</details>

### AI会剥夺我们的人性吗？

首先，我认为人工智能将极大地丰富我们对自身的理解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Well, first of all, I think like AI will seriously enrich our understanding of ourselves.</p>
</details>

我认为人工智能是一面令人难以置信的镜子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think AI is an incredible mirror.</p>
</details>

仅仅通过与ChatGPT交谈，并向它输入“我刚刚开完会，你能告诉我我在会议中表现如何吗？”我就对自己有了更多的了解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like I understand so much more about myself just from being able to talk to ChatGPT, and being able to throw into it, like here's a meeting that I just had, like can you tell me like how I showed up in that meeting?</p>
</details>

所以它是一面令人难以置信的镜子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So it's an incredible mirror.</p>
</details>

它也是我们心智的一个绝佳隐喻。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's also an incredible metaphor for our minds.</p>
</details>

所以我们正在从将心智理想化为基于逻辑规则的明确计算机的隐喻，转向一个更模糊、对情境更敏感、模式匹配、经验驱动的语言模型，我认为这很好地隐喻了我们心智中更直觉的部分。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So we're moving from this metaphor of our minds, as like in an ideal world, this like logic rule-based explicit computer, to a much squishier, contextually-sensitive pattern-matching, experience-driven language model that I think is a really good metaphor for the more intuitive parts of our mind.</p>
</details>

因此，我认为这将丰富我们对“何以为人”这一曾经非常狭隘的图景的理解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so I think that will enrich our, what used to be a very narrow picture of what it means to be human.</p>
</details>

但我认为最重要的是要理解人性存在于我们内心。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But I think what's what's most important is to understand that the humanity is inside of us.</p>
</details>

是我们把人性带给工具，带给我们使用的工具，带给我们创造的事物。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like we bring the humanity to the tools, to the tools that use, to the things that we build.</p>
</details>

我认为在很多方面，“它会夺走我们的人性吗？”这个问题犯了两个错误。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think in a lot of ways, the like, will it take our humanity? It makes two errors.</p>
</details>

第一个错误是认为你可以将“何以为人”固定在一个不变的事物上。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The first error is to think that you can like pin down what it is to be human into like one unchanging thing.</p>
</details>

实际上，它已经进化，并随着时间而变化。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like that actually has evolved, and is different over time.</p>
</details>

我认为第二个错误是混淆了我们是什么——这有点难以表达，但它有点像说你不熟悉的东西是坏的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think the second error is to confuse what we are- It's a little hard to put it, but it's like, it's sort of like saying that what you're unfamiliar with is bad.</p>
</details>

这并不完全正确。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's not exactly the right thing.</p>
</details>

但我认为一个很好的例子是，你知道，我的祖母，例如，她现在已经不在了，但当她使用电话，或给某人发短信，或与某人通电话时，对她来说，这感觉非常不人情化。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But like, I think a really good example is, you know, when my grandmother, for example, she's not alive anymore, but when she would use like the phone, or text someone, or be on the phone with someone, to her, it felt very impersonal.</p>
</details>

在很多方面，这感觉有点不人道，对吧？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In a lot of ways, it feels like kind of inhuman, right?</p>
</details>

对她来说，面对面的互动是一种更人性化、更私人的事情。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like a sort of face-to-face interaction is a much more human, personal thing for her.</p>
</details>

对我来说，或者对那些比我更年轻的人来说，发短信可以感觉非常非常亲密。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">For me, or for people who are even younger than me, texting like can feel very, very intimate.</p>
</details>

你知道，在19世纪后期，收到一封打字信有点侮辱人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You know, in the late 1800s, getting a typewritten letter from someone was kind of insulting.</p>
</details>

没有收到手写信感觉非常不人情化。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It felt very impersonal not to get something in longhand.</p>
</details>

但现在我们根本收不到手写信了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But now we don't get any longhand letters.</p>
</details>

如果你收到，那实际上仍然非常非常私人，但收到一封电子邮件并不侮辱人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you do, it's like that is actually, it's still very, very personal, but it's not insulting to get an email from someone.</p>
</details>

如果有人给你发一封长邮件，你可能会觉得“哇，他们花时间想到我，真好。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If someone sends you a long email, you're kind of like, wow, that's really nice that they took the time to think of me.</p>
</details>

我认为所有这些担忧，比如“它会夺走我的人性吗？”很多都源于我们对这些新事物缺乏经验。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think all those worries that are sort of like, does it take away my humanity? A lot of them come from the fact that we just don't have a lot of experience yet with these new things.</p>
</details>

它们没有我们生活中其他技术所拥有的那种怀旧和历史的“光泽”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They don't have that like patina of like nostalgia and history that other things that we look at in our lives that our technologies do have.</p>
</details>

比如书籍，在某个时期书籍是非常可疑的东西。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So like books, at a certain point books were a very suspicious thing.</p>
</details>

而现在它们是——我爱书。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And now they are, I love books.</p>
</details>

我对它们有着如此浪漫的依恋。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like I have such a romantic attachment to them.</p>
</details>

我认为这是我们在评估新技术时常常忽略的一点，那就是我们还没有机会让它们对我们来说变得“人性化”，因为我们不熟悉它们。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think that's one of the things that we miss when we evaluate new technologies, is they just, we just haven't had the chance to allow them to feel human to us, 'cause we're unfamiliar with them.</p>
</details>

我认为那些非常害怕人工智能的人，实际上又回到了我们一直在讨论的这种理性主义思想，即如果你不能明确定义并100%证明一件事是安全的，那么它就是危险的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think the people who are super afraid of AI, it is actually, it sort of goes back to this rationalist idea that we've been talking about, which is if you can't explicitly define, and prove 100% that a thing is safe, then it's dangerous.</p>
</details>

我不知道是否有人有过这样的老师、父母或学校里的人，他们会说：“无论你做什么，即使你是世界上最聪明的人，他们也会找到你的一次失误，然后狠狠地批评你。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I don't know if anyone's had like a teacher, or a parent, or someone in school that's like, no matter what you do, you can be the smartest person in the world, but they're gonna find that one fuck up, and just like hammer you for it.</p>
</details>

我认为很多担心的人，他们只是在等待那一次失误。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think a lot of people that are worried about that are, they're just waiting for that one fuck up.</p>
</details>

确实，这确实会发生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's true, that does happen.</p>
</details>

但另一种选择是，要求人工智能只说那些可以被证明是真实的事情。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the alternative is, the demand that AI only say things that can be proved to be true.</p>
</details>

对我来说，这似乎剥夺了人工智能的许多魔力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that sort of, to me at least, like takes away a lot of the magic of AI.</p>
</details>

它之所以真正强大，是因为它基于概率运作，它基于成千上万个相关性汇聚在一起，以找出在这个独特、丰富的情境中适当的响应。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like the thing about it that makes it actually powerful is that it works on probability, it works on many, many, many thousands of correlations coming together to figure out what the appropriate response is in this one very unique, very rich context.</p>
</details>

允许它只说那些可证明的事情，显然会引发一个问题：那么什么是真的，我们如何知道？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And allowing it to say only things that are provable, obviously begs the question like, well, what is true and how do we know?</p>
</details>

在某些领域我们可以回答这个问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there are certain domains where we can answer that question.</p>
</details>

例如在数学和计算机科学中，一个定理是否正确是相当清楚的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So like in math and computer science, for example, it's like pretty clear whether or not like a theorem is right.</p>
</details>

这又回到了苏格拉底的那个问题：“我们知道什么，我们如何知道？”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's back to the same question from Socrates, which is like, what do we know and how do we know it?</p>
</details>

以及对我们所说的每一件事都要求明确的理性解释。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And a demand for explicit rational explanation for every single thing that we say.</p>
</details>

我认为这种要求过于强烈，实际上排除了我们对世界许多部分的了解，或者我们希望与之合作的世界部分，而我们实际上并没有精确、明确的答案。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think that that demand is like way, way, way too strong, and actually eliminates a lot of things that we know about the world, or parts of the world we want to work with, where we actually don't have precise, exact explicit answers.</p>
</details>

它导致了那些让人们非常害怕的思想实验，比如“一次性”的想法，即你只有一次机会，一旦你构建了一个超级智能，你只有一次机会确保它与人类偏好对齐，否则它就会杀死我们并接管世界。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it sort of results in these thought experiments that get people really scared, like the sort of one shot idea, that you have one shot, once you build a super intelligence, you have one shot to make sure that it's aligned, that it will follow human preferences, or it will kill us and take over the world.</p>
</details>

你可以找到像**埃利泽·尤德科夫斯基**（Eliezer Yudkowsky: 人工智能研究者，理性主义运动的倡导者，关注AI风险）这样的真正理性主义者，他们真的相信这一点，真的相信我们都会死去。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you can find people who are like real rationalists, like Eliezer Yudkowsky, who really believe this, and really believe that we're like going to all die.</p>
</details>

那很糟糕。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Which that sucks.</p>
</details>

那不是一个好境地。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That's like not a great place to be.</p>
</details>

有趣的是，我们现在拥有非常智能的人工智能。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's kind of interesting is we have really smart AI right now.</p>
</details>

我认为，如果你在十年前问理性主义者或思考这些问题的人：“这是人工智能吗？它是否达到了危险的水平？”他们可能会说是。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like I think it's the kind of AI that if you had asked rationalists, or people who were thinking about this stuff 10 years ago, is this AI and is this at a level that's like, could be dangerous?</p>
</details>

如果你看看它是如何实际构建的，是的，我们没有任何可证明的方法来保证它100%安全。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They would have probably have said yes. If you look at how it's actually built, yes, we don't have any provable ways to be like it's 100% safe.</p>
</details>

这还不包括定义什么是100%安全本身就是不可能的事实。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Ignoring the fact that even defining what 100% safe is, is like impossible.</p>
</details>

这正是语言模型运作的全部原因。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that's like the whole reason that language models work.</p>
</details>

但我们每天都在做的是，我们正在根据人类偏好训练这些模型。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But what we're doing every single day is we are training these models on human preferences.</p>
</details>

我们一遍又一遍地给它们提供我们想要什么以及为什么的例子。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We're giving them examples over, and over, and over again of what we want and why.</p>
</details>

每个模型都建立在它之前的模型之上。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And each model builds on models that came before it.</p>
</details>

它们实际上对“什么是好”有一个密集而丰富的理解，这来自于它们获得的所有数据。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They actually have a dense, rich idea of what it is to be good from all the data that they get.</p>
</details>

它们也可能对“什么是坏”有一个密集而丰富的理解。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They also have a dense, rich idea of like probably what it is to be bad.</p>
</details>

但在很多方面，我们正在进行的训练使它们做那些事情的可能性大大降低。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But in a lot of ways, the training that we're doing makes them much, much, much less likely to do any of that stuff.</p>
</details>

有一种非常实际和务实的态度，那就是我们有一台机器，我们不完全知道它是如何工作的，但我们只是要教它，我们将一遍又一遍地与它迭代，直到我们基本上让它工作。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's something very like practical and pragmatic about, we have a machine, we don't know fully how it works, but we're just gonna like teach it, and we're gonna like iterate with it over, and over, and over again until we kind of basically get it to work.</p>
</details>

它有点模糊。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's sort of squishy.</p>
</details>

我们没有任何保证，而那个世界，它实际上就是那种混乱的现实世界。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We don't have any guarantees, and that world is, it is actually the sort of like messy real world.</p>
</details>

它实际上有点像你思考如何与人互动：是的，我不知道你是否会对我撒谎，但我会想办法弄清楚。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It is actually kind of like how you think about interacting with a human is like, yeah, I don't know if you're gonna lie to me, but like I'm gonna sort of figure it out.</p>
</details>

我们无法从语言模型那里获得这些保证，这正是它们如此强大的原因。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The fact that we don't have those guarantees from language models is what makes them so powerful.</p>
</details>

所以，我认为语言模型并非永远不会危险，但我认为采取更务实、基于经验的心态，即“我们将构建这些东西，我们将以一种相当可预测的方式改进它们。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so I think like, it's not that language models could never be dangerous, but I think adopting the more pragmatic experience-based mindset, which is like, we're gonna build these things, we're going to improve them in a fairly predictable way.</p>
</details>

它们将获得的所有具体能力并非完全可预测，但我们基本上可以判断，每次训练运行时它们会变得多聪明。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's not predictable exactly all of the specific capabilities that they're gonna get, but we can basically tell like in general, how much smarter they're gonna get every time we do a training run.</p>
</details>

在此过程中，我们将在现实世界场景中与它们迭代，以降低它们做坏事的可能性。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And along the way, we are going to iterate with them in real world scenarios to make them less likely to do bad things.</p>
</details>

这吓坏了那些要求某种理性主义保证的人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That scares people who demand a certain kind of rationalistic guarantee.</p>
</details>

但对于像我这样的人，那些建造东西的人来说，在实践中解决问题实际上是比在理论中解决问题更好的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But for people like me, people who build stuff, solving the problems in practice actually is a better way to do things than solving them in theory.</p>
</details>

### AI与创造性工作：从雕塑家到园丁

我认为关于人工智能如何改变创造性工作有一个非常大的问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think there's a really big question about how AI may change creative work.</p>
</details>

有一种观点认为，“它会替我完成所有工作，所以我基本上不再做了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there's this idea that, well, it's gonna do all the work for me, so like I'm basically not even doing it anymore.</p>
</details>

这不是我的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's not mine.</p>
</details>

这不是我的作品。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's not like, it's not my work.</p>
</details>

我喜欢思考关于它实际上可能是什么样子，或者它现在是什么样子，以及未来会继续是什么样子的想法或隐喻，来解释你如何仍然可以进行感觉真实且像你自己的创造性工作，即使人工智能正在完成其中一部分。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I like thinking up ideas or metaphors for what it may actually be like, or what it sort of, honestly what it is like now, and what it will continue to be like more in the future to explain how you can still do creative work that feels authentic and feels like you while an AI is doing some part of it.</p>
</details>

我喜欢用的一个隐喻是雕塑家和园丁之间的区别。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One of the metaphors that I like to use is this sort of difference between a sculptor and a gardener.</p>
</details>

所以，通常的创造性工作很像雕塑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So creative work ordinarily is a lot like sculpting.</p>
</details>

如果你是一个雕塑家，你有一大块大理石，或者一大块粘土或其他什么，那个成品中的每一个曲线和线条都是你亲手决定的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you're a sculptor, and you have a big block of marble, or you know, big piece of clay or whatever, every curve in line in that finished product is something that you decided to do like with your own hands.</p>
</details>

所以你必须决定这样做，否则它就不会在那里。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So you had to decide to do it, otherwise it would not be there.</p>
</details>

我认为与人工智能合作实际上有点不同。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think that working with AI is actually, it's a bit different.</p>
</details>

它更像园艺。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's a lot more like gardening.</p>
</details>

如果你是一个园丁，你不会把植物从地下连根拔起，试图让它们生长。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If you're a gardener, you don't like pull the plants up from the ground by the roots to try to make them grow.</p>
</details>

那样行不通。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Like that won't work.</p>
</details>

你不能直接导致植物生长。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can't directly cause the plants to grow.</p>
</details>

但你可以做的是，你可以为植物或你正在建造的花园创造条件，让它们以特定的方式繁荣生长。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But what you can do is you can create the conditions for the plants or the garden that you're making to flourish in a particular kind of way.</p>
</details>

你可以改变阳光的量，你可以改变土壤，你可以改变水的量，或者你可以决定哪些植物放在哪里，你可以除草。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You can change the amount of sun, you can change the soil, you can change the amount of water, or you can decide which plants go where, you can do some weeding.</p>
</details>

所有这些都是你通过改变事物发生的条件来塑造事物的方式，而无需亲自动手。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And all of that stuff is a way for you to shape something by altering the conditions under which it happens without doing it yourself.</p>
</details>

我认为这与很好地使用模型非常相似，尤其是那些更具代理性、能自主完成更多工作的模型。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think that's a lot like what working with a model well is, especially a model that is more agentic and does a lot more by itself.</p>
</details>

我认为这很好地隐喻了那种体验。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think a lot of, I think that's a good metaphor for what that experience is like.</p>
</details>

### 从知识经济到分配经济

我认为这个技术时代我最喜欢的一点是，我是一个