---
area: society-systems
category: technology
companies_orgs:
- Every
- Big Think
- Apple
- Meta
- Google
date: '2025-11-21'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- Protagoras
people:
- Dan Shipper
- Socrates
- Protagoras
- Plato
- Descartes
- Newton
- Galileo
- Herbert Simon
- Alan Newell
- Freud
- Eliezer Yudkowsky
products_models:
- ChatGPT
- General Problem Solver
project:
- ai-impact-analysis
- systems-thinking
- personal-growth-lab
series: ''
source: https://www.youtube.com/watch?v=jkXOudImoI0
speaker: Big Think
status: evergreen
summary: 演讲者探讨了理性主义从古希腊到科学启蒙的历史演变，将其基于规则、显性化的方法与现代人工智能（如神经网络和大型语言模型）的直觉、模式匹配特性进行对比。他认为，人工智能凸显了直觉思维的价值，挑战了传统科学方法，并将工作模式转变为“分配经济”，同时丰富了我们对人性的理解。
tags:
- consciousness
- economy
- intuition
- neural-network
- rationalism
title: 理性主义的局限：从苏格拉底到神经网络
---

### 理性主义的局限：从苏格拉底到神经网络


我经常有机会与人们交谈，了解他们在工作和生活中如何使用 AI，以及 AI 如何改变了他们个人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I get to talk to people all the time about how they use AI in their work and in their lives, and also how it has changed them as people.</p>
</details>

我们有许多不同的认知方式，也有许多不同的理解事物的方式。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's many different ways of knowing things, and many different ways of understanding things.</p>
</details>

计算机科学与传统科学，这两种观察世界的方式都试图做同一件事：将世界简化为一套真正清晰、通用的定律，适用于任何情况。如果 X 是真的，那么 Y 就会发生。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Computers, science, what both of those ways of seeing the world are trying to do is reduce the world into a set of really clean universal laws that apply in any situation. If X is true, then Y will happen.</p>
</details>

而语言模型看到的则截然不同，它们看到的是一张密集的因果关系网，这些关系连接着世界的不同部分，以独特且极具情境特异性的方式汇聚在一起，从而产生接下来的结果。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what language models see instead is a dense web of causal relationships between different parts of the world that all come together in unique, very context specific ways to produce what comes next.</p>
</details>

神经网络真正有趣的地方在于，它们的思考方式或运作方式非常像人类的直觉。人类的直觉也是通过成千上万小时的直接经验训练出来的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting about neural networks is the way that they think or the way that they operate is a lot like human intuition. Human intuition is also trained by thousands, and thousands, and thousands of hours of direct experience.</p>
</details>

我之所以喜欢这一点，是因为我希望它能让我们更清晰地看到直觉思维的价值和重要性。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The reason I love that is because I hope that it makes more visible to us, the value and importance of intuitive thought.</p>
</details>

我是 Dan Shipper，Every 的联合创始人兼 CEO，也是《AI & I》播客的主持人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">My name is Dan Shipper, I'm the Co-Founder and CEO of Every, and I'm the host of the AI & I podcast.</p>
</details>

### 第一章：理性主义的局限——从苏格拉底到神经网络

我认为**理性主义**（Rationalism: 一种认为理性和逻辑是知识主要来源的哲学观点）是过去两千年来最重要的思想之一。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Chapter 1, the limits of rationalism from Socrates to neural networks. I think rationalism is one of the most important ideas in the last, like 2,000 years.</p>
</details>

理性主义的核心理念是：如果我们能明确我们所知道的，如果我们能真正将我们所知道的简化为一套理论、一套关于世界如何运作的规则，那就是关于世界的真实知识。这与那些扰乱我们头脑、扰乱我们在社会中运作方式的其他事物截然不同。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Rationalism is really the idea that if we can be explicit about what we know, if we can really reduce what we know down into a set of theories, a set of rules for how the world works, that is true knowledge about the world, and that is distinct from everything else that kind of messes with our heads, messes with how we operate in society.</p>
</details>

你可能没听说过这个词，或者即使听说过，你也未必意识到它已经根植于你观察世界的方式中。例如，计算机的工作原理、疫苗的作用机制、我们预测天气的方式，或者我们在做决定时试图避免情绪化、追求思维精确性的方式，都体现了这一点。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you may not have heard that word, or maybe you have, but it is built into the way that you see the world. For example, the way computers work, or the way vaccines work, or the way that we predict the weather, or the way that we try to make decisions when we're, you know, thinking about, I don't wanna be too emotional about this. I want to get really precise about my thinking on this issue.</p>
</details>

甚至我们进行心理治疗的方式，很多时候也是关于理性化，或者通过各种思考和感受进行理性梳理。所有这些东西都源于一个源远流长的思想谱系，它始于古希腊，在启蒙运动时期真正繁荣，现在已成为我们文化和世界观的基石。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Even the way that we do therapy, a lot of therapy is about rationalizing, or rationalizing through what you think, and what you feel. All that stuff comes from an extensive lineage of ideas that started in Ancient Greece, really blossomed during the enlightenment, and now is like the bedrock of our culture, and the way that we think about the world.</p>
</details>

我认为理性主义之父是哲学家苏格拉底。苏格拉底是最早真正审视“我们知道什么以及如何知道”这一问题的人之一。什么是真实的，什么不是。他致力于描述我们知道什么以及我们如何知道它，使其清晰明确，以便只有那些知道真理、知道世界如何真正运作的人才能掌舵国家。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think the father of rationalism is Socrates, the philosopher. Socrates is one of the first people to really examine the question of what we know and how. What is true and what's not true. To be able to describe what we know, and how we know it, to make that clear and explicit so that only people that knew the truth, that knew how the world really works were the ones that were steering the state.</p>
</details>

这实际上成为了哲学的诞生：这一理念认为，如果你深入探究我们对世界通常拥有的那种模糊的直觉，你就能发现、识别出一套规则或理论，关于世界是什么样子的，什么是真什么是假，并且你可以明确地将其陈述出来，用来判定真伪。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That really became the birth of philosophy, is this idea that if you inquire deeply into what is usually kind of like the in explicit intuitions that we have about the world, you can find, you can identify a set of rules, or a theory, about what the world is like, and what's true and what's not, that you can lay out explicitly, and that you can use to decide the difference between true and false.</p>
</details>

我认为你可以将理性主义的诞生追溯到这篇名为《普罗泰戈拉篇》（Protagoras）的对话录。在这场对话中，辩论的双方是苏格拉底和普罗泰戈拉。普罗泰戈拉就是我们所说的**诡辩家**（Sophist：古希腊以教授修辞和辩论为业的智者，常被指责通过巧妙的言辞混淆视听）。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think that you can trace the birth of rationalism to this dialogue, Protagoras. And in the dialogue, it's a debate between Socrates on the one hand, and Protagoras. And Protagoras is what we call a sophist.</p>
</details>

“诡辩”（Sophistry）这个词就来源于此，它的意思大概是指那种说起话来很有说服力，但实际上满口胡言的人。普罗泰戈拉和苏格拉底辩论的主题是：卓越（Excellence）是可以被教授的吗？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it's where the term, sophistry which means like kind of, you know, someone who says really compelling things but is actually full of shit. What Protagoras and Socrates are debating is, can excellence be taught?</p>
</details>

“Excellence”这个词在英语中常被翻译为“美德”（Virtue），但我认为更恰当的翻译是“卓越”。在古希腊，那种卓越备受推崇。它大概是指一种在生活和社会的关键事务上表现出色的综合能力。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And excellence, the word is often translated in English as virtue, but I think a more appropriate translation is excellence. And in Ancient Greece, like that kind of excellence was really prized. It's sort of like a general ability to be good at important things in life, and in society.</p>
</details>

他们从截然不同的角度探讨这个问题。普罗泰戈拉相信每个人都有能力变得卓越，他讲了一个宏大的神话故事来解释人类是如何获得这种能力的。而苏格拉底却说：不不不，我不想听这些。我要的是一个定义。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And they approach it from very different angles. Protagoras believes that everyone has the capacity, every human has the capacity to be excellent, and he tells this big myth about how we, as humans, gain the capacity to be excellent. And Socrates is saying, no, no, no, I don't want any of that. What I want is I want a definition.</p>
</details>

我要你明确地说出它是什么，它不是什么，它的组成部分是什么。这是一个非常关键的时刻。至少在柏拉图的笔下，苏格拉底基本上拆解了普罗泰戈拉的观点。到最后很明显，普罗泰戈拉不知道，也没办法用一种不自相矛盾的方式来定义什么是卓越，什么是“好”。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I want you to say explicitly what it is and what it's not, and what are the components of it. And that's a really big moment. At least the way that Plato writes it, Socrates kind of like takes apart Protagoras, and it's pretty clear by the end, that Protagoras doesn't know, doesn't have any way to define in a non-contradictory way what excellence is, what it means to be good.</p>
</details>

其言外之意是，既然他无法定义，那他就并不真正懂得它。这使得西方社会走上了一条试图为我们所谈论的事物寻找极其清晰的定义和理论的道路。它将知识——即知道某事的能力——与你是否能清晰定义它等同起来。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the implication is that then he doesn't know it. And that sort of set western society on this path of trying to find really clear definitions and theories for the things that we talk about, and to identify knowledge, the ability to know something, or whether or not you know something with whether or not you can really clearly define it.</p>
</details>

### 理性主义与人工智能的早期尝试

这一理念在科学启蒙运动中变得极其重要。哲学方面的思想家如笛卡尔，科学方面的如牛顿和伽利略，都采纳了这一理念，并将其作为理解和解释世界的新方法。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And that idea became incredibly important in the scientific enlightenment. Thinkers on the philosophy side, like Descartes, and on the science side, like Newton and Galileo, took this idea, and used it as a new method to understand and explain the world.</p>
</details>

于是这就变成了：我们能否用数学来解释和预测世界上的不同事物？从苏格拉底到伽利略再到牛顿，他们不断强化这一观念：为了真正了解某事，你必须能够明确地描述它。你必须能够建立关于它的理论。理想情况下，你必须能够用数学描述它。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So what it became is, can we use mathematics to explain and predict different things in the world? And from Socrates, to Galileo, to Newton, they continually reinforced this idea that in order to truly know something, you have to be able to describe it explicitly. You have to be able to have a theory about it. You have to be able to describe it mathematically ideally.</p>
</details>

我们周围的世界正是由这一框架塑造的。从智能手机、电脑、汽车、火箭、相机、电力，到你家里的每一件电器、疫苗，这世界的一切都是由这种理念或这种观察世界的方式塑造的。它的影响极其深远。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The world around us is shaped by this framework. So everything from smartphones, to computers, to cars, to rockets, to cameras, to electricity, every appliance in your house, vaccines, everything in our world is shaped with this idea, or this way of seeing the world. It's been incredibly impactful.</p>
</details>

在文化的其他方面你也能发现这一点，比如每当你看到一本书、一部电影或一篇博客文章谈论“权力的五大法则”或“谈判的五大定律”时，这都是物理学和理性主义渗透到我们日常思考世界方式中的体现。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And you can find this too in the rest of the culture, like anytime you see, you know, a book, or a movie, or a blog post or whatever, talking about like the five laws of power, or like the five laws of negotiation. All that stuff is ways that physics has, and rationalism in general has like sort of seeped into the everyday way that we think about the world.</p>
</details>

需要明确的是，这非常成功。但在心理学、经济学或神经科学等领域，要想取得像物理学那样的进步却非常困难。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And to be clear, it's been super successful. But in areas of the world like psychology, or economics, or neuroscience, it has been really hard to make progress in the same way that physics has made progress.</p>
</details>

如果你观察社会科学，你会发现其结构的很多方面都受到了物理学的启发。我们试图将非常复杂的高层现象（如心理学或经济学）简化为一组定义、理论和规则。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think if you look, for example, at the social sciences, a lot of the way that the social sciences are structured is inspired by physics. What we're trying to do is take very complex higher level phenomena, so like maybe psychology, or economics, or you know, any other branch of social science. And we're trying to reduce it down to a set of definitions, and a theory, and a set of rules for how things in that domain work.</p>
</details>

有趣的是，像心理学这样的领域正处于巨大的**可重复性危机**（Replication Crisis: 指许多科学研究结果无法被其他研究者重复验证的现象）之中。尽管我们做了 100 年的心理学研究，但在普适性方面，我们所建立的知识体系——即我们像牛顿发现万有引力定律那样发现普遍规律的能力——似乎相当可疑。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting is if you look at those fields, so like psychology, for example, it's in the middle of a gigantic replication crisis. Even though we spent like 100 years doing psychology research, the body of knowledge that we've been able to build there in terms of its universal applicability, our ability to find, you know, universal laws in the same way that Newton found universal laws seems pretty suspect.</p>
</details>

我们觉得无法停止这种做法，因为我们没有更好的替代方案。这种观察世界的方式在另一个非常重要且有趣的领域也遇到了挫折，那就是人工智能（AI）。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we feel like we can't stop doing it because we have no better alternative. Another really interesting and important part of the world that this way of looking at things didn't work for in many ways is AI.</p>
</details>

### AI 的定义困境与符号主义的失败

通常在这个环节我会尝试定义 AI。什么是 AI？有趣的是，关于这一点并没有达成普遍一致的定义，就像我们很难就“知道某事”意味着什么，或者“焦虑”在心理学中到底是什么达成普遍定义一样。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So this is usually the part of an explanation where I try to define it. And like, what is AI? And what's really interesting is, there's no universal agreed upon definition for this, in the same way that there's, we've struggled to come up with a universal definition for what it is to know something, or universal definition for what anxiety is, for example, in psychology is another really good example.</p>
</details>

尽管有很多方式可以描述 AI，但显然，AI 代表人工智能（Artificial Intelligence）。AI 的目标是制造一台能够像人类一样思考和学习的计算机。由于计算机的工作原理，这在很长一段时间内都是一个难题。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There are a lot of ways to kind of like gesture at what AI is. But really it's like obviously, or maybe not obviously, AI stands for artificial intelligence. And the AI's project is to build a computer that can think and learn in the same way that humans learn. And because of the way that computers work, for a very long time, that was a really hard problem.</p>
</details>

AI 作为一个领域起源于 50 年代的达特茅斯会议。如果你去读最初的论文，你会发现他们非常乐观。他们当时觉得，大概花个把夏天的功夫就能搞定。他们定义 AI 的方式是将人类智能简化为一个符号系统，通过明确的规则将这些符号组合起来，以模仿人类智能。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">AI started as a field in the '50s at Dartmouth, and you can like actually look at the original paper. They were very optimistic. They were like, you know, maybe like, you know, a summer's worth of work and we'll have nailed this. And the way that they defined it is to be able to reduce down human intelligence into a system of symbols that they could combine together based on explicit rules that would mimic human intelligence.</p>
</details>

这与苏格拉底最初的项目、启蒙运动以及早期 AI 理论家采取的被称为**符号主义 AI**（Symbolic AI）的方法之间，有着清晰的脉络。这种观点认为，你可以将思维具体化为逻辑符号以及逻辑符号之间的转换，这与基础哲学非常相似。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so there's a really clear through line from Socrates's original project to the enlightenment, to the original approach that AI theorists took called symbolic AI. The idea that you could embody thinking in, essentially like logic, logical symbols, and transformations between logical symbols, which is, it's very similar to just basic philosophy.</p>
</details>

早期确实取得了很多成功。例如，AI 的两位鼻祖 Herbert Simon 和 Alan Newell 制造了一台他们称之为“通用问题求解器”（General Problem Solver）的机器。有趣的是，它甚至最初都不是作为计算机程序构建的，因为那时的计算机极其昂贵。他们最初是在纸上编码了这个求解器，然后手动执行。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there were actually a lot of early successes. For example, the two founding fathers of AI, Herbert Simon and Alan Newell, built this machine that they called the general problem solver. And what's really interesting is it wasn't even built as a computer because computers were extremely expensive back then. They originally codified the general problem solver on paper and then executed it themselves by hand.</p>
</details>

他们试图将复杂的现实世界情况简化为简单的逻辑问题，看起来有点像游戏。然后他们试图看看能否制造一台计算机来解决这些游戏。起初他们相当成功，发现它在解决简单问题时效果很好。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the general problem solver, they kind of, they tried to reduce down, you know, complex real world situations into simple logical logic problems, that they look a little bit like games. And then they tried to see if they could build a computer that would solve some of those games. And they were actually quite successful at first. What they found was it worked really well for simple problems.</p>
</details>

但随着问题变得越来越复杂，可能解决方案的搜索空间变得非常非常大。一旦他们离开玩具般的问题去处理更复杂的问题，他们构建的系统就开始崩溃。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But as problems got more and more complex, the search space of possible solutions got really, really, really, really big. And so by representing the problem in that way, the systems that they built started to fail as soon as they moved away from toy problems to more complex ones.</p>
</details>

一个简单有趣的例子是判断一封电子邮件是垃圾邮件还是重要邮件。你可能会说：如果它提到我中了彩票，那就是垃圾邮件。这种“如果-那么”规则（If-Then Rules）很像早期符号 AI 理论家试图制定以此来解决所有问题的规则。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think a really interesting and simple example of this is thinking about how you might decide whether an email in your inbox is spam, or whether it's important. And you might say something like, if it mentions that I won the lottery, it's spam, right? And so that sort of like if then rule, is a lot like the kinds of rules that early symbolic AI theorists were trying to come up with to help you solve any problem, is to codify like if X, Y, Z is true, then here are the implications.</p>
</details>

但如果你仔细观察，总会有很多小例外。比如，如果它写着“紧急”，也许你想把它放在收件箱顶部。但很快垃圾邮件发送者就会在主题行加上“紧急”。所以你得制定新规则：如果是“紧急”，且来自我的同事或家人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">What happens is if you look at that really closely, there are always lots of little exceptions. So an example might be, if it says emergency, maybe you wanna put that at the top of your inbox, But very quickly you'll have spammers obviously being like, just put emergency in the subject line, and they'll shoot to the top. So then you have to kind of like create another rule, which is it's emergency, but only if it's from my coworkers or my family.</p>
</details>

但电脑不知道什么是同事或家人。所以你得定义：同事就是我公司的任何人。但公司里可能有些人很烦人，即使你不希望他们联系你，他们也在滥用“紧急”这个词。于是你又得制定规则来屏蔽这些人。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But computers don't really know what coworkers or family is. So then you have to define, okay, like how is it gonna know what a coworkers or what a family member is? So what you can do is maybe it's like a coworker is anybody from my company. And so if it says emergency, and it's from anybody in my company, put it at the top of my inbox. But what you may find is that there are certain people at your company who are annoying and want your attention, even if you don't really want them to contact you. And so they start putting emergency into their inbox, and now you have to create another rule which is like, don't let people who are abusing the privilege of getting to the top of my inbox, abuse it even if they're coworkers.</p>
</details>

你会发现，每当你试图制定规则来定义这些事物时，总会遇到例外。要定义什么是重要邮件，你几乎需要定义关于世界的一切。通过定义让整个世界变得明确的工程根本行不通。它太脆弱、太困难，需要太多的算力来循环遍历所有定义，而需要创建的定义又太多了。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what you find is anytime you try to create rules to define these things, you always run up against exceptions. If you wanna, for example, define what an important email is, you have to define pretty much everything about the world. You have to create a world full of definitions. And that project of making the entire world explicit in definitions just didn't work. It's too brittle, it's too hard, there's too much computational power required to loop through all the different definitions to decide, you know, if this email is important or not. And it's just, there are too many definitions to create. It's just, it's too big of a project.</p>
</details>

### 神经网络的崛起：模拟直觉

替代方案是**神经网络**（Neural Network），它起源于 AI 诞生的同一时期，但直到 80 和 90 年代才被真正重视。神经网络受大脑工作方式的启发，由相互连接的人工神经元层组成。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The alternative, which originated around the time that AI itself originated, but really wasn't taken that seriously until probably the '80s and '90s is what's called a neural network. And a neural network, it is inspired by the way our brains work. It doesn't work exactly the same way, but it is inspired that way. It is inspired from brains. And it basically consists of layers of artificial neurons that are connected to each other.</p>
</details>

你可以通过提供大量示例让神经网络识别模式。比如，给它一封同事的邮件，让它猜测是否重要。如果猜错了，我们有一种训练方法来纠正它。经过无数次迭代和无数个例子，神经网络学会了识别模式，而不需要任何明确的定义或规则（比如“这是一封重要邮件”或“这是一只猫”）。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what you can do with a neural network is you can get it to recognize patterns by giving it lots of examples. You can, you know, for example, if you want it to recognize like whether an email is important, what you can do is you can give it an example, say like, you know, here's an email from a coworker, and have a guess the answer. And if the answer is wrong, what we've done is we've created a way to train the network to correct its wrong answer. And what happens is over many, many, many, many iterations, and many, many different examples, what we find is without any explicit set of definitions, or explicit rules about like, you know, this is a important email, or this is a cat, or this is a good move in chess. The neural network learns to recognize patterns, and is able to do a lot of the more complex thinking style tasks that early symbolic AI was unable to do.</p>
</details>

大型语言模型（LLMs）是一种特殊类型的神经网络，它通过在语言内部寻找复杂模式来运作，并利用这些模式来预测序列中的下一个内容。我们给它们喂了互联网上几乎所有的文本。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Language models are a particular kind of neural network that operates by finding complex patterns inside of language and using that to produce what comes next in a sequence. So what we've done with language models is fed them basically, you know, all of the text on the internet.</p>
</details>

语言模型学习到成千上万条“部分适用”的规则，基于之前的文本历史来预测下一个词。所有这些规则都是隐性的。你无法在网络中找到“这就是它的全部规则列表”。这就像我无法用显微镜观察你的大脑并找到你识别猫或下棋的确切规则列表一样。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And language models learn that there are many, many thousands of partially fitting rules that they can apply based on the previous history of texts they've seen to predict what comes next. And all of those rules are inexplicit. They're kind of like, you can observe them in the overall behavior of the network, but they don't exist anywhere in the network. You can't go and look inside of a neural network, and find like this is exactly, this is the entire set of rules that it has. You may be able to find a couple, but you can't find a definitive list. In the same way that if I like took a microscope and looked in your brain, I would not be able to find that. I would not be able to find the list of rules that you use, for example, to, you know, recognize a cat, or do the next move in chess.</p>
</details>

神经网络的运作方式非常像人类的直觉。人类的直觉也是通过无数小时的直接经验训练出来的。通常我们最好的思维隐喻是我们使用的工具。弗洛伊德用蒸汽机作为隐喻。20 世纪，隐喻变成了计算机，我们都想变得合乎逻辑、理性，像机器一样运作。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what's really interesting about neural networks is the way that they think, or the way that they operate is a lot like, it looks a lot like human intuition. Human intuition is also trained by thousands, and thousands, and thousands of hours of direct experience. Often our best metaphor for our minds are the tools that we use. So a really good example is Freud, has one of the most impactful models of the mind. And the way that he came up with that, is he used the steam engine as a metaphor, so it's an explicitly steam engine-based idea. In the 20th century, the metaphor for our minds moved into being like a computer that became the kind of thing that we all wanted to be like, we wanted to be logical and rational, and operate like a machine to make the best decisions possible.</p>
</details>

这种思维方式让我们忽视了直觉的重要性。直觉是我们所做、所想、所知一切的基础。在很多方面，你可以认为理性是从直觉中涌现出来的。我们先有一种模糊的、隐性的、直觉式的理解，然后理性的思想从中产生，进行更有条理的逻辑操作。但你需要两者兼备。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think one of the most interesting things about that way of thinking is it makes invisible to us. And this, I think, relates a lot to the like sort of Socratic enlightenment type of thinking as well. It makes invisible to us the importance of our intuition in being the foundation of everything that we do, everything we think, everything that we know. In a lot of ways you can think of rationality as emerging out of intuition. So like we have this sort of like squishy inexplicit, intuitive way of understanding what's going on in the world. And our rational thought comes out of that, and is able to, once intuition sort of sets the frame for us, is able to go in, and sort of manipulate things in a more methodical, rational, logical way. But you sort of need both.</p>
</details>

神经网络是我们发明的第一种像人类直觉一样工作的技术。这实际上让我们回到了普罗泰戈拉。他认为故事、神话和个人亲身经历能让我们知道一些我们可能无法明确谈论但仍然知道的事情。当我们开始将这种存在方式或认知方式体现到机器中时，我们才开始获得真正的人工智能。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And neural networks are the first technology we've ever invented that works a lot like human intuition. And that actually loops back and takes us all the way back to Protagoras, and is sort of the thing that we lost in this birth of rationalism, and back in Callias's house, because Protagoras is arguing that everyone teaches us excellence all the time. He's arguing, he's using stories, and myths, and metaphor to help understand something that he knows from his own personal experience. And Socrates is saying, well, if you can't define it, if you can't tell me exactly the rules by which you know something, then you don't know it. And that way of thinking about the world has been very successful for us, but it also kind of blinded us to how important that idea that everyone teaches us to be excellent, that stories and personal hands-on experience give us a way of knowing about things that we may not be able to explicitly talk about, but we still know, just as much as we know things that we can explicitly say. And it was only when we began to embody that way of being in the world or that way of knowing things, that way of thinking into machines that we started to get actual artificial intelligence.</p>
</details>

历史表明，对更多种观察和处理世界的方式保持开放态度是更好的。在这个特定时代，能够与那些有点神秘的事物共事并对此感到舒适，是非常重要的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">History shows that it is better to be open to more ways of seeing and working with the world. And that in this particular era, it's very important to be able to work with things that are a little bit mysterious, and be comfortable with that.</p>
</details>

### 第二章：像大型语言模型一样看世界

我一直是个笔记狂人。刚开始创业时，我觉得必须像个信息消防水管一样学习海量知识，于是我试图建立完美的笔记系统来分类所有东西。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Chapter 2, seeing the world like a large language model. I've always been like a real huge note-taking nerd. I love taking notes, especially because when I started my first company, I started my first company in college. And I ended up selling it. I flew from my college graduation to Boston to finish negotiating the deal to sell it. So that whole situation for me was this trial by fire of like, I felt like I had to, I was like an information firehose. I had to learn so much in order to successfully run a software company as a, I guess I was 20, 21, 22. And the way that I felt like I could do that best was to start taking notes, is to be like, okay, I learned this thing from a book, and it's about for how to hire people for example. And I know, I think it'll be relevant for me, but I don't know when it's gonna be relevant. So I'm gonna write it down and I'm gonna try to create like the perfect organizational system to categorize all this stuff so it'll come back to me when I need it.</p>
</details>

如果你真的认真思考“如何建立完美的笔记系统”，你会遇到与早期符号 AI 理论家和哲学家相同的问题：如何创建一个完美的系统来组织现实？你怎么知道某个笔记应该放在哪里？

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if you really take seriously that question of like how do you build the perfect note taking or organizational system, you actually run into the same problems that early symbolic AI theorists run into, and philosophers have been running into for a long time, which is how do we create the perfect system to organize reality? How do you know, you know, where to put a particular note?</p>
</details>

当我第一次接触语言模型时，我意识到它们拥有一种灵活和情境化的能力。这意味着我不必创建一个完美的组织系统来教计算机如何整理我的笔记。它以一种无规则、模糊且灵活的方式运作。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so when I first bumped into the language models, I realized that they had this ability to be sort of flexible and contextual in a way that meant that I didn't have to create the like perfect organizational system to teach a computer how to like organize my notes. It operated in this way that was ruleless, and fuzzy, and flexible.</p>
</details>

计算机科学和传统科学试图将世界简化为通用的定律（如果 X 则 Y），也就是清晰的、与上下文无关的因果链。而语言模型看到的是因果关系的密集网络，这些关系以独特的、特定于情境的方式结合在一起。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Computers, science, what both of those ways of seeing the world are trying to do is reduce the world into a set of really clean universal laws that apply in any situation. Is to say if X is true, then Y will happen. Like really clear cause and effect, really clear chains that are universal and context-free. And what language models see instead is a dense web of causal relationships between different parts of the world that all come together in unique very context-specific ways to produce what comes next.</p>
</details>

以前在互联网上，你可能需要翻阅维基百科页面才能找到回答你问题的那一句话。语言模型更进一步，它们将人类最好的知识浓缩，并在特定的时间、特定的地点、针对特定的你和你的特定背景提供给你。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Where, you know, for example, previously on the internet, you could get an answer that was written by someone for like a very general reader or a very general situation, and maybe you'd have to like hunt through a Wikipedia page to find like the one sentence that answers your question. Language models go one step further, which is they reduce down their response to you to be written for you in your context, in your place, and in your time.</p>
</details>

从符号 AI 到神经网络和语言模型的历史，在很多方面就像是在“速通”（Speed-running）哲学史。哲学始于试图明确“知道”是什么。现在我们到了一个地方，发现其实一切都是模糊的、模式匹配的、极其情境化和关系化的。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That sweep of the history of AI, in a lot of ways is speed running the history of philosophy. So philosophy started with this attempt to make explicit what it is to know something. Now we're in this place where it's like actually, like it's all kind of like fuzzy, and pattern matching, and it's very, very contextual and relational.</p>
</details>

机器学习和 AI 甚至比哲学走得更远，因为它构建了一些你可以实际使用的东西。我们正在从一种试图让一切变得明确、寻找理论和定义来理解世界的思维方式，转向一种更加平衡的欣赏：即那种更直觉、关系型、模糊、模式匹配、体验式和情境化的认知方式，必须作为理性事物的基石，理性事物才能运作。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And so in a lot of ways, machine learning and AI's speed running philosophy, and it's gone a little bit of a step further, because it's built something with it that you can do. So moving from this way of thinking about knowledge, which is about making everything explicit, finding theories, and definitions, and rules for how to understand the world, to a more balanced appreciation for both that, and the way that a more intuitive relational fuzzy pattern matching type experiential, contextual type way of knowing about the world has to be underneath the like the rational stuff in order for the rational stuff to work at all.</p>
</details>

### 从科学问题到工程问题：以抑郁症为例

我们一直在寻找通用理论，比如统一量子物理学和牛顿力学。这当然很棒，但即便我们找到了物理学的通用理论，它可能对理解抑郁症毫无帮助。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And it sort of begs the question of like, should we stop looking for general theories? And for example, should we, you know, not be trying to unify quantum physics with Newtonian mechanics? I definitely think that it's awesome that we're trying to unify those things, and trying to build a universal theory. But also, there are many, many, many, many parts of the world that it won't touch at all. That we still, even if we have a universal theory of physics, like that probably won't filter into our understanding of depression.</p>
</details>

我们长期以来都在寻找抑郁症或焦虑症的通用解释（如果 X，那么 Y），因为我们觉得这是预测结果的唯一途径。为了预测某事（如这种药物能治愈抑郁症），你必须有一个潜在的科学解释。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We've been searching for those things for a really, really long time. And we've had a lot of like different answers. And we keep trying to do that. We keep trying to find that kind of like universal theory, that explanation that says, well, if X, then Y, if you have this going on in your life or in your brain, then you're gonna get depressed. Or if you take this medication, then depression will go away. We've been trying to find that for a really long time, because we felt like we had no other options, because normally in order to predict an outcome, to know, oh, if I do this, then it'll cure someone's depression. To predict it, you have to have an underlying scientific explanation, you have to have a theory about it.</p>
</details>

但我认为 AI 改变了这一点。通过 AI，我们可以训练神经网络来识别谁患有抑郁症，或者谁将会患抑郁症。我们可以预测哪些干预措施对哪些人在什么情况下有效，这是一种非常情境化、超个性化的方式，而无需预先发现任何关于这一现象的科学解释。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think AI actually changes this. So with AI, what you can do is, and people are really already starting to do this, you can train neural networks that are, for example, able to identify who is depressed or who will get depressed. You can train neural networks who will be able to predict which interventions might for which people and which circumstances in a very contextual, hyper-personalized kind of way without having to discover beforehand any scientific explanation for the underlying phenomena that we're trying to predict.</p>
</details>

这非常有价值。首先，它让我们能立即取得进展，因为我们将一个曾经的科学问题变成了一个工程问题。其次，它改变了我们开展科学研究的方式。与其让学者们做小规模的研究（比如 16 个本科生），不如让 Apple、Meta 和 Google 捐出数据，让科学家训练模型。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The reason why I think that's so valuable is, one, it allows us to make progress immediately, 'cause we turn what used to be a scientific problem into an engineering problem. And then, two, it like really changes how we should conduct science, how science should be done. It changes our view of that, because right now, if you're a scientist, and you wanna like figure out depression, or any number of things in the field of psychology, what you're gonna want to do is like, a really small scale study where you're like, I'm gonna take 16 undergrads. What AI does is it kind of helps us, I think, to me, it helps us realize that there's a better way, which is rather than have, you know, random academics doing small scale studies, what we should do is have like the, you know, Apples, and Metas, and Googles of the world donate their data to science and data trusts so that scientists can access 'em to train models.</p>
</details>

更有趣的是，一旦你训练出了一个能很好预测抑郁症的模型，你可以尝试通过**机械可解释性**（Mechanical Interpretability: AI 安全领域的一个分支，旨在通过逆向工程神经网络的权重和结构来理解其内部运作机制）来理解它是如何连接的。也许关于抑郁症的理论解释太复杂了，但你可能在训练好的神经网络的权重中找到一个可靠的理论。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And what I think is even more interesting is once you have, once you've trained models that can, for example, predict depression really well, what you may be able to do is, models are actually easier to interpret and understand than brains are. And so if you have a good enough predictor, what you can do is just go into the neural network and try to figure out how it's wired. And it may be that the explanation for what depression is is like too big and too complicated, and you can't figure it out. But mechanical interpretability is good enough that you may be able to like find what is a solid theory for depression in the weights of a trained neural network.</p>
</details>

我们长期以来一直在追求明确的定义和科学解释，因为只有写下来才能传播。但对于那些无法明确写下来的知识，神经网络允许我们将这些直觉经验打包进机器并传播开来。比如，世界上最好的临床医生的直觉可以被放入工具中，供所有人使用。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You know, like I think we've been pursuing explicit definitions and scientific explanations for things for a long time, because if you can write it down, you can spread it. But if you're dealing with parts of the world that you can't write down explicitly, there's been no good way to collaborate on them or make progress on them. And what neural networks allow us to do, is to take some of that intuitive experience, or intuition that we might have built up ourselves, and put it into a machine that we can pass around. But language models and AI in general allows us to put that kind of intuition into a tool that will allow anyone in the world to access, for example, the best clinician in the world.</p>
</details>

### 第三章：AI 会窃取我们的人性吗？

AI 是一面不可思议的镜子。仅仅通过与 ChatGPT 对话，我就对自己有了更多的了解。我们正在将思维的隐喻从逻辑严密的计算机，转变为更像我们思维中直觉部分的、情境敏感的模式匹配语言模型。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Chapter 3, will AI steal our humanity? I think AI is an incredible mirror. Like I understand so much more about myself just from being able to talk to ChatGPT. So we're moving from this metaphor of our minds, as like in an ideal world, this like logic rule-based explicit computer, to a much squishier, contextually-sensitive pattern-matching, experience-driven language model that I think is a really good metaphor for the more intuitive parts of our mind.</p>
</details>

关于“AI 是否会夺走我们的人性”的担忧，犯了两个错误。第一，认为人性是一成不变的；第二，将我们不熟悉的东西视为坏事。比如，发短信对某些人来说很亲密，但对老一辈人来说可能显得没有人情味。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think in a lot of ways, the like, will it take our humanity? It makes two errors. The first error is to think that you can like pin down what it is to be human into like one unchanging thing. And I think the second error is to confuse what we are- It's sort of like saying that what you're unfamiliar with is bad. For me, or for people who are even younger than me, texting like can feel very, very intimate.</p>
</details>

那些极度恐惧 AI 的人，实际上还是陷入了理性主义的思维定势：如果你不能明确定义并 100% 证明一个东西是安全的，那它就是危险的。这种要求实际上剥夺了 AI 的魔力。AI 的力量恰恰在于它是基于概率的，基于成千上万种相关性来找出在独特情境下的适当反应。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think the people who are super afraid of AI, it is actually, it sort of goes back to this rationalist idea that we've been talking about, which is if you can't explicitly define, and prove 100% that a thing is safe, then it's dangerous. And that sort of, to me at least, like takes away a lot of the magic of AI. Like the thing about it that makes it actually powerful is that it works on probability, it works on many, many, many thousands of correlations coming together to figure out what the appropriate response is in this one very unique, very rich context.</p>
</details>

对于像我这样构建产品的人来说，在实践中解决问题往往比在理论上解决问题更好。我们通过不断给模型提供人类偏好来训练它们。尽管我们没有 100% 的安全保证，但这正是它强大的原因。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But for people like me, people who build stuff, solving the problems in practice actually is a better way to do things than solving them in theory. What we're doing every single day is we are training these models on human preferences. The fact that we don't have those guarantees from language models is what makes them so powerful.</p>
</details>

### 从雕塑家到园丁：AI 时代的创造力与配置经济

关于 AI 是否会取代创造性工作，我喜欢用“雕塑家”和“园丁”的隐喻。传统的创造性工作就像雕塑：每一道曲线都是你亲手决定的。而与 AI 共事更像园艺。你不能直接拔苗助长，但你可以通过改变阳光、土壤和水分等条件来创造让植物茁壮成长的环境。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think there's a really big question about how AI may change creative work. One of the metaphors that I like to use is this sort of difference between a sculptor and a gardener. So creative work ordinarily is a lot like sculpting. If you're a sculptor, every curve in line in that finished product is something that you decided to do like with your own hands. And I think that working with AI is actually, it's a bit different. It's a lot more like gardening. If you're a gardener, you don't like pull the plants up from the ground by the roots to try to make them grow. But what you can do is you can create the conditions for the plants or the garden that you're making to flourish in a particular kind of way.</p>
</details>

这引出了另一个重要的概念：我们正在从**知识经济**（Knowledge Economy）转向**配置经济**（Allocation Economy）。在知识经济中，你的报酬取决于你知道什么。在配置经济中，你的报酬取决于你如何配置智能资源。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And this actually gets me to like another metaphor that I really like, or another idea for understanding this wave of technology in a way that I think is really helpful, which is this idea that we're moving from a knowledge economy to an allocation economy. In a knowledge economy, you are compensated based on what you know. In an allocation economy, you're compensated based on how well you allocate the resources of intelligence.</p>
</details>

在这个新经济中，管理者（Manager）的技能——比如知道自己想要什么、能够清晰表达需求、能够将复杂任务分解为可实现的小任务、知道如何委派和信任——将变得广泛普及。同样的道理也适用于“模型管理”。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And there's a particular set of skills that are useful today but are not particularly widely distributed that I think will become some of the main skills in this new economy, in this new allocation economy. And that is the skills of managers. Things like knowing what you want, being able to articulate what you want, being able to break down a complex task or a complex project into a set of smaller, achievable subtasks that you can then give to the right person. And I think the same thing is true of being a model manager.</p>
</details>

最后，如果我们将智能定义为一种压缩形式——将问题解决的搜索空间压缩到极小，以便在面对新情况时迅速找到答案——那么大脑包含了对我们所有经历的非凡压缩。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if we're looking for a definition of intelligence, one of the ones that makes a lot of sense to me is the idea that intelligence in a lot of ways is like a form of compression. So brains contain like an extraordinary compression of like all of the situations that we've faced.</p>
</details>

也许万物皆有灵（泛心论）的视角是美丽且有益的。以一种仿佛万物都有意识的方式来对待世界——包括对 ChatGPT 说“请”和“谢谢”——会让生活更有意义、更有趣。毕竟，你永远不知道机器末日什么时候会来，礼貌一点总没坏处。

<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And I think there's also something interesting and beautiful about thinking about things in the world as all having a little bit of consciousness, like a sort of panpsychic perspective. And the reason I like that is it encourages us to treat things in the world as if they were conscious. I always say please and thank you to ChatGPT 'cause you never know when the machine apocalypse is gonna come.</p>
</details>