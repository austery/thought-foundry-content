---
author: 东京人文论坛
date: '2025-12-25'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=ZY1iTM7X2r0
speaker: 东京人文论坛
tags:
  - llm
  - prompt-engineering
  - knowledge-management
  - reading-habits
  - ai-education
title: 李厚辰：AI时代，我们还要读书吗？
summary: 讲者李厚辰探讨AI时代读书形态的巨变。他认为AI工具如Notebook LM和ChatGPT能高效替代大部分理论类书籍的阅读，尤其在获取知识广度方面优势显著。然而，AI无法替代“为愉悦而读”的内容，也难以取代深度思考的“剧读”。核心挑战在于，AI时代要求读者从“理解”转向“提问”，掌握高质量的Prompt工程能力，以构建更丰富的上下文，从而最大化AI辅助阅读的价值。
insight: ''
draft: true
series: ''
category: ai-ml
area: "work-career"
project: []
people:
  - 李厚辰
  - 贾家老师
  - 汉娜·阿伦特
  - 张枣
  - 尤瓦尔·赫拉利
  - 王岐山
  - 许晨刚
  - 托克维尔
  - 哈贝马斯
  - 卢梭
  - 亨廷顿
  - 陈嘉宁
companies_orgs:
  - Google
  - OpenAI
  - 逻辑思维
  - 樊登读书会
  - Anthropic
products_models:
  - Notebook LM
  - ChatGPT
  - Gemini
  - Grok
media_books:
  - 《极权主义的起源》
  - 《枪炮、病菌与钢铁》
  - 《旧制度与大革命》
  - 《新教伦理与资本主义精神》
  - 《哲学研究》
  - 《存在与时间》
  - 《人类简史》
  - 《制度基因》
  - 《红太阳是怎么升起的》
  - 观察线
status: evergreen
---
### AI工具改变阅读形态

今天是一个简单的分享，因为正值图书节，我觉得大家读书的形态正在发生特别大的改变。在场用过**Notebook LM**（Google Project: 一个可以上传文档并进行问答、生成导读、思维导图和报告的AI工具）的人很少，这让我很意外。既然大家来了，至少要知道**Notebook LM**是**谷歌**员工做的一个项目。这个项目允许你把任何文档放进去，无论是一本书、一个PDF，还是一个YouTube视频，它都能抓取内容，然后你可以向它提问。其中一个最常用的功能是生成语音导读。

### 《极权主义的起源》案例演示

我给大家演示一段。今天上午**贾家老师**提到一本书叫**《极权主义的起源》**。我放一段这本书的导读，可能声音有点小。这是**汉娜·阿伦特**的**《极权主义的起源》**，这本书名气很大，但读起来很难。我们的任务是利用导读和资料深入这本书的核心。这本书的书名叫“起源”，它探讨了极权主义与传统专制独裁的根本区别，这种区别在于统治的底层逻辑。传统的暴政，如历史上的皇帝或军阀，逻辑很简单：谁反对我，我就干掉谁，其恐怖是有目标的，是为了维护统治。但极权的逻辑完全不同，它的目标是让一种宏大的运动法则，比如纳粹的种族优胜劣汰法则，或斯大林的阶级斗争历史法则，彻底贯穿社会。

这听起来很抽象，什么是运动法则？感觉像物理定律一样。这个比喻很贴切。在集权统治者看来，历史或自然就像一个巨大的传送带，正朝着一个确定的方向前进，而他们不是统治者，只是这个法则的执行者。在这种逻辑下，很多东西都变了，首先敌人变了。这是一个两人对话的播客，由**Notebook LM**生成语音预览，也就是语音导读。它还有思维导图、文本报告等，都可以基于你提供的材料来做。现在很多人会把想读的书扔进去，让它生成一个语音导读，短则十几分钟，长则半小时。

### AI导读的效率与局限

你可以使用**Prompt**（提示词: 用户写给AI的指令或问题）让它生成导读。我通常会用两个不同的**Prompt**生成两个不同的导读，所以一本书加起来可能一个小时或一个多小时。听完一遍后，我必须诚实地说，过去读过的书就不用再读了，很多新书听完一遍后，我其实也没有心思再读了，因为我觉得书的内容差不多也就知道了。**AI在某种程度上替代了传统读书方式**。

当然，AI并非能替代所有书的阅读。比如今天上午我推荐的**张枣**的诗集，你想用AI帮你读诗，这完全没有意义。我们有很多阅读是“read for fun”，为了愉悦和阅读体验，比如读诗、读小说。看侦探小说，你要的就是跌宕起伏的解密过程。如果让AI生成，它直接揭露谜底，你就没机会再读了。所以，**所有“read for fun”的内容，AI无法替代**，你仍然需要去读小说、读诗。

### AI对“知其所以然”书籍的替代

然而，我们生活中有很多阅读并非“read for fun”。例如，很多“know-how”类书籍，工具书、行业书籍，你读它们是为了知道“该怎么办”。我甚至认为，对于“know-how”这个领域，连书本身都被AI替代了，更不用说读书过程。**对于“know-how”类书籍，AI的总结甚至可能超越非顶尖作者**。

我再举一本书为例，我相信在座读过**《枪炮、病菌与钢铁》**的人，一定比用过**Notebook LM**的人多。这本书是社科领域的经典畅销书。读过这本书的人，有多少人有足够的自信，如果我给你三分钟，你对这本书的复述能比**ChatGPT**更好？我猜是没有的，这非常正常。因为大家都有阅读理论书籍的经验，读完一本理论书籍后，你基本只能复述出特别零散的观点。比如很多人读过**《旧制度与大革命》**，但如果让你讲它讲了什么，我猜绝大多数人做得不会比**ChatGPT**好。这说明这本书在你脑子里留下的印象是非常浅的。

### 理论书籍的吸收困境与AI的优势

这是我们很多时候读书的经验，也不奇怪，人的记忆就是如此。如果你读书没有花那么多功夫，感受也不会那么深。问题是，既然你读完**《枪炮、病菌与钢铁》**五年后，印象只剩下两句话，那你何不直接读**ChatGPT**对它的介绍呢？文本更短，注意力消耗更少，观点更了解。我们发现，阅读理论类书籍本身就存在记不住很多内容的问题。理论类书籍有两种：一种是事实量非常大，比如历史书籍，这类有叙事性的非虚构书籍，如历史书、人类学著作、现场研究，需要了解大量细节和事例，读起来可能还有点意义，但即便如此，两个月后你可能也记不住多少。

另一种是非虚构的理论书，如大量经济学、政治学、历史哲学、社会学著作，像**《旧制度与大革命》**或**《新教伦理与资本主义精神》**。这类书你自己通读一遍，吸收也非常有限，那为何不找AI来读呢？其实早在AI出现之前，我们就已经用其他方式替代阅读这类书了，比如**逻辑思维**或**樊登读书会**的书籍拆解。你要的就是书的观点，如果一个人能用很好的方式在40分钟内讲给你，何苦去读整本书呢？当然，我不认为读整本书的收获会比40分钟小，只是成本完全不匹配。所以，理论类书籍的阅读体验被其他体验替代，早已是发生的事情。

### 深度阅读的挑战与AI的崛起

我自己也做过讲书和讲一套书，篇幅更长而已。所以，即便是我这个自认为会读书、读得多的人，绝大多数读过的理论书，如果现在让我复述，我也没有自信能超过**ChatGPT**。当然，有些书我有自信能超过**ChatGPT**的解释，但这些书我基本都投入了远超一般阅读的精力，比如我以剧读的方式讲过的**《哲学研究》**。对于这类书，我当然有十足把握，**ChatGPT**再更新几代，我都会超过它。但我必须说，我花这么大功夫读的书也非常非常少。

我们把读一本书分为几种不同的努力类型。最简单的是读了三分之一到一半，这很常见，很多人读理论书读不完就放弃了。这种情况下，花的时间不如找**ChatGPT**或**Notebook LM**听40分钟，时间更少，你至少能完整了解书的含义，而不是半途而废。第二种是通读完了，但没有做任何笔记、思考或反思，就像听音乐会或看小说一样。我必须说实话，这种功夫读的理论书，最后吸收不了多少，只是得到一个感觉，觉得好像了解了很多了不起的东西，但这种感觉能否实际使用，是高度存疑的。

### AI时代知识生产的困境

我认为，这种阅读方法也已经被AI替代。**唯有深度投入、边读边思考做笔记的“剧读”方式，AI无法替代**。在这个过程中，你的脑力思考和积累才能超越AI。但我不得不提出一个悲观的事实：现在有多少人有时间用这种心态来读一本书？在这种情况下，我确实认为，类似非叙事性的理论书，AI已经非常有用了。而且，很多作者为了字数，把三万字能说清楚的内容拉拉杂杂写到二三十万字。你自己啃一本十五万字的书，不如读一个精简版。其次，很多英文书靠翻译，过去很多翻译者的心血和水平与现在的**ChatGPT**相比，差距很大。一本翻译很烂的书，不如让**ChatGPT**给你来一遍中文。**对于非叙事性理论书，AI已成为很好的替代方案，尤其能解决冗长和翻译质量问题**。

### AI的交互式阅读体验

AI比**樊登读书会**和**罗振宇**又前进了一大步。比如**罗振宇**讲**《新教伦理与资本主义精神》**，他可能花半小时讲一遍，你听完觉得不错，但如果哪里没听懂，你无法继续发问。但AI不同，无论是**Notebook LM**还是**ChatGPT**，你都可以继续发问。**Notebook LM**这个平台就是让你对提供的文档进行进一步发问。它左边是文档，右边是语音预览，中间是**ChatGPT**对话框，你可以问这本书讲了什么，哪个部分是什么，它都能答出来。这是一个很厉害的产品。**AI能提供持续的对话式互动，突破传统讲述的单向性**。

它突破了过去讲述最大的麻烦，即你听一个人讲述时，某个点可能触及你的问题，你很想深入了解，但他讲的是写死的，无法继续提供信息。但**ChatGPT**和**Notebook LM**都可以继续发问，对话过程可以持续下去。我甚至想出了这个产品的终极形态：如果未来这个产品能让你中间打断，用语音提问，比如“你们刚才讲的一个点非常好，我想更深度了解一下，在书里能再给我讲讲吗？”这在**ChatGPT**看来根本不是技术障碍，一定可以实现。**未来AI产品将实现语音打断、随时深入的对话式阅读体验**。

### 知识获取模式的转变

如果这种对话可以中间打断并继续下去，意味着你完全在一个针对这本书的对话之中，这个产品很快就会有人做出来，甚至已经有人在做了。有了这种体验后，我认为你吸收一本非叙事性理论书，绝对比你自己读一遍吸收得要好得多。你甚至可以让他再给你讲一遍，举个例子，这些都能做到。在这种情况下，读书这件事真的遇到了很大的挑战，挑战在于我们过去与书的互动关系比较弱，是一个非常单向的过程。但一旦与书的互动关系变成这种可以用语音互动、随时暂停、随时深入，甚至还能看到文稿的方式，那不就非常厉害吗？它把一本书变成了一个对话。**Notebook LM**已经在做这个事情，未来会有更多包装更成熟的产品。读书的体验变了，用更少的时间、更好的方式、更好的吸收方式了解一本书的全貌，这个挑战非常多。

过去，读书在社会上是一个非常主流的吸收知识的方式，在其他媒介不发达时更是如此。后来出现了更平民的媒介，如电视，现在是短视频。如果把社会想象成一个中产阶级社会，过去这种民间形式是从下往上替代的。也就是说，过去我们的父母那辈还读书，后来抖音上有了那么多人生智慧、治世名言、社会真理、金融真相，他们可能就不太读书了。花30秒了解金融真相，何苦花三周去读一本书呢？过去媒介替代是从下往上进行的。**在AI到这一步之前，书籍依然是精英群体非常重要的获取知识的方式**。

### AI时代精英阅读的变革

对于精英群体而言，书籍仍是他们重要的生活方式。但现在，这波替代是从上往下的。也就是说，对知识要求最高、技术掌握最好的人，比如过去读书最多的人，他们可能会率先使用AI方式替代读书。我自己就是如此。第一，要读的书很多，我不是为了好玩而读。如果一个话题我需要在不长的时间内吸收十本书的内容，完全读一遍需要大量时间，但如果变成十个小时在**Notebook LM**上听，是完全可行的。我甚至愿意为一个话题花十个小时听完这十本书。

第二，你对技术手段掌握较好，知道如何用更好的**Prompt**榨取书的精华，也愿意用多元方式与书和**Notebook LM**互动。这群人过去在系统性获取知识方面处于领先地位。现在，**AI对读书的替代正从精英群体开始，改变了系统性知识获取的方式**。因此，上下层级再往中间挤压，中间部分的替代必然会发生。中间这群人要的是什么？他们不愿意花时间探索，他们要人做好一个成熟的产品。

### AI阅读应用的兴起与知识深度的牺牲

你可以想象未来有一个APP，就叫“读书”。你点开后有很多话题，比如你对日本历史、江户历史感兴趣，点开后有50本书，你选择其中四本，它就给你生成这四本书的语音，你可以听并互动，提问这四本书的内容。这相当于把**Notebook LM**的东西包装成一个非常成熟的产品。有人提到手机里已经有这样的软件叫**dailybrew**（一款AI总结书籍内容的APP），它能总结书的内容。这种软件一定会越来越多，中间那层读书的人可能也就不读书了，而是用这种方式。而且这个软件一定会越来越好用。

这其实也不是坏事，大家能更高效地吸收知识有什么不好呢？但它有两点问题。第一个问题是，如果每个人都用这种方式读书，写书的人为什么要写书呢？这对写书的人是巨大打击。我辛辛苦苦两年写三十万字，你半小时消化完，也不买我的书，我最后只能跟这种软件签协议，几万块钱授权给它，然后你们几天就听完了。如果你们只要这个，我直接写两万字文章不就完了吗？再配一个三千字的摘要。**AI可能导致书籍篇幅压缩，影响知识生产的深度和作者的盈利模式**。

### 知识深度与广度的权衡

这确实正在发生。我认为在这种情况下，采用写书进行表达的人会越来越少，未来可听的书也就越来越少。未来能听的可能是两万字的文章。听两万字文章也不坏，但书籍毕竟是一种盈利模式。你愿意为一本书付1500日元，但一篇两万字的文章你愿意付多少钱？你可能觉得花1000多日元买一篇两万字的文章太亏了，即便它可能比十二万字的书更好。但因为篇幅所限，你不愿意付钱，出版社也不愿意买。因此，过去知识生产和知识付费与篇幅直接相关。如果现在篇幅因AI大幅压缩，对知识生产是个很大的问题。

如果知识生产者变少，都转向播客或YouTube等其他付费方式，问题在于，好好写书这件事还是很特别的。一本书的篇幅，如果不是为了凑字数而写到十几万字，而是精心写就，其论理深度与两万字文章毕竟不同。在这个篇幅之下，即便绝大多数人囫囵吞枣地读摘要，但如果你真的静下心来深度阅读，收获量还是很大的。我们可以举个例子：现在通过精心写就的二十万字书和长时间阅读，知识深度假设能达到一百。用AI快速阅读，知识深度可能到三十。你自己囫囵吞枣看一遍，知识深度可能只有十。从十到三十是一个很大的进步。

### AI时代对人类能力的挑战：从理解到提问

我相信未来大家都能借助AI，以更好的方式达到三十。但是，它可能牺牲的就是达到一百的代价，即能够达到一百的素材和时间都大量减少了。这很有意思。**陈嘉宁老师**曾讲他们在文革时期的读书经历，下放到农村，无事可做，书非常少，不像今天去**Z Library**（一个提供免费电子书下载的网站）下载三千本书。那时整个草原上几个村子只有几本书，而且多是**马恩列毛斯**（马克思、恩格斯、列宁、毛泽东的著作合称）等，你只能以“韦编三绝”的心态读，一个字一个字地读。那种吸收是不一样的。今天是一个信息爆炸和书籍爆炸的时代，当你突然发现能用三十分钟高效了解到“三十”这一层，你会觉得以前读书从未如此明白。

但书这么多，自然产生一个问题：你可能过去想在一本书上花更多时间，这就出现了一个机会成本。假设你觉得**海德格尔**的**《存在与时间》**很厉害，想花两个月达到“一百”的深度，但你又担心读不懂。而这两个月可以听多少三十分钟的AI导读呢？你可能觉得算了，听一个网上对**《存在与时间》**的解读，变成三十分钟，或者找五本解读，变成五个三十分钟，两个小时听一遍，替代自己读。我不得不说，这是一个理性的决定，也是绝大多数人会做的决定。但这会让达到“一百分”的知识深度大幅削减。当然，这听上去糟糕，但我觉得也还好。对于大量普通公众，如果你不想成为**海德格尔**专家，花“一百分”的精力可能也并非必要。**AI时代能高效获取“30分”的知识广度，但可能牺牲达到“100分”的深度**。

### 提问能力成为核心素养

所以，AI对读书的冲击和改变，我认为未来整个知识生产的生态都会发生改变。既然AI辅助阅读似乎也不坏，大家估计会采用这种方式，那它其实对人的能力有一个很大的挑战。如果你想在这个路径上做得更好，这与你过去读书的方式不同。过去读书主要靠记性，一本书二十万字，你需要非常宽幅的注意力资源和非常长的**工作记忆**（Working Memory: 人类认知系统暂时存储和处理信息的能力）才能读通。现在三十分钟的导读不需要那么长的**工作记忆**，只要保持三十分钟注意力即可。

但这里面出现了另一个问题：过去读书，问题意识是作者的，作者花整本书的篇幅把问题意识传授给你。但现在用AI总结读书，我不得不说，AI在这方面有很大欠缺，它没有很强的问题意识。如果你了解**Large Language Model**（大型语言模型: 基于海量文本数据训练，能理解和生成自然语言的AI模型）的运算方式，就知道它很难有很强的问题意识。因此，用AI总结一本书，它很可能错过书中最关键的部分，或者错过你在阅读时可能与书中某个章节产生的深度链接。**AI时代读书，核心能力从“理解”转向“提问”**。

### AI内容生成机制与上下文构建

提问变得非常重要。你对一本书能问出多么好的问题，因为**ChatGPT**就是这样，你问题问得好，它答案答得好；问题问得泛泛，答案也泛泛。**ChatGPT**的问题训练不是单一的，它是“a chain of questions”，一个链条式的问题。你可以问一个问题，然后是Follow up question，Follow up question。所以，你有没有通过深度问题链与AI挖掘的能力，这变得非常重要。未来，对一本书的阅读，你通过AI了解多少，最关键的是发问能力。发问能力是一个很需要经验与感受的能力。

大家平时用AI应该很多，最普遍的用法是把AI当搜索引擎用，问它过去问搜索引擎的问题，只不过它能给出更好的答案。但这肯定不是用AI的好办法。我想请问各位，对于什么是好的问题问AI，你们现在有什么心得？我告诉大家一个观念，对于用AI读书依然非常重要：你给AI的问题，永远别是你自己写的问题，而是你拜托AI帮你写的问题。因为你自己问问题的能力很差，或者说你花不了那么多时间。如果你让AI给你写一个**Prompt**提问，提问可能长达四千字，你自己不愿意花那么多时间，但你可以让AI帮你写。

### 学习AI提问的技巧

我分享两个拜托**Notebook LM**生成语音摘要的**Prompt**，它们都是AI帮我写的。我就是想知道这本书在讲什么，但不想通过目录了解，因为很多书作者的问题埋在目录之中。所以我会让**ChatGPT**基于一本书生成两个长的**Prompt**。第一个问题是：“跟其他该领域的书相比，这本书的特殊之处是什么？”第二个问题是，从这本书的内容中找出十个最关键的、平时讨论较多的话题，把这些话题问出来。另一个方面是有七个更深的问题，这些都可以让**ChatGPT**帮你写。

如果你直接让**Notebook LM**帮你生成一本书的语音摘要，它很可能只是非常机械地从头到尾讲述。但如果你用**Prompt**的方式，让**ChatGPT**基于你的要求，把内容重新组织成十个或七个问题，它既节省时间，又生成了十个更好的问题。而且，你可以继续要求它修改。所以，无论是给**Notebook LM**的**Prompt**，还是给**ChatGPT**的**Prompt**，都应该是一个**ChatGPT**给的**Prompt**。这是第一步。

### AI时代的教育变革：从“学”到“问”

从这一步开始，你不能永远或百分之百依赖AI，这里面也需要一部分你的问题。所以，人要学会向AI学习。每次让AI生成问题后，你当然可以不看就直接扔给AI，这是最简单的方式。但如果你稍微花点时间读一读AI问的问题，我觉得这是在练习这个时代最重要的技能。因为AI时代最重要的技能就是**Prompting**，即如何问问题。AI生成的问题，其前因后果和论述结构，是人可以去学的，就像跟AI学下围棋一样，也跟AI学问问题。

这个东西，以前有人问我AI时代学校教育有什么改变，我慢慢觉得，学校教育的最大改变，要从“怎么学”变成“怎么问”。因为怎么问问题，在我们的教育过程中，即便是西方教育，都基本上没有特别好的练习。我们的教育练得最多的是“理解它是什么”、“理解它怎么样”，即搞懂一本书在说什么。我们非常少被训练该怎么问问题，这是很难的事情。

### 实践提问能力：以《制度基因》为例

我们现场来做一个简单的练习。大家应该都知道**许晨刚**的**《制度基因》**吧？我们现在不求了解这本书的全貌，你可能没看过更好，大概知道这本书讲什么。假设你现在得到这本书的EPOP或PDF，扔给**ChatGPT**，你想从中抓取与这本书相关的内容来替代阅读它。请问你大概会问一个什么样的问题？首先，在马列主义教育中有一个很糟糕的点，很多人一想到问题就想找“本质”，这种问法很糟糕。比如你把**《制度基因》**放进去，问“请透过这本书的内容，告诉我这个集权基因的本质是什么”，这一定是很糟糕的问问题方法。

大家想想，你们会问什么问题？有人说“这本书的论述框架是什么？”这是一种问法，但很可能会得到一个比较笼统的回答，比如“这本书的论述框架是使用历史上详实的历史资料，通过精细的分析和跨学科的研究得出的。”你可能得到的答案并没有让你真正了解。但如果问“这本书的局限是什么？”或者“这本书的盲点是什么？”这真的是一个好问题，虽然可能是第二步的问题，但这种问题确实很容易把AI的那个点“炸”出来。你会发现AI每次回答这类问题时，它对一本书的逻辑深度是相对较深的。如果它要整理这本书的盲点，它就不得不跳出这本书之外，而不是简单复述内容。所有跳出这本书之外的问题，都会有比较好的穿透力。

### 拓展上下文语境的提问策略

比如，你可以让他通过这本书的内容，帮你分析2025年的美国或中国，符不符合某种极权的基因模式，给他一个案例，这比你问他这本书怎么样要好。这本书的盲点是什么、问题是什么，很多时候都能得到远比你直接问“这本书说了什么”更好的问题。

我们来感受一下**Large Language Model**是如何生成内容的。它主要是“接下文”。比如我们做一个“接下文”的实验：“外面的狗真渴”，或者“武律发怒的时候真可”...大家都有“接下茬”能力，基于上面的文本，下面的文本出现概率是一定的。比如“那只狗真渴”，也可以是“真可怕”或“真可悲”，但纵观人类所有文本，“真可爱”的概率比较高。如果上下文更长，比如“狗病了”，那一定是“真可悲”；“狗吠”，那一定是“真可怕”。

### AI的“思考”模式与高质量提问

一个外星人来看人类的文字，他不用了解文字意思，就会发现“Dog barking terrified”、“Dog fur cute”、“Dog illness miserable”，这些词彼此之间存在一定的统计关系。AI是如何出词的呢？现在的AI没有任何思考能力，它做的事情是训练了很多内容，训练过程就是让它猜下一个字跟训练材料符不符合。它不断训练，使其能基于一个文本，生成的下一个字与训练材料符合。它就是在计算如何更好地预测人类上下文的一个函数分布。所以整个AI就是一个“接下茬”的工具。

当你了解AI的模式后，就知道你贴一本书给它，如果你问“这本书讲了什么”，那么在过去人类文本的函数分布中，大量会出现的内容是这本书的目录、大致介绍等，它是基于这本书的上下文文本生成的。如果你要问一个好的问题来突破这个上下文，你就要引用别的东西。比如你问“网上对这本书的批评是什么？”那它就要通过**Web Search**功能去搜，搜出的批评是与这本书不一样的看法，它需要把这些东西和这本书的几十万字组合成一个上下文，再猜下一个字应该是什么。那么它的函数分布就超出了这本书的函数分布。

### 赋予AI角色与上下文的重要性

比如你再问：“请问网上对**《制度基因》**的批评是什么？这些批评都有什么共通的问题和盲点？”这又改变了函数分布的样式，输出的东西又不一样。所以你会发现它是一个上下文的**Manipulation**，通过更好的上下文来完成。现在其实方便很多，因为大家也知道，现在都不是直接这么吐了，都有**Chain of Thought**（思维链: AI在生成最终答案前，模拟人类思考过程，逐步推理的内部机制）。它吐的东西不是直接根据你的**Prompt**生成的下一条，而是你问了这个问题，它会在函数里“想”个十多二十步。你们经常发现只要用Thinking模式，它在想“我要啥，要啥”。

现在AI都知道人类问不出好问题，所以你问了一个特别烂的问题，它会帮你把这个烂问题通过“想了二十步”来充实一个非常好的上下文，生成的结果比单独根据你这句话生成的结果好很多，这就叫做Thinking模式，**Chain of Thought**。**Chain of Thought**的本质不是一个思考模式，而是一个上下文的放大器，它把你的上下文变成一个更高质量的上下文，因此“接下茬”质量可能会更高。当你问一个特别简单的问题，它通过**Chain of Thought**能生成一定程度的上下文，但如果你问了一个高质量的问题，让**ChatGPT**给你生成一个四千字的问题，它拿这四千字的问题再通过**Chain of Thought**所形成的上下文质量就更高。

### 培养“对AI提问”的能力

所以，虽然你问个很普通的问题，现在AI很贴心，质量已经很好了，但绝对不比你生成一个好的问题再给它更好。因此，如果你要用这种方法读一本书，就要有办法尝试有好的问题。什么是好的问题呢？我们刚才至少有一个点，就是能够扩充这个上下文语境的问题。比如介绍这本书没有加入任何上下文，你就算给一本书一个空的**Prompt**，它自动的下一句大概也是介绍这本书。所以“这本书说了什么”、“这本书的问题是什么”、“这本书讲了什么”没有任何有益的上下文。

你会发现直到现在使用AI都有一个非常有益的上下文，就是给AI赋予一个角色。比如你说“你是一个政治哲学的研究者”、“你是一个专门研究中美问题的研究者”，你经常发现在问题前面会加这一句。加这一句其实对AI来讲就是一个非常有益的上下文。但这个东西对于人来讲是比较反直觉的。也就是说，对AI来讲，我们现在肯定没有穷尽AI有哪些非常有益的上下文样式，因为程序和函数的逻辑与我们平时思考逻辑不同。**AI时代需要培养“如何向AI提问”的能力，赋予AI角色是有效上下文构建方式**。

### 读书的问题意识与AI上下文

一个人是一个好的提问者和一个人是一个好的AI提问者，其实还是不同的事情。一个人在AI时代要用这种方法读书，要练习提问能力，他不只要成为一个好的发问者，他还要成为一个好的“对AI的发问者”。这两个都是非常需要练习的技能。所以我觉得这不只是对于读书，对很多领域都是，你怎么样基于AI来经营好的发问，这是大家平时用AI时要有意识去做的东西。如果我们把AI当搜索引擎来用，使用方法就太无意识了。一个最有意识的方法就是你要明白，它不是搜索引擎，它是结合上下文的“接下茬”工具。你每次问问题时，要非常有意识地来看，我的什么问题在扩充上下文，什么问题没有扩充上下文。

我们回到读书这个问题。对于书籍来讲，什么东西是非常有意义的上下文？什么东西是你读一本书的问题意识？我们先抛开AI不谈，大家问问自己，你们过去读书时，除了“这本书大家都说好，我想看”，一般会带着什么样的问题意识读一本书？这太泛泛了。比如我读**尤瓦尔·赫拉利**的**《人类简史》**，是什么问题意识？回答不出来很正常，说明大家过去可能并没有带着什么问题意识读一本书，所以这本书很流行，大家都说好，这也不坏。但这就是在AI时代你过去的经验与它脱节了。

### 案例分析：王岐山与《旧制度与大革命》

比如我读书的话，有一个主题是读那些共产党国家破败期的社会史、经济史，了解它们如何衰败，问题是什么，这就是好的历史论述。我再举个例子，在**《旧制度与大革命》**之前，网上有个说法，据说**王岐山**同志在到处推荐这本书，推荐的原因是这本书恰恰说明了中国不应该改革，因为这些国家的瓦解就发生在改革的时候。那么这个就可以是一个问题意识。你完全可以告诉**ChatGPT**：“网上有这样一个说法针对这本书，请你介绍这本书的内容，并且评价这个说法对不对？”你看，这就是一个这本书“偏出来”的上下文。用AI读书，甚至你自己读书，这都是在这本书以外的**Context**。

这东西就像炼金术士一样，就像做菜一样，你原来炖牛肉就这么炖，突然有人告诉你里面加可乐、加冰糖、加柠檬，特别好吃。你没试过。刚才这个问题，就像是给一本书“滴柠檬”的**Context**一样，它未必有好效果，可能特别难吃，那就需要用别的方式来做。**Prompting**这个东西有点炼金术士的色彩。从这个角度，大家还能不能举出一些问题，你过去读书时是带着什么样的问题？我们可以一起来感受感受，它是不是一个AI时代的好问题意识。

### 跨书关联与批判性提问

“这本书里提到了另外一本书，那本书我的感觉是这样，请问那本书我的这个感觉，在这本书里面是不是得到了印证，还是有什么不同？”这是一个很好的问题意识。AI有这个东西还会把那本书的**Context**引进来，所以关联另外一本书与这本书的碰撞，本身肯定是AI时代一个很好的**Question**。

很多问题，我知道实际上有三个不同的答案，但我就想知道你这个A答案的推进逻辑怎么可能，你怎么推出A，你怎么推出B，你的具体论证是什么？但如果你这个答案就来自这本书本身，它还是没有跳出来。比如**《新教伦理与资本主义精神》**，你说这本书有文化决定论的色彩，认为文化对社会形态有决定性作用，那请从这个角度讲这本书。那很可能它就在这本书语境之中，它就没有跳出来，你得到的是一个可能挺普通的答案，就没有那么有启发性。也就是说，这个问题要跟这本书有一点点距离，是一个最好的问题，或者比这本书的抽象层次高一点点，或者对这本书有点批判性，或者这个**Context**最好不来自于这本书本身。

### AI的知识中立性与权威性

比如看**亨廷顿**的书，当时我就想研究他们以前的社会转型和互联网社会，就是中国类似互联网非常发达，市场经济非常发达，就是一个旧化的国家，就有异同之处。互联网国家就觉得也比较失望，就是他们也没提出答案，在传统的社会转型当中，因为没有互联网化，市场经济也不是那么好。但这可能就是**ChatGPT**能够给你惊喜的部分了。也就是说，**亨廷顿**没写，你也想不到，但你把这个问题问给**ChatGPT**，他可以想到，他可以给你解答**亨廷顿**哪部分，或者哪部分如果加入到这个互联网的模式，他会产生什么衍生的变化。这恰恰是用AI读书可能会比自己读书更好的部分。

有人会问，对**ChatGPT**提到的答案，都想找一个权威去认识它是正确的，担心它不懂。我为什么去看**亨廷顿**的书呢？因为他是这个专业方面的权威。我必须诚实地说，我觉得**ChatGPT**在知识上的中立性和权威性好过于你看到的这些人。因为学者都有自己的问题意识，而且尤其是这样的，我觉得有两种心态：一种是做扶桑研究，这是个玩法；第二个是对政治学有兴趣。如果你是做扶桑研究的，那**ChatGPT**不行，因为它很难只深入扶桑的语境，尤其它一搜索，那就是全世界都来了。

### AI幻觉问题的解决与多AI验证

但如果你不是只了解扶桑，而是既了解扶桑也了解中国转型，那我觉得**ChatGPT**生成的答案会比某个学术权威给的答案更好。因为我也读过不少这家那家的书，学者有他自己的问题意识，但那个问题意识的盲点其实非常非常大，绝大多数学者都是如此。所以如果你只是用那个学者来佐证他对，未必他真的有那么四平八稳的道理。**ChatGPT**尤其是现在，很多人可能还提到在2025年初觉得这个东西所谓的幻觉很严重，怕它瞎编乱造，但这个问题到现在基本上已经解决百分之九十了。

到这个版本的AI，有**Web Search**，有**Chain of Thought**，现在AI给你编一个论文的可能性非常非常小，也不是说完全没有，但已经非常非常小了。现在AI的幻觉问题基本得到解决。那么在这个基础之上，它对一个问题给出了分析，包括AI自己训练，它有中立性的**Fine-Tune**。从这个角度来看，我觉得你基本可以认为，它绝对不会输出一个极端偏颇的答案，是非常非常小的概率。它会输出一个剑走偏锋的答案，这不是现在AI的模式。AI能不能给出剑走偏锋的答案？肯定是可以的，但我们在利用方法时，它很难给出一个特别偏颇的东西。**AI在知识中立性和权威性上可能优于带有偏见的学者，且“幻觉”问题已大幅解决**。

### 提问的艺术：构建多维度上下文

再加上本来也是综合到你自己的头脑里做判断。当然现在也有个好的方法，就是三个AI一起来回答同一个问题，**ChatGPT**、**Gemini**、**Grok**、**Anthropic**，让你一起看，就更不容易偏向其中一家。这都比你过去读一本书的成本要低。

还有谁有读书的某种问题意识吗？我们来感受一下。有人说：“我看书的问题就是，可能当时写书的那个时代，或者当时那个位置，现在是感觉不到的。然后通过这本书，我想知道关于当时代人的想法，或者是他们的问题，跟我们现在的差别，或者有什么微量的理由。”这个问题非常好。我们尝试一下把这个问题转化为你阅读这本书时的关键。比如我们拿**《旧制度与大革命》**来讲，因为**托克维尔**是时代清理者，他一定有很多内容是只有他才知道的，我们读这本书可能会误解。

### 迭代优化Prompt，提升阅读效率

你可以问**ChatGPT**：“**托克维尔**写这本书的时代背景和他的思想背景是什么？”这是一个问法。但他能给你出。但如果你要把它变成一个**Prompt**，在他解读这本书时同时告诉你，我觉得你可能可以尝试这样问，因为这需要点经验。一个人有两个时代背景：一个是他所处的环境，一个是他的思想资源。因为**托克维尔**可没有看过什么**哈贝马斯**，他看的是**卢梭**，是他看的，和他同时代的。也就是说你可以问：“你是一个思想史研究者，就**《旧制度与大革命》**这本书有独特的时代背景和它心理的事件，也有独特的思想背景。请关联**托克维尔**的其他著作，了解**托克维尔**的阅读和思想背景，以及**托克维尔**时代的时代背景，来解读**《旧制度与大革命》**，并提出在我们阅读这本书的时候，有哪些不易察觉的时代背景差异可能导致对这本书的误解，以及有哪些非常独特的**托克维尔**的思想背景导致我们用今天的视角无法好好地理解。”

如果用这个方式，你拉近了**托克维尔**其他书籍，拉近了等等的东西，用这个角度来读这本书，这个**Context**很可能就会产出和你推荐读这本书完全不同的东西。你刚才的问题是好问题，但如何把它变成一个**Prompt**？你会发现我为什么要提到**托克维尔**其他著作呢？因为你当然可以让他去搜**托克维尔**的思想背景，这是一个方法，但这个方法其实被拉进来的**Context**不具体。那更具体的当然就是**托克维尔**的其他书。甚至如果我对**《旧制度与大革命》**非常关心，我把**托克维尔**其他书下载下来，一起给他，让他先去读其他书，从里面了解些东西，再来以这些书解读这本书，那**Context**不就突然变得巨大了吗？这是一个非常好的办法。这有点像在训练AI，其实你是在构建**Context**，**Context**对于AI生成内容来讲是最重要的东西。所以你如何能够帮它跳出这本书的**Context**是很关键的，当然你自己的问题也是在里面很关键的，就是你到底想知道什么。

### 读书的工程化与持续优化

我给大家推荐一个方法，可以帮助大家更好地在AI时代读书。AI有一个特点，如果你只给它一次机会，它生成的东西未必是最好的，如果你给它三四个让你选一选，就可能会好一些。一本书也一样，如果这本书足够重要，你只让AI来一次，结果未必好，所以多来几次，让它从里面选择一个比较好的，可能是一个最靠谱的方法。而且这个方法也能帮助你去对提问有更好的认识。

你未来的工作流是这样的：拿一本书和你的一个**Prompt**，让AI生成一系列问题。你再拿这个问题去**Notebook LM**生成语音摘要，来听这个语音摘要，用这种方式来读一本书。但是，你自己一本书加一个**Prompt**生成一堆问题，不要是一个，你自己写几种不同的方式。而且你写的时候，不要每次都想不一样的，就写几个一样的。比如刚才我们那个对话就可以，你把**托克维尔**拿掉，可以把它抽象成“请找这个作者的其他作品和作者的时代背景、作者的思想资源”，这可以是一个放置四海皆准的**Prompt**，哪个作者都能来。

### AI辅助阅读的未来：高效与深刻并存

比如你就特别关心中国转型，这也可以是一个放置四海皆准的问题。因为大家每天时间有限、脑力有限，如果你每对一本书都要想四个不同的问题，你就耗尽了。一是耗尽，二是不利于**Prompt**的迭代。也就是说，你最后试了很多**Prompt**，这个**Prompt**能够很稳定地生成高质量的**Context**，这个**Prompt**本身是需要优化的。它未必是一次成功。也就是说，你发现这个方向好，你下次再加一点，再加一点。你把这个**Prompt**当作一个调料来看，你这次炖红烧肉放这些，下次发现再加点八角更好。

也就是说，你写几个放置四海皆准的**Prompt**来作为生成问题的**Context**。你每次这个问题本身的扩充和优化，是你每周都能让读书效率更高的一个非常好的点。比如有这四个东西，你每次都拿这四个东西生成一堆问题，然后你就来看，你每次不得不做一个选择，这四个哪个更好？当然最懒的选择就是过去用AI方式，哪个最长哪个最好，但其实不是。你仔细看看这四个答案，你觉得哪个最好？你相信我，你越看这些，你越懂怎么问问题，这是非常重要的技能。然后你就这么看，哪个更好，然后你就拿这个去喂给那个，或者四选二，选最好的两个，喂给那个**Notebook LM**去生成。

### 持续优化Prompt，发现新视角

刚才我说这个方法还有个好处，因为你每次都是重复的一个文档、四个**Prompt**、生成四个结果、选择喂过去。如果你们听过我之前讲的**Vibe Coding**（一种通过编程自动化工作流的方法），这个东西是绝对可以很方便写成脚本的，你不用每次去操作，每次就是一本书回车，哗就出来了。那你读书效率就更高了。我现在读书就是，比如今天下午我发现有两个小时，我就一次性处理十本书，用这个方法，就是AI搬运工。处理完之后，这十本书也十个小时，然后平时就听。因为这个你就很高效地以流水线的方式处理书和读书，去了解它的内容。

这是一个比较好的、很快的方法。这个方法你会发现里面有两点：第一点是问问题，第二点是工程化。从此之后，读书变成一个流水线工程，听着很不浪漫，但这是很高效的方式。这上面可以进一步优化非常非常多。比如你知道**Notebook LM**是根据文档生成的，那么如果是一本书，你可以再贴近别的文档，上下文就更扩充了。你自己的那四个**Prompt**，或者更多的**Prompt**，它本身是你发现这个问法每次出的问题都非常棒，那我可不可以改它让它更棒？你就是说，但你会觉得怎么改呢？不用，改也是AI给你改。你把这个**Prompt**给AI，你说它的好处在哪里哪里，但我觉得它哪里哪里有所欠缺，你能不能帮我再生成一个版本？它给你改，这样你再用它。你给AI的**Prompt**，这是AI写的，这是一个最好的方式。

### AI与人的协同进化

这样你既形成了读书的方法，也形成了你读书的流水线作业方式，而且这个流水线作业方式是不断在优化扩充的。我现在对我的要求，因为我有很多大量的**Prompt**积累下来，我每周起码要对两三个**Prompt**进行优化，我要求自己必须这样。所以我的各种工作都在每周不断的优化中，效果会越来越好。如果你们听我的**观察线**节目，你们会发现这周的**观察线**节目，至少我认为，比之前都好很多，因为我改了它的**Prompt**。而且AI提了一个非常好的**Prompt**，这AI提的我从来没想到：你解读一个文章的时候，最后总结一句，这个文章是基于哪个最重要的假设？如果这个假设不成立，这个内容就不成立。当时我说这问题问真好，我怎么没想到呢？AI问的。所以以后每一个文章解读，最后都有一个“这个文章里面最关键的假设是什么什么，如果这个假设不成立，这个文章的理论就有很大的问题。”这多好的视角啊！**与AI磨合打磨问题，可发现意想不到的深刻视角**。