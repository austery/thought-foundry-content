---
area: "work-career"
category: ai-ml
companies_orgs:
- OpenAI
date: '2024-05-16'
draft: true
guest: ''
insight: ''
layout: post.njk
people:
- John Schulman
products_models:
- GPT-4
project: []
series: ''
source: https://www.youtube.com/watch?v=JclnqKZBTUU
speaker: Dwarkesh Patel
status: evergreen
summary: 本次讨论聚焦于人工智能模型训练计算资源的分配趋势，特别是从预训练转向后训练的转变。演讲者认为，后训练是提升模型性能（如GPT-4 ELO评分的显著提高）的关键，并探讨了构建AI竞争优势（护城河）的复杂性、所需专业知识以及可能被规避的途径。同时，也阐述了进行有效后训练研究所需的跨领域经验和第一性原理思考。
tags:
- ai-development
- investment
- llm
title: GPT-4的智能飞跃：OpenAI联合创始人解析后训练的重要性
---
### 训练计算的重心转移

随着训练计算资源的投入，**预训练** (pre-training) 与**后训练** (post-training: 对预训练模型进行微调以提升性能或行为对齐的过程) 的比例正在发生显著变化，未来将大幅倾向于后训练。尽管目前比例失衡，但可以认为模型生成的输出质量很高，甚至高于网络上的大部分内容。因此，让模型自主思考，而非仅仅模仿网络信息进行训练，似乎更为合理。这背后存在着基于第一性原理的论证，并且我们在后训练中发现了大量收益。因此，我们预计将继续推行这种方法论，并可能增加在此方面的计算投入。

### GPT-4性能的显著提升

当前的**GPT-4**拥有比最初发布版本高出约100个**ELO score** (ELO评分: 用于衡量AI模型相对性能的评分系统) 的评分。这是否完全归功于你所说的，即由后训练带来的改进？是的，可以说大部分的提升都来自于后训练。

### 后训练改进的多重维度

这很有趣。在改进方面存在许多不同的、独立的维度。例如，我们可以考虑数据的质量、数据的数量，以及对部署和收集新数据整个过程进行更多迭代，并改变所收集的标注类型。因此，有许多因素会累加起来，但它们共同作用，能带来相当可观的有效计算增量。

### AI领域的“护城河”

后训练在多大程度上构成了竞争优势（**moat**，护城河: 指企业难以被竞争对手模仿的竞争优势）？目前，公司通过“我们的模型有多大”等方式来区分自己。这是否会形成一个巨大的护城河？谁能解决你之前提到的所有关于这些数据的细微差别问题？我认为这构成了一种护城河，因为这是一个非常复杂的操作。它需要大量技术娴熟的人员参与，涉及大量的隐性知识和组织知识。

### 复杂的研发与门槛

因此，我认为，要创造出一个真正具备人们所需功能的模型，后训练是一个相当复杂的过程，需要付出巨大的努力。这本质上是大量**研发** (R&D: Research and Development) 的积累。所以，我认为这使得它在一定程度上成为一种护城河，因为立即复制这种能力并非易事。

### 巨头与追赶者

不过，似乎那些投入大量资源进行预训练的公司，也在投入资源进行后训练。因此，复制或启动更多此类项目似乎是可能的。

### 规避“护城河”的策略

同时，也有一些因素会削弱这种护城河效应：你可以对模型进行**蒸馏** (distill)，或者采用他人的模型来克隆其输出，还可以使用他人的模型作为裁判来进行比较。虽然顶尖公司可能不会这样做，因为这违反了服务条款，并且有损其声誉，但我预计一些小型参与者会利用这些方法来起步。

### 跨领域经验与好奇心

对于那些非常擅长进行此类研究的人来说，是什么让他们脱颖而出？我听说这非常棘手，但究竟是怎样的直觉能让你找到方法来处理数据并设置这些环境？我可以说，我在这方面积累了相当多的经验，涵盖了技术栈的各个部分，从**RL algorithms** (强化学习算法: 通过试错学习最优行为的算法)（我从研究生时期就开始研究它们）到数据收集、标注过程，再到与语言模型的互动。我只是涉猎过这些领域。

### 经验与理论的结合

我认为，那些在此类研究中表现出色的人，对整个技术栈都有一定的了解，并对其中各个部分充满好奇心。他们也会思考：你需要既进行实证研究，让实验来更新你的观点，同时也要从第一性原理出发思考，比如，假设学习是有效的，那么理想的数据类型是什么？诸如此类。