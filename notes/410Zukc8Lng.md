---
area: "tech-engineering"
category: technology
companies_orgs:
- NVIDIA
- Boston Dynamics
- 斯坦福大学
- Epic Games
- 宇树科技
- 本田
- ByteDance
- Alibaba
- 腾讯
- DeepSeek
- 豆包
date: '2025-11-05'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《硅谷101》
people:
- Sam Altman
- Jensen Huang
- Sergey Levine
products_models:
- Sora
- Sora 2
- Genie3
- ChatGPT
- Unreal Engine
project: []
series: ''
source: https://www.youtube.com/watch?v=410Zukc8Lng
speaker: 硅谷101播客
status: evergreen
summary: 随着Sora 2将文生视频推向新高度，一个更深层次的变革正在发生：从2D视频生成到实时3D数字人的演进。本期节目深入探讨了3D数字人与2D视频的核心区别，揭示了通过“AI渲染”技术大幅降低成本的关键突破。文章追溯了3D动画与机器人技术长达二十年的渊源，并展望了3D数字人如何驱动物理世界的机器人，以及它将如何定义未来的人机交互范式。这不仅是一场技术的轮回，更是一次全新的开始。
tags:
- dynamic
- human
- llm
- real
title: 从Sora 2到具身智能：3D数字人如何重塑虚拟与现实的边界
---
### 引言：Sora 2 引爆的数字人新浪潮

近期，Sora 2的发布引起了广泛关注，它能将一句话变成一段10秒的短视频，展示了强大的**文生视频**（Text-to-Video: 指通过输入文字描述直接生成视频内容的技术）能力。与此同时，完全由AI创作的好莱坞演员Tilly Norwood，诞生仅6个多月就吸引了6.5万粉丝，她会发自拍、代言品牌，却从未真实存在过。

这些现象揭示了一个趋势：数字人正在成为新的内容生产者。然而，从屏幕上生成一段2D视频，到实现一个可以稳定、实时互动的3D数字人，这中间仍存在巨大的技术壁垒。

本期嘉宾柴金祥教授，早在2000年就进入卡内基梅隆大学研究机器人。由于机器人应用落地困难，他的团队反而成为世界上最早用AI做3D动画的团队之一。在长达18年的研究中，他从机器人到好莱坞AI动画，再到今天探讨一个前沿问题：3D数字人模型能否反过来驱动机器人？这听起来像一种轮回，却也是一个新的开始。本期节目将深入探讨，此轮人工智能浪潮如何改变3D数字人和机器人领域，以及在好莱坞与游戏产业中，谁将成为这项技术的真正受益者。

### Sora 2 vs. 3D数字人：2D视频与3D交互的本质区别

Sora 2相较于Sora 1在画质和视频形态上进步巨大，其核心是文生视频能力，并且主要以人为中心。它可以让视频里的人跳舞、交流、吃东西等。然而，它仍然存在一些局限性。

首先，生成的视频时长限制在10秒内。其次，物理一致性问题依然存在。虽然许多刷屏的视频效果惊艳，但用户自己动手制作时会发现不少瑕疵，例如文字乱码或物体形态错误。更重要的是，目前用户无法精细化地控制视频中人物的动作和表情，也缺乏便捷的编辑功能来修正瑕疵。

尽管如此，Sora 2首次让人们看到了大模型驱动人物做出各种动作的潜力。那么，与Sora 2生成的2D视频相比，我们所做的3D数字人有何不同？

最大的区别在于维度。Sora 2生成的是2D视频，而3D数字人则存在于三维空间，可以放置在VR/AR环境中，像现实生活一样360度观察。3D的另一个核心优势是可控性，你可以像控制真人一样精确地驱动它的动作和表情，而这在2D的像素层面是难以实现的。

### 实时交互的三大挑战：延迟、准确性与成本

当一个数字人出现在展厅屏幕上，扮演与人交流的角色时，它必须满足几个严苛的条件。

第一是**实时性**。人机交流要求极低的延迟，通常端到端延迟需要小于1.5到2秒，而不能像生成视频那样等待几分钟。

第二是**准确性**。作为服务或销售人员，数字人的动作、表情不能有任何瑕疵。例如，不能出现手臂衔接不上，或者像文生视频中常见的手指数量错误、模型穿插等问题。这种物理上的准确性对交互体验至关重要。

第三是**成本**。将3D数字人部署在终端设备上，成本必须足够低。如果在一个价值一万人民币的屏幕上，运行一个交互20分钟就需要花费巨额的计算成本，那么这项技术将无法规模化。目前，Sora 2这类文生视频模型的推理成本非常高，难以扩展。

### AI渲染：破解3D数字人成本难题的关键

我们之所以能将成本大幅降低，核心在于我们利用AI解决了渲染和物理结算的难题。描述一个人的动作表情，只需要几百个参数，类似于控制几百块肌肉。我们的模型将文本转换成驱动语音、表情、动作和手势的3D多模态参数。

过去，将这些3D内容变成视频需要昂贵的游戏引擎和GPU进行**3D渲染**（3D Rendering: 将三维模型转换为二维图像的过程）和**物理解算**（Physics Simulation: 模拟物理定律，如重力、碰撞、布料和毛发动态的过程）。我们最大的突破在于，用AI替代了这两个环节。

我们将文本生成的多模态参数传到终端（如平板或大屏），再用AI渲染和AI解算将其变成视频。由于渲染和解算过程由AI完成，对终端算力的要求极低。我们现在甚至可以在国内几百元级别的芯片（如瑞芯微RK3566）上流畅运行。这使得我们的成本远低于传统的语音合成大模型，大约只有其几十分之一。

在交互流程上，我们通常会结合两个模型：一个类似ChatGPT的多模态输入到文本输出的大模型，负责理解与决策；另一个是我们自研的文生3D多模态大模型，负责将文本转化为包含语音、动作、表情、手势的综合表达。我们即将发布的“星云平台”，就是将这种能力开放给所有开发者，避免重复造轮子。

### 从好莱坞到游戏：AI如何颠覆传统3D内容生产

在AI时代之前，制作一个像NVIDIA发布会上黄仁勋那样的超写实数字人，成本极其高昂。通常需要一个研发团队和美术团队配合，仅制作一个高精度模型在美国的成本就在10万美元左右，后续的动画制作更是按秒计费。

传统的专业级内容生产流程非常复杂。首先，通过相机阵列扫描演员，进行**建模与绑定**（Modeling and Rigging: 创建角色的三维几何形态，并为其构建一套可控制的骨骼系统），重建其几何形态、表面纹理和肌肉结构。然后，演员需要穿上带有标记点的**运动捕捉**（Motion Capture: 记录物体或人的动作，并将其转换为数字模型的技术）服装，由周围的相机捕捉动作数据。最后，这些数据被用来驱动数字模型，再通过渲染引擎输出视频。整个过程从建模、动画到最终输出，都极为昂贵。

如今，AI正在改变这一切。然而，3D内容的AI化取决于两大要素：高质量的3D数据和强大的AI算法。影视和游戏公司拥有制作精美3D模型的美术能力，但普遍缺乏AI研发能力。反之，AI公司算法虽强，却缺少高质量的3D数据。这两个行业之间存在明显的壁垒。

我们从2018年成立之初，就为游戏、影视公司提供3D内容制作服务，通过“AI+美术”的方式积累了大量高质量数据。例如，我们目前拥有超过1000小时的高质量3D动画数据。这些数据的获取成本极高，在国内，一秒钟高质量的人脸、手势动画数据成本至少在1000元人民币左右。正是这些宝贵的数据，成为了我们训练3D多模态大模型的核心基础。

### 动画与机器人的轮回：一段跨越20年的技术渊源

我从2000年在卡内基梅隆大学机器人研究所读博时就开始研究这个方向，博士论文就是关于如何创建可交互的3D数字人以及如何用AI做动画。我们的团队可以说是世界上最早用AI做动画的，因为运动捕捉技术在当时刚刚出现，为AI训练提供了数据。

我的博士导师是Jessica Hodgins，她主要研究人形机器人和3D数字动画，而她的导师则是波士顿动力创始人Marc Raibert。这背后有一段有趣的技术传承。Jessica在读博时研究单腿人形机器人，因为双腿平衡在当时是极大的难题。她毕业后进入了图形学和动画领域，尝试用控制机器人的物理和动力学方法来驱动虚拟世界中的数字人，成为全球首个用此方法做动画的学者。

2000年，随着运动捕捉数据的出现，她开始带领我们用AI做动画。有趣的是，当AI动画技术成熟后，大家又开始思考，它是否能反过来驱动机器人（Robotics）？事实上，现在许多顶尖的机器人专家，如Pi的联合创始人Sergey Levine，在博士期间都是做动画研究的。动画和机器人这两个领域本质上是相通的，都是在驱动一个3D的“人”，一个在虚拟世界，一个在物理世界。动画研究相对简单，因为它没有硬件实体和物理限制，这使得许多研究者先从动画入手，再将成果应用于机器人。

### 从虚拟到现实：3D模型如何驱动物理机器人

我们训练的3D数字人模型完全可以用来驱动机器人。当一个3D数字人能理解对话，并生成相应的语音、动作、表情和姿态时，这套信号同样可以用来驱动一个物理机器人。机器人可以实时地做出相应的语音、动作和手势，只是目前大部分机器人没有面部肌肉，无法表现表情。

我们将这套能力提供给机器人公司后，他们可以利用这些生成的动作数据，结合**强化学习**（Reinforcement Learning: 一种机器学习方法，智能体通过与环境互动，根据获得的奖励或惩罚来学习如何做出最优决策）和仿真环境，来训练机器人的平衡与执行能力。

这里涉及两个核心概念：**运动学**（Kinematics: 研究物体运动几何特性而不考虑其受力的学科）和**动力学**（Dynamics: 研究力与物体运动之间关系的学科）。我们的模型首先解决运动学问题，即规划出“手应该如何运动去抓杯子”的姿态路径。机器人公司则需要解决动力学问题，即“需要用多大的力”来精确执行这个动作。

我们即将发布一个3D动作大模型，用户可以直接输入指令，如“往前走五步，趴在地上，然后爬起来跑”，模型就能自动生成相应的3D动作数据。这些数据可以直接用于机器人的训练，省去了昂贵且耗时的动作捕捉环节。

### 机器人研究的范式转移：从白盒控制到黑盒学习

机器人技术经历了巨大的变迁。20年前，人形机器人最难的问题是平衡和抓取。当时，工程师需要手动调整大量参数来设计控制器，让机器人能在特定平面上行走而不摔倒，这种方法缺乏泛化能力，换个环境就可能失效。

如今，研究范式发生了根本性转变，从传统的白盒控制转向了基于AI和强化学习的黑盒模型。我们不再需要精确计算每一个动作的力，而是像人学习一样，通过海量数据和奖励函数进行端到端的训练。我们看到机器人走路，但不知道模型内部的具体运作原理，这正是AI方法的特点。

尽管进步显著，但挑战依然巨大。目前，机器人只是在特定场景下解决了平面行走的问题，泛化能力仍然很弱。比如，世界上还没有任何一款人形机器人能够稳健地攀爬任意一种它没见过的楼梯。抓取物体同样困难，我们看到的很多演示都严重依赖于特定的环境设置。

对于机器人的未来，我认为长期前景光明，但这套黑盒学习的方法是否能最终收敛，解决通用场景下的各种复杂任务，还需要很长时间的探索，也许是十年。在此之前，行业可能还会经历起起落落。从商业化角度看，人形机器人在“白领”场景（如服务、陪伴）的应用，或许会比在“蓝领”场景（如工厂、物流）更快落地。