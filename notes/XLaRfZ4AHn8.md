---
area: tech-engineering
category: ai-ml
companies_orgs:
- Anthropic
- DeepMind
- OpenAI
- 80,000 Hours
date: '2025-03-25'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books:
- 《The Scaling Era》
- 《Fantastic Anachronism》
- 《Caro LBJ biographies》
people:
- Trenton Bricken
- Sholto Douglas
- Dario Amodei
- Demis Hassabis
- Scott Alexander
- Leopold Aschenbrenner
- David Reich
- Mark Zuckerberg
- Jeff Bezos
- Lyndon B. Johnson
- Robert Moses
products_models:
- AlphaZero
- Claude
- Substack
- TikTok
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=XLaRfZ4AHn8
speaker: Dwarkesh Patel
status: evergreen
summary: 本期AMA节目中，主持人**Dwarkesh Patel**与嘉宾**Trenton Bricken**和**Sholto Douglas**探讨了AI对职业生涯的影响、播客运营策略及个人成长方法。节目介绍了新书《The
  Scaling Era》，讨论了AI模型在知识联结方面的局限性，并为年轻人提供了职业建议，如成为AI领域的**Matt Levine**。此外，还分享了播客嘉宾选择、内容分发技巧以及在AGI快速发展背景下如何规划个人生活和慈善事业。节目强调了持续学习和靠近前沿的重要性。
tags:
- career
- content-creation
- growth
- knowledge-management
title: AI时代下的职业发展与播客成长策略
---

### 新书发布与AI的跨学科影响

本期节目是“你问我答”（Ask Me Anything，简称AMA）特辑，主持人**Dwarkesh Patel**邀请了朋友**Trenton Bricken**和**Sholto Douglas**一同参与。他们都是**Anthropic**的AI研究员。**Dwarkesh**还宣布他的新书《**The Scaling Era**》于今日发行。他希望听众能通过本书了解智能的本质、数十亿额外劳动力出现后的经济影响，以及如何理解超越人类总和的智能。这本书由**Stripe Press**出版，汇集了**Dwarkesh**对AI实验室CEO、研究员、经济学家和哲学家等各领域学者的采访精华。例如，读者可以读到**Dario Amodei**解释“规模化为何有效”，下一页则是**Demis Hassabis**阐述**DeepMind**关于**RL**（Reinforcement Learning: 强化学习）路线的计划，以及**AlphaZero**如何影响下一代**LLM**（Large Language Model: 大语言模型）。

**Dwarkesh**认为，AI是一个极具跨学科性质的领域，因为它与人类知识的各个领域都息息相关。书中包含了**Carl Shulman**关于“规模化假说”如何体现在灵长类大脑演化中的讨论，以及经济学家**Tyler Cowen**对爆炸性经济增长持怀疑态度的观点。这本书是各领域知识的结晶，旨在解答人类当前面临的最重要问题。嘉宾们也认同，这本书以主题和访谈交叉的方式呈现，提供了一种易于消化的方式来理解这些复杂的议题。

### 播客的幕后与AI模型的局限性

**Dwarkesh**透露，书中还收录了两篇此前未公开发布的访谈，其中一篇是与**Anthropic**联合创始人之一**Jared Kaplan**的对话，他从数学角度解释了数据流形（data manifolds）的规模化问题。另一篇是**Gwern Branwen**讨论通用智能（general intelligence）最初的进化目的。这些内容以逐页对比的方式呈现，帮助读者理解不同见解之间的关联。嘉宾们也提到，**Stripe Press**出版的书籍设计精美，附有侧边注释和图表，解释了诸如“参数”和“模型”等概念，极大地提升了可读性。**Dwarkesh**表示，他希望通过这种方式，让每期技术性访谈都能得到充分的背景补充和定义解释，让听众的父母也能理解他们的工作。

有听众**Brian Krav**提问，关于AI模型在不同主题之间建立联系的挑战，即“组合式注意力挑战”（combinatorial attention challenge），是否能通过规模化或“思考模型”来解决。**Dwarkesh**曾与**Dario Amodei**讨论过，**LLM**拥有人类所有知识，但却无法像人类一样进行跨领域联结。他举例**Donald Swann**发现镁缺乏症与偏头痛之间的联系，从而提出镁补充剂疗法并取得成功。**Scott Alexander**曾指出，人类也并非拥有“逻辑全知”（logical omniscience），语言中的词语联结也存在“组合爆炸”（combinatorial explosion）。然而，人类确实能做到这一点，而**LLM**目前还没有成功的案例。

### AI模型的记忆与泛化能力

**Sholto Douglas**认为，当前的预训练目标赋予了**LLM**灵活的通用知识，但并未赋予其进行创新性联结或研究的能力。他表示，这需要通过**RL**（强化学习）等方式进行大量训练，并让模型与世界互动，尝试进行科学发现，模拟人类在这些职位上的行为。**Trenton Bricken**补充说，模型可能不擅长存储记忆，它们的训练主要集中在预测互联网上的下一个词，并记住特定事实。而人类在学习新事物时会主动构建总结以帮助记忆，模型目前缺乏这种“记忆脚手架”（memory scaffolding）。他将**LLM**比作“白痴学者”（idiot savants），就像**Kim Peek**（一位天生没有**胼胝体**（corpus callosum: 连接大脑左右半球的神经纤维束）的学者），拥有百科全书式的记忆，但在社交等方面存在障碍。**LLM**在特定小众领域表现出色，但在其他方面却可能完全失败。

**Dwarkesh**对记忆与泛化之间的权衡很感兴趣。他提到，人类大脑的存储能力远超**Wiki**文本的五兆字节，但大脑会主动修剪记忆，以避免被细节困扰，从而提取有意义的泛化见解。他引用了**Terrence Deacon**的观点：儿童时期学习能力最强，但会完全遗忘童年记忆；成年人则处于中间状态，不记细节但能有效学习；而**LLM**则走向另一个极端，能精确记住**Wiki**文本的措辞，却无法进行显而易见的泛化。这与**Gwern Branwen**的“**优化器理论**”（optimizer theory: Gwern提出的一种关于智能体行为的理论）有异曲同工之妙。

### AGI时代下的职业发展建议

有听众**Rabid Monkey**提问，在**AGI**（Artificial General Intelligence: 通用人工智能）时代背景下，会给一个17岁刚上大学的年轻人什么职业建议。**Dwarkesh**开玩笑说可以成为播客，因为这个职业可能仍然存在。他反思自己从计算机科学转行做播客，虽然当时看起来不负责任，但现在看来却“奏效了”，尤其是在软件工程师工作可能被自动化的情况下。**Sholto**认为，未来几年个人杠杆率将大幅提升，软件工程师的工作效率每年都在倍增。他预计这种趋势将持续，从与AI模型协作到管理小型团队，再到管理一个部门或公司。他强调，**深厚的技术知识在未来四年内仍然至关重要**，因为个人将需要管理数十个甚至更多的AI团队。

**Dwarkesh**补充说，这并非“自我安慰”（cope），而是因为AI模型目前缺乏长期连贯性，这对于成功创办公司或处理复杂事务是必不可少的。他认为，在数据稀疏且需要深入了解行业背景的领域，人类仍将占据优势。**Dwarkesh**也承认职业规划的困难性，并建议年轻人“多尝试，多实践”，因为在AI时代，预测转型类型非常困难。他对此类职业建议持怀疑态度。**Sholto**则建议，**将自己置于“前沿”**（frontier），无论是计算机科学还是生物学，都能更好地发现问题。

### AI原生学习与播客成长策略

**Trenton**补充说，招聘时仍看重解决实际问题的能力，并建议采用“**AI原生**”（AI-native）的学习方式，即利用AI模型更高效地学习，并了解其能力边界。他认为，任何强调死记硬背而非思维方式的学科都值得怀疑，但如果始终使用AI工具，自然会对其优缺点有很好的把握。关于选择播客嘉宾的标准，**Dwarkesh**表示最重要的是他是否愿意花一到两周时间深入研究嘉宾的所有作品和访谈。他更看重研究的趣味性和对未来研究的帮助，而非嘉宾的影响力。他指出，他的播客最受欢迎的嘉宾是**Sarah Payne**，一位在他采访前并不出名的学者，其次是古DNA遗传学家**David Reich**，而**Satya Nadella**或**Mark Zuckerberg**等知名人物的节目反而排名靠后。

**Dwarkesh**认为，播客的第一个重大成功是**Mark Zuckerberg**那期节目带来的广告收入，让他意识到播客可以成为一门真正的生意。他开玩笑地建议年轻人“创办一个博客，成为AI界的**Matt Levine**”，因为这是一个“完全开放的利基市场”（totally empty niche）。他强调，成功的媒体产品通常由个人的愿景驱动，而非集体产物。他鼓励大家尝试，即使早期作品可能不尽如人意，但重要的是坚持下去，获得反馈并不断改进。嘉宾们也认同博客的价值，认为高质量的AI深度文章几乎总能在**Twitter**上广泛传播。**Dwarkesh**引用一位知名博主的话说，发现新博主很难，但一旦发现，一周内全世界都会知道，这表明内容传播效率很高。

### 播客的“飞轮效应”与长期目标

**Dwarkesh**认为，媒体领域的缓慢复合增长是“虚假的”。他以**Leopold Aschenbrenner**的“**情境感知**”（situational awareness）文章为例，指出如果内容足够好，几乎所有重要人物都会阅读。对他而言，播客的复合增长更多体现在他自身的进步。他强调，播客最重要的反馈循环并非观众的增长，也不是简单地重复做节目，而是**播客的质量足以让他结识像嘉宾这样的人**。通过与这些人的交流和学习，他能制作出更好的播客，进而结识更多其他领域的人，形成一个“飞轮效应”（flywheel effect）。他最近关于中国的博客文章，就为他带来了庞大的中国关系网络。

关于长期目标，**Dwarkesh**表示，**AGI**（通用人工智能）的快速发展使得长期规划变得难以明确。他引用**Peter Thiel**的观点，即“你的十年计划是什么，为什么不能在六个月内完成？”他目前计划继续发展播客和写作，因为在**AGI**快速发展的背景下，未来十年世界可能大不相同。他认为，播客的目的是成为一个“**认知工具**”（epistemic tool: 帮助理解世界、获取知识的工具），因为在AI领域，很容易犯错，因此建立对相关论点的基本理解是最高优先级。

### 个人生活与慈善：AGI时代的选择

在**AGI**快速发展的时间线面前，**Dwarkesh**也做出了一些短期个人决定。他透露，在采访**Mark Zuckerberg**后，他将所有广告收入立即投资了**英伟达**（Nvidia）。**Sholto**和**Trenton**也分享了他们的改变，**Sholto**取消了**401K**（美国退休金计划: 一种由雇主赞助的退休储蓄计划）的缴费，因为他难以想象在60岁时，世界会变得多么不同。

**Dwarkesh**还思考了如何将财富用于慈善目的，例如资助有潜力的内容创作者。他感谢**Anil Varanasi**和**Leopold Aschenbrenner**此前对他的支持，这让他得以在播客初期坚持下去。但他同时认为，很难找到“隐藏的天才”，如果设立资助项目，效果可能不佳。**Trenton**建议，可以资助有潜力的人搬到**旧金山**（San Francisco）两到三个月，让他们置身于一个能快速成长的环境中，结识更多人，获得反馈。**Dwarkesh**也承认，搬到旧金山对他发展AI播客帮助巨大。他提到**MATS项目**（MATS program: 针对AI安全研究的导师制项目）和**Anthropic Fellows Program**（Anthropic研究员项目: Anthropic公司提供的研究员项目）的成功，这些项目为研究人员提供了时间、资金和社交支持，让他们得以从事AI安全研究。

### 内容分发与团队建设

**Dwarkesh**认为，内容分发是一个被低估的环节。他指出，**YouTube Shorts**（YouTube短视频: YouTube上的短视频功能）是他播客增长最成功的渠道，贡献了至少一半的增长。他还分享了撰写**Twitter**推文的技巧：像在群聊中与朋友交流一样写作，而非正式的文本。他提到**TikTok**（抖音国际版: 短视频平台）是他尚未攻克的平台。

在团队建设方面，**Dwarkesh**表示自己非常幸运能与三到四位优秀的编辑合作，他们都非常出色且自驱。他的编辑团队成员背景多样，包括阿根廷的农民、斯里兰卡的数学系新生、**MrBeast**前编辑以及捷克的导演。他通过举办播客剪辑比赛来招募人才。他认为，视频编辑领域存在“套利机会”（arbitrage opportunity），即在其他国家可以找到愿意努力工作并不断提升技能的人才，即使薪资大幅提高，也比在本地招聘更具优势。然而，对于总经理这类职位，则需要通过人脉推荐，例如他最终聘请了**Sholto**的儿时好友**Max Herrns**。**Dwarkesh**感叹，大公司如何大规模招聘优秀人才是一个难题，因为即使拥有公众平台，顶尖人才也往往通过推荐而非公开申请获得职位。

### 新手写作建议与结语

听众**Aditya Ray**提问，新手作家如何在**Substack**（订阅制内容平台: 允许作者发布内容并向读者收费的平台）上取得成功。**Dwarkesh**提供了两个“实用技巧”（useful hacks）：一是做播客，因为可以通过采访他人来利用他们的平台，无需原创观点；二是撰写书评，因为有现成的内容可以评论，而非凭空创造独特的世界观。他指出，书评是一个“供应不足”（under-supplied）的领域，例如经济学家**Jason Furman**在**GoodReads**（社交阅读网站: 用户可以记录阅读、评价书籍、与书友交流的平台）上有大量书评，**Gwern Branwen**的书评也广受欢迎。

最后，**Dwarkesh**感谢嘉宾的参与，并再次宣传他的新书，可在**stripe.press/scaling**购买。