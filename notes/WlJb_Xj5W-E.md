---
area: "tech-engineering"
category: technology
companies_orgs:
- OpenAI
date: '2025-11-22'
draft: true
guest: ''
insight: ''
layout: post.njk
products_models:
- GPT
- Claude
- GPT-2
project: []
series: ''
source: https://www.youtube.com/watch?v=WlJb_Xj5W-E
speaker: Best Partners TV
status: evergreen
summary: OpenAI最新研究提出一种通过训练权重稀疏的Transformer模型来解决大模型黑盒困境的新思路。该方法通过限制模型将多个概念压缩到同一组件中，迫使模型形成人类可理解的、紧凑的计算电路。论文详细介绍了模型架构、优化过程和创新的修剪算法，并通过三大任务验证了电路的可解释性，并提出了“桥接方法”以解释现有稠密模型，为AI安全和对齐研究提供了全新工具。
tags:
- ai-safety
- architecture
- canada
- llm
- model
title: 揭秘大模型黑盒：OpenAI权重稀疏Transformer的可解释性研究
---
### 揭开大模型的黑盒：OpenAI的全新思路

大家好，这里是最佳拍档。当我们每天使用**GPT**、**Claude**这些大语言模型时，我们真的知道它们是如何思考的吗？我们输入一个查询，模型给出精准的回答，但是中间的决策过程却像一个完全封闭的黑盒一样，我们只能看到输入和输出，对内部的计算逻辑却一无所知。这种黑盒困境不仅让我们无法真正信任AI，更成为了AI安全和对齐研究的最大障碍之一。而今天我们要解读的这篇来自OpenAI的论文，恰恰为打破这个黑盒提供了一种全新的思路：通过训练权重稀疏的**Transformer**模型，让大模型的内部计算电路变得人类可理解。这篇论文的作者团队包含了多位OpenAI的研究员，他们的核心目标是实现大模型的机制可解释性，搞清楚模型内部的算法和计算流程。

### 大模型可解释性为何如此困难？叠加态的挑战

在深入论文的细节之前，我们需要先明白一个关键问题：为什么大模型的可解释性这么难？其实，大模型难以解释的核心原因之一，被研究者们称为**叠加态**（Superposition: 稠密模型中多个概念被压缩到同一个神经元或残留通道中表示的现象）。简单来说，**稠密模型**（Dense Model: 指大多数神经元之间都存在连接，权重非零的模型），也就是我们现在常用的大多数大模型，为了追求效率，会把多个不同的概念压缩到同一个神经元或者残留通道中进行表示。这就好比一个房间里挤满了人，每个人都在同时说话，你根本听不清任何一个人的声音，导致神经元的激活模式变得毫无规律，无法对应到具体的人类可理解概念。

之前的研究尝试过各种方法来解决这个问题，比如通过**稀疏自编码器**（Sparse Autoencoder, SAE: 一种学习稀疏表示基的神经网络）学习一个稀疏的表示基，再在这个基础上解读模型计算。但是这些方法都有一个共同的局限：它们需要先对复杂的计算进行抽象，而这些抽象本身可能会偏离模型的真实机制，最终得到的可解释电路往往掺杂了人为假设，不够纯粹。

### 核心创新：权重稀疏Transformer模型

而这篇论文提出的思路完全不同。既然稠密模型的叠加态是问题根源，那我们何不直接训练一个不叠加的模型呢？论文的核心创新就是训练一个绝大多数权重都为零的**Transformer**模型，也就是**权重稀疏模型**（Weight-Sparse Model: 大部分连接权重为零，只保留少量关键连接的模型）。在这种模型中，每个神经元只能与少数几个残留通道建立连接，这就从根本上限制了模型将多个概念压缩到同一组件中的可能，迫使模型用独立的、紧凑的电路来实现不同的任务。这种从源头设计可解释性的思路，彻底改变了之前事后解读黑盒的研究范式。

### 构建权重稀疏模型的技术细节

接下来，我们详细聊聊论文中的关键技术细节，如何构建这样一个权重稀疏模型。

#### 模型架构与稀疏性约束

首先是模型架构。作者团队基于**GPT-2**的解码器架构进行了改造。为了确保残留流中的零值具有特殊意义，他们用**RMSNorm**（Root Mean Square Normalization: 一种归一化方法，通过计算均方根来归一化激活值）替代了传统的**LayerNorm**（Layer Normalization: 一种归一化方法，对每个样本的每个层进行归一化）。这种选择不仅能让归一化权重融入**MLP**（Multi-Layer Perceptron: 多层感知机）和注意力权重中，还不会改变权重的**L0范数**（L0 Norm: 向量中非零元素的数量），也就是非零参数的数量。这样一来，模型的嵌入层和非嵌入层是解耦的。部分模型还引入了**attention sinks**（注意力槽: 一种每个注意力头可学习的分母偏置），能让注意力电路更加清晰，同时不会显著影响模型的性能。

在稀疏性约束上，模型实现了**双重稀疏**（Dual Sparsity: 同时对模型的权重和激活值进行稀疏化处理），分别是权重稀疏和激活稀疏。权重方面，最极端的模型每1000个权重中只有1个非零值；激活方面，通过在模型各个节点位置插入**AbsTopK激活函数**（AbsTopK Activation Function: 一种激活函数，保留绝对值最大的K个激活值，其余置零），确保每个位置只有四分之一的激活值非零。这里的**AbsTopK函数**会保留绝对值最大的k个激活值，将其余置零。这种设计能进一步强化模型的稀疏表示，让每个节点的功能更加明确。

#### 优化过程的精妙设计

模型的优化过程同样充满了巧思。作者使用了**AdamW优化器**（AdamW Optimizer: 一种带有权重衰减的Adam优化器）。核心挑战是如何在训练中严格执行L0权重稀疏约束。他们的解决方案是，在每个训练步骤的**AdamW**更新后，将每个权重矩阵中除了最大幅值之外的所有元素置零，确保每个矩阵的非零元素比例一致。

为了让模型适应稀疏性，他们还采用了**L0退火策略**（L0 Annealing Strategy: 在训练初期逐渐增加L0稀疏约束的强度，让模型适应稀疏性）。在训练的前50%，模型从完全稠密逐渐过渡到目标稀疏度。学习率调度则采用了**鲨鱼鳍模式**（Sharkfin Pattern: 一种学习率调度策略，学习率先升高后降低，形似鲨鱼鳍），包含1%的热身阶段，并且随着L0范数的减小适当增大学习率，因为稀疏度越高的模型就需要更大的学习率才能稳定训练。此外，**梯度裁剪**（Gradient Clipping: 限制梯度的大小，防止梯度爆炸）也就是将梯度的均方根限制为1，被证明是确保训练稳定性的一个关键步骤，没有梯度裁剪的模型会出现严重的训练震荡。

### 提取可解释电路：全新的修剪算法

训练好权重稀疏模型后，下一步就是提取每个任务对应的可解释电路。这就需要论文提出的全新**修剪算法**（Pruning Algorithm: 一种用于减小模型大小和复杂性的算法，通过移除不重要的连接或神经元）。很多人可能会问，传统的模型修剪不也是去掉不重要的参数吗？但是传统修剪有两个致命问题：一是修剪的单位太粗糙，比如整个注意力头；二是修剪后的电路依然庞大，无法直接解释。而这篇论文的修剪算法实现了颗粒度最细的电路提取。

首先，作者对节点和电路给出了精准定义：节点包括单个神经元、注意力通道、残留通道的读取或写入操作，而电路则是由非零权重连接起来的节点集合。这种定义让修剪能够精确到模型的最小计算单元。

修剪的目标是找到完成特定任务所需的最小电路。具体过程是通过训练一组掩码来控制每个节点的启用或禁用。掩码参数被钳位在[-1,1]之间，通过**Heaviside阶跃函数**转换为布尔值，决定节点是否被纳入电路。为了让掩码训练可微分，作者使用了**sigmoid替代梯度**来近似阶跃函数的梯度。损失函数则是任务交叉熵和电路大小的线性组合，这样既可以保证电路能完成任务，又能最小化电路规模。训练完成后，还需要通过**二分法**（Bisection Method: 一种数值方法，通过不断缩小搜索区间来逼近目标值）确定刚好达到目标损失的电路大小，并且对最终的**logits**（Logits: 模型输出层未经归一化的原始预测分数）进行缩放和平移校准。为了优化修剪的超参数，作者还使用了**CARBS超参数搜索框架**（CARBS Hyperparameter Search Framework: 一种用于优化模型超参数的自动化框架）。每个模型和任务组合都会经过32轮迭代搜索，确保找到最优的修剪方案。

与传统的基于**归因修剪**（Attribution-based Pruning: 基于模型中各部分对输出贡献的评估来移除不重要参数的方法）相比，这种学习式修剪的优势非常明显：在相同的任务损失下，学习式修剪找到的电路大小要小得多。论文中给出的数据显示，在多个任务上，学习式修剪的电路边缘数量比归因修剪要少一个数量级，这为电路的人工解读奠定了基础。

### 三大任务的定性分析：验证电路可解释性

接下来就是这篇论文最精彩的部分：通过三大任务的定性分析，验证稀疏模型电路的可解释性。这三个任务分别是**字符串闭合**、**嵌套深度计数**和**变量类型跟踪**，覆盖了从简单到复杂的不同计算场景。我们逐一来看。

#### 任务一：字符串闭合

第一个任务是**字符串闭合**（String Closure: 根据字符串开头的引号类型预测对应的闭合引号）。任务目标很简单：根据字符串开头的引号类型，比如单引号或者双引号，来预测对应的闭合引号。作者发现，模型完成这个任务的电路只包含12个节点和9条边，完全可以被人类完整理解。

具体来说，这个电路分为两个步骤：第一步是在最早期的**MLP**层（0.mlp），模型将输入的引号标记嵌入转换为两个关键通道，分别是引号检测器（channel 985）和引号类型分类器（channel 460）。其中，引号检测器对单引号和双引号的激活都是正向的，作用是识别出引号的存在；而引号类型分类器对双引号激活正向、对单引号激活负向，负责区分引号类型。第二步是在第10层的注意力头（10.attn.head82），这个注意力头用引号检测器作为键（channel 1），用引号类型分类器作为值（channel 0），而最后一个标记的查询是恒定正值。因此注意力头会通过关注开头的引号，复制对应的类型信息，最终预测出正确的闭合引号。

更令人惊喜的是，这个电路中的节点在整个预训练分布上都具有较好的单义性。比如引号类型分类器通道，在预训练数据中，只要是双引号字符串，激活值就为正，单引号字符串则为负，在非字符串区域则接近零。这意味着模型的节点确实学到了人类可理解的自然概念，而不是任务特定的虚假特征。

#### 任务二：嵌套深度计数

第二个任务是**嵌套深度计数**（Bracket Counting: 根据列表的嵌套层数预测闭合括号类型），难度比字符串闭合更高，需要模型根据列表的嵌套层数，预测用一个右括号（]）还是两个右括号（]]）闭合。作者提取的最小电路包含7个节点和4条边，计算逻辑可以分为三个步骤：

首先是嵌入阶段，左括号（[）的标记嵌入会写入三个残留通道，分别是759、826和1711。这些通道成为括号检测器，专门响应左括号标记。

接下来是计数阶段，第2层的一个注意力头head 125将这些括号检测器的激活值求和，得到一个开放括号检测器（head 125 channel 12）。由于这个注意力头的查询几乎为零、键在序列中恒定，所以**softmax**注意力操作就相当于对上下文所有左括号的激活值求平均，然后将结果写入残留通道1249。这个通道的激活幅值就编码了列表深度。

最后是阈值阶段，第4层的另一个注意力头head 80利用**attention sinks**，将列表深度作为查询通道激活（channel 4）。当查询与键的乘积大于**attention sinks**时，说明是嵌套列表，注意力头会输出正向激活到残留通道1079，最终预测两个右括号]]，否则预测一个右括号]。

这个电路的美妙之处在于，我们可以基于对它的理解，成功设计出对抗样本。比如，在列表前加入大量不匹配的左括号作为干扰项，模型会因为平均激活值被干扰而误判嵌套深度；或者将列表做得非常长，由于激活值是上下文的平均值，会随着上下文长度增加而稀释，模型会错误地将嵌套列表判断为扁平列表。这些对抗样本的成功，恰恰证明了我们对电路的解读是正确的，模型确实是按照我们发现的逻辑在进行计算。

#### 任务三：变量类型跟踪

第三个任务是**变量类型跟踪**（Variable Type Tracking: 跟踪变量类型并预测后续操作），要求模型跟踪变量current的类型是集合set()还是字符串""，并且预测后续应该使用add方法，还是+=运算符。这个任务的电路相对复杂一些，采用了两跳算法，涉及两个注意力头的协作。

首先，第4层的注意力头（head 73）会将变量名current的嵌入复制到set()或者字符串""标记中。然后，当模型需要在序列末尾回忆变量的类型时，第6层的注意力头（head 26）会以current的嵌入作为查询和键，将之前存储在set()或字符串""标记中的类型信息复制到最终的标记位置，从而选择正确的运算符。

这个电路虽然包含的查询、键通道和值通道更多，但是每个通道的功能依然清晰，计算流程符合人类的逻辑推理方式。

通过这三个任务的分析，我们可以看到权重稀疏模型的核心优势：它的电路是紧凑的、模块化的，节点对应自然概念，连接逻辑直观易懂。而且这些电路是完成任务的必要且充分条件。如果我们将电路中的节点进行**均值消融**（Mean Ablation: 将模型中特定节点的激活值固定为预训练分布的平均激活值），那么模型的任务性能会急剧下降；而消融电路之外的节点，任务性能几乎不受影响。这说明我们找到的确实是模型完成任务的核心计算路径。

### 桥接方法：解释现有稠密模型

除了直接训练稀疏模型，论文还提出了一种**桥接方法**（Bridging Method: 一种将稀疏模型与稠密模型连接起来的方法，使稀疏模型能够解释稠密模型的行为），让稀疏模型能够解释已经训练好的稠密模型。这一点非常重要，因为现有的稠密模型在性能上远超稀疏模型，而且训练成本极低，我们不可能为了可解释性而放弃所有现有的稠密模型。

桥接方法的核心思路是，在稠密模型和稀疏模型的每个子层之间，训练一组**编码器**（Encoder: 将输入数据转换为另一种表示形式的神经网络）和**解码器**（Decoder: 将编码器输出的表示形式转换回原始数据或目标输出的神经网络）。编码器将稠密模型的激活映射到稀疏模型的激活空间，解码器则反之。

为了让桥接后的稀疏模型与稠密模型的计算保持一致，作者设计了三种损失函数：首先是**归一化MSE损失**（Normalized MSE Loss: 一种标准化后的均方误差损失函数），确保编码器和解码器的映射精度；其次是**KL散度损失**（KL Divergence Loss: 一种衡量两个概率分布之间差异的损失函数）（d→s方向），训练稀疏模型能够接受稠密模型的激活，并且输出与稠密模型一致的结果；第三是**KL散度损失**（s→d方向），训练稠密模型能够接受稀疏模型的激活，并保持输出一致。

通过这种方式，稀疏模型就成为了稠密模型的可解释替身。我们可以在稀疏模型上找到任务对应的电路，然后通过桥接将对稀疏模型的干预映射到稠密模型上，从而验证电路的一致性。

论文中给出了两个非常有说服力的实验：第一个实验针对字符串闭合任务，在4层稠密模型和对应的桥接稀疏模型上，当我们在稀疏模型的引号类型分类器通道施加干预，让它的激活值从双引号模式转向单引号模式的时候，通过桥接映射到稠密模型后，稠密模型输出单引号的概率会显著上升。第二个实验针对**while return true**任务，模型需要判断行尾应该输出冒号还是换行。当我们在稀疏模型的对应通道施加干预，让它的激活值从**return true**模式转向**while true**模式的时候，稠密模型输出冒号的概率也会明显增加。这两个实验证明，稀疏模型的电路不仅自身可解释，还能反映稠密模型的内部计算机制，为解释现有大模型提供了全新的途径。

### 局限性与未来方向

当然，任何研究都有一定的局限性，这篇论文也不例外。

首先是训练和部署的效率问题。权重稀疏模型的非零参数是无结构的，这与现代**GPU**（Graphics Processing Unit: 图形处理器）的张量核心优化不兼容，导致它的训练和推理效率比稠密模型低100到1000倍，而且训练过程中会出现大量的死亡神经元，进一步降低效率。

其次是多义特征的问题。虽然稀疏模型的节点比稠密模型更单义，但是对于复杂任务，概念依然会在少数几个节点上轻微叠加，完全的单义性还没有实现。

第三是特征的非二值化。很多节点的激活幅值包含重要信息，比如嵌套深度计数中的平均激活值。这意味着我们不仅要解释节点是否激活，还要解释激活的强度，增加了解读难度。此外，论文中使用的**均值消融**，虽然能够验证电路的必要性和充分性，但是与更严格的**causal scrubbing**（因果擦洗: 一种更严格的忠实性验证方法，通过干预模型内部表示来测试其因果关系）相比，在忠实性验证上还有差距。

论文作者也提出了未来的研究方向：

第一个方向是训练可解释模型的**有机体**（Organism: 在此指具有特定行为和可解释机制的AI模型），将稀疏模型的规模扩展到**GPT-3**级别，探索不同规模模型中是否存在通用的**计算基序**（Computational Motifs: 指在不同计算任务或模型中重复出现的、具有特定功能的计算模式或结构），如果存在，我们就可以通过研究这些基序来指导前沿大模型的可解释性研究。

第二个方向是针对特定任务训练稀疏桥接模型，比如欺骗、拒绝、目标寻求等等与AI安全密切相关的任务。虽然无法对前沿模型进行全面的**逆向工程**（Reverse Engineering: 对现有系统进行分析以理解其设计和工作原理的过程），但是可以为AI安全提供有价值的工具。

第三个方向是结合**自动化可解释性**（Automated Interpretability: 自动分析和理解AI模型内部工作机制的方法），稀疏电路提供了一种更简单的计算表达语言，可能成为自动化解读大模型的关键**原语**（Primitives: 指最基本、不可再分解的组成单元），突破当前自动化可解释性的瓶颈。

总结一下，这篇论文提出了一种可解释性优先的大模型训练范式，通过权重稀疏约束，迫使模型使用紧凑、模块化的电路完成任务。这些电路中的节点对应人类可理解的自然概念，连接逻辑直观易懂。同时，桥接方法让稀疏模型能够解释现有稠密模型，解决了可解释性与模型性能之间的矛盾。虽然这种方法目前存在训练效率低等局限性，但是它为大模型可解释性研究打开了一扇全新的大门，让我们看到了完全理解大模型内部计算机制的可能性。

好了，感谢大家收看本期视频，我们下期再见。