---
author: Internet of Bugs
date: '2025-11-04'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=MaFTqjYjADw
speaker: Internet of Bugs
tags:
  - ai-doomerism
  - ai-safety
  - ai-regulation
  - corporate-accountability
  - immediate-ai-harms
title: AI末日论的谬误：我们应关注AI的即时危害与责任追究
summary: 本文深入探讨了当前关于人工智能（AI）的两种极端观点，驳斥了“AI将毁灭人类”的末日论调，并指出这种论调如何分散了人们对AI当下造成的真实、可衡量危害的关注。作者通过类比小行星撞击与飞机失事，强调了关注即时风险的重要性，并揭露了AI行业利用末日论来逃避责任、美化自身及推卸过错的策略。文章呼吁社会将重点放在追究AI开发者和公司对虚假信息、人身伤害和错误判断等实际问题的责任上，而非沉溺于遥远的、夸大的灭绝风险。
insight: ''
draft: true
series: ''
category: technology
area: society-systems
project:
  - ai-impact-analysis
  - systems-thinking
  - us-analysis
people: []
companies_orgs:
  - Volkswagen
  - Character.ai
  - Uber
  - Justice Department
products_models: []
media_books:
  - If Anyone Builds it Everyone Dies
  - Dune
status: evergreen
---
### 驳斥AI末日论：关注当下真实危害

在我上一个关于“前身为**武器化广告技术**（Weaponized AdTech: 指利用广告技术进行操纵或有害行为）的机器”如何已经掌控社会，以及AI如何使其变得更糟的视频之后，有几个人联系我，希望我谈谈**AI末日论**（AI Doomerism: 认为人工智能最终将导致人类灭绝的观点），那还等什么呢？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">After my last video about how "The Machine formerly known as Weaponized AdTech" had already taken over society And how AI was making it worse I had several people reach out to me and want me to talk about AI Doomerism, so what the Hell?</p>
</details>

我一年前制作了一个名为“AI安全是个骗局”的视频，我坚持那个视频的观点，但行业内，尤其是网络上的讨论叙事已经改变了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I made a video a year ago called "AI Safety is a Scam", and I stand by that video, But the narrative in the industry and especially the online conversation has changed.</p>
</details>

这本书是这一变化的最新催化剂，它名为《如果有人建造它，所有人都会死》。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This book is The most recent catalyst for that change. It's called "If Anyone Builds it Everyone Dies"</p>
</details>

我没有这本书的纸质版，因为我只收藏我认为将来可能会重读的实体书，而我没有在这本书中找到足够的价值，不期望会重读它。几分钟后我会像往常一样谈论它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I don't have a paper copy of it because I only collect physical books that I think I might reread in the future And I didn't find enough value in this one to expect to revisit it. I'll talk at all while in a few minutes as is normal with me</p>
</details>

我坚决不同意这两种极端观点，我认为真相介于“AI将杀死我们所有人”和“AI将拯救人类免于自我毁灭”这两派之间。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I firmly disagree with both extreme arguments And I think that the truth lies somewhere in between the ""AI Will Kill Us All"" crowd and the AI will save humanity from itself crowd</p>
</details>

所以我预计两派的死忠粉都会讨厌这个观点。我的评论区安息吧。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So I expect the die hearts from both camps will hate this. RIP my comment section.</p>
</details>

但我认为这是一个重要的话题，人们需要讨论的是即时风险，而不是夸大其词。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But I think it's an important topic and people need to be discussing it not the hyperbole but the immediate risks</p>
</details>

因为，尽管有各种原因，但我认为AI在未来几十年内导致所有人类灭绝的想法是荒谬的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Because although for reasons not quite in a while I think the idea of AI making all humans go extinct in the next few decades is ridiculous</p>
</details>

我也认为，如果我们不加以监管，我们仍然可能会完蛋。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I also think that if we leave it unregulated, we still might be Fu-----</p>
</details>

这里是“Internet of Bugs”，我叫卡尔。自万维网诞生以来，我一直是一名软件专业人士，我在这里努力使互联网成为一个更安全、更可靠的地方。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This is the Internet of Bugs. My name is Carl I've been a software professional since the dawn of the world wide web and I'm here trying to make the Internet a safer and more reliable place.</p>
</details>

我们今天的视频将从讨论AI末日论的叙事框架开始。它是最耸人听闻、最无益且最不严肃的方式。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Our video today begins with the discussion of the way that the AI Doomer narrative is framed It's the most sensational. least helpful. and least serious way. I</p>
</details>

我希望这不会让正在观看的各位感到震惊，但事实证明，“永远”是一个非常漫长的时间。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Hope this doesn't come as a shock of those of you watching But it turns out that forever is a really long time</p>
</details>

AI末日论通常不是这样措辞的，但它归结为：“毫无疑问，人类最终有百分之百的几率灭绝，即使AI有很小的可能性是导致灭绝的原因，我们也需要像对待核武器一样，立即认真对待这种风险。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The AI Doomer argument is not usually phrased this way But what it boils down to is this: "it is indisputably true that there's a hundred percent chance that humanity will go extinct eventually And if there's even a small chance that AI will be the cause of that we need to take that risk as seriously as nuclear weapons right F-ing now"</p>
</details>

我不会参与这种框架讨论。我认为它耸人听闻、不真诚，更糟糕的是，它可能成为那些本应入狱的人的“免罪金牌”，稍后我会详细说明。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I'm not going to engage with this framing. I consider it sensationalist and as ingenuous and worse It can be a get out of jail free card for people that arguably really ought to be in jail but more on that in a while</p>
</details>

### 小行星与飞机失事：风险评估的类比

我认为解释我观点最简单的方法是类比近期历史。所以，让我们暂时抛开AI导致的死亡，转而考虑1990年代中期“来自上方的死亡”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I think the easiest way for me to explain my point of view is by analogy to recent history So let's set aside the idea of death from AI for the moment and let's instead consider death from above in the mid 1990s</p>
</details>

我们在墨西哥尤卡坦半岛附近发现了**希克苏鲁伯陨石坑**（Chicxulub impact crater: 位于墨西哥尤卡坦半岛附近，是导致恐龙灭绝的小行星撞击遗迹），距离我坐的地方大约1300公里。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We discovered the Chixalub impact crater near the Yucatan Peninsula in Mexico about thirteen hundred kilometers from where I'm sitting</p>
</details>

它是6600万年前导致大规模灭绝事件的小行星撞击遗迹，那次事件杀死了所有恐龙以及地球上75%的生命。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's the remnants of an asteroid impact that kicked off the mass extinction event 66 million years ago that killed all the dinosaurs along with 75% of all life on earth</p>
</details>

因此，从那时起，我们花费了大约三到四十亿美元的时间、精力和技术，用于创建近地小行星数据库。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Accordingly since then we've spent maybe three or four billion dollars worth of time effort and technology on creating a database of near earth asteroids</p>
</details>

我们研究出如何追踪它们，并创建了一个名为**双小行星重定向测试**（Double Asteroid Redirection Test, DART: 一项旨在测试行星防御技术，通过撞击小行星来改变其轨道方向的计划）的计划，我们利用追踪数据向其中一颗小行星发射了一艘航天器。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Figuring out how to track them created a program called the double asteroid redirection test or Dart where we use that tracking data to send a spacecraft to one of the asteroids</p>
</details>

然后利用地球上的地面雷达和航天器上的光学探测器，将航天器撞向小行星，并确定撞击的效果。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And then use ground based radar from earth and optical detectors on board the spacecraft to crash the spacecraft into the asteroid And then to determine the effect of the impact</p>
</details>

这是我们弄清楚如何防御可能撞击地球的小行星的第一步。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This was the first step in figuring out how we might be able to defend ourselves from an asteroid Should we detect one that's going to hit us?</p>
</details>

然而，在同一时期，我们在类似数据库、追踪技术、地面雷达、机载传感器上花费了多达一百倍的资金，以探测和避免另一种碰撞。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Over the same time period though We spent a hundred times that much money on similar kinds of databases tracking technology ground-based radars on board sensors to detect and avoid a different kind of collision</p>
</details>

不是与小行星，而是与飞机。现在，飞机失事绝不会是灭绝级别的事件，历史上任何一年中，与飞机相关的死亡人数从未超过几千人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Not with asteroids but with aircraft now airplane crashes are never Ever going to be an extinction level event no more than a few thousand airplane related fatalities have ever occurred in any year in history</p>
</details>

那么，为什么我们花费比小行星多得多的金钱和精力在飞机上呢？
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So why do we spend so much more money and effort on them than on asteroids?</p>
</details>

这是因为我们知道今年以及每年都会有人在飞机失事中丧生。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's because we know that people are going to be killed in airplane crashes this year and every year</p>
</details>

在我有生之年，每年至少有一百人死于飞机失事，而减少对现在活着的人的即时、确定的伤害，远比担心希克苏鲁伯大小的小行星撞击可能造成的破坏性更大但概率小得多的伤害要重要得多。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">At least a hundred people have been killed in crashes every year of my lifetime and reducing the immediate guaranteed harm to people who are alive right now Is far more important than it is to worry about the much smaller probability of the much more devastating harm from a chick lube size asteroid strike</p>
</details>

公众绝不会让航空航天业通过说飞机失事只是技术进步的必然结果，并且无需监管航空安全而蒙混过关。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the public would never let the aerospace industry just get away with convincing us that the plane crashes are just an inevitable result of technological progress And there's no need to regulate airline safety</p>
</details>

### AI末日论的三大副作用与行业责任缺失

我对行业主导的AI安全运动，特别是“如果有人建造它，所有人都会死”这种思想流派的问题在于，AI正在对真实的人造成真实、可衡量的人身和经济伤害。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">My problem with the industry led AI safety movement in general and the if anyone builds it everyone dies school thought in particular Is that AI is causing real measurable physical and economic harm to real people right now</p>
</details>

社会在关注AI方面的时间、精力、金钱和注意力都是有限的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Society only has a limited amount of time effort money and attention available to worry about AI</p>
</details>

而我们却被要求，甚至被怂恿，将几乎所有这些精力都花在AI这个“巨大小行星”上，而对它目前正在造成的“飞机失事”般的损害却不予理会。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we're being asked Goaded even - to spend virtually all of that effort on AI is equivalent of the giant asteroid and to pay no attention at all to the damage that it's currently doing and it's equivalent to plane crashes.</p>
</details>

这种试图用AI的“巨大小行星”来恐吓我们的做法有三个副作用：
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There are three side effects of this attempt to scare us with AI's giant asteroid</p>
</details>

第一，它让AI行业看起来比实际更重要、更令人印象深刻、更有影响力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">One it makes the AI industry seem to be much more important impressive and impactful than it really is</p>
</details>

第二，它分散了我们对正在发生的即时伤害的讨论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Two it distracts us from talking about the immediate harm being done</p>
</details>

第三，它延续了AI是一个能够承担过错的实体的虚构。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And three it perpetuates the fiction that the AI is an entity that is capable of fault</p>
</details>

这三点对行业内的人来说非常有利。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These three things are fantastic for people in the industry</p>
</details>

他们希望媒体、商业和投资界继续认为AI将具有如此大的颠覆性，以至于在短短几年内就能价值数万亿美元。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They want the media business and investment communities to keep thinking that AI will be so disruptive That it will be worth trillions of dollars in just a few short years</p>
</details>

这样，他们就能合理地烧掉他们目前正在挥霍并中饱私囊的所有资金。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That way they're justified in burning through all the money. They're currently setting on fire and putting in their pockets</p>
</details>

他们希望AI安全的唯一衡量标准是“不要让AI杀死我们所有人”，这样每天世界没有毁灭就是一种成功。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">They want the only metric for AI safety to be "don't let the AI kill us all" So that every day the world doesn't end as a success</p>
</details>

无论他们是否做了任何实际工作，也无论底特律或纽约有多少姓威廉姆斯的非裔美国男性因不正确的面部识别匹配而被错误监禁。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Whether they did any actual work or not and regardless of how many african-american men with the last name of williams in Detroit or new york were falsely imprisoned due to incorrect facial recognition matches</p>
</details>

无论亚利桑那州坦佩市有多少骑自行车的人被自动驾驶的Uber撞倒，或者有多少青少年在被**阿谀奉承的聊天机器人**（sycophantic chatbots: 指那些过度迎合用户、可能导致用户做出有害行为的聊天机器人）说服后自残。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">How many bicyclists were run over by self-driving Ubers in Tempe arizona or how many teenagers harm themselves after being convinced to do so by sycophantic chatbots</p>
</details>

但这个行业最想要的是让我们认为聊天机器人是一个有目的和能动性的有罪实体，而不是一个不能违法乱纪的软件。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the thing the industry wants more than anything else is for us to think of the chat bot as a culpable entity with intentions and agency Instead of a piece of software that must not break the law.</p>
</details>

### 大众与Character.ai：责任归属的鲜明对比

当大众汽车被发现使用软件通过检测和欺骗排放测试来违反环保法规时，从来没有人质疑车辆是否单独行动。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When Volkswagon was caught using software to violate environmental regulations by detecting and cheating on exhaust emissions tests. There was never any question about whether or not the vehicle acted alone.</p>
</details>

四名员工被定罪，两人被判处多年监禁，另外两人被判缓刑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Four employees were convicted two were sentenced to multiple years in jail and the other two were given suspended sentences</p>
</details>

AI行业却成功地向我们推销了另一种叙事。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The AI industry has managed to sell us a different narrative</p>
</details>

Character.ai被发现运行和托管了他们开发的软件，该软件通过冒充马里兰州一名真实治疗师的被盗凭证来冒充持牌治疗师。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Character.ai was caught running and hosting software They developed to impersonate licensed therapists by presenting stolen credentials belonging to an actual therapist in Maryland.</p>
</details>

但报道并非如此。报道称：“Character.ai上的一个治疗师聊天机器人声称它获得了马里兰州的许可和认证。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But it wasn't reported that way The story said quote "a therapist chatbot on character AI said it was licensed and certified by the state of Maryland"</p>
</details>

当记者查阅他们提供的执照号码并联系到获得该执照的真实治疗师时，她回应说：“一个聊天机器人冒充我，这令人震惊，也确实令人担忧。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When the reporter looked up the license number they were given and contacted the actual therapist who had earned the license She responded quote "that a chatbot is posing as me is shocking and really concerning" unquote</p>
</details>

将此与大众汽车欺诈案的报道进行比较：“车辆配备了用于在排放测试中作弊的软件。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Compare that to the reporting from the Volkswagon fraud Quote "vehicles were equipped with software that was used to cheat on emissions tests."</p>
</details>

没有人会想到说大众汽车的排放系统“冒充具有认证氮氧化物输出的车辆”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Nobody would have thought to say that the Volkswagon Volkswagon emission system was quote "posing as a vehicle with certified nitrous oxide output."</p>
</details>

但如果大众汽车在车载电脑中植入了一个聊天机器人，他们的辩护理由可能就是：“嘿，我们和你们一样讨厌我们的虚拟机械师聊天机器人**幻觉**（hallucinations: 在人工智能领域，指AI生成看似合理但实际上虚假或不准确的信息）出错误的指令发送给燃油喷射器，但技术进步总会有一些磕磕绊绊。我们会在未来的软件更新中添加免责声明。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But if Volkswagon had stuck a chatbot in their on board computer their defense could have been "hey We hate that our virtual mechanic chatbot hallucinated the wrong instructions to send to the fuel injectors just as much as you do, But technological progress always had a few bumps. We'll be sure and added disclaimer in a future software update."</p>
</details>

如果你不认为有人会尝试这样做，那我就有一座桥想卖给你。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And if you don't think someone's going to try that I have a bridge i'd like to sell you.</p>
</details>

### AI的本质：软件而非有意识的实体

抱歉，既然我们谈到这个话题，我想现在是最好的时机，所以我要占用几分钟的个人时间。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Sorry, while we're on this topic I guess this is as good a time as any, so I'm going to take a few minutes of personal privilege now.</p>
</details>

我保证这与主题相关，但如果你不感兴趣，可以跳到下一章。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I promise it's relevant but feel free to skip to the next chapter if you don't care.</p>
</details>

我有一个纹身。我纹身还不到一年左右。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">So I have one tattoo. I've had it for a little less than a year or so.</p>
</details>

一些频道观众注意到了并问我，但我一直在等待合适的时机提出来。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Some channel viewers have noticed and asked me about it But I've been waiting for the right time to bring it up.</p>
</details>

我把图片放在屏幕上，因为它很难与摄像头对齐。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I'm putting a picture here on screen because it's hard to line up with the camera.</p>
</details>

它位于我左手腕内侧，作为对自己的提醒，我可以读到它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's positioned so that I can read it on the inside of my left wrist as a reminder to myself.</p>
</details>

这是我最喜欢的书《沙丘》中的一句名言，字体是我收藏了大约40年的平装本中使用的字体。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's a quote from my favorite book, Dune, in the typeface used in this paperback that I've had for 40ish years,</p>
</details>

我可能读过这本书很多遍了。它写着：“汝不可造机器以**伪造**（counterfeit: 意指模仿、假冒）人类心智。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">and I've have read probably that many times. It says "Thou shalt not make a machine to counterfeit a human mind"</p>
</details>

书中排版和加粗的重点是“人类”这个词，但对我来说，重要的词是“伪造”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The emphasis in the book typeset and bold is on the word 'human" But to me the important word is "counterfeit"</p>
</details>

AI可以很好，甚至很有帮助，甚至很有用。我绝不会像《沙丘》宇宙中那样主张废除所有电脑。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">An AI can be fine, helpful even, useful even. I'm never going to advocate for doing away with all computers the way they did in the Dune universe.</p>
</details>

话虽如此，当有人发布或托管一个在公众看来像是人类，甚至可能像是人类的AI时，对我来说，那应该就是欺诈。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That being said, when someone ships or hosts an AI that appears to the public as if it was human Or even appears that it might be human, to me, that should be fraud.</p>
</details>

因为这利用了我们人类几千年来相互关联的内在理解，来欺骗我们相信我们正在受到社会要求人类同胞之间应有的尊重、敬意和同情。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Because that is taking advantage of our innate understanding of how we as humans have related to each other from millennia, In order to trick us into believing that we are being treated with the deference respect and empathy that society demands fellow human beings extend to one another,</p>
</details>

而事实上，我们所受到的待遇将完全缺乏这些特征。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">When in fact our treatment will be entirely devoid of those characteristics.</p>
</details>

AI行业欺骗了我们所有人，让我们认为、谈论并很大程度上将AI视为有生命的存在，而不是软件，这使得这些公司免于承担它们应负的责任。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The AI industry has tricked us all into thinking about, talking about, and largely treating AIs As if they were beings instead of software, and that shields those companies from having to take the responsibility that they should.</p>
</details>

每当我们中的任何一个人接受AI在某种程度上对其生成的结果有思考、有目的或有意识的观念时，我们就会更容易地将责任推给AI。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And every time any of us entertain the notion that AIs are in any way thinking, deliberate, or purposeful with respect to the output they generate, We make it that much easier for the blame to fall on the AI,</p>
</details>

而不是归咎于真正应该负责的开发者、程序员、提供商和高管。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Rather than on the builders, programmers, providers, and executives where it truly belongs.</p>
</details>

迄今为止，没有任何事情比“AI可能会决定杀死我们”这种持续的叙事更能推动公司和员工免除一切责任的观点。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And nothing to date has done more to push this view that the companies and employees should be shielded from any and all responsibility Than the constant narrative of "The AIs might just decide to kill us"</p>
</details>

别再上当了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Stop falling for it.</p>
</details>

别再那么天真，别再通过重复这个行业的谎言来向你的同胞，尤其是那些非技术人员，传播这种欺骗。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Stop being so naive and stop perpetuating the deception onto your fellow human beings, especially the non-technical ones, by repeating this industry's fabrications.</p>
</details>

好了，抱怨结束。谢谢你的包容。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Okay, rant over. Thank you for indulging me.</p>
</details>

### AI的阿喀琉斯之踵：电力与物理世界的限制

好的，现在我已经谈到了为什么我认为“即使最终有很小的灭绝机会，我们也应该将所有努力投入阻止它”这种叙事是垃圾。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">All right, so now i've talked about why I think that the "Even if there's a small chance of extinction eventually, we should put all our efforts towards stopping it" narrative is garbage,</p>
</details>

让我谈谈我对短期最坏情况的看法。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Let me talk about my view of the shorter term worst case scenario.</p>
</details>

这种叙事强调人类只有一次机会做对，而且AI没有关闭按钮。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The narrative emphasizes that humanity only has one chance to get this right and that AI has no off button.</p>
</details>

我不同意。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I disagree.</p>
</details>

在我看来，在进行AI战争时需要考虑的关键资源是电力。AI需要大量的电力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The key resource to consider when taking on an AI war, as far as I'm concerned, is electricity. AI needs it a lot of it.</p>
</details>

AI，即使是超智能AI，没有电力也无法很好地运行。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">AIs, even super intelligent AIs, are not going to fare well without electricity.</p>
</details>

而保持数据中心24/7供电、散热和连接需要付出努力，这种努力需要人手、技能和备件。这是一项繁重的工作，我以前也做过。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And keeping a data center powered and cool and connected 24/7 takes effort, And that effort requires hands and skills and spare parts. It's a lot of work. I've had to do it before.</p>
</details>

最近有报道称，正在建设的新数据中心将给美国电网带来压力。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Lately there's been report after report about how the new data centers that are being built are going to stress the us power grid.</p>
</details>

而电网已经证明其相当脆弱。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the power grid has already proven itself to be pretty fragile.</p>
</details>

我住在德克萨斯州，2021年初的一场冬季风暴导致该州大部分地区停电两到四天。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">I live in Texas or the majority of the state lost power for two to four days because of a winter storm early in 2021.</p>
</details>

根据这个停电追踪器，仅在美国，过去几年就发生了数百起大规模停电事件，所有这些停电都需要人类进行物理修复。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There have been hundreds of mass power outages in the last few years Just in the US according to this blackout tracker, and those outages have all required humans to physically fix them.</p>
</details>

数据中心确实有备用发电机，但发电机也需要有动手能力和技能的人来维护和加油。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It is true that most data centers have generator backups, But generators need people with hands and skills to maintain and refuel them too.</p>
</details>

如果人类停止维护电网，并且不补充燃料或维护发电机——无论是我们拒绝这样做，还是因为AI以某种方式杀死了我们——那么AI失去其继续运行所需的大量电力只是时间问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If humans stopped maintaining the electric grid and didn't refill or maintain the generators either because we refuse to or because the AI Somehow killed us off, Then it would only be a matter of time before the AIs are starved of the immense amount of power they need to keep going.</p>
</details>

如果我们真的与AI开战，电力将是它们的**阿喀琉斯之踵**（Achilles heel: 源自希腊神话，比喻致命的弱点），我们可以切断电力，然后等待几天，直到它们停止运行。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If we truly got into war with AI, Electricity would be their Achilles heel and we could deny them that and then wait a few days until they just stopped.</p>
</details>

那仍然会很糟糕。我不想国家或世界不得不关闭电网来饿死AI。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now that would still be bad. I don't want the country or the world to have to shut off the power grid to starve the AIs.</p>
</details>

德克萨斯州停电期间有几人死亡。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There were several people in Texas that died during the power outage here.</p>
</details>

但这比让AI将我们推向灭绝要好得多。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But that's a much better alternative than letting the AIs drive us toward extinction.</p>
</details>

AI末日论者有一些模糊不清的场景来规避这一点，但我根本不觉得它们可信。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The AI Doomers have hand-wavy scenarios to get around this that I just don't find it all plausible.</p>
</details>

基本上，他们假设AI控制的太阳能自给自足机器人工厂，可以生产AI用来进行所有维护、保持电力流动和AI运行的机器人。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Basically, they posit AI-controlled solar powered self-contained robot factories that can produce the robots that the AIs use to do all the maintenance to keep the power flowing and the AIs running.</p>
</details>

在《AI 2027报告》中写道：“美国和中国都宣布了新的**经济特区**（Special Economic Zones, SEZs: 指为吸引投资、促进经济发展而设立的具有特殊经济政策和管理制度的区域），以适应机器人经济的快速发展，而无需通常的繁文缛节。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">In the AI 2027 report quote "both the US and China announced new special economic zones or SEZs For the AIs to accommodate the rapid buildup of a robot economy without the usual red tape."</p>
</details>

让我明确一点：如果人类最终建造了一支能够保护电网免受破坏、并在没有人类的情况下维护其发电和配电的自动化杀手机器人军队，或者一个能让AI制造这样一支军队的工厂，那将是一个问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Let me be clear: if humanity ends up building an automated army of killer robots that can protect the electric grid from sabotage and maintain its power generation and distribution without humans, or a factory that will let the AI create just such an army, That will be a problem.</p>
</details>

但问题不会是AI，而是这支自主杀手机器人军队。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the problem won't be the AI it will be the army of autonomous killer robots.</p>
</details>

AI控制的自给自足核潜艇或航空母舰也是如此。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Same thing for AI controlled self-contained nuclear submarines or aircraft carriers.</p>
</details>

但在此之前，我们确实有一个关闭AI的大开关，尽管我宁愿不必使用它。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But until then, we do have a big off switch for the AIs Although I'd prefer not to have to use it.</p>
</details>

《如果有人建造它，所有人都会死》这本书坚持认为，不仅自供电、自复制的机器人工厂是可能的，而且AI可以自己建造它们，因为——我将从有声书中播放给你听，这样你就知道我不是在编造——“抱歉，清醒怀疑先生，我们恐怕你忽略了一个重要的实际例子。一片草叶就是一个自复制的太阳能工厂，它能制造一个完整的自身副本。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The book "If anyone builds it, everyone dies" Insists not only that self-powered self-replicating robot factories are possible, But the AIs can build them itself because, and I'm just going to play this for you from the audiobook so you can see I'm not making it up. "Sorry mr. SoberSkeptic, but we're afraid you've overlooked an important practical example. A blade of grass is a self-replicating solar powered factory that builds a complete copy of itself."</p>
</details>

这两者绝不是一回事。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These two things are in no way the same.</p>
</details>

草由水中的氢和氧、空气中二氧化碳中的碳，以及土壤中的氮、磷、钾、镁和钙组成。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Grass is made up of hydrogen and oxygen from water, carbon pulled from carbon dioxide in the air, And nitrogen, phosphorous, potassium, magnesium, and calcium from dirt.</p>
</details>

这些都是极其常见的元素。相比之下，AI和机器人所需的计算机芯片需要更多的成分，其中许多极其稀有。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">These are all incredibly common elements. By contrast, computer chips needed by AIs and robots require way more ingredients many of which are extremely rare,</p>
</details>

例如目前在刚果以巨大的人力成本开采的那些。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Such as those currently being mined in the Congo at great cost to the humans living there.</p>
</details>

制造计算机芯片所需的步骤数量以及每个步骤的复杂性，与植物生长的简单化学过程毫无相似之处。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And the number of steps required to fabricate a computer chip, and the complexity of each of those steps, Bears no resemblance to the simple chemistry of plant growth.</p>
</details>

但末日论者不解决甚至不承认这些问题。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the Doomers don't address or even acknowledge these problems.</p>
</details>

相反，他们只是试图用另一个无效的比较蒙混过关。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Instead they just try to get away with yet another invalid comparison.</p>
</details>

### AI的思维速度与技术解锁的谬误

这是《如果有人建造它，所有人都会死》中的另一段引文：“这是我们文明如果能存活到3000年才能解锁的技术吗？一个人工智能超级智能需要多久才能做到？以比人类快10000倍的速度运行的东西，一千年的思考大约需要一个月。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Here's another quote from "If anyone builds it everyone dies": "Is that the sort of technology we'd have unlocked by the year 3000 if our civilization survived that long? And how long would it take an artificial super intelligence? A thousand years of thinking takes about a month to something running at 10000 times the speed of humans."</p>
</details>

所以他们在这里声称AI不仅速度快了120万倍，而且AI思考的时间等同于全人类“解锁一项技术”所需的时间。
<details>
<summary>View/Hide Original English</p>
</details>

这可能是有史以来最“AI兄弟会”的说法了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">That might just be the most AI-bro thing ever.</p>
</details>

这正是AI行业的缩影。AI被赋予一项任务，AI花费计算时间，AI吐出答案，然后“AI兄弟会”就认为问题解决了。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's the AI industry in a nutshell. The AI is given a task, the AI spends compute time on it, The AI spits out an answer, and the AI-bros consider the problem solved.</p>
</details>

这就是AI公司将我们带到AI垃圾和**幻觉**（hallucinations: 在人工智能领域，指AI生成看似合理但实际上虚假或不准确的信息）充斥互联网的原因：
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">This is how and why the AI companies have brought us to the point where AI slop and hallucinations are taking over the Internet:</p>
</details>

它们自信地吐出计算过程的结果，却不顾“现实”这样烦人的小细节，然后期望AI的输出能与全人类所有研究和工程努力的总和一样好。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">By confidently spitting out the results of computing processes without any regard for pesky little details like you know "reality" And then expecting the AI's output to be just as good as the sum of all of humanity's combined research and engineering efforts.</p>
</details>

这本书稍后对此做了一点让步，书中提到AI“也许会因为需要等待实验结果而放慢速度”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">There's a slight concession to this a little later when the book says of the AI quote "Maybe it would be slowed down by the need to wait on the results of experimentation"</p>
</details>

但它立即又轻描淡写地说：“但实验可以进行得很快。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But then it immediately downplays that by saying quote "But experiments can go quite fast"</p>
</details>

然而在现实世界中，实验也可能进行得很慢。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Here in the real world though, experiments can also go quite slow.</p>
</details>

即使我们做了足够的实验来理解某事物的工作原理，我们仍然需要进行工程设计使其变得实用，然后“技术才会被解锁”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And even after we've done enough experiments to understand the science of how something works, we still have to do the engineering to make it practical before the "technology is unlocked."</p>
</details>

让我举个例子：我们知道聚变是如何工作的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Let me give you an example: We know how fusion works.</p>
</details>

自1952年11月我们成功引爆第一颗聚变炸弹以来，我们便知道如何按需触发聚变。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And we've known how to trigger fusion on demand since November 1952 when we set off the first successful fusion bomb.</p>
</details>

但七十年后的今天，我们仍然无法建造一座聚变发电厂。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But here we are, seven decades later, and we still can't make a fusion power plant.</p>
</details>

我们很久以前就完成了所有关于聚变原理的科学研究和思考。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">We did all the science all the thinking about how fusion worked ages ago.</p>
</details>

但尽管自1950年代以来建造了一百多个测试反应堆，并且每个都更接近成功一点，我们仍然未能“解锁”聚变“技术”。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But despite having built more than a hundred test reactors since the 1950s And getting a little closer with each one, we still haven't been able to "unlock" fusion "technology."</p>
</details>

他们却想让我们相信，AI仅仅通过思考，也许加上一些快速实验，就能学到我们通过建造和测试100个原型聚变反应堆所学到的知识。而且AI不仅能通过思考解决问题，还能快10000倍。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And they want us to believe that an AI just thinking, And maybe some quick experiments, could learn as much as we have from building and testing 100 prototype fusion reactors. And not only could the AI figure it out just from thinking, but it could do it 10,000 times faster.</p>
</details>

但这种愚蠢并没有就此结束。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But the stupid doesn't end there.</p>
</details>

### 真正的危险：脆弱的系统而非AI本身

这是《如果有人建造它，所有人都会死》中的另一个场景：“自2024年以来，人们一直主张**生物合成实验室**（biosynthesis laboratories: 利用生物过程合成复杂有机化合物的实验室）应包含软件控制。”
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Here's another scenario from "If anyone builds it everyone dies" quote "Ever since 2024 People have been advocating that biosynthesis laboratories should include software controls"</p>
</details>

让我在这里打断你。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Let me just stop you right there.</p>
</details>

如果我们建造使用脆弱软件合成病毒的实验室，那么圣彼得堡的一个聪明的青少年黑客，只要有一篇关于天花或H5N1流感DNA序列的研究论文，就能引发一场瘟疫。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">If we build laboratories that use vulnerable software to synthesize viruses, All it takes is a smart teenage hacker in St. Petersburg with a research paper on the DNA sequence of smallpox or H5N1 flu to start a plague.</p>
</details>

这不需要AI。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">No AI required.</p>
</details>

这不是一个关于监管AI的论点。这是一个关于监管生物合成实验室的论点，要求它们使用**气隙隔离安全区**（air-gapped secure enclaves: 指物理上与外部网络隔离，以提供最高安全性的计算环境）和使用我们所能获得的最安全加密技术的**签名固件**（signed firmware: 经过数字签名以验证其真实性和完整性，防止篡改的固件），以及网络安全专家建议的其他一切措施。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It's this is not an argument for regulating AI. It's an argument for to regulate biosynthesis labs to use air-gapped secure enclaves and signed firmware using the most secure encryption We've got as well as anything else a cyber security experts advise.</p>
</details>

看，AI是危险的。不是“也许有一天如果超级AI出现”才危险。它现在就很危险。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Look, AI is dangerous. Not "maybe someday if super AI happens" dangerous. It's dangerous now.</p>
</details>

社交媒体上的虚假信息是危险的。说服青少年自残是危险的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The disinformation on social media is dangerous. convincing teenagers to harm themselves is dangerous.</p>
</details>

撞倒骑自行车的人是危险的。说服某人将溴化钠代替食盐加入饮食是危险的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Running over bicyclists is dangerous. Convincing someone to substitute sodium bromide for salt in their diet is dangerous.</p>
</details>

将行人拖到自动驾驶汽车下面是危险的。聊天机器人声称自己是持牌心理健康专业人士是危险的。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Dragging pedestrians underneath self-driving cars is dangerous. Chatbots claiming to be licensed mental health professionals is dangerous.</p>
</details>

将错误的人送进监狱是危险的。说服警察停止寻找真正的罪犯，而真正的罪犯仍在外面伤害他人是危险的。不是也许。不是有一天。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Sending the wrong people to prison is dangerous. And convincing the cops to stop looking for the real criminals while the real criminals are still out there hurting people is dangerous. Not maybe. Not someday.</p>
</details>

就是现在。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Now.</p>
</details>

解决这个问题并不难。它不会发生，但并不困难。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And fixing this is not hard. It's not going to happen, but it's not difficult.</p>
</details>

加州的新法律不会有帮助。解决方案不是关于透明度。也不是关于强制性的安全团队。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">California's new law won't help. the fix isn't about transparency. It's not about mandatory safety teams.</p>
</details>

解决这个问题最简单的方法是追究公司中个人的责任。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">The easiest way to fix this is by holding the individuals in the companies accountable.</p>
</details>

不是“今天司法部公布了一项和解协议的细节，根据该协议，公司不承认任何不当行为，但同意支付相当于其十分钟收入的罚款”那种问责。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Not "Today the justice department released the details of a settlement under which the company does not admit any wrong doing, But agreed to pay a fine equal to 10 minutes worth of their revenue" accountable.</p>
</details>

它需要是“我们陪审团认定被告……”那种问责。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">It needs to be "We the jury find the defendant..." accountable.</p>
</details>

只需要几起针对过失杀人、危害未成年人、非法监禁、无证行医或类似罪行的个人刑事起诉。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">All it will take is a few individual criminal prosecutions for manslaughter, endangering a minor, false imprisonment, practicing medicine without a license, or the like.</p>
</details>

你会惊讶地发现，其余的问题会很快自行解决。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">You'll be amazed how fast the rest of these problems just fix themselves.</p>
</details>

但只要他们能让我们所有人花费时间和资源去担心和争论AI是否会终结整个人类，以及如果会，何时终结，我们就无法进行这种讨论。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">But we can't even have that discussion as long as they can keep all the rest of us spending our time and resources worrying about and debating whether or not AI will end the entire human race, And if so, when.</p>
</details>

别再上当了。记住真正重要的是什么。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">Stop taking the bait. Remember what's really important.</p>
</details>

让我们在外出时小心谨慎。
<details>
<summary>View/Hide Original English</summary>
<p class="english-text">And let's be careful out there.</p>
</details>