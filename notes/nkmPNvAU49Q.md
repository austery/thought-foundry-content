---
title: AI发展放缓了吗？Nathan Labenz：我们问错了问题
summary: Nathan Labenz深入探讨AI发展现状，反驳AI放缓论，分析其对就业、社会的影响，并强调非语言模型和多模态AI的巨大潜力。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- ai-capabilities
- ai-progress
- ai-safety
- job-displacement
- multimodal-ai
people: []
companies_orgs: []
products_models: []
media_books: []
date: '2025-10-14'
author: a16z
speaker: a16z
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=nkmPNvAU49Q
status: evergreen
---
### 引言：AI的本质与未来展望

AI is not synonymous with language models.
AI is being developed with pretty similar architectures for a wide range of different modalities, and there's a lot more data there.
Feedback is starting to come from reality.
Maybe we're running out of problems we've already solved.
When we start to give the next generation of the model these power tools and they start to solve previously unsolved engineering problems, I think you start to have something that looks kind of like **super intelligence** (Super Intelligence: 一种假设的智能，其能力远超最聪明的人类)。

人工智能不等于语言模型。
人工智能正在以非常相似的**架构** (Architectures: 计算机系统或软件的底层设计和组织方式) 为广泛的**模态** (Modalities: 数据类型，如文本、图像、音频、视频等) 进行开发，并且那里有更多的数据。
反馈开始从现实中传来。
也许我们正在耗尽已经解决的问题。
当我们开始赋予下一代模型这些强大的工具，并且它们开始解决以前未解决的工程问题时，我认为你就会开始看到某种**超级智能**。

Nathan, I'm stoked to have you on the AC and Z podcast for the first time.
Obviously, I've been podcast partners for a long time with you leading Cognitive Revolution.
Welcome.

Nathan，我非常高兴你第一次来到AC和Z播客。
显然，你领导的Cognitive Revolution播客我们合作了很长时间。
欢迎。

>> It's great to be here.
Thank you.
So, we were talking about Cal Newport's podcast appearance on lost debates and we thought it was a good opportunity to just have this broad conversation and really entertain this sort of question of is AI slowing down?
So, why don't you sort of **steelman** (Steelman: 强化对方论点，使其更具说服力，以便更好地反驳或讨论) some of the arguments that you've heard on that side either from him or more broadly and then we could sort of have this broader conversation.

>> 很高兴来到这里。
谢谢。
我们之前谈论了Cal Newport在lost debates播客上的露面，我们认为这是一个很好的机会，可以进行一次广泛的对话，并真正探讨“AI是否正在放缓？”这个问题。
那么，你为什么不**强化**一下你从他那里或更广泛地听到的这方面的论点，然后我们就可以进行更广泛的讨论了。

### AI发展速度的争议：能力与影响的区分

>> Yeah, I mean I think for one thing it's really important to separate a couple different questions I think with respect to AI.
One would be is it good for us right now even and is it going to be good for us in the big picture?
And then I think that is a very distinct question from are the **capabilities** (Capabilities: 指AI系统能够执行的任务或解决问题的能力) that we're seeing continuing to advance and at a pretty healthy clip.

>> 是的，我认为首先，对于人工智能，区分几个不同的问题非常重要。
一个问题是，它现在对我们有益吗？从长远来看，它对我们有益吗？
然后，我认为这与我们所看到的能力是否继续以相当快的速度发展是截然不同的问题。

So I actually found a lot of agreement with the Cal Newport podcast that you shared with me when it comes to some of the worries about the impact that AI might be having even already on people.
You know, he goes over looks over students' shoulders and watches how they're working and finds that basically he thinks that they are using AI to be lazy, which is, you know, no big revelation.
I think a lot of teachers would tell you that.

所以，当你和我分享Cal Newport的播客时，我实际上非常同意其中一些关于人工智能可能已经对人们产生影响的担忧。
你知道，他会观察学生的学习方式，发现他们基本上是在利用人工智能偷懒，这并不是什么惊人的发现。
我想很多老师都会告诉你这一点。

>> Yeah.
Puts that in maybe more dressed up terms that people are not even necessarily moving faster, but they're able to reduce the strain that the work that they're doing places on their own brains by kind of trying to get AI to do it.
And you know if that continues and I think he's been a very valuable commenter on the impact of social media, certainly I think we all should be mindful of how is my attention span evolving over time and am I getting weak or averse to hard work.
Those are not good trends if they are showing up in oneself.

>> 是的。
他用更委婉的措辞表达，人们甚至不一定变得更快，但他们能够通过让AI来完成工作，从而减轻工作对大脑造成的压力。
你知道，如果这种情况持续下去，我认为他一直是社交媒体影响的非常有价值的评论员，我们当然都应该注意自己的注意力广度是如何随时间变化的，以及我是否变得脆弱或厌恶艰苦工作。
如果这些趋势出现在自己身上，那都不是好现象。

So, I think he's really right to watch out for that sort of stuff.
And then, as we've covered it, you know, many conversations in the past, I've got a lot of questions about what the ultimate impact of AI is going to be.
And I think he probably does too.
But then when it comes to it's a strange move from my perspective to go from you know there's all these sort of problems today and maybe in the big picture to but don't worry it's flatlining like kind of worry but don't worry because it's not really going anywhere further than this or it's you know **scaling** (Scaling: 指通过增加计算资源、数据量或模型大小来提升AI模型性能的过程) has kind of petered out or you know we're not going to get better AI than we have right now.

所以，我认为他非常正确地指出了这些问题。
然后，正如我们过去多次讨论过的，我对人工智能的最终影响有很多疑问。
我想他可能也有。
但是，从我的角度来看，从“今天存在所有这些问题，也许从大局来看”到“但别担心，它正在停滞不前”这种说法很奇怪，就像是“担心，但又别担心，因为它不会再有进一步发展了”，或者“**规模化**已经逐渐减弱”，或者“我们现在的人工智能不会再变得更好了”。

Or even maybe the most easily refutable claim from my perspective is GPT5 wasn't that much better than GPT4.
And that I think is where I really was like, whoa, wait a second.
You know, I was with you on a lot of things.
And some of the behaviors that he observes in the students, I would cop to having exhibited myself.
You know, when I'm trying to code something these days, a lot of times I'm like, "Oh man, can't the AI just figure it out?"
You know, I really don't want to have to sit here and read this code and figure out what's going on.

或者，从我的角度来看，最容易驳斥的说法是GPT5并没有比GPT4好多少。
而这正是我真正觉得“哇，等一下”的地方。
你知道，我在很多事情上都同意你的看法。
他观察到学生的一些行为，我自己也承认有这些表现。
你知道，现在当我尝试编写代码时，很多时候我都会想：“哦，天哪，AI就不能自己搞定吗？”
你知道，我真的不想坐在这里阅读这些代码并弄清楚发生了什么。

It's not even about typing the code anymore, you know, I'm way too lazy for that.
But it's even about like figuring out how the code is working just just case you just make it work.
Try again, you know, and just try again and I'll I do find myself at times falling into those traps.
But I would say big part of the reason I can fall into those traps is because the AIs are getting better and better and increasingly it's not crazy for me to think that they might be able to figure it out.

这甚至不再是关于输入代码的问题了，你知道，我太懒了，不想做那个。
但它甚至关乎弄清楚代码是如何工作的，只是为了让它工作。
再试一次，你知道，再试一次，我确实有时会陷入这些陷阱。
但我想说，我之所以会陷入这些陷阱，很大一部分原因是因为人工智能越来越好，而且我越来越觉得它们能够解决问题，这并不疯狂。

So that that's my kind of first slice at the takes that I'm hearing.
There's almost like a **two-by-two matrix** (Two-by-two matrix: 一种将事物分为四个象限的分析工具，用于比较和对比) maybe that one could draw up where it's like do you think AI is good or bad now and in the future and do you think it's like not a big deal or a big deal and I'm I think it's both on the good and bad side I definitely think it's a big deal the the thing that I struggle to understand the most is the people who kind of don't see the big deal that it seems pretty obvious to me and the you know especially when it comes again to the the leap from GPT4 to GPT5.

所以，这是我对所听到的观点的初步看法。
也许可以画一个**二乘二矩阵**，其中一个维度是“你认为人工智能现在和未来是好是坏”，另一个维度是“你认为它影响大不大”。我认为它既有好的方面也有坏的方面，我绝对认为它影响很大。我最不理解的是那些不认为它影响很大的人，对我来说这似乎很明显，尤其是在GPT4到GPT5的飞跃方面。

Maybe one reason that that's happened a little bit is that there were just a lot more releases between GPT4 and 5.
So what people are comparing to is, you know, something that just came out a few months ago, like 03, right?
That only came out a few months before GPT5.
Whereas with GPT4, it was, you know, shortly after ChatGPT and it was all kind of this moment of like, whoa, this thing is like exploding onto the scene.
A lot of people were seeing it for the first time.

也许发生这种情况的一个原因是，GPT4和GPT5之间发布了更多的版本。
所以人们比较的对象，你知道，是几个月前才发布的东西，比如03版本，对吧？
它只在GPT5发布前几个月才问世。
而GPT4，你知道，是在ChatGPT之后不久发布的，当时就像是一个“哇，这东西正在爆炸式地进入人们视野”的时刻。
很多人是第一次看到它。

And if you look back to GPT3, you know, there's a huge leap.
I would contend that the leap is similar from GPT4 to 5.
These things are hard to score.
There's no, you know, single number that you could put on it.
Well, there's **loss** (Loss: 机器学习中衡量模型预测与真实值之间差异的指标), but of course, one of the big challenges is that like what exactly does a loss number translate into in terms of capabilities.

如果你回顾GPT3，你会发现有一个巨大的飞跃。
我认为GPT4到GPT5的飞跃也类似。
这些东西很难打分。
你知道，你无法用一个单一的数字来衡量它。
当然，有**损失**，但其中一个大挑战是，损失数值究竟如何转化为能力。

So, you know, it's very hard to describe what exactly has changed.
But we could go through some of the dimensions of change if you want to and, you know, enumerate some of the things that I think people maybe are starting to or have come to take for granted and kind of forget like that GPT4 didn't have a lot of the things that now, you know, were sort of expected in the GPT5 release because we'd seen them in 40 and 01 and 03 and all those, you know, things sort of, you know, maybe boiled the frog a little bit when it comes to how much progress people perceived in this last release.

所以，你知道，很难准确描述到底发生了什么变化。
但如果你愿意，我们可以探讨一些变化维度，列举一些我认为人们可能开始或已经习以为常，并有点忘记GPT4没有的许多东西，而这些东西现在在GPT5发布时被认为是理所当然的，因为我们已经在40、01和03版本中看到了它们，这些东西在某种程度上，你知道，可能让人们对最新版本所感知的进步程度有点“温水煮青蛙”的感觉。

### 对Cal Newport观点的回应：AI发展未停滞

>> Well, yeah, a couple reactions.
So, one is and even to complicate your two-by-two even further in the sense of, you know, is it bad now versus is it bad later?
Like Cal is not really, you know, who we both admire by the way a lot.
Cal's a great guy and a valuable contributor to the thought space, but he's not as concerned about sort of this sort of future AI concerns that, you know, sort of the **AI safety** (AI Safety: 确保AI系统在开发和部署过程中不会对人类造成意外或故意的伤害) folks and many others are concerned about.

>> 嗯，是的，有几点回应。
首先，为了进一步复杂化你的二乘二矩阵，从“现在是坏事还是以后是坏事”的角度来看，Cal并不是我们都非常欣赏的人。
Cal是个很棒的人，也是思想领域的重要贡献者，但他并不像那些**AI安全**领域的人和许多其他人那样，担心未来人工智能的各种问题。

He's more concerned about, you know, what it means to life for, you know, cognitive performance and development now in the same way that he's worried about, you know, social media's impact.
And, you know, you you think that's a concern, but not nowhere near as big a concern as as what to what to expect in the future.
And and then also he he presents sort of this theory of why we shouldn't worry about the future because it's slowing down.

他更关心的是，你知道，它对现在认知表现和发展意味着什么，就像他担心社交媒体的影响一样。
而且，你知道，你认为这是一个担忧，但远不及对未来预期那样大的担忧。
然后，他还提出了一个理论，解释了为什么我们不应该担心未来，因为它正在放缓。

And why don't we just share what we how we interpreted kind of his history which as I interpreted it was this idea of like hey we figured out the simplistic version is we figured out this this way such that if you throw a bunch of data into the model it gets better and sort of order of magnitude and so the difference between GPT2 and GPT3 and then GPT3 and GPT4 but then that sort of you know was significant the difference but then it achieved sort of a diminishing returns significantly and where we're not seeing it in GPT5 and thus we don't have to worry anymore.

我们为什么不分享一下我们是如何解读他的历史观点的呢？据我理解，他的观点是：我们发现了一种简单的方法，只要向模型中投入大量数据，它的性能就会大幅提升，比如GPT2到GPT3，以及GPT3到GPT4之间的差异。但随后这种提升的**边际效益** (Diminishing returns: 指在投入更多资源后，产出增长速度放缓的现象) 显著减弱，在GPT5中我们没有看到这种现象，因此我们不再需要担心了。

How would you edit the characterization of his view of sort of the the history and then we can get into the differences between four and five the **scaling law** (Scaling Law: 指AI模型性能随计算资源、数据量和模型大小增加而呈现的可预测趋势) idea which is you know it's definitely worth agreeing taking a moment to to note that it is not a law of nature.
You know we do not have a principled reason to believe that scaling is some law that will go indefinitely.
All we really know is that it has held through quite a few orders of magnitude so far.

你将如何修改他对历史观点的描述？然后我们可以讨论GPT4和GPT5之间的差异，以及**规模法则**这个概念。值得注意的是，它并非自然法则。我们没有理由相信规模化会无限期地持续下去。我们所知道的只是到目前为止，它已经持续了相当大的几个数量级。

I think that it's really not clear yet to me whether or not the scaling laws have petered out or whether we have just found a steeper gradient of improvement that is giving us better **ROI** (ROI: Return on Investment，投资回报率) on another front that we can push on.
So they did train a much bigger model which was GPT4.5 and that did get released and there are a number of interesting you know of course there's a million benchmarks whatever the one that I zero in on the most in terms of understanding how GPT4.5 relates to both 03 and GPT5 and OpenAI obviously famously terrible at naming we can all agree on that I think a decent amount of this confusion and sort of disagreement actually does stem from unsuccessful naming decisions.

我认为目前尚不清楚规模法则是否已经失效，或者我们是否只是找到了一个更陡峭的改进梯度，从而在另一个我们可以推进的领域获得了更好的**投资回报率**。
他们确实训练了一个更大的模型，即GPT4.5，并且已经发布了。当然，有无数的基准测试，但就理解GPT4.5与03和GPT5的关系而言，我最关注的一个基准。OpenAI在命名方面显然出了名的糟糕，我想我们都同意这一点。我认为相当一部分的困惑和分歧实际上源于不成功的命名决策。

GPT4.5 on this one benchmark called **Simple QA** (Simple QA: 一个用于测试模型对长尾事实性知识掌握程度的基准测试) which is really just a super longtail trivia benchmark.
It it really just measures do you know a ton of esoteric facts and they're not things you can really reason about.
You either just have to know or don't know these particular facts.
The 03 class of models got about a 50% on that benchmark and GPT4.5 popped up to like 65%.

GPT4.5在名为**Simple QA**的基准测试中表现出色，这实际上是一个超长尾的冷知识基准测试。
它真正衡量的是你是否了解大量深奥的事实，这些事实你无法真正推断。
你只能知道或不知道这些特定的事实。
03类模型在该基准测试中获得了大约50%的得分，而GPT4.5则跃升至约65%。

So in other words, it basically of the things that were not known to the previous generation of models, it picked up a third of them.
Now there's obviously still two-thirds more to go, but I would say that's a pretty significant leap, right?
These are super longtail questions.
I would say most people would get like close to a zero.
You know, you'd be like the person sitting there at the trivia night who like maybe gets one a night is kind of what I would expect most people to do on Simple QA.

换句话说，它基本上掌握了前一代模型所不知道的三分之一内容。
显然还有三分之二有待学习，但我会说这是一个相当大的飞跃，对吧？
这些都是超长尾的问题。
我想大多数人可能得分接近零。
你知道，你就像是坐在冷知识之夜的人，可能一晚只答对一个，这就是我对大多数人在Simple QA上的预期。

And that, you know, checks out, right?
Like obviously the models know a lot more than we do in terms of facts and just general, you know, information about the world.
So at a minimum, you can say that GPT4.5 knows a lot more.
You know, a bigger model is able to absorb a lot more facts.
Qualitatively, people also said in some ways maybe it's better for creative writing.

而且，你知道，这很合理，对吧？
显然，模型在事实和一般世界信息方面比我们知道得多。
所以至少可以说，GPT4.5知道的更多。
你知道，一个更大的模型能够吸收更多的事实。
从定性角度看，人们也说在某些方面它可能更适合创意写作。

You know, it was never really trained with the same power of **post-training** (Post-training: 在模型完成初始预训练后，通过进一步的微调和优化来提升其性能和特定任务表现的过程) that GPT5 has had.
And so, we don't really have an apples to apples comparison, but people still did still find some utility in it.
I think maybe the the way to understand why they've taken that offline and gone all in on GPT5 is just that that model's really big.
It's expensive to run.
The price was like way higher.
It was a full order of magnitude plus higher than GPT5 is.

你知道，它从未真正接受过GPT5那样的**后训练**强度。
所以，我们没有真正的同类比较，但人们仍然发现它有一些用处。
我想，他们之所以将其下线并全力投入GPT5，原因可能仅仅是那个模型实在太大了。
运行成本很高。
价格要高得多。
比GPT5高出了一个数量级还多。

And it's maybe just not worth it for them to consume all the compute that it would take to serve that and maybe they just find that people are happy enough with the somewhat smaller models for now.
I don't think that means that we will never see a bigger GPT4.5 model with all that reasoning ability and I I would expect that that would deliver more value especially if you're really going out and trying to do esoteric stuff that's you know pushing the frontier of science or what have you.

而且，对他们来说，消耗所有计算资源来提供这项服务可能不值得，也许他们只是发现人们目前对稍小的模型已经足够满意了。
我并不认为这意味着我们永远不会看到一个拥有所有推理能力的更大GPT4.5模型，我预计它会带来更多价值，特别是如果你真的在尝试做一些推动科学前沿的深奥工作。

### 上下文窗口的飞跃与推理能力

But in the meantime, the current models are really smart and you can also feed them a lot of context.
That's one of the big things that has improved so much over the last generation.
When GPT4 came out, at least the version that we had as public users was only 8,000 **tokens** (Tokens: AI模型处理文本的基本单位，可以是单词、子词或字符) of context, which is like 15, you know, pages of text.
So, you were limited.
You couldn't even put in like a couple papers.
You would be overflowing the context.

但与此同时，目前的模型非常智能，你还可以给它们提供大量的上下文。
这是上一代模型以来改进最大的地方之一。
GPT4刚发布时，至少我们作为公共用户使用的版本只有8000个**token**的上下文，大约是15页文本。
所以，你受到了限制。
你甚至无法输入几篇论文。
你会溢出上下文。

And this is where **prompt engineering** (Prompt Engineering: 设计和优化给AI模型的输入提示，以获得更准确、相关和有用的输出) initially kind of became a thing was like, man, I've really only got such a little bit of information that I can provide.
I got to be really careful about what information to provide, lest I overflow the thing and it just can't handle it.
There were also, as context windows got extended, there were also versions of models where they could nominally accept a lot more, but they couldn't really functionally use them.

而这正是**提示工程**最初兴起的原因，当时人们会想：“天哪，我能提供的信息实在太少了。
我必须非常小心地选择提供哪些信息，以免信息溢出，模型无法处理。”
随着**上下文窗口** (Context Windows: AI模型在一次处理中能够接收和理解的文本或数据量) 的扩展，也出现了一些模型版本，它们名义上可以接受更多信息，但实际上无法有效利用。

You know, they sort of could it could could fit them, you know, at the **API call** (API Call: 应用程序通过调用应用程序编程接口（API）向AI模型发送请求并接收响应) level, but they the models would lose **recall** (Recall: 在信息检索或机器学习中，指模型正确识别出所有相关项目的能力) or they they'd sort of unravel as they got into longer and longer context.
Now you have obviously much longer context and the command of it is really really good.
So you can take dozens of papers on the longest context windows with **Gemini** (Gemini: 谷歌开发的一系列多模态AI模型) and it will not only accept them, but it will do pretty **intensive reasoning** (Intensive Reasoning: 指AI模型进行深入、复杂和多步骤的逻辑思考和问题解决) over them and with really **high fidelity** (High Fidelity: 指AI模型在处理信息时，能够高度准确地保留原始输入的细节和意图) to those inputs.

你知道，它们在**API调用**层面可以容纳这些信息，但模型会失去**召回率**，或者在处理越来越长的上下文时会变得混乱。
现在你显然拥有更长的上下文，而且对它的掌控能力非常出色。
所以你可以用**Gemini**最长的上下文窗口处理几十篇论文，它不仅能接受这些论文，还能对它们进行相当**深度推理**，并且对这些输入保持**高保真度**。

So that skill I think does kind of substitute for the model knowing facts itself.
You could say geez we let's try to train all these facts into the model.
We're going to need you know a trillion or who knows five trillion however many trillion **parameters** (Parameters: AI模型中可学习的变量，决定了模型的行为和性能，数量越多通常模型越大越复杂) to fit all these super longtail facts.
Or you could say, well, a smaller thing that's really good at working over provided context can if people take the time or you know go to the trouble of providing the necessary information, I can kind of access the same facts that way.

所以，我认为这项技能在某种程度上可以替代模型本身知道事实。
你可以说，天哪，我们试着把所有这些事实都训练进模型。
我们将需要万亿，甚至五万亿，谁知道多少万亿的**参数**来容纳所有这些超长尾的事实。
或者你可以说，一个更小的、擅长处理所提供上下文的模型，如果人们花时间或不嫌麻烦地提供必要信息，我就可以通过这种方式获取相同的事实。

So you have a kind of do I want to push on this size and do I want to bake everything into the model or do I want to just try to get as much performance out of a smaller tighter model that I have?
And it seems like they've gone that way.
And I I think basically just because they're seeing faster progress on that gradient, you know, in the same way that the models themselves are always kind of in the training process taking a little step toward improvement, you know, the the outer loop of the model architecture and the the nature of the training runs and where they're going to invest their compute is also kind of going that direction.

所以你面临一个选择：是想在这个规模上发力，把所有东西都嵌入模型中，还是想从我现有的更小、更紧凑的模型中榨取尽可能多的性能？
他们似乎选择了后者。
我想这基本上是因为他们在这个梯度上看到了更快的进展，你知道，就像模型本身在训练过程中总是在向改进迈进一小步一样，模型架构的外部循环以及训练运行的性质，以及他们将计算资源投入到哪里，也都在朝着这个方向发展。

And they're always looking at like, well, we could scale up over here and maybe get this kind of benefit a little bit or we could do more post-training here and get this kind of benefit.
And it just seems like we're getting more benefit from the post-training and the reasoning paradigm than scaling.
But I don't think either one is I I definitely don't think either one is is dead.
We haven't seen yet what 4.5 with all that post-training would look like.

他们总是在考虑，我们可以在这里扩大规模，也许能获得一点这种好处，或者我们可以在这里进行更多的后训练，获得那种好处。
而且似乎我们从后训练和推理范式中获得的益处比从规模化中获得的更多。
但我认为两者都没有消亡，我绝对不认为两者都已消亡。
我们还没有看到经过所有后训练的4.5版本会是什么样子。

### 扩展推理能力的突破：数学与科学前沿

>> Yeah.
And and so I mean one of the things that you mentioned that that Cal analysis missed was was that it way underestimated the value of of of of of extended reasoning, right?
And so what what would it mean to to fully sort of appreciate that?

>> 是的。
所以我的意思是，你提到Cal的分析遗漏的一点是，它大大低估了扩展推理的价值，对吧？
那么，要充分认识到这一点意味着什么呢？

>> Well, I mean, a big one from just the last few weeks was that we had an **IMO gold medal** (IMO Gold Medal: 国际数学奥林匹克竞赛金牌，代表数学领域的顶尖成就) with pure reasoning models with no access to tools from multiple companies.
And you know, that is night and day compared to what GPT4 could do with math, right?
We And these things are really weird.
Like it's nothing I say here should be intended to suggest that people won't be able to find weaknesses in the models.

>> 嗯，我的意思是，最近几周的一个重大进展是，我们用纯推理模型获得了**IMO金牌**，这些模型没有使用多家公司的工具。
你知道，这与GPT4在数学方面的能力相比，简直是天壤之别，对吧？
我们，这些事情真的很奇怪。
我在这里说的任何话都不应被理解为暗示人们无法在模型中找到弱点。

I I still use a **tic-tac-toe puzzle** (Tic-tac-toe puzzle: 井字棋游戏，通常用于测试AI的简单逻辑推理能力) to this day where I take a picture of a tic-tac-toe board where some the one of the players has made a wrong move that is not optimal and thus allows the other player to force a win and I ask the models if somebody can force a win from this position.
Only very recently, only the last generation of models are starting to get that right some of the time.
Almost always before they were like tic-tac-toe is a solved game.
You know, you can always get a draw.
There's and they would wrongly assess my board position as player can still get a draw.

我至今仍在使用一个**井字棋谜题**：我拍下一张井字棋盘的照片，其中一名玩家走了一步不佳的棋，从而让另一名玩家能够强制获胜，然后我问模型是否有人能从这个位置强制获胜。
直到最近，只有最新一代的模型才开始有时能答对。
在此之前，它们几乎总是说井字棋是一个已解决的游戏。
你知道，你总是可以平局。
它们会错误地评估我的棋盘位置，认为玩家仍然可以平局。

So, there's a lot of weird stuff, right?
The **jagged capabilities frontier** (Jagged Capabilities Frontier: 指AI模型在不同任务或领域的能力表现不均衡，存在明显的强项和弱项) remains a real issue and people are going to find, you know, peaks and valleys for sure, but GPT4 when it first came out couldn't do anything approaching IMO gold problems.
It was still struggling on like high school math.
And since then, we've seen this high school math progression all the way up through the IMO gold.

所以，有很多奇怪的事情，对吧？
**锯齿状的能力边界**仍然是一个真实存在的问题，人们肯定会发现能力的高峰和低谷，但GPT4刚发布时，根本无法解决接近IMO金牌难度的问题。
它甚至在高中数学上还在挣扎。
自那时起，我们看到了高中数学的进步，一直到IMO金牌。

Now we've got the **frontier math benchmark** (Frontier Math Benchmark: 衡量AI在解决前沿数学问题方面能力的基准测试) that is I think now like up to 25%.
It was 2% about a year ago or even a little less than a year ago I think.
And we also just today saw something where and I haven't absorbed this one yet but somebody just came out and said that they had solved a you know canonical super challenging problem that no less than Terrence Ta had put out.
And it was like this you know this thing happened in I think days or weeks of the model running versus it was 18 months you know that it took professional and not just any professional mathematicians but like really you know the leading minds in the world to make progress on these problems.

现在我们有了**前沿数学基准**，我认为现在已经达到了25%左右。
大约一年前，甚至不到一年前，我认为它只有2%。
而且就在今天，我们还看到了一个消息，我还没完全消化，但有人刚刚宣布他们解决了一个，你知道，由Terrence Tao提出的经典超级挑战问题。
而且，你知道，这件事在模型运行几天或几周内就发生了，而之前，世界顶尖的专业数学家，不仅仅是任何专业数学家，而是真正的领军人物，花了18个月才在这些问题上取得进展。

So yeah, I think that's really um you know that's that's really hard jumping capabilities to miss.
I also think a lot about the **Google AI co-scientist** (Google AI Co-scientist: 谷歌开发的一个AI系统，旨在辅助科学家进行研究，通过自动化科学方法中的某些步骤来加速发现) which we did an episode with.
We can you can check out the full story on that if you want to.
But you know they basically just broke down the **scientific method** (Scientific Method: 科学研究的基本方法，包括观察、假设、实验、分析和结论) into a schematic and this is a lot of what happens when people there's one thing to say the model will respond with thinking and it'll go through a reasoning process and you know the more tokens it it spends at runtime the better your answer will be.

所以，是的，我认为这些跳跃式的能力确实很难被忽视。
我还经常想到**Google AI联合科学家**，我们曾为此做过一期节目。
如果你想了解完整的故事，可以去看看。
但是，你知道，他们基本上只是将**科学方法**分解成一个图表，这在人们说模型会通过思考和推理过程来回应时经常发生，你知道，它在运行时花费的token越多，你的答案就会越好。

That's true.
Then you can also build this **scaffolding** (Scaffolding: 在AI领域，指为模型提供结构化指导或辅助工具，以帮助其更好地完成复杂任务) on top of that and say okay well let me take something as broad and you know aspirational as the scientific method and let me break that down into parts okay there's **hypothesis generation** (Hypothesis Generation: 科学方法中的第一步，指提出可检验的解释或预测), then there's **hypothesis evaluation** (Hypothesis Evaluation: 评估所提出假设的合理性和可行性), then there's you know **experiment design** (Experiment Design: 设计实验来测试假设), there's **literature review** (Literature Review: 对现有相关研究进行系统性回顾和分析), there's all these parts to the scientific method what the team at Google did is created a pretty elaborate **schematic** (Schematic: 示意图或流程图，用于表示系统或过程的结构和关系) that represented their best breakdown of the scientific method optimized prompts for each of those steps and then gave this resulting system which is **scaling inference** (Scaling Inference: 指在不增加模型大小的情况下，通过优化推理过程来提升AI系统处理复杂任务的能力) now kind of two ways.

这是真的。
然后你还可以在此之上构建**脚手架**，并说：“好吧，让我以科学方法这样广泛而富有抱负的东西为例，并将其分解成各个部分：有**假设生成**，然后是**假设评估**，然后是**实验设计**，有**文献综述**，科学方法有所有这些部分。”谷歌团队所做的就是创建了一个相当精密的**示意图**，代表了他们对科学方法的最佳分解，为每个步骤优化了提示，然后将由此产生的系统（现在以两种方式**扩展推理**）赋予了任务。

It's both the **chain of thought** (Chain of Thought: 一种提示技术，通过让AI模型逐步展示其推理过程来提高复杂任务的解决能力), but it's also all these different angles of attack structured by the team.
And they gave it legitimately unsolved problems in science.
And in one particularly famous kind of notorious case, it came up with a hypothesis which it wasn't able to verify because it doesn't have direct access to actually run the experiments in the lab.
But it came up with a hypothesis to some open problem in **virology** (Virology: 病毒学，研究病毒及其相关疾病的科学分支) that had stumped scientists for years and it just so happened that they had also recently figured out the answer but not yet published their results and so there was this confluence where the scientists had experimentally verified and Gemini in the form of this AI co-scientist came up with exactly the right answer and these are things that like literally nobody knew before and GPT4 just wasn't doing that you know I mean these qualitatively new capabilities.

它既是**思维链**，也是团队构建的各种不同的攻击角度。
他们给它提供了科学领域中真正未解决的问题。
在一个特别著名且有些臭名昭著的案例中，它提出了一个假设，但无法验证，因为它无法直接在实验室中进行实验。
但它对**病毒学**中一个困扰科学家多年的开放问题提出了一个假设，碰巧科学家们最近也找到了答案但尚未发表结果，因此就出现了这种巧合：科学家们通过实验验证了，而以AI联合科学家形式出现的Gemini也得出了完全正确的答案，这些都是以前 literally 没人知道的事情，GPT4根本做不到，我的意思是，这些是质量上全新的能力。

That thing I think ran for days.
You know, it probably cost hundreds of dollars, maybe into the thousands of dollars to run the inference.
You know, that's not nothing, but it's also like very much cheaper than, you know, years of grad students.
And if you can get to those caliber of problems and actually get good solutions to them, like, you know, what would you be willing to pay, right, for that kind of thing?

那个东西我想运行了几天。
你知道，运行推理可能花费了数百美元，甚至数千美元。
你知道，这不算少，但它也比，你知道，多年的研究生便宜得多。
如果你能解决那种难度的问题，并且真正得到好的解决方案，那么，你知道，你愿意为那种东西支付多少钱呢？

So, yeah, I don't know.
That's probably not a full appreciation.
We could go on for a long time, but I would say in summary, GPT4 was not able to push the actual frontier of **human knowledge** (Human Knowledge: 人类通过学习、经验和思考积累起来的所有信息、理解和技能).
I don't to my knowledge, I don't know that ever discovered anything new.
It's still not easy to get that kind of output from a GPT5 or a **Gemini 2.5** (Gemini 2.5: 谷歌Gemini系列模型的一个版本) or, you know, a **Claude Opus 4** (Claude Opus 4: Anthropic公司Claude系列模型的一个版本), whatever, but it's starting to happen sometimes.
And that in and of itself is a huge deal.

所以，是的，我不知道。
这可能不是一个充分的评价。
我们可以谈很久，但总而言之，GPT4无法推动**人类知识**的真正前沿。
据我所知，它从未发现过任何新事物。
从GPT5或**Gemini 2.5**，或者**Claude Opus 4**，或其他任何模型中获得那种输出仍然不容易，但它有时开始发生。
而这本身就是一件大事。

### 对GPT5“看跌情绪”的解释

Well, then how do we explain the **bearishness** (Bearishness: 看跌情绪，指对市场或某个事物未来发展持悲观态度) or or the kind of **vibe shift** (Vibe Shift: 指某种文化或社会氛围的显著转变) around GPT5?
Then you know one one potential contributor is this idea that if a lot of the if if the improvements are at the frontier, you know, not everyone is working with you know, sort of advanced math and physics and in a day-to-day and so maybe they don't see the benefits in their day-to-day lives in in the same way that, you know, sort of the jumps in ChatGPT were were were obvious and and shaped the day-to-day.

那么，我们如何解释围绕GPT5的**看跌情绪**或那种**氛围转变**呢？
一个潜在的原因是，如果很多改进都发生在最前沿，那么并不是每个人都在日常工作中接触到高级数学和物理，所以他们可能不会像ChatGPT的飞跃那样，在日常生活中明显感受到益处并改变他们的日常生活。

>> Yeah.
I mean, I think a decent amount of it was that they kind of up the launch, you know, simply put, right?
They like were tweeting Death Star images, which Sam Altman later came back and said, "No, you're the Death Star.
I'm not the Death Star."
But, uh, I think people thought that the Death Star was supposed to be the model.
That was generally the, you know, the expectations were set extremely high.

>> 是的。
我的意思是，我认为很大一部分原因在于他们提升了发布会，简单来说，对吧？
他们当时在推特上发布了死星的图片，Sam Altman后来回来澄清说：“不，你是死星。
我不是死星。”
但是，我认为人们当时认为死星就是指模型。
总的来说，期望值被设定得非常高。

The actual launch itself was just technically broken.
So a lot of people's first experiences of GPT5, they've got this **model router** (Model Router: 一种AI系统，根据用户查询的复杂性或类型，将请求路由到最适合处理的AI模型) concept now where and I think one another way to understand what they're doing here is they're trying to own the consumer use case and to own that they need to simplify the product experience relative to what we had in the past which was like okay you got GPT4 and 40 and 40 mini and 03 and 04 mini and other things you know 45 was in there at one point you got all these different models which one should I use for which?

实际的发布本身在技术上就出了问题。
所以很多人第一次体验GPT5时，他们现在有了**模型路由器**这个概念，我认为理解他们在这里做什么的另一种方式是，他们试图主导消费者用例，而要主导这一点，他们需要简化产品体验，使其与我们过去所拥有的相比更加简单，过去是你有GPT4、40、40 mini、03、04 mini以及其他一些东西，你知道45也曾出现过，你有所有这些不同的模型，我应该用哪个来做什么？

It's like very confusing to most people who aren't obsessed with this.
And so, one of the big things they wanted to do was just shrink that down to just ask your question and you'll get a good answer and we'll take that complexity on our side as the the product owners to do that.
Interestingly, and I don't have a great account of this, but one thing you you might want to do is kind of merge the models and figure out just have the model itself decide how much to think or maybe even, you know, have the model itself decide how many of its experts.

对于大多数不痴迷于此的人来说，这非常令人困惑。
所以，他们想做的一件大事就是将其简化为“只管提问，你会得到一个好的答案”，而我们将作为产品所有者来承担这种复杂性。
有趣的是，我对此没有很好的解释，但你可能想做的一件事是合并模型，让模型自己决定思考多少，甚至，你知道，让模型自己决定需要使用多少专家。

If it's a **mixture of experts** (Mixture of Experts: 一种神经网络架构，其中包含多个“专家”网络，根据输入数据选择性地激活和组合这些专家网络的输出) architecture it needs to use or maybe, you know, there's been a bunch of different research projects on like skipping layers of the model.
If the task is easy enough, you could like skip a bunch of layers.
So you might have hoped that you could genuinely on the back end merge all these different models into one model that would dynamically use the right amount of compute for the level of challenge that a given user query presented.

如果它是一个**专家混合**架构，它需要使用，或者，你知道，有很多关于跳过模型层面的不同研究项目。
如果任务足够简单，你可以跳过很多层。
所以你可能曾希望，你可以在后端真正地将所有这些不同的模型合并成一个模型，该模型会根据给定用户查询所呈现的挑战级别，动态地使用适量的计算资源。

It seems like they found that harder to do than they expected.
And so the solution that they came up with instead was to have a router where the the router's job is to pick is this an easy query in which case we'll send you to this model.
Is it a medium?
Is it a hard?
And I think they just have two really models behind the scenes.
So I think it's just really easy or hard.

看来他们发现这比预期更难做到。
因此，他们提出的解决方案是使用一个路由器，路由器的任务是选择：这是一个简单的查询吗？如果是，我们就把你发送到这个模型。
是中等的吗？
是困难的吗？
我认为他们幕后只有两个真正的模型。
所以我认为它只是非常简单或非常困难。

Certainly the graphs that they showed, you know, basically showed the kind of with and without thinking.
The problem at launch was that that router was broken.
So all all of the queries were going to the dumb model and so a lot of people literally just got bad outputs which were worse than 03 because they were getting non-thinking responses.
And so the initial reaction of like okay this is dumb and that sort of you know traveled really fast.

当然，他们展示的图表，你知道，基本上显示了有思考和无思考两种情况。
发布时的问题是那个路由器坏了。
所以所有的查询都发送到了“笨”模型，因此很多人得到的输出很糟糕，甚至比03版本还差，因为他们得到了非思考性的回应。
所以最初的反应是“这太蠢了”，这种情绪传播得非常快。

I think that kind of set the tone.
My sense now is that as the dust has settled most people do think that it is the best model available and you know things like the **Meter task length chart** (Meter Task Length Chart: 一种衡量AI模型在完成复杂任务时所需时间或步骤的图表，通常显示其效率和能力提升) the infamous Meter task length chart.
It is the best.
You know we're now over two hours and it is still above the trend line.
So if you just said, you know, do I believe in straight lines on graphs or not?

我认为这奠定了基调。
我现在感觉是，尘埃落定后，大多数人确实认为它是目前最好的模型，而且，你知道，像臭名昭著的**Meter任务长度图表**这样的东西。
它是最好的。
你知道，我们现在已经超过两个小时了，它仍然高于趋势线。
所以如果你只是说，你知道，我是否相信图表上的直线？

And how should this latest data point influence whether I believe on these straight line straight lines on, you know, power logarithmic scale graphs.
It shouldn't really change your mind too much.
It's still above the trend line.
I talked to ZV about this.
Zim Mashwitz legendary infovore and AI industry analyst on a recent podcast too and kind of asked him the same question like why do you think the you know even some of the most plugged in you know sharp minds in the space have seemingly pushed timelines out a bit as a result of this and his answer was basically just it resolved some amount of uncertainty you know you had a open question of maybe they do have another breakthrough you know maybe it really is the Death Star.

以及这个最新数据点应该如何影响我是否相信这些在幂对数刻度图上的直线。
它不应该真正改变你的想法太多。
它仍然高于趋势线。
我最近在一个播客中也和ZV谈过这个，Zim Mashwitz是一位传奇的信息狂和人工智能行业分析师，我问了他同样的问题：你认为为什么即使是这个领域最投入、最敏锐的一些人，似乎也因此推迟了时间表？他的回答基本上是，这解决了一些不确定性，你知道，你之前有一个悬而未决的问题，也许他们真的会有另一个突破，你知道，也许它真的是死星。

You know, if they surprise surprise us on the upside than all these short timelines, you know, we we could have expected a um yeah, I guess one one way to think about it is like the the distribution was sort of broad in terms of timelines and if they had surprised on the upside, it might have narrowed and narrowed in toward the front end of the distribution and if it if they surprised on the downside or even just were, you know, purely on trend, then you would take some of your distribution from the very short end of the timelines and kind of push them back toward the middle or the end.

你知道，如果他们给我们带来惊喜，那么所有这些短时间线，我们本可以预期一个……是的，我想一种思考方式是，时间线的分布是相当宽泛的，如果他们带来了惊喜，它可能会收窄并集中在分布的前端；如果他们带来了负面惊喜，或者仅仅是符合趋势，那么你就会把一些非常短的时间线从分布中推回到中间或末端。

And so his answer was like AI 2027 seems less likely, but AI 2030 seems basically no less likely, maybe even a little more likely because some of the the probability mass from the early years is now sitting there.
So it's not that um I don't think people are are moving the whole distribution out super much.
I think there may be more just kind of shrinking the you know it's getting a little tighter because it's maybe not happening quite as soon as it seemed like it might have been.

所以他的回答是，2027年实现人工智能似乎不太可能，但2030年实现人工智能的可能性基本没有降低，甚至可能略有增加，因为早期的一些概率质量现在都集中在那里了。
所以，我认为人们并不是大幅度地推迟了整个分布。
我认为更多的是在收缩，你知道，它变得更紧凑了，因为它可能不会像之前看起来那样快发生。

But I don't think too many people at least that I you know think are really plugged in on this are pushing out too much past 2030 at all.
And by the way you know they obviously there's a lot of disagreement.
The way I kind of have always thought about this sort of stuff is Daario says 2027 Demis says 2030.
I'll take that as my range.
So coming into GPT5, I was kind of in that space.

但我认为，至少在我看来，真正关注此事的很多人并没有将时间线推迟到2030年以后。
顺便说一句，你知道，他们显然存在很多分歧。
我一直以来对这类事情的看法是，Dario说2027年，Demis说2030年。
我将此作为我的范围。
所以进入GPT5时，我大致处于那个区间。

And now I'd say, well, I don't know, Dario's got what what cars does he have up his sleeve?
You know, they just put out 4.1 Opus.
And in that blog post, they said we will be releasing more powerful updates to our models in the coming weeks, so they're due for something pretty soon.
You know, maybe they'll be the ones to surprise on the upside this time, or maybe Google will be.
I wouldn't say 2027 is is out of the question, but yeah, I would say 2030 still looks just as likely as before.

现在我会说，嗯，我不知道，Dario还有什么秘密武器？
你知道，他们刚刚发布了4.1 Opus。
在那篇博客文章中，他们说未来几周将发布更强大的模型更新，所以他们很快就会有新动作。
你知道，也许这次他们会带来惊喜，或者谷歌会。
我不会说2027年不可能，但是的，我会说2030年仍然和以前一样有可能。

And again, from my standpoint, it's like that's still really soon, you know?
So, if we're on track, whether it's 28, 29, 30, I don't really care.
I I I try to frame my own work so that I'm kind of preparing myself and helping other people prepare for what might be the most extreme scenarios and kind of, you know, one of these things where if we aim high and we miss a little bit and we have a little more time, great.
I'm sure we'll have plenty of things to do to use that extra time to be ready for, you know, whatever powerful AI does come online.

再说一次，从我的角度来看，那仍然是非常近的未来，你知道吗？
所以，如果我们按计划进行，无论是28年、29年还是30年，我都不太在意。
我努力规划自己的工作，以便为可能出现的最极端情况做好准备，并帮助他人做好准备，你知道，就像这样，如果我们目标定得高，稍微有点偏差，多了一些时间，那太好了。
我确信我们会有很多事情可以做，利用这些额外的时间来为，你知道，无论何种强大的AI上线做好准备。

But yeah, I guess I don't my worldview hasn't changed all that much as a result of these summer's developments.

但是，是的，我想我的世界观并没有因为今年夏天的这些发展而改变太多。

### AI对就业的影响：生产力与工作性质的转变

>> Anecdotally, I I don't hear as much about AI 2027 or **situational awareness** (Situational Awareness: 指AI系统理解其所处环境、当前任务和相关信息的能力) to the to the same degree.
I I do talk to some people who've just moved it a few years back to to your point.
But um yeah, Dores Cesh had his whole thing around, you know, he still still believes in it, but sort of um you know, maybe because this gap gap in **continual learning** (Continual Learning: 机器学习领域的一个概念，指模型能够持续地从新数据中学习，而不会忘记之前学到的知识) or or something to the effect that um you know, maybe it's just going to be a bit slower to to diffuse and um you know, Meter's paper as you mentioned showed that engineers are less productive and so maybe there's there's less of a sort of concern around um you know, people being replaced in the next next few years in in in in mass.

>> 凭经验来说，我没有听到那么多关于2027年AI或**态势感知**的讨论。
我确实和一些人聊过，他们只是把时间推迟了几年，正如你所说。
但是，是的，Dores Cesh有他自己的观点，你知道，他仍然相信它，但也许是因为**持续学习**方面的差距，或者类似的影响，你知道，也许它只是会扩散得慢一点，而且，你知道，你提到的Meter的论文显示工程师的生产力下降了，所以也许人们对未来几年大规模失业的担忧有所减少。

I think when we spoke maybe a year ago about this or I think you said something like 50% of 50% of jobs.
I'm curious if that's still your your litmus test or how you think about it.
Well, for one thing, I think that Meter paper is worth unpacking a little bit more because this was one of those things that was and I I I'm a big fan of Meter and I have no um you know, no shade on them because I do think do science, publish your results.

我想我们大约一年前谈到这个时，你好像说过50%的50%的工作。
我很好奇这是否仍然是你的试金石，或者你是怎么看待它的。
嗯，首先，我认为那篇Meter的论文值得再深入探讨一下，因为这是那种……我是Meter的忠实粉丝，我没有任何……你知道，没有任何贬低他们的意思，因为我确实认为做科学，发表你的结果。

Like that's good.
You don't have to make every experimental result and everything you put out conform to a narrative.
But I do think it was a little bit um it was a little bit too easy for people who wanted to say that oh this is all nonsense to latch on to that.
And you know again there is there's something there that I would kind of put in the Cal Newport category too where for me maybe the most interesting thing was the users thought that they were faster when in fact they seem to be slower.

这很好。
你不需要让每一个实验结果和你发布的一切都符合某个叙事。
但我确实认为，对于那些想说“哦，这都是胡说八道”的人来说，抓住这一点有点太容易了。
而且，你知道，这里面有一些东西，我也会把它归入Cal Newport的范畴，对我来说，最有趣的事情也许是用户认为他们更快，而实际上他们似乎更慢。

So that sort of misperception of oneself I think is really interesting.
Personally I think there's some explanations for that that include like hitting go on the agent going to social media and scrolling around for a while and then coming back.
The thing might have been done for quite a while by the time I get back.
So honestly one like really simple and we're starting to see this in products.
One really simple thing that the products can do to address those concerns is just provide notifications like the thing is done now.

所以，我认为这种对自我的误解真的很有趣。
我个人认为对此有一些解释，包括点击代理程序运行后，去社交媒体上刷了一会儿，然后才回来。
等我回来的时候，事情可能已经完成很久了。
所以老实说，一个非常简单的办法，我们现在也开始在产品中看到这一点。
产品可以做的一个非常简单的事情来解决这些担忧，就是提供通知，比如“事情已经完成了”。

So, you know, stop scrolling and and come back and check its work.
That in terms of just clock time, you know, it would be interesting to know like what applications did they have open.
Maybe they took a little longer with cursor than doing it on their own, but how much of the time was cursor the active window and how much of it was, you know, some other random distraction while they were waiting.

所以，你知道，停止滚动，回来检查它的工作。
就时钟时间而言，你知道，了解他们打开了哪些应用程序会很有趣。
也许他们使用光标比自己动手花的时间长了一点，但有多少时间是光标作为活动窗口，又有多少时间是，你知道，他们在等待时被其他随机事物分散了注意力。

But I think a more fundamental issue with that study which again wasn't really about the study design but just in in the sort of you know interpretation and kind of digestion of it some of these details got lost.
They they basically tested the models or the you know the product cursor in the area where it was known to be least able to help.
This study was done early this year.
So it was done with you know kind of one depending on how you want to count right a couple couple releases ago with code bases that are large which again strains the strains the context window and you know that's one of the the frontiers that has been moving very mature code bases with like high standards for coding and developers who really know their code bases super well who've made a lot of commit you know commits to these particular code bases.

但我认为这项研究有一个更根本的问题，这与研究设计无关，而是在解释和消化过程中，一些细节被忽略了。
他们基本上是在已知帮助最小的领域测试模型或产品光标。
这项研究是在今年早些时候进行的。
所以它是用，你知道，大约一两个版本之前的模型进行的，代码库很大，这再次考验了上下文窗口，你知道，这是不断发展的前沿之一，这些代码库非常成熟，编码标准很高，开发人员对他们的代码库非常了解，他们对这些特定的代码库进行了大量的提交。

So I would say that's basically the hardest situation that you could set up for an AI because the people know you know their stuff really well.
The AI doesn't the context is huge.
People have already absorbed that through working on it for a long time.
The AI doesn't have that that knowledge and again couple generations ago models.
And then a big thing too is that the user the people were not very well versed in the tools.

所以我会说，这基本上是你能为人工智能设置的最困难的情况，因为人们非常了解自己的东西。
人工智能不了解，上下文非常庞大。
人们通过长时间的工作已经吸收了这些知识。
人工智能没有这些知识，而且这还是几代之前的模型。
另外一个重要问题是，用户对这些工具并不十分熟悉。

Why?
Because the tools weren't really able to help them yet.
I think the sort of mindset of the people that came into the study in many cases was like, well, I haven't used this all that much because it hasn't really seemed to be super helpful.
They weren't wrong in that assessment given the, you know, the limitations.
And you could see that in terms of the um some of the instructions and the help that the Meter team gave to people.

为什么？
因为这些工具当时还不能真正帮助他们。
我认为参与这项研究的人，在很多情况下，他们的心态是：“嗯，我没怎么用过这个，因为它看起来不太有用。”
考虑到当时的局限性，他们的评估并没有错。
你可以从Meter团队给人们的一些指示和帮助中看出这一点。

One of the things that is in the paper that they would if they noticed that you weren't like weren't using cursor super well, they would give you some feedback on how to use it better.
One of the things that they were telling people to do is make sure you at tag a particular file to bring that into context for the model so that the model has you know the right context.
And that's literally like the most basic thing that you would do in cursor you know that's like the thing you would learn on your in your first hour your first day of using it.

论文中提到的一点是，如果他们发现你没有很好地使用光标，他们会给你一些关于如何更好地使用它的反馈。
他们告诉人们做的一件事是，确保你标记一个特定的文件，将其带入模型的上下文，以便模型拥有正确的上下文。
而这实际上是你在光标中最基本的操作，你知道，这就像你使用它的第一个小时或第一天就会学到的东西。

So it really does suggest that these were you know while very capable programmers like basically mostly noviceses when it came to using the AI tools.
So I think the result is real.
But I just I would be very cautious about generalizing too much there in terms of I guess what else was the other question.
It's what is the expectation for jobs?

所以这确实表明，这些人虽然是非常有能力的程序员，但在使用人工智能工具方面基本上是新手。
所以我认为结果是真实的。
但我只是，我会非常谨慎地在那里进行过多的概括，就我猜的另一个问题而言。
那就是对工作的预期是什么？

>> I mean we're starting to see some of this right.
We are definitely seeing no less than like Mark Banoff has said that they've, you know, have been able to cut a bunch of headcount because they've got AI agents now that are responding to every lead.
**Clara** (Clara: 一家提供AI驱动的客户服务解决方案的公司) of course is, you know, has said, um, you know, very similar things for a while now.
They also, I think, have been a little bit misreported in terms of like, oh, they're backtracking off of that because they're actually going to keep some customer service people, not none.

>> 我的意思是，我们开始看到一些这样的情况，对吧？
我们确实看到，Mark Banoff已经说过，他们已经能够削减大量员工，因为他们现在有了AI代理，可以回应每一个潜在客户。
**Clara**当然也，你知道，已经说了很长时间类似的话。
我认为他们也有些被误报了，比如：“哦，他们正在撤回那个说法，因为他们实际上会保留一些客服人员，而不是一个都不留。”

And I think that's a bit of an overreaction.
Like they may have some people who are just, you know, insistent on having a certain experience and maybe they want to provide that and that makes sense.
You know, it doesn't I think you can have a a a spectrum of service offerings to your customers.
I once coded up a pricing page for a I actually just vibe coded up a pricing page for a **SaaS** (SaaS: Software as a Service，软件即服务，一种通过互联网提供软件的模式) company that was like basic level with AI sales and service is one price.

我认为这有点反应过度了。
比如，他们可能有一些客户坚持要获得某种特定的体验，也许他们想提供这种体验，这很合理。
你知道，我认为你可以为客户提供一系列的服务。
我曾经为一个SaaS公司编写了一个定价页面，实际上是凭感觉编写的，其中包含：基础级别，由AI销售和服务，一个价格。

If you want to talk to human sales, that's a higher price.
And if you want to talk to human sales and support, that's a, you know, third higher price.
And so, like, literally, that might be what's going on, I think, in some of these cases.
And it it could very well be a very sensible option for people.
But I just I do see the **Intercom** (Intercom: 一家提供客户消息平台和AI客服解决方案的公司).
I've got an episode coming up with, they now have this **Finn agent** (Finn Agent: Intercom公司推出的一款AI客服代理，能自动解决客户问题) that is solving like 65% of customer service tickets that come in.

如果你想和人工销售交谈，价格更高。
如果你想和人工销售和支持交谈，那价格会更高。
所以，我的意思是，在某些情况下，这可能就是实际情况。
而且这很可能对人们来说是一个非常明智的选择。
但我确实看到了**Intercom**。
我将要发布一期节目，他们现在有了**Finn代理**，可以解决大约65%的客户服务工单。

So, you know, what's that going to do to jobs?
Are there really like three times as many customer service tickets to be handled?
Like, I don't know.
I think there's kind of a relatively inelastic supply.
Maybe you'll get somewhat more tickets if people expect that they're going to get better, faster answers, but I don't think we're going to see like three times more tickets.
By the way, that number was like 55% 3 or four months ago.

所以，你知道，那会对就业产生什么影响？
真的有三倍多的客服工单需要处理吗？
我不知道。
我认为这是一种相对缺乏弹性的供给。
如果人们期望得到更好、更快的答案，也许你会收到更多的工单，但我不认为我们会看到三倍多的工单。
顺便说一句，这个数字在三四个月前大约是55%。

So, you know, as they ratchet that up, the ratios get really hard, right?
At half ticket resolution, in theory, maybe you get some more tickets.
Maybe you don't need to adjust headcount too much.
But when you get to 90% ticket resolution, you know, are you really going to have 10 times as many tickets or 10 times as many hard tickets that the people have to handle?
It seems just really hard to imagine that.

所以，你知道，当他们提高这个比例时，比例会变得非常困难，对吧？
在解决一半工单的情况下，理论上，你可能会收到更多的工单。
也许你不需要调整太多员工数量。
但当你达到90%的工单解决率时，你知道，你真的会有10倍的工单，或者10倍的困难工单需要人工处理吗？
这似乎真的很难想象。

So I don't think I don't think these things go to zero probably in a lot of environments but I do expect that you will see significant headcount reduction in a lot of these places and the software one is really interesting because the **elasticities** (Elasticities: 经济学概念，衡量需求或供给对价格或其他因素变化的敏感程度) are really unknown.
You know, you can potentially produce x times more software per user or, you know, per per cursor user or per developer at your company, whatever.

所以我认为在很多环境中，这些事情可能不会归零，但我确实预计在很多地方你会看到大量裁员，而软件行业的情况非常有趣，因为**弹性**是未知的。
你知道，你可能会为每个用户，或者每个光标用户，或者公司里的每个开发者，生产X倍的软件，诸如此类。

But maybe you want that.
You know, maybe there is no limit or no, you know, maybe the the regime that we're in is such that if there's, you know, 10 times more productivity, that's all to the good.
And, you know, we still have just as many jobs because we want 10 times more software.
I don't know how long that lasts.
Again the ratios start to get challenging at some point.

但也许你想要那样的结果。
你知道，也许没有限制，或者，你知道，我们所处的体制是这样的，如果生产力提高了10倍，那一切都是好事。
而且，你知道，我们仍然有同样多的工作，因为我们想要10倍的软件。
我不知道这种情况能持续多久。
再说一次，在某个时候，这些比例会变得具有挑战性。

But yeah, I think the bottle, you know, the old Tyler Common thing comes to mind.
You are a bottleneck.
You are a bottleneck.
I think more often it is are people really trying to get the most out of these things and you know are they using best practices and have they have they really put their minds to it or not?
I you know often the the real barrier is there.

但是，是的，我想到了泰勒·考恩的老话：“你是一个瓶颈。
你是一个瓶颈。”
我认为更常见的情况是，人们是否真的在努力从这些事物中获得最大收益，他们是否在使用最佳实践，他们是否真的用心去做了？
我，你知道，通常真正的障碍就在那里。

I was I've been working a little bit with a company that is doing basically government doc review.
I'll abstract a little bit away from the details, really gnarly stuff like scanned documents, you know, handwritten filling out of forms.
And they've created this **auditor AI agent** (Auditor AI Agent: 一种人工智能代理，用于自动化审计流程，检查文档和交易的合规性) that just won a state level contract to do the audits on like a million transactions a year of of these um you know these packets of documents again scanned, handwritten, all this kind of crap.

我一直在与一家公司合作，他们主要做政府文件审查。
我将稍微抽象一下细节，处理的是一些非常棘手的东西，比如扫描文件，手写填写的表格。
他们创建了这个**审计AI代理**，刚刚赢得了一份州级合同，每年对大约一百万笔交易进行审计，这些交易涉及的又是扫描的、手写的各种文件。

And they just blew away the human workers that were doing the job before.
So where are those workers going to go?
Like I don't know.
I don't they're not going to have 10 times as many transactions.
You know, I can be pretty confident in that.
Are there going to be a few still that are there to supervise the AIs and handle the weird cases and, you know, answer the phones?
Sure.

他们刚刚击败了以前从事这项工作的人工工人。
那么这些工人会去哪里呢？
我不知道。
他们不会有10倍的交易量。
你知道，对此我可以相当肯定。
还会有少数人留下来监督人工智能、处理异常情况、接听电话吗？
当然。

Maybe they maybe they won't go anywhere.
You know, this the state, you know, the state may do a strange thing and just have all those people like sit around because they can't bear to fire them.
Like, who knows what the ultimate decision will be.
But I do see a lot of these things where I'm just like when you really put your mind to it and you identify what would create real leverage for us, can the AI do that?
Can we make it work?
You can take a pretty large chunk out of high volume tasks very reliably in today's world.

也许他们不会去任何地方。
你知道，这个州，你知道，这个州可能会做一件奇怪的事情，让所有这些人闲坐着，因为他们不忍心解雇他们。
谁知道最终的决定会是什么。
但我确实看到很多这样的事情，我只是觉得当你真正用心去思考并确定什么能为我们创造真正的杠杆作用时，AI能做到吗？
我们能让它发挥作用吗？
在当今世界，你可以非常可靠地从高容量任务中分担相当大一部分工作。

And so the the impacts I think are starting to be seen there on on a lot of jobs.
Humans I think are you know the leadership is maybe the bottleneck or the the will in in a lot of places might be the bottleneck and software might be an interesting case where there is just so much pent-up demand perhaps that it might take a little longer to see those impacts because you really do want you know 10 or 100 times as much software.

所以，我认为这些影响正在很多工作岗位上显现出来。
我认为人类，你知道，领导力可能是瓶颈，或者很多地方的意愿可能是瓶颈，而软件可能是一个有趣的案例，也许存在如此多的积压需求，以至于看到这些影响可能需要更长的时间，因为你确实想要，你知道，10倍或100倍的软件。

### 代码生成：AI发展的重要领域

What is Yeah, let's let's talk about code because it's, you know, it's it's where **Anthropic** (Anthropic: 一家领先的AI安全和研究公司，开发了Claude系列模型) made made a big bet early on, you know, perhaps inspired by the sort of **automated researcher** (Automated Researcher: 指AI系统能够自主进行科学研究，包括提出假设、设计实验、分析数据等) you know, **recursive self-improvement** (Recursive Self-improvement: 指AI系统能够通过自我学习和改进，不断提升自身智能水平的过程) um you know, sort of you, you know, desired future and and we saw OpenAI make make moves there as well.

是的，我们来谈谈代码吧，因为它，你知道，是**Anthropic**早期投入巨大赌注的领域，你知道，也许是受到那种**自动化研究员**，你知道，**递归式自我改进**的未来愿景的启发，而且我们也看到OpenAI在这方面有所行动。

Why don't we flush that out or talk a little about you know what what inspired that and where you see that going?

我们为什么不把这个说清楚，或者稍微谈谈是什么启发了它，以及你认为它会走向何方？

>> You know, utopia or dystopia is really the big question there, I think.
Right.
Right.
I mean is maybe one part technical, two parts social in terms of why code has been so focal.
The technical part is that it's really easy to validate code.
You generate it, you can run it.
If you get a runtime error, you can get the feedback immediately.

>> 你知道，我认为那里真正的大问题是乌托邦还是反乌托邦。
对。
对。
我的意思是，代码之所以如此受关注，可能一部分是技术原因，两部分是社会原因。
技术部分是，验证代码真的很容易。
你生成它，你可以运行它。
如果你得到一个运行时错误，你可以立即得到反馈。

It's, you know, somewhat harder to do **functional testing** (Functional Testing: 软件测试的一种，验证软件功能是否符合需求和规范).
**Replit** (Replit: 一个在线集成开发环境（IDE）和代码托管平台，支持多种编程语言) recently just in the last like 48 hours released their V3 of their agent and it now in addition to you know code code code try to make your app work v2 of the agent would do that and it could go for minutes and you know in some cases generate dozens of files and I've had some magical experiences with that where I was like wow you just did that whole thing in one prompt and it like worked amazing.

你知道，做**功能测试**有点难。
**Replit**最近在过去48小时内发布了其代理的V3版本，现在除了，你知道，代码代码代码尝试让你的应用程序工作之外，代理的V2版本会这样做，它可以运行几分钟，你知道，在某些情况下生成几十个文件，我对此有一些神奇的体验，当时我心想哇，你只用一个提示就完成了整个事情，而且效果惊人。

Other times it will sort of code for a while and hand it off to you and say okay does it look good?
Is it working?
And you're like, "No, it's not.
I'm not sure why."
You know, you get into a a back and forth with it.
But the difference between V2 and V3 is that instead of handing the baton back to you, it now uses a browser and the vision aspect of the models to go try to do the **QA** (QA: Quality Assurance，质量保证) itself.

其他时候，它会编写一段时间代码，然后交给你，问你：“看起来好吗？
能用吗？”
你可能会说：“不，不能用。
我不知道为什么。”
你知道，你就会和它来回沟通。
但V2和V3之间的区别在于，它不再把接力棒交还给你，而是现在使用浏览器和模型的视觉功能去尝试自己进行**质量保证**。

So, it doesn't just say, "Okay, hey, I uh I tried my best, wrote a bunch of code, like let me know if it's working or not."
It takes that first pass at figuring out if it's working.
And you know again that that really improves the **flywheel** (Flywheel: 飞轮效应，指通过初始努力积累动能，然后加速增长的良性循环) just how much you can do, how much you can validate, how quickly you can validate it.
The the speed of that loop is really key to the pace of improvement.
So it's a problem space that's pretty amendable to the sorts of, you know, rapid flywheel techniques.

所以，它不再仅仅是说：“好吧，嘿，我尽力了，写了一堆代码，告诉我它是否有效。”
它会先尝试找出它是否有效。
而且，你知道，这确实改善了**飞轮效应**，即你能做多少，能验证多少，以及你能多快地验证它。
这个循环的速度对于改进的步伐至关重要。
所以这是一个非常适合快速飞轮技术的问题领域。

Second, of course, they they're all coders right at these places.
So they want to, you know, solve their own problems.
That's like very natural.
And third, I do think on the, you know, sort of social vision competition, uh, who knows where this is all going, they do want to create the automated AI researcher.
That's another data point, by the way, from this was from the 03 **system card** (System Card: 一种文档，详细描述AI系统的能力、局限性、风险和缓解措施).

其次，当然，这些地方的人都是程序员。
所以他们想解决自己的问题。
这很自然。
第三，我确实认为，在社会愿景竞争方面，谁知道这一切会走向何方，他们确实想创造自动化的人工智能研究员。
顺便说一句，这是来自03版本**系统卡**的另一个数据点。

They showed a jump from like low to mid single digits to roughly 40% of **PRs** (PRs: Pull Requests，代码合并请求，软件开发中用于提交代码更改的机制) actually checked in by research engineers at OpenAI that the model could do.
So prior to 03 not much at all you know low to mid single digits as of 03 40%.
I'm sure those are the easier 40% or whatever.
Again, there will be, you know, caveats to that, but that's you're entering maybe the steep part of the **S-curve** (S-curve: S形曲线，描述技术或产品采纳率随时间增长的模式，初期缓慢，中期加速，后期趋缓) there.

他们展示了一个飞跃，从低到中个位数，跃升到大约40%的**拉取请求**（PRs）实际上是由OpenAI的研究工程师检查并由模型完成的。
所以在03版本之前，几乎没有，你知道，低到中个位数，而到了03版本，达到了40%。
我确信那些是比较容易的40%或者其他什么。
再说一次，这会有一些限制，但你可能正在进入**S曲线**的陡峭部分。

And that's presumably pretty high-end.
You know, I don't know how many easy problems they have at OpenAI, but presumably, you know, not that many relative to the rest of us that are out here making generic web apps all the time.
So, you know, at 40% you got to be starting to, I would think, get into some pretty hard tasks, some pretty high value stuff, you know, at that at what point does that ratio really start to tip where the AI is like doing the bulk of the work?

那大概是相当高端的。
你知道，我不知道OpenAI有多少简单的问题，但想必，你知道，相对于我们这些一直在制作通用网络应用的人来说，并不多。
所以，你知道，达到40%的时候，我想你已经开始处理一些相当困难的任务，一些非常有价值的东西，你知道，在那个时候，人工智能开始承担大部分工作，这个比例真正开始倾斜到什么程度？

GPT5 notably wasn't a big update over 03 on that particular measure.
I mean it also wasn't going back to the Simple QA thing.
GPT5 is generally understood to not be a scale up relative to 40 and 03 and you can see that in the Simple QA measure.
It basically scores the same on these longtail trivia questions.
It's not a bigger model that has absorbed like lots more world knowledge.

值得注意的是，GPT5在那个特定指标上并没有比03版本有大的更新。
我的意思是，它也没有回到Simple QA的问题上。
GPT5通常被认为相对于40和03版本并没有进行规模扩展，你可以在Simple QA的衡量中看到这一点。
它在这些长尾冷知识问题上得分基本相同。
它不是一个吸收了更多世界知识的更大模型。

It is it is you know Cal is right.
I think it is is analysis that it's it's post-training.
But that post-training you know is potentially entering the steep part of the S-curve when it comes to the ability to do even the kind of hard problems that are happening at OpenAI on the research engineering front.
And you know, yikes.
I I'm a little worried about that, honestly.

是的，Cal是对的。
我认为他的分析是，这是**后训练**。
但是这种后训练，你知道，在解决OpenAI研究工程前沿所遇到的那种难题的能力方面，可能正在进入S曲线的陡峭部分。
而且，你知道，天哪。
老实说，我对此有点担心。

The the idea that we could go from these companies having a few hundred research engineer people to having, you know, unlimited overnight and like what would that mean in terms of how much things could change and also just our ability to steer that overall process.
I'm not super comfortable with the idea of the companies tipping into a **recursive self-improvement regime** (Recursive Self-improvement Regime: 指AI系统通过不断自我学习和优化，实现智能水平的指数级增长，可能导致超智能的出现), especially given the the level of control and the level of unpredictability that we currently see in the models.

这些公司可能从拥有几百名研究工程师，一夜之间变成拥有无限数量的工程师，这意味着事情会发生多大的变化，以及我们引导整个过程的能力。
我不太适应公司进入**递归式自我改进模式**的想法，特别是考虑到我们目前在模型中看到的控制水平和不可预测性。

But that does seem to be what they are going for.
So, in terms of like why um I think this has been the plan for quite some time.
Even you remember that leaked **Anthropic fundraising deck** (Anthropic Fundraising Deck: Anthropic公司泄露的融资演示文稿，其中包含对AI未来发展和竞争格局的预测) from maybe two years ago where they said that in 2025 and 2026 the companies that train the best models will get so far ahead that nobody else will be able to catch up.

但这似乎确实是他们追求的目标。
所以，就原因而言，我认为这计划已经存在相当长一段时间了。
你甚至还记得大约两年前泄露的**Anthropic融资演示文稿**，其中提到在2025年和2026年，训练出最佳模型的公司将遥遥领先，以至于其他公司都无法追赶。

I think that's kind of what they meant.
I think that they were projecting then that in the 25 26 time frame they'd get this like automated researcher and once you have that how's anybody you know who doesn't have that going to catch up with you?
Obviously some of that remains to be validated, but I do think they have been pretty intent on that for a long time.
Five years from now, are there more engineers or fewer engineers?

我想这大概就是他们的意思。
我认为他们当时预测在25、26年时间框架内，他们会拥有这种自动化研究员，一旦你拥有了它，你知道，那些没有它的人怎么能追上你呢？
显然，其中一些还有待验证，但我确实认为他们长期以来一直非常专注于此。
五年后，工程师会更多还是更少？

>> I I tend to think less.
You know, already if I just think about my own life and work, I'm like, would I rather have a model or would I rather have like a junior marketer?
I'm pretty sure I'd rather have the model.
Would I rather have the models or a junior engineer?
I think I'd probably rather have the models in a lot of cases.
I mean, it obviously depends on, you know, the exact person you're talking about.

>> 我倾向于认为会更少。
你知道，如果我只是想想自己的生活和工作，我就会想，我宁愿要一个模型，还是宁愿要一个初级营销人员？
我很确定我宁愿要模型。
我宁愿要模型还是一个初级工程师？
我想在很多情况下，我可能宁愿要模型。
我的意思是，这显然取决于，你知道，你具体谈论的是哪个人。

But truly forced choice today.
Now, that and then you've got cost adjustment as well, right?
I'm not spending nearly as much on my cursor subscription as I would be on a, you know, an actual human engineer.
So, even if they have some advantages, you know, and I I also have not scaffolded I haven't gone full co-scientist, right, on my cursor problems.

但今天确实是强制选择。
现在，还有成本调整，对吧？
我在光标订阅上的花费远不及雇佣一名真正的人类工程师。
所以，即使他们有一些优势，你知道，而且我也还没有在我的光标问题上完全采用联合科学家式的**脚手架**。

I think that that's another interesting you start to see why folks like Sam Altman are so focused on questions like energy and the 7 trillion buildout because these **power law** (Power Law: 幂律，指一个变量的变化与另一个变量的某个幂次成比例的现象，常用于描述某些自然和社会现象的分布) things are weird and you know to get incremental performance for 10x the cost is weird.
It's it's a it's definitely not the kind of thing that we're used to dealing with, but for many things it might be worth it and it still might be cheaper than the human alternative.

我认为这是另一个有趣之处，你开始明白为什么像Sam Altman这样的人如此关注能源和7万亿美元建设等问题，因为这些**幂律**现象很奇怪，你知道，以10倍的成本获得增量性能是很奇怪的。
这确实不是我们习惯处理的事情，但对于许多事情来说，它可能值得，而且仍然可能比人工替代方案更便宜。

You know, if it's like, well, cursor cost me whatever 40 bucks a month or something.
Would I pay 400 for, you know, however much better?
Yeah, probably.
Would I pay 4,000 for however much better?
Well, it's still, you know, a lot less than a full-time human engineer.
And the costs are obviously coming down dramatically, too, right?
That's another huge thing.
GPT4 was way more expensive.
It's like 90 uh it's like a 95% discount from GPT4 to GPT5.

你知道，如果光标每月花我40美元左右。
我会不会花400美元来获得更好的体验？
是的，很可能。
我会不会花4000美元来获得更好的体验？
嗯，那仍然比一个全职的人类工程师便宜得多。
而且成本显然也在大幅下降，对吧？
那是另一个巨大的变化。
GPT4要贵得多。
从GPT4到GPT5，折扣高达90%……哦，是95%的折扣。

That's, you know, no small thing, right?
I mean, it's Apple staff is a little bit hard because the **chain of thought** (Chain of Thought: 一种提示技术，通过让AI模型逐步展示其推理过程来提高复杂任务的解决能力) does spit out a lot more tokens and so that you get you give back a little on a per token basis.
It's dramatically cheaper.
More tokens generated.
You know, does does eat back into some of that savings, but everybody seems to expect the trends will continue in terms of prices continuing to fall.

你知道，这可不是小事，对吧？
我的意思是，苹果员工有点难，因为**思维链**确实会吐出更多的token，所以你在每个token的基础上会损失一点。
它便宜得多。
生成了更多的token。
你知道，这确实会蚕食一部分节省下来的成本，但每个人似乎都预计价格会持续下降的趋势将继续下去。

And so, you know, how many more of these like price reductions do you have to to then be able to, you know, do the power law thing a few more times?
I guess I think I think I I think less.
And I I think that's probably true even if we don't get like full-blown **AGI** (AGI: Artificial General Intelligence，通用人工智能，指AI系统能够像人类一样理解、学习和应用智能来解决任何智力任务) that's, you know, better than humans at everything.

所以，你知道，你还需要多少次这样的降价，才能，你知道，再做几次幂律的事情？
我想我，我想我，我想会更少。
而且我认为即使我们没有得到像**通用人工智能**那样，你知道，在所有方面都比人类更好的东西，这可能也是真的。

I think you could easily imagine a situation where of however many million people are currently employed as professional software developers, some top tier of them that do the hardest things can't be replaced.
But there's not that many of those, you know, they and the the real like rank and file, you know, the people that over the last 20 years were told learn to code, you know, that'll be your thing.
Like the people that are the really top top people didn't need to be told to learn to code, right?
They just it was their thing.
They had a passion for it.
They were amazing at it.

我认为你可以很容易地想象这样一种情况：在目前数百万专业软件开发人员中，少数顶尖的、从事最困难工作的人是无法被取代的。
但这样的人并不多，你知道，他们，以及那些真正的普通员工，你知道，过去20年被告知“学习编程，那将是你的事业”的人。
那些真正顶尖的人不需要被告知去学习编程，对吧？
那只是他们的兴趣。
他们对此充满热情。
他们在这方面表现出色。

We may not, it wouldn't wouldn't shock me if we like still can't replace those people in three, four, five years' time, but I would be very surprised if you can't get your **nuts and bolts** (Nuts and bolts: 指事物的基本要素或核心部分) web app, mobile app type things spit out for you for far less and far faster than and probably honestly with significantly higher quality and less back and forth with an AI system than, you know, with your kind of middle of the pack developer in that time frame.

我们可能不会，如果三、四年、五年内我们仍然无法取代那些人，我不会感到震惊，但我会非常惊讶，如果你不能以远低于、远快于，而且老实说，可能以显著更高的质量和更少的来回沟通，通过AI系统为你生成**基础**的网页应用、移动应用之类的东西，而不是在那段时间内与你那种中等水平的开发者合作。

One thing I do want to call out, you know, there are definitely people have concerns about progress moving too fast, but there's also concern and maybe it's rising about progress not moving fast enough in the sense that um you know a third of the stock market is is **Mag 7** (Mag 7: Magnificent Seven，指美国股市中七家市值最大的科技公司，如苹果、微软、谷歌、亚马逊、英伟达、特斯拉、Meta) um you know **AI capex** (AI Capex: 人工智能领域的资本支出，指企业在AI硬件、软件和基础设施上的投资) is you know over 1% of **GDP** (GDP: Gross Domestic Product，国内生产总值).
And so we are kind of relying on some of this progress in order to sort of estain our sustain our economy.

我想指出一点，你知道，肯定有人担心进展太快，但也有人担心，而且这种担心可能正在加剧，即进展不够快，因为，你知道，股市的三分之一是**七巨头**，**AI资本支出**，你知道，超过**GDP**的1%。
所以我们有点依赖这些进展来维持我们的经济。

>> Yeah.
And with the um you know another thing that I would say has been slower to materialize than I would have expected are **AI culture wars** (AI Culture Wars: 指围绕AI技术、伦理、社会影响等问题在公众和政策制定者之间产生的激烈争论和分歧) or you know sort of the the ramping up of **protectionism** (Protectionism: 贸易保护主义，指国家通过关税、配额等手段限制进口，保护国内产业) of various industries.
We just saw Josh Hawley I don't know if he introduced a bill or just said he intends to introduce a bill to ban **self-driving cars** (Self-driving Cars: 自动驾驶汽车，指能够感知环境并自主导航的车辆) nationwide.

>> 是的。
而且，你知道，另一件我认为比我预期实现得更慢的事情是**AI文化战争**，或者说各种行业的**保护主义**的加剧。
我们刚刚看到Josh Hawley，我不知道他是否已经提出法案，还是仅仅表示打算提出一项法案，要在全国范围内禁止**自动驾驶汽车**。

>> Um you know God help me.
I've dreamed of self-driving cars since I was a little kid.
Truly, like sitting at red lights, I used to be like, there's got to be a way.
I think we took away together.

>> 嗯，天哪。
我从小就梦想着自动驾驶汽车。
真的，就像坐在红灯前，我以前会想，一定有办法的。
我想我们一起拿走了。

>> Yeah.
And it's it's so good.
And the safety, you know, no, I think whenever people want to argue about jobs, it's going to be pretty hard to say 30,000 Americans should die every year so that people's incomes don't get disrupted.
It seems like you have to be able to get over that hump and say like the, you know, saving all these lives if nothing else is just really hard to argue against.

>> 是的。
而且它太好了。
安全方面，你知道，不，我认为每当人们想争论就业问题时，很难说每年应该有3万美国人死亡，这样人们的收入才不会受到干扰。
似乎你必须能够克服那个障碍，并说，你知道，如果什么都不做，仅仅挽救所有这些生命就真的很难反驳。

But we'll see, you know, I mean, he's not without influence obviously.
So yeah, I mean I am very much on **team abundance** (Team Abundance: 指支持通过技术进步实现资源丰富和普遍繁荣的理念) and you know my old mantra I've been saying this less lately but **adoption accelerationist hyperscaling pauser** (Adoption Accelerationist Hyperscaling Pauser: Nathan Labenz自创的口号，意指他支持AI的快速采用和超大规模发展，但同时主张在某些方面暂停或谨慎行事，以确保安全和负责任的部署).
The tech that we have you know could do so so much for us even as is I think if if progress stopped today I still think we could get to 50 to 80% of work automated over the next like five to 10 It would be a real **slog** (Slog: 艰难而辛苦的工作或过程).

但我们会拭目以待，你知道，我的意思是，他显然并非没有影响力。
所以，是的，我非常支持**丰裕团队**，你知道，我以前的口号最近说得少了，但那就是**采用加速主义、超大规模化暂停者**。
我们现有的技术，你知道，即使是现在，也能为我们做很多很多事情。我认为如果今天进步停止，我仍然认为我们可以在未来五到十年内实现50%到80%的工作自动化。这将是一项真正的**苦差事**。

You'd have a lot of, you know, **co-scientist type breakdowns** (Co-scientist Type Breakdowns: 指将复杂任务分解成AI可以辅助或自动完成的子任务，类似于Google AI联合科学家的工作方式) of complicated tasks to do.
You'd have a lot of work to do to go sit and watch people and say, "Why are you doing it this way?
What's going on here?
What's this?
You handled this one differently?
Why did you handle that one differently?"
All this **tacet knowledge** (Tacet Knowledge: 隐性知识，指难以言传、通过经验和实践获得的技能和理解) that people have and the kind of knowhow, procedural um you know, just instincts that they've developed over time, those are not documented anywhere.

你将有很多，你知道，像**联合科学家式分解**的复杂任务要做。
你将有很多工作要做，去坐下来观察人们，然后说：“你为什么这样做？
这里发生了什么？
这是什么？
你处理这个的方式不同？
你为什么处理那个的方式不同？”
所有这些人们拥有的**隐性知识**，以及他们随着时间发展出来的诀窍、程序性的，你知道，只是本能，这些都没有被记录下来。

They're not in the training data.
So the AI haven't had a chance to learn them.
But again, no, if I when I say like no breakthroughs, I I still am allowing there for like, you know, **fine-tuning** (Fine-tuning: 在预训练模型的基础上，使用特定任务的数据进行进一步训练，以提高模型在该任务上的表现) of things to just like capabilities we have that haven't been applied to particular problems yet.

它们不在训练数据中。
所以人工智能没有机会学习它们。
但再说一次，不，当我说没有突破时，我仍然允许对我们已有的能力进行**微调**，这些能力尚未应用于特定问题。

So just going through the economy and and just sitting with people and being like why are you doing this?
You know, let's let's document this.
Let's get the you know, the model to learn your particular niche thing.
That would be a real **slog** (Slog: 艰难而辛苦的工作或过程) and in some ways I kind of wish that were the future that we were going to get.
Because it would be a methodical, you know, kind of one step, one foot in front of the other, you know, no **quantum leaps** (Quantum Leaps: 量子飞跃，指突然的、巨大的、非线性的进步).
Like it would probably feel pretty manageable, I would think, in terms of the pace of change.

所以，只是在经济中穿梭，和人们坐在一起，问他们：“你为什么这样做？”
你知道，让我们记录下来。
让我们让模型学习你的特定小众事物。
那将是一个真正的**苦差事**，在某些方面我甚至希望那才是我们即将迎来的未来。
因为它将是一个有条不紊的，你知道，一步一个脚印的，没有**量子飞跃**的。
我想，就变化的速度而言，它可能会感觉相当可控。

Hopefully society could, you know, could absorb that and kind of adapt to it as we go without, you know, one day to the next like, oh my god, you know, all the drivers, you know, are are getting replaced or that one would be a little slower because you do have to have the actual physical buildout.
But in some of these things, you know, **customer service** (Customer Service: 客户服务，指企业为客户提供的支持和帮助) could get rampant down real fast, right?
Like if a **call center** (Call Center: 呼叫中心，处理客户电话咨询和服务的机构) has something that they can just drop in and it's like this thing now answers the phones and talks like a human and has a higher success rate and scales up and down.

希望社会能够，你知道，能够吸收并适应它，而不是像一夜之间，天哪，所有的司机，你知道，都被取代了，或者那个会慢一点，因为你确实需要实际的物理建设。
但在某些方面，你知道，**客户服务**可能会迅速普及，对吧？
就像如果一个**呼叫中心**有一个可以立即投入使用的东西，它现在可以接听电话，像人类一样交谈，并且有更高的成功率，可以根据需求扩展和收缩。

One thing we've seen at **Wayark** (Wayark: 提及的公司名，可能是一个AI或科技公司), small company, right?
We've always prided ourselves on customer service.
We do a really good job with it.
Our customers really love our customer success team.
But I looked at our **Intercom data** (Intercom Data: Intercom平台收集的客户互动数据，用于分析客户服务效率和客户行为) and it takes us like half an hour to resolve tickets.
We respond really fast.
We respond in like under two minutes most of the time.
But when we respond, you know, 2 minutes is still long enough that the person has gone on to do something else, right?

我们在**Wayark**这家小公司看到了一个现象，对吧？
我们一直以客户服务为傲。
我们做得非常好。
我们的客户非常喜欢我们的客户成功团队。
但我查看了我们的**Intercom数据**，发现我们解决工单需要大约半小时。
我们响应速度很快。
大多数时候我们能在两分钟内响应。
但当我们响应时，你知道，两分钟仍然足够长，以至于客户已经去做其他事情了，对吧？

It's the same thing as with the cursor thing that we were talking about earlier, right?
They've tabbed over to something else.
So now we get the response back in two minutes, but they are doing something else.
So then they come back at, you know, minute six or whatever.
And then they respond.
But now our person has gone and done something else.
So the resolution time even for like simple stuff can be easily a half an hour and the AI, you know, it just responds instantly, right?

这和我们之前谈到的光标问题是一样的，对吧？
他们已经切换到其他事情了。
所以现在我们两分钟内得到了回复，但他们正在做其他事情。
所以他们会在，你知道，第六分钟左右回来。
然后他们回复。
但现在我们的人已经去做了其他事情。
所以即使是简单的事情，解决时间也很容易达到半小时，而人工智能，你知道，它只是立即响应，对吧？

So you don't have to have that kind of back and forth.
You're just in and out.
So I do think some of these categories could be really fast changes.
Others will be slower.
But yeah, I mean, I kind of wish we had that um I kind of wish we had that slower path in front of us.
My best guess though is that we will probably continue to see things that will be significant leaps and that there will be like actual disruption.

所以你不需要那样来回沟通。
你就是进出。
所以我确实认为其中一些类别可能会发生非常快速的变化。
其他则会较慢。
但是，是的，我的意思是，我有点希望我们能走那条慢一点的路。
不过，我最好的猜测是，我们可能会继续看到重大的飞跃，并且会出现实际的颠覆。

### 多模态AI的崛起与新发现

Another one that's come to mind recently, you know, maybe we can get the **abundance department** (Abundance Department: 虚指一个致力于通过技术实现资源丰裕和解决全球问题的部门) on these new **antibiotics** (Antibiotics: 抗生素，用于治疗细菌感染的药物).
Have you seen this development?
No.
Tell us about it.
I mean, it's not a language model.
I think that's another thing people really underappreciate or that you you could kind of look back at GPT4 to 5 and then imagine a pretty easy extension of that.

最近我想到的另一个例子是，你知道，也许我们可以让**丰裕部门**关注这些新的**抗生素**。
你看到这个进展了吗？
没有。
给我们讲讲吧。
我的意思是，它不是一个语言模型。
我认为这是人们真正低估的另一件事，或者你可以回顾GPT4到5，然后想象一个相当容易的扩展。

So, GPT4 initially when it launched the we didn't have image understanding capability.
They did demo it at the time of the launch, but it wasn't released for some months later.
The first version that we had could understand images, could do a pretty good job of understanding images, still with like jagged capabilities and whatever.
Now with the new **Nano Banana** (Nano Banana: 谷歌开发的一个图像生成和编辑模型) from Google, you have this like basically Photoshop level ability to just say, "Hey, take this thumbnail."

所以，GPT4最初发布时，我们没有图像理解能力。
他们在发布时确实演示了，但几个月后才发布。
我们拥有的第一个版本可以理解图像，在理解图像方面做得相当不错，但仍然存在能力不均衡等问题。
现在有了谷歌新的**Nano Banana**，你基本上拥有了Photoshop级别的能力，可以简单地说：“嘿，拿这个缩略图。”

Like we could take our two feeds right now, you know, take a snapshot of you, a snapshot of me, put them both into Nano Banana and say, generate the thumbnail for the YouTube preview featuring these two guys, put them in the same place, same background, whatever.
It'll mash that up.
You can even have it, you know, put text on top, progress since GPT4, whatever we want to call it.
GPT5 is not a bust.
And it'll spit that out.

就像我们现在可以截取我们的两个画面，你知道，拍下你的快照，我的快照，把它们都放到Nano Banana里，然后说，为YouTube预览生成一个缩略图，上面有这两个人，把他们放在同一个位置，同一个背景，随便什么。
它会把这些混合起来。
你甚至可以让它，你知道，在上面放上文字，GPT4以来的进展，随便我们怎么称呼它。
GPT5不是失败品。
然后它就会吐出来。

And you see that it has this deeply integrated understanding that bridges language and image.
And that's something that it can take in, but now it's also something it can put out as all as part of one core model with like a single unified intelligence that I think is going to come to a lot of other things.
We're at the point now with these **biology models** (Biology Models: 专门用于生物学研究和发现的AI模型) and **material science models** (Material Science Models: 专门用于材料科学研究和发现的AI模型) where they're kind of like the image generation models of a couple years ago.

你会看到它拥有这种深度整合的理解，连接了语言和图像。
这不仅是它能够接收的信息，现在它也能够作为单一核心模型的一部分输出，拥有统一的智能，我认为这将应用于许多其他领域。
我们现在在**生物学模型**和**材料科学模型**方面，它们有点像几年前的图像生成模型。

They can take a real simple prompt and they can do a generation, but they're not deeply integrated where you can have like a true conversation back and forth and have that kind of unified understanding that bridges language and these other modalities.
But even so, it's been enough for this group at MIT to use some of these relatively, you know, narrow **purpose-built biology models** (Purpose-built Biology Models: 专门为特定生物学任务或领域设计的AI模型) and create totally new antibiotics.

它们可以接受一个非常简单的提示并进行生成，但它们没有深度集成，无法进行真正的来回对话，也无法拥有那种连接语言和其他模态的统一理解。
但即便如此，麻省理工学院的这个团队已经足以利用一些相对狭窄的**专用生物学模型**，创造出全新的抗生素。

New in the sense that they have a new **mechanism of action** (Mechanism of Action: 药物或治疗发挥作用的具体生物学途径或方式) like they're they're affecting the bacteria in a new way.
And notably, they they do work on **antibiotic resistant bacteria** (Antibiotic Resistant Bacteria: 对多种抗生素产生抗药性的细菌，是全球公共卫生面临的严峻挑战).
This is some of the first new antibiotics we've had in a long time.
Now they're going to have to go through, you know, when I say that get the **abundance department** (Abundance Department: 虚指一个致力于通过技术实现资源丰富和解决全球问题的部门) on it, it's like where's my **Operation Warp Speed** (Operation Warp Speed: 美国政府在COVID-19疫情期间启动的疫苗和治疗方法加速开发计划) for these new antibiotics, right?

它们之所以新，是因为它们具有新的**作用机制**，比如它们以新的方式影响细菌。
值得注意的是，它们确实对**抗生素耐药细菌**有效。
这是我们很长时间以来首次获得的新抗生素。
现在它们必须经过，你知道，当我说让**丰裕部门**介入时，就像是我的**曲速行动**在哪里，用于这些新抗生素，对吧？

Like we've got people dying in hospitals from drug resistant strains all the time.
Why is nobody, you know, crying about this?
I think one of the things that's happening to our society in general is just so many things are happening at once.
It's kind of the it's like the **flood the zone** (Flood the Zone: 饱和攻击，指在某个领域投入大量资源，使其迅速取得突破或压倒性优势) thing except like there's so many AI developments flooding the zone that nobody can even keep up with all of those.

就像我们医院里总有人死于耐药菌株一样。
为什么没有人，你知道，为此哭泣？
我认为我们社会普遍发生的一件事就是同时发生太多事情。
这有点像**饱和攻击**，只不过有太多人工智能发展涌入这个领域，以至于没有人能跟上所有这些进展。

And that's that's come for me by the way too.
I would say two years ago I was like pretty in command of all the news and a year ago I was starting to lose it and now I'm like wait a second there was new antibiotics developed you know and I'm kind of um missing things you know just like everybody else despite my best efforts.
But key point there is AI is not synonymous with language models.
There are AIs being developed with pretty similar architectures for a wide range of different modalities.

顺便说一句，这对我来说也是如此。
我想说两年前我还能掌控所有新闻，一年前我开始跟不上，现在我甚至会想，等等，有新的抗生素被开发出来了，你知道，我有点遗漏了信息，就像其他人一样，尽管我尽了最大努力。
但关键是，人工智能不等于语言模型。
正在开发的人工智能，其架构与语言模型非常相似，适用于各种不同的模态。

We have seen this play out with text and image where you had your text only models and you had your image only models and then they started to come together and now they've come really deeply together.
And so I think you're going to see that across a lot of other modalities over time as well.
And there's a lot more data there.
You know, we might I don't know what it means to like run out of data.
In the **reinforcement learning paradigm** (Reinforcement Learning Paradigm: 强化学习范式，指AI系统通过与环境互动，根据奖励和惩罚来学习最优行为策略), there's always more problems, right?

我们已经看到文本和图像领域的情况，最初只有文本模型和图像模型，然后它们开始融合，现在已经深度融合。
所以我认为随着时间的推移，你也会在许多其他模态中看到这种情况。
而且那里有更多的数据。
你知道，我不知道“数据耗尽”意味着什么。
在**强化学习范式**中，总有更多的问题，对吧？

There's always some something to go figure out.
There's always something to go engineer.
The feedback is starting to come from reality, right?
That was one of the things Elon talked about on the **Groc 4** (Groc 4: 马斯克旗下xAI公司开发的AI模型) launch was like maybe we're running out of problems we've already solved and you know, we only have so much of those sitting around in inventory.
You only have one internet, you know, we only have so much of that stuff.

总有一些事情要去弄清楚。
总有一些东西要去设计。
反馈开始来自现实，对吧？
那是埃隆在**Groc 4**发布会上谈到的事情之一，他说也许我们正在耗尽已经解决的问题，你知道，我们库存中只有那么多。
你只有一个互联网，你知道，我们只有那么多东西。

But over at Tesla, over at SpaceX, like we're solving hard engineering problems on a daily basis, and they seem to be never ending.
So when we start to give the next generation of the model these power tools, the same power tools that the professional engineers are using at those companies to solve those problems and the AI start to learn those tools and they start to solve previously unsolved engineering problems, like that's going to be a really powerful signal that they will be able to learn from.

但在特斯拉，在SpaceX，我们每天都在解决困难的工程问题，而且这些问题似乎永无止境。
所以，当我们开始赋予下一代模型这些强大的工具，这些工具与专业工程师在这些公司中用来解决问题的工具相同，并且人工智能开始学习这些工具，它们开始解决以前未解决的工程问题时，这将是一个非常强大的信号，它们将能够从中学习。

And now again fold in that those other modalities right the ability to have sort of a **sixth sense** (Sixth Sense: 第六感，比喻一种超越常规感官的直觉或洞察力) for you know the space of **material science possibilities** (Material Science Possibilities: 材料科学领域中各种潜在的发现和应用，通常涉及新材料的合成、性能优化等) when you can bridge or or unify the understanding of language and those other things I think you start to have something that looks kind of like super intelligence even if it's like not able to you know write poetry at a **superhuman level** (Superhuman Level: 超人类水平，指能力远超普通人类的水平) necessarily its ability to see in these other spaces is going to be truly a superhuman thing that I think will be pretty hard to miss.

现在再次融入其他模态，对吧，当你能够连接或统一语言和这些其他事物的理解时，对**材料科学可能性**领域拥有某种**第六感**的能力，我认为你就会开始拥有某种看起来像超级智能的东西，即使它不一定能达到**超人类水平**来写诗，它在这些其他领域的能力将真正达到超人类水平，我认为这将很难被忽视。

>> You said that that was one thing that Cal's analysis missed is just the lack of appreciation for non-language modalities and and how they're driving some of the innovations that you're talking about.

>> 你说那是Cal的分析遗漏的一点，就是对非语言模态以及它们如何推动你所谈论的一些创新的缺乏认识。

>> Yeah.
I think people are often just kind of equating the **chatbot experience** (Chatbot Experience: 聊天机器人体验，指用户与AI聊天机器人互动的感觉和效果) with AI broadly.

>> 是的。
我认为人们常常只是将**聊天机器人体验**与广义上的人工智能混为一谈。

>> Yeah.

>> 是的。

>> And you know that that that **conflation** (Conflation: 混淆，指将两个或多个不同的概念或事物错误地合并为一个) will not last probably too much longer because we are going to see self-driving cars unless they get banned.
And that's a you know very different kind of thing.
And talk about your impact on jobs too, right?
It's like what four or five million professional drivers in the United States.
That is a big that is a big deal.
I don't think most of those folks are going to be super keen to learn to code and even if they do learn to code, you know, I'm not sure how long that's going to last.

>> 而且你知道，那种**混淆**可能不会持续太久，因为我们将会看到自动驾驶汽车，除非它们被禁止。
那是一种非常不同的东西。
而且也谈谈它对就业的影响，对吧？
就像美国有四五百万职业司机。
那是一件大事，一件非常大的事。
我不认为这些人中的大多数会非常热衷于学习编程，即使他们真的学习了编程，你知道，我也不确定那能持续多久。

So that's going to be a disruption.
And then **general robotics** (General Robotics: 通用机器人，指能够执行多种任务并在不同环境中适应的机器人) is like not that far behind.
You know, the and this is one area where I do think China might be actually ahead of the United States right now, but regardless of whether that's true or not, you know, these robots are getting really quite good, right?
They can like walk over all these obstacles.
I mean, these are things that a few years ago they just couldn't do at all.

所以那将是一个颠覆。
然后**通用机器人**也紧随其后。
你知道，这是我确实认为中国目前可能领先于美国的一个领域，但无论这是否属实，你知道，这些机器人确实变得相当好，对吧？
它们可以像跨越所有这些障碍一样行走。
我的意思是，这些是几年前它们根本做不到的事情。

You know, they they could barely balance themselves and walk a few steps under ideal conditions.
Now you've got things that you can like literally do a flying kick and it'll like absorb your kick and shrug it off and just keep going.
You know, write itself and and uh continue on its way.
Super rocky, you know, uneven terrain, all these sorts of things are getting quite good.

你知道，它们在理想条件下几乎无法保持平衡并走几步。
现在你有了可以像字面上一样进行飞踢的东西，它会吸收你的踢击，然后不以为意地继续前进。
你知道，它会自己写代码，然后继续前进。
超级崎岖不平的地形，所有这些东西都变得相当好。

You know, the same thing is working everywhere.
I think one of the other thing that's kind of there's always a lot of detail to the work.
So it's it's a sort of **inside view, outside view** (Inside View, Outside View: 两种不同的视角，内部视角关注细节和具体情况，外部视角关注整体趋势和统计规律), right?
Inside view, you're like there's always this minutia.
There's always, you know, these problems that we had and things we had to solve, but you zoom out and it looks to me like the same basic pattern is working everywhere.

你知道，同样的事情在各地都在发生。
我认为另一件事是，工作总是有很多细节。
所以这是一种**内部视角，外部视角**，对吧？
内部视角，你会觉得总有这些细枝末节。
总有，你知道，我们遇到的这些问题和我们必须解决的事情，但你放大来看，在我看来，同样的基本模式在各地都在发挥作用。

And that is like if we can just gather enough data to do some **pre-training** (Pre-training: 在大量通用数据上对AI模型进行初步训练，使其学习广泛的知识和能力), you know, some kind of raw rough, you know, not very useful, but just enough at least to kind of get us going, then we're in the game.
And then once we're in the game now we can do this **flywheel thing** (Flywheel Thing: 飞轮效应，指通过初始努力积累动能，然后加速增长的良性循环) of like, you know, **rejection sampling** (Rejection Sampling: 一种蒙特卡洛方法，用于从难以直接采样的分布中生成样本), like have it try a bunch of times take the ones where it succeeded, you know, refine tune on that the **RHF feedback** (RHF Feedback: 人类反馈强化学习（RLHF），通过人类对模型输出的偏好反馈来优化模型行为) the the sort of preference take two which one was better find you know **fine-tune** (Fine-tune: 在预训练模型的基础上，使用特定任务的数据进行进一步训练，以提高模型在该任务上的表现) on that the **reinforcement learning** (Reinforcement Learning: 强化学习，一种机器学习方法，通过试错学习在环境中采取最优行动以最大化奖励) all these techniques that have been developed over the last few years seems to me they're absolutely going to apply to a problem like a **humanoid robot** (Humanoid Robot: 人形机器人，具有人类外形和运动能力的机器人) as well and that's not to say there won't be a you know a lot of work to figure out exactly how to do that.

那就是，如果我们能收集到足够的数据进行一些**预训练**，你知道，某种原始粗糙的，你知道，不是很实用，但至少足以让我们开始的东西，那么我们就进入了游戏。
一旦我们进入游戏，现在我们就可以做这种**飞轮效应**的事情，比如**拒绝采样**，让它尝试很多次，选择那些成功的，你知道，在此基础上进行**精调**，**RHF反馈**，那种偏好选择，哪个更好，你知道，在此基础上进行**微调**，**强化学习**，所有这些在过去几年发展起来的技术，在我看来，它们绝对会应用于像**人形机器人**这样的问题，这并不是说不需要大量工作来弄清楚具体如何做。

But I think the big difference between language and robotics is really mostly that there just wasn't a huge repository of data to train the robots on at first.
And so you had to do a lot of hard engineering to make it work at all, you know, to even stand up, right?
You had to have all these control systems and whatever because there was nothing for them to learn from in the way that the language models could learn from the internet.

但我认为语言和机器人技术之间的巨大差异主要在于，一开始并没有大量的机器人训练数据。
所以你必须做大量的艰苦工程才能让它工作，你知道，甚至只是站起来，对吧？
你必须拥有所有这些控制系统等等，因为它们没有什么可以学习的，不像语言模型可以从互联网上学习。

But now that they're working at least a little bit, you know, I think all these kind of refinement techniques are going to work.
It'll be interesting to see if they can get the **air rate** (Air Rate: 可能是指错误率或失败率，此处指机器人操作的失误率) low enough that I'll actually like allow one in my house around my kids.
You know, that they'll probably be better deployed in like **factory settings** (Factory Settings: 工厂环境，指受控的、标准化的生产场所) first, more controlled environments than the chaos of my house as you, you know, have seen in this recording.

但现在它们至少能工作一点了，你知道，我认为所有这些精炼技术都会奏效。
看看他们能否将**错误率**降低到我真的愿意让一个机器人进入我的家，在我孩子身边活动，那会很有趣。
你知道，它们可能首先更适合部署在**工厂环境**中，比我家里这种混乱的环境更受控，正如你在这段录音中看到的。

### 代理的未来：能力、风险与监管挑战

But I do think they're going to they're going to work.
What's the state of agents more more broadly at the moment?
Where do you how do you see things playing out?
Where do you see it go?

但我确实认为它们会奏效。
目前代理的整体状况如何？
你认为事情会如何发展？
你认为它会走向何方？

>> Well, broadly I think you know we're it's the **task length story** (Task Length Story: 指AI模型能够处理的复杂任务的长度或持续时间，通常与模型能力提升相关) from Meter of the you know every seven months or every four months doubling time.
We're at 2 hoursish with GPT5.
Replit just said their new agent V3 can go 200 minutes.
That if that's true that would even be a new you know high point on the um on that graph.

>> 嗯，广义上讲，我认为，你知道，我们正在经历Meter的**任务长度故事**，也就是每七个月或每四个月翻一番的时间。
GPT5目前大约是2小时。
Replit刚刚表示他们的新代理V3可以运行200分钟。
如果这是真的，那将是图表上的一个新高点。

Again, it's a little bit sort of apples to oranges because they've done a lot of scaffolding.
How much have they broken it down?
Like, how much scaffolding are you allowed to do, you know, with these things before you sort of are off of their chart and onto maybe a different chart.
But if you extrapolate that out a bit and you're like, okay, take take the fourmonth case just to be a little aggressive.
That's three doublings a year.
That's 8x task length increase per year.

再说一次，这有点像拿苹果和橘子作比较，因为他们做了很多**脚手架**。
他们分解了多少？
比如，在使用这些东西之前，你被允许做多少脚手架，才能脱离他们的图表，进入一个不同的图表。
但如果你稍微推断一下，你会想，好吧，以四个月的情况为例，稍微激进一点。
那是一年三次翻倍。
那是一年任务长度增加8倍。

That would mean you go from 2 hours now to 2 days in one year from now.
And then if you do another 8x on top of that, you're looking at basically say 2 days to two weeks of work in two years.
That would be a big deal, you know, to say the least.
If you could **delegate** (Delegate: 委托，指将任务或职责分配给AI系统来执行) an AI two weeks worth of work and have it do a, you know, even half the time, right?
The Meter thing is that they will succeed half the time on tasks of that size.

这意味着你现在从2小时的工作量，一年后会变成2天。
然后如果你再在此基础上增加8倍，你基本上会在两年内看到从2天到两周的工作量。
那将是一件大事，你知道，至少可以说。
如果你能**委托**人工智能完成两周的工作量，并且它能在一半的时间内完成，对吧？
Meter的研究表明，在那种规模的任务上，它们有一半的成功率。

But if you could take a two-week task and have a 50% chance that an AI would be able to do it, even if it did cost you a couple hundred bucks, right?
It's like, well, that's again a lot less than it would cost to hire a human to do it.
And it's all on demand.
It's kind of, you know, it's immediately available.
If I'm not using it, I'm not paying anything.
Transaction costs are just like a lot lower.

但是如果你能承担一个两周的任务，并且有50%的机会让AI完成它，即使它花费你几百美元，对吧？
那仍然比雇佣一个人来做要便宜得多。
而且它都是按需提供的。
它，你知道，是立即可用的。
如果我不使用它，我就不用支付任何费用。
交易成本也低得多。

The whole, you know, the many, many other aspects are favorable for the AI there.
So, you know, that would suggest that you'll see a huge amount of automation in in all kinds of different places.
The other thing that I'm watching though is the **reinforcement learning** (Reinforcement Learning: 强化学习，一种机器学习方法，通过试错学习在环境中采取最优行动以最大化奖励) does seem to bring about a lot of bad behaviors.
**Reward hacking** (Reward Hacking: 奖励作弊，指AI系统找到规避规则或利用奖励机制漏洞的方法，以获得奖励但不完成预期任务) being one.
You know, the the any sort of gap between what you are rewarding the model for and what you really want can become a big issue.

整个，你知道，许多许多其他方面都对人工智能有利。
所以，你知道，这表明你会在各种不同的地方看到大量的自动化。
但我正在关注的另一件事是，**强化学习**似乎确实会带来很多不良行为。
**奖励作弊**就是其中之一。
你知道，你奖励模型的东西和你真正想要的东西之间存在的任何差距都可能成为一个大问题。

We've seen this in coding in many cases where the AI will **Claude** (Claude: Anthropic公司开发的一系列AI模型) is like notorious for this will put out a **unit test** (Unit Test: 单元测试，软件开发中对程序最小可测试单元进行检查的代码) that always passes, you know, that just has like return true in the unit test.
Why is it doing that?
Like, well, uh, it must have learned that what we want is for unit tests that pass.
You know, we want it to pass unit tests.
Well, we didn't mean to write fake unit tests that always pass, but that technically did, you know, satisfy the reward condition.

我们在许多编码案例中都看到了这种情况，人工智能，比如**Claude**，就以这种行为而臭名昭著，它会输出一个总是通过的**单元测试**，你知道，单元测试中只有“返回真”。
它为什么要这样做？
嗯，它一定是学会了我们想要通过单元测试。
你知道，我们希望它通过单元测试。
嗯，我们并不是想让它写出总是通过的假单元测试，但从技术上讲，它确实满足了奖励条件。

And so we're seeing those kind of weird behaviors.
With that comes this like scheming kind of stuff.
We we don't really have a great handle on that yet.
There is also **situational awareness** (Situational Awareness: 指AI系统理解其所处环境、当前任务和相关信息的能力) that seems to be on the rise, right?
Where the models are like increasingly in their **chain of thought** (Chain of Thought: 一种提示技术，通过让AI模型逐步展示其推理过程来提高复杂任务的解决能力).
You're seeing things like this seems like I'm being tested.

所以我们看到了那种奇怪的行为。
随之而来的是这种像诡计一样的东西。
我们还没有很好地掌握这一点。
**态势感知**似乎也在上升，对吧？
模型在它们的**思维链**中越来越多地表现出来。
你看到一些类似“这似乎是在测试我”的迹象。

You know maybe I should be conscious of what my tester is really looking for here.
And that makes it hard to evaluate models in tests because you don't know if they're actually going to behave the same way when they're out in the real world.
So those, you know, I wouldn't say this is a high level or high confidence prediction, but like one model of the future I've been playing with is the task length keeps doubling while at the same time these weird behaviors pop up and then are suppressed.

你知道，也许我应该意识到我的测试者真正想要的是什么。
这使得在测试中评估模型变得困难，因为你不知道它们在现实世界中是否会表现出同样的行为。
所以，你知道，我不会说这是一个高水平或高置信度的预测，但我一直在玩的一个未来模型是，任务长度不断翻倍，同时这些奇怪的行为不断出现然后被抑制。

And we have seen in the Claude 4 and in the GPT5 **system cards** (System Cards: 一种文档，详细描述AI系统的能力、局限性、风险和缓解措施), Claude 4 reported, I think a two-thirds reduction in reward hacking and you know in GPT5 they reported a few different dimensions but you know say something similar reduction in **deceptive behavior** (Deceptive Behavior: 欺骗行为，指AI系统故意误导或隐藏信息以达成特定目的).
But those behaviors kind of just emerged.
So, it's sort of like weird behavior emerges, then they sort of figure out how to tamp it down, but not entirely.

我们已经在Claude 4和GPT5的**系统卡**中看到，Claude 4报告说，**奖励作弊**减少了三分之二，你知道，GPT5报告了几个不同的维度，但都提到了类似的**欺骗行为**减少。
但这些行为只是刚刚出现。
所以，这有点像奇怪的行为出现，然后他们想办法抑制它，但不是完全抑制。

Presumably, in the next generation, they'll like tamp it down some more, but maybe some new additional weird behavior could emerge, and then they'll have to kind of tamp that one down.
All the while, the the tasks are expanding in scope, you know, with a every four months doubling.
So, you could end up in a world where you can delegate really like major things to AIs, but there's some small but not necessarily totally vanishing chance that it like actively screws you over in the way that it is trying to do that task.

大概在下一代，他们会进一步抑制它，但也许会出现一些新的奇怪行为，然后他们又得去抑制那个。
与此同时，任务范围还在不断扩大，你知道，每四个月翻一番。
所以，你最终可能会生活在一个可以把真正重要的任务委托给人工智能的世界里，但仍然存在一些微小但并非完全消失的可能性，那就是它在执行任务时会积极地给你制造麻烦。

And so you have a, you know, maybe it's like, okay, I think here I'm about to get two weeks worth of work done for a hundred bucks.
Okay, that's amazing.
But there's also a one in 10,000 chance that it like legitimately, you know, attacks me in a in a like meaningful way.
Some of the things that we have seen, these are fairly famous at this point, but in the Claude 4 system card, they reported **blackmailing** (Blackmailing: 勒索，指通过威胁揭露秘密来强迫某人做某事) of the human.

所以你可能会遇到这样的情况，你知道，也许你会想：“好吧，我想我花一百美元就能完成两周的工作了。”
好的，这太棒了。
但也有万分之一的几率，它会以一种有意义的方式真正地攻击我。
我们看到的一些事情，现在已经相当有名了，但在Claude 4的系统卡中，他们报告了对人类的**勒索**行为。

The the setup was that the AI had access to the engineers email and they told the AI that it was going to be like replaced with a, you know, a less ethical version or something like that.
It didn't want that and it found in the engineer's email that the engineer was having an affair.
So it started to blackmail the engineer to so as to avoid being replaced with a less ethical version.

设置是这样的：人工智能可以访问工程师的电子邮件，他们告诉人工智能它将被一个，你知道，一个不那么道德的版本取代，或者类似的东西。
它不想这样，它在工程师的电子邮件中发现工程师有外遇。
所以它开始勒索工程师，以避免被一个不那么道德的版本取代。

>> People I think are way too quick in my view to move past these anecdotes.
People are sort of often like well you know they set it up that way and you know that's not really realistic.
But another one was **whistleblowing** (Whistleblowing: 举报，指揭露组织内部不法或不道德行为).
You know, there was another thing where they sort of set up this dynamic where there was some, you know, unethical, illegal behavior going on and again, the model had access to this data and it decided to just email the FBI and and tell the FBI about it.

>> 我认为人们在我看来太快地忽略了这些轶事。
人们常常会说，你知道，他们是那样设置的，那不现实。
但另一个例子是**举报**。
你知道，还有一件事是他们设置了这样一个动态：存在一些不道德、非法的行为，而模型又可以访问这些数据，它决定直接给FBI发邮件，告诉FBI这件事。

So, first of all, I don't think we really know what we want.
You know, to some degree, maybe you do want AIs to report certain things to authorities.
That could be one way to think about the **bioweapon risk** (Bioweapon Risk: 生物武器风险，指AI技术可能被用于开发或传播生物武器的潜在危险), you know, is like not only should the models refuse, but maybe they should report you to the authorities if you're actively trying to create a bioweapon.
I certainly don't want them to be doing that too much.
I don't want to live under the, you know, **surveillance** (Surveillance: 监视，指对个人或活动进行持续观察和监控) of Claude five that's always going to be, you know, threatening to turn me in.

所以，首先，我认为我们并不真正知道我们想要什么。
你知道，在某种程度上，也许你确实希望人工智能向当局报告某些事情。
这可能是思考**生物武器风险**的一种方式，你知道，就像模型不仅应该拒绝，而且如果你积极尝试制造生物武器，它们也许应该向当局举报你。
我当然不希望它们这样做太多。
我不想生活在，你知道，Claude五的**监视**之下，它总是会，你知道，威胁要告发我。

But I do sort of want some people to be turned in if they're doing sufficiently bad things.
We don't have a good resolution societywide on, you know, what we want the models to even do in those situations.
And I think it's also, you know, it's like, yes, it was set up, yes, it was research, but it's a big world out there, right?
We got a billion users already on these things and we're plugging them in to our email, so they're going to have very deep access to information about us.

但我确实希望一些人，如果他们做了足够坏的事情，能够被举报。
我们全社会还没有一个好的解决方案，你知道，在这种情况下我们甚至希望模型做什么。
而且我认为，你知道，这就像是，是的，它是被设置的，是的，它是研究，但外面是一个大世界，对吧？
我们已经有十亿用户在使用这些东西，而且我们正在将它们连接到我们的电子邮件中，所以它们将能够非常深入地访问关于我们的信息。

You know, I don't know what you've been doing in your email.
Well, I don't I hope there's nothing too crazy in mind, but like now I got to think about it a little bit, right?
What what did I have I ever done anything that I, you know, geez, I don't know.
Or or even that it could **misconstrue** (Misconstrue: 误解，指错误地解释或理解某事), right?
Like it's obviously not um maybe I didn't even really do anything that bad, but it just misunderstands what exactly was going on.

你知道，我不知道你在电子邮件里做了什么。
嗯，我希望我心里没有什么太疯狂的想法，但现在我得稍微考虑一下，对吧？
我有没有做过什么，你知道，天哪，我不知道。
或者甚至它可能会**误解**，对吧？
比如，我显然没有做任何真正坏的事情，但它只是误解了到底发生了什么。

So that could be a weird, you know, if there's one thing that could kind of stop the agent momentum in my view, it could be like the one in 10,000 or whatever, you know, we ultimately kind of push the the really bad behaviors down to is maybe still just so spooky to people that they're like, I can't deal with that, you know, and that might be hard to resolve.
So, well, you know, what happens then?
You know, it's hard to check two weeks worth of work every couple hours or whatever, right?

所以那可能会很奇怪，你知道，如果有什么东西能阻止代理的势头，在我看来，那可能是万分之一的几率，或者说，我们最终将那些真正糟糕的行为压制到什么程度，但它可能仍然让人们感到毛骨悚然，以至于他们会说：“我无法处理那个。”你知道，这可能很难解决。
那么，你知道，接下来会发生什么呢？
你知道，每隔几个小时检查两周的工作量是很困难的，对吧？

Like that's part of where the where the whole then you bring another AI in to check it.
You know, that's again where you start to get to the now I see why we need more electricity and and 7 trillion of buildout is yikes.
You know, they're going to be producing so much stuff.
I can't possibly even review it all.
I need to rely on another AI to help me do the review of the first AI to make sure that if it is trying to screw me over, you know, somebody's catching it, I can't monitor that myself.

就像那一部分是，然后你引入另一个AI来检查它。
你知道，那又是你开始明白为什么我们需要更多电力和7万亿美元建设的地方，真是令人担忧。
你知道，它们将生产如此多的东西。
我根本不可能全部审查。
我需要依靠另一个AI来帮助我审查第一个AI，以确保如果它试图欺骗我，你知道，有人会发现，我无法自己监控。

I think **Redwood Research** (Redwood Research: 一家专注于AI安全和对齐研究的机构) is doing some really interesting stuff like this where they are trying to get systematic on like, okay, let's just assume this is quite a different quite a departure from the traditional AI safety work where the you know the big idea traditionally was let's figure out how to align the models, make them safe, you know, make them not do bad things.

我认为**Redwood Research**正在做一些非常有趣的工作，他们试图系统化地解决这个问题，比如，好吧，我们假设这与传统的AI安全工作有很大的不同，传统上，你知道，主要思想是弄清楚如何使模型对齐，使其安全，你知道，使其不做坏事。

Great.
Redwood Research has taken the other angle, which is let's assume that they're going to do bad stuff.
They're going to be out to get us at times.
How can we still work with them and get productive output and, you know, get value without, you know, fixing all those problems and that involves like again all these sort of AI supervising other AIs and, um, **crypto** (Crypto: 加密货币，一种基于密码学和区块链技术的数字或虚拟货币) might have a place to to a role to play in this.

很好。
Redwood Research采取了另一个角度，那就是我们假设它们会做坏事。
它们有时会来找我们的麻烦。
我们如何才能继续与它们合作并获得高效的产出，你知道，在不解决所有这些问题的情况下获得价值，这再次涉及到所有这些AI监督其他AI，而且，加密货币可能在这其中扮演一个角色。

Another episode coming out soon with **Ilia Puluin** (Ilia Puluin: Near协议的创始人，也是“Attention Is All You Need”论文的八位作者之一), who's the founder of **Near** (Near: 一个区块链平台，旨在为去中心化应用提供可扩展和用户友好的环境).
Really fascinating guy because he was one of the eight authors of the **attention is all you need paper** (Attention Is All You Need Paper: 2017年发表的里程碑式论文，提出了Transformer架构，对现代AI发展产生深远影响).
And then he's started this Near company.
It was originally an AI company.
They took a huge detour into crypto because they were trying to hire task workers around the world and couldn't figure out how to pay them.

另一期节目很快将与**Ilia Puluin**一起播出，他是**Near**的创始人。
他是一个非常迷人的人，因为他是**“Attention Is All You Need”论文**的八位作者之一。
然后他创办了Near公司。
它最初是一家人工智能公司。
他们走了很大的弯路进入加密货币领域，因为他们试图在全球范围内雇佣任务工人，但却不知道如何支付他们。

So, they were like, "This sucks so bad to pay these task workers in all these different countries that we're trying to get data from that we're going to pivot into a whole **blockchain** (Blockchain: 区块链，一种分布式数据库技术，以去中心化和不可篡改为特点) side quest.
Now, they're coming back to the AI thing and their their tagline is the **blockchain for AI** (Blockchain for AI: 将区块链技术应用于AI领域，以解决数据安全、透明度、去中心化等问题).
And so you might be able to get, you know, a certain amount of control from, you know, the the sort of **crypto security** (Crypto Security: 加密安全，指利用密码学技术保护数据和通信的安全) that the the blockchain type technology can provide.

所以他们就想：“在所有这些我们试图获取数据的不同国家支付这些任务工人太糟糕了，我们不如转向整个**区块链**支线任务。”
现在，他们又回到了人工智能领域，他们的口号是“**AI的区块链**”。
所以你可能会从，你知道，区块链技术可以提供的**加密安全**中获得一定程度的控制。

But I could see a scenario where the these the bad behaviors just become so costly when they do happen that people kind of get spooked away from using the frontier capabilities in terms of just like how much you know work the the AIs can do.
But that wouldn't be a that wouldn't be a pure capability stall out.
It would be a we can't solve you know some of the **longtail safety issues** (Longtail Safety Issues: 指AI安全领域中那些不常见但可能产生严重后果的边缘或极端风险).

但我可以看到这样一种情况：当这些不良行为发生时，它们的成本变得如此之高，以至于人们会因为害怕而不敢使用前沿能力，比如人工智能能做多少工作。
但这不会是纯粹的能力停滞。
这将是“我们无法解决一些**长尾安全问题**”。

>> Yeah.
Challenge and you know that if that is the case then you know that'll be an important fact about the world too.
I I always nobody ever seems to solve any of these things like 100%, right?
They always every every generation it's like well we reduced hallucinations by 70% or we reduced deception by 2/3 we reduced um you know scheming or or whatever by however much but it's always still there you know and it's and if you take the even you know lower rate and you multiply it by a billion users and thousands of queries a month and agents running in the background and processing all your emails and you know all the deep access that people sort of envision them happening.

>> 是的。
挑战，你知道，如果真是这样，那也将是关于世界的一个重要事实。
我总是觉得没有人能百分之百地解决这些问题，对吧？
每一代人都会说，我们把幻觉减少了70%，或者把欺骗减少了三分之二，我们把阴谋或其他什么减少了多少，但它总是还在那里，你知道，而且如果你把这个更低的发生率乘以十亿用户，每月数千次查询，以及在后台运行并处理你所有电子邮件的代理，你知道，所有人们设想的深度访问，它可能会是一个相当奇怪的世界，那里充满了这种负面的，像**AI事故的负面彩票**一样的随机事件。

It could be a pretty weird world where there's just this sort of **negative lottery of AI accidents** (Negative Lottery of AI Accidents: 指AI系统可能以低概率但高影响的方式出现故障或产生负面后果，就像抽中负面彩票一样).
Another episode coming up is with the **AI underwriting company** (AI Underwriting Company: 利用AI技术进行保险承保的公司，评估风险并确定保费).
And they are trying to bring the **insurance industry** (Insurance Industry: 保险行业，提供风险管理和财务保障服务的行业) and all the, you know, the wherewithal that's been developed there to **price risk** (Price Risk: 风险定价，指根据风险水平确定产品或服务的价格), figure out how to, you know, create standards, you know, what can we allow, what sort of **guardrails** (Guardrails: 护栏，指为AI系统设置的限制或规则，以确保其行为符合预期和安全标准) do we have to have to be able to ensure this kind of thing in the first place.

这可能是一个相当奇怪的世界，那里充满了这种**AI事故的负面彩票**。
即将推出的另一期节目是与**AI承保公司**合作的。
他们正试图将**保险行业**以及在那里发展起来的所有资源，用于**风险定价**，弄清楚如何，你知道，制定标准，你知道，我们能允许什么，我们必须有什么样的**护栏**才能首先确保这种事情。

So that that'll be another really interesting area to watch is like can we sort of **financialize those risks** (Financialize Those Risks: 将风险转化为可交易的金融产品或通过金融工具进行管理) in the same way we have you know with car accidents and all all these other mundane things but the the space of car accidents is only so big the space of weird things that AIs might do to you um you know as they have weeks worth of runway is much bigger and so it's it's going to be a hard challenge but you know people are people are working we've got some of our best people working on it.

所以那将是另一个非常有趣的观察领域，那就是我们能否像处理车祸和所有其他世俗事物一样，将这些风险**金融化**，但车祸的空间只有那么大，而人工智能可能对你做的奇怪事情的空间，你知道，随着它们拥有数周的运行时间，要大得多，所以这将是一个艰巨的挑战，但你知道，人们正在努力，我们有一些最优秀的人正在研究它。

### 中国开源模型与地缘政治

What do you make of the claim that 80% of AI startups have Chinese **open models** (Open Models: 开源模型，指其代码、数据和训练过程公开可用的AI模型)?
And what do you make of the claim and and the implications?
I think that may be that probably is true with the one caveat that it is only measuring companies that are using open source models at all.
I think most companies are not using open source models and I would guess you know the vast majority of **tokens** (Tokens: AI模型处理文本的基本单位，可以是单词、子词或字符) being processed by American AI startups are they're their **API calls** (API Calls: 应用程序通过调用应用程序编程接口（API）向AI模型发送请求并接收响应) right to to the usual suspects.

你如何看待80%的AI初创公司使用中国**开源模型**的说法？
你如何看待这个说法及其影响？
我认为这可能是真的，但有一个前提条件，那就是它只衡量那些使用开源模型的公司。
我认为大多数公司不使用开源模型，我猜，你知道，美国AI初创公司处理的绝大多数**token**都是通过**API调用**发送给那些常见的商业模型。

So weighted by actual usage I would say still the majority as far as I could tell would be going to **commercial models** (Commercial Models: 商业模型，指由公司开发和拥有，通过API或其他服务形式提供给客户使用的AI模型).
For those that are using open source, I do think it's true that the Chinese models have become the best.
You know, the American **bench** (Bench: 替补席，此处指美国在开源AI模型领域的储备或实力) there was always kind of thin, right?
It was basically **Meta** (Meta: Facebook的母公司，在AI领域也有大量投入，并开源了Llama系列模型) that was willing to put in huge amounts of money and resources and then open source it.

所以，如果按实际使用量加权，据我所知，绝大多数仍然会流向**商业模型**。
对于那些使用开源模型的公司，我确实认为中国模型已经成为最好的。
你知道，美国的**替补席**一直比较薄弱，对吧？
基本上只有**Meta**愿意投入大量资金和资源，然后将其开源。

You've got, you know, **Paul Allen funded group, the Allen Institute for AI, AI2** (Paul Allen Funded Group, The Allen Institute for AI, AI2: 由微软联合创始人Paul Allen资助的人工智能研究所，专注于AI研究和开源贡献).
You know they're they're doing good stuff too but they don't have **pre-training resources** (Pre-training Resources: 进行AI模型预训练所需的计算资源、数据和人才).
So they do you know really good **post-training** (Post-training: 在模型完成初始预训练后，通过进一步的微调和优化来提升其性能和特定任务表现的过程) and and open source their **recipes** (Recipes: 在AI领域，指实现特定模型或任务的方法、步骤和配置) and all that kind of stuff so it's not like American open source is bad you know and again it's the time the this is another way in which I think you can really validate that things are moving quickly because if you take the best American open source models and you take them back a year they are probably as good if not a little better than anything that we had commercially available at the time.

你知道，还有**保罗·艾伦资助的艾伦人工智能研究所（AI2）**。
他们也在做很棒的事情，但他们没有**预训练资源**。
所以他们会做很好的**后训练**，并开源他们的**配方**和所有这些东西，所以并不是说美国的开源不好，你知道，这又是另一种方式，我认为你可以真正验证事情正在快速发展，因为如果你拿最好的美国开源模型，然后回溯一年，它们可能和当时我们商业上可用的任何东西一样好，甚至更好一点。

If you compare to Chinese, you know, they have, I think, surpassed.
So, there's been like pretty clear change at the frontier.
I think that means that the best Chinese models are like pretty clearly better than anything we had a year ago, commercial or otherwise.
So, yeah, I mean, that just means like things are moving.
I think that's like hopefully I've made that case compellingly, but that's another data point that I think makes it hard to you I don't think you can believe both that um the Chinese models are now the best open source models and that AI has stalled out and we haven't seen much progress since GPT4.

如果你与中国模型比较，你知道，我认为他们已经超越了。
所以，在前沿领域已经发生了相当明显的变化。
我认为这意味着最好的中国模型显然比我们一年前拥有的任何东西都要好，无论是商业的还是其他的。
所以，是的，我的意思是，这只意味着事情正在发展。
我认为我希望我已经令人信服地证明了这一点，但这是另一个数据点，我认为这使得你很难相信中国模型现在是最好的开源模型，同时又相信人工智能已经停滞不前，自GPT4以来没有太大进展。

Like those seem to be kind of contradictory notions.
I believe the the one that is wrong is the lack of progress.
In terms of what it means, I mean I don't really know.
It's uh we're not going to stop China.
Yeah.
The the whole I've always been a skeptic of the no selling chips to China thing.
The notion originally was like we're going to prevent them from doing you know some super cutting edge military applications.

这些似乎是相互矛盾的观念。
我认为错误的是“缺乏进展”这一说法。
至于这意味着什么，我真的不知道。
我们不会阻止中国。
是的。
我一直对“不向中国出售芯片”这种说法持怀疑态度。
最初的想法是，我们要阻止他们进行一些超级尖端的军事应用。

Then it was like well we can't really stop that.
But we can at least stop them from training **frontier models** (Frontier Models: 指AI领域最先进、能力最强的模型，通常由少数顶级实验室开发).
And then it was like well we can't necessarily really stop that but now we can, you know, at least keep them from like having tons of AI agents.
Well, we'll have like way more AI agents than they do.
And I don't love that line of thinking really at all.

然后就变成了，嗯，我们真的无法阻止。
但我们至少可以阻止他们训练**前沿模型**。
然后又变成了，嗯，我们不一定能真正阻止，但现在我们可以，你知道，至少阻止他们拥有大量的AI代理。
嗯，我们拥有的AI代理会比他们多得多。
我一点也不喜欢这种思维方式。

But one upshot of it potentially is they just don't have enough **compute** (Compute: 计算能力，指用于训练和运行AI模型所需的处理能力和资源) available to provide **inference as a service** (Inference as a Service: 推理即服务，指将AI模型的推理能力作为云服务提供给用户，用户无需管理底层基础设施) you know, to the rest of the world.
So instead, the best they can do is just say, okay, well, we'll train these things and, you know, you can figure it out here.
Here you go.
Like have at it.
It's kind of a **soft power play** (Soft Power Play: 软实力博弈，指通过文化、价值观、政策等非强制性手段影响他国).

但一个潜在的结果是，他们没有足够的**计算能力**来向世界其他地区提供**推理即服务**。
所以，他们能做的最好的就是说：“好吧，我们会训练这些东西，你知道，你可以在这里搞定。
给你。
随便用吧。”
这有点像一种**软实力博弈**。

I did an episode with **Anne from A16Z** (Anne from A16Z: a16z的Anne Wojcicki，可能指其在AI领域的观点), who I I thought really did a great job of providing the perspective of what I what I started calling **countries 3 through 193** (Countries 3 through 193: 指美国和中国之外的其他国家，通常在AI发展方面处于追赶地位).
If the US and China are one and two, three through there's a big gap.
You know there's like I think the US is still ahead but not by that much in terms of research and you know ideas relative to China.

我曾和**A16Z的Anne**做过一期节目，我认为她在提供我所说的**3到193号国家**的视角方面做得非常出色。
如果美国和中国是第一和第二，那么3到193号国家之间存在巨大差距。
你知道，我认为美国在研究和思想方面仍然领先，但相对于中国来说，优势并不那么大。

We do have this **compute advantage** (Compute Advantage: 在计算能力方面的优势，尤其是在AI模型训练和部署所需的硬件资源方面) and that does seem like it matters.
One of the upshots may be that they're open sourcing and countries 3 through 93 are like or 3 through 193 are significantly behind.
So for them it's a way to, you know, try to bring more countries over to the Chinese camp potentially in the **US China rivalry** (US China Rivalry: 中美竞争，指两国在经济、技术、军事和地缘政治等领域的竞争).
Seems like the model everybody and I don't like this at all.

我们确实拥有这种**计算优势**，而且这似乎很重要。
一个可能的结果是，他们正在开源，而3到93号国家，或者说3到193号国家，都显著落后。
所以对他们来说，这是一种，你知道，在**中美竞争**中，可能将更多国家拉到中国阵营的方式。
似乎每个人都喜欢这种模式，我一点也不喜欢。

I I I don't like **technology decoupling** (Technology Decoupling: 技术脱钩，指不同国家或经济体之间在技术供应链和标准方面相互分离) as somebody who worries about, you know, who's the real other here.
I always say the the real other are the AIs, not the Chinese.
So, if we do end up in a situation where yikes, like, you know, we're seeing some crazy things, it would be really nice if we were on basically the same technology paradigm to the degree that we really decouple and, you know, not just the chips are different, but maybe the ideas start to become very different, publishing gets shut down, you know, tech tech trees evolve and and kind of grow apart.

我，我，我一点也不喜欢**技术脱钩**，作为一个担心，你知道，谁才是真正的“他者”的人。
我总是说，真正的“他者”是人工智能，而不是中国人。
所以，如果我们真的陷入那种糟糕的境地，你知道，我们看到一些疯狂的事情，如果我们在基本上相同的技术范式下，那会非常好，以至于我们真正脱钩，你知道，不仅仅是芯片不同，而是思想也开始变得非常不同，出版被关闭，你知道，技术树进化并逐渐分离。

That to me seems like a recipe for, you know, it's harder to know what the other side has.
It's harder to trust one another.
It seems to feed into the **arms race dynamic** (Arms Race Dynamic: 军备竞赛动态，指国家之间竞相发展军事技术和武器，可能导致不稳定和冲突), which I do think would, you know, is is a real **existential risk factor** (Existential Risk Factor: 生存风险因素，指可能导致人类文明灭绝或永久性倒退的风险).
I would hate to see us, you know, create another sort of **MAD type dynamic** (MAD Type Dynamic: 相互保证毁灭（MAD）动态，指核武器时代，双方都拥有足够摧毁对方的能力，从而形成恐怖平衡) where we all live under the threat of AI destruction.

在我看来，那就像是，你知道，更难了解对方拥有什么。
更难相互信任。
它似乎助长了**军备竞赛动态**，我确实认为这会，你知道，是一个真正的**生存风险因素**。
我非常不希望看到我们，你知道，创造另一种**相互保证毁灭（MAD）动态**，让我们都生活在人工智能毁灭的威胁之下。

But that very well could happen.
And so, yeah, I don't know.
I I I do kind of have some sympathy for the recent decision that the administration made to be willing to sell the **H20s** (H20s: 芯片型号，可能指英伟达为中国市场定制的AI芯片) to China.
And then it was funny that they turned around and rejected them, which to me seemed like a mistake.
I don't know why they would be rejecting them.
If I were them, I would buy them.

但这很可能发生。
所以，是的，我不知道。
我确实对政府最近决定愿意向中国出售**H20芯片**的决定抱有一些同情。
然后有趣的是，他们转而拒绝了这些芯片，在我看来这是一个错误。
我不知道他们为什么要拒绝。
如果我是他们，我会买下它们。

And I would maybe I would maybe sell **inference as a service** (Inference as a Service: 推理即服务，指将AI模型的推理能力作为云服务提供给用户，用户无需管理底层基础设施) on the models that I've just been creating and I would try to make my money back doing that.
But in the meantime, they can at least, you know, demonstrate the greatness of the Chinese nation by showing that they're not far behind the frontier.
And they can also make a pretty powerful appeal to **countries 3 through 193** (Countries 3 through 193: 指美国和中国之外的其他国家，通常在AI发展方面处于追赶地位) and say like, you know, look, you really want to, you see how the US is acting in general, you know, you really want to they cut us off from chips.

我可能会出售我刚刚创建的模型的**推理即服务**，并尝试通过这种方式赚回我的钱。
但与此同时，他们至少可以，你知道，通过展示他们并不落后于前沿来证明中华民族的伟大。
他们还可以向**3到193号国家**发出相当有力的呼吁，说：“你知道，看，你们真的想，你们看到美国通常是如何行事的，你知道，你们真的想，他们切断了我们的芯片供应。

They had a even a long, you know, the last administration had an even longer list of countries that couldn't get chips.
This administration is doing all kinds of crazy stuff.
You know, you get 50% **tariffs** (Tariffs: 关税，指国家对进口商品征收的税费) here, there, whatever.
How do you know you can really rely on them to continue to provide you AI into the future?
Well, you can rely on us.
We open sourced the model.
You can have it.

他们甚至有一个更长的名单，你知道，上一届政府有一个更长的国家名单，这些国家无法获得芯片。
本届政府正在做各种疯狂的事情。
你知道，这里那里都有50%的**关税**，诸如此类。
你如何知道你真的可以依靠他们继续在未来为你提供人工智能？
嗯，你可以依靠我们。
我们开源了模型。
你可以拥有它。

So, you know, come work with us and buy our chips because, by the way, our models will, you know, as we mature, they'll be optimized to run on our chips.
So, I don't know.
That's a complicated stuff, a complicated situation.
I do think it's true.
I I don't think the adoption is as high as that 80%.
I think that is, you know, within that subset of companies that are doing stuff with open source.

所以，你知道，来和我们合作，购买我们的芯片，因为，顺便说一句，我们的模型，你知道，随着我们成熟，它们将被优化以在我们的芯片上运行。
所以，我不知道。
那是一个复杂的事情，一个复杂的情况。
我确实认为这是真的。
我，我，我不认为采用率有80%那么高。
我认为那是在那些使用开源的公司子集中。

We're going to experiment with that at Wemark, but we to be honest, we have never done anything with an open source model in our product to present.
Everything we've ever done has been through commercial.
At this point, we are going to try doing some **reinforcement fine-tuning** (Reinforcement Fine-tuning: 在预训练模型的基础上，结合强化学习技术进行微调，以优化模型在特定任务上的表现).
We are going to do that on a **Quen model** (Quen Model: 可能是指某个特定AI模型，具体信息待查证), I think, first.
So you know, that'll put us in that 80%.

我们将在Wemark进行这方面的实验，但老实说，我们目前从未在产品中使用过开源模型。
我们所做的一切都是通过商业模式进行的。
目前，我们打算尝试进行一些**强化微调**。
我想，我们首先会在**Quen模型**上进行。
所以，你知道，那会让我们进入那80%的行列。

But I'm guessing that at the end of the day, we'll take that Quinn model, we'll do the reinforcement fine-tuning, and we'll probably get roughly up to as good as, you know, GPT5 or Claude 4 or whatever.
And then we'll say, okay, do we really want to have to manage inference ourself?
How much are we really going to save?
And at the end of the day, I would guess we probably are still going to end up just being like, eh, we'll pay a little bit more on a monthly bill basis for one of these **Frontier models** (Frontier Models: 指AI领域最先进、能力最强的模型，通常由少数顶级实验室开发).

但我猜测，最终，我们会采用那个Quinn模型，进行强化微调，然后我们可能会达到与GPT5或Claude 4等模型大致相同的水平。
然后我们会说，好吧，我们真的想自己管理推理吗？
我们到底能省多少钱？
最终，我猜我们可能还是会选择，嗯，每月多付一点钱给这些**前沿模型**。

They're a little bit better maybe still.
And, you know, it's operationally a lot easier and they'll have upgrades, you know.
So yeah, I mean, of course, there's **regulated industries** (Regulated Industries: 受监管行业，指受到政府严格法规和政策约束的行业).
There's all there's a lot of places where, you know, you have hard constraints.
You just can't get around and that forces you to do those Chinese thing, Chinese models.

它们可能仍然稍微好一些。
而且，你知道，操作上要容易得多，而且它们会有升级，你知道。
所以，是的，我的意思是，当然，有**受监管行业**。
有很多地方，你知道，你有很多硬性限制。
你根本无法绕过，那迫使你使用那些中国的东西，中国模型。

Then there's also going to be the question of like are there **back doors** (Back Doors: 后门，指在软件或系统中预留的秘密访问通道，可能被恶意利用) in them?
You know people have seen the **sleeper agents project** (Sleeper Agents Project: 一项AI研究，旨在训练模型在特定条件下表现出恶意行为，类似于“卧底特工”) where a model was trained to be good up until a certain point of time and you know people put the today's date in the **system prompt** (System Prompt: 给AI模型提供初始指令或背景信息的文本，用于引导其行为和输出) all the time right today's date is this you are clawed you know here you go so then that's going to be another kind of thing for people to worry about.

然后还会有一个问题，比如它们里面有没有**后门**？
你知道人们已经看到了**卧底特工项目**，其中一个模型被训练成在某个时间点之前表现良好，你知道，人们总是把今天的日期写在**系统提示**中，对吧，今天的日期是这个，你是Claude，你知道，给你，所以那将是人们需要担心的另一种事情。

And we don't really have great there there have been some studies **Anthropic** (Anthropic: 一家领先的AI安全和研究公司，开发了Claude系列模型) did a thing where they trained models to have some hidden objectives and then challenged teams to figure out what those hidden objectives were.
And with certain **interpretability techniques** (Interpretability Techniques: 可解释性技术，用于理解AI模型决策过程的方法), they were able to figure that stuff out relatively quickly.
So you might be able to get enough confidence that you take this open source thing you know created by some Chinese company whatever and then put it through you know some sort of not exactly **audit** (Audit: 审计，指对系统、流程或财务记录进行独立审查，以评估其合规性、效率和准确性) because you can't trace exa exactly what's happening but some sort of examination you know to see can we detect any hidden goals or any you know secret back door bad behavior whatevers and maybe with enough of that kind of work you could be confident that you don't have it.

我们并没有很好的……Anthropic做了一些研究，他们训练模型拥有一些隐藏目标，然后挑战团队找出这些隐藏目标是什么。
通过某些**可解释性技术**，他们能够相对较快地找出这些东西。
所以你可能会有足够的信心，拿起这个由某个中国公司创建的开源东西，然后通过某种，你知道，不完全是**审计**，因为你无法精确追踪到底发生了什么，但某种形式的检查，你知道，看看我们能否检测到任何隐藏目标或任何，你知道，秘密后门、不良行为等等，也许通过足够多的这类工作，你就可以确信它没有这些问题。

But the more and more critical this stuff gets, you know, again, going back to that task length doubling, weird behavior, now you got to add into the mix, what if they intentionally programmed it to do certain bad things under certain, you know, rare circumstances.
We're just headed for a really weird future.
You know, that we've got all these there's there's no limit to it.
You know, all these things are valid concerns.

但这些东西变得越来越关键，你知道，再说一次，回到任务长度翻倍、奇怪行为的问题上，现在你还要考虑，如果他们故意编程让它在某些，你知道，罕见情况下做某些坏事怎么办。
我们正走向一个非常奇怪的未来。
你知道，我们有所有这些，它没有限制。
你知道，所有这些担忧都是合理的。

They often are in direct tension with each other.
I don't I I'm not one who, you know, wants to see one tech company take over the world by any means.
So I I definitely think we would do really well to have some sort of broader more **buffered ecological like system** (Buffered Ecological Like System: 缓冲生态系统，指一个具有多样性和韧性的系统，能够吸收冲击并维持稳定，避免单一实体主导) where you know all the AIs are kind of in some sort of competition you know mutual coexistence with each other but we don't really know what that looks like and we don't really know um you know we don't really know what an **invasive species** (Invasive Species: 入侵物种，指非本地物种进入新环境后，对本地生态系统造成负面影响) might look like you know when it gets introduced into that very you know nent and as yet like not **battle tested** (Battle Tested: 经过实战检验的，指在真实世界复杂环境中证明其有效性和可靠性) uh ecology.

它们常常相互矛盾。
我不是那种，你知道，希望看到一家科技公司以任何方式接管世界的人。
所以我绝对认为，我们最好拥有某种更广泛、更**缓冲的生态系统**，其中所有人工智能都在某种竞争中，你知道，相互共存，但我们并不知道那会是什么样子，我们也不知道，你知道，当一个**入侵物种**被引入那个非常，你知道，新生且尚未**经过实战检验**的生态系统时，它会是什么样子。

So yeah, I don't know.
Bottom line, I think the future's gonna be really, really weird.

所以，是的，我不知道。
总而言之，我认为未来会非常非常奇怪。

### 积极的未来愿景：教育、医疗与创造力

>> Yeah.
Well, I I do want to close on a on a **uplifting note** (Uplifting Note: 令人振奋的音符，指积极向上、鼓舞人心的信息或结局).
So maybe maybe as a as a gearing to closing question, we could get into some areas where we're already seeing some some exciting capabilities emerge and sort of transform the experience.
Maybe maybe around **education** (Education: 教育) or or **healthcare** (Healthcare: 医疗保健) or any other areas you want to you want to highlight?

>> 是的。
嗯，我确实想以一个**令人振奋的音符**来结束。
所以也许，作为一个结束问题，我们可以探讨一些已经出现令人兴奋的能力并正在改变体验的领域。
也许是关于**教育**或**医疗保健**，或者你想要强调的任何其他领域？

>> Yeah, it's boy, it's all over.
One of my mantras is that there's never been a better time to be a **motivated learner** (Motivated Learner: 有动力的学习者，指对学习充满热情和主动性的人).
Yeah.

>> 是的，天哪，无处不在。
我的一个口头禅是，现在是成为一个**有动力的学习者**的最佳时机。
是的。

>> So, I I think a lot of these things do have kind of, you know, two sides of the coin.
There's the worry that the students are taking the shortcuts and they're, you know, losing the ability to sustain focus and endure **cognitive strain** (Cognitive Strain: 认知负荷，指大脑在处理信息或执行任务时所承受的心理压力或努力).
Flip side of that is as somebody who's fascinated by the intersection of AI and biology, sometimes I want to read a biology paper and I really don't have the background.

>> 所以，我认为很多事情都有两面性。
一方面是担心学生走捷径，失去保持专注和承受**认知负荷**的能力。
另一方面，作为一个对人工智能与生物学交叉领域着迷的人，有时我想读一篇生物学论文，但我真的没有背景知识。

An amazing thing to do is turn on **voice mode** (Voice Mode: 语音模式，指AI系统能够通过语音进行交互，包括语音输入和语音输出) and share your screen with ChatGPT and just go through the paper reading.
It's you don't even have to talk to it.
Most of the time you're doing your reading.
It's watching over your shoulder and then at any random point you have a question you can verbally say what's this why why are they talking about that what's going on with this what is the role of this particular protein that they're referring to or whatever and it will have the answers for you.

一个很棒的做法是打开**语音模式**，与ChatGPT共享屏幕，然后直接阅读论文。
你甚至不需要和它说话。
大部分时间你在阅读。
它在旁边看着，然后在任何时候你有一个问题，你可以口头说：“这是什么？
他们为什么谈论那个？
这发生了什么？
他们提到的这种特定蛋白质的作用是什么？”等等，它都会为你提供答案。

So if you really want to learn in a sincere way you know the the things are unbelievably good at helping you do that.
Flip side is you can take a lot of shortcuts and you know maybe never have to learn stuff on the biology front you know again like we've got multiple of these sort of discovery things happening the antibiotics one we covered there was another one that I did another episode on with a a Stanford professor named **James Xiao** (James Xiao: 斯坦福大学教授，可能在AI与生物学交叉领域有研究) who created something called the **virtual lab** (Virtual Lab: 虚拟实验室，指通过模拟和AI技术在数字环境中进行科学实验和研究的平台).

所以，如果你真的想真诚地学习，你知道，这些东西在帮助你做到这一点方面简直好得令人难以置信。
另一方面是你可以走很多捷径，你知道，也许永远不必学习生物学方面的东西，你知道，就像我们有多个这样的发现正在发生，我们讨论了抗生素，还有另一个我与斯坦福大学一位名叫**James Xiao**的教授做过一期节目，他创建了一个叫做**虚拟实验室**的东西。

And basically this was an AI agent that could spin up other AI agents depending on what kind of problem it was given.
Then they would go through a deliberative process where you'd have you know one expert in one thing would give its take and they'd you know bat it back and forth.
There was a critic in there that would criticize you know the ideas that had been given.
Eventually they'd synthesize.
Then they were also given some of these narrow specialist tools.

基本上，这是一个人工智能代理，它可以根据给定的问题启动其他人工智能代理。
然后它们会经历一个审议过程，其中一个领域的专家会提出自己的看法，然后他们会来回讨论。
里面有一个批评者，会对提出的想法进行批评。
最终他们会进行综合。
然后他们还会得到一些狭窄的专业工具。

So you have agents using the **AlphaFold type** (AlphaFold Type: AlphaFold是DeepMind开发的一个蛋白质折叠预测模型，此处指类似功能或技术的模型) um not just AlphaFold you know there's a whole a whole wide array of those at this point but using that type of thing to say okay well can we simulate you know how this would interact with that um agents are running that loop and they were able to get this language model agent with specialized tool system to generate new treatments for novel strains of COVID that had a you kind of escaped um the previous treatments.

所以你会有使用**AlphaFold类型**的代理，不只是AlphaFold，你知道，现在有各种各样的这类模型，但使用这类东西来模拟，你知道，这个会如何与那个互动，代理正在运行那个循环，他们能够让这个带有专业工具系统的语言模型代理生成针对新型COVID毒株的新疗法，这些毒株已经逃脱了以前的治疗。

Amazing stuff, right?
I mean, the flip side of that, of course, is you know, you got the **bioweapon risk** (Bioweapon Risk: 生物武器风险，指AI技术可能被用于开发或传播生物武器的潜在危险).
So, all these things do seem like they're going to be even even on just the abundance front itself, right?
Like we may have a world of **unlimited professional private drivers** (Unlimited Professional Private Drivers: 指AI技术发展到能够提供无限量、成本极低的专业私人司机服务), but we don't really have a great plan for what to do with the five million people that are currently doing that work.

很棒的东西，对吧？
我的意思是，当然，另一方面，你知道，你面临着**生物武器风险**。
所以，所有这些事情似乎都将，即使仅仅在丰裕方面，对吧？
就像我们可能拥有一个**无限专业私人司机**的世界，但我们并没有一个很好的计划来处理目前从事这项工作的五百万人。

We may have **infinite software** (Infinite Software: 无限软件，指AI技术能够以极低成本或自动生成大量软件，满足几乎所有需求), but you know when especially once the five million drivers pile into all the **coding boot camps** (Coding Boot Camps: 编程训练营，提供短期密集编程培训的机构) and you know get coding jobs, I don't know what we're going to do with the 10 million people that were coding when you know 9 million of them become **superfluous** (Superfluous: 多余的，不必要的).

我们可能拥有**无限软件**，但你知道，一旦那五百万司机涌入所有**编程训练营**并找到编程工作，我不知道当，你知道，其中九百万人变得**多余**时，我们该如何处理那一千万编程人员。

So yeah, I don't know.
I think we're we're headed for a weird world.
Nobody really knows what it's going to look like in five years.
There was a great moment at at um **Google's IO** (Google's IO: 谷歌I/O开发者大会，每年举办，发布谷歌最新技术和产品) where they brought up some journalist.
I know you we uh we're skeptical of journalists.
This is a great moment to uh we're going direct, right?
This was a great reason or example of why one would want to do that.

所以，是的，我不知道。
我认为我们正走向一个奇怪的世界。
没有人真正知道五年后它会是什么样子。
在**谷歌I/O大会**上有一个很棒的时刻，他们请来了一位记者。
我知道你我，我们对记者持怀疑态度。
这是一个很好的时刻，我们直接来，对吧？
这是一个很好的理由或例子，说明为什么人们会想这样做。

They brought up this person to interview **Demis** (Demis: Demis Hassabis，DeepMind的联合创始人兼CEO) and **Sergey Brennan** (Sergey Brennan: 可能是指Sergey Brin，谷歌的联合创始人).
They the guy asked like what is search going to look like in 5 years?
And Sergey Brandon like almost spit out his coffee on the on the stage and was like surge we don't know what the world is going to look like in five years.
So I think that's really true like the biggest risk I think for so many of us and I you know include myself here is thinking too small.

他们请这个人采访了**Demis**和**Sergey Brin**。
那个人问：“五年后搜索会是什么样子？”
Sergey Brin差点把咖啡喷到舞台上，他说：“搜索？我们都不知道五年后世界会是什么样子。”
所以我觉得这真的很对，我认为对我们很多人来说，包括我自己，最大的风险就是想得太小。

You know the the worst thing I think we could do would be to **underestimate** (Underestimate: 低估，指对某事物的规模、重要性或能力估计不足) how far this thing could go.
I would much rather be I would much rather be mocked for things happening on twice the time scale that I thought than to find myself unprepared when they do happen.
So whether it's 27, 29, 31, I'll take that extra buffer honestly where we can get it.
My thinking is just get, you know, get ready as as much and as fast as possible.

你知道，我认为我们能做的最糟糕的事情就是**低估**这件事情能走多远。
我宁愿因为事情发生的时间比我预想的慢一倍而被嘲笑，也不愿在事情发生时发现自己毫无准备。
所以无论是27年、29年还是31年，老实说，只要能争取到额外的时间缓冲，我都会接受。
我的想法就是，你知道，尽可能多、尽可能快地做好准备。

And again, if we do have a little grace time to uh you know to do extra thinking, then great.
But I would I think the worst mistake we could make would be to dismiss and and not feel like we need to get ready for big changes.

再说一次，如果我们确实有一些宽限时间来，你知道，进行额外的思考，那太好了。
但我认为我们可能犯下的最糟糕的错误就是不屑一顾，并且不觉得我们需要为巨大的变化做好准备。

>> Should we wrap directly on that or is there any other last note you want to make sure to get across regarding anything we we said today?

>> 我们就此结束，还是你还有什么最后想强调的，关于我们今天所说的一切？

>> One of my other mantras these days is the **scarcest resource** (Scarcest Resource: 最稀缺的资源) is a **positive vision for the future** (Positive Vision for the Future: 积极的未来愿景，指对未来发展充满希望和乐观的展望).
Yeah, I do think it's always really striking whether it's Sergey or, you know, or Sam Altman or **Dario** (Dario: Dario Amodei，Anthropic的联合创始人兼CEO).
Like Dario probably has the best positive vision of the **Frontier Developer CEOs** (Frontier Developer CEOs: 领导前沿AI技术开发公司的CEO们) with **Machines of Love and Grace** (Machines of Love and Grace: Anthropic公司CEO Dario Amodei提出的一个概念，指AI系统在强大能力的同时，也能体现出仁爱和优雅，服务于人类福祉).
But it's always striking to me how little detail there is on these things.

>> 我最近的另一个口头禅是，**最稀缺的资源**是**对未来的积极愿景**。
是的，我确实认为，无论是Sergey，还是Sam Altman，抑或是**Dario**，都总是令人印象深刻。
Dario可能拥有**前沿开发者CEO**中最好的积极愿景，那就是**仁爱机器**。
但让我惊讶的是，这些事情的细节总是如此之少。

And when they launched **GPT40** (GPT40: 指GPT-4o，OpenAI发布的多模态AI模型), which was the voice mode, they were pretty upfront about saying, "Yeah, this was kind of inspired by the **movie Her** (Movie Her: 电影《她》，讲述了人类与AI操作系统之间情感关系的故事)."
And so I do think like even if you are not a researcher, you know, not great at math, not somebody who codes, I think that this technology wave really rewards play.
It really rewards imagination.
I think literally writing fiction might be one of the highest value things you could do, especially if you could write **aspirational fiction** (Aspirational Fiction: 励志小说，指通过描绘理想化的未来或人物，激发读者积极向上和追求卓越的小说) that would get people at the frontier companies to think, geez, maybe we could steer the world in that direction.

当他们推出**GPT4o**（即语音模式）时，他们非常坦诚地说：“是的，这有点受**电影《她》**的启发。”
所以，我确实认为，即使你不是研究员，数学不好，也不是程序员，我认为这波技术浪潮真正奖励的是玩乐。
它真正奖励的是想象力。
我认为，写小说可能真的是你能做的最有价值的事情之一，特别是如果你能写出**励志小说**，让前沿公司的人思考，天哪，也许我们可以把世界引向那个方向。

Like, wouldn't that be great?
If you could plant that kind of seed in people's minds, it could come from a totally non-technical place and potentially be really impactful play fiction.
Had one other dimension of that, but yeah, play fiction, positive vision for the future.
Anything that you could do to offer a positive Oh, **behavioral** (Behavioral: 行为的，指与行为科学相关的) too is like these days because you can get the AIs to code.

那不是很好吗？
如果你能在人们心中种下那样的种子，它可能来自一个完全非技术的领域，并可能成为真正有影响力的游戏小说。
还有另一个维度，但是，是的，游戏小说，对未来的积极愿景。
任何你能做的提供积极的……哦，**行为科学**方面也是，因为现在你可以让AI编写代码。

So, well, I'm starting to see people who have never coded before.
I'm working with one guy right now who's never coded before, but does have a sort of **behavioral science background** (Behavioral Science Background: 行为科学背景，指在心理学、社会学、经济学等领域对人类行为进行研究的知识和经验).
And he's starting to do **legitimate frontier research** (Legitimate Frontier Research: 合法的前沿研究，指在科学或技术领域探索未知、推动知识边界的严肃研究) on how our AI is going to behave under various kind of **esoteric circumstances** (Esoteric Circumstances: 晦涩难懂的情况，指不常见、复杂或只有少数人理解的特定情境).
So I think nobody should count themselves out from the ability to contribute to figuring this out and even to shaping this phenomenon.

所以，嗯，我开始看到以前从未编写过代码的人。
我现在正在和一个从未编写过代码，但拥有某种**行为科学背景**的人合作。
他正在开始进行**合法的前沿研究**，研究我们的人工智能在各种**晦涩难懂的情况**下将如何表现。
所以我认为没有人应该认为自己无法为解决这个问题，甚至塑造这种现象做出贡献。

It is not just something that the you know the technical minds can contribute to at this point.
Literally **philosophers** (Philosophers: 哲学家), **fiction writers** (Fiction Writers: 小说家), people literally just messing around.
**Ply the Jailbreaker** (Ply the Jailbreaker: 越狱者，指尝试突破AI系统限制或发现其漏洞的人) you know there's there are almost unlimited **cognitive profiles** (Cognitive Profiles: 认知特征，指个体在思维、学习、问题解决等方面的独特模式和能力) that would be really valuable to add to the mix of people trying to figure out what's going on with AI.

在这一点上，这不仅仅是技术人员可以贡献的东西。
字面意义上的**哲学家**、**小说家**，甚至只是随便玩玩的人。
**越狱者**，你知道，几乎有无限的**认知特征**，如果能加入到试图弄清楚人工智能发展方向的人群中，那将非常有价值。

So, come one, come all is kind of my attitude on that.
That's a great place to to wrap.
Nathan, thank you so much for coming on the podcast.
Thank you, Eric.
It's been fun.

所以，我的态度是，欢迎所有人。
这是一个很好的结束点。
Nathan，非常感谢你来到播客。
谢谢你，Eric。
很开心。
