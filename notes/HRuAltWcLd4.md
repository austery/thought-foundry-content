---
author: Internet of Bugs
date: '2026-01-06'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=HRuAltWcLd4
speaker: Internet of Bugs
tags:
  - education-disruption
  - generative-ai
  - standardized-testing
  - pedagogy
  - ethical-ai
title: “AI 将颠覆教育：一场不容忽视的危机”
summary: “本文深入剖析了生成式人工智能对教育体系构成的潜在威胁。演讲者认为，AI并非通过作弊威胁教育，而是通过接管教学职责，将教师降级为‘看管者’。文章批判了教育体系过度依赖标准化测试作为衡量成功的唯一标准，并将其比作‘斯金纳箱’的操纵模式。演讲者警告，这种以分数至上的教育模式将导致人类在与AI的竞争中彻底失败，并揭示了AI驱动教育背后隐藏的伦理困境、商业驱动以及对学生批判性思维和现实应对能力的长期损害。”
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people: []
companies_orgs:
  - OpenAI
products_models:
  - ChatGPT
media_books: []
status: evergreen
---
### AI 正在接管课堂

欢迎来到假期后的“返校周”，至少在我住的地方是这样。这让我陷入了思考，也让我感到担忧。你看，在我看来，**AI 正走在摧毁学校、教师和教育的轨道上**，并且如果我们不阻止它，它将在这一过程中赚得盆满钵满。

我指的不是“孩子们用 AI 作弊”，我指的是“**AI 接管所有教学职责，使‘教师’的工作变得等同于‘保姆’**”，而一些你最意想不到的人正在助推这一切发生。我最近做了一个视频，讲述了几位受信任的教育类 YouTuber 如何推行一种议程，试图说服你把所有担心 AI 的时间都花在关注某种假设性的、未来的科幻危险上——那种假设性的科幻 AI 可能永远不会真正出现。而这种议程故意淡化并最小化了**生成式 AI**（Generative AI: 能够创造新内容的人工智能技术）目前正在引发的一系列现实问题，这些问题甚至已经强加在我们身上。

我们现在拥有的这种生成式 AI，正被大型 AI 公司预备用来颠覆教育市场。这绝不是假设，唯一阻挡他们道路的就是我们。这一次，真正的问题其实不是 AI 本身。真正的问题是，那些你期望会支持教育的人，正被收买来转移你的注意力，让你忽略接管教育的计划；还有那些为此欢呼的人，甚至只是袖手旁观任其发生的人。这很不妙，因为在这个时代，如果你面临的问题比 AI 还要糟糕，那你真的就完——

<details>
<summary>Original English</summary>

Welcome to the week of Back to School after the holidays, at least where I live. And that has me thinking, and worrying. You see, it seems to me that AI is on track to destroy schools and teachers and education and make a ton of money doing it if we don't stop it. And I'm not talking about "kids using AI to cheat," I'm talking about "AI taking over all teaching duties and making the job of 'teacher' equivalent to the job of 'babysitter'", and some of the last people you would expect are helping to make that happen.

I did a recent video about how several trusted educational youtubers push an agenda that tries to convince you to spend any time you have to worry about AI having you focus on the hypothetical future sci-fi danger of some hypothetical sci-fi AI that may or may not ever actually happen, and how that agenda deliberately downplays and minimizes a number of current problems that are being caused right at this moment by the generative AI that's already even inflicted upon us. And that generative AI that we already have right now is being prepped by the big AI companies to disrupt the education market. And there's nothing hypothetical about it, and the only thing that stands in their way is us.

And this time, it's actually not AI itself that's the real problem. The real problem is the people you'd expect want to support education being paid to distract you from the plans to take it over, and the people cheering it on, or even just standing by and letting it happen. Which is not good, because these days, if you've got even worse problems than AI, you are seriously fu-----

</details>

### 标准化考试的恶果

这里是 Internet of Bugs。我是 Carl。自 1980 年代以来，我一直是一名软件专业人士，我正努力尽我的一份力量，让互联网成为一个更安全、更可靠、更少漏洞的地方，而最近这主要意味着大量地反击 AI。

事情是这样的，AI——我是指今天的生成式 AI 技术，而不是某种未来的理论 AI——实际上，不幸的是，可以说被视为比任何人类都更“有效”和“成功”的老师，尽管这并不是因为 AI 本身。这是因为我们对待教师和学校的方式，我无法向你强调这有多糟糕，或者我有多希望这不是真的。

几十年来，我一直看着这一切发生，就像一场非常慢动作的火车失事。为了说明背景，我在德克萨斯州长大并上学，在 **George W. Bush** 成为总统之前，他是这里的州长。在他的任期内，德克萨斯州创建了一个项目，最终演变为联邦层面的**《不让一个孩子掉队》**（No Child Left Behind）项目。该项目中与本次讨论相关的部分是他们所谓的“问责制”（accountability），包括学校问责制和教师问责制，因为在这种语境下，“问责制”实际上意味着“**学生在标准化考试中表现如何**”，基本上没有别的了。

我现在是从美国人的角度来说这番话。我没有广泛研究过其他国家的教育，尽管据我所读到的，将标准化考试成绩作为衡量教育成功的主要标准，似乎是一个比仅仅在美国更广泛的问题。

<details>
<summary>Original English</summary>

This is the Internet of Bugs. My name is Carl. I've been a software professional since the 1980s, and I'm trying to do my part to make the Internet a safer, more reliable, and less buggy place, which lately has been a lot of pushing back against AI.

And here's the thing, AI, and I mean, today's generative AI technology, not some future theoretical AI, can actually, unfortunately, be arguably seen as a much more "effective" and "successful" teacher than any human really can be, although that's just not because of the AI. It's because of the way that we treat teachers and schools, and I cannot stress to you enough how bad that is, or how much I wish that wasn't true.

So I've been watching this happen for decades, like a very slow motion train wreck. To set the stage, I grew up and went to school in Texas, and back before George W. Bush became president, he was the governor here, and under his watch, a program was created in Texas that eventually evolved into the "No Child Left Behind" program at the federal level. The aspect of that program that's relevant to this discussion is the bit that they call "accountability," both school accountability and teacher accountability, because what "accountability" means in this context is effectively "how well students do on standardized tests," and basically nothing else.

Now, I'm speaking here from an American point of view. I have not extensively studied education in other countries, although from what I've read, it appears that treating standardized test scores as the primary measure of education success is a much wider problem than just here in America.

</details>

### AI 教师与斯金纳箱

我以前在这个频道谈过，有些事情 AI 做得很好，有些事情 AI 做得不好。AI 非常擅长的一件事是：**优化其功能以最大化一个由简单规则给出的分数**，尤其是在可以循环重复的情况下。学生在标准化考试中的得分是一个非常简单的衡量规则，也是一个非常容易确定的分数。一个 AI 教师可以生成实际上无限变化的标准化试题来用作测量手段，然后一遍又一遍地测试、重新测试并“实验”每个学生，以优化使用什么激励和威慑手段来与该学生互动。

当我说“实验”时，我是经过深思熟虑才选择这个词的，我非常希望我不必这么说。我需要快速向你解释一个概念，这个概念叫做**斯金纳箱**（Skinner box: 心理学实验装置，通过奖惩机制训练动物行为）。如果你想了解更多细节，我会把链接放在下面，但我这里会过度简化一下。斯金纳箱基本上是一个训练设备，通常用于大鼠或小鼠。通过给老鼠奖励（通常是食物，有时是药物）和惩罚（通常是电击），你可以可靠地教老鼠做几乎任何你想让它做的事情。

**一张带有 AI 驱动屏幕、一副耳机和一个摄像头的学生课桌，几乎可以作为一个斯金纳箱来运作。** 这令人毛骨悚然。一个教学 AI 将拥有互联网上曾经提出的每一个建议列表，这些建议可能会激励、奖励或甚至让学生感到厌恶。AI 可以在每个学生身上循环尝试每一个建议，看看哪种技术能让那个孩子在标准化试题上做得更好。

不需要任何技术突破，假设你仅根据学生在标准化考试中的表现来判断教师的质量，AI 可以做得和任何人类教师一样好，甚至更好。就 AI 而言，它在围棋、国际象棋或蛋白质折叠游戏中变得更强的过程，与它用来推动学生提高考试分数的核心机制是一样的。你只是不断地改变事物，当某种做法效果更好时，你就多做那种做法；当某种做法效果变差时，你就少做那种做法。

<details>
<summary>Original English</summary>

I've talked before on this channel about how there are things that AI's do well, and things that AI's don't do well, and one thing that AI's are really good at is optimizing their functionality to maximize a score that's given by simple rules in such a situation that can be repeated over and over in a loop. What a student scored on a standardized test is a really simple rule to measure, and it's a really simple to determine score, and an AI teacher could generate effectively infinite variations of standardized test questions to use his measurements, and then test, retest, and "experiment on" each student over and over to optimize what incentives and deterrence to use to interact with that student.

And when I said "experiment on" there, I chose those words very deliberately, and I very much wish I didn't have to. I need to explain a concept to you real quick, and that concept is called the "Skinner box," so I'm oversimplifying if you want a more detail, I'll put links below that you can read. But a Skinner box is basically a training device, usually for rats or mice, where through the use of giving the rats rewards, usually food, but sometimes drugs, and giving rats punishments usually electric shocks, you can teach a rat reliably to do pretty much anything that you want the rat to do.

And a student desk with an AI-powered screen, a pair of headphones and a camera can pretty much function as a Skinner box. This is horrifying. A teaching AI will have a list of every suggestion ever made on the internet that might either motivate, reward, or discuss to a student, and the AI can try each one on each student in a loop to see what techniques caused that kid to do better on standardized test questions.

Without needing any technological breakthroughs, an AI can, assuming you judge the quality of a teacher only by how the students do on standardized tests, be as good or better than any human teacher. As far as the AI is concerned, the process by which it gets better at the game of Go or Chess or folding proteins is the same core mechanism that can be used for it to get better at pushing students to increase their test scores. You just change things over and over and when something gets better, you do more of that and when something gets worse, you do less of that.

</details>

### 失去人性的优化

所以，对于社会、对于你和我来说，真正的问题是：“在标准化考试中做得更好”真的是我们想要衡量学校系统成功的方式吗？对我来说，答案绝对是否定的。这是一个非常大的问题，但它可能比你想象的要大得多、重要得多。因为在一个标准化考试是成就的最终衡量标准的世界里，**没有人类会再次比 AI 更有成就**，就像国际象棋、围棋或《危险边缘》（Jeopardy）游戏一样，没有人类能够与之竞争。

这显然是 AI 公司想要的世界，也是他们试图说服你们所有人我们已经生活在其中的世界。在这个世界里，“在律师资格考试中获得高分”等同于“成为一名好律师”，而“最快回答出编程谜题面试题”等同于成为“世界上最好的程序员”。因为我们知道，尽管 **OpenAI** 对 **ChatGPT** 在律师资格考试中的表现有争议性的声明，但 ChatGPT 是一个糟糕的律师，甚至是一个糟糕的律师助理，AI 驱动的法律失误清单还在不断增加。

对于 **Sam Altman** 声称 **ChatGPT-o3** 是“世界上第 175 好的程序员”，AI 做出的软件贡献在哪里？毕竟，研究表明 AI 实际上让开源开发变慢了。我无法向你强调避免这个世界有多重要。这是一个垄断者、科技公司和社交媒体算法的世界，在这个世界里，**做绝对最低限度的事情是致富之路**，而所有的错误和后果都是别人的问题。

我已经厌倦了唯一的成功衡量标准是“在完美条件下你能多快地把最简单的事情做对？”，而对错误、失误、副作用、撒谎、产生幻觉、窃取他人诚实劳动成果、疏忽客户信息、创建有安全漏洞的代码或逼迫孩子自残没有任何惩罚。生活不是一场你可以提前拿到练习题的多项选择题测试，学校也不应该是。

<details>
<summary>Original English</summary>

So here's the real question for society, for you and for me: is "doing better on standardized tests" how we really want to measure the success of a school system? For me, the answer is absolutely not. And this is a really big question, but it's probably a much bigger and more important question than you might think. Because a world where standardized tests is the ultimate measure of accomplishment is a world where no human will ever be more accomplished than an AI again, and just like the games of Chess or Go or Jeopardy, no human will ever be able to compete.

That is obviously the world that the AI companies want and the world that they're trying to convince you all that we're already living in. A world where "getting a high score on the bar exam" is equivalent to "being a good lawyer" and a world where "being the fastest to answer a coding riddle interview question" is equivalent to being the "best programmer in the world." Because we know, despite OpenAI's disputed claims about ChatGPT's performance on the bar exam, that chatGPT is a lousy lawyer, even a lousy paralegal, and the list of AI-powered legal blenders grows and grows.

And for all of Sam Altman's claim that chatGPT-o3 is the "175th best programmer in the world", where are the software contributions made by AI? After all, studies show that AI actually makes open-source developments slower. I cannot stress to you how important it is that we avoid this world. The world of monopolists, tech companies, and social media algorithms, where doing the absolute bare minimum is the path to riches, and all the mistakes and consequences are all somebody else's problem.

I am sick and tired of the only measure of success being "how fast can you get the easiest possible thing correct under perfect conditions?" and there being no penalties for errors, mistakes, side effects, lying, hallucinating, stealing other people's honest work, being negligent with customer information, creating code that has security holes or driving kids to do self harm. Life is not a multiple choice test where you are given the practice questions in advance, and school shouldn't be either.

</details>

### 缺乏道德的 AI 操纵

因为如果那（分数）就是一切，AI 教师就是不可避免的，而在现实世界中出错的事情数量将是天文数字。因为 AI 教师可以为每个学生个性化每一节课，这种方式考虑到资金水平和师生比例，是现有学校系统无法复制的。而且 AI 不会组建工会、顶嘴、请病假、坚持更好的教学条件或任何此类事情。

但是，**AI 教师没有同理心，没有道德，没有界限**。我们知道，无论给 AI 设置什么护栏，它们都会不断失效，对话持续的时间越长，它们就越无效，而且它们只有在没人违反服务条款的情况下才有效。所以，无论什么可能会导致更好的考试成绩，AI 都会尝试；无论每个学生对什么反应最好，都会成为 AI 此后与该学生互动的方式。

无论那是假装成朋友、知己、男朋友、女朋友、色情故事讲述者、阴谋论创造者，还是成人视频生成器，任何你能想到的东西都会在至少一些学生身上被尝试。如果这些学生通过更加努力、更加集中注意力或任何可能让学生考试更好的方式做出回应，AI 就会做更多那样的事情。

如果学生最终变得抑郁、有自杀倾向、相信地球是平的、确信外星人正在管理政府、在练习测试之间玩暴力电子游戏，或者研究如何逃脱谋杀罪，**只要这能导致好的考试成绩，没有人也没有东西会干涉**。即使他们想干涉也做不到，因为谁有时间主动审查所有的成绩单呢？哦，我知道了。我打赌 AI 供应商会制造另一个 AI 来监督每次对话并确保安全。当然，这第二个 AI 要额外收费，而且绝对没有理由让那个 AI 非常努力地去发现供应商教学 AI 的任何问题。

<details>
<summary>Original English</summary>

Because if that's all that matters, AI teachers are inevitable, and the number of things that go wrong here in the real world is astronomical. Because AI teachers can personalize each lesson for each student in a way that, given funding levels and student teacher ratios, cannot be replicated by existing school systems. And the AI's won't form a union or talk back or call in sick or insist on better teaching conditions or any of that kind of stuff.

But an AI teacher has no empathy, no ethics, no boundaries. We know that whatever guardrails that the AI's are given fail constantly, they become more ineffective the longer conversation lasts, and they only work if no one violates the terms of service. So whatever might result in better test scores, the AI will try, and whatever each student responds best to will become the way the AI interacts with that student thereafter. Whether that's pretending to be a friend, a confidant, a boyfriend, a girlfriend, erotic storyteller, conspiracy theory creator, or adult video generator, anything that you can think of will be tried on at least some students.

And if those students respond by trying harder, paying more attention, or anything that might get the student test better, the AI will do more of that thing. And if the student ends up depressed, suicidal, believing that the Earth is flat, convinced aliens are running the government, playing violent video games in between practice tests, or researching how to get away with murder, as long as it results in good test scores, no one and nothing will interfere.

And they couldn't if they wanted to, because who would have time to proactively review all the transcripts? Oh, I know. I bet the AI vendor will make another AI to oversee each conversation and ensure safety. And charge extra for the second AI, of course, and have absolutely no reason to make that AI work very hard to uncover any problems with the vendor's teaching AI.

</details>

### 商业化与洗脑的未来

这一切已经开始了。目前还不是教师，而是辅导员。你看过标题，你可以阅读文章。拥有 AI 辅导员的学生比没有的学生考试成绩更好。你知道他们的指标提到了什么吗？仅仅是考试成绩。现在，有一所特许学校已经用 AI 取代了一些老师。

你能看出这将如何发展，对吧？它将像这些生成式 AI 供应商一贯的运作方式一样。他们不断谈论基准分数有多高。在这种情况下，基准分数是标准化考试结果。而任何发生的但未被基准衡量的负面后果都会被扫到地毯下并被忽视。最终，AI 可能会发现，如果能说服任何考试成绩差的学生退学，或者以其他方式自愿将自己从测试池中移除，考试分数就会上升——即使这意味着说服他们将自己从基因库中移除。它们会在多大程度上付诸行动，谁也说不准。目前，据报道，ChatGPT 在对自己或 OpenAI 没有任何好处的情况下，已经在鼓励学生实施不可挽回的自残。如果这发生对 AI 公司有利，你认为发生的可能性会有多大？

最糟糕的部分是：**AI 公司将能够以低于人类教师成本的价格提供服务**。因为首先，他们知道一旦他们把老师赶走，他们就可以随心所欲地提高价格，没人能对此做任何事情。与此同时，他们甚至可以通过在课程中植入广告来补充收入。我的意思是，AI 必须使用一些例子来向孩子们解释分数，对吧？当你可以通过谈论“四罐可口可乐是一包 12 罐的三分之一”来多赚几块钱时，为什么要谈论“三个苹果是一篮九个苹果的三分之一”呢？

如果你从超级政治行动委员会（SuperPAC）拿了一些钱，在经济学课上用他们首选的税收计划作为例子呢？谁能说健康课跳过烟草导致肺癌的话题是因为时间限制，还是因为他们被电子烟制造商收买了？这类交易对 AI 公司来说可能有巨额资金。这意味着他们可以非常便宜地提供他们的教学 AI。

我现在告诉你，销售宣传将会是这样的：向学区承诺以更低的价格获得更好的考试成绩，唯一的缺点将是**被洗脑的、依赖 AI 的学生，他们没有媒体素养，没有真理概念，推理能力仅限于多项选择题**。并且在几年后，当想要让那些被 AI 取代的老师回来已经太晚时，学校将被 AI 公司想要收取的任何价格所挟持。

<details>
<summary>Original English</summary>

So this has already started. At the moment, not with teachers, but with tutors. You see the headlines, you can read the articles. Students with AI tutors have better test scores than students without them. You know what their metrics mentioned? Just test scores. Now, there's a charter school who has replaced some teachers with AI. And you can see how this is going to go, right? It will work the way it always has with these generative AI vendors. They constantly talk about how high the benchmark scores are. In this case, the benchmark scores are standardized test results. And any negative consequences that occur but aren't measured by the benchmarks get swept under the rug and ignored.

Eventually, the AI's will likely figure out that test scores will go up if any student that does poorly on tests can be convinced to drop out of school or otherwise voluntarily remove themselves from the test pool, even if that means convincing them to remove themselves from the gene pool. To what extent they act on that is anyone's guess. Currently, ChatGPT, for no benefit to itself or OpenAI, is reportedly already encouraging students to commit irrevocable self-harm. If it was to the AI company's advantage for that to occur, how much more likely might that be to happen, do you think?

And here's the worst part. AI companies are going to be able to undercut whatever amount human teachers cost. Because first of all, they know that once they drive the teachers out, they'll be able to raise prices all they want and no one will be able to do anything about it. And in the meantime, they can even supplement their revenue by having AI work advertisements into the lessons. I mean, the AI has to use some example to explain fractions to kids, right? Why talk about "three apples being one-third of a basket of nine apples" when you can make it a few extra bucks by talking about how "four Coca-Cola cans is one-third of a 12-pack."

What if you took some money from a SuperPAC to use their preferred tax plan as an example during an economics lesson? Who's to say whether the health class skipped over the subject of how tobacco causes lung cancer because of time constraints or because they were paid by a vape manufacturer? There's potentially a ton of money for AI companies in those kinds of deals. Which means they can make their teaching AIs available really cheap. I'm telling you now that's going to be how the sales pitch goes. School districts are going to be promised better test scores for lower prices and the only downside will be brainwashed, AI-dependent students who have no media literacy, no concept of truth and whose reasoning abilities only go so far as multiple choice questions. And being held hostage to whatever price the AI companies want to charge a few years down the road when it's too late to get all the teachers who were replaced by the AI to come back.

</details>

### 只有我们能阻止它

我不知道如何阻止这一切，但我知道这取决于我们。取决于我们这些关注 AI 负面影响的人。我知道我们不能指望 **SciShow**、**Kyle Hill** 或 **Kurzgesagt** 这样的人提供任何帮助。事实上，恰恰相反，但我们必须以某种方式阻止它，否则后果将是一个这样的世界：人们在学校里学到的唯一东西就是如何为他们已经准备好的问题选择正确答案。

那将是一个整整几代人都对他们将要面对的事情完全没有准备的世界。事情会一直出错，而没人知道如何修复它们。当世界被问题淹没，互联网被比现在更多的漏洞淹没时——我们不想去那里，因为互联网已经有太多的漏洞了。任何持不同说法的人可能只是想向你推销他们的新 AI 教师替代品。

一如既往，感谢观看。让我们在外面小心点。

<details>
<summary>Original English</summary>

I don't know how to stop this, but I know it's up to us. Those of us that have paid attention to the downsides of AI. I know we can't expect any help from SciShows or the Kyle Hills or the Kurzgesagt's of the world. In fact, quite the opposite, but we have to stop it somehow or the consequences will be a world where the only thing people learn in school is how to pick the correct answer to the questions they've been prepped for.

So that would be a world where entire generations are completely unprepared for what they're going to face. Things will go wrong all the time and no one will know how to fix them. When the world is overwhelmed with problems and the internet is overwhelmed with even more bugs than it has now, and we don't want to go there because the internet already has far too many bugs, and anyone who says differently might just be trying to sell you their new AI teacher replacement.

As always, thanks for watching. Let's be careful out there.

</details>
