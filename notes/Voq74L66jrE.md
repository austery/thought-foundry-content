---
author: Best Partners TV
date: '2026-01-07'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=Voq74L66jrE
speaker: Best Partners TV
tags:
  - spatial-intelligence
  - embodied-ai
  - data-driven-ai
  - ai-ethics
  - agi-foundations
title: 李飞飞：空间智能——通用AI的物理底座与以人为本的未来
summary: 本视频深入探讨了李飞飞在2025年提出的“空间智能”理念，批判当前大语言模型热潮的局限性，强调AI理解三维物理世界的重要性。内容涵盖智能的进化史、ImageNet项目的数据信仰、World Labs的Marble模型如何构建物理一致的虚拟世界、合成数据在具身智能中的应用，以及AI在医疗和普惠领域的伦理实践。最终，视频呼吁学术界采取非对称竞争策略，并强调“智力无畏”是未来AI人才的核心特质，旨在构建一个能真正感知、交互物理世界的有温度的通用智能。
insight: ''
draft: true
series: ''
category: ai-ml
area: tech-engineering
project: []
people:
  - 李飞飞
  - 亚里士多德
  - 艾伦·图灵
  - 艾达·洛夫莱斯
  - 乔治·米勒
  - 杰弗里·辛顿
  - 约翰·麦卡锡
  - 马文·明斯基
  - Yann LeCun
  - 贾斯汀·约翰逊
companies_orgs:
  - World Labs
  - OpenAI
  - Google
  - Meta
  - Amazon Mechanical Turk
  - NVIDIA
  - 斯坦福HAI
  - AI for All
products_models:
  - ImageNet
  - Marble
  - AlexNet
  - Sora
  - GPT
  - Llama
  - Behavior 1K
  - OmniGibson
  - RTFM
  - WordNet
media_books:
  - 《计算机器与智能》
status: evergreen
---
大家好，这里是最佳拍档。2025年的人工智能行业就像一幅分裂的画卷。生成式AI能够拍出以假乱真的电影片段，大模型参数突破万亿级，投资人挤破头追逐规模神话，仿佛通用人工智能近在咫尺。但是跳出这片狂热，你会发现那些能够真正走进物理世界、帮我们叠被子、照顾病人、修复机器的AI，却始终停留在慢热的状态。它们要么在简单的动作中频繁出错，要么根本无法理解三维空间的基本规律。这种感知温差的背后，藏着一个被大模型狂热所掩盖的核心问题：我们对智能的定义是不是从一开始就跑偏了呢？

今天我们这期视频要盘点的，正是在这场狂欢中保持清醒，甚至逆潮流而行的AI先驱——**李飞飞**。这位曾经用**ImageNet**（ImageNet: 一个大规模视觉数据集），一手开启深度学习时代的科学家，在2025年将所有的精力都投入到了一个更底层的方向上，那就是**空间智能**（Spatial Intelligence: 理解和操作三维物理世界的能力）。通过一整年的公开演讲、实验室实践和深度访谈，她用一套横跨历史、进化生物学、物理学和工程学的完整逻辑告诉我们，当前的生成式AI，哪怕已经能够写出媲美文学大师的文字，也只是摸到了智能的冰山一角。真正的通用智能，必须先学会看懂三维世界的物理规律，学会在空间中行动，而这背后，是5.4亿年的生物进化刻在神经系统里的底层密码。要搞懂李飞飞的空间智能，我们必须先跳出AI等于语言模型的思维惯性，回到一个最根本的问题上：智能到底是什么？

### 智能的演进：从哲学到计算的认知外化

在李飞飞眼中，智能不是凭空出现的一项技术奇迹，而是人类文明和生物进化所共同塑造的一个产物。在2025年的巴黎AI峰会上，李飞飞提出了一个颠覆性的观点：AI不是1956年达特茅斯会议后突然诞生出来的一个技术突变，而是人类花了几千年的时间，试图将理性外化为物理实体的一种工程延续。这个说法看似十分抽象，却能通过几个关键的历史节点清晰地串联起来。

第一个节点是古希腊的哲学家**亚里士多德**。你可能很难想象，李飞飞将他称为第一位计算机科学家。这背后是基于对智能本质的一种深刻洞察。亚里士多德的核心贡献，是第一次把人类混沌和模糊的思维过程提炼成了可以执行的逻辑算法。他提出的**三段论**至今仍然是逻辑推理的基础：“所有人终有一死，苏格拉底是人，因此苏格拉底终有一死。”这个简单的推理其实奠定了AI的核心公理：智能不是不可捉摸的灵感，而是可以拆解、编码，并且在非生物载体上重现的逻辑过程。从那时起，人类就开始了将认知从大脑剥离的尝试。

第二个关键节点是13世纪**机械钟表**的发明。在那之前，人类对时间的感知完全依赖于自然周期，日升月落、四季更迭，这是一种生物性的、主观的感受。而机械钟表的出现彻底改变了这一切，它利用擒纵机构的周期性震荡，将时间这个抽象的概念转化为了机器能够精确计算的物理运动。李飞飞在**斯坦福HAI**（Stanford Human-Centered AI Institute: 斯坦福大学以人为本人工智能研究院）的演讲中强调，这绝不仅仅是计时工具的革新，它证明了一件足以影响后世AI的关键事实，那就是人类的认知功能，比如计算和测量，可以完全脱离生物大脑，移植到由金属、齿轮组成的无机实体上。这种认知外化的实践，为后来**艾伦·图灵**提出机器能否思考的命题埋下了物理可行性的种子。

到了19世纪，**艾达·洛夫莱斯**为这种外化智能注入了创造力的基因。作为**查尔斯·巴贝奇**分析机的核心合作者，艾达没有局限于机器只能计算数字的认知，而是敏锐地洞察到机器处理的本质是符号。只要遵循逻辑规则，机器不仅能够处理数值，还能处理音乐、艺术等复杂的符号系统。她在笔记中大胆地预言分析机有朝一日或许能够作曲。这句话跨越了两个世纪，精准命中了今天生成式AI的核心能力。李飞飞引用这段历史，是想告诉我们，智能从一开始就不只是计算，更包含了创造，而空间智能的终极目标也不仅仅是理解世界，更是创造符合物理规律的世界。

最终，时间来到了20世纪中期，艾伦·图灵在**《计算机器与智能》**中抛出了机器能否思考的终极拷问，直接推动了AI领域的诞生。1956年夏天，**约翰·麦卡锡**、**马文·明斯基**等先驱在**达特茅斯会议**上正式提出了人工智能的术语。一个有趣的历史细节是，当时这些科学家乐观地认为，只需要两个月的集中研究就能破解智能的大部分奥秘。如今看来，这个两个月的项目变成了跨越70年的漫长征途。但是李飞飞却将这种乐观误判解读为一种宝贵的**智力无畏**（Intellectual Fearlessness: 面对根本难题、保持初学者心态的特质），一种坚信智能的奥秘终将能用物理和数学语言解构的科学信仰。而这种信仰也贯穿了李飞飞自己的科研生涯，从AI寒冬中押注ImageNet，到如今在大语言模型的统治时代毅然转向空间智能，她始终在直面最根本的难题，而不是追逐表面的技术热点。

### 进化生物学视角：语言与视觉的算力分配真相

如果说历史为智能提供了人文坐标，那么进化生物学则为李飞飞的空间智能提供了科学的基石。这也是她批判当前大模型路径的核心依据。在斯坦福大学的公开课程中，李飞飞用了一组极具冲击力的进化时间对比。她说，人类语言的诞生仅能追溯到大约30万至50万年，而视觉的进化史要上溯到5.4亿年前的**寒武纪大爆发**。当第一个原始生物的感光细胞捕捉到地球表面的第一束光线时，地球生命就开启了一场长达数亿年的从感知到行动的军备竞赛。

50万年与5.4亿年，这个1比1000的时间差距背后是生物神经系统的算力分配逻辑。李飞飞解释说，在漫长的进化中，生物神经系统99%的算力和架构优化都是为了解决三维世界中的生存问题。比如，如何判断猎物的距离？如何避开障碍物？如何理解物体的几何形状和物理属性？这些能力早就已经刻进了基因里，变成了人类无需思考的潜意识本能。而语言，只是在这个坚实的底座上，为了群体协作和信息传递而发展出的上层应用。它是对高维、复杂物理世界的有损压缩，把阳光斜照下、蜷缩在沙发角落的橘猫简化成了“猫在垫子上”这样离散的文字符号。

这就完美解释了AI领域著名的**莫拉维克悖论**（Moravec's Paradox: 机器在人类认为困难的任务上表现出色，但在人类认为简单的任务上却表现不佳）。为什么AI能够轻松战胜围棋世界冠军、解决复杂的数学证明，却连像叠被子、走楼梯这种人类觉得很简单的动作都难以完成？李飞飞的答案是，前者是人类最近几千年才发展出的显式规则，逻辑清晰、易于编码；而后者是5亿年进化打磨成的隐式物理能力，背后涉及到海量的高维连续变量和非线性物理反馈，计算复杂度极高，只是因为它太过于本能，才被我们低估了难度。她的结论非常明确：如果AI只停留在语言层面，只处理离散的文本符号，它永远只能是**缸中之脑**（Brain in a Vat: 哲学思想实验，指一个脱离物理世界的意识），虽然能理解文字描述的世界，却无法真正感知、交互、生存于物理世界中。

### ImageNet的遗产：数据信仰与深度学习的奇点时刻

要理解李飞飞今天对空间智能的坚持，就必须回溯她在2006年启动的**ImageNet**项目。这个看似堆图片的工程，不仅开启了深度学习时代，更是奠定了李飞飞**数据信仰**（Data Fundamentalism: 坚信大规模数据是智能涌现的基础）的核心逻辑。2025年，在回顾这段历史时，李飞飞毫无保留地分享了当时的反直觉决策，而这些决策，恰恰能够帮我们看懂她今天为何坚定地站在像素至上的阵营方。

2006年前后的AI行业正深陷寒冬，尤其是计算机视觉领域，陷入了一个无解的死循环。当时的主流研究范式是**手工设计特征**（Hand-crafted Features: 人工定义图像特征，如边缘、角点），研究者们花费了几年的时间，试图用人类的逻辑去描述视觉规律，然后在极小的数据集上进行测试。这种研究方式的结果是，模型在训练集上的准确率极高，但是一碰到真实世界的复杂光照、遮挡、形变，识别率就会瞬间崩塌。李飞飞在访谈中直言，当时的算法只能识别出数据集中的猫，也就是那种在标准光照下、正面朝向镜头的猫，但是现实世界中的猫可能在阴影里、可能蜷缩着、可能只露出半个脑袋，这些算法根本认不出来。

问题到底出在哪呢？当时的学术界普遍认为，是算法不够聪明，于是大家纷纷投入更复杂的数学模型研发，试图用更为精巧的公式去拟合少量的数据，就像用高阶函数去拟合只有几个点的曲线一样。但是李飞飞却从信息论的角度提出了完全相反的判断：问题不在于模型，而在于数据不够多。她的逻辑很简单：**泛化能力**（Generalization Ability: 模型适应未见过数据的能力）是智能的核心，而泛化能力的唯一燃料就是规模足够大、覆盖足够广的数据。就像儿童要通过观察上亿个视觉样本才能建立对世界的认知一样，因此，机器智能的涌现也必须建立在海量数据的统计学基础上。这个想法在当时被很多人质疑，甚至被视为不切实际的狂想，因为在那个年代，构建大规模的标注数据集不仅成本极高，还被视为是一种低级的苦力活。在学术界看来，推导一个新的数学公式远比找图片、做标注要优雅得多。但是李飞飞坚信自己的判断，她做出了第一个关键决策：停止优化单一算法，转而全力构建一个前所未有的大规模视觉数据集——**ImageNet**。

构建ImageNet的第一个难题不是去哪里找图片，而是如何定义图片。互联网上的图片浩如烟海，但是如果只是随机抓取，得到的只会是一堆无法被机器理解的数字垃圾。李飞飞团队没有从零开始，而是极具智慧地借鉴了普林斯顿心理学家**乔治·米勒**构建的**WordNet**（WordNet: 一个语义词典，将英文单词组织成层级结构）词汇网络。WordNet不是一个普通的字典，而是一个将人类语言的概念组织成严密层级结构的语义网络，比如波斯猫是猫的下位词，猫是猫科动物的下位词，猫科动物又是哺乳动物的下位词。李飞飞团队将这个语言学骨架完整映射到了视觉领域，构建了包含2.2万个视觉类别的庞大分类体系。这种结构化的设计至关重要，它迫使AI不仅要区分猫和狗，还要在更细粒度上区分波斯猫与暹罗猫，同时理解它们同属猫科动物的层级关系。这种基于语义层级的数据集设计，让ImageNet超越了扁平的图像库，成为一个具有认知深度的视觉知识图谱，从而为后来深度学习模型学习到层次化的特征提供了关键的基础。模型在底层学习边缘、纹理，在中层学习物体部件，在高层学习语义类别，这恰恰模拟了人类视觉皮层的工作原理。

解决了分类体系，下一个更大的挑战是数据标注。按照ImageNet的目标，每个类别有1000张图片，总共1500万张高质量的标注图。仅靠实验室的本科生根本无法完成，李飞飞团队陷入了绝望，直到他们发现了当时刚刚起步的**Amazon Mechanical Turk**（Amazon Mechanical Turk: 亚马逊众包平台）众包平台。这是一次极具开创性的群体智能实验。但是新的问题随之而来：如何保证分布在全球各地、为了赚取微薄报酬的在线工人们都能提供高质量的标注呢？如果有人为了快速完成任务随意点击“是”或“否”，整个数据集的质量都会被污染。为了解决这个问题，李飞飞团队设计了一套精密的算法博弈机制。首先，他们在任务流中随机插入**黄金标准图片**（Golden Standard Images: 已知正确答案的图片），如果工人在这些测试题上出错，系统会立即判定其为不可信，实时丢弃他提交的所有数据。其次，团队引入了**贝叶斯推断模型**（Bayesian Inference Model: 一种统计推断方法），根据多个工人的标注结果计算每张图片的置信度分数。对于争议较大的图片，比如模糊的动物图像或者罕见的物种，系统会自动分发给更多的工人进行重复验证，直到置信度达到预设的阈值为止。最终，来自167个国家的近5万名工人花了两年多时间，完成了数千万次的高质量标注。李飞飞将这个过程形容为机器智能诞生前的母体孕育，在算法还不具备自我学习能力的时候，是人类智能通过众包的方式，手把手地教会机器什么是猫、什么是狗、什么是物理世界的视觉真理。

而ImageNet真正的奇点时刻出现在2012年的**ImageNet挑战赛**上。在那之前，挑战赛的获胜算法错误率一直徘徊在26%到28%之间，这个水平根本无法满足工业应用的需求，整个计算机视觉领域仿佛撞上了一堵无形的墙。但是那一年，**杰弗里·辛顿**的学生**亚历克斯**和**伊利亚**提交的**AlexNet**算法将错误率断崖式地降到了15.3%，比第二名基于传统手工特征的算法低了整整十个百分点，震惊了整个行业。为什么会出现如此巨大的突破？李飞飞在2025年的演讲中提出了**AI爆发的铁三角定律**（AI Explosion's Iron Triangle Law: 数据、算法、算力三者协同推动AI发展），完美解释了这一现象。

1.  **数据**：ImageNet提供的一千五百万张高质量的标注图，刚好超过了深层神经网络训练的临界阈值。深层神经网络拥有数千万个参数，如果没有足够的数据来约束这些参数，模型必然会过拟合。而ImageNet提供的海量的、多样化的监督信号，终于让深层网络吃饱了，得以充分学习到视觉世界的统计规律。
2.  **算法**：**卷积神经网络**（Convolutional Neural Network: 一种专门处理图像的深度学习网络）其实早在20世纪80年代就由**Yann LeCun**等人提出，但是在ImageNet之前，由于缺乏大规模数据的训练，它一直被视为是难以训练的黑盒。AlexNet的核心突破在于两点：一是引入了**ReLU激活函数**（ReLU Activation Function: 一种非线性激活函数），彻底解决了传统**Sigmoid函数**在深层网络中出现的**梯度消失问题**（Vanishing Gradient Problem: 深度学习中梯度过小导致训练停滞的问题）；二是采用了**Dropout正则化技术**（Dropout Regularization: 随机关闭神经元以防止过拟合的技术），通过随机关闭一部分的神经元，防止模型过度依赖于某些局部特征，进一步降低了过拟合的风险。这两项技术彻底激活了深层神经网络的表征潜力。
3.  **算力**：这是最关键的物理加速器。当时的CPU计算能力有限，而深层网络的参数规模和计算量极大，传统的训练方式可能需要几个月甚至几年时间。亚历克斯首次尝试用两块**英伟达GTX 580 GPU**进行模型的并行训练。当时的GPU显存只有3GB，根本装不下整个网络，于是他就设计了一种巧妙的架构，让神经网络的不同部分分布在两块GPU上，只在特定的层进行数据通信。这种针对硬件特性的工程优化，将原本需要几个月的训练时间压缩到了几天，让深层网络的训练从理论可能变成了现实可行。

这三者的完美结合在2012年引发了AI领域的相变。AlexNet的胜利宣告了手工特征时代的彻底终结，开启了**端到端学习**（End-to-End Learning: 模型直接从原始输入到最终输出进行学习）的新纪元。在此之前，计算机视觉专家花费几十年时间研发特征算子，试图用人类的逻辑去描述视觉规律，而AlexNet证明机器通过多层神经网络自动提取的特征，比人类设计的更抽象、更健壮、更能适应复杂场景。这个时刻也确立了现代AI的**Scaling Law**（扩展定律: 模型性能随数据、算力、参数规模的增加而提升）雏形，AI的性能提升不再依赖于对特定规则的修补，而是依赖于模型深度、数据广度与计算强度的指数级扩展。

ImageNet留给今天的最大遗产不仅仅是一个数据集，更是李飞飞的**数据信仰**。智能的涌现需要暴力规模的物质基础，而要让AI理解物理世界，就必须回到更原始、更完整、更接近物理真理的**像素流数据**（Pixel Stream Data: 连续的图像像素数据）。这也正是她在2025年坚定推行空间智能的核心逻辑。语言数据再海量，也只是对物理世界的压缩版，只有直接处理像素流中的几何结构和动力学规律，AI才能真正看懂并走进物理世界。

### Marble模型：构建物理一致性、可交互的三维世界

2025年，李飞飞创办的**World Labs**正式发布了首款核心产品——**Marble**。这款产品的定位从一开始就与当前最火的视频生成模型划清了界限。在李飞飞看来，这些视频生成模型虽然能够产出几秒钟的逼真画面，但是本质上只是在“画皮”，而Marble要做的，是“造骨”，是构建一个具备物理一致性、可交互、可导航的三维世界模型。

为什么这么说呢？我们可以从一个直观的测试来看。如果你让**Sora**（Sora: OpenAI的视频生成模型）生成一段绕着一把椅子旋转拍摄的视频，前几帧可能非常逼真，但是随着摄像机角度的大幅变化，你会发现椅子的结构开始出现错乱，比如背面突然多了一条腿，或者扶手在旋转中融化、变形。李飞飞在**YC创业学校**的分享中解释了背后的原因：这些视频生成模型本质上是在做下一帧的预测，它们通过**Diffusion Transformer**（Diffusion Transformer: 扩散模型与Transformer结合的生成模型）学习像素变化的统计规律，比如水的流动纹理、火焰的跳动轨迹。但是模型的内部并没有建立起一个稳定的3D椅子的结构，它只能根据前一帧的像素分布猜测下一帧的像素应该是什么样，却无法回答椅子背面到底是什么结构，因为它没有**物体恒常性**（Object Permanence: 即使物体不可见，也知道其持续存在的概念）的概念，不知道椅子即使被遮挡也依然是一个完整的3D实体。这种缺乏显式3D结构的模型，注定会在长程视角的变换中遭遇几何坍塌，这是单纯的统计学拟合所无法逾越的一道物理墙。

而Marble的核心突破正是引入了**显式3D表征**（Explicit 3D Representation: 直接描述物体几何形状的3D数据）。它不再输出一段固定的、不可修改的视频，而是根据单张图片、文本提示甚至是粗糙的3D布局，输出一个完整的**4D时空结构**（4D Spacetime Structure: 包含三维空间和时间维度的数据结构）。这里的4D指的是3D空间加上时间维度。用户可以在这个生成的场景中自由地移动摄像机的视角，比如绕着桌子走一圈，或者从地面升到天花板，场景中的物体几何结构始终可以保持一致。甚至你还可以直接编辑场景，比如把红色的沙发改成蓝色，移除茶几，添加一盆植物，所有的空间关系和物理逻辑都不会出错。

实现这个突破的核心技术是**高斯泼溅**（Gaussian Splatting: 一种基于高斯球体的3D场景表示和渲染技术）。李飞飞的团队在技术白皮书里详细解释了选择这个技术的原因。与传统的3D表征方式相比，高斯泼溅有两个不可替代的优势：
1.  **不需要复杂的拓扑连接**：传统的网格表征需要保证顶点之间的连通性，生成的难度极高。而高斯泼溅用数百万个离散的**高斯球体**来描述场景，神经网络生成离散点远比生成连通图更加容易。
2.  **支持实时渲染和显式编辑**：由于**NeRF**（Neural Radiance Fields: 一种隐式3D场景表示方法）是一种隐式表征，所以要想修改物体的颜色或形状，必须重新训练模型。而高斯泼溅中的每个高斯球体都有明确的位置、形状、颜色和不透明度参数，用户可以直接调整这些参数，实时看到修改后的效果。

在Marble中，一个厨房场景就是由数百万个这样的3D高斯球体组成的，它们共同构建了一个既逼真又具备物理一致性的虚拟世界。

除了表征方式的革新，Marble的另一个核心创新是对**Transformer**架构的本质重构。长久以来，人们普遍认为Transformer是为了处理序列设计的。但是World Labs的联合创始人**贾斯汀·约翰逊**在2025年的**Latent Space**访谈中提出了一个极具洞察力的观点：Transformer本质上是处理**集合**（Set: 无序元素的组合）的数学机器，而非处理**序列**（Sequence: 有序元素的排列）的机器。这个判断的核心在于Transformer的核心机制——**自注意力的置换等变性**（Permutation Equivariance of Self-Attention: 自注意力机制对输入顺序不敏感的特性）。简单来说，如果你打乱输入Token的顺序，自注意力矩阵计算出的Token之间的相关性权重是完全不变的，变化的只是输出矩阵的行顺序。这意味着Transformer本身并不知道输入的顺序，它处理的是一个无序的Token集合。之所以它能处理语言，完全是因为我们在输入层强行注入了**位置编码**（Positional Encoding: 编码序列中元素位置信息的方法），告诉模型单词的顺序很重要。这个数学特性让Transformer天生适合处理3D空间数据，因为3D空间中的点本质上就是无序的集合。比如点A和点B在空间中并存，没有固定的先后顺序，只要它们的位置和属性正确，组合起来就是一个完整的场景。因此，Marble的做法是，将3D空间的坐标映射为高维的**位置嵌入**（Positional Embeddings: 将位置信息编码为向量），再注入到Transformer中。模型通过自注意力机制计算空间中不同点之间的几何关系，从而理解整个场景的空间结构。这种方式彻底打破了Transformer只适合语言的迷思，为空间智能借力大模型的庞大算力基础设施提供了数学上的合法性。

不过，李飞飞的团队并没有完全否定隐式表征的价值。他们提出了一种**混合架构**（Hybrid Architecture: 结合隐式和显式表征的系统），试图在隐式推理和显式输出之间架起一座桥梁。在模型的推理核心中，世界是以高度压缩的**隐式高维向量**存在的。这种表征方式虽然不够直观，但是能高效地进行语义推理和物理规律的模拟，比如理解把杯子放在桌子边缘会掉下来的因果关系。而在模型的输出层，则会把这种隐式向量解码为显式的3D结构，比如高斯泼溅。这样既能保证推理的效率和泛化能力，又能支持人类直观的编辑和交互。李飞飞解释说，纯粹的隐式模型就像你知道杯子的概念却无法直接修改它的颜色，而纯粹的显式模型就像你能画出杯子却不懂装水的功能和易碎的物理属性一样。因此，混合架构就是要兼顾两者的优势。

而Marble的下一个技术目标是**实时性**。目前，无论是生成式模型还是传统的3D渲染，都面临着耗时的问题。生成一段10秒的视频可能需要几分钟，渲染一个复杂场景可能需要几个小时。World Labs展示的**RTFM技术**（RTFM Technology: World Labs的实时生成和交互技术）正是为了解决这个问题而生的。它试图在单张**H100 GPU**上实现每秒24帧以上的实时生成和交互。虽然具体的技术细节尚未完全公开，但是李飞飞透露，RTFM采用了两种关键的优化策略：一是**关键帧预测加神经插值**（Keyframe Prediction with Neural Interpolation: 只生成关键帧，中间帧通过AI插值），即只对少数关键帧进行完整的3D生成，中间的过渡帧通过AI快速插值补充，这样既保证了物理一致性又大幅提升了速度；二是借鉴了**一致性模型**（Consistency Model: 一种加速扩散模型采样的方法）的加速采样技术，将Diffusion模型原本需要几百步的去噪过程压缩到一两步的映射，极大地降低了计算量。

李飞飞在演讲中预言，未来的技术栈将不再区分生成模型和渲染引擎，两者将深度融合为**神经空间引擎**（Neural Spatial Engine: 融合AI生成与物理渲染的未来引擎）。这个引擎不再通过光栅化多边形来成像，而是通过神经查询来直接生成光线。它会利用AI的生成能力自动创造出丰富多样的场景内容，同时利用嵌入的物理引擎保证场景的物理一致性。这种融合的终极目标是为了实现**交互式生成**（Interactive Generation: 用户可主动参与和改变生成内容）。用户不再只是被动观看场景的观察者，而是可以主动介入、改变世界的参与者。比如，在神经空间引擎生成的厨房场景中，你可以打开冰箱，AI会实时生成冰箱内部的食物，并且这些食物会符合物理逻辑；你可以拿起水壶倒水，水流的轨迹、杯子里水面的上升高度都会严格遵循流体力学的规律。这种可交互、可修改、物理一致的虚拟世界正是李飞飞心中空间智能的核心形态，它让AI从只能描述世界走向构建世界，与世界交互。

### 具身智能：合成数据闭环与虚拟世界的无限训练

有了能理解和构建3D世界的大脑，下一步就是让AI拥有身体，能够在物理世界中行动，这就是**具身智能**（Embodied AI: 具有物理身体并在物理世界中交互的AI）。但是2025年的机器人领域还面临着一个致命的瓶颈，那就是数据匮乏。李飞飞在**英伟达GTC**（NVIDIA GPU Technology Conference: 英伟达GPU技术大会）的演讲中将这个问题称为**非对称的困境**（Asymmetric Dilemma: 语言模型数据丰富，机器人数据匮乏）。大语言模型可以轻松获取互联网上海量的文本数据，输入和输出都是Token，完美对齐。而机器人的输入是来自摄像头的2D像素流，输出的则是3D动作指令，这种维度错位让机器人学习变得异常困难。

为什么会出现这种困境呢？李飞飞深入剖析了背后的结构性原因。
1.  **数据视角受限**：互联网上的视频虽然多，但几乎都是旁观者视角。你能看到别人如何叠被子、如何炒菜，但是看不到他手上的力度、被子的触感、锅具的重量反馈。而机器人需要的是第一人称的数据，包括视觉、力触觉、本体感受在内的多模态信息，这些数据在现实世界中几乎无法大规模地采集。
2.  **试错成本极高**：物理世界的试错成本极高。让机器人在现实中练习抓取玻璃杯，可能会打碎无数的杯子；练习应对火灾清理、化学泄漏，更是不可能实现。
3.  **时间线性限制**：物理世界的时间是线性的，机器人只能以1倍速积累经验。而AI模型的训练需要海量数据，仅靠现实世界的训练，速度远远跟不上。

面对这个看似无解的难题，李飞飞给出了唯一的解决方案：那就是**合成数据**（Synthetic Data: 通过计算机生成而非真实世界采集的数据）。用AI生成的虚拟世界，为机器人提供无限的、安全的、低成本的训练素材。而她的团队已经在通过**Behavior 1K基准测试**（Behavior 1K Benchmark: 衡量具身智能处理复杂日常任务能力的测试集）和**OmniGibson物理仿真引擎**（OmniGibson Physics Simulation Engine: 高保真物理仿真平台）搭建起了这套解决方案的完整框架。

首先是**Behavior 1K基准测试**。过去，机器人学习的任务大多是抓取积木、开门、移动物体这种简单的、单步骤的动作。但是李飞飞认为，真正的具身智能需要学会“生活”，也就是处理人类日常生活中复杂的、长流程的琐事。因此，Behavior 1K的任务设计并没有凭空创造，而是参考了**美国劳工统计局的时间利用调查**，统计了人类日常生活中最耗时、最希望被自动化的一千项任务，比如擦桌子、洗碗、清理派对现场、给宠物洗澡、拆开圣诞礼物、整理行李箱等等。这些任务的复杂度远超传统的机器人任务。以清理派对现场为例，它需要机器人完成一整套的长程规划：
*   第一步是**场景理解**：机器人需要识别出散落的酒杯、食物残渣、纸巾、礼品盒等不同类型的垃圾。
*   第二步是**任务排序**：确定先捡大块的垃圾，再擦桌子上的液体，最后归位家具的顺序。
*   第三步是**精细操作**：比如抓取易碎的玻璃杯时要控制力度，用抹布擦桌子时要施加合适的法向力，避免液体飞溅。
*   第四步是**异常处理**：如果垃圾桶满了，要先倒掉垃圾再继续清理，而不是机械地重复投放垃圾的动作。

李飞飞说，Behavior 1K的目标是让机器人从执行单一动作的工具，变成能够理解复杂需求、自主解决问题的伙伴。

支撑这些复杂任务的，是与**英伟达**合作开发的**OmniGibson物理仿真引擎**。这是一个高保真的、高真实度的虚拟环境。它与传统仿真引擎的最大区别在于对物理属性的深度模拟，而不仅仅是视觉上的逼真。OmniGibson支持四大核心物理模拟能力：
1.  **刚体模拟**：比如桌椅碰撞时的稳定性、物体堆叠的平衡感，完全符合现实世界的力学规律。
2.  **可变形物体模拟**：这是传统仿真引擎的盲区。OmniGibson能够精准模拟折叠衣物时的布料形变、揉面团时的弹塑性变化、海绵吸水后的质量和形状改变。
3.  **流体模拟**：通过粒子系统来模拟倒水和制作奶昔时的流体动力学，包括液体在不同容器间的转移、泼洒后的扩散、表面张力等细节。
4.  **热力学模拟**：这是极其罕见的高级功能。引擎能够模拟热传导的过程，比如微波炉加热食物时，食物的温度会随着时间变化，从冰冷到温热再到煮熟、烧焦，而这种温度变化会影响机器人的红外感知和操作策略。

有了Behavior 1K的任务基准和OmniGibson的仿真引擎，接下来就是李飞飞提出的**合成数据闭环**（Synthetic Data Loop: AI生成场景、物理模拟、强化学习、迁移现实的自我强化过程）。这是一个左脚踩右脚的自我强化过程。这个闭环的第一步是用**Marble**生成海量的、多样化的3D场景。比如，要训练机器人洗碗，不需要手工建模一个厨房，而是让Marble自动生成一千种含有不同的灶台布局、不同光照、不同材质的厨房，每个厨房的水槽位置、水龙头的样式、餐具的摆放都不相同，极大地扩展了数据的多样性。第二步，将这些只有视觉信息的场景导入OmniGibson引擎，为每个物体赋予物理属性，比如盘子的质量、碗的易碎程度、水的密度和粘度。第三步，在这些虚拟场景中用**强化学习**（Reinforcement Learning: 通过与环境交互学习最优策略的机器学习方法）训练机器人**Agent**（Agent: 在环境中感知和行动的智能体）。由于是虚拟环境，我们可以同时并行运行几万个训练实例，让机器人在几天内积累几百万年的经验，快速学会应对各种复杂情况。第四步，将训练好的策略迁移到现实世界的物理机器人上，同时利用**域随机化技术**（Domain Randomization: 在仿真环境中随机化参数以提高模型泛化能力）在虚拟场景中随机地调整光照、材质、物体的位置，让机器人学会适应现实世界中的各种变化，弥合模拟到现实的鸿沟。

这个闭环的核心魅力在于**自举**（Bootstrapping: 通过自身能力提升自身性能）。Marble生成的场景越逼真、越多样化，OmniGibson的物理模拟就越精准，训练出的机器人策略就越强大。而更强大的机器人，在现实世界中执行任务时，能够反馈更多真实的物理数据，这些数据又可以反过来优化Marble的生成能力和OmniGibson的模拟精度，形成一个不断强化的正向循环。李飞飞在访谈中坚定地表示，现实世界的数据永远无法满足具身智能的需求，既不够多，也不够安全。只有让AI自己生成虚拟世界，才能给机器人提供无限的训练素材，这是突破莫拉维克悖论、实现通用机器人的唯一的、确定性的路径。

### 以人为本的AI：医疗应用与普惠价值的深度融合

聊了这么多硬核的技术架构和理论，我们也不能忘记李飞飞一直是以人为本的AI的坚定倡导者。2025年，她在**斯坦福HAI**的工作将空间智能从实验室里的黑科技变成了能守护生命、恢复尊严、赋能普通人的现实工具。其中最具代表性的就是环境智能在医疗领域的应用，以及脑机接口和AI普惠项目。

首先是**环境智能**（Ambient Intelligence: 融入环境的隐形AI），它的核心理念是“最好的AI应该是消失在环境中的AI”。李飞飞在斯坦福医学中心的试点项目中，将深度摄像头、热成像传感器等智能设备无缝嵌入到重症监护室、老年病房和手术室中，结合空间智能算法，在不干扰医护人员和病人日常活动的前提下，实现了实时的感知和智能分析。这种智能不是通过穿戴设备实现的，而是让空间本身具备了视觉和理解力。在设计之初，李飞飞就特别强调**隐私设计优先**（Privacy-by-Design: 在系统设计初期就考虑隐私保护）的原则。考虑到医疗场景的高隐私敏感性，系统刻意避开了**RGB摄像头**（RGB Camera: 捕捉彩色图像的摄像头），转而使用**深度传感器**（Depth Sensor: 捕捉物体距离信息的传感器）。它只能捕捉到模糊的人体轮廓和骨架图，无法识别出具体身份，这样就从物理层面彻底阻断了隐私泄露的风险。这种技术选择体现了李飞飞对技术伦理的深刻理解，因为在医疗这种特殊场景中，技术必须在效用和隐私之间找到一个完美的平衡点，不能为了功能而牺牲人的基本权利。

在具体应用中，环境智能展现出了巨大的实用价值。在老年病房，系统实现了**跌倒预警**。AI通过分析病人的步态、身体倾斜角度等微小的特征，能够在病人下床时步态不稳的瞬间预判到跌倒风险，并且在跌倒发生的前几秒钟向护士站发出预警，同时自动打开病房门口的警示灯。这个功能将传统的事后救治转变为了事前预防，极大地降低了老年患者跌倒受伤的概率。在重症监护室，系统则承担了**活动监测**的任务，会自动记录病人的翻身频率、肢体活动的范围、呼吸的节奏等细微数据。这些数据是评估病人康复进度和病情变化的关键指标，但是在过去只能靠护士在巡房时偶尔的手工记录，数据零散而且不连续。现在系统能够实现24小时的全量数字化记录，为医生提供精准的诊疗依据。而在手术室，空间智能算法被用在**器械追踪**方面，通过实时定位手术刀、纱布、镊子等器械的位置，自动记录器械的使用流程和去向，防止异物被遗留体内这种严重的医疗事故。

除了守护病人，环境智能还将目标对准了医护人员的减负。李飞飞在访谈中多次提到，她对护士群体的工作现状深感担忧。护士每次轮班的步行距离常常超过10公里，还要处理几百项琐碎的任务，从补充输液袋、更换床单，到记录生命体征、回应病人的呼叫等等。高强度的工作负荷是导致医疗错误和职业倦怠的主要原因。因此，环境智能的另一个核心目标是优化医疗流程，为护士松绑。系统通过分析病房的**人流热力图**、医疗物资的消耗速度以及护士的任务执行路径，能够自动优化物资的摆放位置和巡房路线。比如，系统可以通过预测某个病房的输液即将结束，提前通知附近的护士准备好新的输液袋，避免护士在多个病房之间来回奔波；通过分析手术时长和器械的使用频率，优化手术室的器械摆放顺序，减少医生和护士的取放时间。李飞飞强调，之所以设计这些功能，不是为了监视护士的工作效率，而是为了通过算法的辅助，让护士从繁琐的后勤事务中解放出来，回归到她们最核心的职责，也就是关怀病人和提供情感支持上。技术应该是护士的第二双眼睛，在她们疲惫时提供安全冗余，而不是成为压垮她们的监工。

如果说环境智能是隐形的守护，那么李飞飞团队展示的**脑机接口烹饪案例**则是对人的尊严的极致守护。在巴黎AI峰会上，李飞飞播放了一段令人动容的视频：一位重度瘫痪的患者失去了所有肢体的行动能力，生活完全依赖他人的照料。研究团队为他配备了**非侵入式脑电图设备**（Non-invasive EEG Device: 无需植入体内的脑电波监测设备），通过采集他的脑波信号，结合空间智能算法，解码他的意图，比如想拿起勺子、想切菜、想打开燃气灶。这些意图信号被实时传递给机械臂，患者仅凭意念就完成了一系列复杂的精细操作，从洗菜、切肉，到调配酱汁、摆盘，最终成功制作出一份完整的日式寿喜烧。视频播放结束后，李飞飞动情地说，这个案例的意义绝不是AI能做饭这么简单。对于这位患者而言，能够通过机械臂为自己或家人做一顿饭，意味着他重新获得了与物理世界交互的权利，找回了生活的自主权和尊严。在这个过程中，AI扮演的不是替代者，而是协作者。它弥补了患者受损的生理机能，但是完全保留了他作为一名厨师的意志、决策和创造力。这个案例完美诠释了李飞飞的技术伦理观，那就是技术的终极目标不是替代人，而是**增强人**（Human Augmentation: 通过技术提升人类能力）。我们不仅要问AI能做什么，更要问它如何帮助人类保留尊严、实现价值。

除了高端的医疗应用，李飞飞同样关注AI的普惠性。她与前学生共同创立了非营利组织**AI for All**（AI for All: 普惠AI非营利组织），旨在打破AI领域的精英壁垒。她敏锐地意识到，如果AI的开发者仅仅是一群同质化的精英，那么开发出的技术难免会带有偏见或者盲区。比如人脸识别对深色皮肤人群的准确率较低，医疗AI模型对罕见病的诊断能力不足。这些问题的根源在于开发者缺乏对不同群体、不同社区真实需求的理解。AI for All通过为来自农村地区、城市低收入社区以及历史上代表性不足群体的高中生提供免费的暑期项目和实习机会，让他们有机会学习到AI技术，接触到前沿科研。这些年轻人没有去追逐微调大模型、开发聊天机器人这些热点，而是聚焦于自己社区的真实问题。有的学生利用AI来优化救护车的调度算法，缩短偏远地区患者的急救时间；有的学生开发了基于图像识别的农村水质评估工具，帮助村民快速判断饮用水是否安全；有的学生则利用卫星图像和AI设计了野火预警系统，保护森林资源和社区安全。李飞飞在分享这些案例时眼中满是欣慰。在她看来，AI不应该是少数精英的专利，而是属于每一个想改变自己生活和社区的人。通过普及AI素养，让更多元的群体参与到AI的开发和应用中，我们才能构建出更公平、更包容、更有温度的AI未来。

### AI生态与未来人才：学术界的非对称策略与智力无畏

在探讨完空间智能的技术、应用之后，李飞飞还对AI行业的生态发展提出了深刻的思考。尤其是在工业界掌握了海量算力、大模型规模竞赛愈演愈烈的今天，学术界应该扮演什么角色呢？开源与闭源的边界在哪里呢？未来的AI人才又需要具备什么样的特质呢？

首先是**学术界的非对称竞争策略**（Academic Asymmetric Competition Strategy: 学术界应避免与工业界在规模上竞争，转而聚焦独特优势）。李飞飞在与贾斯汀·约翰逊的访谈中明确警告年轻的研究者和博士生，不要试图在训练最大模型的赛道上与**Google**、**Meta**、**OpenAI**这些科技巨头竞争。大学实验室根本无法获得成千上万张GPU，在规模这个单一维度上，学术界毫无胜算。她提出，学术界应该坚守自己的核心优势，聚焦三个工业界不愿碰的新战场：
1.  **古怪的架构探索**：工业界受限于季度财报和产品落地的压力，往往倾向于优化现有的Transformer架构，追求短期性能的提升。而学术界没有这些束缚，可以自由探索那些看似疯狂、短期无用，但是可能颠覆未来的技术路径。贾斯汀·约翰逊补充道，现在的神经网络都是为GPU优化的，但是20年后的硬件架构可能完全不同，比如**光子计算**、**量子计算**。学术界应该提前思考非GPU架构下的AI算法形态，甚至通过设计全新的**硬件原语**（Hardware Primitives: 硬件层面的基本操作单元），打破**冯·诺依曼架构**（Von Neumann Architecture: 存储程序计算机的基本架构）的瓶颈。
2.  **理论基础与可解释性**：李飞飞指出，当前的AI发展已经呈现出了实验领先于理论的态势。我们知道Transformer有效，知道大模型能够涌现出复杂的能力，但是我们不知道这些能力是如何产生的，也无法解释模型为什么会出现偏见和幻觉等问题。学术界的核心使命就是打开AI的黑盒，研究**机制可解释性**（Mechanistic Interpretability: 理解AI模型内部工作原理），为AI建立起坚实的数学和物理基础，从根本上理解智能涌现的机制。只有这样，AI才能从靠经验驱动的工程升级为靠理论指导的科学。
3.  **跨学科AI**：利用AI解决生物学、材料学、天文学、核聚变等基础科学问题。这是大学相较于单个科技公司的天然优势，这些领域需要深厚的领域知识，而不是单纯的算力堆砌。比如，利用AI预测**蛋白质折叠**，帮助研发新型药物；或者利用AI分析**核聚变**的实验数据，优化反应条件；以及利用AI处理天文观测数据，发现新的天体和物理规律。李飞飞认为，这些跨学科研究不仅能够推动基础科学的进步，也能为AI带来新的突破，因为基础科学中的复杂问题会倒逼AI发展出更强的推理和建模能力。

在开源与闭源的争论上，李飞飞的观点也是显得务实又深刻。她认为，开源不是一种慈善行为，而是一种精明的商业杠杆，或者是对抗垄断的生态武器。以**Meta**开源**Llama**为例，这并不是一种纯粹的利他主义，而是基于自身清晰的生态战略。Meta的核心商业模式不是卖模型的API，而是通过开源构建底层的技术标准，吸引全球开发者进入自己的生态系统，从而削弱OpenAI、Google等竞争对手的护城河。相反，OpenAI选择闭源**GPT**系列，是因为模型本身就是核心的商业护城河，闭源能够保护技术秘密，维持产品的独特性和商业优势。李飞飞强调，这两种选择没有绝对的对错，关键在于是否匹配公司的商业模式和发展目标。但是，从更宏观的行业生态角度来看，李飞飞坚决捍卫开源的公共价值。她指出，如果AI技术被少数巨头垄断，不仅会导致创新停滞，还会固化偏见。开源让AI技术像科学知识一样，成为全人类共享的财富。初创公司可以基于开源模型快速地迭代产品，学术界可以利用开源工具开展研究，发展中国家的开发者可以用低成本获得先进的技术。因此，李飞飞呼吁政策的制定者们应该保护开源社区，防止巨头通过算力垄断、数据垄断等手段扼杀开源创新。AI是推动社会进步的公共产品，不应该成为少数公司的私产。

而贯穿李飞飞所有思考的，是她反复强调的**智力无畏**。这也是她认为未来AI人才最核心的特质。她结合自己的经历，分享了这种无畏的内涵：从普林斯顿的物理系博士转到当时还很冷门的计算机视觉领域；从ImageNet的数据驱动转到大模型狂热时代的空间智能。每一次转型，都是跳出舒适区，面对未知的挑战。但是这种无畏不是盲目的鲁莽，而是基于**第一性原理**（First Principles: 从最基本的事实出发进行思考）的信仰，坚信自己所研究的是根本问题，坚信智能的奥秘终能被解构。她特别提到了**初学者心态**（Beginner's Mind: 保持开放、好奇、无偏见的学习态度）的重要性。她回忆起小时候，父亲在旧货市场对每一件小工具都充满了好奇心，这种对于未知事物的探索欲是保持智力无畏的源泉。在AI技术每6个月就迭代一次的今天，过去的经验很容易成为认知枷锁。唯有保持无知的好奇，敢于在陌生领域从头学起，才能跟上技术爆炸的速度。她给年轻从业者的建议是：不要追逐当下的热点，应该去寻找那些根本且困难的问题，因为难，所以竞争者少；因为根本，所以价值长久。

### 总结：空间智能——AGI的物理底座与以人为本的未来

2025年，当杰弗里·辛顿还在警示硅基智能可能超越人类的非对称优势时，李飞飞选择了一条更底层的道路。她没有纠结于语言模型的参数规模，而是回归到智能的本质，试图教会机器要像造物主一样理解和构建物理世界。她用5.4亿年的进化史告诉我们，语言只是智能的表层应用，视觉与行动才是历经亿万年打磨的生存底座。她用ImageNet的成功证明，智能的涌现需要数据的暴力规模，而物理世界的真理隐藏在像素流的连续性中，而非离散的文本符号里。她用Marble模型和神经空间引擎展示了空间智能的核心不是生成逼真的视频，而是构建具备物理一致性、可交互的三维世界。她用合成数据和Behavior 1K为具身智能打通了从虚拟到现实的路径。最后，她用医疗应用和AI普惠项目提醒我们，技术的终极目标永远是守护人的尊严，赋能人的价值。

或许，空间智能不会像大语言模型那样在短时间内引发全民式的狂欢，它没有酷炫的对话能力，也没有惊艳的生成效果，甚至需要我们重新理解智能的定义。但是它正在默默搭建着**AGI**（Artificial General Intelligence: 通用人工智能，具备人类智能水平的AI）的物理底座。当AI能够真正看懂三维世界的几何规律，能够理解物体的物理属性，能够在空间中自由地行动，能够帮助人类解决现实中的琐事和难题时，那时的智能才是完整的、有温度的、能够真正融入人类社会的智能。就像李飞飞在2025的演讲中所说，她的科研生涯始终在追逐一个北极星，那就是理解智能的本质。从ImageNet到空间智能，从数据驱动到以人为本，这条道路漫长且艰难，但是她坚信，只有回到物理世界的本质，回到人类智能的进化根源，AI才能真正实现它的价值。相信未来的AI不再会是困在屏幕里的文字匠人，而是一个能够触摸、感知、创造物理世界的同行者。感谢收看本期视频，我们下期再见。