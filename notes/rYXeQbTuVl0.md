---
area: tech-work
category: ai-ml
companies_orgs:
- Meta
- OpenAI
- NVIDIA
- Anthropic
- Google
- Apple
- Microsoft
- Amazon
date: '2025-04-29'
draft: true
guest: ''
insight: ''
layout: post.njk
media_books: []
people:
- Mark Zuckerberg
- Sam Altman
products_models:
- Llama 3
- Llama 4
- Meta AI
- Scout
- Maverick
- Behemoth
- o4-mini
- Gemini 2.5 Flash
- Sonnet 3.7
- Claude
- MetaMate
- Llama Guard
- Code Shield
- Ray-Ban Meta
- Android
- iMessage
- WhatsApp
- Instagram
- Facebook
- Netflix
- ESPN
- TikTok
project:
- ai-impact-analysis
series: ''
source: https://www.youtube.com/watch?v=rYXeQbTuVl0
speaker: Dwarkesh Patel
status: evergreen
summary: Meta首席执行官马克·扎克伯格在播客中分享了Llama 4的最新进展，包括其多模态能力和未来规划。他深入探讨了开源AI与闭源AI的竞争格局，强调Meta
  AI的北极星指标是用户价值而非传统基准。扎克伯格还展望了AI在软件工程、客户支持、社交娱乐等领域的巨大潜力，并讨论了AI治理、模型价值观编码及基础设施建设等关键议题。
tags:
- ai-agent
- ai-infrastructure
- ai-social-impact
- open-source-ai
title: 扎克伯格：AI将在18个月内编写Meta大部分代码
---

马克，感谢你再次来到播客。很高兴能来，很高兴见到你。我也是。你上次来的时候发布了 **Llama 3**，现在又发布了 **Llama 4** 的第一个版本。没错。有什么新东西？有什么令人兴奋的？有什么变化？整个领域变化如此之快，感觉自从我们上次谈话以来，一切都发生了巨大变化。**Meta AI** 现在每月有近 **10亿** 人使用，这相当惊人。我认为今年对所有这些都将是重要的一年，特别是当你启动个性化循环时。我们现在才刚刚开始真正构建它，这不仅包括所有算法对你感兴趣的内容（如信息流、个人资料信息、社交图谱信息）的理解，还包括你与AI的互动方式。这将是下一个令人兴奋的重点，我对此非常看好。

### Llama 4 模型发布与规划

模型方面也持续取得令人印象深刻的进展。我对首批 **Llama 4** 版本感到非常满意。我们宣布了四款模型，并发布了前两款——**Scout** 和 **Maverick**，它们是中小型模型。最受欢迎的 **Llama 3** 模型是 **80亿参数** 的版本，所以我们也会在 **Llama 4** 系列中推出一个类似的模型，内部代号是“小Llama”，预计会在未来几个月内发布。**Scout** 和 **Maverick** 表现出色，它们提供了市面上任何模型中最高的“智能成本比”。它们天生就是**多模态**（Multimodal: 能够处理和理解多种类型数据，如文本、图像、音频等的人工智能模型），效率很高，可以在单个主机上运行。它们旨在为我们内部构建的许多用例提供高效率和低延迟。这就是我们的宗旨：我们构建我们想要的东西，然后将其开源，以便其他人也能使用。我对此感到非常兴奋。

我也对即将推出的 **Behemoth** 模型感到兴奋。这将是我们的第一个前沿模型，拥有超过 **2万亿参数**。正如其名字所示，它非常庞大。我们正在努力研究如何使其对人们有用。它如此庞大，以至于我们不得不构建大量基础设施才能自行进行后期训练。现在我们正在思考，普通开发者如何才能真正使用这样的模型？我们如何使其有用——也许通过**模型蒸馏**（Model Distillation: 一种将大型复杂模型（教师模型）的知识转移到小型简单模型（学生模型）的技术，以提高效率和降低成本），将其提炼成合理大小的模型来运行？因为你显然不会想在消费级模型中运行这样的东西。正如你去年在 **Llama 3** 上看到的那样，最初的发布令人兴奋，然后我们全年都在此基础上进行构建。**3.1** 版本发布了 **4050亿参数** 的模型，**3.2** 版本则包含了所有多模态功能。我们今年也基本有类似的路线图，所以有很多事情正在进行。

### 开源AI与基准测试的挑战

我很想听听更多关于这方面的信息。有一种印象认为，过去一年中，最佳闭源模型与最佳开源模型之间的差距扩大了。我知道 **Llama 4** 的完整模型系列尚未发布，但 **Llama 4 Maverick** 在 **Chatbot Arena** 上排名第35位。在许多主要**基准测试**（Benchmarking: 通过标准化的测试集和评估指标来衡量和比较不同模型性能的方法）中，**o4-mini** 或 **Gemini 2.5 Flash** 似乎都击败了同级别的 **Maverick**。你如何看待这种印象？

有几点。首先，我实际上认为今年对开源总体而言是非常好的一年。如果你回顾去年，**Llama** 是唯一真正具有超级创新性的开源模型。现在，这个领域中有很多这样的模型。总的来说，关于今年开源模型将普遍超越闭源模型，成为最广泛使用的模型这一预测，我认为正在按计划实现。一个有趣的惊喜——在某些方面是积极的，在某些方面是消极的，但总体来说是好的——是它不仅仅是 **Llama**。市面上有很多优秀的开源模型，我认为这非常好。

然后是推理现象，你提到了 **o3**、**o4** 和其他模型。这正在发生专业化。如果你想要一个在数学问题、编码或类似任务上表现最好的模型，那么那些消耗更多**推理时计算**（Inference-time Compute: 模型在进行预测或生成输出时所需的计算资源）以提供更高智能的推理模型，是一种非常有吸引力的范式。我们也在构建 **Llama 4** 推理模型，它会在某个时候发布。但对于我们关心的许多应用来说，延迟和良好的“智能成本比”是更重要的产品属性。如果你主要是为消费产品设计，人们不想等待半分钟才能得到答案。如果你能在半秒内给他们一个普遍不错的答案，那是一个很好的权衡。我认为这两者最终都将成为重要的方向。我乐观地认为，推理模型将随着时间的推移与核心语言模型集成。**Google** 在最近的一些 **Gemini** 模型中就走了这个方向，我认为这非常有前景。但我认为会有很多不同的事情发生。

你还提到了 **Chatbot Arena**，我认为这很有趣，它指出了基准测试的挑战。你如何知道哪些模型适合哪些任务？过去一年，我们一直努力将更多模型锚定在 **Meta AI** 产品的**北极星指标**（North Star Metric: 指导产品或业务增长的单一关键指标，通常与用户价值直接相关）用例上。开源基准测试以及像 **LM Arena** 这样的任何特定测试的问题在于，它们往往偏向于非常具体的用例，而这些用例通常并非普通用户在你的产品中实际会做的事情。它们试图衡量的东西组合，往往与人们在任何特定产品中关心的东西不同。

正因为如此，我们发现过度优化这类东西会让我们误入歧途。它实际上并没有带来最高质量的产品、最多的使用量以及人们在使用我们的 **Meta AI** 产品时获得的最佳反馈。所以，我们正在努力将我们的北极星指标锚定在用户向我们报告的产品价值、他们所说的需求以及他们所揭示的偏好上，并利用我们已有的经验。有时这些基准测试只是不太吻合。我认为其中很多都非常容易被“玩弄”。在 **Arena** 上你会看到像 **Sonnet 3.7** 这样的优秀模型并没有排在前列。我们的团队相对容易地调整出一个 **Llama 4 Maverick** 版本，使其位居榜首。但我们发布的纯模型根本没有为此进行任何调整，所以它排名靠后。因此，在使用这些基准测试时需要谨慎。我们将主要以产品为导向。

你认为是否存在某种基准，能够客观衡量不同模型之间的用户价值北极星指标，让你能说：“我需要 **Llama 4** 在这方面脱颖而出”？我们的基准基本上是 **Meta AI** 中的用户价值。但这无法与其他模型进行比较。我们也许可以，因为我们可能会运行其他模型并进行判断。这就是开源的优势之一。你有一个优秀的社区，他们可以找出你的不足之处，并指出：“好的，你的模型在哪里不好，在哪里好？”

### 通用人工智能与物理基础设施的瓶颈

目前，所有这些模型都针对略微不同的组合进行了优化。所有领先的实验室都在努力实现相同的目标，即创造**通用人工智能**（Artificial General Intelligence, AGI: 指能够理解或学习任何人类智力任务的AI）、**超级智能**（Superintelligence: 指在几乎所有领域都大大超越最聪明人类智力的AI），无论你称之为什。AI可以带来一个富足的世界，每个人都拥有这些超人工具来创造他们想要的一切。这极大地赋能了人们，并创造了所有这些经济效益。无论你如何定义，这都是许多实验室正在追求的目标。但毫无疑问，不同的人优化了不同的东西。我认为 **Anthropic** 的人真正专注于编码和围绕它的代理。**OpenAI** 的人，我认为最近更多地转向了推理。

有一个领域，如果我不得不猜测，我认为它最终会成为最常用的：快速、交互自然、原生的**多模态**，以你想要的方式融入你的日常生活。我想你已经有机会试用我们正在发布的新的 **Meta AI** 应用程序了。我们放在里面的一个有趣功能是**全双工语音**（Full-duplex Voice: 指在语音交流中，双方可以同时说话和听到对方，就像自然人际对话一样）的演示。它还处于早期阶段，这就是为什么我们还没有将其设为应用程序中的默认语音模型的原因。但它那种自然的对话方式真的很有趣且引人注目。能够将它与适当的个性化结合起来，将带来一种产品体验，如果你快进几年，我想我们整天都会和AI谈论我们好奇的各种事情。

你会有你的手机，在浏览信息流应用时和它交谈。它会为你提供关于不同内容的上下文，回答你的问题，在你与消息应用中的人互动时提供帮助。最终，我认为我们将在日常生活中佩戴眼镜或其他类型的AI设备，并全天候无缝地与它互动。这就是北极星指标。无论哪些基准能让人们觉得质量达到了他们想要互动的水平，那最终对我们来说才是最重要的。我那天有机会试用了 **Orion** 和 **Meta AI** 应用程序，语音模式非常流畅，给我留下了深刻印象。

关于不同实验室优化的重点——为了更好地理解他们的观点——我认为他们中的很多人相信，一旦你完全自动化了软件工程和AI研究，就能引发一场**智能爆炸**（Intelligence Explosion: 一种假设，认为一旦AI达到一定水平，它将能够自我改进，导致智能呈指数级增长）。你将拥有数百万个这些软件工程师的副本，它们可以在几周或几个月内，而不是几年内，复制 **Llama 1** 和 **Llama 4** 之间发生的研究改进规模。所以，关键在于完成软件工程师的闭环，然后你就能成为第一个实现 **ASI** 的公司。你对此有何看法？

我个人认为这很有说服力。这也是我们投入大量精力进行编码工作的原因。我们正在 **Meta** 内部开发多个编码代理。因为我们并不是一家企业软件公司，我们主要是为自己构建这些工具。同样，我们追求一个特定的目标。我们不打算构建一个通用的开发者工具。我们正在努力构建一个**编码代理**（Coding Agent: 能够独立理解需求、编写、测试和部署代码的AI代理）和一个AI研究代理，专门用于推进 **Llama** 的研究。它完全融入了我们的工具链和所有相关系统。这很重要，并将成为完成这项工作的重要组成部分。我猜测在未来 **12到18个月** 内，我们将达到大部分用于这些工作的代码都由AI编写的程度。我指的不是自动补全。今天你已经有了很好的自动补全功能，你开始写一些东西，它就能完成一段代码。我指的是更像这样：你给它一个目标，它就能运行测试，改进功能，发现问题，它编写的代码质量甚至比团队中普通优秀的人还要高。我认为这肯定会是其中非常重要的一部分。

但我不知道这是否是全部。这会是一个庞大的行业，也将是AI发展的重要组成部分。但我认为仍然存在……一种思考方式是，这是一个巨大的领域。我不认为只会有一家公司，用一个优化函数尽可能地服务所有人。会有很多不同的实验室在不同领域进行领先的工作。有些会更专注于企业或编码，有些会更专注于生产力，有些会更专注于社交或娱乐。在助手领域，有些会更侧重于信息和生产力，有些则更侧重于陪伴。会有很多有趣和娱乐性的东西出现在你的信息流中。

这是一个巨大的空间。走向 **AGI** 未来有趣的一点是，有很多共同的线索需要被发明，但也有很多东西仍然需要被创造。如果我不得不猜测，我认为你会开始看到不同群体之间出现更多的专业化。你基本上同意会发生智能爆炸，我们会得到类似超级智能的东西，这对我来说真的很有趣。如果我误解了你，请告诉我。如果是这样，为什么还要费心去做个人助理之类的东西呢？为什么不先达到超人智能，然后再处理其他一切呢？

我认为这只是飞轮的一个方面。我通常不同意“快速起飞”观点的原因之一是，构建物理基础设施需要时间。如果你想建立一个**千兆瓦级计算集群**，那需要时间。**NVIDIA** 需要时间来稳定他们新一代的系统。然后你需要解决网络问题。然后你需要建造建筑物，获得许可，获取能源。这可能意味着燃气轮机或绿色能源，无论哪种方式，都有一个完整的供应链。我们上次在播客中和你谈了很多。我认为其中一些只是物理世界、人类时间的事情。当你开始在堆栈的某个部分获得更多智能时，你只会遇到不同的瓶颈。工程总是这样运作的：解决一个瓶颈，就会出现另一个瓶颈。

系统中或使之运作良好的另一个瓶颈是人们习惯于学习并与系统形成反馈循环。这些系统不会在人们神奇地知道如何使用它们的情况下完全成形。存在一个协同进化过程，人们正在学习如何最好地使用这些AI助手。同时，AI助手也在学习人们关心什么。开发者正在改进AI助手。你也在建立一个上下文基础。一两年后你醒来，助手可以引用你两年前谈论过的事情，这非常酷。即使你在第一天就推出了完美的产品，你也无法做到这一点。如果它两年前不存在，它就无法引用你两年前谈论过的事情。

所以我想我的观点是，存在巨大的智能增长。人们与AI助手的互动以及围绕它的学习反馈和数据飞轮呈现出非常快速的曲线。然后还有供应链和基础设施的建设，以及监管框架的建立，以实现许多物理基础设施的规模化。在某种程度上，所有这些都将是必要的，而不仅仅是编码部分。

### AI与广告系统：计算瓶颈与假设质量

我举一个具体的例子，我认为很有趣。即使回到几年前，我们有一个项目，我认为是在我们的广告团队，旨在自动化排名实验。这是一个相当受限的环境，不是开放式的代码。它基本上是查看公司的整个历史——广告系统中每个工程师做过的每个实验——并查看哪些有效，哪些无效，以及结果是什么。然后基本上为我们应该运行的不同测试制定新的假设，这些测试可以提高广告系统的性能。

我们基本发现，我们受限于运行测试的计算能力，这取决于假设的数量。事实证明，即使我们广告团队现在只有人类，我们已经有比实际拥有的计算资源或测试人群更多的优秀想法需要测试。即使你有 **35亿** 人使用你的产品，你仍然希望每个测试都具有统计学意义。它需要有数十万或数百万人参与。通过测试，你只能获得这么多的吞吐量。所以我们已经到了一个地步，即使只有我们现有的人，我们也无法真正测试所有我们想测试的东西。

现在，仅仅能够测试更多东西并不一定会增加价值。我们需要达到这样的程度：AI生成的假设的平均质量，要优于团队中最优秀的人类能够实际测试的所有“及格线以上”的东西，这样它才会有边际上的用处。我认为我们很快就能达到这个目标。但这不仅仅是“好的，这个东西能写代码了，然后一切都突然大规模改进了。”还有现实世界的限制需要克服。然后你需要有计算资源和人员进行测试。随着时间的推移，当质量逐渐提高时，我们是否会在五到十年后，没有任何人类群体能像AI系统一样提出好的假设？我不知道，也许吧。在那个世界里，显然所有的价值都将由此创造。但这并不是第一步。

### Meta AI 的用户分布与未来愿景

如果你认同这种观点，即智能正朝着这个方向发展，那么看好 **Meta** 的原因显然是你拥有所有这些分发渠道。你还可以利用这些渠道学习更多对训练有用的东西。你提到 **Meta AI** 应用程序现在有 **10亿** 活跃用户。不是应用程序。应用程序是我们现在刚刚推出的一个独立产品。对于想使用它的人来说会很有趣，这是一个很酷的体验。我们也可以谈谈这个，因为我们正在其中尝试一些新颖且值得讨论的想法。

但我主要指的是我们的应用程序。**Meta AI** 实际上在 **WhatsApp** 中使用最多。**WhatsApp** 主要在美国以外使用。我们刚在美国突破了 **1亿** 用户，但它不是美国主要的即时通讯系统，**iMessage** 才是。所以美国人可能会低估 **Meta AI** 的使用量。但独立应用程序之所以如此重要，部分原因在于美国，由于多种原因，是最重要的国家之一。而 **WhatsApp** 是人们使用 **Meta AI** 的主要方式，但它不是美国主要的即时通讯系统，这意味着我们需要另一种方式来构建一流的、真正呈现在人们面前的体验。

我想，为了完成这个问题，看跌的观点是，如果AI的未来不再仅仅是回答你的问题，而更多是成为一个虚拟同事，那么 **WhatsApp** 中的 **Meta AI** 如何为你提供相关的训练数据来打造一个完全自主的程序员或远程工作者，这就不清楚了。在这种情况下，谁现在拥有更多的 **LLM** 分发渠道，是不是就不那么重要了？

### AI的多样化应用与商业模式

再次，我只是认为会有不同的事物。想象一下，你坐在互联网发展的开端，你问：“互联网的主要用途会是什么？是知识工作还是大规模的消费者应用？”两者都有。你不需要选择一个。世界是庞大而复杂的。一家公司能构建所有这些东西吗？通常答案是否定的。但就你的问题而言，人们大多不会在 **WhatsApp** 中编写代码。我也不认为人们开始在 **WhatsApp** 中编写代码会成为一个主要用例。尽管我确实认为人们会要求AI做很多事情，而这些事情最终会导致AI进行编码，而他们自己不一定知道。那是另一回事。

我们确实有很多人在 **Meta** 编写代码，他们使用 **Meta AI**。我们有一个内部工具叫做 **MetaMate**，以及围绕它构建的许多不同的编码和AI研究代理。这有它自己的反馈循环，我认为它在加速这些工作方面会非常出色。但再次强调，会有很多事情。AI几乎肯定会引发知识工作和代码领域的巨大革命。我还认为它将是下一代搜索以及人们如何获取信息和执行更复杂信息任务的方式。

我也认为这会很有趣。人们会用它来娱乐。今天互联网上的很多内容都是表情包和幽默。我们拥有触手可及的这项惊人技术。当你想到人类有多少精力用于娱乐自己、设计、推动文化发展以及寻找幽默的方式来解释我们观察到的文化现象时，这既令人惊叹又有趣。我认为这在未来几乎肯定会是这样。看看 **Instagram** 和 **Facebook** 等事物的演变。如果你回到10、15、20年前，内容是文字。然后我们都拥有带摄像头的手机，大部分内容变成了照片。然后移动网络变得足够好，如果你想在手机上观看视频，它就不会一直缓冲。所以这变得很好了。

在过去的 **10年** 里，大部分内容都转向了视频。今天，人们在 **Facebook** 和 **Instagram** 上花费的大部分时间都在观看视频。但你认为五年后我们还会坐在信息流中，只消费视频媒体吗？不，它将是交互式的。你会在信息流中滚动。可能会有内容一开始看起来像 **Reel**，但你可以和它对话，或者与它互动，它会回应，或者改变它正在做的事情。或者你可以像玩游戏一样跳进去与它互动。所有这些都将是AI。我的观点是会有所有这些不同的事物。我们雄心勃勃，所以我们正在研究其中很多。但我认为没有一家公司能做到所有这些。

### AI关系与用户福祉

关于AI生成内容和AI互动这一点，人们已经与AI治疗师、AI朋友建立了有意义的关系，甚至可能更多。随着这些AI变得更加独特、更具个性、更智能、更自发、更有趣等等，这种关系只会变得更加紧密。人们将与AI建立关系。我们如何确保这些是健康的关系？

有很多问题只有在你开始看到行为时才能真正回答。最重要的是，从一开始就提出这个问题并在每一步都关心它。但我也认为，如果一开始就过于规定性地指出“我们认为这些事情不好”，往往会扼杀价值。人们使用对他们有价值的东西。我设计产品的一个核心指导原则是：人们很聪明，他们知道什么对他们的生活有价值。产品偶尔会出问题，你需要确保你的产品设计良好以尽量减少这种情况。但如果你认为某人正在做的事情不好，而他们认为它非常有价值，那么根据我的经验，大多数时候他们是对的，你是错的。你只是还没有找到理解他们所做的事情为何对他们的生活有价值和有帮助的框架。这是我思考这个问题的主要方式。

我确实认为人们会使用AI来完成很多这些社交任务。目前，我们看到人们使用 **Meta AI** 的主要用途之一是，讨论他们生活中需要与他人进行的困难对话。“我和女朋友有这个问题，帮我进行这次对话。”或者“我需要在工作中与老板进行一次艰难的对话，我该如何进行？”这非常有帮助。随着个性化循环的启动，AI会越来越了解你，那将非常引人注目。

我在社交媒体领域工作了很长时间，有一个数据总是让我觉得很疯狂。平均每个美国人拥有的朋友少于三个，少于三个他们认为是朋友的人。而普通人对有意义的更多朋友有需求。我认为大概是15个朋友左右。在某个时候你会想：“好吧，我太忙了，我无法处理更多的人。”但普通人渴望比他们现有更多的联系。很多人担心，这是否会取代现实世界的面对面联系？我的默认回答是，可能不会。

当你能够进行面对面交流时，物理连接有许多更好的地方。但现实是，人们只是没有他们想要的那么多连接。很多时候他们比自己希望的更感到孤独。所以我认为很多这些事情——今天可能带有一点污名的事情——随着时间的推移，我们作为一个社会会找到词汇来阐明它们为何有价值，为什么做这些事情的人是理性的，以及它实际上如何为他们的生活增加价值。但这个领域也还处于早期阶段。有一些公司正在做虚拟治疗师、虚拟女友之类的事情。但它还非常早期。这些东西的实体化仍然相当薄弱。你打开它，它只是治疗师或你正在交谈的人的图像。有时有一些非常粗糙的动画，但它不是一个实体。你已经看到了我们在 **Reality Labs** 正在做的事情，那里有 **Codec Avatars**，它真的感觉像一个真实的人。那就是它将要去的地方。你将能够与AI进行始终在线的视频聊天。手势也很重要。当你真正进行对话时，超过一半的交流不是你所说的词语，而是所有非语言的东西。

我前几天确实有机会体验了一下 **Orion**，我觉得它非常令人印象深刻。我总体上对这项技术持乐观态度。总的来说，就像你提到的，我在这方面相当自由主义。如果人们正在做某事，他们可能认为这对他们有好处。尽管，我实际上不知道如果有人在使用 **TikTok**，他们是否会说他们对自己花在 **TikTok** 上的时间感到满意。我对此大多持乐观态度，因为如果我们要生活在这个 **AGI** 的未来世界中，我们也需要用这样的工具来提升我们的能力。而且总的来说，如果到处都能看到 **吉卜力工作室** 的作品之类的，世界会变得更美好。

我曾担心你的团队给我展示的一个旗舰用例。我坐在早餐桌旁，余光中只是一堆正在滚动的 **Reels**。也许未来，我的AI女友就在屏幕的另一边。所以我担心我们只是在消除所有摩擦，让我们完全被技术“奖励劫持”。我们如何确保五年后不会发生这种情况？

### AR眼镜与数字世界的融合

再次，我认为人们对他们想要什么有很好的判断力。你看到的那个体验只是一个演示，展示了多任务处理和全息图。我同意，我不认为未来是一个你总是在视野角落里有东西试图争夺你注意力的世界。我不认为人们会太喜欢那样。

当我们设计这些眼镜时，这实际上是我们非常注意的事情之一。眼镜最重要的事情可能就是“不碍事”，并成为一副好眼镜。顺便说一句，我认为这也是 **Ray-Ban Meta** 产品如此成功的部分原因。它非常适合听音乐、接打电话、拍照和录像。当你需要AI时，它就在那里。但当你不需要时，它就是一副人们喜欢的、好看的眼镜，它很好地“不碍事”。我猜测这将是增强现实未来一个非常重要的设计原则。我在这里看到的主要事情是：数字世界在我们的生活中如此重要，但我们访问它的唯一方式是通过这些物理的数字屏幕，这有点疯狂。你有手机，有电脑。你可以在墙上挂一台大电视，这是一个巨大的物理物体。

似乎我们已经到了技术可以完全融合物理世界和数字世界的地步。这就是全息叠加层所能做到的。但我同意，我认为围绕它的设计原则很大一部分将是如何与人互动。你将能够无缝地将数字物品带入这些互动中，并做一些很酷的事情。如果我想给你看一些东西，这里有一个屏幕。我们可以与它互动，它可以是3D的，我们可以玩它。你想玩纸牌游戏吗？好的，这是一副牌，我们可以玩。如果我们两个人在一起，还有一个朋友以全息图的形式加入，他们也可以参与。但在那个世界里——就像你不想让你的物理空间杂乱无章，因为它会在心理上让你感到疲惫一样——我也不认为人们会希望他们的数字-物理空间有那种感觉。这更多是一种审美规范，需要解决，但我认为我们会解决的。

### AI基础设施与国际竞争

回到AI的对话，你提到了物理基础设施可能是一个巨大的瓶颈。关于其他开源模型，比如 **DeepSeek** 等，**DeepSeek** 目前的计算能力比 **Meta** 这样的实验室要少，但你可以说它与 **Llama** 模型具有竞争力。如果中国在物理基础设施、工业规模扩张、提供更多电力和更多数据中心方面做得更好，你有多担心他们可能会在这里击败我们？

这是一场真正的竞争。你正在看到产业政策的真正发挥。中国正在提供更多的电力。正因为如此，美国确实需要专注于简化数据中心建设和能源生产的能力。否则，我认为我们将处于显著劣势。同时，一些对芯片等产品的出口管制，我认为你可以看到它们确实在发挥作用。关于 **DeepSeek** 有很多讨论，说“哦，他们做了所有这些非常令人印象深刻的底层优化。”现实是，他们确实做到了，这令人印象深刻。

但你接着会问：“为什么他们必须这样做，而美国实验室却没有？”那是因为他们使用的是部分受限的芯片，这是 **NVIDIA** 因出口管制而唯一被允许在中国销售的。**DeepSeek** 基本上不得不花费大量的精力和时间进行底层基础设施优化，而美国实验室则不必这样做。现在，他们在文本方面取得了不错的成果。**DeepSeek** 仅支持文本。其基础设施令人印象深刻，文本结果也令人印象深刻。但现在发布的每一个新的主要模型都是**多模态**的，包括图像和语音。他们的模型不是。

现在问题是，为什么会这样？我不认为是因为他们没有能力做到。而是因为他们不得不将精力花在这些基础设施优化上，以克服出口管制的事实。但当你将 **Llama 4** 与 **DeepSeek** 进行比较时——我的推理模型尚未发布，所以 **R1** 比较尚不清楚——但我们在 **DeepSeek** 所做的所有文本方面基本上处于同一水平，但模型更小。因此，我们为 **Llama** 在文本方面所做的“智能成本比”更低。在多模态方面，我们实际上处于领先地位，而这在他们的模型中根本不存在。所以，当你将 **Llama 4** 模型与 **DeepSeek** 所做的进行比较时，它们是优秀的。我认为人们通常会更喜欢使用 **Llama 4** 模型。但这里有一个有趣的特点，那就是那里显然有一个优秀的团队在做事情。你提出关于电力可及性、计算和芯片可及性的问题是正确的，因为你看到不同实验室所做的工作以及其发展方式，在某种程度上是受这些因素影响的。

### 开源许可证与模型价值观

**Sam Altman** 最近发推文说，**OpenAI** 将发布一个开源的 **SOTA** 推理模型。我想推文的一部分是他们不会做任何愚蠢的事情，比如规定你只有在用户少于 **7亿** 时才能使用它。**DeepSeek** 采用 **MIT 许可证**，而 **Llama** 许可证中的一些条款要求你在使用它的应用程序上注明“使用 **Llama** 构建”，或者任何你使用 **Llama** 训练的模型都必须以“Llama”开头。你如何看待这个许可证？它对开发者来说是否应该不那么繁琐？

你看，我们基本上开创了开源 **LLM** 的先河。所以我认为这个许可证并不繁琐。当我们开始推动开源时，行业内有一场大辩论：这甚至是一件合理的事情吗？你能用开源做一些安全可靠的事情吗？开源是否能足够有竞争力，以至于有人会关心？基本上，当我们回答这些问题时，很多艰苦的工作都是由 **Meta** 的团队完成的。行业中还有其他人，但实际上，**Llama** 模型是真正以巨大的方式开启了整个开源AI时代。

如果我们投入所有这些精力，那么至少，如果这些大型云公司——比如 **Microsoft**、**Amazon** 和 **Google**——要转而销售我们的模型，那么他们至少应该在这样做之前与我们进行一次对话，讨论我们应该建立什么样的商业安排。我们许可证的目标，通常不是阻止人们使用模型。我们只是认为，如果你是这些公司之一，或者你是 **Apple**，就来和我们谈谈你想做什么。让我们找到一种富有成效的方式一起做。我认为这通常是没问题的。

现在，如果行业中开源部分的发展方向是出现很多其他优秀的选项，并且许可证最终成为人们不想使用 **Llama** 的原因，那么我们将不得不重新评估策略，看看那时做什么才有意义。但我认为我们还没有到那个地步。在实践中，我们并没有看到公司来找我们说：“我们不想使用这个，因为你的许可证规定如果你达到 **7亿** 用户，你就必须来和我们谈。”到目前为止，这更多是我们从开源纯粹主义者那里听到的，比如“这是否像你希望的那样是一个纯粹的开源模型？”

这场辩论自开源之初就存在。所有 **GPL 许可证**（GNU General Public License, GPL: 一种自由软件许可证，要求任何基于GPL软件修改或分发的作品也必须以GPL许可证发布）与其它许可证的争论，你是否需要让任何接触开源的东西也必须开源？或者人们可以拿去以不同的方式使用？我确信围绕这个问题会有持续的辩论。但如果你花费数十亿美元训练这些模型，我认为要求其他公司——那些规模庞大、可以轻易与我们建立关系的公司——在使用之前与我们交谈，这似乎是一件相当合理的事情。

如果事实证明其他模型也非常好，有很多优秀的开源模型。那么你的部分使命就完成了，也许其他模型在编码方面更好。是否存在这样一个世界：你只是说，“看，开源生态系统很健康，竞争很充分。我们很高兴使用其他模型，无论是用于 **Meta** 内部的软件工程还是部署到我们的应用程序。我们不一定需要用 **Llama** 来构建”？

### 自主构建与开源生态的未来

再次，我们做了很多事情。让我们退一步看。我们构建自己的大型模型的原因是，我们希望能够精确地构建我们想要的东西。世界上没有其他模型完全符合我们的要求。如果它们是开源的，你可以拿来并以不同的方式进行微调。但你仍然需要处理模型架构。它们在尺寸上做出不同的权衡，这会影响延迟和推理成本。在我们运营的规模下，这些东西非常重要。我们之所以将 **Llama Scout** 和 **Maverick** 模型设计成特定尺寸，是有特定原因的。它们适合在一个主机上运行，我们想要特定的延迟——特别是对于我们正在开发的语音模型——我们希望它能渗透到我们正在做的所有事情中，从眼镜到我们所有的应用程序，再到 **Meta AI** 应用程序等等。

只有当你自己构建这些东西时，你才能获得一定程度的命运掌控权。话虽如此，AI将用于每个公司所做的每一件事情。当我们构建一个大型模型时，我们也必须选择要为哪些内部用例进行优化。那么，这是否意味着对于某些事情，我们可能会说：“好吧，也许 **Claude** 更适合构建这个团队正在使用的特定开发工具”？好的，那就用它。太棒了。我们不想束手束脚。我们正在做很多不同的事情。

你还问，是否因为其他人也在做开源，所以它就不再重要了？对此，我有点担心。你必须问自己：对于现在出现并正在做开源的任何人——既然我们已经做到了——如果我们没有做，他们还会做开源吗？我认为有少数人看到了越来越多的开发正在走向开源的趋势，他们会想：“哦，糟糕，我们必须赶上这趟列车，否则我们就会输。”如果你有一个闭源模型 **API**，越来越多的开发者不想要那样的东西。所以你看到很多其他玩家开始在开源方面做一些工作。但目前尚不清楚这是否只是尝试，或者对他们来说是否像对我们一样是根本性的。一个很好的例子是 **Android** 的情况。**Android** 最初是开源的。现在实际上没有任何真正的开源替代品。随着时间的推移，**Android** 变得越来越封闭。

所以如果你是我们，你需要担心的是，如果我们停止推动这个行业朝着这个方向发展，所有其他人……也许他们只是因为想与我们竞争以及我们正在推动的方向才这样做。他们已经通过实际行动表明了，如果开源不存在，他们会怎么做。而那不是开源。我们只需要小心，不要依赖这种持续的行为来决定我们公司未来将构建的技术。

### 美国模型标准与AI安全

我还听你提过，围绕像 **Llama** 这样的美国模型建立标准很重要。我想了解一下你的逻辑。对于某些类型的网络，**Apple App Store** 确实对其构建方式有很大的限制。但似乎如果你为 **DeepSeek** 构建了某种支架，你也可以很容易地将其切换到 **Llama 4**，特别是在不同代模型之间。**Llama 3** 不是 **MoE**（Mixture of Experts: 专家混合模型，一种神经网络架构，通过组合多个“专家”网络的输出来处理不同类型的输入或任务），而 **Llama 4** 是。所以模型代际之间也在发生变化。那么，认为事物会以这种依赖特定标准的方式构建起来的原因是什么？

我不确定，你说的“依赖”是什么意思？我的意思是，人们为 **Llama** 而非一般的 **LLM** 进行构建很重要，因为这将决定未来的标准。

我认为这些模型编码了价值观和看待世界的方式。我们早期有过一次有趣的经历，我们拿了一个早期版本的 **Llama** 并对其进行了翻译。我认为是法语，或者其他语言。我们从法国人那里得到的反馈是：“这听起来像一个学会说法语的美国人，不像一个法国人。”我们当时想，“什么意思，它法语说得不好吗？”不，它法语说得很好。只是它看待世界的方式似乎有点美国化。所以我认为这些模型中内置了一些微妙的东西。

随着时间的推移，随着模型变得越来越复杂，它们应该能够体现世界各地不同的价值观。所以这可能不是一个特别复杂的例子，但我认为它说明了这一点。我们在测试一些模型时看到的一些东西，特别是来自中国的模型，其中编码了某些价值观。而这不仅仅是简单的微调就能改变的。现在，语言模型——或者说内置了某种世界模型的模型——拥有更多的价值观。推理，我想你也可以说它有价值观。但推理模型的一个优点是它们是在可验证的问题上进行训练的。如果你的模型在做数学题，你需要担心文化偏见吗？可能不需要。我认为某个地方构建的推理模型会以一种狡猾的方式解决数学问题来“植入”你的思想，这种可能性很低。

但围绕编码还有一系列不同的问题，这是另一个可验证的领域。你需要担心有一天醒来，如果你使用的模型与另一个政府有某种联系，它是否可以在代码中嵌入漏洞，供其情报机构日后利用？在未来的某个版本中，你正在使用来自另一个国家的模型，它正在保护你的系统。然后你醒来，发现一切都以那个国家知道而你不知道的方式变得脆弱。或者它在某个时候开启了一个漏洞。这些都是真实的问题。我非常感兴趣研究这个问题，因为我认为开源最有趣的事情之一是模型**蒸馏**的能力。对于大多数人来说，主要价值不仅仅是拿一个现成的模型说：“好的，**Meta** 构建了这个版本的 **Llama**。我要拿它并在我的应用程序中完全运行它。”不，如果你只是运行我们的东西，你的应用程序就不会做任何不同的事情。你至少会微调它，或者尝试将其蒸馏成一个不同的模型。当我们谈到像 **Behemoth** 这样的模型时，其全部价值在于能够获取如此高水平的智能，并将其蒸馏成一个你真正想要运行的更小的模型。

这就是蒸馏的魅力。我认为这是过去一年来，自从我们上次坐下来以来，真正成为一种非常强大的技术之一。我认为它的效果比大多数人预测的要好。你基本上可以拿一个大得多的模型，捕获其 **90%** 或 **95%** 的智能，并在一个只有其 **10%** 大小的模型中运行。现在，你能获得 **100%** 的智能吗？不能。但以 **10%** 的成本获得 **95%** 的智能，对于很多事情来说都相当不错。

另一个有趣的地方是，现在有了这个更加多样化的开源社区，不仅仅是 **Llama**。你还有其他模型。你能够从多个来源进行蒸馏。所以现在你基本上可以说：“好的，**Llama** 在这方面非常出色。也许它的架构非常好，因为它本质上是多模态的，更适合推理，效率更高。但假设另一个模型在编码方面更好。”好的，太棒了。你可以从两者中进行蒸馏，并为自己的用例构建一个比单独使用任何一个都更好的模型。这很酷。

但你确实需要解决安全问题，即知道你可以以安全可靠的方式进行蒸馏。这是我们一直在研究并投入大量时间的事情。我们基本发现，任何与语言相关的东西都相当复杂。其中嵌入了大量的价值观。除非你不在乎从你正在蒸馏的模型中继承价值观，否则你可能不想直接蒸馏一个纯粹的语言世界模型。

然而，在推理方面，你可以通过将其限制在可验证的领域，并运行代码清洁度和安全过滤器，从而取得很大的进展。无论是使用开源的 **Llama Guard**（Llama Guard: Meta开源的安全工具，用于检测和过滤大语言模型中的不安全或有害内容），还是我们开发的 **Code Shield**（Code Shield: Meta开源的代码安全工具，用于确保AI生成代码的安全性）开源工具，这些工具都允许你将不同的输入整合到你的模型中，并确保输入和输出都是安全的。

然后就是大量的**红队测试**（Red Teaming: 一种安全测试方法，模拟攻击者行为来发现系统或模型的漏洞和弱点）。让专家审查模型并提问：“好的，这个模型在蒸馏后是否做了我们不希望它做的事情？”我认为结合这些技术，你可以在可验证领域相当安全地进行推理方面的蒸馏。对此我非常有信心，我们也为此做了大量研究。但我认为这是一个非常大的问题：如何做好蒸馏？因为有如此多的价值可以被释放。但同时，我确实认为不同的模型中嵌入了一些根本性的偏见。

### AI的商业化与未来就业

谈到可释放的价值，你认为AI的正确变现方式会是什么？显然数字广告非常有利可图。但作为 **GDP** 总量的一部分，它与所有远程工作相比仍然很小。即使你能在不取代工作的情况下提高生产力，那仍然价值数万亿美元。广告可能不是唯一的变现方式吗？你对此有何看法？

就像我们之前谈到的，会有所有这些不同的应用，不同的应用倾向于不同的事物。当你想要为人们提供免费服务时，广告是很好的。因为它是免费的，你需要以某种方式覆盖成本。广告解决了人们不需要为某些东西付费的问题。他们可以免费获得一些很棒的东西。顺便说一句，对于现代广告系统，很多时候人们认为如果你做得好，广告会为产品增加价值。你需要擅长排名，并且需要有足够的广告库存流动性。如果系统中只有五个广告商，无论你排名能力多强，你可能都无法向某人展示他们感兴趣的东西。但如果系统中有 **100万** 个广告商，那么如果你擅长从大海捞针中挑选出那个人会感兴趣的不同“针”，那么你很可能会找到一些非常有吸引力的东西。

所以广告肯定有它的位置。但显然也会有其他商业模式，包括那些成本更高，以至于免费提供根本不划算的模式。顺便说一句，这样的商业模式一直都存在。社交媒体之所以免费且由广告支持，但如果你想看 **Netflix** 或 **ESPN** 之类的，你就需要付费，这是有原因的。制作这些内容对他们来说非常昂贵。他们可能无法在服务中获得足够的广告收入来弥补制作内容的成本。基本上，你只需要付费才能访问它。权衡是使用的人会更少。你谈论的不是数十亿人，而是数亿人使用这些服务。这里有一个价值转换。我认为这里也类似。不是每个人都会想要一个软件工程师，或者一千个软件工程代理，或者其他什么。但如果你想要，那你就可能愿意为此支付数千、数万甚至数十万美元。

这只是说明了需要创造的不同事物的多样性。在整个光谱的每个点上都会有商业模式。在 **Meta**，对于消费者部分，我们肯定希望有一个免费的东西。我确信那最终会是广告支持的。但我也认为我们希望有一种商业模式，支持人们使用任意数量的计算来做比免费服务中提供更有意义的事情。为此，我确信我们最终会有一个高级服务。但我认为我们在这方面的基本价值观是，我们希望服务世界上尽可能多的人。

### 领导力与AI发展方向

你如何跟踪所有这些不同的项目，其中一些我们今天已经谈到了。我确信还有很多我甚至不知道的项目。作为监督一切的 **CEO**，从对 **Llama** 团队说：“这是你们应该使用的超参数”，到仅仅下达一个指令：“去把AI做得更好”，这之间有一个很大的范围。而且项目如此之多。你如何思考你如何才能最好地发挥你的附加价值并监督所有这些事情？

我大部分时间都花在努力让优秀的人才加入团队上。除了这一点，还有一些跨团队的工作。你构建了 **Meta AI**，然后你想把它整合到 **WhatsApp** 或 **Instagram** 中。好的，现在我需要让这些团队进行沟通。然后会有很多问题，比如：“你希望 **WhatsApp** 中 **Meta AI** 的对话感觉像其他 **WhatsApp** 对话，还是希望它感觉像其他AI聊天体验？”这些有不同的惯例。所以有很多有趣的问题需要回答，关于这些东西如何基本上融入我们正在做的一切。

然后我们所做的还有另一个部分，那就是推动基础设施建设。如果你想建立一个**千兆瓦级计算集群**，首先，这对我们进行基础设施建设的方式有很多影响。它对你与正在建设这些设施的不同州进行互动的方式有政治影响。它对公司的财务有影响，比如：“好吧，世界经济存在很多不确定性。我们现在是否要加倍投入基础设施？如果是，我们还想在公司内部做出哪些其他权衡？”这些都是其他人很难真正做出的决定。

然后是关于品味和质量的问题。什么时候一个东西足够好，我们想把它发布出去？总的来说，我是公司这方面的负责人。尽管我们还有很多其他人，我认为他们也有很好的品味，并且也是不同事物的过滤器。这些基本上就是这些领域。AI很有趣，因为它比我们做的其他一些事情，更多地是由研究和模型驱动，而不是真正由产品驱动。你不能只设计你想要的产品，然后尝试构建模型来适应它。你真的需要首先设计模型和你想要的能力，然后你会得到一些**涌现特性**。然后你会发现，“哦，你可以构建一些不同的东西，因为这以某种方式实现了。”归根结底，人们想要使用最好的模型。

这部分解释了为什么当我们谈论构建最个性化的AI、最好的语音、最好的个性化——以及一个具有极低延迟的非常智能的体验时——这些都是我们需要设计整个系统来构建的东西。这就是为什么我们正在开发**全双工语音**。这就是为什么我们正在开发个性化，既能从你与AI的互动中进行良好的记忆提取，又能接入所有其他 **Meta** 系统。这就是为什么我们设计了特定的模型，使其具有我们所设定的尺寸和延迟**参数**（Parameters: 机器学习模型中的可调变量，决定了模型从数据中学习到的知识量和复杂性）。

### AI治理与社会影响

谈到政治，有一种看法认为一些科技领袖一直在与 **特朗普** 结盟。你和其他人向他的就职典礼捐款，并与他同台，我想你还解决了一起诉讼，使他们获得了 **2500万美元**。我想知道这里发生了什么？这感觉像是与政府打交道的成本吗？最好的思考方式是什么？

我对此的看法是，他是美国总统。作为一家美国公司，我们的默认立场应该是努力与任何执政的政府建立富有成效的关系。我们也曾尝试向前几届政府提供支持。我曾公开表达过对前一届政府的一些不满，他们基本上没有与我们或更广泛的商界进行接触。坦率地说，这对于在某些事情上取得进展是必要的。如果你没有对话，如果他们不优先考虑做这些事情，我们就无法建立我们所需的能源水平。很多人想写关于人们走向哪个方向的故事。我们正在努力构建伟大的东西，我们希望与人们建立富有成效的关系。我是这样看待的。我猜大多数其他人也是这样看待的，但显然，我不能代表他们发言。

你曾公开表示，你重新思考了过去在内容审核方面与政府互动和顺从政府的一些方式。你如何看待AI治理？因为如果AI像我们认为的那样强大，政府会想要介入。在这方面，最有效的方法是什么，政府应该考虑什么？

我想过去我发表的大部分评论都是在内容审核的背景下。过去 **10年** 在这方面是一段有趣的旅程。这显然是一个有趣的时代。关于在线内容审核，出现了一些新颖的问题。其中一些导致了富有成效的新系统被构建，比如我们的AI系统，用于检测民族国家试图干预彼此的选举。我认为我们将继续构建这些东西，这总体上是积极的。

在其他一些方面，我们走了一些弯路。我只是认为**事实核查**（Fact-checking: 对信息进行验证，以确定其真实性和准确性）不如 **Community Notes** 有效，因为它不是一个互联网规模的解决方案。事实核查员不够多，人们也不信任特定的事实核查员。你需要一个更健壮的系统。所以我认为我们通过 **Community Notes** 得到的才是正确的。但我的观点更多是，历史上我可能在一些政府没有真正管辖权的事情上，对媒体的批评或政府的意见过于顺从。但作为一个核心人物，我认为我们曾试图构建一些系统，也许我们不必自己做出所有的内容审核决定。

我想过去 **10年** 的成长过程的一部分是意识到：“好吧，我们是一家有影响力的公司。我们需要对我们必须做出的决定负责。我们应该听取人们的反馈，但不应该过度顺从那些实际上没有管辖权的人。因为归根结底，我们身处这个位置，我们需要对我们做出的决定负责。”这是一个成熟的过程，在某些方面是痛苦的，但我认为我们因此成为了一家更好的公司。

关税会增加美国数据中心的建设成本，并将建设转移到欧洲和亚洲吗？这真的很难说会如何发展。我认为我们可能还处于早期阶段，很难知道。

你一周中杠杆率最高的一个小时是在做什么？你在这一个小时里在做什么？我不知道。每周都有些不同。杠杆率最高的事情每周都不一样，这可能是必然的。否则，从定义上讲，你每周都应该花不止一个小时做那件事。我不知道。这份工作的乐趣之一，以及这个行业如此充满活力的原因，就是事情变化很快。现在的世界与年初、甚至六个月前或去年年中都大不相同。我认为很多事情都取得了有意义的进展。自从我们上次坐下来以来，很多牌都已经被翻开了。我想那大概是一年前吧？是的。我想你之前说过，招聘人才是你做的一件杠杆率极高的事情。是的，杠杆率非常高。

### AI驱动的创意与社会进步

你提到这些模型将在年底前达到中级软件工程师的水平。如果软件生产力在两年内提高 **100倍**，那会带来什么可能性？现在无法构建的哪些东西可以被构建出来？

什么样的东西？这是一个有趣的问题。这次对话的一个主题是，将被释放的创造力将是巨大的。如果你看看人类社会和经济在 **100到150年** 间的整体发展轨迹，基本上是人们从主要从事农业——大部分人类精力都用于养活自己——到这一比例越来越小。而那些满足我们基本物质需求的事情在人类精力中所占的比例也越来越小。这种转变带来了两个影响：一是更多的人从事创意和文化追求。二是更多的人总的来说工作时间更少，花在娱乐和文化上的时间更多。我认为随着这种情况的继续，这几乎肯定会持续下去。

这不是一两年内拥有一个超级强大的软件工程师会发生的事情。但随着时间的推移，如果每个人都拥有这些超人工具来创造大量不同的东西，你将获得令人难以置信的多样性。其中一部分将是解决难题：解决疾病，推进科学，开发改善我们生活的新技术。但我猜测其中很大一部分最终将是文化和社会追求以及娱乐。我猜测世界将变得更加有趣、更怪异、更奇特，就像过去 **10年** 互联网上的表情包一样。我认为这增加了一定的丰富性和深度。以有趣的方式，它实际上帮助你更好地与人连接。现在我整天都在互联网上寻找有趣的东西，然后发到我关心的人的群聊中，他们会觉得好笑。

今天人们可以制作的媒体，用来表达非常细致、具体的文化观念，真的很酷。这会继续发展。它确实在很多方面推动了社会进步，即使它不是“硬科学”那种治愈疾病的方式。如果你仔细想想，**Meta** 社交媒体对世界的看法是，是的，未来人们会花更多时间做这些事情。它会变得更好，它会帮助你连接，因为它会帮助表达不同的想法。世界会变得更复杂，但我们的技术，我们的文化技术，来表达这些非常复杂的事情——以一种非常有趣的短片或任何形式——会变得好得多。我认为这都很棒。

我不知道明年会怎样。另一个我认为有趣的观点是，我倾向于认为，至少在可预见的未来，这会带来对工作岗位的更多需求，而不是更少。现在，人们可以选择他们想花多少时间工作。我给你举一个我们最近讨论的有趣例子。我们每天有近 **35亿** 人使用我们的服务。我们一直以来都在努力解决的一个问题是，如何提供客户支持？

今天，你可以写电子邮件，但我们从未认真考虑过提供语音支持，让人们可以直接打电话进来。我想这也许是免费服务的一个特点。每人收入不足以支撑人们打电话进来的经济模型。但同时，每天有 **35亿** 人使用你的服务，电话量将是巨大的。那将是世界上最大的呼叫中心。每年需要 **100亿** 或 **200亿** 美元来配备人员。所以我们从未太认真地考虑过，因为它似乎总是没有道理。但现在，随着AI变得更好，你将达到一个AI可以处理很多人问题的地方。不是所有问题——也许 **10年** 后它可以处理所有问题——但从 **3-5年** 的时间范围来看，它将能够处理很多问题。这有点像自动驾驶汽车。它们可以处理很多地形，但在大多数情况下，它们还不能完全独立完成整个路线。人们认为卡车司机的工作会消失，但实际上，现在卡车司机的工作比我们 **20年前** 刚开始谈论自动驾驶汽车时还要多。

回到客户支持的事情，为每个人配备电话支持是没有意义的。但假设AI可以处理 **90%** 的问题。然后如果它不能处理，它就会转交给人工。如果你将提供该服务的成本降低到原来的十分之一，那么现在它可能就变得有意义了。那会很酷。所以最终结果是，我实际上认为我们可能会雇佣更多的客户支持人员。普遍的看法是AI会自动化掉工作。但技术史并非如此。通常，你创造的东西会减少 **90%** 的工作。

最后一个问题：今天世界上你最常向谁寻求建议？哦，天哪。我觉得我的一部分风格是我喜欢拥有广泛的顾问。不是只有一个人。我们有一个很棒的团队。公司里有人，董事会里有人。行业里有很多正在做新事情的人。没有一个单一的人。但这很有趣。而且，当世界充满活力时，仅仅因为喜欢的人一起做酷的事情而工作……对我来说，这就是生活的意义。

这是一个很好的结束语。谢谢你。